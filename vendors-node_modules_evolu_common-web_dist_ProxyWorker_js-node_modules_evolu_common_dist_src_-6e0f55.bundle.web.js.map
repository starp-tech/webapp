{"version":3,"file":"vendors-node_modules_evolu_common-web_dist_ProxyWorker_js-node_modules_evolu_common_dist_src_-6e0f55.bundle.web.js","mappings":";;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC/FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACjLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AClOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACxQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC1KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACxGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACvOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AClLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACpOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACtJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACpTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACrgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC1LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/LA;AA+BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;ACnGA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC9HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;ACpNA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACztEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACjeA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACryCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAuEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAqBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACx5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACz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zKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACvQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACrLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AC7DA;AACA;;;;;;;;;;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC1HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AC1dA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACrIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC//DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA6CA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvwEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACl0BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACthBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACrNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5fA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACh1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC5hCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9ZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA2BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA8BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AC9yGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA8BA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzlBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACrKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACh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l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nDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC9ZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7PA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC9LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACx6BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClkBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/uBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACrbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC1MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAiBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC10EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAgCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClhCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;ACxPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3uBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACvPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACvFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC10BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AClQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACjzBA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AChSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACn1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAoCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA+BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AC5tHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC/hBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAmDA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;ACvWA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACldA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACp4BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9qBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AClKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACzEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1PA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACvaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACrjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC3FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACjIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACjIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACjIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACzKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC1NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;AC5LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACl+DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACneA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACrbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AC5KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9VA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC5MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACpLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzuCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACheA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC5iCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC/LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACzxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACz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zxBA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACppFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACp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hHA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC1NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC3HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACzGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACjKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC9MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACj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nDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACzGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACRA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrCA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACxJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjDA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACNA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC9MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC7EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC9EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACfA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC9EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC3IA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACjHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5GA;AACA;AACA;;;;;;;;;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACxZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACnQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACjCA;AACA;AACA;;;;;;;;;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACnIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACdA;AACA;AACA","sources":["webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/assert.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/base64.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/binary-format-contract.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/binary-reader.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/binary-writer.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/goog-varint.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/json-format-contract.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/json-typings.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/lower-camel-case.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/message-type-contract.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/message-type.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/oneof.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/pb-long.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-binary-reader.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-binary-writer.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-create.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-equals.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-info.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-json-reader.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-json-writer.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-long-convert.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-merge-partial.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-scalar-default.js","webpack://starpyapp/./node_modules/@protobuf-ts/runtime/build/es2015/reflection-type-check.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/Cookies.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/Error.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/FileSystem.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/Headers.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/HttpClient.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/HttpClientError.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/HttpClientRequest.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/HttpClientResponse.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/HttpIncomingMessage.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/HttpMethod.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/HttpTraceContext.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/UrlParams.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/internal/error.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/internal/fileSystem.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/internal/httpBody.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/internal/httpClient.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/internal/httpClientError.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/internal/httpClientRequest.js","webpack://starpyapp/./node_modules/@effect/platform/dist/esm/internal/httpClientResponse.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/AST.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/Arbitrary.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/Equivalence.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/FastCheck.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/ParseResult.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/Pretty.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/Schema.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/TreeFormatter.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/internal/errors.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/internal/filters.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/internal/serializable.js","webpack://starpyapp/./node_modules/@effect/schema/dist/esm/internal/util.js","webpack://starpyapp/./node_modules/@evolu/common-web/dist/ProxyWorker.js","webpack://starpyapp/./node_modules/@evolu/common/dist/src/Config.js","webpack://starpyapp/./node_modules/@evolu/common/dist/src/Crdt.js","webpack://starpyapp/./node_modules/@evolu/common/dist/src/Crypto.js","webpack://starpyapp/./node_modules/@evolu/common/dist/src/Error.js","webpack://starpyapp/./node_modules/@evolu/common/dist/src/Murmurhash.js","webpack://starpyapp/./node_modules/@evolu/common/dist/src/Owner.js","webpack://starpyapp/./node_modules/@evolu/common/dist/src/Protobuf.js","webpack://starpyapp/./node_modules/@evolu/common/dist/src/Sync.js","webpack://starpyapp/./node_modules/@noble/ciphers/esm/_arx.js","webpack://starpyapp/./node_modules/@noble/ciphers/esm/_assert.js","webpack://starpyapp/./node_modules/@noble/ciphers/esm/_poly1305.js","webpack://starpyapp/./node_modules/@noble/ciphers/esm/salsa.js","webpack://starpyapp/./node_modules/@noble/ciphers/esm/utils.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/_assert.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/_md.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/_u64.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/crypto.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/hmac.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/pbkdf2.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/sha256.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/sha512.js","webpack://starpyapp/./node_modules/@noble/hashes/esm/utils.js","webpack://starpyapp/./node_modules/@scure/base/lib/esm/index.js","webpack://starpyapp/./node_modules/@scure/bip39/esm/index.js","webpack://starpyapp/./node_modules/@scure/bip39/esm/wordlists/english.js","webpack://starpyapp/./node_modules/effect/dist/esm/Array.js","webpack://starpyapp/./node_modules/effect/dist/esm/BigDecimal.js","webpack://starpyapp/./node_modules/effect/dist/esm/BigInt.js","webpack://starpyapp/./node_modules/effect/dist/esm/Boolean.js","webpack://starpyapp/./node_modules/effect/dist/esm/Brand.js","webpack://starpyapp/./node_modules/effect/dist/esm/Cause.js","webpack://starpyapp/./node_modules/effect/dist/esm/Channel.js","webpack://starpyapp/./node_modules/effect/dist/esm/Chunk.js","webpack://starpyapp/./node_modules/effect/dist/esm/Clock.js","webpack://starpyapp/./node_modules/effect/dist/esm/Config.js","webpack://starpyapp/./node_modules/effect/dist/esm/ConfigError.js","webpack://starpyapp/./node_modules/effect/dist/esm/Context.js","webpack://starpyapp/./node_modules/effect/dist/esm/Cron.js","webpack://starpyapp/./node_modules/effect/dist/esm/Data.js","webpack://starpyapp/./node_modules/effect/dist/esm/Deferred.js","webpack://starpyapp/./node_modules/effect/dist/esm/Differ.js","webpack://starpyapp/./node_modules/effect/dist/esm/Duration.js","webpack://starpyapp/./node_modules/effect/dist/esm/Effect.js","webpack://starpyapp/./node_modules/effect/dist/esm/Effectable.js","webpack://starpyapp/./node_modules/effect/dist/esm/Either.js","webpack://starpyapp/./node_modules/effect/dist/esm/Encoding.js","webpack://starpyapp/./node_modules/effect/dist/esm/Equal.js","webpack://starpyapp/./node_modules/effect/dist/esm/Equivalence.js","webpack://starpyapp/./node_modules/effect/dist/esm/ExecutionStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/Exit.js","webpack://starpyapp/./node_modules/effect/dist/esm/Fiber.js","webpack://starpyapp/./node_modules/effect/dist/esm/FiberId.js","webpack://starpyapp/./node_modules/effect/dist/esm/FiberRef.js","webpack://starpyapp/./node_modules/effect/dist/esm/FiberRefs.js","webpack://starpyapp/./node_modules/effect/dist/esm/FiberRefsPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/FiberStatus.js","webpack://starpyapp/./node_modules/effect/dist/esm/Function.js","webpack://starpyapp/./node_modules/effect/dist/esm/GlobalValue.js","webpack://starpyapp/./node_modules/effect/dist/esm/Hash.js","webpack://starpyapp/./node_modules/effect/dist/esm/HashMap.js","webpack://starpyapp/./node_modules/effect/dist/esm/HashSet.js","webpack://starpyapp/./node_modules/effect/dist/esm/Inspectable.js","webpack://starpyapp/./node_modules/effect/dist/esm/Iterable.js","webpack://starpyapp/./node_modules/effect/dist/esm/Layer.js","webpack://starpyapp/./node_modules/effect/dist/esm/List.js","webpack://starpyapp/./node_modules/effect/dist/esm/LogLevel.js","webpack://starpyapp/./node_modules/effect/dist/esm/LogSpan.js","webpack://starpyapp/./node_modules/effect/dist/esm/Logger.js","webpack://starpyapp/./node_modules/effect/dist/esm/ManagedRuntime.js","webpack://starpyapp/./node_modules/effect/dist/esm/Match.js","webpack://starpyapp/./node_modules/effect/dist/esm/MergeDecision.js","webpack://starpyapp/./node_modules/effect/dist/esm/Micro.js","webpack://starpyapp/./node_modules/effect/dist/esm/MutableHashMap.js","webpack://starpyapp/./node_modules/effect/dist/esm/MutableList.js","webpack://starpyapp/./node_modules/effect/dist/esm/MutableQueue.js","webpack://starpyapp/./node_modules/effect/dist/esm/MutableRef.js","webpack://starpyapp/./node_modules/effect/dist/esm/Number.js","webpack://starpyapp/./node_modules/effect/dist/esm/Option.js","webpack://starpyapp/./node_modules/effect/dist/esm/Order.js","webpack://starpyapp/./node_modules/effect/dist/esm/Pipeable.js","webpack://starpyapp/./node_modules/effect/dist/esm/Predicate.js","webpack://starpyapp/./node_modules/effect/dist/esm/PubSub.js","webpack://starpyapp/./node_modules/effect/dist/esm/Queue.js","webpack://starpyapp/./node_modules/effect/dist/esm/Random.js","webpack://starpyapp/./node_modules/effect/dist/esm/Readable.js","webpack://starpyapp/./node_modules/effect/dist/esm/Record.js","webpack://starpyapp/./node_modules/effect/dist/esm/RedBlackTree.js","webpack://starpyapp/./node_modules/effect/dist/esm/Redacted.js","webpack://starpyapp/./node_modules/effect/dist/esm/Ref.js","webpack://starpyapp/./node_modules/effect/dist/esm/RegExp.js","webpack://starpyapp/./node_modules/effect/dist/esm/Request.js","webpack://starpyapp/./node_modules/effect/dist/esm/Runtime.js","webpack://starpyapp/./node_modules/effect/dist/esm/RuntimeFlagsPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/Schedule.js","webpack://starpyapp/./node_modules/effect/dist/esm/ScheduleDecision.js","webpack://starpyapp/./node_modules/effect/dist/esm/ScheduleInterval.js","webpack://starpyapp/./node_modules/effect/dist/esm/ScheduleIntervals.js","webpack://starpyapp/./node_modules/effect/dist/esm/Scheduler.js","webpack://starpyapp/./node_modules/effect/dist/esm/Scope.js","webpack://starpyapp/./node_modules/effect/dist/esm/Sink.js","webpack://starpyapp/./node_modules/effect/dist/esm/SortedSet.js","webpack://starpyapp/./node_modules/effect/dist/esm/Stream.js","webpack://starpyapp/./node_modules/effect/dist/esm/StreamHaltStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/String.js","webpack://starpyapp/./node_modules/effect/dist/esm/Tracer.js","webpack://starpyapp/./node_modules/effect/dist/esm/Tuple.js","webpack://starpyapp/./node_modules/effect/dist/esm/Utils.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/array.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/blockedRequests.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/cache.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/cause.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/channelExecutor.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/channelState.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/childExecutorDecision.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/continuation.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/mergeDecision.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/mergeState.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/mergeStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/singleProducerAsyncInput.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/subexecutor.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/upstreamPullRequest.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/channel/upstreamPullStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/clock.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/completedRequestMap.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/concurrency.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/config.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/configError.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/configProvider.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/configProvider/pathPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/console.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/context.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/core-effect.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/core-stream.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/core.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/data.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/defaultServices.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/defaultServices/console.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/deferred.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/differ.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/differ/chunkPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/differ/contextPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/differ/hashMapPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/differ/hashSetPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/differ/orPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/differ/readonlyArrayPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/doNotation.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/effect/circular.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/effectable.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/either.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/encoding/base64.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/encoding/base64Url.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/encoding/common.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/encoding/hex.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/errors.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/executionStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/fiber.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/fiberId.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/fiberMessage.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/fiberRefs.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/fiberRefs/patch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/fiberRuntime.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/fiberScope.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/fiberStatus.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/groupBy.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/hashMap.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/hashMap/array.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/hashMap/bitwise.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/hashMap/config.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/hashMap/keySet.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/hashMap/node.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/hashSet.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/layer.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/layer/circular.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/logSpan.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/logger-circular.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/logger.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/managedRuntime.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/matcher.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric/boundaries.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric/hook.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric/key.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric/keyType.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric/label.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric/pair.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric/registry.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/metric/state.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/cause.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/channel.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/channelChildExecutorDecision.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/channelMergeDecision.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/channelMergeState.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/channelMergeStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/channelState.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/channelUpstreamPullRequest.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/channelUpstreamPullStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/config.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/configError.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/continuation.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/deferred.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/effect.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/layer.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/opCodes/streamHaltStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/option.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/pubsub.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/query.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/queue.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/random.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/redBlackTree.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/redBlackTree/iterator.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/redBlackTree/node.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/redacted.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/ref.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/request.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/ringBuffer.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/runtime.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/runtimeFlags.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/runtimeFlagsPatch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/schedule.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/schedule/decision.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/schedule/interval.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/schedule/intervals.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/secret.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/singleShotGen.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/sink.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stack.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/debounceState.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/emit.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/haltStrategy.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/handoff.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/handoffSignal.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/pull.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/sinkEndReason.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/zipAllState.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/stream/zipChunksState.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/string-utils.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/supervisor.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/supervisor/patch.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/synchronizedRef.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/take.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/tracer.js","webpack://starpyapp/./node_modules/effect/dist/esm/internal/version.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/AdapterArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/AlwaysShrinkableArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/ArrayArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/ArrayInt64Arbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/BigIntArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/CloneArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/CommandsArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/ConstantArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/FrequencyArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/GeneratorArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/IntegerArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/LazyArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/MixedCaseArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/SchedulerArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/StreamArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/SubarrayArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/TupleArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/WithShrinkFromOtherArbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/AnyArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/BoxedArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/CharacterArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/CharacterRangeArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/CompareFunctionArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/GeneratorValueBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/PaddedNumberArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/PartialRecordArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/RestrictedIntegerArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/StableArbitraryGeneratorCache.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/StringifiedNatArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/TypedIntArrayArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/UriPathArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/builders/UriQueryOrFragmentArbitraryBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/ArrayInt64.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/BiasNumericRange.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/BuildSchedulerFor.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/BuildSlicedGenerator.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/CustomEqualSet.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/DepthContext.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/DoubleHelpers.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/DoubleOnlyHelpers.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/EnumerableKeysExtractor.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/FloatHelpers.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/FloatOnlyHelpers.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/FloatingOnlyHelpers.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/InvalidSubdomainLabelFiIter.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/IsSubarrayOf.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/JsonConstraintsBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/MaxLengthFromMinLength.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/NoUndefinedAsContext.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/QualifiedObjectConstraints.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/ReadRegex.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/SameValueSet.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/SameValueZeroSet.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/SanitizeRegexAst.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/ShrinkBigInt.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/ShrinkInteger.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/SlicesForStringBuilder.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/StrictlyEqualSet.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/TextEscaper.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/ToggleFlags.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/helpers/TokenizeRegex.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/implementations/NoopSlicedGenerator.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/implementations/SchedulerImplem.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/implementations/SlicedBasedGenerator.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/ArrayToMap.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/ArrayToSet.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/CharsToString.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/CodePointsToString.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/EntitiesToIPv6.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/IndexToCharString.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/IndexToMappedConstant.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/IndexToPrintableIndex.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/KeyValuePairsToObject.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/NatToStringifiedNat.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/NumberToPaddedEight.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/PaddedEightsToUuid.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/PartsToUrl.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/PatternsToString.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/SegmentsToPath.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/StringToBase64.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/TimeToDate.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/UintToBase32String.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/UnboxedToBoxed.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/ValuesAndSeparateKeysToObject.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/_internals/mappers/WordsToLorem.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/anything.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/ascii.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/asciiString.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/base64.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/base64String.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/bigInt.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/bigInt64Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/bigIntN.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/bigUint.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/bigUint64Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/bigUintN.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/boolean.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/char.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/char16bits.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/clone.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/commands.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/compareBooleanFunc.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/compareFunc.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/constant.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/constantFrom.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/context.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/date.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/dictionary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/domain.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/double.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/emailAddress.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/falsy.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/float.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/float32Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/float64Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/fullUnicode.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/fullUnicodeString.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/func.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/gen.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/hexa.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/hexaString.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/infiniteStream.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/int16Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/int32Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/int8Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/integer.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/ipV4.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/ipV4Extended.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/ipV6.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/json.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/jsonValue.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/letrec.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/lorem.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/mapToConstant.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/maxSafeInteger.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/maxSafeNat.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/memo.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/mixedCase.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/nat.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/object.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/oneof.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/option.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/record.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/scheduler.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/shuffledSubarray.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/sparseArray.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/string.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/string16bits.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/stringMatching.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/stringOf.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/subarray.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/tuple.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/uint16Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/uint32Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/uint8Array.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/uint8ClampedArray.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/ulid.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/unicode.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/unicodeJson.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/unicodeJsonValue.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/unicodeString.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/uniqueArray.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/uuid.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/uuidV.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/webAuthority.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/webFragments.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/webPath.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/webQueryParameters.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/webSegment.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/arbitrary/webUrl.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/arbitrary/definition/Arbitrary.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/arbitrary/definition/Value.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/model/ModelRunner.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/model/ReplayPath.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/model/commands/CommandWrapper.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/model/commands/CommandsIterable.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/model/commands/ScheduledCommand.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/precondition/Pre.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/precondition/PreconditionFailure.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/AsyncProperty.generic.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/AsyncProperty.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/IRawProperty.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/IgnoreEqualValuesProperty.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/Property.generic.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/Property.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/SkipAfterProperty.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/TimeoutProperty.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/property/UnbiasedProperty.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/DecorateProperty.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/Runner.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/RunnerIterator.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/Sampler.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/SourceValuesIterator.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/Tosser.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/configuration/GlobalParameters.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/configuration/QualifiedParameters.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/configuration/VerbosityLevel.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/reporter/ExecutionStatus.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/reporter/RunExecution.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/utils/PathWalker.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/runner/utils/RunDetailsFormatter.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/check/symbols.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/fast-check-default.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/fast-check.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/random/generator/Random.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/stream/LazyIterableIterator.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/stream/Stream.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/stream/StreamHelpers.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/utils/apply.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/utils/globals.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/utils/hash.js","webpack://starpyapp/./node_modules/fast-check/lib/esm/utils/stringify.js","webpack://starpyapp/./node_modules/nanoid/index.browser.js","webpack://starpyapp/./node_modules/nanoid/url-alphabet/index.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/UniformArrayIntDistribution.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/UniformBigIntDistribution.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/UniformIntDistribution.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/UnsafeUniformArrayIntDistribution.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/UnsafeUniformBigIntDistribution.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/UnsafeUniformIntDistribution.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/internals/ArrayInt.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/internals/UnsafeUniformArrayIntDistributionInternal.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/distribution/internals/UnsafeUniformIntDistributionInternal.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/generator/LinearCongruential.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/generator/MersenneTwister.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/generator/RandomGenerator.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/generator/XorShift.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/generator/XoroShiro.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/pure-rand-default.js","webpack://starpyapp/./node_modules/pure-rand/lib/esm/pure-rand.js"],"sourcesContent":["/**\n * assert that condition is true or throw error (with message)\n */\nexport function assert(condition, msg) {\n    if (!condition) {\n        throw new Error(msg);\n    }\n}\n/**\n * assert that value cannot exist = type `never`. throw runtime error if it does.\n */\nexport function assertNever(value, msg) {\n    throw new Error(msg !== null && msg !== void 0 ? msg : 'Unexpected object: ' + value);\n}\nconst FLOAT32_MAX = 3.4028234663852886e+38, FLOAT32_MIN = -3.4028234663852886e+38, UINT32_MAX = 0xFFFFFFFF, INT32_MAX = 0X7FFFFFFF, INT32_MIN = -0X80000000;\nexport function assertInt32(arg) {\n    if (typeof arg !== \"number\")\n        throw new Error('invalid int 32: ' + typeof arg);\n    if (!Number.isInteger(arg) || arg > INT32_MAX || arg < INT32_MIN)\n        throw new Error('invalid int 32: ' + arg);\n}\nexport function assertUInt32(arg) {\n    if (typeof arg !== \"number\")\n        throw new Error('invalid uint 32: ' + typeof arg);\n    if (!Number.isInteger(arg) || arg > UINT32_MAX || arg < 0)\n        throw new Error('invalid uint 32: ' + arg);\n}\nexport function assertFloat32(arg) {\n    if (typeof arg !== \"number\")\n        throw new Error('invalid float 32: ' + typeof arg);\n    if (!Number.isFinite(arg))\n        return;\n    if (arg > FLOAT32_MAX || arg < FLOAT32_MIN)\n        throw new Error('invalid float 32: ' + arg);\n}\n","// lookup table from base64 character to byte\nlet encTable = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'.split('');\n// lookup table from base64 character *code* to byte because lookup by number is fast\nlet decTable = [];\nfor (let i = 0; i < encTable.length; i++)\n    decTable[encTable[i].charCodeAt(0)] = i;\n// support base64url variants\ndecTable[\"-\".charCodeAt(0)] = encTable.indexOf(\"+\");\ndecTable[\"_\".charCodeAt(0)] = encTable.indexOf(\"/\");\n/**\n * Decodes a base64 string to a byte array.\n *\n * - ignores white-space, including line breaks and tabs\n * - allows inner padding (can decode concatenated base64 strings)\n * - does not require padding\n * - understands base64url encoding:\n *   \"-\" instead of \"+\",\n *   \"_\" instead of \"/\",\n *   no padding\n */\nexport function base64decode(base64Str) {\n    // estimate byte size, not accounting for inner padding and whitespace\n    let es = base64Str.length * 3 / 4;\n    // if (es % 3 !== 0)\n    // throw new Error('invalid base64 string');\n    if (base64Str[base64Str.length - 2] == '=')\n        es -= 2;\n    else if (base64Str[base64Str.length - 1] == '=')\n        es -= 1;\n    let bytes = new Uint8Array(es), bytePos = 0, // position in byte array\n    groupPos = 0, // position in base64 group\n    b, // current byte\n    p = 0 // previous byte\n    ;\n    for (let i = 0; i < base64Str.length; i++) {\n        b = decTable[base64Str.charCodeAt(i)];\n        if (b === undefined) {\n            // noinspection FallThroughInSwitchStatementJS\n            switch (base64Str[i]) {\n                case '=':\n                    groupPos = 0; // reset state when padding found\n                case '\\n':\n                case '\\r':\n                case '\\t':\n                case ' ':\n                    continue; // skip white-space, and padding\n                default:\n                    throw Error(`invalid base64 string.`);\n            }\n        }\n        switch (groupPos) {\n            case 0:\n                p = b;\n                groupPos = 1;\n                break;\n            case 1:\n                bytes[bytePos++] = p << 2 | (b & 48) >> 4;\n                p = b;\n                groupPos = 2;\n                break;\n            case 2:\n                bytes[bytePos++] = (p & 15) << 4 | (b & 60) >> 2;\n                p = b;\n                groupPos = 3;\n                break;\n            case 3:\n                bytes[bytePos++] = (p & 3) << 6 | b;\n                groupPos = 0;\n                break;\n        }\n    }\n    if (groupPos == 1)\n        throw Error(`invalid base64 string.`);\n    return bytes.subarray(0, bytePos);\n}\n/**\n * Encodes a byte array to a base64 string.\n * Adds padding at the end.\n * Does not insert newlines.\n */\nexport function base64encode(bytes) {\n    let base64 = '', groupPos = 0, // position in base64 group\n    b, // current byte\n    p = 0; // carry over from previous byte\n    for (let i = 0; i < bytes.length; i++) {\n        b = bytes[i];\n        switch (groupPos) {\n            case 0:\n                base64 += encTable[b >> 2];\n                p = (b & 3) << 4;\n                groupPos = 1;\n                break;\n            case 1:\n                base64 += encTable[p | b >> 4];\n                p = (b & 15) << 2;\n                groupPos = 2;\n                break;\n            case 2:\n                base64 += encTable[p | b >> 6];\n                base64 += encTable[b & 63];\n                groupPos = 0;\n                break;\n        }\n    }\n    // padding required?\n    if (groupPos) {\n        base64 += encTable[p];\n        base64 += '=';\n        if (groupPos == 1)\n            base64 += '=';\n    }\n    return base64;\n}\n","/**\n * This handler implements the default behaviour for unknown fields.\n * When reading data, unknown fields are stored on the message, in a\n * symbol property.\n * When writing data, the symbol property is queried and unknown fields\n * are serialized into the output again.\n */\nexport var UnknownFieldHandler;\n(function (UnknownFieldHandler) {\n    /**\n     * The symbol used to store unknown fields for a message.\n     * The property must conform to `UnknownFieldContainer`.\n     */\n    UnknownFieldHandler.symbol = Symbol.for(\"protobuf-ts/unknown\");\n    /**\n     * Store an unknown field during binary read directly on the message.\n     * This method is compatible with `BinaryReadOptions.readUnknownField`.\n     */\n    UnknownFieldHandler.onRead = (typeName, message, fieldNo, wireType, data) => {\n        let container = is(message) ? message[UnknownFieldHandler.symbol] : message[UnknownFieldHandler.symbol] = [];\n        container.push({ no: fieldNo, wireType, data });\n    };\n    /**\n     * Write unknown fields stored for the message to the writer.\n     * This method is compatible with `BinaryWriteOptions.writeUnknownFields`.\n     */\n    UnknownFieldHandler.onWrite = (typeName, message, writer) => {\n        for (let { no, wireType, data } of UnknownFieldHandler.list(message))\n            writer.tag(no, wireType).raw(data);\n    };\n    /**\n     * List unknown fields stored for the message.\n     * Note that there may be multiples fields with the same number.\n     */\n    UnknownFieldHandler.list = (message, fieldNo) => {\n        if (is(message)) {\n            let all = message[UnknownFieldHandler.symbol];\n            return fieldNo ? all.filter(uf => uf.no == fieldNo) : all;\n        }\n        return [];\n    };\n    /**\n     * Returns the last unknown field by field number.\n     */\n    UnknownFieldHandler.last = (message, fieldNo) => UnknownFieldHandler.list(message, fieldNo).slice(-1)[0];\n    const is = (message) => message && Array.isArray(message[UnknownFieldHandler.symbol]);\n})(UnknownFieldHandler || (UnknownFieldHandler = {}));\n/**\n * Merges binary write or read options. Later values override earlier values.\n */\nexport function mergeBinaryOptions(a, b) {\n    return Object.assign(Object.assign({}, a), b);\n}\n/**\n * Protobuf binary format wire types.\n *\n * A wire type provides just enough information to find the length of the\n * following value.\n *\n * See https://developers.google.com/protocol-buffers/docs/encoding#structure\n */\nexport var WireType;\n(function (WireType) {\n    /**\n     * Used for int32, int64, uint32, uint64, sint32, sint64, bool, enum\n     */\n    WireType[WireType[\"Varint\"] = 0] = \"Varint\";\n    /**\n     * Used for fixed64, sfixed64, double.\n     * Always 8 bytes with little-endian byte order.\n     */\n    WireType[WireType[\"Bit64\"] = 1] = \"Bit64\";\n    /**\n     * Used for string, bytes, embedded messages, packed repeated fields\n     *\n     * Only repeated numeric types (types which use the varint, 32-bit,\n     * or 64-bit wire types) can be packed. In proto3, such fields are\n     * packed by default.\n     */\n    WireType[WireType[\"LengthDelimited\"] = 2] = \"LengthDelimited\";\n    /**\n     * Used for groups\n     * @deprecated\n     */\n    WireType[WireType[\"StartGroup\"] = 3] = \"StartGroup\";\n    /**\n     * Used for groups\n     * @deprecated\n     */\n    WireType[WireType[\"EndGroup\"] = 4] = \"EndGroup\";\n    /**\n     * Used for fixed32, sfixed32, float.\n     * Always 4 bytes with little-endian byte order.\n     */\n    WireType[WireType[\"Bit32\"] = 5] = \"Bit32\";\n})(WireType || (WireType = {}));\n","import { WireType } from \"./binary-format-contract\";\nimport { PbLong, PbULong } from \"./pb-long\";\nimport { varint32read, varint64read } from \"./goog-varint\";\nconst defaultsRead = {\n    readUnknownField: true,\n    readerFactory: bytes => new BinaryReader(bytes),\n};\n/**\n * Make options for reading binary data form partial options.\n */\nexport function binaryReadOptions(options) {\n    return options ? Object.assign(Object.assign({}, defaultsRead), options) : defaultsRead;\n}\nexport class BinaryReader {\n    constructor(buf, textDecoder) {\n        this.varint64 = varint64read; // dirty cast for `this`\n        /**\n         * Read a `uint32` field, an unsigned 32 bit varint.\n         */\n        this.uint32 = varint32read; // dirty cast for `this` and access to protected `buf`\n        this.buf = buf;\n        this.len = buf.length;\n        this.pos = 0;\n        this.view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        this.textDecoder = textDecoder !== null && textDecoder !== void 0 ? textDecoder : new TextDecoder(\"utf-8\", {\n            fatal: true,\n            ignoreBOM: true,\n        });\n    }\n    /**\n     * Reads a tag - field number and wire type.\n     */\n    tag() {\n        let tag = this.uint32(), fieldNo = tag >>> 3, wireType = tag & 7;\n        if (fieldNo <= 0 || wireType < 0 || wireType > 5)\n            throw new Error(\"illegal tag: field no \" + fieldNo + \" wire type \" + wireType);\n        return [fieldNo, wireType];\n    }\n    /**\n     * Skip one element on the wire and return the skipped data.\n     * Supports WireType.StartGroup since v2.0.0-alpha.23.\n     */\n    skip(wireType) {\n        let start = this.pos;\n        // noinspection FallThroughInSwitchStatementJS\n        switch (wireType) {\n            case WireType.Varint:\n                while (this.buf[this.pos++] & 0x80) {\n                    // ignore\n                }\n                break;\n            case WireType.Bit64:\n                this.pos += 4;\n            case WireType.Bit32:\n                this.pos += 4;\n                break;\n            case WireType.LengthDelimited:\n                let len = this.uint32();\n                this.pos += len;\n                break;\n            case WireType.StartGroup:\n                // From descriptor.proto: Group type is deprecated, not supported in proto3.\n                // But we must still be able to parse and treat as unknown.\n                let t;\n                while ((t = this.tag()[1]) !== WireType.EndGroup) {\n                    this.skip(t);\n                }\n                break;\n            default:\n                throw new Error(\"cant skip wire type \" + wireType);\n        }\n        this.assertBounds();\n        return this.buf.subarray(start, this.pos);\n    }\n    /**\n     * Throws error if position in byte array is out of range.\n     */\n    assertBounds() {\n        if (this.pos > this.len)\n            throw new RangeError(\"premature EOF\");\n    }\n    /**\n     * Read a `int32` field, a signed 32 bit varint.\n     */\n    int32() {\n        return this.uint32() | 0;\n    }\n    /**\n     * Read a `sint32` field, a signed, zigzag-encoded 32-bit varint.\n     */\n    sint32() {\n        let zze = this.uint32();\n        // decode zigzag\n        return (zze >>> 1) ^ -(zze & 1);\n    }\n    /**\n     * Read a `int64` field, a signed 64-bit varint.\n     */\n    int64() {\n        return new PbLong(...this.varint64());\n    }\n    /**\n     * Read a `uint64` field, an unsigned 64-bit varint.\n     */\n    uint64() {\n        return new PbULong(...this.varint64());\n    }\n    /**\n     * Read a `sint64` field, a signed, zig-zag-encoded 64-bit varint.\n     */\n    sint64() {\n        let [lo, hi] = this.varint64();\n        // decode zig zag\n        let s = -(lo & 1);\n        lo = ((lo >>> 1 | (hi & 1) << 31) ^ s);\n        hi = (hi >>> 1 ^ s);\n        return new PbLong(lo, hi);\n    }\n    /**\n     * Read a `bool` field, a variant.\n     */\n    bool() {\n        let [lo, hi] = this.varint64();\n        return lo !== 0 || hi !== 0;\n    }\n    /**\n     * Read a `fixed32` field, an unsigned, fixed-length 32-bit integer.\n     */\n    fixed32() {\n        return this.view.getUint32((this.pos += 4) - 4, true);\n    }\n    /**\n     * Read a `sfixed32` field, a signed, fixed-length 32-bit integer.\n     */\n    sfixed32() {\n        return this.view.getInt32((this.pos += 4) - 4, true);\n    }\n    /**\n     * Read a `fixed64` field, an unsigned, fixed-length 64 bit integer.\n     */\n    fixed64() {\n        return new PbULong(this.sfixed32(), this.sfixed32());\n    }\n    /**\n     * Read a `fixed64` field, a signed, fixed-length 64-bit integer.\n     */\n    sfixed64() {\n        return new PbLong(this.sfixed32(), this.sfixed32());\n    }\n    /**\n     * Read a `float` field, 32-bit floating point number.\n     */\n    float() {\n        return this.view.getFloat32((this.pos += 4) - 4, true);\n    }\n    /**\n     * Read a `double` field, a 64-bit floating point number.\n     */\n    double() {\n        return this.view.getFloat64((this.pos += 8) - 8, true);\n    }\n    /**\n     * Read a `bytes` field, length-delimited arbitrary data.\n     */\n    bytes() {\n        let len = this.uint32();\n        let start = this.pos;\n        this.pos += len;\n        this.assertBounds();\n        return this.buf.subarray(start, start + len);\n    }\n    /**\n     * Read a `string` field, length-delimited data converted to UTF-8 text.\n     */\n    string() {\n        return this.textDecoder.decode(this.bytes());\n    }\n}\n","import { PbLong, PbULong } from \"./pb-long\";\nimport { varint32write, varint64write } from \"./goog-varint\";\nimport { assertFloat32, assertInt32, assertUInt32 } from \"./assert\";\nconst defaultsWrite = {\n    writeUnknownFields: true,\n    writerFactory: () => new BinaryWriter(),\n};\n/**\n * Make options for writing binary data form partial options.\n */\nexport function binaryWriteOptions(options) {\n    return options ? Object.assign(Object.assign({}, defaultsWrite), options) : defaultsWrite;\n}\nexport class BinaryWriter {\n    constructor(textEncoder) {\n        /**\n         * Previous fork states.\n         */\n        this.stack = [];\n        this.textEncoder = textEncoder !== null && textEncoder !== void 0 ? textEncoder : new TextEncoder();\n        this.chunks = [];\n        this.buf = [];\n    }\n    /**\n     * Return all bytes written and reset this writer.\n     */\n    finish() {\n        this.chunks.push(new Uint8Array(this.buf)); // flush the buffer\n        let len = 0;\n        for (let i = 0; i < this.chunks.length; i++)\n            len += this.chunks[i].length;\n        let bytes = new Uint8Array(len);\n        let offset = 0;\n        for (let i = 0; i < this.chunks.length; i++) {\n            bytes.set(this.chunks[i], offset);\n            offset += this.chunks[i].length;\n        }\n        this.chunks = [];\n        return bytes;\n    }\n    /**\n     * Start a new fork for length-delimited data like a message\n     * or a packed repeated field.\n     *\n     * Must be joined later with `join()`.\n     */\n    fork() {\n        this.stack.push({ chunks: this.chunks, buf: this.buf });\n        this.chunks = [];\n        this.buf = [];\n        return this;\n    }\n    /**\n     * Join the last fork. Write its length and bytes, then\n     * return to the previous state.\n     */\n    join() {\n        // get chunk of fork\n        let chunk = this.finish();\n        // restore previous state\n        let prev = this.stack.pop();\n        if (!prev)\n            throw new Error('invalid state, fork stack empty');\n        this.chunks = prev.chunks;\n        this.buf = prev.buf;\n        // write length of chunk as varint\n        this.uint32(chunk.byteLength);\n        return this.raw(chunk);\n    }\n    /**\n     * Writes a tag (field number and wire type).\n     *\n     * Equivalent to `uint32( (fieldNo << 3 | type) >>> 0 )`.\n     *\n     * Generated code should compute the tag ahead of time and call `uint32()`.\n     */\n    tag(fieldNo, type) {\n        return this.uint32((fieldNo << 3 | type) >>> 0);\n    }\n    /**\n     * Write a chunk of raw bytes.\n     */\n    raw(chunk) {\n        if (this.buf.length) {\n            this.chunks.push(new Uint8Array(this.buf));\n            this.buf = [];\n        }\n        this.chunks.push(chunk);\n        return this;\n    }\n    /**\n     * Write a `uint32` value, an unsigned 32 bit varint.\n     */\n    uint32(value) {\n        assertUInt32(value);\n        // write value as varint 32, inlined for speed\n        while (value > 0x7f) {\n            this.buf.push((value & 0x7f) | 0x80);\n            value = value >>> 7;\n        }\n        this.buf.push(value);\n        return this;\n    }\n    /**\n     * Write a `int32` value, a signed 32 bit varint.\n     */\n    int32(value) {\n        assertInt32(value);\n        varint32write(value, this.buf);\n        return this;\n    }\n    /**\n     * Write a `bool` value, a variant.\n     */\n    bool(value) {\n        this.buf.push(value ? 1 : 0);\n        return this;\n    }\n    /**\n     * Write a `bytes` value, length-delimited arbitrary data.\n     */\n    bytes(value) {\n        this.uint32(value.byteLength); // write length of chunk as varint\n        return this.raw(value);\n    }\n    /**\n     * Write a `string` value, length-delimited data converted to UTF-8 text.\n     */\n    string(value) {\n        let chunk = this.textEncoder.encode(value);\n        this.uint32(chunk.byteLength); // write length of chunk as varint\n        return this.raw(chunk);\n    }\n    /**\n     * Write a `float` value, 32-bit floating point number.\n     */\n    float(value) {\n        assertFloat32(value);\n        let chunk = new Uint8Array(4);\n        new DataView(chunk.buffer).setFloat32(0, value, true);\n        return this.raw(chunk);\n    }\n    /**\n     * Write a `double` value, a 64-bit floating point number.\n     */\n    double(value) {\n        let chunk = new Uint8Array(8);\n        new DataView(chunk.buffer).setFloat64(0, value, true);\n        return this.raw(chunk);\n    }\n    /**\n     * Write a `fixed32` value, an unsigned, fixed-length 32-bit integer.\n     */\n    fixed32(value) {\n        assertUInt32(value);\n        let chunk = new Uint8Array(4);\n        new DataView(chunk.buffer).setUint32(0, value, true);\n        return this.raw(chunk);\n    }\n    /**\n     * Write a `sfixed32` value, a signed, fixed-length 32-bit integer.\n     */\n    sfixed32(value) {\n        assertInt32(value);\n        let chunk = new Uint8Array(4);\n        new DataView(chunk.buffer).setInt32(0, value, true);\n        return this.raw(chunk);\n    }\n    /**\n     * Write a `sint32` value, a signed, zigzag-encoded 32-bit varint.\n     */\n    sint32(value) {\n        assertInt32(value);\n        // zigzag encode\n        value = ((value << 1) ^ (value >> 31)) >>> 0;\n        varint32write(value, this.buf);\n        return this;\n    }\n    /**\n     * Write a `fixed64` value, a signed, fixed-length 64-bit integer.\n     */\n    sfixed64(value) {\n        let chunk = new Uint8Array(8);\n        let view = new DataView(chunk.buffer);\n        let long = PbLong.from(value);\n        view.setInt32(0, long.lo, true);\n        view.setInt32(4, long.hi, true);\n        return this.raw(chunk);\n    }\n    /**\n     * Write a `fixed64` value, an unsigned, fixed-length 64 bit integer.\n     */\n    fixed64(value) {\n        let chunk = new Uint8Array(8);\n        let view = new DataView(chunk.buffer);\n        let long = PbULong.from(value);\n        view.setInt32(0, long.lo, true);\n        view.setInt32(4, long.hi, true);\n        return this.raw(chunk);\n    }\n    /**\n     * Write a `int64` value, a signed 64-bit varint.\n     */\n    int64(value) {\n        let long = PbLong.from(value);\n        varint64write(long.lo, long.hi, this.buf);\n        return this;\n    }\n    /**\n     * Write a `sint64` value, a signed, zig-zag-encoded 64-bit varint.\n     */\n    sint64(value) {\n        let long = PbLong.from(value), \n        // zigzag encode\n        sign = long.hi >> 31, lo = (long.lo << 1) ^ sign, hi = ((long.hi << 1) | (long.lo >>> 31)) ^ sign;\n        varint64write(lo, hi, this.buf);\n        return this;\n    }\n    /**\n     * Write a `uint64` value, an unsigned 64-bit varint.\n     */\n    uint64(value) {\n        let long = PbULong.from(value);\n        varint64write(long.lo, long.hi, this.buf);\n        return this;\n    }\n}\n","// Copyright 2008 Google Inc.  All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n//\n// * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n// * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n// * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n// Code generated by the Protocol Buffer compiler is owned by the owner\n// of the input file used when generating it.  This code is not\n// standalone and requires a support library to be linked with it.  This\n// support library is itself covered by the above license.\n/**\n * Read a 64 bit varint as two JS numbers.\n *\n * Returns tuple:\n * [0]: low bits\n * [0]: high bits\n *\n * Copyright 2008 Google Inc.  All rights reserved.\n *\n * See https://github.com/protocolbuffers/protobuf/blob/8a71927d74a4ce34efe2d8769fda198f52d20d12/js/experimental/runtime/kernel/buffer_decoder.js#L175\n */\nexport function varint64read() {\n    let lowBits = 0;\n    let highBits = 0;\n    for (let shift = 0; shift < 28; shift += 7) {\n        let b = this.buf[this.pos++];\n        lowBits |= (b & 0x7F) << shift;\n        if ((b & 0x80) == 0) {\n            this.assertBounds();\n            return [lowBits, highBits];\n        }\n    }\n    let middleByte = this.buf[this.pos++];\n    // last four bits of the first 32 bit number\n    lowBits |= (middleByte & 0x0F) << 28;\n    // 3 upper bits are part of the next 32 bit number\n    highBits = (middleByte & 0x70) >> 4;\n    if ((middleByte & 0x80) == 0) {\n        this.assertBounds();\n        return [lowBits, highBits];\n    }\n    for (let shift = 3; shift <= 31; shift += 7) {\n        let b = this.buf[this.pos++];\n        highBits |= (b & 0x7F) << shift;\n        if ((b & 0x80) == 0) {\n            this.assertBounds();\n            return [lowBits, highBits];\n        }\n    }\n    throw new Error('invalid varint');\n}\n/**\n * Write a 64 bit varint, given as two JS numbers, to the given bytes array.\n *\n * Copyright 2008 Google Inc.  All rights reserved.\n *\n * See https://github.com/protocolbuffers/protobuf/blob/8a71927d74a4ce34efe2d8769fda198f52d20d12/js/experimental/runtime/kernel/writer.js#L344\n */\nexport function varint64write(lo, hi, bytes) {\n    for (let i = 0; i < 28; i = i + 7) {\n        const shift = lo >>> i;\n        const hasNext = !((shift >>> 7) == 0 && hi == 0);\n        const byte = (hasNext ? shift | 0x80 : shift) & 0xFF;\n        bytes.push(byte);\n        if (!hasNext) {\n            return;\n        }\n    }\n    const splitBits = ((lo >>> 28) & 0x0F) | ((hi & 0x07) << 4);\n    const hasMoreBits = !((hi >> 3) == 0);\n    bytes.push((hasMoreBits ? splitBits | 0x80 : splitBits) & 0xFF);\n    if (!hasMoreBits) {\n        return;\n    }\n    for (let i = 3; i < 31; i = i + 7) {\n        const shift = hi >>> i;\n        const hasNext = !((shift >>> 7) == 0);\n        const byte = (hasNext ? shift | 0x80 : shift) & 0xFF;\n        bytes.push(byte);\n        if (!hasNext) {\n            return;\n        }\n    }\n    bytes.push((hi >>> 31) & 0x01);\n}\n// constants for binary math\nconst TWO_PWR_32_DBL = (1 << 16) * (1 << 16);\n/**\n * Parse decimal string of 64 bit integer value as two JS numbers.\n *\n * Returns tuple:\n * [0]: minus sign?\n * [1]: low bits\n * [2]: high bits\n *\n * Copyright 2008 Google Inc.\n */\nexport function int64fromString(dec) {\n    // Check for minus sign.\n    let minus = dec[0] == '-';\n    if (minus)\n        dec = dec.slice(1);\n    // Work 6 decimal digits at a time, acting like we're converting base 1e6\n    // digits to binary. This is safe to do with floating point math because\n    // Number.isSafeInteger(ALL_32_BITS * 1e6) == true.\n    const base = 1e6;\n    let lowBits = 0;\n    let highBits = 0;\n    function add1e6digit(begin, end) {\n        // Note: Number('') is 0.\n        const digit1e6 = Number(dec.slice(begin, end));\n        highBits *= base;\n        lowBits = lowBits * base + digit1e6;\n        // Carry bits from lowBits to highBits\n        if (lowBits >= TWO_PWR_32_DBL) {\n            highBits = highBits + ((lowBits / TWO_PWR_32_DBL) | 0);\n            lowBits = lowBits % TWO_PWR_32_DBL;\n        }\n    }\n    add1e6digit(-24, -18);\n    add1e6digit(-18, -12);\n    add1e6digit(-12, -6);\n    add1e6digit(-6);\n    return [minus, lowBits, highBits];\n}\n/**\n * Format 64 bit integer value (as two JS numbers) to decimal string.\n *\n * Copyright 2008 Google Inc.\n */\nexport function int64toString(bitsLow, bitsHigh) {\n    // Skip the expensive conversion if the number is small enough to use the\n    // built-in conversions.\n    if ((bitsHigh >>> 0) <= 0x1FFFFF) {\n        return '' + (TWO_PWR_32_DBL * bitsHigh + (bitsLow >>> 0));\n    }\n    // What this code is doing is essentially converting the input number from\n    // base-2 to base-1e7, which allows us to represent the 64-bit range with\n    // only 3 (very large) digits. Those digits are then trivial to convert to\n    // a base-10 string.\n    // The magic numbers used here are -\n    // 2^24 = 16777216 = (1,6777216) in base-1e7.\n    // 2^48 = 281474976710656 = (2,8147497,6710656) in base-1e7.\n    // Split 32:32 representation into 16:24:24 representation so our\n    // intermediate digits don't overflow.\n    let low = bitsLow & 0xFFFFFF;\n    let mid = (((bitsLow >>> 24) | (bitsHigh << 8)) >>> 0) & 0xFFFFFF;\n    let high = (bitsHigh >> 16) & 0xFFFF;\n    // Assemble our three base-1e7 digits, ignoring carries. The maximum\n    // value in a digit at this step is representable as a 48-bit integer, which\n    // can be stored in a 64-bit floating point number.\n    let digitA = low + (mid * 6777216) + (high * 6710656);\n    let digitB = mid + (high * 8147497);\n    let digitC = (high * 2);\n    // Apply carries from A to B and from B to C.\n    let base = 10000000;\n    if (digitA >= base) {\n        digitB += Math.floor(digitA / base);\n        digitA %= base;\n    }\n    if (digitB >= base) {\n        digitC += Math.floor(digitB / base);\n        digitB %= base;\n    }\n    // Convert base-1e7 digits to base-10, with optional leading zeroes.\n    function decimalFrom1e7(digit1e7, needLeadingZeros) {\n        let partial = digit1e7 ? String(digit1e7) : '';\n        if (needLeadingZeros) {\n            return '0000000'.slice(partial.length) + partial;\n        }\n        return partial;\n    }\n    return decimalFrom1e7(digitC, /*needLeadingZeros=*/ 0) +\n        decimalFrom1e7(digitB, /*needLeadingZeros=*/ digitC) +\n        // If the final 1e7 digit didn't need leading zeros, we would have\n        // returned via the trivial code path at the top.\n        decimalFrom1e7(digitA, /*needLeadingZeros=*/ 1);\n}\n/**\n * Write a 32 bit varint, signed or unsigned. Same as `varint64write(0, value, bytes)`\n *\n * Copyright 2008 Google Inc.  All rights reserved.\n *\n * See https://github.com/protocolbuffers/protobuf/blob/1b18833f4f2a2f681f4e4a25cdf3b0a43115ec26/js/binary/encoder.js#L144\n */\nexport function varint32write(value, bytes) {\n    if (value >= 0) {\n        // write value as varint 32\n        while (value > 0x7f) {\n            bytes.push((value & 0x7f) | 0x80);\n            value = value >>> 7;\n        }\n        bytes.push(value);\n    }\n    else {\n        for (let i = 0; i < 9; i++) {\n            bytes.push(value & 127 | 128);\n            value = value >> 7;\n        }\n        bytes.push(1);\n    }\n}\n/**\n * Read an unsigned 32 bit varint.\n *\n * See https://github.com/protocolbuffers/protobuf/blob/8a71927d74a4ce34efe2d8769fda198f52d20d12/js/experimental/runtime/kernel/buffer_decoder.js#L220\n */\nexport function varint32read() {\n    let b = this.buf[this.pos++];\n    let result = b & 0x7F;\n    if ((b & 0x80) == 0) {\n        this.assertBounds();\n        return result;\n    }\n    b = this.buf[this.pos++];\n    result |= (b & 0x7F) << 7;\n    if ((b & 0x80) == 0) {\n        this.assertBounds();\n        return result;\n    }\n    b = this.buf[this.pos++];\n    result |= (b & 0x7F) << 14;\n    if ((b & 0x80) == 0) {\n        this.assertBounds();\n        return result;\n    }\n    b = this.buf[this.pos++];\n    result |= (b & 0x7F) << 21;\n    if ((b & 0x80) == 0) {\n        this.assertBounds();\n        return result;\n    }\n    // Extract only last 4 bits\n    b = this.buf[this.pos++];\n    result |= (b & 0x0F) << 28;\n    for (let readBytes = 5; ((b & 0x80) !== 0) && readBytes < 10; readBytes++)\n        b = this.buf[this.pos++];\n    if ((b & 0x80) != 0)\n        throw new Error('invalid varint');\n    this.assertBounds();\n    // Result can have 32 bits, convert it to unsigned\n    return result >>> 0;\n}\n","const defaultsWrite = {\n    emitDefaultValues: false,\n    enumAsInteger: false,\n    useProtoFieldName: false,\n    prettySpaces: 0,\n}, defaultsRead = {\n    ignoreUnknownFields: false,\n};\n/**\n * Make options for reading JSON data from partial options.\n */\nexport function jsonReadOptions(options) {\n    return options ? Object.assign(Object.assign({}, defaultsRead), options) : defaultsRead;\n}\n/**\n * Make options for writing JSON data from partial options.\n */\nexport function jsonWriteOptions(options) {\n    return options ? Object.assign(Object.assign({}, defaultsWrite), options) : defaultsWrite;\n}\n/**\n * Merges JSON write or read options. Later values override earlier values. Type registries are merged.\n */\nexport function mergeJsonOptions(a, b) {\n    var _a, _b;\n    let c = Object.assign(Object.assign({}, a), b);\n    c.typeRegistry = [...((_a = a === null || a === void 0 ? void 0 : a.typeRegistry) !== null && _a !== void 0 ? _a : []), ...((_b = b === null || b === void 0 ? void 0 : b.typeRegistry) !== null && _b !== void 0 ? _b : [])];\n    return c;\n}\n","/**\n * Get the type of a JSON value.\n * Distinguishes between array, null and object.\n */\nexport function typeofJsonValue(value) {\n    let t = typeof value;\n    if (t == \"object\") {\n        if (Array.isArray(value))\n            return \"array\";\n        if (value === null)\n            return \"null\";\n    }\n    return t;\n}\n/**\n * Is this a JSON object (instead of an array or null)?\n */\nexport function isJsonObject(value) {\n    return value !== null && typeof value == \"object\" && !Array.isArray(value);\n}\n","/**\n * Converts snake_case to lowerCamelCase.\n *\n * Should behave like protoc:\n * https://github.com/protocolbuffers/protobuf/blob/e8ae137c96444ea313485ed1118c5e43b2099cf1/src/google/protobuf/compiler/java/java_helpers.cc#L118\n */\nexport function lowerCamelCase(snakeCase) {\n    let capNext = false;\n    const sb = [];\n    for (let i = 0; i < snakeCase.length; i++) {\n        let next = snakeCase.charAt(i);\n        if (next == '_') {\n            capNext = true;\n        }\n        else if (/\\d/.test(next)) {\n            sb.push(next);\n            capNext = true;\n        }\n        else if (capNext) {\n            sb.push(next.toUpperCase());\n            capNext = false;\n        }\n        else if (i == 0) {\n            sb.push(next.toLowerCase());\n        }\n        else {\n            sb.push(next);\n        }\n    }\n    return sb.join('');\n}\n","/**\n * The symbol used as a key on message objects to store the message type.\n *\n * Note that this is an experimental feature - it is here to stay, but\n * implementation details may change without notice.\n */\nexport const MESSAGE_TYPE = Symbol.for(\"protobuf-ts/message-type\");\n","import { MESSAGE_TYPE } from \"./message-type-contract\";\nimport { normalizeFieldInfo } from \"./reflection-info\";\nimport { ReflectionTypeCheck } from \"./reflection-type-check\";\nimport { ReflectionJsonReader } from \"./reflection-json-reader\";\nimport { ReflectionJsonWriter } from \"./reflection-json-writer\";\nimport { ReflectionBinaryReader } from \"./reflection-binary-reader\";\nimport { ReflectionBinaryWriter } from \"./reflection-binary-writer\";\nimport { reflectionCreate } from \"./reflection-create\";\nimport { reflectionMergePartial } from \"./reflection-merge-partial\";\nimport { typeofJsonValue } from \"./json-typings\";\nimport { jsonReadOptions, jsonWriteOptions, } from \"./json-format-contract\";\nimport { reflectionEquals } from \"./reflection-equals\";\nimport { binaryWriteOptions } from \"./binary-writer\";\nimport { binaryReadOptions } from \"./binary-reader\";\nconst baseDescriptors = Object.getOwnPropertyDescriptors(Object.getPrototypeOf({}));\n/**\n * This standard message type provides reflection-based\n * operations to work with a message.\n */\nexport class MessageType {\n    constructor(name, fields, options) {\n        this.defaultCheckDepth = 16;\n        this.typeName = name;\n        this.fields = fields.map(normalizeFieldInfo);\n        this.options = options !== null && options !== void 0 ? options : {};\n        this.messagePrototype = Object.create(null, Object.assign(Object.assign({}, baseDescriptors), { [MESSAGE_TYPE]: { value: this } }));\n        this.refTypeCheck = new ReflectionTypeCheck(this);\n        this.refJsonReader = new ReflectionJsonReader(this);\n        this.refJsonWriter = new ReflectionJsonWriter(this);\n        this.refBinReader = new ReflectionBinaryReader(this);\n        this.refBinWriter = new ReflectionBinaryWriter(this);\n    }\n    create(value) {\n        let message = reflectionCreate(this);\n        if (value !== undefined) {\n            reflectionMergePartial(this, message, value);\n        }\n        return message;\n    }\n    /**\n     * Clone the message.\n     *\n     * Unknown fields are discarded.\n     */\n    clone(message) {\n        let copy = this.create();\n        reflectionMergePartial(this, copy, message);\n        return copy;\n    }\n    /**\n     * Determines whether two message of the same type have the same field values.\n     * Checks for deep equality, traversing repeated fields, oneof groups, maps\n     * and messages recursively.\n     * Will also return true if both messages are `undefined`.\n     */\n    equals(a, b) {\n        return reflectionEquals(this, a, b);\n    }\n    /**\n     * Is the given value assignable to our message type\n     * and contains no [excess properties](https://www.typescriptlang.org/docs/handbook/interfaces.html#excess-property-checks)?\n     */\n    is(arg, depth = this.defaultCheckDepth) {\n        return this.refTypeCheck.is(arg, depth, false);\n    }\n    /**\n     * Is the given value assignable to our message type,\n     * regardless of [excess properties](https://www.typescriptlang.org/docs/handbook/interfaces.html#excess-property-checks)?\n     */\n    isAssignable(arg, depth = this.defaultCheckDepth) {\n        return this.refTypeCheck.is(arg, depth, true);\n    }\n    /**\n     * Copy partial data into the target message.\n     */\n    mergePartial(target, source) {\n        reflectionMergePartial(this, target, source);\n    }\n    /**\n     * Create a new message from binary format.\n     */\n    fromBinary(data, options) {\n        let opt = binaryReadOptions(options);\n        return this.internalBinaryRead(opt.readerFactory(data), data.byteLength, opt);\n    }\n    /**\n     * Read a new message from a JSON value.\n     */\n    fromJson(json, options) {\n        return this.internalJsonRead(json, jsonReadOptions(options));\n    }\n    /**\n     * Read a new message from a JSON string.\n     * This is equivalent to `T.fromJson(JSON.parse(json))`.\n     */\n    fromJsonString(json, options) {\n        let value = JSON.parse(json);\n        return this.fromJson(value, options);\n    }\n    /**\n     * Write the message to canonical JSON value.\n     */\n    toJson(message, options) {\n        return this.internalJsonWrite(message, jsonWriteOptions(options));\n    }\n    /**\n     * Convert the message to canonical JSON string.\n     * This is equivalent to `JSON.stringify(T.toJson(t))`\n     */\n    toJsonString(message, options) {\n        var _a;\n        let value = this.toJson(message, options);\n        return JSON.stringify(value, null, (_a = options === null || options === void 0 ? void 0 : options.prettySpaces) !== null && _a !== void 0 ? _a : 0);\n    }\n    /**\n     * Write the message to binary format.\n     */\n    toBinary(message, options) {\n        let opt = binaryWriteOptions(options);\n        return this.internalBinaryWrite(message, opt.writerFactory(), opt).finish();\n    }\n    /**\n     * This is an internal method. If you just want to read a message from\n     * JSON, use `fromJson()` or `fromJsonString()`.\n     *\n     * Reads JSON value and merges the fields into the target\n     * according to protobuf rules. If the target is omitted,\n     * a new instance is created first.\n     */\n    internalJsonRead(json, options, target) {\n        if (json !== null && typeof json == \"object\" && !Array.isArray(json)) {\n            let message = target !== null && target !== void 0 ? target : this.create();\n            this.refJsonReader.read(json, message, options);\n            return message;\n        }\n        throw new Error(`Unable to parse message ${this.typeName} from JSON ${typeofJsonValue(json)}.`);\n    }\n    /**\n     * This is an internal method. If you just want to write a message\n     * to JSON, use `toJson()` or `toJsonString().\n     *\n     * Writes JSON value and returns it.\n     */\n    internalJsonWrite(message, options) {\n        return this.refJsonWriter.write(message, options);\n    }\n    /**\n     * This is an internal method. If you just want to write a message\n     * in binary format, use `toBinary()`.\n     *\n     * Serializes the message in binary format and appends it to the given\n     * writer. Returns passed writer.\n     */\n    internalBinaryWrite(message, writer, options) {\n        this.refBinWriter.write(message, writer, options);\n        return writer;\n    }\n    /**\n     * This is an internal method. If you just want to read a message from\n     * binary data, use `fromBinary()`.\n     *\n     * Reads data from binary format and merges the fields into\n     * the target according to protobuf rules. If the target is\n     * omitted, a new instance is created first.\n     */\n    internalBinaryRead(reader, length, options, target) {\n        let message = target !== null && target !== void 0 ? target : this.create();\n        this.refBinReader.read(reader, message, options, length);\n        return message;\n    }\n}\n","/**\n * Is the given value a valid oneof group?\n *\n * We represent protobuf `oneof` as algebraic data types (ADT) in generated\n * code. But when working with messages of unknown type, the ADT does not\n * help us.\n *\n * This type guard checks if the given object adheres to the ADT rules, which\n * are as follows:\n *\n * 1) Must be an object.\n *\n * 2) Must have a \"oneofKind\" discriminator property.\n *\n * 3) If \"oneofKind\" is `undefined`, no member field is selected. The object\n * must not have any other properties.\n *\n * 4) If \"oneofKind\" is a `string`, the member field with this name is\n * selected.\n *\n * 5) If a member field is selected, the object must have a second property\n * with this name. The property must not be `undefined`.\n *\n * 6) No extra properties are allowed. The object has either one property\n * (no selection) or two properties (selection).\n *\n */\nexport function isOneofGroup(any) {\n    if (typeof any != 'object' || any === null || !any.hasOwnProperty('oneofKind')) {\n        return false;\n    }\n    switch (typeof any.oneofKind) {\n        case \"string\":\n            if (any[any.oneofKind] === undefined)\n                return false;\n            return Object.keys(any).length == 2;\n        case \"undefined\":\n            return Object.keys(any).length == 1;\n        default:\n            return false;\n    }\n}\n/**\n * Returns the value of the given field in a oneof group.\n */\nexport function getOneofValue(oneof, kind) {\n    return oneof[kind];\n}\nexport function setOneofValue(oneof, kind, value) {\n    if (oneof.oneofKind !== undefined) {\n        delete oneof[oneof.oneofKind];\n    }\n    oneof.oneofKind = kind;\n    if (value !== undefined) {\n        oneof[kind] = value;\n    }\n}\nexport function setUnknownOneofValue(oneof, kind, value) {\n    if (oneof.oneofKind !== undefined) {\n        delete oneof[oneof.oneofKind];\n    }\n    oneof.oneofKind = kind;\n    if (value !== undefined && kind !== undefined) {\n        oneof[kind] = value;\n    }\n}\n/**\n * Removes the selected field in a oneof group.\n *\n * Note that the recommended way to modify a oneof group is to set\n * a new object:\n *\n * ```ts\n * message.result = { oneofKind: undefined };\n * ```\n */\nexport function clearOneofValue(oneof) {\n    if (oneof.oneofKind !== undefined) {\n        delete oneof[oneof.oneofKind];\n    }\n    oneof.oneofKind = undefined;\n}\n/**\n * Returns the selected value of the given oneof group.\n *\n * Not that the recommended way to access a oneof group is to check\n * the \"oneofKind\" property and let TypeScript narrow down the union\n * type for you:\n *\n * ```ts\n * if (message.result.oneofKind === \"error\") {\n *   message.result.error; // string\n * }\n * ```\n *\n * In the rare case you just need the value, and do not care about\n * which protobuf field is selected, you can use this function\n * for convenience.\n */\nexport function getSelectedOneofValue(oneof) {\n    if (oneof.oneofKind === undefined) {\n        return undefined;\n    }\n    return oneof[oneof.oneofKind];\n}\n","import { int64fromString, int64toString } from \"./goog-varint\";\nlet BI;\nexport function detectBi() {\n    const dv = new DataView(new ArrayBuffer(8));\n    const ok = globalThis.BigInt !== undefined\n        && typeof dv.getBigInt64 === \"function\"\n        && typeof dv.getBigUint64 === \"function\"\n        && typeof dv.setBigInt64 === \"function\"\n        && typeof dv.setBigUint64 === \"function\";\n    BI = ok ? {\n        MIN: BigInt(\"-9223372036854775808\"),\n        MAX: BigInt(\"9223372036854775807\"),\n        UMIN: BigInt(\"0\"),\n        UMAX: BigInt(\"18446744073709551615\"),\n        C: BigInt,\n        V: dv,\n    } : undefined;\n}\ndetectBi();\nfunction assertBi(bi) {\n    if (!bi)\n        throw new Error(\"BigInt unavailable, see https://github.com/timostamm/protobuf-ts/blob/v1.0.8/MANUAL.md#bigint-support\");\n}\n// used to validate from(string) input (when bigint is unavailable)\nconst RE_DECIMAL_STR = /^-?[0-9]+$/;\n// constants for binary math\nconst TWO_PWR_32_DBL = 0x100000000;\nconst HALF_2_PWR_32 = 0x080000000;\n// base class for PbLong and PbULong provides shared code\nclass SharedPbLong {\n    /**\n     * Create a new instance with the given bits.\n     */\n    constructor(lo, hi) {\n        this.lo = lo | 0;\n        this.hi = hi | 0;\n    }\n    /**\n     * Is this instance equal to 0?\n     */\n    isZero() {\n        return this.lo == 0 && this.hi == 0;\n    }\n    /**\n     * Convert to a native number.\n     */\n    toNumber() {\n        let result = this.hi * TWO_PWR_32_DBL + (this.lo >>> 0);\n        if (!Number.isSafeInteger(result))\n            throw new Error(\"cannot convert to safe number\");\n        return result;\n    }\n}\n/**\n * 64-bit unsigned integer as two 32-bit values.\n * Converts between `string`, `number` and `bigint` representations.\n */\nexport class PbULong extends SharedPbLong {\n    /**\n     * Create instance from a `string`, `number` or `bigint`.\n     */\n    static from(value) {\n        if (BI)\n            // noinspection FallThroughInSwitchStatementJS\n            switch (typeof value) {\n                case \"string\":\n                    if (value == \"0\")\n                        return this.ZERO;\n                    if (value == \"\")\n                        throw new Error('string is no integer');\n                    value = BI.C(value);\n                case \"number\":\n                    if (value === 0)\n                        return this.ZERO;\n                    value = BI.C(value);\n                case \"bigint\":\n                    if (!value)\n                        return this.ZERO;\n                    if (value < BI.UMIN)\n                        throw new Error('signed value for ulong');\n                    if (value > BI.UMAX)\n                        throw new Error('ulong too large');\n                    BI.V.setBigUint64(0, value, true);\n                    return new PbULong(BI.V.getInt32(0, true), BI.V.getInt32(4, true));\n            }\n        else\n            switch (typeof value) {\n                case \"string\":\n                    if (value == \"0\")\n                        return this.ZERO;\n                    value = value.trim();\n                    if (!RE_DECIMAL_STR.test(value))\n                        throw new Error('string is no integer');\n                    let [minus, lo, hi] = int64fromString(value);\n                    if (minus)\n                        throw new Error('signed value for ulong');\n                    return new PbULong(lo, hi);\n                case \"number\":\n                    if (value == 0)\n                        return this.ZERO;\n                    if (!Number.isSafeInteger(value))\n                        throw new Error('number is no integer');\n                    if (value < 0)\n                        throw new Error('signed value for ulong');\n                    return new PbULong(value, value / TWO_PWR_32_DBL);\n            }\n        throw new Error('unknown value ' + typeof value);\n    }\n    /**\n     * Convert to decimal string.\n     */\n    toString() {\n        return BI ? this.toBigInt().toString() : int64toString(this.lo, this.hi);\n    }\n    /**\n     * Convert to native bigint.\n     */\n    toBigInt() {\n        assertBi(BI);\n        BI.V.setInt32(0, this.lo, true);\n        BI.V.setInt32(4, this.hi, true);\n        return BI.V.getBigUint64(0, true);\n    }\n}\n/**\n * ulong 0 singleton.\n */\nPbULong.ZERO = new PbULong(0, 0);\n/**\n * 64-bit signed integer as two 32-bit values.\n * Converts between `string`, `number` and `bigint` representations.\n */\nexport class PbLong extends SharedPbLong {\n    /**\n     * Create instance from a `string`, `number` or `bigint`.\n     */\n    static from(value) {\n        if (BI)\n            // noinspection FallThroughInSwitchStatementJS\n            switch (typeof value) {\n                case \"string\":\n                    if (value == \"0\")\n                        return this.ZERO;\n                    if (value == \"\")\n                        throw new Error('string is no integer');\n                    value = BI.C(value);\n                case \"number\":\n                    if (value === 0)\n                        return this.ZERO;\n                    value = BI.C(value);\n                case \"bigint\":\n                    if (!value)\n                        return this.ZERO;\n                    if (value < BI.MIN)\n                        throw new Error('signed long too small');\n                    if (value > BI.MAX)\n                        throw new Error('signed long too large');\n                    BI.V.setBigInt64(0, value, true);\n                    return new PbLong(BI.V.getInt32(0, true), BI.V.getInt32(4, true));\n            }\n        else\n            switch (typeof value) {\n                case \"string\":\n                    if (value == \"0\")\n                        return this.ZERO;\n                    value = value.trim();\n                    if (!RE_DECIMAL_STR.test(value))\n                        throw new Error('string is no integer');\n                    let [minus, lo, hi] = int64fromString(value);\n                    if (minus) {\n                        if (hi > HALF_2_PWR_32 || (hi == HALF_2_PWR_32 && lo != 0))\n                            throw new Error('signed long too small');\n                    }\n                    else if (hi >= HALF_2_PWR_32)\n                        throw new Error('signed long too large');\n                    let pbl = new PbLong(lo, hi);\n                    return minus ? pbl.negate() : pbl;\n                case \"number\":\n                    if (value == 0)\n                        return this.ZERO;\n                    if (!Number.isSafeInteger(value))\n                        throw new Error('number is no integer');\n                    return value > 0\n                        ? new PbLong(value, value / TWO_PWR_32_DBL)\n                        : new PbLong(-value, -value / TWO_PWR_32_DBL).negate();\n            }\n        throw new Error('unknown value ' + typeof value);\n    }\n    /**\n     * Do we have a minus sign?\n     */\n    isNegative() {\n        return (this.hi & HALF_2_PWR_32) !== 0;\n    }\n    /**\n     * Negate two's complement.\n     * Invert all the bits and add one to the result.\n     */\n    negate() {\n        let hi = ~this.hi, lo = this.lo;\n        if (lo)\n            lo = ~lo + 1;\n        else\n            hi += 1;\n        return new PbLong(lo, hi);\n    }\n    /**\n     * Convert to decimal string.\n     */\n    toString() {\n        if (BI)\n            return this.toBigInt().toString();\n        if (this.isNegative()) {\n            let n = this.negate();\n            return '-' + int64toString(n.lo, n.hi);\n        }\n        return int64toString(this.lo, this.hi);\n    }\n    /**\n     * Convert to native bigint.\n     */\n    toBigInt() {\n        assertBi(BI);\n        BI.V.setInt32(0, this.lo, true);\n        BI.V.setInt32(4, this.hi, true);\n        return BI.V.getBigInt64(0, true);\n    }\n}\n/**\n * long 0 singleton.\n */\nPbLong.ZERO = new PbLong(0, 0);\n","import { UnknownFieldHandler, WireType } from \"./binary-format-contract\";\nimport { LongType, ScalarType } from \"./reflection-info\";\nimport { reflectionLongConvert } from \"./reflection-long-convert\";\nimport { reflectionScalarDefault } from \"./reflection-scalar-default\";\n/**\n * Reads proto3 messages in binary format using reflection information.\n *\n * https://developers.google.com/protocol-buffers/docs/encoding\n */\nexport class ReflectionBinaryReader {\n    constructor(info) {\n        this.info = info;\n    }\n    prepare() {\n        var _a;\n        if (!this.fieldNoToField) {\n            const fieldsInput = (_a = this.info.fields) !== null && _a !== void 0 ? _a : [];\n            this.fieldNoToField = new Map(fieldsInput.map(field => [field.no, field]));\n        }\n    }\n    /**\n     * Reads a message from binary format into the target message.\n     *\n     * Repeated fields are appended. Map entries are added, overwriting\n     * existing keys.\n     *\n     * If a message field is already present, it will be merged with the\n     * new data.\n     */\n    read(reader, message, options, length) {\n        this.prepare();\n        const end = length === undefined ? reader.len : reader.pos + length;\n        while (reader.pos < end) {\n            // read the tag and find the field\n            const [fieldNo, wireType] = reader.tag(), field = this.fieldNoToField.get(fieldNo);\n            if (!field) {\n                let u = options.readUnknownField;\n                if (u == \"throw\")\n                    throw new Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.info.typeName}`);\n                let d = reader.skip(wireType);\n                if (u !== false)\n                    (u === true ? UnknownFieldHandler.onRead : u)(this.info.typeName, message, fieldNo, wireType, d);\n                continue;\n            }\n            // target object for the field we are reading\n            let target = message, repeated = field.repeat, localName = field.localName;\n            // if field is member of oneof ADT, use ADT as target\n            if (field.oneof) {\n                target = target[field.oneof];\n                // if other oneof member selected, set new ADT\n                if (target.oneofKind !== localName)\n                    target = message[field.oneof] = {\n                        oneofKind: localName\n                    };\n            }\n            // we have handled oneof above, we just have read the value into `target[localName]`\n            switch (field.kind) {\n                case \"scalar\":\n                case \"enum\":\n                    let T = field.kind == \"enum\" ? ScalarType.INT32 : field.T;\n                    let L = field.kind == \"scalar\" ? field.L : undefined;\n                    if (repeated) {\n                        let arr = target[localName]; // safe to assume presence of array, oneof cannot contain repeated values\n                        if (wireType == WireType.LengthDelimited && T != ScalarType.STRING && T != ScalarType.BYTES) {\n                            let e = reader.uint32() + reader.pos;\n                            while (reader.pos < e)\n                                arr.push(this.scalar(reader, T, L));\n                        }\n                        else\n                            arr.push(this.scalar(reader, T, L));\n                    }\n                    else\n                        target[localName] = this.scalar(reader, T, L);\n                    break;\n                case \"message\":\n                    if (repeated) {\n                        let arr = target[localName]; // safe to assume presence of array, oneof cannot contain repeated values\n                        let msg = field.T().internalBinaryRead(reader, reader.uint32(), options);\n                        arr.push(msg);\n                    }\n                    else\n                        target[localName] = field.T().internalBinaryRead(reader, reader.uint32(), options, target[localName]);\n                    break;\n                case \"map\":\n                    let [mapKey, mapVal] = this.mapEntry(field, reader, options);\n                    // safe to assume presence of map object, oneof cannot contain repeated values\n                    target[localName][mapKey] = mapVal;\n                    break;\n            }\n        }\n    }\n    /**\n     * Read a map field, expecting key field = 1, value field = 2\n     */\n    mapEntry(field, reader, options) {\n        let length = reader.uint32();\n        let end = reader.pos + length;\n        let key = undefined; // javascript only allows number or string for object properties\n        let val = undefined;\n        while (reader.pos < end) {\n            let [fieldNo, wireType] = reader.tag();\n            switch (fieldNo) {\n                case 1:\n                    if (field.K == ScalarType.BOOL)\n                        key = reader.bool().toString();\n                    else\n                        // long types are read as string, number types are okay as number\n                        key = this.scalar(reader, field.K, LongType.STRING);\n                    break;\n                case 2:\n                    switch (field.V.kind) {\n                        case \"scalar\":\n                            val = this.scalar(reader, field.V.T, field.V.L);\n                            break;\n                        case \"enum\":\n                            val = reader.int32();\n                            break;\n                        case \"message\":\n                            val = field.V.T().internalBinaryRead(reader, reader.uint32(), options);\n                            break;\n                    }\n                    break;\n                default:\n                    throw new Error(`Unknown field ${fieldNo} (wire type ${wireType}) in map entry for ${this.info.typeName}#${field.name}`);\n            }\n        }\n        if (key === undefined) {\n            let keyRaw = reflectionScalarDefault(field.K);\n            key = field.K == ScalarType.BOOL ? keyRaw.toString() : keyRaw;\n        }\n        if (val === undefined)\n            switch (field.V.kind) {\n                case \"scalar\":\n                    val = reflectionScalarDefault(field.V.T, field.V.L);\n                    break;\n                case \"enum\":\n                    val = 0;\n                    break;\n                case \"message\":\n                    val = field.V.T().create();\n                    break;\n            }\n        return [key, val];\n    }\n    scalar(reader, type, longType) {\n        switch (type) {\n            case ScalarType.INT32:\n                return reader.int32();\n            case ScalarType.STRING:\n                return reader.string();\n            case ScalarType.BOOL:\n                return reader.bool();\n            case ScalarType.DOUBLE:\n                return reader.double();\n            case ScalarType.FLOAT:\n                return reader.float();\n            case ScalarType.INT64:\n                return reflectionLongConvert(reader.int64(), longType);\n            case ScalarType.UINT64:\n                return reflectionLongConvert(reader.uint64(), longType);\n            case ScalarType.FIXED64:\n                return reflectionLongConvert(reader.fixed64(), longType);\n            case ScalarType.FIXED32:\n                return reader.fixed32();\n            case ScalarType.BYTES:\n                return reader.bytes();\n            case ScalarType.UINT32:\n                return reader.uint32();\n            case ScalarType.SFIXED32:\n                return reader.sfixed32();\n            case ScalarType.SFIXED64:\n                return reflectionLongConvert(reader.sfixed64(), longType);\n            case ScalarType.SINT32:\n                return reader.sint32();\n            case ScalarType.SINT64:\n                return reflectionLongConvert(reader.sint64(), longType);\n        }\n    }\n}\n","import { UnknownFieldHandler, WireType } from \"./binary-format-contract\";\nimport { RepeatType, ScalarType } from \"./reflection-info\";\nimport { assert } from \"./assert\";\nimport { PbLong, PbULong } from \"./pb-long\";\n/**\n * Writes proto3 messages in binary format using reflection information.\n *\n * https://developers.google.com/protocol-buffers/docs/encoding\n */\nexport class ReflectionBinaryWriter {\n    constructor(info) {\n        this.info = info;\n    }\n    prepare() {\n        if (!this.fields) {\n            const fieldsInput = this.info.fields ? this.info.fields.concat() : [];\n            this.fields = fieldsInput.sort((a, b) => a.no - b.no);\n        }\n    }\n    /**\n     * Writes the message to binary format.\n     */\n    write(message, writer, options) {\n        this.prepare();\n        for (const field of this.fields) {\n            let value, // this will be our field value, whether it is member of a oneof or not\n            emitDefault, // whether we emit the default value (only true for oneof members)\n            repeated = field.repeat, localName = field.localName;\n            // handle oneof ADT\n            if (field.oneof) {\n                const group = message[field.oneof];\n                if (group.oneofKind !== localName)\n                    continue; // if field is not selected, skip\n                value = group[localName];\n                emitDefault = true;\n            }\n            else {\n                value = message[localName];\n                emitDefault = false;\n            }\n            // we have handled oneof above. we just have to honor `emitDefault`.\n            switch (field.kind) {\n                case \"scalar\":\n                case \"enum\":\n                    let T = field.kind == \"enum\" ? ScalarType.INT32 : field.T;\n                    if (repeated) {\n                        assert(Array.isArray(value));\n                        if (repeated == RepeatType.PACKED)\n                            this.packed(writer, T, field.no, value);\n                        else\n                            for (const item of value)\n                                this.scalar(writer, T, field.no, item, true);\n                    }\n                    else if (value === undefined)\n                        assert(field.opt);\n                    else\n                        this.scalar(writer, T, field.no, value, emitDefault || field.opt);\n                    break;\n                case \"message\":\n                    if (repeated) {\n                        assert(Array.isArray(value));\n                        for (const item of value)\n                            this.message(writer, options, field.T(), field.no, item);\n                    }\n                    else {\n                        this.message(writer, options, field.T(), field.no, value);\n                    }\n                    break;\n                case \"map\":\n                    assert(typeof value == 'object' && value !== null);\n                    for (const [key, val] of Object.entries(value))\n                        this.mapEntry(writer, options, field, key, val);\n                    break;\n            }\n        }\n        let u = options.writeUnknownFields;\n        if (u !== false)\n            (u === true ? UnknownFieldHandler.onWrite : u)(this.info.typeName, message, writer);\n    }\n    mapEntry(writer, options, field, key, value) {\n        writer.tag(field.no, WireType.LengthDelimited);\n        writer.fork();\n        // javascript only allows number or string for object properties\n        // we convert from our representation to the protobuf type\n        let keyValue = key;\n        switch (field.K) {\n            case ScalarType.INT32:\n            case ScalarType.FIXED32:\n            case ScalarType.UINT32:\n            case ScalarType.SFIXED32:\n            case ScalarType.SINT32:\n                keyValue = Number.parseInt(key);\n                break;\n            case ScalarType.BOOL:\n                assert(key == 'true' || key == 'false');\n                keyValue = key == 'true';\n                break;\n        }\n        // write key, expecting key field number = 1\n        this.scalar(writer, field.K, 1, keyValue, true);\n        // write value, expecting value field number = 2\n        switch (field.V.kind) {\n            case 'scalar':\n                this.scalar(writer, field.V.T, 2, value, true);\n                break;\n            case 'enum':\n                this.scalar(writer, ScalarType.INT32, 2, value, true);\n                break;\n            case 'message':\n                this.message(writer, options, field.V.T(), 2, value);\n                break;\n        }\n        writer.join();\n    }\n    message(writer, options, handler, fieldNo, value) {\n        if (value === undefined)\n            return;\n        handler.internalBinaryWrite(value, writer.tag(fieldNo, WireType.LengthDelimited).fork(), options);\n        writer.join();\n    }\n    /**\n     * Write a single scalar value.\n     */\n    scalar(writer, type, fieldNo, value, emitDefault) {\n        let [wireType, method, isDefault] = this.scalarInfo(type, value);\n        if (!isDefault || emitDefault) {\n            writer.tag(fieldNo, wireType);\n            writer[method](value);\n        }\n    }\n    /**\n     * Write an array of scalar values in packed format.\n     */\n    packed(writer, type, fieldNo, value) {\n        if (!value.length)\n            return;\n        assert(type !== ScalarType.BYTES && type !== ScalarType.STRING);\n        // write tag\n        writer.tag(fieldNo, WireType.LengthDelimited);\n        // begin length-delimited\n        writer.fork();\n        // write values without tags\n        let [, method,] = this.scalarInfo(type);\n        for (let i = 0; i < value.length; i++)\n            writer[method](value[i]);\n        // end length delimited\n        writer.join();\n    }\n    /**\n     * Get information for writing a scalar value.\n     *\n     * Returns tuple:\n     * [0]: appropriate WireType\n     * [1]: name of the appropriate method of IBinaryWriter\n     * [2]: whether the given value is a default value\n     *\n     * If argument `value` is omitted, [2] is always false.\n     */\n    scalarInfo(type, value) {\n        let t = WireType.Varint;\n        let m;\n        let i = value === undefined;\n        let d = value === 0;\n        switch (type) {\n            case ScalarType.INT32:\n                m = \"int32\";\n                break;\n            case ScalarType.STRING:\n                d = i || !value.length;\n                t = WireType.LengthDelimited;\n                m = \"string\";\n                break;\n            case ScalarType.BOOL:\n                d = value === false;\n                m = \"bool\";\n                break;\n            case ScalarType.UINT32:\n                m = \"uint32\";\n                break;\n            case ScalarType.DOUBLE:\n                t = WireType.Bit64;\n                m = \"double\";\n                break;\n            case ScalarType.FLOAT:\n                t = WireType.Bit32;\n                m = \"float\";\n                break;\n            case ScalarType.INT64:\n                d = i || PbLong.from(value).isZero();\n                m = \"int64\";\n                break;\n            case ScalarType.UINT64:\n                d = i || PbULong.from(value).isZero();\n                m = \"uint64\";\n                break;\n            case ScalarType.FIXED64:\n                d = i || PbULong.from(value).isZero();\n                t = WireType.Bit64;\n                m = \"fixed64\";\n                break;\n            case ScalarType.BYTES:\n                d = i || !value.byteLength;\n                t = WireType.LengthDelimited;\n                m = \"bytes\";\n                break;\n            case ScalarType.FIXED32:\n                t = WireType.Bit32;\n                m = \"fixed32\";\n                break;\n            case ScalarType.SFIXED32:\n                t = WireType.Bit32;\n                m = \"sfixed32\";\n                break;\n            case ScalarType.SFIXED64:\n                d = i || PbLong.from(value).isZero();\n                t = WireType.Bit64;\n                m = \"sfixed64\";\n                break;\n            case ScalarType.SINT32:\n                m = \"sint32\";\n                break;\n            case ScalarType.SINT64:\n                d = i || PbLong.from(value).isZero();\n                m = \"sint64\";\n                break;\n        }\n        return [t, m, i || d];\n    }\n}\n","import { reflectionScalarDefault } from \"./reflection-scalar-default\";\nimport { MESSAGE_TYPE } from './message-type-contract';\n/**\n * Creates an instance of the generic message, using the field\n * information.\n */\nexport function reflectionCreate(type) {\n    /**\n     * This ternary can be removed in the next major version.\n     * The `Object.create()` code path utilizes a new `messagePrototype`\n     * property on the `IMessageType` which has this same `MESSAGE_TYPE`\n     * non-enumerable property on it. Doing it this way means that we only\n     * pay the cost of `Object.defineProperty()` once per `IMessageType`\n     * class of once per \"instance\". The falsy code path is only provided\n     * for backwards compatibility in cases where the runtime library is\n     * updated without also updating the generated code.\n     */\n    const msg = type.messagePrototype\n        ? Object.create(type.messagePrototype)\n        : Object.defineProperty({}, MESSAGE_TYPE, { value: type });\n    for (let field of type.fields) {\n        let name = field.localName;\n        if (field.opt)\n            continue;\n        if (field.oneof)\n            msg[field.oneof] = { oneofKind: undefined };\n        else if (field.repeat)\n            msg[name] = [];\n        else\n            switch (field.kind) {\n                case \"scalar\":\n                    msg[name] = reflectionScalarDefault(field.T, field.L);\n                    break;\n                case \"enum\":\n                    // we require 0 to be default value for all enums\n                    msg[name] = 0;\n                    break;\n                case \"map\":\n                    msg[name] = {};\n                    break;\n            }\n    }\n    return msg;\n}\n","import { ScalarType } from \"./reflection-info\";\n/**\n * Determines whether two message of the same type have the same field values.\n * Checks for deep equality, traversing repeated fields, oneof groups, maps\n * and messages recursively.\n * Will also return true if both messages are `undefined`.\n */\nexport function reflectionEquals(info, a, b) {\n    if (a === b)\n        return true;\n    if (!a || !b)\n        return false;\n    for (let field of info.fields) {\n        let localName = field.localName;\n        let val_a = field.oneof ? a[field.oneof][localName] : a[localName];\n        let val_b = field.oneof ? b[field.oneof][localName] : b[localName];\n        switch (field.kind) {\n            case \"enum\":\n            case \"scalar\":\n                let t = field.kind == \"enum\" ? ScalarType.INT32 : field.T;\n                if (!(field.repeat\n                    ? repeatedPrimitiveEq(t, val_a, val_b)\n                    : primitiveEq(t, val_a, val_b)))\n                    return false;\n                break;\n            case \"map\":\n                if (!(field.V.kind == \"message\"\n                    ? repeatedMsgEq(field.V.T(), objectValues(val_a), objectValues(val_b))\n                    : repeatedPrimitiveEq(field.V.kind == \"enum\" ? ScalarType.INT32 : field.V.T, objectValues(val_a), objectValues(val_b))))\n                    return false;\n                break;\n            case \"message\":\n                let T = field.T();\n                if (!(field.repeat\n                    ? repeatedMsgEq(T, val_a, val_b)\n                    : T.equals(val_a, val_b)))\n                    return false;\n                break;\n        }\n    }\n    return true;\n}\nconst objectValues = Object.values;\nfunction primitiveEq(type, a, b) {\n    if (a === b)\n        return true;\n    if (type !== ScalarType.BYTES)\n        return false;\n    let ba = a;\n    let bb = b;\n    if (ba.length !== bb.length)\n        return false;\n    for (let i = 0; i < ba.length; i++)\n        if (ba[i] != bb[i])\n            return false;\n    return true;\n}\nfunction repeatedPrimitiveEq(type, a, b) {\n    if (a.length !== b.length)\n        return false;\n    for (let i = 0; i < a.length; i++)\n        if (!primitiveEq(type, a[i], b[i]))\n            return false;\n    return true;\n}\nfunction repeatedMsgEq(type, a, b) {\n    if (a.length !== b.length)\n        return false;\n    for (let i = 0; i < a.length; i++)\n        if (!type.equals(a[i], b[i]))\n            return false;\n    return true;\n}\n","import { lowerCamelCase } from \"./lower-camel-case\";\n/**\n * Scalar value types. This is a subset of field types declared by protobuf\n * enum google.protobuf.FieldDescriptorProto.Type The types GROUP and MESSAGE\n * are omitted, but the numerical values are identical.\n */\nexport var ScalarType;\n(function (ScalarType) {\n    // 0 is reserved for errors.\n    // Order is weird for historical reasons.\n    ScalarType[ScalarType[\"DOUBLE\"] = 1] = \"DOUBLE\";\n    ScalarType[ScalarType[\"FLOAT\"] = 2] = \"FLOAT\";\n    // Not ZigZag encoded.  Negative numbers take 10 bytes.  Use TYPE_SINT64 if\n    // negative values are likely.\n    ScalarType[ScalarType[\"INT64\"] = 3] = \"INT64\";\n    ScalarType[ScalarType[\"UINT64\"] = 4] = \"UINT64\";\n    // Not ZigZag encoded.  Negative numbers take 10 bytes.  Use TYPE_SINT32 if\n    // negative values are likely.\n    ScalarType[ScalarType[\"INT32\"] = 5] = \"INT32\";\n    ScalarType[ScalarType[\"FIXED64\"] = 6] = \"FIXED64\";\n    ScalarType[ScalarType[\"FIXED32\"] = 7] = \"FIXED32\";\n    ScalarType[ScalarType[\"BOOL\"] = 8] = \"BOOL\";\n    ScalarType[ScalarType[\"STRING\"] = 9] = \"STRING\";\n    // Tag-delimited aggregate.\n    // Group type is deprecated and not supported in proto3. However, Proto3\n    // implementations should still be able to parse the group wire format and\n    // treat group fields as unknown fields.\n    // TYPE_GROUP = 10,\n    // TYPE_MESSAGE = 11,  // Length-delimited aggregate.\n    // New in version 2.\n    ScalarType[ScalarType[\"BYTES\"] = 12] = \"BYTES\";\n    ScalarType[ScalarType[\"UINT32\"] = 13] = \"UINT32\";\n    // TYPE_ENUM = 14,\n    ScalarType[ScalarType[\"SFIXED32\"] = 15] = \"SFIXED32\";\n    ScalarType[ScalarType[\"SFIXED64\"] = 16] = \"SFIXED64\";\n    ScalarType[ScalarType[\"SINT32\"] = 17] = \"SINT32\";\n    ScalarType[ScalarType[\"SINT64\"] = 18] = \"SINT64\";\n})(ScalarType || (ScalarType = {}));\n/**\n * JavaScript representation of 64 bit integral types. Equivalent to the\n * field option \"jstype\".\n *\n * By default, protobuf-ts represents 64 bit types as `bigint`.\n *\n * You can change the default behaviour by enabling the plugin parameter\n * `long_type_string`, which will represent 64 bit types as `string`.\n *\n * Alternatively, you can change the behaviour for individual fields\n * with the field option \"jstype\":\n *\n * ```protobuf\n * uint64 my_field = 1 [jstype = JS_STRING];\n * uint64 other_field = 2 [jstype = JS_NUMBER];\n * ```\n */\nexport var LongType;\n(function (LongType) {\n    /**\n     * Use JavaScript `bigint`.\n     *\n     * Field option `[jstype = JS_NORMAL]`.\n     */\n    LongType[LongType[\"BIGINT\"] = 0] = \"BIGINT\";\n    /**\n     * Use JavaScript `string`.\n     *\n     * Field option `[jstype = JS_STRING]`.\n     */\n    LongType[LongType[\"STRING\"] = 1] = \"STRING\";\n    /**\n     * Use JavaScript `number`.\n     *\n     * Large values will loose precision.\n     *\n     * Field option `[jstype = JS_NUMBER]`.\n     */\n    LongType[LongType[\"NUMBER\"] = 2] = \"NUMBER\";\n})(LongType || (LongType = {}));\n/**\n * Protobuf 2.1.0 introduced packed repeated fields.\n * Setting the field option `[packed = true]` enables packing.\n *\n * In proto3, all repeated fields are packed by default.\n * Setting the field option `[packed = false]` disables packing.\n *\n * Packed repeated fields are encoded with a single tag,\n * then a length-delimiter, then the element values.\n *\n * Unpacked repeated fields are encoded with a tag and\n * value for each element.\n *\n * `bytes` and `string` cannot be packed.\n */\nexport var RepeatType;\n(function (RepeatType) {\n    /**\n     * The field is not repeated.\n     */\n    RepeatType[RepeatType[\"NO\"] = 0] = \"NO\";\n    /**\n     * The field is repeated and should be packed.\n     * Invalid for `bytes` and `string`, they cannot be packed.\n     */\n    RepeatType[RepeatType[\"PACKED\"] = 1] = \"PACKED\";\n    /**\n     * The field is repeated but should not be packed.\n     * The only valid repeat type for repeated `bytes` and `string`.\n     */\n    RepeatType[RepeatType[\"UNPACKED\"] = 2] = \"UNPACKED\";\n})(RepeatType || (RepeatType = {}));\n/**\n * Turns PartialFieldInfo into FieldInfo.\n */\nexport function normalizeFieldInfo(field) {\n    var _a, _b, _c, _d;\n    field.localName = (_a = field.localName) !== null && _a !== void 0 ? _a : lowerCamelCase(field.name);\n    field.jsonName = (_b = field.jsonName) !== null && _b !== void 0 ? _b : lowerCamelCase(field.name);\n    field.repeat = (_c = field.repeat) !== null && _c !== void 0 ? _c : RepeatType.NO;\n    field.opt = (_d = field.opt) !== null && _d !== void 0 ? _d : (field.repeat ? false : field.oneof ? false : field.kind == \"message\");\n    return field;\n}\n/**\n * Read custom field options from a generated message type.\n *\n * @deprecated use readFieldOption()\n */\nexport function readFieldOptions(messageType, fieldName, extensionName, extensionType) {\n    var _a;\n    const options = (_a = messageType.fields.find((m, i) => m.localName == fieldName || i == fieldName)) === null || _a === void 0 ? void 0 : _a.options;\n    return options && options[extensionName] ? extensionType.fromJson(options[extensionName]) : undefined;\n}\nexport function readFieldOption(messageType, fieldName, extensionName, extensionType) {\n    var _a;\n    const options = (_a = messageType.fields.find((m, i) => m.localName == fieldName || i == fieldName)) === null || _a === void 0 ? void 0 : _a.options;\n    if (!options) {\n        return undefined;\n    }\n    const optionVal = options[extensionName];\n    if (optionVal === undefined) {\n        return optionVal;\n    }\n    return extensionType ? extensionType.fromJson(optionVal) : optionVal;\n}\nexport function readMessageOption(messageType, extensionName, extensionType) {\n    const options = messageType.options;\n    const optionVal = options[extensionName];\n    if (optionVal === undefined) {\n        return optionVal;\n    }\n    return extensionType ? extensionType.fromJson(optionVal) : optionVal;\n}\n","import { isJsonObject, typeofJsonValue } from \"./json-typings\";\nimport { base64decode } from \"./base64\";\nimport { LongType, ScalarType } from \"./reflection-info\";\nimport { PbLong, PbULong } from \"./pb-long\";\nimport { assert, assertFloat32, assertInt32, assertUInt32 } from \"./assert\";\nimport { reflectionLongConvert } from \"./reflection-long-convert\";\n/**\n * Reads proto3 messages in canonical JSON format using reflection information.\n *\n * https://developers.google.com/protocol-buffers/docs/proto3#json\n */\nexport class ReflectionJsonReader {\n    constructor(info) {\n        this.info = info;\n    }\n    prepare() {\n        var _a;\n        if (this.fMap === undefined) {\n            this.fMap = {};\n            const fieldsInput = (_a = this.info.fields) !== null && _a !== void 0 ? _a : [];\n            for (const field of fieldsInput) {\n                this.fMap[field.name] = field;\n                this.fMap[field.jsonName] = field;\n                this.fMap[field.localName] = field;\n            }\n        }\n    }\n    // Cannot parse JSON <type of jsonValue> for <type name>#<fieldName>.\n    assert(condition, fieldName, jsonValue) {\n        if (!condition) {\n            let what = typeofJsonValue(jsonValue);\n            if (what == \"number\" || what == \"boolean\")\n                what = jsonValue.toString();\n            throw new Error(`Cannot parse JSON ${what} for ${this.info.typeName}#${fieldName}`);\n        }\n    }\n    /**\n     * Reads a message from canonical JSON format into the target message.\n     *\n     * Repeated fields are appended. Map entries are added, overwriting\n     * existing keys.\n     *\n     * If a message field is already present, it will be merged with the\n     * new data.\n     */\n    read(input, message, options) {\n        this.prepare();\n        const oneofsHandled = [];\n        for (const [jsonKey, jsonValue] of Object.entries(input)) {\n            const field = this.fMap[jsonKey];\n            if (!field) {\n                if (!options.ignoreUnknownFields)\n                    throw new Error(`Found unknown field while reading ${this.info.typeName} from JSON format. JSON key: ${jsonKey}`);\n                continue;\n            }\n            const localName = field.localName;\n            // handle oneof ADT\n            let target; // this will be the target for the field value, whether it is member of a oneof or not\n            if (field.oneof) {\n                if (jsonValue === null && (field.kind !== 'enum' || field.T()[0] !== 'google.protobuf.NullValue')) {\n                    continue;\n                }\n                // since json objects are unordered by specification, it is not possible to take the last of multiple oneofs\n                if (oneofsHandled.includes(field.oneof))\n                    throw new Error(`Multiple members of the oneof group \"${field.oneof}\" of ${this.info.typeName} are present in JSON.`);\n                oneofsHandled.push(field.oneof);\n                target = message[field.oneof] = {\n                    oneofKind: localName\n                };\n            }\n            else {\n                target = message;\n            }\n            // we have handled oneof above. we just have read the value into `target`.\n            if (field.kind == 'map') {\n                if (jsonValue === null) {\n                    continue;\n                }\n                // check input\n                this.assert(isJsonObject(jsonValue), field.name, jsonValue);\n                // our target to put map entries into\n                const fieldObj = target[localName];\n                // read entries\n                for (const [jsonObjKey, jsonObjValue] of Object.entries(jsonValue)) {\n                    this.assert(jsonObjValue !== null, field.name + \" map value\", null);\n                    // read value\n                    let val;\n                    switch (field.V.kind) {\n                        case \"message\":\n                            val = field.V.T().internalJsonRead(jsonObjValue, options);\n                            break;\n                        case \"enum\":\n                            val = this.enum(field.V.T(), jsonObjValue, field.name, options.ignoreUnknownFields);\n                            if (val === false)\n                                continue;\n                            break;\n                        case \"scalar\":\n                            val = this.scalar(jsonObjValue, field.V.T, field.V.L, field.name);\n                            break;\n                    }\n                    this.assert(val !== undefined, field.name + \" map value\", jsonObjValue);\n                    // read key\n                    let key = jsonObjKey;\n                    if (field.K == ScalarType.BOOL)\n                        key = key == \"true\" ? true : key == \"false\" ? false : key;\n                    key = this.scalar(key, field.K, LongType.STRING, field.name).toString();\n                    fieldObj[key] = val;\n                }\n            }\n            else if (field.repeat) {\n                if (jsonValue === null)\n                    continue;\n                // check input\n                this.assert(Array.isArray(jsonValue), field.name, jsonValue);\n                // our target to put array entries into\n                const fieldArr = target[localName];\n                // read array entries\n                for (const jsonItem of jsonValue) {\n                    this.assert(jsonItem !== null, field.name, null);\n                    let val;\n                    switch (field.kind) {\n                        case \"message\":\n                            val = field.T().internalJsonRead(jsonItem, options);\n                            break;\n                        case \"enum\":\n                            val = this.enum(field.T(), jsonItem, field.name, options.ignoreUnknownFields);\n                            if (val === false)\n                                continue;\n                            break;\n                        case \"scalar\":\n                            val = this.scalar(jsonItem, field.T, field.L, field.name);\n                            break;\n                    }\n                    this.assert(val !== undefined, field.name, jsonValue);\n                    fieldArr.push(val);\n                }\n            }\n            else {\n                switch (field.kind) {\n                    case \"message\":\n                        if (jsonValue === null && field.T().typeName != 'google.protobuf.Value') {\n                            this.assert(field.oneof === undefined, field.name + \" (oneof member)\", null);\n                            continue;\n                        }\n                        target[localName] = field.T().internalJsonRead(jsonValue, options, target[localName]);\n                        break;\n                    case \"enum\":\n                        let val = this.enum(field.T(), jsonValue, field.name, options.ignoreUnknownFields);\n                        if (val === false)\n                            continue;\n                        target[localName] = val;\n                        break;\n                    case \"scalar\":\n                        target[localName] = this.scalar(jsonValue, field.T, field.L, field.name);\n                        break;\n                }\n            }\n        }\n    }\n    /**\n     * Returns `false` for unrecognized string representations.\n     *\n     * google.protobuf.NullValue accepts only JSON `null` (or the old `\"NULL_VALUE\"`).\n     */\n    enum(type, json, fieldName, ignoreUnknownFields) {\n        if (type[0] == 'google.protobuf.NullValue')\n            assert(json === null || json === \"NULL_VALUE\", `Unable to parse field ${this.info.typeName}#${fieldName}, enum ${type[0]} only accepts null.`);\n        if (json === null)\n            // we require 0 to be default value for all enums\n            return 0;\n        switch (typeof json) {\n            case \"number\":\n                assert(Number.isInteger(json), `Unable to parse field ${this.info.typeName}#${fieldName}, enum can only be integral number, got ${json}.`);\n                return json;\n            case \"string\":\n                let localEnumName = json;\n                if (type[2] && json.substring(0, type[2].length) === type[2])\n                    // lookup without the shared prefix\n                    localEnumName = json.substring(type[2].length);\n                let enumNumber = type[1][localEnumName];\n                if (typeof enumNumber === 'undefined' && ignoreUnknownFields) {\n                    return false;\n                }\n                assert(typeof enumNumber == \"number\", `Unable to parse field ${this.info.typeName}#${fieldName}, enum ${type[0]} has no value for \"${json}\".`);\n                return enumNumber;\n        }\n        assert(false, `Unable to parse field ${this.info.typeName}#${fieldName}, cannot parse enum value from ${typeof json}\".`);\n    }\n    scalar(json, type, longType, fieldName) {\n        let e;\n        try {\n            switch (type) {\n                // float, double: JSON value will be a number or one of the special string values \"NaN\", \"Infinity\", and \"-Infinity\".\n                // Either numbers or strings are accepted. Exponent notation is also accepted.\n                case ScalarType.DOUBLE:\n                case ScalarType.FLOAT:\n                    if (json === null)\n                        return .0;\n                    if (json === \"NaN\")\n                        return Number.NaN;\n                    if (json === \"Infinity\")\n                        return Number.POSITIVE_INFINITY;\n                    if (json === \"-Infinity\")\n                        return Number.NEGATIVE_INFINITY;\n                    if (json === \"\") {\n                        e = \"empty string\";\n                        break;\n                    }\n                    if (typeof json == \"string\" && json.trim().length !== json.length) {\n                        e = \"extra whitespace\";\n                        break;\n                    }\n                    if (typeof json != \"string\" && typeof json != \"number\") {\n                        break;\n                    }\n                    let float = Number(json);\n                    if (Number.isNaN(float)) {\n                        e = \"not a number\";\n                        break;\n                    }\n                    if (!Number.isFinite(float)) {\n                        // infinity and -infinity are handled by string representation above, so this is an error\n                        e = \"too large or small\";\n                        break;\n                    }\n                    if (type == ScalarType.FLOAT)\n                        assertFloat32(float);\n                    return float;\n                // int32, fixed32, uint32: JSON value will be a decimal number. Either numbers or strings are accepted.\n                case ScalarType.INT32:\n                case ScalarType.FIXED32:\n                case ScalarType.SFIXED32:\n                case ScalarType.SINT32:\n                case ScalarType.UINT32:\n                    if (json === null)\n                        return 0;\n                    let int32;\n                    if (typeof json == \"number\")\n                        int32 = json;\n                    else if (json === \"\")\n                        e = \"empty string\";\n                    else if (typeof json == \"string\") {\n                        if (json.trim().length !== json.length)\n                            e = \"extra whitespace\";\n                        else\n                            int32 = Number(json);\n                    }\n                    if (int32 === undefined)\n                        break;\n                    if (type == ScalarType.UINT32)\n                        assertUInt32(int32);\n                    else\n                        assertInt32(int32);\n                    return int32;\n                // int64, fixed64, uint64: JSON value will be a decimal string. Either numbers or strings are accepted.\n                case ScalarType.INT64:\n                case ScalarType.SFIXED64:\n                case ScalarType.SINT64:\n                    if (json === null)\n                        return reflectionLongConvert(PbLong.ZERO, longType);\n                    if (typeof json != \"number\" && typeof json != \"string\")\n                        break;\n                    return reflectionLongConvert(PbLong.from(json), longType);\n                case ScalarType.FIXED64:\n                case ScalarType.UINT64:\n                    if (json === null)\n                        return reflectionLongConvert(PbULong.ZERO, longType);\n                    if (typeof json != \"number\" && typeof json != \"string\")\n                        break;\n                    return reflectionLongConvert(PbULong.from(json), longType);\n                // bool:\n                case ScalarType.BOOL:\n                    if (json === null)\n                        return false;\n                    if (typeof json !== \"boolean\")\n                        break;\n                    return json;\n                // string:\n                case ScalarType.STRING:\n                    if (json === null)\n                        return \"\";\n                    if (typeof json !== \"string\") {\n                        e = \"extra whitespace\";\n                        break;\n                    }\n                    try {\n                        encodeURIComponent(json);\n                    }\n                    catch (e) {\n                        e = \"invalid UTF8\";\n                        break;\n                    }\n                    return json;\n                // bytes: JSON value will be the data encoded as a string using standard base64 encoding with paddings.\n                // Either standard or URL-safe base64 encoding with/without paddings are accepted.\n                case ScalarType.BYTES:\n                    if (json === null || json === \"\")\n                        return new Uint8Array(0);\n                    if (typeof json !== 'string')\n                        break;\n                    return base64decode(json);\n            }\n        }\n        catch (error) {\n            e = error.message;\n        }\n        this.assert(false, fieldName + (e ? \" - \" + e : \"\"), json);\n    }\n}\n","import { base64encode } from \"./base64\";\nimport { PbLong, PbULong } from \"./pb-long\";\nimport { ScalarType } from \"./reflection-info\";\nimport { assert, assertFloat32, assertInt32, assertUInt32 } from \"./assert\";\n/**\n * Writes proto3 messages in canonical JSON format using reflection\n * information.\n *\n * https://developers.google.com/protocol-buffers/docs/proto3#json\n */\nexport class ReflectionJsonWriter {\n    constructor(info) {\n        var _a;\n        this.fields = (_a = info.fields) !== null && _a !== void 0 ? _a : [];\n    }\n    /**\n     * Converts the message to a JSON object, based on the field descriptors.\n     */\n    write(message, options) {\n        const json = {}, source = message;\n        for (const field of this.fields) {\n            // field is not part of a oneof, simply write as is\n            if (!field.oneof) {\n                let jsonValue = this.field(field, source[field.localName], options);\n                if (jsonValue !== undefined)\n                    json[options.useProtoFieldName ? field.name : field.jsonName] = jsonValue;\n                continue;\n            }\n            // field is part of a oneof\n            const group = source[field.oneof];\n            if (group.oneofKind !== field.localName)\n                continue; // not selected, skip\n            const opt = field.kind == 'scalar' || field.kind == 'enum'\n                ? Object.assign(Object.assign({}, options), { emitDefaultValues: true }) : options;\n            let jsonValue = this.field(field, group[field.localName], opt);\n            assert(jsonValue !== undefined);\n            json[options.useProtoFieldName ? field.name : field.jsonName] = jsonValue;\n        }\n        return json;\n    }\n    field(field, value, options) {\n        let jsonValue = undefined;\n        if (field.kind == 'map') {\n            assert(typeof value == \"object\" && value !== null);\n            const jsonObj = {};\n            switch (field.V.kind) {\n                case \"scalar\":\n                    for (const [entryKey, entryValue] of Object.entries(value)) {\n                        const val = this.scalar(field.V.T, entryValue, field.name, false, true);\n                        assert(val !== undefined);\n                        jsonObj[entryKey.toString()] = val; // JSON standard allows only (double quoted) string as property key\n                    }\n                    break;\n                case \"message\":\n                    const messageType = field.V.T();\n                    for (const [entryKey, entryValue] of Object.entries(value)) {\n                        const val = this.message(messageType, entryValue, field.name, options);\n                        assert(val !== undefined);\n                        jsonObj[entryKey.toString()] = val; // JSON standard allows only (double quoted) string as property key\n                    }\n                    break;\n                case \"enum\":\n                    const enumInfo = field.V.T();\n                    for (const [entryKey, entryValue] of Object.entries(value)) {\n                        assert(entryValue === undefined || typeof entryValue == 'number');\n                        const val = this.enum(enumInfo, entryValue, field.name, false, true, options.enumAsInteger);\n                        assert(val !== undefined);\n                        jsonObj[entryKey.toString()] = val; // JSON standard allows only (double quoted) string as property key\n                    }\n                    break;\n            }\n            if (options.emitDefaultValues || Object.keys(jsonObj).length > 0)\n                jsonValue = jsonObj;\n        }\n        else if (field.repeat) {\n            assert(Array.isArray(value));\n            const jsonArr = [];\n            switch (field.kind) {\n                case \"scalar\":\n                    for (let i = 0; i < value.length; i++) {\n                        const val = this.scalar(field.T, value[i], field.name, field.opt, true);\n                        assert(val !== undefined);\n                        jsonArr.push(val);\n                    }\n                    break;\n                case \"enum\":\n                    const enumInfo = field.T();\n                    for (let i = 0; i < value.length; i++) {\n                        assert(value[i] === undefined || typeof value[i] == 'number');\n                        const val = this.enum(enumInfo, value[i], field.name, field.opt, true, options.enumAsInteger);\n                        assert(val !== undefined);\n                        jsonArr.push(val);\n                    }\n                    break;\n                case \"message\":\n                    const messageType = field.T();\n                    for (let i = 0; i < value.length; i++) {\n                        const val = this.message(messageType, value[i], field.name, options);\n                        assert(val !== undefined);\n                        jsonArr.push(val);\n                    }\n                    break;\n            }\n            // add converted array to json output\n            if (options.emitDefaultValues || jsonArr.length > 0 || options.emitDefaultValues)\n                jsonValue = jsonArr;\n        }\n        else {\n            switch (field.kind) {\n                case \"scalar\":\n                    jsonValue = this.scalar(field.T, value, field.name, field.opt, options.emitDefaultValues);\n                    break;\n                case \"enum\":\n                    jsonValue = this.enum(field.T(), value, field.name, field.opt, options.emitDefaultValues, options.enumAsInteger);\n                    break;\n                case \"message\":\n                    jsonValue = this.message(field.T(), value, field.name, options);\n                    break;\n            }\n        }\n        return jsonValue;\n    }\n    /**\n     * Returns `null` as the default for google.protobuf.NullValue.\n     */\n    enum(type, value, fieldName, optional, emitDefaultValues, enumAsInteger) {\n        if (type[0] == 'google.protobuf.NullValue')\n            return !emitDefaultValues && !optional ? undefined : null;\n        if (value === undefined) {\n            assert(optional);\n            return undefined;\n        }\n        if (value === 0 && !emitDefaultValues && !optional)\n            // we require 0 to be default value for all enums\n            return undefined;\n        assert(typeof value == 'number');\n        assert(Number.isInteger(value));\n        if (enumAsInteger || !type[1].hasOwnProperty(value))\n            // if we don't now the enum value, just return the number\n            return value;\n        if (type[2])\n            // restore the dropped prefix\n            return type[2] + type[1][value];\n        return type[1][value];\n    }\n    message(type, value, fieldName, options) {\n        if (value === undefined)\n            return options.emitDefaultValues ? null : undefined;\n        return type.internalJsonWrite(value, options);\n    }\n    scalar(type, value, fieldName, optional, emitDefaultValues) {\n        if (value === undefined) {\n            assert(optional);\n            return undefined;\n        }\n        const ed = emitDefaultValues || optional;\n        // noinspection FallThroughInSwitchStatementJS\n        switch (type) {\n            // int32, fixed32, uint32: JSON value will be a decimal number. Either numbers or strings are accepted.\n            case ScalarType.INT32:\n            case ScalarType.SFIXED32:\n            case ScalarType.SINT32:\n                if (value === 0)\n                    return ed ? 0 : undefined;\n                assertInt32(value);\n                return value;\n            case ScalarType.FIXED32:\n            case ScalarType.UINT32:\n                if (value === 0)\n                    return ed ? 0 : undefined;\n                assertUInt32(value);\n                return value;\n            // float, double: JSON value will be a number or one of the special string values \"NaN\", \"Infinity\", and \"-Infinity\".\n            // Either numbers or strings are accepted. Exponent notation is also accepted.\n            case ScalarType.FLOAT:\n                assertFloat32(value);\n            case ScalarType.DOUBLE:\n                if (value === 0)\n                    return ed ? 0 : undefined;\n                assert(typeof value == 'number');\n                if (Number.isNaN(value))\n                    return 'NaN';\n                if (value === Number.POSITIVE_INFINITY)\n                    return 'Infinity';\n                if (value === Number.NEGATIVE_INFINITY)\n                    return '-Infinity';\n                return value;\n            // string:\n            case ScalarType.STRING:\n                if (value === \"\")\n                    return ed ? '' : undefined;\n                assert(typeof value == 'string');\n                return value;\n            // bool:\n            case ScalarType.BOOL:\n                if (value === false)\n                    return ed ? false : undefined;\n                assert(typeof value == 'boolean');\n                return value;\n            // JSON value will be a decimal string. Either numbers or strings are accepted.\n            case ScalarType.UINT64:\n            case ScalarType.FIXED64:\n                assert(typeof value == 'number' || typeof value == 'string' || typeof value == 'bigint');\n                let ulong = PbULong.from(value);\n                if (ulong.isZero() && !ed)\n                    return undefined;\n                return ulong.toString();\n            // JSON value will be a decimal string. Either numbers or strings are accepted.\n            case ScalarType.INT64:\n            case ScalarType.SFIXED64:\n            case ScalarType.SINT64:\n                assert(typeof value == 'number' || typeof value == 'string' || typeof value == 'bigint');\n                let long = PbLong.from(value);\n                if (long.isZero() && !ed)\n                    return undefined;\n                return long.toString();\n            // bytes: JSON value will be the data encoded as a string using standard base64 encoding with paddings.\n            // Either standard or URL-safe base64 encoding with/without paddings are accepted.\n            case ScalarType.BYTES:\n                assert(value instanceof Uint8Array);\n                if (!value.byteLength)\n                    return ed ? \"\" : undefined;\n                return base64encode(value);\n        }\n    }\n}\n","import { LongType } from \"./reflection-info\";\n/**\n * Utility method to convert a PbLong or PbUlong to a JavaScript\n * representation during runtime.\n *\n * Works with generated field information, `undefined` is equivalent\n * to `STRING`.\n */\nexport function reflectionLongConvert(long, type) {\n    switch (type) {\n        case LongType.BIGINT:\n            return long.toBigInt();\n        case LongType.NUMBER:\n            return long.toNumber();\n        default:\n            // case undefined:\n            // case LongType.STRING:\n            return long.toString();\n    }\n}\n","/**\n * Copy partial data into the target message.\n *\n * If a singular scalar or enum field is present in the source, it\n * replaces the field in the target.\n *\n * If a singular message field is present in the source, it is merged\n * with the target field by calling mergePartial() of the responsible\n * message type.\n *\n * If a repeated field is present in the source, its values replace\n * all values in the target array, removing extraneous values.\n * Repeated message fields are copied, not merged.\n *\n * If a map field is present in the source, entries are added to the\n * target map, replacing entries with the same key. Entries that only\n * exist in the target remain. Entries with message values are copied,\n * not merged.\n *\n * Note that this function differs from protobuf merge semantics,\n * which appends repeated fields.\n */\nexport function reflectionMergePartial(info, target, source) {\n    let fieldValue, // the field value we are working with\n    input = source, output; // where we want our field value to go\n    for (let field of info.fields) {\n        let name = field.localName;\n        if (field.oneof) {\n            const group = input[field.oneof]; // this is the oneof`s group in the source\n            if ((group === null || group === void 0 ? void 0 : group.oneofKind) == undefined) { // the user is free to omit\n                continue; // we skip this field, and all other members too\n            }\n            fieldValue = group[name]; // our value comes from the the oneof group of the source\n            output = target[field.oneof]; // and our output is the oneof group of the target\n            output.oneofKind = group.oneofKind; // always update discriminator\n            if (fieldValue == undefined) {\n                delete output[name]; // remove any existing value\n                continue; // skip further work on field\n            }\n        }\n        else {\n            fieldValue = input[name]; // we are using the source directly\n            output = target; // we want our field value to go directly into the target\n            if (fieldValue == undefined) {\n                continue; // skip further work on field, existing value is used as is\n            }\n        }\n        if (field.repeat)\n            output[name].length = fieldValue.length; // resize target array to match source array\n        // now we just work with `fieldValue` and `output` to merge the value\n        switch (field.kind) {\n            case \"scalar\":\n            case \"enum\":\n                if (field.repeat)\n                    for (let i = 0; i < fieldValue.length; i++)\n                        output[name][i] = fieldValue[i]; // not a reference type\n                else\n                    output[name] = fieldValue; // not a reference type\n                break;\n            case \"message\":\n                let T = field.T();\n                if (field.repeat)\n                    for (let i = 0; i < fieldValue.length; i++)\n                        output[name][i] = T.create(fieldValue[i]);\n                else if (output[name] === undefined)\n                    output[name] = T.create(fieldValue); // nothing to merge with\n                else\n                    T.mergePartial(output[name], fieldValue);\n                break;\n            case \"map\":\n                // Map and repeated fields are simply overwritten, not appended or merged\n                switch (field.V.kind) {\n                    case \"scalar\":\n                    case \"enum\":\n                        Object.assign(output[name], fieldValue); // elements are not reference types\n                        break;\n                    case \"message\":\n                        let T = field.V.T();\n                        for (let k of Object.keys(fieldValue))\n                            output[name][k] = T.create(fieldValue[k]);\n                        break;\n                }\n                break;\n        }\n    }\n}\n","import { LongType, ScalarType } from \"./reflection-info\";\nimport { reflectionLongConvert } from \"./reflection-long-convert\";\nimport { PbLong, PbULong } from \"./pb-long\";\n/**\n * Creates the default value for a scalar type.\n */\nexport function reflectionScalarDefault(type, longType = LongType.STRING) {\n    switch (type) {\n        case ScalarType.BOOL:\n            return false;\n        case ScalarType.UINT64:\n        case ScalarType.FIXED64:\n            return reflectionLongConvert(PbULong.ZERO, longType);\n        case ScalarType.INT64:\n        case ScalarType.SFIXED64:\n        case ScalarType.SINT64:\n            return reflectionLongConvert(PbLong.ZERO, longType);\n        case ScalarType.DOUBLE:\n        case ScalarType.FLOAT:\n            return 0.0;\n        case ScalarType.BYTES:\n            return new Uint8Array(0);\n        case ScalarType.STRING:\n            return \"\";\n        default:\n            // case ScalarType.INT32:\n            // case ScalarType.UINT32:\n            // case ScalarType.SINT32:\n            // case ScalarType.FIXED32:\n            // case ScalarType.SFIXED32:\n            return 0;\n    }\n}\n","import { LongType, ScalarType } from \"./reflection-info\";\nimport { isOneofGroup } from \"./oneof\";\n// noinspection JSMethodCanBeStatic\nexport class ReflectionTypeCheck {\n    constructor(info) {\n        var _a;\n        this.fields = (_a = info.fields) !== null && _a !== void 0 ? _a : [];\n    }\n    prepare() {\n        if (this.data)\n            return;\n        const req = [], known = [], oneofs = [];\n        for (let field of this.fields) {\n            if (field.oneof) {\n                if (!oneofs.includes(field.oneof)) {\n                    oneofs.push(field.oneof);\n                    req.push(field.oneof);\n                    known.push(field.oneof);\n                }\n            }\n            else {\n                known.push(field.localName);\n                switch (field.kind) {\n                    case \"scalar\":\n                    case \"enum\":\n                        if (!field.opt || field.repeat)\n                            req.push(field.localName);\n                        break;\n                    case \"message\":\n                        if (field.repeat)\n                            req.push(field.localName);\n                        break;\n                    case \"map\":\n                        req.push(field.localName);\n                        break;\n                }\n            }\n        }\n        this.data = { req, known, oneofs: Object.values(oneofs) };\n    }\n    /**\n     * Is the argument a valid message as specified by the\n     * reflection information?\n     *\n     * Checks all field types recursively. The `depth`\n     * specifies how deep into the structure the check will be.\n     *\n     * With a depth of 0, only the presence of fields\n     * is checked.\n     *\n     * With a depth of 1 or more, the field types are checked.\n     *\n     * With a depth of 2 or more, the members of map, repeated\n     * and message fields are checked.\n     *\n     * Message fields will be checked recursively with depth - 1.\n     *\n     * The number of map entries / repeated values being checked\n     * is < depth.\n     */\n    is(message, depth, allowExcessProperties = false) {\n        if (depth < 0)\n            return true;\n        if (message === null || message === undefined || typeof message != 'object')\n            return false;\n        this.prepare();\n        let keys = Object.keys(message), data = this.data;\n        // if a required field is missing in arg, this cannot be a T\n        if (keys.length < data.req.length || data.req.some(n => !keys.includes(n)))\n            return false;\n        if (!allowExcessProperties) {\n            // if the arg contains a key we dont know, this is not a literal T\n            if (keys.some(k => !data.known.includes(k)))\n                return false;\n        }\n        // \"With a depth of 0, only the presence and absence of fields is checked.\"\n        // \"With a depth of 1 or more, the field types are checked.\"\n        if (depth < 1) {\n            return true;\n        }\n        // check oneof group\n        for (const name of data.oneofs) {\n            const group = message[name];\n            if (!isOneofGroup(group))\n                return false;\n            if (group.oneofKind === undefined)\n                continue;\n            const field = this.fields.find(f => f.localName === group.oneofKind);\n            if (!field)\n                return false; // we found no field, but have a kind, something is wrong\n            if (!this.field(group[group.oneofKind], field, allowExcessProperties, depth))\n                return false;\n        }\n        // check types\n        for (const field of this.fields) {\n            if (field.oneof !== undefined)\n                continue;\n            if (!this.field(message[field.localName], field, allowExcessProperties, depth))\n                return false;\n        }\n        return true;\n    }\n    field(arg, field, allowExcessProperties, depth) {\n        let repeated = field.repeat;\n        switch (field.kind) {\n            case \"scalar\":\n                if (arg === undefined)\n                    return field.opt;\n                if (repeated)\n                    return this.scalars(arg, field.T, depth, field.L);\n                return this.scalar(arg, field.T, field.L);\n            case \"enum\":\n                if (arg === undefined)\n                    return field.opt;\n                if (repeated)\n                    return this.scalars(arg, ScalarType.INT32, depth);\n                return this.scalar(arg, ScalarType.INT32);\n            case \"message\":\n                if (arg === undefined)\n                    return true;\n                if (repeated)\n                    return this.messages(arg, field.T(), allowExcessProperties, depth);\n                return this.message(arg, field.T(), allowExcessProperties, depth);\n            case \"map\":\n                if (typeof arg != 'object' || arg === null)\n                    return false;\n                if (depth < 2)\n                    return true;\n                if (!this.mapKeys(arg, field.K, depth))\n                    return false;\n                switch (field.V.kind) {\n                    case \"scalar\":\n                        return this.scalars(Object.values(arg), field.V.T, depth, field.V.L);\n                    case \"enum\":\n                        return this.scalars(Object.values(arg), ScalarType.INT32, depth);\n                    case \"message\":\n                        return this.messages(Object.values(arg), field.V.T(), allowExcessProperties, depth);\n                }\n                break;\n        }\n        return true;\n    }\n    message(arg, type, allowExcessProperties, depth) {\n        if (allowExcessProperties) {\n            return type.isAssignable(arg, depth);\n        }\n        return type.is(arg, depth);\n    }\n    messages(arg, type, allowExcessProperties, depth) {\n        if (!Array.isArray(arg))\n            return false;\n        if (depth < 2)\n            return true;\n        if (allowExcessProperties) {\n            for (let i = 0; i < arg.length && i < depth; i++)\n                if (!type.isAssignable(arg[i], depth - 1))\n                    return false;\n        }\n        else {\n            for (let i = 0; i < arg.length && i < depth; i++)\n                if (!type.is(arg[i], depth - 1))\n                    return false;\n        }\n        return true;\n    }\n    scalar(arg, type, longType) {\n        let argType = typeof arg;\n        switch (type) {\n            case ScalarType.UINT64:\n            case ScalarType.FIXED64:\n            case ScalarType.INT64:\n            case ScalarType.SFIXED64:\n            case ScalarType.SINT64:\n                switch (longType) {\n                    case LongType.BIGINT:\n                        return argType == \"bigint\";\n                    case LongType.NUMBER:\n                        return argType == \"number\" && !isNaN(arg);\n                    default:\n                        return argType == \"string\";\n                }\n            case ScalarType.BOOL:\n                return argType == 'boolean';\n            case ScalarType.STRING:\n                return argType == 'string';\n            case ScalarType.BYTES:\n                return arg instanceof Uint8Array;\n            case ScalarType.DOUBLE:\n            case ScalarType.FLOAT:\n                return argType == 'number' && !isNaN(arg);\n            default:\n                // case ScalarType.UINT32:\n                // case ScalarType.FIXED32:\n                // case ScalarType.INT32:\n                // case ScalarType.SINT32:\n                // case ScalarType.SFIXED32:\n                return argType == 'number' && Number.isInteger(arg);\n        }\n    }\n    scalars(arg, type, depth, longType) {\n        if (!Array.isArray(arg))\n            return false;\n        if (depth < 2)\n            return true;\n        if (Array.isArray(arg))\n            for (let i = 0; i < arg.length && i < depth; i++)\n                if (!this.scalar(arg[i], type, longType))\n                    return false;\n        return true;\n    }\n    mapKeys(map, type, depth) {\n        let keys = Object.keys(map);\n        switch (type) {\n            case ScalarType.INT32:\n            case ScalarType.FIXED32:\n            case ScalarType.SFIXED32:\n            case ScalarType.SINT32:\n            case ScalarType.UINT32:\n                return this.scalars(keys.slice(0, depth).map(k => parseInt(k)), type, depth);\n            case ScalarType.BOOL:\n                return this.scalars(keys.slice(0, depth).map(k => k == 'true' ? true : k == 'false' ? false : k), type, depth);\n            default:\n                return this.scalars(keys, type, depth, LongType.STRING);\n        }\n    }\n}\n","/**\n * @since 1.0.0\n */\nimport * as Duration from \"effect/Duration\";\nimport * as Either from \"effect/Either\";\nimport { dual } from \"effect/Function\";\nimport * as Inspectable from \"effect/Inspectable\";\nimport * as Option from \"effect/Option\";\nimport { pipeArguments } from \"effect/Pipeable\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as Record from \"effect/Record\";\nimport { TypeIdError } from \"./Error.js\";\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/Cookies\");\n/**\n * @since 1.0.0\n * @category refinements\n */\nexport const isCookies = u => Predicate.hasProperty(u, TypeId);\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const CookieTypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/Cookies/Cookie\");\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const ErrorTypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/Cookies/CookieError\");\n/**\n * @since 1.0.0\n * @category errors\n */\nexport class CookiesError extends /*#__PURE__*/TypeIdError(ErrorTypeId, \"CookieError\") {\n  get message() {\n    return this.reason;\n  }\n}\nconst Proto = {\n  [TypeId]: TypeId,\n  ...Inspectable.BaseProto,\n  toJSON() {\n    return {\n      _id: \"@effect/platform/Cookies\",\n      cookies: Record.map(this.cookies, cookie => cookie.toJSON())\n    };\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/**\n * Create a Cookies object from an Iterable\n *\n * @since 1.0.0\n * @category constructors\n */\nexport const fromReadonlyRecord = cookies => {\n  const self = Object.create(Proto);\n  self.cookies = cookies;\n  return self;\n};\n/**\n * Create a Cookies object from an Iterable\n *\n * @since 1.0.0\n * @category constructors\n */\nexport const fromIterable = cookies => {\n  const record = {};\n  for (const cookie of cookies) {\n    record[cookie.name] = cookie;\n  }\n  return fromReadonlyRecord(record);\n};\n/**\n * Create a Cookies object from a set of Set-Cookie headers\n *\n * @since 1.0.0\n * @category constructors\n */\nexport const fromSetCookie = headers => {\n  const arrayHeaders = typeof headers === \"string\" ? [headers] : headers;\n  const cookies = [];\n  for (const header of arrayHeaders) {\n    const cookie = parseSetCookie(header.trim());\n    if (Option.isSome(cookie)) {\n      cookies.push(cookie.value);\n    }\n  }\n  return fromIterable(cookies);\n};\nfunction parseSetCookie(header) {\n  const parts = header.split(\";\").map(_ => _.trim()).filter(_ => _ !== \"\");\n  if (parts.length === 0) {\n    return Option.none();\n  }\n  const firstEqual = parts[0].indexOf(\"=\");\n  if (firstEqual === -1) {\n    return Option.none();\n  }\n  const name = parts[0].slice(0, firstEqual);\n  if (!fieldContentRegExp.test(name)) {\n    return Option.none();\n  }\n  const valueEncoded = parts[0].slice(firstEqual + 1);\n  const value = tryDecodeURIComponent(valueEncoded);\n  if (parts.length === 1) {\n    return Option.some(Object.assign(Object.create(CookieProto), {\n      name,\n      value,\n      valueEncoded\n    }));\n  }\n  const options = {};\n  for (let i = 1; i < parts.length; i++) {\n    const part = parts[i];\n    const equalIndex = part.indexOf(\"=\");\n    const key = equalIndex === -1 ? part : part.slice(0, equalIndex).trim();\n    const value = equalIndex === -1 ? undefined : part.slice(equalIndex + 1).trim();\n    switch (key.toLowerCase()) {\n      case \"domain\":\n        {\n          if (value === undefined) {\n            break;\n          }\n          const domain = value.trim().replace(/^\\./, \"\");\n          if (domain) {\n            options.domain = domain;\n          }\n          break;\n        }\n      case \"expires\":\n        {\n          if (value === undefined) {\n            break;\n          }\n          const date = new Date(value);\n          if (!isNaN(date.getTime())) {\n            options.expires = date;\n          }\n          break;\n        }\n      case \"max-age\":\n        {\n          if (value === undefined) {\n            break;\n          }\n          const maxAge = parseInt(value, 10);\n          if (!isNaN(maxAge)) {\n            options.maxAge = Duration.seconds(maxAge);\n          }\n          break;\n        }\n      case \"path\":\n        {\n          if (value === undefined) {\n            break;\n          }\n          if (value[0] === \"/\") {\n            options.path = value;\n          }\n          break;\n        }\n      case \"priority\":\n        {\n          if (value === undefined) {\n            break;\n          }\n          switch (value.toLowerCase()) {\n            case \"low\":\n              options.priority = \"low\";\n              break;\n            case \"medium\":\n              options.priority = \"medium\";\n              break;\n            case \"high\":\n              options.priority = \"high\";\n              break;\n          }\n          break;\n        }\n      case \"httponly\":\n        {\n          options.httpOnly = true;\n          break;\n        }\n      case \"secure\":\n        {\n          options.secure = true;\n          break;\n        }\n      case \"partitioned\":\n        {\n          options.partitioned = true;\n          break;\n        }\n      case \"samesite\":\n        {\n          if (value === undefined) {\n            break;\n          }\n          switch (value.toLowerCase()) {\n            case \"lax\":\n              options.sameSite = \"lax\";\n              break;\n            case \"strict\":\n              options.sameSite = \"strict\";\n              break;\n            case \"none\":\n              options.sameSite = \"none\";\n              break;\n          }\n          break;\n        }\n    }\n  }\n  return Option.some(Object.assign(Object.create(CookieProto), {\n    name,\n    value,\n    valueEncoded,\n    options: Object.keys(options).length > 0 ? options : undefined\n  }));\n}\n/**\n * An empty Cookies object\n *\n * @since 1.0.0\n * @category constructors\n */\nexport const empty = /*#__PURE__*/fromIterable([]);\n/**\n * @since 1.0.0\n * @category refinements\n */\nexport const isEmpty = self => Record.isEmptyRecord(self.cookies);\n// eslint-disable-next-line no-control-regex\nconst fieldContentRegExp = /^[\\u0009\\u0020-\\u007e\\u0080-\\u00ff]+$/;\nconst CookieProto = {\n  [CookieTypeId]: CookieTypeId,\n  ...Inspectable.BaseProto,\n  toJSON() {\n    return {\n      _id: \"@effect/platform/Cookies/Cookie\",\n      name: this.name,\n      value: this.value,\n      options: this.options\n    };\n  }\n};\n/**\n * Create a new cookie\n *\n * @since 1.0.0\n * @category constructors\n */\nexport function makeCookie(name, value, options) {\n  if (!fieldContentRegExp.test(name)) {\n    return Either.left(new CookiesError({\n      reason: \"InvalidName\"\n    }));\n  }\n  const encodedValue = encodeURIComponent(value);\n  if (encodedValue && !fieldContentRegExp.test(encodedValue)) {\n    return Either.left(new CookiesError({\n      reason: \"InvalidValue\"\n    }));\n  }\n  if (options !== undefined) {\n    if (options.domain !== undefined && !fieldContentRegExp.test(options.domain)) {\n      return Either.left(new CookiesError({\n        reason: \"InvalidDomain\"\n      }));\n    }\n    if (options.path !== undefined && !fieldContentRegExp.test(options.path)) {\n      return Either.left(new CookiesError({\n        reason: \"InvalidPath\"\n      }));\n    }\n    if (options.maxAge !== undefined && !Duration.isFinite(Duration.decode(options.maxAge))) {\n      return Either.left(new CookiesError({\n        reason: \"InfinityMaxAge\"\n      }));\n    }\n  }\n  return Either.right(Object.assign(Object.create(CookieProto), {\n    name,\n    value,\n    valueEncoded: encodedValue,\n    options\n  }));\n}\n/**\n * Create a new cookie, throwing an error if invalid\n *\n * @since 1.0.0\n * @category constructors\n */\nexport const unsafeMakeCookie = (name, value, options) => Either.getOrThrow(makeCookie(name, value, options));\n/**\n * Add a cookie to a Cookies object\n *\n * @since 1.0.0\n * @category combinators\n */\nexport const setCookie = /*#__PURE__*/dual(2, (self, cookie) => fromReadonlyRecord(Record.set(self.cookies, cookie.name, cookie)));\n/**\n * Add multiple cookies to a Cookies object\n *\n * @since 1.0.0\n * @category combinators\n */\nexport const setAllCookie = /*#__PURE__*/dual(2, (self, cookies) => {\n  const record = {\n    ...self.cookies\n  };\n  for (const cookie of cookies) {\n    record[cookie.name] = cookie;\n  }\n  return fromReadonlyRecord(record);\n});\n/**\n * Combine two Cookies objects, removing duplicates from the first\n *\n * @since 1.0.0\n * @category combinators\n */\nexport const merge = /*#__PURE__*/dual(2, (self, that) => fromReadonlyRecord({\n  ...self.cookies,\n  ...that.cookies\n}));\n/**\n * Remove a cookie by name\n *\n * @since 1.0.0\n * @category combinators\n */\nexport const remove = /*#__PURE__*/dual(2, (self, name) => fromReadonlyRecord(Record.remove(self.cookies, name)));\n/**\n * Add a cookie to a Cookies object\n *\n * @since 1.0.0\n * @category combinators\n */\nexport const set = /*#__PURE__*/dual(args => isCookies(args[0]), (self, name, value, options) => Either.map(makeCookie(name, value, options), cookie => fromReadonlyRecord(Record.set(self.cookies, name, cookie))));\n/**\n * Add a cookie to a Cookies object\n *\n * @since 1.0.0\n * @category combinators\n */\nexport const unsafeSet = /*#__PURE__*/dual(args => isCookies(args[0]), (self, name, value, options) => fromReadonlyRecord(Record.set(self.cookies, name, unsafeMakeCookie(name, value, options))));\n/**\n * Add multiple cookies to a Cookies object\n *\n * @since 1.0.0\n * @category combinators\n */\nexport const setAll = /*#__PURE__*/dual(2, (self, cookies) => {\n  const record = {\n    ...self.cookies\n  };\n  for (const [name, value, options] of cookies) {\n    const either = makeCookie(name, value, options);\n    if (Either.isLeft(either)) {\n      return either;\n    }\n    record[name] = either.right;\n  }\n  return Either.right(fromReadonlyRecord(record));\n});\n/**\n * Add multiple cookies to a Cookies object, throwing an error if invalid\n *\n * @since 1.0.0\n * @category combinators\n */\nexport const unsafeSetAll = /*#__PURE__*/dual(2, (self, cookies) => Either.getOrThrow(setAll(self, cookies)));\n/**\n * Serialize a cookie into a string\n *\n * Adapted from https://github.com/fastify/fastify-cookie under MIT License\n *\n * @since 1.0.0\n * @category encoding\n */\nexport function serializeCookie(self) {\n  let str = self.name + \"=\" + self.valueEncoded;\n  if (self.options === undefined) {\n    return str;\n  }\n  const options = self.options;\n  if (options.maxAge !== undefined) {\n    const maxAge = Duration.toSeconds(options.maxAge);\n    str += \"; Max-Age=\" + Math.trunc(maxAge);\n  }\n  if (options.domain !== undefined) {\n    str += \"; Domain=\" + options.domain;\n  }\n  if (options.path !== undefined) {\n    str += \"; Path=\" + options.path;\n  }\n  if (options.priority !== undefined) {\n    switch (options.priority) {\n      case \"low\":\n        str += \"; Priority=Low\";\n        break;\n      case \"medium\":\n        str += \"; Priority=Medium\";\n        break;\n      case \"high\":\n        str += \"; Priority=High\";\n        break;\n    }\n  }\n  if (options.expires !== undefined) {\n    str += \"; Expires=\" + options.expires.toUTCString();\n  }\n  if (options.httpOnly) {\n    str += \"; HttpOnly\";\n  }\n  if (options.secure) {\n    str += \"; Secure\";\n  }\n  // Draft implementation to support Chrome from 2024-Q1 forward.\n  // See https://datatracker.ietf.org/doc/html/draft-cutler-httpbis-partitioned-cookies#section-2.1\n  if (options.partitioned) {\n    str += \"; Partitioned\";\n  }\n  if (options.sameSite !== undefined) {\n    switch (options.sameSite) {\n      case \"lax\":\n        str += \"; SameSite=Lax\";\n        break;\n      case \"strict\":\n        str += \"; SameSite=Strict\";\n        break;\n      case \"none\":\n        str += \"; SameSite=None\";\n        break;\n    }\n  }\n  return str;\n}\n/**\n * Serialize a Cookies object into a Cookie header\n *\n * @since 1.0.0\n * @category encoding\n */\nexport const toCookieHeader = self => Object.values(self.cookies).map(cookie => `${cookie.name}=${cookie.valueEncoded}`).join(\"; \");\n/**\n * To record\n *\n * @since 1.0.0\n * @category encoding\n */\nexport const toRecord = self => {\n  const record = {};\n  const cookies = Object.values(self.cookies);\n  for (let index = 0; index < cookies.length; index++) {\n    const cookie = cookies[index];\n    record[cookie.name] = cookie.value;\n  }\n  return record;\n};\n/**\n * Serialize a Cookies object into Headers object containing one or more Set-Cookie headers\n *\n * @since 1.0.0\n * @category encoding\n */\nexport const toSetCookieHeaders = self => Object.values(self.cookies).map(serializeCookie);\n/**\n * Parse a cookie header into a record of key-value pairs\n *\n * Adapted from https://github.com/fastify/fastify-cookie under MIT License\n *\n * @since 1.0.0\n * @category decoding\n */\nexport function parseHeader(header) {\n  const result = {};\n  const strLen = header.length;\n  let pos = 0;\n  let terminatorPos = 0;\n  // eslint-disable-next-line no-constant-condition\n  while (true) {\n    if (terminatorPos === strLen) break;\n    terminatorPos = header.indexOf(\";\", pos);\n    if (terminatorPos === -1) terminatorPos = strLen; // This is the last pair\n    let eqIdx = header.indexOf(\"=\", pos);\n    if (eqIdx === -1) break; // No key-value pairs left\n    if (eqIdx > terminatorPos) {\n      // Malformed key-value pair\n      pos = terminatorPos + 1;\n      continue;\n    }\n    const key = header.substring(pos, eqIdx++).trim();\n    if (result[key] === undefined) {\n      const val = header.charCodeAt(eqIdx) === 0x22 ? header.substring(eqIdx + 1, terminatorPos - 1).trim() : header.substring(eqIdx, terminatorPos).trim();\n      result[key] = !(val.indexOf(\"%\") === -1) ? tryDecodeURIComponent(val) : val;\n    }\n    pos = terminatorPos + 1;\n  }\n  return result;\n}\nconst tryDecodeURIComponent = str => {\n  try {\n    return decodeURIComponent(str);\n  } catch (_) {\n    return str;\n  }\n};\n//# sourceMappingURL=Cookies.js.map","import * as Data from \"effect/Data\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as internal from \"./internal/error.js\";\n/**\n * @since 1.0.0\n * @category type id\n */\nexport const PlatformErrorTypeId = internal.PlatformErrorTypeId;\n/**\n * @since 1.0.0\n * @category refinements\n */\nexport const isPlatformError = u => Predicate.hasProperty(u, PlatformErrorTypeId);\n/**\n * @since 1.0.0\n * @category error\n */\nexport const TypeIdError = (typeId, tag) => {\n  class Base extends Data.Error {\n    _tag = tag;\n  }\n  ;\n  Base.prototype[typeId] = typeId;\n  Base.prototype.name = tag;\n  return Base;\n};\n/**\n * @since 1.0.0\n * @category error\n */\nexport const BadArgument = internal.badArgument;\n/**\n * @since 1.0.0\n * @category error\n */\nexport const SystemError = internal.systemError;\n//# sourceMappingURL=Error.js.map","/**\n * @since 1.0.0\n */\nimport * as Brand from \"effect/Brand\";\nimport * as Context from \"effect/Context\";\nimport * as Data from \"effect/Data\";\nimport * as internal from \"./internal/fileSystem.js\";\n/**\n * @since 1.0.0\n * @category sizes\n */\nexport const Size = internal.Size;\n/**\n * @since 1.0.0\n * @category sizes\n */\nexport const KiB = internal.KiB;\n/**\n * @since 1.0.0\n * @category sizes\n */\nexport const MiB = internal.MiB;\n/**\n * @since 1.0.0\n * @category sizes\n */\nexport const GiB = internal.GiB;\n/**\n * @since 1.0.0\n * @category sizes\n */\nexport const TiB = internal.TiB;\n/**\n * @since 1.0.0\n * @category sizes\n */\nexport const PiB = internal.PiB;\n/**\n * @since 1.0.0\n * @category tag\n */\nexport const FileSystem = internal.tag;\n/**\n * @since 1.0.0\n * @category constructor\n */\nexport const make = internal.make;\n/**\n * Create a no-op file system that can be used for testing.\n *\n * @since 1.0.0\n * @category constructor\n */\nexport const makeNoop = internal.makeNoop;\n/**\n * Create a no-op file system that can be used for testing.\n *\n * @since 1.0.0\n * @category layers\n */\nexport const layerNoop = internal.layerNoop;\n/**\n * @since 1.0.0\n * @category type id\n */\nexport const FileTypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/FileSystem/File\");\n/**\n * @since 1.0.0\n * @category guard\n */\nexport const isFile = u => typeof u === \"object\" && u !== null && FileTypeId in u;\n/**\n * @since 1.0.0\n * @category constructor\n */\nexport const FileDescriptor = /*#__PURE__*/Brand.nominal();\n/**\n * @since 1.0.0\n * @category constructor\n */\nexport const WatchEventCreate = /*#__PURE__*/Data.tagged(\"Create\");\n/**\n * @since 1.0.0\n * @category constructor\n */\nexport const WatchEventUpdate = /*#__PURE__*/Data.tagged(\"Update\");\n/**\n * @since 1.0.0\n * @category constructor\n */\nexport const WatchEventRemove = /*#__PURE__*/Data.tagged(\"Remove\");\n/**\n * @since 1.0.0\n * @category file watcher\n */\nexport class WatchBackend extends /*#__PURE__*/Context.Tag(\"@effect/platform/FileSystem/WatchBackend\")() {}\n//# sourceMappingURL=FileSystem.js.map","/**\n * @since 1.0.0\n */\nimport * as Schema from \"@effect/schema/Schema\";\nimport * as FiberRef from \"effect/FiberRef\";\nimport { dual, identity } from \"effect/Function\";\nimport { globalValue } from \"effect/GlobalValue\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as Record from \"effect/Record\";\nimport * as Redacted from \"effect/Redacted\";\nimport * as String from \"effect/String\";\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const HeadersTypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/Headers\");\n/**\n * @since 1.0.0\n * @category refinements\n */\nexport const isHeaders = u => Predicate.hasProperty(u, HeadersTypeId);\nconst Proto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(null), {\n  [HeadersTypeId]: HeadersTypeId\n});\nconst make = input => Object.assign(Object.create(Proto), input);\n/**\n * @since 1.0.0\n * @category schemas\n */\nexport const schemaFromSelf = /*#__PURE__*/Schema.declare(isHeaders, {\n  identifier: \"Headers\",\n  equivalence: () => Record.getEquivalence(String.Equivalence)\n});\n/**\n * @since 1.0.0\n * @category schemas\n */\nexport const schema = /*#__PURE__*/Schema.transform( /*#__PURE__*/Schema.Record(Schema.String, /*#__PURE__*/Schema.Union(Schema.String, /*#__PURE__*/Schema.Array(Schema.String))), schemaFromSelf, {\n  strict: true,\n  decode: record => fromInput(record),\n  encode: identity\n});\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const empty = /*#__PURE__*/Object.create(Proto);\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const fromInput = input => {\n  if (input === undefined) {\n    return empty;\n  } else if (Symbol.iterator in input) {\n    const out = Object.create(Proto);\n    for (const [k, v] of input) {\n      out[k.toLowerCase()] = v;\n    }\n    return out;\n  }\n  const out = Object.create(Proto);\n  for (const [k, v] of Object.entries(input)) {\n    if (Array.isArray(v)) {\n      out[k.toLowerCase()] = v.join(\", \");\n    } else if (v !== undefined) {\n      out[k.toLowerCase()] = v;\n    }\n  }\n  return out;\n};\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const unsafeFromRecord = input => Object.setPrototypeOf(input, Proto);\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const has = /*#__PURE__*/dual(2, (self, key) => key.toLowerCase() in self);\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const get = /*#__PURE__*/dual(2, (self, key) => Record.get(self, key.toLowerCase()));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const set = /*#__PURE__*/dual(3, (self, key, value) => {\n  const out = make(self);\n  out[key.toLowerCase()] = value;\n  return out;\n});\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setAll = /*#__PURE__*/dual(2, (self, headers) => make({\n  ...self,\n  ...fromInput(headers)\n}));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const merge = /*#__PURE__*/dual(2, (self, headers) => {\n  const out = make(self);\n  Object.assign(out, headers);\n  return out;\n});\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const remove = /*#__PURE__*/dual(2, (self, key) => {\n  const out = make(self);\n  delete out[key.toLowerCase()];\n  return out;\n});\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const redact = /*#__PURE__*/dual(2, (self, key) => {\n  const out = {\n    ...self\n  };\n  const modify = key => {\n    if (typeof key === \"string\") {\n      const k = key.toLowerCase();\n      if (k in self) {\n        out[k] = Redacted.make(self[k]);\n      }\n    } else {\n      for (const name in self) {\n        if (key.test(name)) {\n          out[name] = Redacted.make(self[name]);\n        }\n      }\n    }\n  };\n  if (Array.isArray(key)) {\n    for (let i = 0; i < key.length; i++) {\n      modify(key[i]);\n    }\n  } else {\n    modify(key);\n  }\n  return out;\n});\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const currentRedactedNames = /*#__PURE__*/globalValue(\"@effect/platform/Headers/currentRedactedNames\", () => FiberRef.unsafeMake([\"authorization\", \"cookie\", \"set-cookie\", \"x-api-key\"]));\n//# sourceMappingURL=Headers.js.map","import * as internal from \"./internal/httpClient.js\";\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const TypeId = internal.TypeId;\n/**\n * @since 1.0.0\n * @category tags\n */\nexport const HttpClient = internal.tag;\n/**\n * @since 1.0.0\n * @category tags\n */\nexport const Fetch = internal.Fetch;\n/**\n * @since 1.0.0\n * @category layers\n */\nexport const layer = internal.layer;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const fetch = internal.fetch;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const fetchOk = internal.fetchOk;\n/**\n * @since 1.0.0\n * @category error handling\n */\nexport const catchAll = internal.catchAll;\n/**\n * @since 1.0.0\n * @category error handling\n */\nexport const catchTag = internal.catchTag;\n/**\n * @since 1.0.0\n * @category error handling\n */\nexport const catchTags = internal.catchTags;\n/**\n * @since 1.0.0\n * @category filters\n */\nexport const filterOrElse = internal.filterOrElse;\n/**\n * @since 1.0.0\n * @category filters\n */\nexport const filterOrFail = internal.filterOrFail;\n/**\n * @since 1.0.0\n * @category filters\n */\nexport const filterStatus = internal.filterStatus;\n/**\n * @since 1.0.0\n * @category filters\n */\nexport const filterStatusOk = internal.filterStatusOk;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const makeDefault = internal.makeDefault;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const transform = internal.transform;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const transformResponse = internal.transformResponse;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const map = internal.map;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const mapEffect = internal.mapEffect;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const mapEffectScoped = internal.mapEffectScoped;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const mapRequest = internal.mapRequest;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const mapRequestEffect = internal.mapRequestEffect;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const mapInputRequest = internal.mapInputRequest;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const mapInputRequestEffect = internal.mapInputRequestEffect;\n/**\n * @since 1.0.0\n * @category error handling\n */\nexport const retry = internal.retry;\n/**\n * @since 1.0.0\n * @category resources & finalizers\n */\nexport const scoped = internal.scoped;\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaFunction = internal.schemaFunction;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const tap = internal.tap;\n/**\n * @since 1.0.0\n * @category mapping & sequencing\n */\nexport const tapRequest = internal.tapRequest;\n/**\n * @since 1.0.0\n * @category cookies\n */\nexport const withCookiesRef = internal.withCookiesRef;\n/**\n * @since 1.0.0\n * @category redirects\n */\nexport const followRedirects = internal.followRedirects;\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const currentTracerDisabledWhen = internal.currentTracerDisabledWhen;\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const withTracerDisabledWhen = internal.withTracerDisabledWhen;\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const currentTracerPropagation = internal.currentTracerPropagation;\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const withTracerPropagation = internal.withTracerPropagation;\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const currentFetchOptions = internal.currentFetchOptions;\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const withFetchOptions = internal.withFetchOptions;\n//# sourceMappingURL=HttpClient.js.map","/**\n * @since 1.0.0\n */\nimport * as Error from \"@effect/platform/Error\";\nimport * as internal from \"./internal/httpClientError.js\";\n/**\n * @since 1.0.0\n * @category type id\n */\nexport const TypeId = internal.TypeId;\n/**\n * @since 1.0.0\n * @category error\n */\nexport class RequestError extends /*#__PURE__*/Error.TypeIdError(TypeId, \"RequestError\") {\n  get methodAndUrl() {\n    return `${this.request.method} ${this.request.url}`;\n  }\n  get message() {\n    return this.description ? `${this.reason}: ${this.description} (${this.methodAndUrl})` : `${this.reason} error (${this.methodAndUrl})`;\n  }\n}\n/**\n * @since 1.0.0\n * @category error\n */\nexport class ResponseError extends /*#__PURE__*/Error.TypeIdError(TypeId, \"ResponseError\") {\n  get methodAndUrl() {\n    return `${this.request.method} ${this.request.url}`;\n  }\n  get message() {\n    const info = `${this.response.status} ${this.methodAndUrl}`;\n    return this.description ? `${this.reason}: ${this.description} (${info})` : `${this.reason} error (${info})`;\n  }\n}\n//# sourceMappingURL=HttpClientError.js.map","import * as internal from \"./internal/httpClientRequest.js\";\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/HttpClientRequest\");\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const get = internal.get;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const post = internal.post;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const patch = internal.patch;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const put = internal.put;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const del = internal.del;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const head = internal.head;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const options = internal.options;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const modify = internal.modify;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setMethod = internal.setMethod;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setHeader = internal.setHeader;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setHeaders = internal.setHeaders;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const basicAuth = internal.basicAuth;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const bearerToken = internal.bearerToken;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const accept = internal.accept;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const acceptJson = internal.acceptJson;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setUrl = internal.setUrl;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const prependUrl = internal.prependUrl;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const appendUrl = internal.appendUrl;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const updateUrl = internal.updateUrl;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setUrlParam = internal.setUrlParam;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setUrlParams = internal.setUrlParams;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const appendUrlParam = internal.appendUrlParam;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const appendUrlParams = internal.appendUrlParams;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setHash = internal.setHash;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const removeHash = internal.removeHash;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setBody = internal.setBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const uint8ArrayBody = internal.uint8ArrayBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const textBody = internal.textBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const jsonBody = internal.jsonBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const unsafeJsonBody = internal.unsafeJsonBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const schemaBody = internal.schemaBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const urlParamsBody = internal.urlParamsBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const formDataBody = internal.formDataBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const streamBody = internal.streamBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const fileBody = internal.fileBody;\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const fileWebBody = internal.fileWebBody;\n//# sourceMappingURL=HttpClientRequest.js.map","import * as internal from \"./internal/httpClientResponse.js\";\nexport {\n/**\n * @since 1.0.0\n * @category schema\n */\nschemaBodyJson,\n/**\n * @since 1.0.0\n * @category schema\n */\nschemaBodyJsonScoped,\n/**\n * @since 1.0.0\n * @category schema\n */\nschemaBodyUrlParams,\n/**\n * @since 1.0.0\n * @category schema\n */\nschemaBodyUrlParamsScoped,\n/**\n * @since 1.0.0\n * @category schema\n */\nschemaHeaders,\n/**\n * @since 1.0.0\n * @category schema\n */\nschemaHeadersScoped } from \"./HttpIncomingMessage.js\";\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const TypeId = internal.TypeId;\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const fromWeb = internal.fromWeb;\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaJson = internal.schemaJson;\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaNoBody = internal.schemaNoBody;\n/**\n * @since 1.0.0\n * @category accessors\n */\nexport const arrayBuffer = internal.arrayBuffer;\n/**\n * @since 1.0.0\n * @category accessors\n */\nexport const formData = internal.formData;\n/**\n * @since 1.0.0\n * @category accessors\n */\nexport const json = internal.json;\nconst void_ = internal.void_;\nexport {\n/**\n * @since 1.0.0\n * @category accessors\n */\nvoid_ as void };\n/**\n * @since 1.0.0\n * @category accessors\n */\nexport const stream = internal.stream;\n/**\n * @since 1.0.0\n * @category accessors\n */\nexport const text = internal.text;\n/**\n * @since 1.0.0\n * @category accessors\n */\nexport const urlParamsBody = internal.urlParamsBody;\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaJsonScoped = internal.schemaJsonScoped;\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaNoBodyScoped = internal.schemaNoBodyScoped;\n/**\n * @since 1.0.0\n * @category pattern matching\n */\nexport const matchStatus = internal.matchStatus;\n/**\n * @since 1.0.0\n * @category pattern matching\n */\nexport const matchStatusScoped = internal.matchStatusScoped;\n//# sourceMappingURL=HttpClientResponse.js.map","import * as Schema from \"@effect/schema/Schema\";\nimport * as Effect from \"effect/Effect\";\nimport * as FiberRef from \"effect/FiberRef\";\nimport { dual } from \"effect/Function\";\nimport * as Global from \"effect/GlobalValue\";\nimport * as Option from \"effect/Option\";\nimport * as FileSystem from \"./FileSystem.js\";\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/HttpIncomingMessage\");\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaBodyJson = (schema, options) => {\n  const parse = Schema.decodeUnknown(schema, options);\n  return self => Effect.flatMap(self.json, parse);\n};\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaBodyJsonScoped = (schema, options) => {\n  const decode = schemaBodyJson(schema, options);\n  return effect => Effect.scoped(Effect.flatMap(effect, decode));\n};\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaBodyUrlParams = (schema, options) => {\n  const parse = Schema.decodeUnknown(schema, options);\n  return self => Effect.flatMap(self.urlParamsBody, _ => parse(Object.fromEntries(_)));\n};\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaBodyUrlParamsScoped = (schema, options) => {\n  const decode = schemaBodyUrlParams(schema, options);\n  return effect => Effect.scoped(Effect.flatMap(effect, decode));\n};\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaHeaders = (schema, options) => {\n  const parse = Schema.decodeUnknown(schema, options);\n  return self => parse(self.headers);\n};\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaHeadersScoped = (schema, options) => {\n  const decode = schemaHeaders(schema, options);\n  return effect => Effect.scoped(Effect.flatMap(effect, decode));\n};\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const maxBodySize = /*#__PURE__*/Global.globalValue(\"@effect/platform/HttpIncomingMessage/maxBodySize\", () => FiberRef.unsafeMake(Option.none()));\n/**\n * @since 1.0.0\n * @category fiber refs\n */\nexport const withMaxBodySize = /*#__PURE__*/dual(2, (effect, size) => Effect.locally(effect, maxBodySize, Option.map(size, FileSystem.Size)));\n/**\n * @since 1.0.0\n */\nexport const inspect = (self, that) => {\n  const contentType = self.headers[\"content-type\"] ?? \"\";\n  let body;\n  if (contentType.includes(\"application/json\")) {\n    try {\n      body = Effect.runSync(self.json);\n    } catch (_) {\n      //\n    }\n  } else if (contentType.includes(\"text/\") || contentType.includes(\"urlencoded\")) {\n    try {\n      body = Effect.runSync(self.text);\n    } catch (_) {\n      //\n    }\n  }\n  const obj = {\n    ...that,\n    headers: self.headers,\n    remoteAddress: self.remoteAddress.toJSON()\n  };\n  if (body !== undefined) {\n    obj.body = body;\n  }\n  return obj;\n};\n//# sourceMappingURL=HttpIncomingMessage.js.map","/**\n * @since 1.0.0\n */\nexport const hasBody = method => method !== \"GET\" && method !== \"HEAD\";\n//# sourceMappingURL=HttpMethod.js.map","/**\n * @since 1.0.0\n */\nimport * as Option from \"effect/Option\";\nimport * as Tracer from \"effect/Tracer\";\nimport * as Headers from \"./Headers.js\";\n/**\n * @since 1.0.0\n * @category encoding\n */\nexport const toHeaders = span => Headers.unsafeFromRecord({\n  b3: `${span.traceId}-${span.spanId}-${span.sampled ? \"1\" : \"0\"}${span.parent._tag === \"Some\" ? `-${span.parent.value.spanId}` : \"\"}`,\n  traceparent: `00-${span.traceId}-${span.spanId}-${span.sampled ? \"01\" : \"00\"}`\n});\n/**\n * @since 1.0.0\n * @category decoding\n */\nexport const fromHeaders = headers => {\n  let span = w3c(headers);\n  if (span._tag === \"Some\") {\n    return span;\n  }\n  span = b3(headers);\n  if (span._tag === \"Some\") {\n    return span;\n  }\n  return xb3(headers);\n};\n/**\n * @since 1.0.0\n * @category decoding\n */\nexport const b3 = headers => {\n  if (!(\"b3\" in headers)) {\n    return Option.none();\n  }\n  const parts = headers[\"b3\"].split(\"-\");\n  if (parts.length < 2) {\n    return Option.none();\n  }\n  return Option.some(Tracer.externalSpan({\n    traceId: parts[0],\n    spanId: parts[1],\n    sampled: parts[2] ? parts[2] === \"1\" : true\n  }));\n};\n/**\n * @since 1.0.0\n * @category decoding\n */\nexport const xb3 = headers => {\n  if (!headers[\"x-b3-traceid\"] || !headers[\"x-b3-spanid\"]) {\n    return Option.none();\n  }\n  return Option.some(Tracer.externalSpan({\n    traceId: headers[\"x-b3-traceid\"],\n    spanId: headers[\"x-b3-spanid\"],\n    sampled: headers[\"x-b3-sampled\"] ? headers[\"x-b3-sampled\"] === \"1\" : true\n  }));\n};\nconst w3cTraceId = /^[0-9a-f]{32}$/gi;\nconst w3cSpanId = /^[0-9a-f]{16}$/gi;\n/**\n * @since 1.0.0\n * @category decoding\n */\nexport const w3c = headers => {\n  if (!headers[\"traceparent\"]) {\n    return Option.none();\n  }\n  const parts = headers[\"traceparent\"].split(\"-\");\n  if (parts.length !== 4) {\n    return Option.none();\n  }\n  const [version, traceId, spanId, flags] = parts;\n  switch (version) {\n    case \"00\":\n      {\n        if (w3cTraceId.test(traceId) === false || w3cSpanId.test(spanId) === false) {\n          return Option.none();\n        }\n        return Option.some(Tracer.externalSpan({\n          traceId,\n          spanId,\n          sampled: (parseInt(flags, 16) & 1) === 1\n        }));\n      }\n    default:\n      {\n        return Option.none();\n      }\n  }\n};\n//# sourceMappingURL=HttpTraceContext.js.map","import * as Schema from \"@effect/schema/Schema\";\nimport * as Arr from \"effect/Array\";\nimport * as Either from \"effect/Either\";\nimport { dual } from \"effect/Function\";\nimport * as Option from \"effect/Option\";\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const fromInput = input => {\n  const entries = Symbol.iterator in input ? Arr.fromIterable(input) : Object.entries(input);\n  const out = [];\n  for (const [key, value] of entries) {\n    if (Array.isArray(value)) {\n      for (let i = 0; i < value.length; i++) {\n        if (value[i] !== undefined) {\n          out.push([key, String(value[i])]);\n        }\n      }\n    } else if (value !== undefined) {\n      out.push([key, String(value)]);\n    }\n  }\n  return out;\n};\n/**\n * @since 1.0.0\n * @category schemas\n */\nexport const schema = /*#__PURE__*/Schema.Array(Schema.Tuple(Schema.String, Schema.String)).annotations({\n  identifier: \"UrlParams\"\n});\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const empty = [];\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const getAll = /*#__PURE__*/dual(2, (self, key) => Arr.reduce(self, [], (acc, [k, value]) => {\n  if (k === key) {\n    acc.push(value);\n  }\n  return acc;\n}));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const getFirst = /*#__PURE__*/dual(2, (self, key) => Option.map(Arr.findFirst(self, ([k]) => k === key), ([, value]) => value));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const getLast = /*#__PURE__*/dual(2, (self, key) => Option.map(Arr.findLast(self, ([k]) => k === key), ([, value]) => value));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const set = /*#__PURE__*/dual(3, (self, key, value) => Arr.append(Arr.filter(self, ([k]) => k !== key), [key, String(value)]));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const setAll = /*#__PURE__*/dual(2, (self, input) => {\n  const toSet = fromInput(input);\n  const keys = toSet.map(([k]) => k);\n  return Arr.appendAll(Arr.filter(self, ([k]) => keys.includes(k)), toSet);\n});\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const append = /*#__PURE__*/dual(3, (self, key, value) => Arr.append(self, [key, String(value)]));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const appendAll = /*#__PURE__*/dual(2, (self, input) => Arr.appendAll(self, fromInput(input)));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const remove = /*#__PURE__*/dual(2, (self, key) => Arr.filter(self, ([k]) => k !== key));\n/**\n * @since 1.0.0\n * @category combinators\n */\nexport const toString = self => new URLSearchParams(self).toString();\n/**\n * @since 1.0.0\n * @category constructors\n */\nexport const makeUrl = (url, params, hash) => {\n  try {\n    const urlInstance = new URL(url, baseUrl());\n    for (let i = 0; i < params.length; i++) {\n      const [key, value] = params[i];\n      if (value !== undefined) {\n        urlInstance.searchParams.append(key, value);\n      }\n    }\n    if (hash._tag === \"Some\") {\n      urlInstance.hash = hash.value;\n    }\n    return Either.right(urlInstance);\n  } catch (e) {\n    return Either.left(e);\n  }\n};\nconst baseUrl = () => {\n  if (\"location\" in globalThis && globalThis.location !== undefined && globalThis.location.origin !== undefined && globalThis.location.pathname !== undefined) {\n    return location.origin + location.pathname;\n  }\n  return undefined;\n};\n/**\n * @since 1.0.0\n * @category schema\n */\nexport const schemaJson = (schema, options) => {\n  const parse = Schema.decodeUnknown(Schema.parseJson(schema), options);\n  return dual(2, (self, field) => parse(Option.getOrElse(getLast(self, field), () => \"\")));\n};\n//# sourceMappingURL=UrlParams.js.map","import * as Data from \"effect/Data\";\n/** @internal */\nexport const PlatformErrorTypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/Error/PlatformErrorTypeId\");\nconst make = tag => props => Data.struct({\n  [PlatformErrorTypeId]: PlatformErrorTypeId,\n  _tag: tag,\n  ...props\n});\n/** @internal */\nexport const badArgument = /*#__PURE__*/make(\"BadArgument\");\n/** @internal */\nexport const systemError = /*#__PURE__*/make(\"SystemError\");\n//# sourceMappingURL=error.js.map","import * as Channel from \"effect/Channel\";\nimport * as Chunk from \"effect/Chunk\";\nimport { GenericTag } from \"effect/Context\";\nimport * as Effect from \"effect/Effect\";\nimport { identity, pipe } from \"effect/Function\";\nimport * as Layer from \"effect/Layer\";\nimport * as Option from \"effect/Option\";\nimport * as Sink from \"effect/Sink\";\nimport * as Stream from \"effect/Stream\";\nimport * as Error from \"../Error.js\";\n/** @internal */\nexport const tag = /*#__PURE__*/GenericTag(\"@effect/platform/FileSystem\");\n/** @internal */\nexport const Size = bytes => typeof bytes === \"bigint\" ? bytes : BigInt(bytes);\n/** @internal */\nexport const KiB = n => Size(n * 1024);\n/** @internal */\nexport const MiB = n => Size(n * 1024 * 1024);\n/** @internal */\nexport const GiB = n => Size(n * 1024 * 1024 * 1024);\n/** @internal */\nexport const TiB = n => Size(n * 1024 * 1024 * 1024 * 1024);\nconst bigint1024 = /*#__PURE__*/BigInt(1024);\nconst bigintPiB = bigint1024 * bigint1024 * bigint1024 * bigint1024 * bigint1024;\n/** @internal */\nexport const PiB = n => Size(BigInt(n) * bigintPiB);\n/** @internal */\nexport const make = impl => {\n  return tag.of({\n    ...impl,\n    exists: path => pipe(impl.access(path), Effect.as(true), Effect.catchTag(\"SystemError\", e => e.reason === \"NotFound\" ? Effect.succeed(false) : Effect.fail(e))),\n    readFileString: (path, encoding) => Effect.tryMap(impl.readFile(path), {\n      try: _ => new TextDecoder(encoding).decode(_),\n      catch: () => Error.BadArgument({\n        module: \"FileSystem\",\n        method: \"readFileString\",\n        message: \"invalid encoding\"\n      })\n    }),\n    stream: (path, options) => pipe(impl.open(path, {\n      flag: \"r\"\n    }), options?.offset ? Effect.tap(file => file.seek(options.offset, \"start\")) : identity, Effect.map(file => stream(file, options)), Stream.unwrapScoped),\n    sink: (path, options) => pipe(impl.open(path, {\n      flag: \"w\",\n      ...options\n    }), Effect.map(file => Sink.forEach(_ => file.writeAll(_))), Sink.unwrapScoped),\n    writeFileString: (path, data, options) => Effect.flatMap(Effect.try({\n      try: () => new TextEncoder().encode(data),\n      catch: () => Error.BadArgument({\n        module: \"FileSystem\",\n        method: \"writeFileString\",\n        message: \"could not encode string\"\n      })\n    }), _ => impl.writeFile(path, _, options))\n  });\n};\nconst notFound = (method, path) => Error.SystemError({\n  module: \"FileSystem\",\n  method,\n  reason: \"NotFound\",\n  message: \"No such file or directory\",\n  pathOrDescriptor: path\n});\n/** @internal */\nexport const makeNoop = fileSystem => {\n  return {\n    access(path) {\n      return Effect.fail(notFound(\"access\", path));\n    },\n    chmod(path) {\n      return Effect.fail(notFound(\"chmod\", path));\n    },\n    chown(path) {\n      return Effect.fail(notFound(\"chown\", path));\n    },\n    copy(path) {\n      return Effect.fail(notFound(\"copy\", path));\n    },\n    copyFile(path) {\n      return Effect.fail(notFound(\"copyFile\", path));\n    },\n    exists() {\n      return Effect.succeed(false);\n    },\n    link(path) {\n      return Effect.fail(notFound(\"link\", path));\n    },\n    makeDirectory() {\n      return Effect.die(\"not implemented\");\n    },\n    makeTempDirectory() {\n      return Effect.die(\"not implemented\");\n    },\n    makeTempDirectoryScoped() {\n      return Effect.die(\"not implemented\");\n    },\n    makeTempFile() {\n      return Effect.die(\"not implemented\");\n    },\n    makeTempFileScoped() {\n      return Effect.die(\"not implemented\");\n    },\n    open(path) {\n      return Effect.fail(notFound(\"open\", path));\n    },\n    readDirectory(path) {\n      return Effect.fail(notFound(\"readDirectory\", path));\n    },\n    readFile(path) {\n      return Effect.fail(notFound(\"readFile\", path));\n    },\n    readFileString(path) {\n      return Effect.fail(notFound(\"readFileString\", path));\n    },\n    readLink(path) {\n      return Effect.fail(notFound(\"readLink\", path));\n    },\n    realPath(path) {\n      return Effect.fail(notFound(\"realPath\", path));\n    },\n    remove() {\n      return Effect.void;\n    },\n    rename(oldPath) {\n      return Effect.fail(notFound(\"rename\", oldPath));\n    },\n    sink(path) {\n      return Sink.fail(notFound(\"sink\", path));\n    },\n    stat(path) {\n      return Effect.fail(notFound(\"stat\", path));\n    },\n    stream(path) {\n      return Stream.fail(notFound(\"stream\", path));\n    },\n    symlink(fromPath) {\n      return Effect.fail(notFound(\"symlink\", fromPath));\n    },\n    truncate(path) {\n      return Effect.fail(notFound(\"truncate\", path));\n    },\n    utimes(path) {\n      return Effect.fail(notFound(\"utimes\", path));\n    },\n    watch(path) {\n      return Stream.fail(notFound(\"watch\", path));\n    },\n    writeFile(path) {\n      return Effect.fail(notFound(\"writeFile\", path));\n    },\n    writeFileString(path) {\n      return Effect.fail(notFound(\"writeFileString\", path));\n    },\n    ...fileSystem\n  };\n};\n/** @internal */\nexport const layerNoop = fileSystem => Layer.succeed(tag, makeNoop(fileSystem));\n/** @internal */\nconst stream = (file, {\n  bufferSize = 16,\n  bytesToRead: bytesToRead_,\n  chunkSize: chunkSize_ = Size(64 * 1024)\n} = {}) => {\n  const bytesToRead = bytesToRead_ !== undefined ? Size(bytesToRead_) : undefined;\n  const chunkSize = Size(chunkSize_);\n  function loop(totalBytesRead) {\n    if (bytesToRead !== undefined && bytesToRead <= totalBytesRead) {\n      return Channel.void;\n    }\n    const toRead = bytesToRead !== undefined && bytesToRead - totalBytesRead < chunkSize ? bytesToRead - totalBytesRead : chunkSize;\n    return Channel.flatMap(file.readAlloc(toRead), Option.match({\n      onNone: () => Channel.void,\n      onSome: buf => Channel.flatMap(Channel.write(Chunk.of(buf)), _ => loop(totalBytesRead + BigInt(buf.length)))\n    }));\n  }\n  return Stream.bufferChunks(Stream.fromChannel(loop(BigInt(0))), {\n    capacity: bufferSize\n  });\n};\n//# sourceMappingURL=fileSystem.js.map","import * as Schema from \"@effect/schema/Schema\";\nimport * as Data from \"effect/Data\";\nimport * as Effect from \"effect/Effect\";\nimport { identity } from \"effect/Function\";\nimport * as Inspectable from \"effect/Inspectable\";\nimport * as Stream_ from \"effect/Stream\";\nimport * as FileSystem from \"../FileSystem.js\";\nimport * as UrlParams from \"../UrlParams.js\";\n/** @internal */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/HttpBody\");\n/** @internal */\nexport const ErrorTypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/HttpBody/HttpBodyError\");\nconst bodyError = /*#__PURE__*/Data.tagged(\"HttpBodyError\");\n/** @internal */\nexport const HttpBodyError = reason => bodyError({\n  [ErrorTypeId]: ErrorTypeId,\n  reason\n});\nclass BodyBase {\n  [TypeId];\n  constructor() {\n    this[TypeId] = TypeId;\n  }\n  [Inspectable.NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n  toString() {\n    return Inspectable.format(this);\n  }\n}\nclass EmptyImpl extends BodyBase {\n  _tag = \"Empty\";\n  toJSON() {\n    return {\n      _id: \"@effect/platform/HttpBody\",\n      _tag: \"Empty\"\n    };\n  }\n}\n/** @internal */\nexport const empty = /*#__PURE__*/new EmptyImpl();\nclass RawImpl extends BodyBase {\n  body;\n  contentType;\n  contentLength;\n  _tag = \"Raw\";\n  constructor(body, contentType, contentLength) {\n    super();\n    this.body = body;\n    this.contentType = contentType;\n    this.contentLength = contentLength;\n  }\n  toJSON() {\n    return {\n      _id: \"@effect/platform/HttpBody\",\n      _tag: \"Raw\",\n      body: this.body,\n      contentType: this.contentType,\n      contentLength: this.contentLength\n    };\n  }\n}\n/** @internal */\nexport const raw = (body, options) => new RawImpl(body, options?.contentType, options?.contentLength);\nclass Uint8ArrayImpl extends BodyBase {\n  body;\n  contentType;\n  _tag = \"Uint8Array\";\n  constructor(body, contentType) {\n    super();\n    this.body = body;\n    this.contentType = contentType;\n  }\n  get contentLength() {\n    return this.body.length;\n  }\n  toJSON() {\n    const toString = this.contentType.startsWith(\"text/\") || this.contentType.endsWith(\"json\");\n    return {\n      _id: \"@effect/platform/HttpBody\",\n      _tag: \"Uint8Array\",\n      body: toString ? new TextDecoder().decode(this.body) : `Uint8Array(${this.body.length})`,\n      contentType: this.contentType,\n      contentLength: this.contentLength\n    };\n  }\n}\n/** @internal */\nexport const uint8Array = (body, contentType) => new Uint8ArrayImpl(body, contentType ?? \"application/octet-stream\");\nconst encoder = /*#__PURE__*/new TextEncoder();\n/** @internal */\nexport const text = (body, contentType) => uint8Array(encoder.encode(body), contentType ?? \"text/plain\");\n/** @internal */\nexport const unsafeJson = body => text(JSON.stringify(body), \"application/json\");\n/** @internal */\nexport const json = body => Effect.try({\n  try: () => unsafeJson(body),\n  catch: error => HttpBodyError({\n    _tag: \"JsonError\",\n    error\n  })\n});\n/** @internal */\nexport const urlParams = urlParams => text(UrlParams.toString(urlParams), \"application/x-www-form-urlencoded\");\n/** @internal */\nexport const jsonSchema = (schema, options) => {\n  const encode = Schema.encode(schema, options);\n  return body => Effect.flatMap(Effect.mapError(encode(body), error => HttpBodyError({\n    _tag: \"SchemaError\",\n    error\n  })), json);\n};\n/** @internal */\nexport const file = (path, options) => Effect.flatMap(FileSystem.FileSystem, fs => Effect.map(fs.stat(path), info => stream(fs.stream(path, options), options?.contentType, Number(info.size))));\n/** @internal */\nexport const fileInfo = (path, info, options) => Effect.map(FileSystem.FileSystem, fs => stream(fs.stream(path, options), options?.contentType, Number(info.size)));\n/** @internal */\nexport const fileWeb = file => stream(Stream_.fromReadableStream(() => file.stream(), identity), file.type, file.size);\nclass FormDataImpl extends BodyBase {\n  formData;\n  _tag = \"FormData\";\n  constructor(formData) {\n    super();\n    this.formData = formData;\n  }\n  toJSON() {\n    return {\n      _id: \"@effect/platform/HttpBody\",\n      _tag: \"FormData\",\n      formData: this.formData\n    };\n  }\n}\n/** @internal */\nexport const formData = body => new FormDataImpl(body);\nclass StreamImpl extends BodyBase {\n  stream;\n  contentType;\n  contentLength;\n  _tag = \"Stream\";\n  constructor(stream, contentType, contentLength) {\n    super();\n    this.stream = stream;\n    this.contentType = contentType;\n    this.contentLength = contentLength;\n  }\n  toJSON() {\n    return {\n      _id: \"@effect/platform/HttpBody\",\n      _tag: \"Stream\",\n      contentType: this.contentType,\n      contentLength: this.contentLength\n    };\n  }\n}\n/** @internal */\nexport const stream = (body, contentType, contentLength) => new StreamImpl(body, contentType ?? \"application/octet-stream\", contentLength);\n//# sourceMappingURL=httpBody.js.map","import * as Schema from \"@effect/schema/Schema\";\nimport * as Context from \"effect/Context\";\nimport * as Effect from \"effect/Effect\";\nimport * as FiberRef from \"effect/FiberRef\";\nimport { constFalse, dual } from \"effect/Function\";\nimport { globalValue } from \"effect/GlobalValue\";\nimport * as Layer from \"effect/Layer\";\nimport { pipeArguments } from \"effect/Pipeable\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as Ref from \"effect/Ref\";\nimport * as Scope from \"effect/Scope\";\nimport * as Stream from \"effect/Stream\";\nimport * as Cookies from \"../Cookies.js\";\nimport * as Headers from \"../Headers.js\";\nimport * as Error from \"../HttpClientError.js\";\nimport * as Method from \"../HttpMethod.js\";\nimport * as TraceContext from \"../HttpTraceContext.js\";\nimport * as UrlParams from \"../UrlParams.js\";\nimport * as internalBody from \"./httpBody.js\";\nimport * as internalRequest from \"./httpClientRequest.js\";\nimport * as internalResponse from \"./httpClientResponse.js\";\n/** @internal */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/HttpClient\");\n/** @internal */\nexport const tag = /*#__PURE__*/Context.GenericTag(\"@effect/platform/HttpClient\");\n/** @internal */\nexport const currentTracerDisabledWhen = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"@effect/platform/HttpClient/tracerDisabledWhen\"), () => FiberRef.unsafeMake(constFalse));\n/** @internal */\nexport const withTracerDisabledWhen = /*#__PURE__*/dual(2, (self, pred) => Effect.locally(self, currentTracerDisabledWhen, pred));\n/** @internal */\nexport const currentTracerPropagation = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"@effect/platform/HttpClient/currentTracerPropagation\"), () => FiberRef.unsafeMake(true));\n/** @internal */\nexport const withTracerPropagation = /*#__PURE__*/dual(2, (self, enabled) => Effect.locally(self, currentTracerPropagation, enabled));\n/** @internal */\nexport const currentFetchOptions = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"@effect/platform/HttpClient/currentFetchOptions\"), () => FiberRef.unsafeMake({}));\n/** @internal */\nexport const withFetchOptions = /*#__PURE__*/dual(2, (self, options) => Effect.locally(self, currentFetchOptions, options));\nconst clientProto = {\n  [TypeId]: TypeId,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst isClient = u => Predicate.hasProperty(u, TypeId);\n/** @internal */\nexport const make = (execute, preprocess) => {\n  function client(request) {\n    return execute(preprocess(request));\n  }\n  Object.setPrototypeOf(client, clientProto);\n  client.preprocess = preprocess;\n  client.execute = execute;\n  return client;\n};\n/** @internal */\nexport const makeDefault = f => make(effect => Effect.flatMap(effect, request => Effect.withFiberRuntime(fiber => {\n  const scope = Context.unsafeGet(fiber.getFiberRef(FiberRef.currentContext), Scope.Scope);\n  const controller = new AbortController();\n  const addAbort = Scope.addFinalizer(scope, Effect.sync(() => controller.abort()));\n  const urlResult = UrlParams.makeUrl(request.url, request.urlParams, request.hash);\n  if (urlResult._tag === \"Left\") {\n    return Effect.fail(new Error.RequestError({\n      request,\n      reason: \"InvalidUrl\",\n      cause: urlResult.left\n    }));\n  }\n  const url = urlResult.right;\n  const tracerDisabled = !fiber.getFiberRef(FiberRef.currentTracerEnabled) || fiber.getFiberRef(currentTracerDisabledWhen)(request);\n  if (tracerDisabled) {\n    return Effect.zipRight(addAbort, f(request, url, controller.signal, fiber));\n  }\n  return Effect.zipRight(addAbort, Effect.useSpan(`http.client ${request.method}`, {\n    kind: \"client\",\n    captureStackTrace: false\n  }, span => {\n    span.attribute(\"http.request.method\", request.method);\n    span.attribute(\"server.address\", url.origin);\n    if (url.port !== \"\") {\n      span.attribute(\"server.port\", +url.port);\n    }\n    span.attribute(\"url.full\", url.toString());\n    span.attribute(\"url.path\", url.pathname);\n    span.attribute(\"url.scheme\", url.protocol.slice(0, -1));\n    const query = url.search.slice(1);\n    if (query !== \"\") {\n      span.attribute(\"url.query\", query);\n    }\n    const redactedHeaderNames = fiber.getFiberRef(Headers.currentRedactedNames);\n    const redactedHeaders = Headers.redact(request.headers, redactedHeaderNames);\n    for (const name in redactedHeaders) {\n      span.attribute(`http.request.header.${name}`, String(redactedHeaders[name]));\n    }\n    request = fiber.getFiberRef(currentTracerPropagation) ? internalRequest.setHeaders(request, TraceContext.toHeaders(span)) : request;\n    return Effect.tap(Effect.withParentSpan(f(request, url, controller.signal, fiber), span), response => {\n      span.attribute(\"http.response.status_code\", response.status);\n      const redactedHeaders = Headers.redact(response.headers, redactedHeaderNames);\n      for (const name in redactedHeaders) {\n        span.attribute(`http.response.header.${name}`, String(redactedHeaders[name]));\n      }\n    });\n  }));\n})), Effect.succeed);\n/** @internal */\nexport const Fetch = /*#__PURE__*/Context.GenericTag(\"@effect/platform/HttpClient/Fetch\");\n/** @internal */\nexport const fetch = /*#__PURE__*/makeDefault((request, url, signal, fiber) => {\n  const context = fiber.getFiberRef(FiberRef.currentContext);\n  const fetch = context.unsafeMap.get(Fetch.key) ?? globalThis.fetch;\n  const options = fiber.getFiberRef(currentFetchOptions);\n  const headers = new globalThis.Headers(request.headers);\n  const send = body => Effect.map(Effect.tryPromise({\n    try: () => fetch(url, {\n      ...options,\n      method: request.method,\n      headers,\n      body,\n      duplex: request.body._tag === \"Stream\" ? \"half\" : undefined,\n      signal\n    }),\n    catch: cause => new Error.RequestError({\n      request,\n      reason: \"Transport\",\n      cause\n    })\n  }), response => internalResponse.fromWeb(request, response));\n  if (Method.hasBody(request.method)) {\n    switch (request.body._tag) {\n      case \"Raw\":\n      case \"Uint8Array\":\n        return send(request.body.body);\n      case \"FormData\":\n        return send(request.body.formData);\n      case \"Stream\":\n        return Effect.flatMap(Stream.toReadableStreamEffect(request.body.stream), send);\n    }\n  }\n  return send(undefined);\n});\n/** @internal */\nexport const transform = /*#__PURE__*/dual(2, (self, f) => make(Effect.flatMap(request => f(self.execute(Effect.succeed(request)), request)), self.preprocess));\n/** @internal */\nexport const filterStatus = /*#__PURE__*/dual(2, (self, f) => transform(self, (effect, request) => Effect.filterOrFail(effect, response => f(response.status), response => new Error.ResponseError({\n  request,\n  response,\n  reason: \"StatusCode\",\n  description: \"invalid status code\"\n}))));\n/** @internal */\nexport const filterStatusOk = self => transform(self, (effect, request) => Effect.filterOrFail(effect, response => response.status >= 200 && response.status < 300, response => new Error.ResponseError({\n  request,\n  response,\n  reason: \"StatusCode\",\n  description: \"non 2xx status code\"\n})));\n/** @internal */\nexport const fetchOk = /*#__PURE__*/filterStatusOk(fetch);\n/** @internal */\nexport const layer = /*#__PURE__*/Layer.succeed(tag, fetch);\n/** @internal */\nexport const transformResponse = /*#__PURE__*/dual(2, (self, f) => make(request => f(self.execute(request)), self.preprocess));\n/** @internal */\nexport const catchTag = /*#__PURE__*/dual(3, (self, tag, f) => transformResponse(self, Effect.catchTag(tag, f)));\n/** @internal */\nexport const catchTags = /*#__PURE__*/dual(2, (self, cases) => transformResponse(self, Effect.catchTags(cases)));\n/** @internal */\nexport const catchAll = /*#__PURE__*/dual(2, (self, f) => transformResponse(self, Effect.catchAll(f)));\n/** @internal */\nexport const filterOrElse = /*#__PURE__*/dual(3, (self, f, orElse) => transformResponse(self, Effect.filterOrElse(f, orElse)));\n/** @internal */\nexport const filterOrFail = /*#__PURE__*/dual(3, (self, f, orFailWith) => transformResponse(self, Effect.filterOrFail(f, orFailWith)));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => transformResponse(self, Effect.map(f)));\n/** @internal */\nexport const mapEffect = /*#__PURE__*/dual(2, (self, f) => transformResponse(self, Effect.flatMap(f)));\n/** @internal */\nexport const scoped = self => transformResponse(self, Effect.scoped);\n/** @internal */\nexport const mapEffectScoped = /*#__PURE__*/dual(2, (self, f) => scoped(mapEffect(self, f)));\n/** @internal */\nexport const mapRequest = /*#__PURE__*/dual(2, (self, f) => make(self.execute, request => Effect.map(self.preprocess(request), f)));\n/** @internal */\nexport const mapRequestEffect = /*#__PURE__*/dual(2, (self, f) => make(self.execute, request => Effect.flatMap(self.preprocess(request), f)));\n/** @internal */\nexport const mapInputRequest = /*#__PURE__*/dual(2, (self, f) => make(self.execute, request => self.preprocess(f(request))));\n/** @internal */\nexport const mapInputRequestEffect = /*#__PURE__*/dual(2, (self, f) => make(self.execute, request => Effect.flatMap(f(request), self.preprocess)));\n/** @internal */\nexport const retry = /*#__PURE__*/dual(2, (self, policy) => transformResponse(self, Effect.retry(policy)));\n/** @internal */\nexport const schemaFunction = /*#__PURE__*/dual(args => isClient(args[0]), (self, schema, options) => {\n  const encode = Schema.encode(schema, options);\n  return request => a => Effect.flatMap(Effect.tryMap(encode(a), {\n    try: body => new TextEncoder().encode(JSON.stringify(body)),\n    catch: cause => new Error.RequestError({\n      request,\n      reason: \"Encode\",\n      cause\n    })\n  }), body => self(internalRequest.setBody(request, internalBody.uint8Array(body, \"application/json\"))));\n});\n/** @internal */\nexport const tap = /*#__PURE__*/dual(2, (self, f) => transformResponse(self, Effect.tap(f)));\n/** @internal */\nexport const tapRequest = /*#__PURE__*/dual(2, (self, f) => make(self.execute, request => Effect.tap(self.preprocess(request), f)));\n/** @internal */\nexport const withCookiesRef = /*#__PURE__*/dual(2, (self, ref) => make(request => Effect.tap(self.execute(request), response => Ref.update(ref, cookies => Cookies.merge(cookies, response.cookies))), request => Effect.flatMap(self.preprocess(request), request => Effect.map(Ref.get(ref), cookies => Cookies.isEmpty(cookies) ? request : internalRequest.setHeader(request, \"cookie\", Cookies.toCookieHeader(cookies))))));\n/** @internal */\nexport const followRedirects = /*#__PURE__*/dual(args => isClient(args[0]), (self, maxRedirects) => make(request => {\n  const loop = (request, redirects) => Effect.flatMap(self.execute(Effect.succeed(request)), response => response.status >= 300 && response.status < 400 && response.headers.location && redirects < (maxRedirects ?? 10) ? loop(internalRequest.setUrl(request, response.headers.location), redirects + 1) : Effect.succeed(response));\n  return Effect.flatMap(request, request => loop(request, 0));\n}, self.preprocess));\n//# sourceMappingURL=httpClient.js.map","/** @internal */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/HttpClientError\");\n//# sourceMappingURL=httpClientError.js.map","import * as Context from \"effect/Context\";\nimport * as Effect from \"effect/Effect\";\nimport * as Effectable from \"effect/Effectable\";\nimport { dual } from \"effect/Function\";\nimport * as Inspectable from \"effect/Inspectable\";\nimport * as Option from \"effect/Option\";\nimport * as Headers from \"../Headers.js\";\nimport * as UrlParams from \"../UrlParams.js\";\nimport * as internalBody from \"./httpBody.js\";\n/** @internal */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/HttpClientRequest\");\n/** @internal */\nexport const clientTag = /*#__PURE__*/Context.GenericTag(\"@effect/platform/HttpClient\");\nconst Proto = {\n  [TypeId]: TypeId,\n  ...Effectable.CommitPrototype,\n  ...Inspectable.BaseProto,\n  commit() {\n    return Effect.flatMap(clientTag, client => client(this));\n  },\n  toJSON() {\n    return {\n      _id: \"@effect/platform/HttpClientRequest\",\n      method: this.method,\n      url: this.url,\n      urlParams: this.urlParams,\n      hash: this.hash,\n      headers: this.headers,\n      body: this.body.toJSON()\n    };\n  }\n};\nfunction makeInternal(method, url, urlParams, hash, headers, body) {\n  const self = Object.create(Proto);\n  self.method = method;\n  self.url = url;\n  self.urlParams = urlParams;\n  self.hash = hash;\n  self.headers = headers;\n  self.body = body;\n  return self;\n}\n/** @internal */\nexport const isClientRequest = u => typeof u === \"object\" && u !== null && TypeId in u;\n/** @internal */\nexport const empty = /*#__PURE__*/makeInternal(\"GET\", \"\", UrlParams.empty, /*#__PURE__*/Option.none(), Headers.empty, internalBody.empty);\n/** @internal */\nexport const make = method => (url, options) => modify(empty, {\n  method,\n  url,\n  ...(options ?? undefined)\n});\n/** @internal */\nexport const get = /*#__PURE__*/make(\"GET\");\n/** @internal */\nexport const post = /*#__PURE__*/make(\"POST\");\n/** @internal */\nexport const put = /*#__PURE__*/make(\"PUT\");\n/** @internal */\nexport const patch = /*#__PURE__*/make(\"PATCH\");\n/** @internal */\nexport const del = /*#__PURE__*/make(\"DELETE\");\n/** @internal */\nexport const head = /*#__PURE__*/make(\"HEAD\");\n/** @internal */\nexport const options = /*#__PURE__*/make(\"OPTIONS\");\n/** @internal */\nexport const modify = /*#__PURE__*/dual(2, (self, options) => {\n  let result = self;\n  if (options.method) {\n    result = setMethod(result, options.method);\n  }\n  if (options.url) {\n    result = setUrl(result, options.url);\n  }\n  if (options.headers) {\n    result = setHeaders(result, options.headers);\n  }\n  if (options.urlParams) {\n    result = setUrlParams(result, options.urlParams);\n  }\n  if (options.hash) {\n    result = setHash(result, options.hash);\n  }\n  if (options.body) {\n    result = setBody(result, options.body);\n  }\n  if (options.accept) {\n    result = accept(result, options.accept);\n  }\n  if (options.acceptJson) {\n    result = acceptJson(result);\n  }\n  return result;\n});\n/** @internal */\nexport const setHeader = /*#__PURE__*/dual(3, (self, key, value) => makeInternal(self.method, self.url, self.urlParams, self.hash, Headers.set(self.headers, key, value), self.body));\n/** @internal */\nexport const setHeaders = /*#__PURE__*/dual(2, (self, input) => makeInternal(self.method, self.url, self.urlParams, self.hash, Headers.setAll(self.headers, input), self.body));\n/** @internal */\nexport const basicAuth = /*#__PURE__*/dual(3, (self, username, password) => setHeader(self, \"Authorization\", `Basic ${btoa(`${username}:${password}`)}`));\n/** @internal */\nexport const bearerToken = /*#__PURE__*/dual(2, (self, token) => setHeader(self, \"Authorization\", `Bearer ${token}`));\n/** @internal */\nexport const accept = /*#__PURE__*/dual(2, (self, mediaType) => setHeader(self, \"Accept\", mediaType));\n/** @internal */\nexport const acceptJson = /*#__PURE__*/accept(\"application/json\");\n/** @internal */\nexport const setMethod = /*#__PURE__*/dual(2, (self, method) => makeInternal(method, self.url, self.urlParams, self.hash, self.headers, self.body));\n/** @internal */\nexport const setUrl = /*#__PURE__*/dual(2, (self, url) => {\n  if (typeof url === \"string\") {\n    return makeInternal(self.method, url, self.urlParams, self.hash, self.headers, self.body);\n  }\n  const clone = new URL(url.toString());\n  const urlParams = UrlParams.fromInput(clone.searchParams);\n  const hash = clone.hash ? Option.some(clone.hash.slice(1)) : Option.none();\n  clone.search = \"\";\n  clone.hash = \"\";\n  return makeInternal(self.method, clone.toString(), urlParams, hash, self.headers, self.body);\n});\n/** @internal */\nexport const appendUrl = /*#__PURE__*/dual(2, (self, url) => makeInternal(self.method, self.url.endsWith(\"/\") && url.startsWith(\"/\") ? self.url + url.slice(1) : self.url + url, self.urlParams, self.hash, self.headers, self.body));\n/** @internal */\nexport const prependUrl = /*#__PURE__*/dual(2, (self, url) => makeInternal(self.method, url.endsWith(\"/\") && self.url.startsWith(\"/\") ? url + self.url.slice(1) : url + self.url, self.urlParams, self.hash, self.headers, self.body));\n/** @internal */\nexport const updateUrl = /*#__PURE__*/dual(2, (self, f) => makeInternal(self.method, f(self.url), self.urlParams, self.hash, self.headers, self.body));\n/** @internal */\nexport const appendUrlParam = /*#__PURE__*/dual(3, (self, key, value) => makeInternal(self.method, self.url, UrlParams.append(self.urlParams, key, value), self.hash, self.headers, self.body));\n/** @internal */\nexport const appendUrlParams = /*#__PURE__*/dual(2, (self, input) => makeInternal(self.method, self.url, UrlParams.appendAll(self.urlParams, input), self.hash, self.headers, self.body));\n/** @internal */\nexport const setUrlParam = /*#__PURE__*/dual(3, (self, key, value) => makeInternal(self.method, self.url, UrlParams.set(self.urlParams, key, value), self.hash, self.headers, self.body));\n/** @internal */\nexport const setUrlParams = /*#__PURE__*/dual(2, (self, input) => makeInternal(self.method, self.url, UrlParams.setAll(self.urlParams, input), self.hash, self.headers, self.body));\n/** @internal */\nexport const setHash = /*#__PURE__*/dual(2, (self, hash) => makeInternal(self.method, self.url, self.urlParams, Option.some(hash), self.headers, self.body));\n/** @internal */\nexport const removeHash = self => makeInternal(self.method, self.url, self.urlParams, Option.none(), self.headers, self.body);\n/** @internal */\nexport const setBody = /*#__PURE__*/dual(2, (self, body) => {\n  let headers = self.headers;\n  if (body._tag === \"Empty\") {\n    headers = Headers.remove(Headers.remove(headers, \"Content-Type\"), \"Content-length\");\n  } else {\n    const contentType = body.contentType;\n    if (contentType) {\n      headers = Headers.set(headers, \"content-type\", contentType);\n    }\n    const contentLength = body.contentLength;\n    if (contentLength) {\n      headers = Headers.set(headers, \"content-length\", contentLength.toString());\n    }\n  }\n  return makeInternal(self.method, self.url, self.urlParams, self.hash, headers, body);\n});\n/** @internal */\nexport const uint8ArrayBody = /*#__PURE__*/dual(args => isClientRequest(args[0]), (self, body, contentType = \"application/octet-stream\") => setBody(self, internalBody.uint8Array(body, contentType)));\n/** @internal */\nexport const textBody = /*#__PURE__*/dual(args => isClientRequest(args[0]), (self, body, contentType = \"text/plain\") => setBody(self, internalBody.text(body, contentType)));\n/** @internal */\nexport const jsonBody = /*#__PURE__*/dual(2, (self, body) => Effect.map(internalBody.json(body), body => setBody(self, body)));\n/** @internal */\nexport const unsafeJsonBody = /*#__PURE__*/dual(2, (self, body) => setBody(self, internalBody.unsafeJson(body)));\n/** @internal */\nexport const fileBody = /*#__PURE__*/dual(args => isClientRequest(args[0]), (self, path, options) => Effect.map(internalBody.file(path, options), body => setBody(self, body)));\n/** @internal */\nexport const fileWebBody = /*#__PURE__*/dual(2, (self, file) => setBody(self, internalBody.fileWeb(file)));\n/** @internal */\nexport const schemaBody = (schema, options) => {\n  const encode = internalBody.jsonSchema(schema, options);\n  return dual(2, (self, body) => Effect.map(encode(body), body => setBody(self, body)));\n};\n/** @internal */\nexport const urlParamsBody = /*#__PURE__*/dual(2, (self, body) => setBody(self, internalBody.text(UrlParams.toString(UrlParams.fromInput(body)), \"application/x-www-form-urlencoded\")));\n/** @internal */\nexport const formDataBody = /*#__PURE__*/dual(2, (self, body) => setBody(self, internalBody.formData(body)));\n/** @internal */\nexport const streamBody = /*#__PURE__*/dual(args => isClientRequest(args[0]), (self, body, {\n  contentLength,\n  contentType = \"application/octet-stream\"\n} = {}) => setBody(self, internalBody.stream(body, contentType, contentLength)));\n//# sourceMappingURL=httpClientRequest.js.map","import * as Schema from \"@effect/schema/Schema\";\nimport * as Effect from \"effect/Effect\";\nimport { dual } from \"effect/Function\";\nimport * as Inspectable from \"effect/Inspectable\";\nimport * as Option from \"effect/Option\";\nimport * as Stream from \"effect/Stream\";\nimport * as Cookies from \"../Cookies.js\";\nimport * as Headers from \"../Headers.js\";\nimport * as Error from \"../HttpClientError.js\";\nimport * as IncomingMessage from \"../HttpIncomingMessage.js\";\nimport * as UrlParams from \"../UrlParams.js\";\n/** @internal */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/platform/HttpClientResponse\");\n/** @internal */\nexport const fromWeb = (request, source) => new ClientResponseImpl(request, source);\nclass ClientResponseImpl extends Inspectable.Class {\n  request;\n  source;\n  [IncomingMessage.TypeId];\n  [TypeId];\n  constructor(request, source) {\n    super();\n    this.request = request;\n    this.source = source;\n    this[IncomingMessage.TypeId] = IncomingMessage.TypeId;\n    this[TypeId] = TypeId;\n  }\n  toJSON() {\n    return IncomingMessage.inspect(this, {\n      _id: \"@effect/platform/HttpClientResponse\",\n      request: this.request.toJSON(),\n      status: this.status\n    });\n  }\n  get status() {\n    return this.source.status;\n  }\n  get headers() {\n    return Headers.fromInput(this.source.headers);\n  }\n  cachedCookies;\n  get cookies() {\n    if (this.cachedCookies) {\n      return this.cachedCookies;\n    }\n    return this.cachedCookies = Cookies.fromSetCookie(this.source.headers.getSetCookie());\n  }\n  get remoteAddress() {\n    return Option.none();\n  }\n  get stream() {\n    return this.source.body ? Stream.fromReadableStream(() => this.source.body, cause => new Error.ResponseError({\n      request: this.request,\n      response: this,\n      reason: \"Decode\",\n      cause\n    })) : Stream.fail(new Error.ResponseError({\n      request: this.request,\n      response: this,\n      reason: \"EmptyBody\",\n      description: \"can not create stream from empty body\"\n    }));\n  }\n  get json() {\n    return Effect.tryMap(this.text, {\n      try: text => text === \"\" ? null : JSON.parse(text),\n      catch: cause => new Error.ResponseError({\n        request: this.request,\n        response: this,\n        reason: \"Decode\",\n        cause\n      })\n    });\n  }\n  textBody;\n  get text() {\n    return this.textBody ??= Effect.tryPromise({\n      try: () => this.source.text(),\n      catch: cause => new Error.ResponseError({\n        request: this.request,\n        response: this,\n        reason: \"Decode\",\n        cause\n      })\n    }).pipe(Effect.cached, Effect.runSync);\n  }\n  get urlParamsBody() {\n    return Effect.flatMap(this.text, _ => Effect.try({\n      try: () => UrlParams.fromInput(new URLSearchParams(_)),\n      catch: cause => new Error.ResponseError({\n        request: this.request,\n        response: this,\n        reason: \"Decode\",\n        cause\n      })\n    }));\n  }\n  formDataBody;\n  get formData() {\n    return this.formDataBody ??= Effect.tryPromise({\n      try: () => this.source.formData(),\n      catch: cause => new Error.ResponseError({\n        request: this.request,\n        response: this,\n        reason: \"Decode\",\n        cause\n      })\n    }).pipe(Effect.cached, Effect.runSync);\n  }\n  arrayBufferBody;\n  get arrayBuffer() {\n    return this.arrayBufferBody ??= Effect.tryPromise({\n      try: () => this.source.arrayBuffer(),\n      catch: cause => new Error.ResponseError({\n        request: this.request,\n        response: this,\n        reason: \"Decode\",\n        cause\n      })\n    }).pipe(Effect.cached, Effect.runSync);\n  }\n}\n/** @internal */\nexport const schemaJson = (schema, options) => {\n  const parse = Schema.decodeUnknown(schema, options);\n  return self => Effect.flatMap(self.json, body => parse({\n    status: self.status,\n    headers: self.headers,\n    body\n  }));\n};\n/** @internal */\nexport const schemaNoBody = (schema, options) => {\n  const parse = Schema.decodeUnknown(schema, options);\n  return self => parse({\n    status: self.status,\n    headers: self.headers\n  });\n};\n/** @internal */\nexport const arrayBuffer = effect => Effect.scoped(Effect.flatMap(effect, _ => _.arrayBuffer));\n/** @internal */\nexport const text = effect => Effect.scoped(Effect.flatMap(effect, _ => _.text));\n/** @internal */\nexport const json = effect => Effect.scoped(Effect.flatMap(effect, _ => _.json));\n/** @internal */\nexport const urlParamsBody = effect => Effect.scoped(Effect.flatMap(effect, _ => _.urlParamsBody));\n/** @internal */\nexport const formData = effect => Effect.scoped(Effect.flatMap(effect, _ => _.formData));\n/** @internal */\nexport const void_ = effect => Effect.scoped(Effect.asVoid(effect));\n/** @internal */\nexport const stream = effect => Stream.unwrapScoped(Effect.map(effect, _ => _.stream));\n/** @internal */\nexport const schemaJsonScoped = (schema, options) => {\n  const decode = schemaJson(schema, options);\n  return effect => Effect.scoped(Effect.flatMap(effect, decode));\n};\n/** @internal */\nexport const schemaNoBodyScoped = (schema, options) => {\n  const decode = schemaNoBody(schema, options);\n  return effect => Effect.scoped(Effect.flatMap(effect, decode));\n};\n/** @internal */\nexport const matchStatus = /*#__PURE__*/dual(2, (self, cases) => {\n  const status = self.status;\n  if (cases[status]) {\n    return cases[status](self);\n  } else if (status >= 200 && status < 300 && cases[\"2xx\"]) {\n    return cases[\"2xx\"](self);\n  } else if (status >= 300 && status < 400 && cases[\"3xx\"]) {\n    return cases[\"3xx\"](self);\n  } else if (status >= 400 && status < 500 && cases[\"4xx\"]) {\n    return cases[\"4xx\"](self);\n  } else if (status >= 500 && status < 600 && cases[\"5xx\"]) {\n    return cases[\"5xx\"](self);\n  }\n  return cases.orElse(self);\n});\n/** @internal */\nexport const matchStatusScoped = /*#__PURE__*/dual(2, (self, cases) => Effect.scoped(Effect.flatMap(self, matchStatus(cases))));\n//# sourceMappingURL=httpClientResponse.js.map","/**\n * @since 0.67.0\n */\nimport * as Arr from \"effect/Array\";\nimport { dual, identity } from \"effect/Function\";\nimport { globalValue } from \"effect/GlobalValue\";\nimport * as Number from \"effect/Number\";\nimport * as Option from \"effect/Option\";\nimport * as Order from \"effect/Order\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as regexp from \"effect/RegExp\";\nimport * as errors_ from \"./internal/errors.js\";\nimport * as util_ from \"./internal/util.js\";\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const BrandAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Brand\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const TypeAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Type\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const MessageAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Message\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const MissingMessageAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/MissingMessage\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const IdentifierAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Identifier\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const TitleAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Title\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const DescriptionAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Description\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const ExamplesAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Examples\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const DefaultAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Default\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const JSONSchemaAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/JSONSchema\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const DocumentationAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Documentation\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const ConcurrencyAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Concurrency\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const BatchingAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Batching\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const ParseIssueTitleAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/ParseIssueTitle\");\n/**\n * @category annotations\n * @since 0.68.3\n */\nexport const ParseOptionsAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/ParseOptions\");\n/** @internal */\nexport const SurrogateAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/Surrogate\");\n/** @internal */\nexport const StableFilterAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/StableFilter\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getAnnotation = /*#__PURE__*/dual(2, (annotated, key) => Object.prototype.hasOwnProperty.call(annotated.annotations, key) ? Option.some(annotated.annotations[key]) : Option.none());\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getBrandAnnotation = /*#__PURE__*/getAnnotation(BrandAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getMessageAnnotation = /*#__PURE__*/getAnnotation(MessageAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getMissingMessageAnnotation = /*#__PURE__*/getAnnotation(MissingMessageAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getTitleAnnotation = /*#__PURE__*/getAnnotation(TitleAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getIdentifierAnnotation = /*#__PURE__*/getAnnotation(IdentifierAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getDescriptionAnnotation = /*#__PURE__*/getAnnotation(DescriptionAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getExamplesAnnotation = /*#__PURE__*/getAnnotation(ExamplesAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getDefaultAnnotation = /*#__PURE__*/getAnnotation(DefaultAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getJSONSchemaAnnotation = /*#__PURE__*/getAnnotation(JSONSchemaAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getDocumentationAnnotation = /*#__PURE__*/getAnnotation(DocumentationAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getConcurrencyAnnotation = /*#__PURE__*/getAnnotation(ConcurrencyAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getBatchingAnnotation = /*#__PURE__*/getAnnotation(BatchingAnnotationId);\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const getParseIssueTitleAnnotation = /*#__PURE__*/getAnnotation(ParseIssueTitleAnnotationId);\n/**\n * @category annotations\n * @since 0.68.3\n */\nexport const getParseOptionsAnnotation = /*#__PURE__*/getAnnotation(ParseOptionsAnnotationId);\n/** @internal */\nexport const getSurrogateAnnotation = /*#__PURE__*/getAnnotation(SurrogateAnnotationId);\nconst getStableFilterAnnotation = /*#__PURE__*/getAnnotation(StableFilterAnnotationId);\nconst JSONIdentifierAnnotationId = /*#__PURE__*/Symbol.for(\"@effect/schema/annotation/JSONIdentifier\");\n/** @internal */\nexport const getJSONIdentifierAnnotation = /*#__PURE__*/getAnnotation(JSONIdentifierAnnotationId);\n/**\n * @category model\n * @since 0.67.0\n */\nexport class Declaration {\n  typeParameters;\n  decodeUnknown;\n  encodeUnknown;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Declaration\";\n  constructor(typeParameters, decodeUnknown, encodeUnknown, annotations = {}) {\n    this.typeParameters = typeParameters;\n    this.decodeUnknown = decodeUnknown;\n    this.encodeUnknown = encodeUnknown;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => \"<declaration schema>\");\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      typeParameters: this.typeParameters.map(ast => ast.toJSON()),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\nconst createASTGuard = tag => ast => ast._tag === tag;\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isDeclaration = /*#__PURE__*/createASTGuard(\"Declaration\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class Literal {\n  literal;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Literal\";\n  constructor(literal, annotations = {}) {\n    this.literal = literal;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => util_.formatUnknown(this.literal));\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      literal: Predicate.isBigInt(this.literal) ? String(this.literal) : this.literal,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isLiteral = /*#__PURE__*/createASTGuard(\"Literal\");\nconst $null = /*#__PURE__*/new Literal(null, {\n  [IdentifierAnnotationId]: \"null\"\n});\nexport {\n/**\n * @category constructors\n * @since 0.67.0\n */\n$null as null };\n/**\n * @category model\n * @since 0.67.0\n */\nexport class UniqueSymbol {\n  symbol;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"UniqueSymbol\";\n  constructor(symbol, annotations = {}) {\n    this.symbol = symbol;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => util_.formatUnknown(this.symbol));\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      symbol: String(this.symbol),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isUniqueSymbol = /*#__PURE__*/createASTGuard(\"UniqueSymbol\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class UndefinedKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"UndefinedKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const undefinedKeyword = /*#__PURE__*/new UndefinedKeyword({\n  [TitleAnnotationId]: \"undefined\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isUndefinedKeyword = /*#__PURE__*/createASTGuard(\"UndefinedKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class VoidKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"VoidKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const voidKeyword = /*#__PURE__*/new VoidKeyword({\n  [TitleAnnotationId]: \"void\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isVoidKeyword = /*#__PURE__*/createASTGuard(\"VoidKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class NeverKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"NeverKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const neverKeyword = /*#__PURE__*/new NeverKeyword({\n  [TitleAnnotationId]: \"never\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isNeverKeyword = /*#__PURE__*/createASTGuard(\"NeverKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class UnknownKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"UnknownKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const unknownKeyword = /*#__PURE__*/new UnknownKeyword({\n  [TitleAnnotationId]: \"unknown\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isUnknownKeyword = /*#__PURE__*/createASTGuard(\"UnknownKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class AnyKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"AnyKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const anyKeyword = /*#__PURE__*/new AnyKeyword({\n  [TitleAnnotationId]: \"any\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isAnyKeyword = /*#__PURE__*/createASTGuard(\"AnyKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class StringKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"StringKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const stringKeyword = /*#__PURE__*/new StringKeyword({\n  [TitleAnnotationId]: \"string\",\n  [DescriptionAnnotationId]: \"a string\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isStringKeyword = /*#__PURE__*/createASTGuard(\"StringKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class NumberKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"NumberKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const numberKeyword = /*#__PURE__*/new NumberKeyword({\n  [TitleAnnotationId]: \"number\",\n  [DescriptionAnnotationId]: \"a number\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isNumberKeyword = /*#__PURE__*/createASTGuard(\"NumberKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class BooleanKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"BooleanKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const booleanKeyword = /*#__PURE__*/new BooleanKeyword({\n  [TitleAnnotationId]: \"boolean\",\n  [DescriptionAnnotationId]: \"a boolean\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isBooleanKeyword = /*#__PURE__*/createASTGuard(\"BooleanKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class BigIntKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"BigIntKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const bigIntKeyword = /*#__PURE__*/new BigIntKeyword({\n  [TitleAnnotationId]: \"bigint\",\n  [DescriptionAnnotationId]: \"a bigint\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isBigIntKeyword = /*#__PURE__*/createASTGuard(\"BigIntKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class SymbolKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"SymbolKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const symbolKeyword = /*#__PURE__*/new SymbolKeyword({\n  [TitleAnnotationId]: \"symbol\",\n  [DescriptionAnnotationId]: \"a symbol\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isSymbolKeyword = /*#__PURE__*/createASTGuard(\"SymbolKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class ObjectKeyword {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"ObjectKeyword\";\n  constructor(annotations = {}) {\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return formatKeyword(this);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const objectKeyword = /*#__PURE__*/new ObjectKeyword({\n  [IdentifierAnnotationId]: \"object\",\n  [TitleAnnotationId]: \"object\",\n  [DescriptionAnnotationId]: \"an object in the TypeScript meaning, i.e. the `object` type\"\n});\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isObjectKeyword = /*#__PURE__*/createASTGuard(\"ObjectKeyword\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class Enums {\n  enums;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Enums\";\n  constructor(enums, annotations = {}) {\n    this.enums = enums;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => `<enum ${this.enums.length} value(s): ${this.enums.map((_, value) => JSON.stringify(value)).join(\" | \")}>`);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      enums: this.enums,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isEnums = /*#__PURE__*/createASTGuard(\"Enums\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class TemplateLiteralSpan {\n  type;\n  literal;\n  constructor(type, literal) {\n    this.type = type;\n    this.literal = literal;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    switch (this.type._tag) {\n      case \"StringKeyword\":\n        return \"${string}\";\n      case \"NumberKeyword\":\n        return \"${number}\";\n    }\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      type: this.type.toJSON(),\n      literal: this.literal\n    };\n  }\n}\n/**\n * @category model\n * @since 0.67.0\n */\nexport class TemplateLiteral {\n  head;\n  spans;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"TemplateLiteral\";\n  constructor(head, spans, annotations = {}) {\n    this.head = head;\n    this.spans = spans;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => formatTemplateLiteral(this));\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      head: this.head,\n      spans: this.spans.map(span => span.toJSON()),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\nconst formatTemplateLiteral = ast => \"`\" + ast.head + ast.spans.map(span => String(span) + span.literal).join(\"\") + \"`\";\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isTemplateLiteral = /*#__PURE__*/createASTGuard(\"TemplateLiteral\");\n/**\n * @category model\n * @since 0.68.0\n */\nexport class Type {\n  type;\n  annotations;\n  constructor(type, annotations = {}) {\n    this.type = type;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.68.0\n   */\n  toJSON() {\n    return {\n      type: this.type.toJSON(),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n  /**\n   * @since 0.68.0\n   */\n  toString() {\n    return String(this.type);\n  }\n}\n/**\n * @category model\n * @since 0.68.0\n */\nexport class OptionalType extends Type {\n  isOptional;\n  constructor(type, isOptional, annotations = {}) {\n    super(type, annotations);\n    this.isOptional = isOptional;\n  }\n  /**\n   * @since 0.68.0\n   */\n  toJSON() {\n    return {\n      type: this.type.toJSON(),\n      isOptional: this.isOptional,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n  /**\n   * @since 0.68.0\n   */\n  toString() {\n    return String(this.type) + (this.isOptional ? \"?\" : \"\");\n  }\n}\nconst getRestASTs = rest => rest.map(annotatedAST => annotatedAST.type);\n/**\n * @category model\n * @since 0.67.0\n */\nexport class TupleType {\n  elements;\n  rest;\n  isReadonly;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"TupleType\";\n  constructor(elements, rest, isReadonly, annotations = {}) {\n    this.elements = elements;\n    this.rest = rest;\n    this.isReadonly = isReadonly;\n    this.annotations = annotations;\n    let hasOptionalElement = false;\n    let hasIllegalRequiredElement = false;\n    for (const e of elements) {\n      if (e.isOptional) {\n        hasOptionalElement = true;\n      } else if (hasOptionalElement) {\n        hasIllegalRequiredElement = true;\n        break;\n      }\n    }\n    if (hasIllegalRequiredElement || hasOptionalElement && rest.length > 1) {\n      throw new Error(errors_.getASTRequiredElementFollowinAnOptionalElementErrorMessage);\n    }\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => formatTuple(this));\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      elements: this.elements.map(e => e.toJSON()),\n      rest: this.rest.map(ast => ast.toJSON()),\n      isReadonly: this.isReadonly,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\nconst formatTuple = ast => {\n  const formattedElements = ast.elements.map(String).join(\", \");\n  return Arr.matchLeft(ast.rest, {\n    onEmpty: () => `readonly [${formattedElements}]`,\n    onNonEmpty: (head, tail) => {\n      const formattedHead = String(head);\n      const wrappedHead = formattedHead.includes(\" | \") ? `(${formattedHead})` : formattedHead;\n      if (tail.length > 0) {\n        const formattedTail = tail.map(String).join(\", \");\n        if (ast.elements.length > 0) {\n          return `readonly [${formattedElements}, ...${wrappedHead}[], ${formattedTail}]`;\n        } else {\n          return `readonly [...${wrappedHead}[], ${formattedTail}]`;\n        }\n      } else {\n        if (ast.elements.length > 0) {\n          return `readonly [${formattedElements}, ...${wrappedHead}[]]`;\n        } else {\n          return `ReadonlyArray<${formattedHead}>`;\n        }\n      }\n    }\n  });\n};\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isTupleType = /*#__PURE__*/createASTGuard(\"TupleType\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class PropertySignature extends OptionalType {\n  name;\n  isReadonly;\n  constructor(name, type, isOptional, isReadonly, annotations) {\n    super(type, isOptional, annotations);\n    this.name = name;\n    this.isReadonly = isReadonly;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      name: String(this.name),\n      type: this.type.toJSON(),\n      isOptional: this.isOptional,\n      isReadonly: this.isReadonly,\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @since 0.67.0\n */\nexport const isParameter = ast => {\n  switch (ast._tag) {\n    case \"StringKeyword\":\n    case \"SymbolKeyword\":\n    case \"TemplateLiteral\":\n      return true;\n    case \"Refinement\":\n      return isParameter(ast.from);\n  }\n  return false;\n};\n/**\n * @category model\n * @since 0.67.0\n */\nexport class IndexSignature {\n  type;\n  isReadonly;\n  /**\n   * @since 0.67.0\n   */\n  parameter;\n  constructor(parameter, type, isReadonly) {\n    this.type = type;\n    this.isReadonly = isReadonly;\n    if (isParameter(parameter)) {\n      this.parameter = parameter;\n    } else {\n      throw new Error(errors_.getASTIndexSignatureParameterErrorMessage);\n    }\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      parameter: this.parameter.toJSON(),\n      type: this.type.toJSON(),\n      isReadonly: this.isReadonly\n    };\n  }\n}\n/**\n * @category model\n * @since 0.67.0\n */\nexport class TypeLiteral {\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"TypeLiteral\";\n  /**\n   * @since 0.67.0\n   */\n  propertySignatures;\n  /**\n   * @since 0.67.0\n   */\n  indexSignatures;\n  constructor(propertySignatures, indexSignatures, annotations = {}) {\n    this.annotations = annotations;\n    // check for duplicate property signatures\n    const keys = {};\n    for (let i = 0; i < propertySignatures.length; i++) {\n      const name = propertySignatures[i].name;\n      if (Object.prototype.hasOwnProperty.call(keys, name)) {\n        throw new Error(errors_.getASTDuplicatePropertySignatureErrorMessage(name));\n      }\n      keys[name] = null;\n    }\n    // check for duplicate index signatures\n    const parameters = {\n      string: false,\n      symbol: false\n    };\n    for (let i = 0; i < indexSignatures.length; i++) {\n      const parameter = getParameterBase(indexSignatures[i].parameter);\n      if (isStringKeyword(parameter)) {\n        if (parameters.string) {\n          throw new Error(errors_.getASTDuplicateIndexSignatureErrorMessage(\"string\"));\n        }\n        parameters.string = true;\n      } else if (isSymbolKeyword(parameter)) {\n        if (parameters.symbol) {\n          throw new Error(errors_.getASTDuplicateIndexSignatureErrorMessage(\"symbol\"));\n        }\n        parameters.symbol = true;\n      }\n    }\n    this.propertySignatures = sortPropertySignatures(propertySignatures);\n    this.indexSignatures = sortIndexSignatures(indexSignatures);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => formatTypeLiteral(this));\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      propertySignatures: this.propertySignatures.map(ps => ps.toJSON()),\n      indexSignatures: this.indexSignatures.map(ps => ps.toJSON()),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\nconst formatTypeLiteral = ast => {\n  const formattedPropertySignatures = ast.propertySignatures.map(ps => (ps.isReadonly ? \"readonly \" : \"\") + String(ps.name) + (ps.isOptional ? \"?\" : \"\") + \": \" + ps.type).join(\"; \");\n  if (ast.indexSignatures.length > 0) {\n    const formattedIndexSignatures = ast.indexSignatures.map(is => (is.isReadonly ? \"readonly \" : \"\") + `[x: ${getParameterBase(is.parameter)}]: ${is.type}`).join(\"; \");\n    if (ast.propertySignatures.length > 0) {\n      return `{ ${formattedPropertySignatures}; ${formattedIndexSignatures} }`;\n    } else {\n      return `{ ${formattedIndexSignatures} }`;\n    }\n  } else {\n    if (ast.propertySignatures.length > 0) {\n      return `{ ${formattedPropertySignatures} }`;\n    } else {\n      return \"{}\";\n    }\n  }\n};\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isTypeLiteral = /*#__PURE__*/createASTGuard(\"TypeLiteral\");\nconst removeNevers = candidates => candidates.filter(ast => !(ast === neverKeyword));\nconst sortCandidates = /*#__PURE__*/Arr.sort( /*#__PURE__*/Order.mapInput(Number.Order, ast => {\n  switch (ast._tag) {\n    case \"AnyKeyword\":\n      return 0;\n    case \"UnknownKeyword\":\n      return 1;\n    case \"ObjectKeyword\":\n      return 2;\n    case \"StringKeyword\":\n    case \"NumberKeyword\":\n    case \"BooleanKeyword\":\n    case \"BigIntKeyword\":\n    case \"SymbolKeyword\":\n      return 3;\n  }\n  return 4;\n}));\nconst literalMap = {\n  string: \"StringKeyword\",\n  number: \"NumberKeyword\",\n  boolean: \"BooleanKeyword\",\n  bigint: \"BigIntKeyword\"\n};\n/** @internal */\nexport const flatten = candidates => Arr.flatMap(candidates, ast => isUnion(ast) ? flatten(ast.types) : [ast]);\n/** @internal */\nexport const unify = candidates => {\n  const cs = sortCandidates(candidates);\n  const out = [];\n  const uniques = {};\n  const literals = [];\n  for (const ast of cs) {\n    switch (ast._tag) {\n      case \"NeverKeyword\":\n        break;\n      case \"AnyKeyword\":\n        return [anyKeyword];\n      case \"UnknownKeyword\":\n        return [unknownKeyword];\n      // uniques\n      case \"ObjectKeyword\":\n      case \"UndefinedKeyword\":\n      case \"VoidKeyword\":\n      case \"StringKeyword\":\n      case \"NumberKeyword\":\n      case \"BooleanKeyword\":\n      case \"BigIntKeyword\":\n      case \"SymbolKeyword\":\n        {\n          if (!uniques[ast._tag]) {\n            uniques[ast._tag] = ast;\n            out.push(ast);\n          }\n          break;\n        }\n      case \"Literal\":\n        {\n          const type = typeof ast.literal;\n          switch (type) {\n            case \"string\":\n            case \"number\":\n            case \"bigint\":\n            case \"boolean\":\n              {\n                const _tag = literalMap[type];\n                if (!uniques[_tag] && !literals.includes(ast.literal)) {\n                  literals.push(ast.literal);\n                  out.push(ast);\n                }\n                break;\n              }\n            // null\n            case \"object\":\n              {\n                if (!literals.includes(ast.literal)) {\n                  literals.push(ast.literal);\n                  out.push(ast);\n                }\n                break;\n              }\n          }\n          break;\n        }\n      case \"UniqueSymbol\":\n        {\n          if (!uniques[\"SymbolKeyword\"] && !literals.includes(ast.symbol)) {\n            literals.push(ast.symbol);\n            out.push(ast);\n          }\n          break;\n        }\n      case \"TupleType\":\n        {\n          if (!uniques[\"ObjectKeyword\"]) {\n            out.push(ast);\n          }\n          break;\n        }\n      case \"TypeLiteral\":\n        {\n          if (ast.propertySignatures.length === 0 && ast.indexSignatures.length === 0) {\n            if (!uniques[\"{}\"]) {\n              uniques[\"{}\"] = ast;\n              out.push(ast);\n            }\n          } else if (!uniques[\"ObjectKeyword\"]) {\n            out.push(ast);\n          }\n          break;\n        }\n      default:\n        out.push(ast);\n    }\n  }\n  return out;\n};\n/**\n * @category model\n * @since 0.67.0\n */\nexport class Union {\n  types;\n  annotations;\n  static make = (candidates, annotations) => {\n    const types = [];\n    const memo = new Set();\n    for (let i = 0; i < candidates.length; i++) {\n      const ast = candidates[i];\n      if (ast === neverKeyword || memo.has(ast)) {\n        continue;\n      }\n      memo.add(ast);\n      types.push(ast);\n    }\n    return Union.union(types, annotations);\n  };\n  /** @internal */\n  static members = (candidates, annotations) => {\n    return Union.union(removeNevers(candidates), annotations);\n  };\n  /** @internal */\n  static unify = (candidates, annotations) => {\n    return Union.union(unify(flatten(candidates)), annotations);\n  };\n  /** @internal */\n  static union = (types, annotations) => {\n    return isMembers(types) ? new Union(types, annotations) : types.length === 1 ? types[0] : neverKeyword;\n  };\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Union\";\n  constructor(types, annotations = {}) {\n    this.types = types;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => this.types.map(String).join(\" | \"));\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      types: this.types.map(ast => ast.toJSON()),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/** @internal */\nexport const mapMembers = (members, f) => members.map(f);\n/** @internal */\nexport const isMembers = as => as.length > 1;\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isUnion = /*#__PURE__*/createASTGuard(\"Union\");\nconst toJSONMemoMap = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"@effect/schema/AST/toJSONMemoMap\"), () => new WeakMap());\n/**\n * @category model\n * @since 0.67.0\n */\nexport class Suspend {\n  f;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Suspend\";\n  constructor(f, annotations = {}) {\n    this.f = f;\n    this.annotations = annotations;\n    this.f = util_.memoizeThunk(f);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return getExpected(this).pipe(Option.orElse(() => Option.flatMap(Option.liftThrowable(this.f)(), ast => getExpected(ast))), Option.getOrElse(() => \"<suspended schema>\"));\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    const ast = this.f();\n    let out = toJSONMemoMap.get(ast);\n    if (out) {\n      return out;\n    }\n    toJSONMemoMap.set(ast, {\n      _tag: this._tag\n    });\n    out = {\n      _tag: this._tag,\n      ast: ast.toJSON(),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n    toJSONMemoMap.set(ast, out);\n    return out;\n  }\n}\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isSuspend = /*#__PURE__*/createASTGuard(\"Suspend\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class Refinement {\n  from;\n  filter;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Refinement\";\n  constructor(from, filter, annotations = {}) {\n    this.from = from;\n    this.filter = filter;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => `{ ${this.from} | filter }`);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      from: this.from.toJSON(),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isRefinement = /*#__PURE__*/createASTGuard(\"Refinement\");\n/**\n * @since 0.67.0\n */\nexport const defaultParseOption = {};\n/**\n * @category model\n * @since 0.67.0\n */\nexport class Transformation {\n  from;\n  to;\n  transformation;\n  annotations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Transformation\";\n  constructor(from, to, transformation, annotations = {}) {\n    this.from = from;\n    this.to = to;\n    this.transformation = transformation;\n    this.annotations = annotations;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return Option.getOrElse(getExpected(this), () => `(${String(this.from)} <-> ${String(this.to)})`);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _tag: this._tag,\n      from: this.from.toJSON(),\n      to: this.to.toJSON(),\n      annotations: toJSONAnnotations(this.annotations)\n    };\n  }\n}\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isTransformation = /*#__PURE__*/createASTGuard(\"Transformation\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class FinalTransformation {\n  decode;\n  encode;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"FinalTransformation\";\n  constructor(decode, encode) {\n    this.decode = decode;\n    this.encode = encode;\n  }\n}\nconst createTransformationGuard = tag => ast => ast._tag === tag;\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isFinalTransformation = /*#__PURE__*/createTransformationGuard(\"FinalTransformation\");\n/**\n * @category model\n * @since 0.67.0\n */\nexport class ComposeTransformation {\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"ComposeTransformation\";\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const composeTransformation = /*#__PURE__*/new ComposeTransformation();\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isComposeTransformation = /*#__PURE__*/createTransformationGuard(\"ComposeTransformation\");\n/**\n * Represents a `PropertySignature -> PropertySignature` transformation\n *\n * The semantic of `decode` is:\n * - `none()` represents the absence of the key/value pair\n * - `some(value)` represents the presence of the key/value pair\n *\n * The semantic of `encode` is:\n * - `none()` you don't want to output the key/value pair\n * - `some(value)` you want to output the key/value pair\n *\n * @category model\n * @since 0.67.0\n */\nexport class PropertySignatureTransformation {\n  from;\n  to;\n  decode;\n  encode;\n  constructor(from, to, decode, encode) {\n    this.from = from;\n    this.to = to;\n    this.decode = decode;\n    this.encode = encode;\n  }\n}\nconst isRenamingPropertySignatureTransformation = t => t.decode === identity && t.encode === identity;\n/**\n * @category model\n * @since 0.67.0\n */\nexport class TypeLiteralTransformation {\n  propertySignatureTransformations;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"TypeLiteralTransformation\";\n  constructor(propertySignatureTransformations) {\n    this.propertySignatureTransformations = propertySignatureTransformations;\n    // check for duplicate property signature transformations\n    const fromKeys = {};\n    const toKeys = {};\n    for (const pst of propertySignatureTransformations) {\n      const from = pst.from;\n      if (fromKeys[from]) {\n        throw new Error(errors_.getASTDuplicatePropertySignatureTransformationErrorMessage(from));\n      }\n      fromKeys[from] = true;\n      const to = pst.to;\n      if (toKeys[to]) {\n        throw new Error(errors_.getASTDuplicatePropertySignatureTransformationErrorMessage(to));\n      }\n      toKeys[to] = true;\n    }\n  }\n}\n/**\n * @category guards\n * @since 0.67.0\n */\nexport const isTypeLiteralTransformation = /*#__PURE__*/createTransformationGuard(\"TypeLiteralTransformation\");\n// -------------------------------------------------------------------------------------\n// API\n// -------------------------------------------------------------------------------------\n/**\n * Adds a group of annotations, potentially overwriting existing annotations.\n *\n * @since 0.67.0\n */\nexport const annotations = (ast, annotations) => {\n  const d = Object.getOwnPropertyDescriptors(ast);\n  d.annotations.value = {\n    ...ast.annotations,\n    ...annotations\n  };\n  return Object.create(Object.getPrototypeOf(ast), d);\n};\n/**\n * Equivalent at runtime to the TypeScript type-level `keyof` operator.\n *\n * @since 0.67.0\n */\nexport const keyof = ast => Union.unify(_keyof(ast));\nconst STRING_KEYWORD_PATTERN = \".*\";\nconst NUMBER_KEYWORD_PATTERN = \"[+-]?\\\\d*\\\\.?\\\\d+(?:[Ee][+-]?\\\\d+)?\";\n/**\n * @since 0.67.0\n */\nexport const getTemplateLiteralRegExp = ast => {\n  let pattern = `^${regexp.escape(ast.head)}`;\n  for (const span of ast.spans) {\n    if (isStringKeyword(span.type)) {\n      pattern += STRING_KEYWORD_PATTERN;\n    } else if (isNumberKeyword(span.type)) {\n      pattern += NUMBER_KEYWORD_PATTERN;\n    }\n    pattern += regexp.escape(span.literal);\n  }\n  pattern += \"$\";\n  return new RegExp(pattern);\n};\n/**\n * @since 0.67.0\n */\nexport const getPropertySignatures = ast => {\n  switch (ast._tag) {\n    case \"Declaration\":\n      {\n        const annotation = getSurrogateAnnotation(ast);\n        if (Option.isSome(annotation)) {\n          return getPropertySignatures(annotation.value);\n        }\n        break;\n      }\n    case \"TypeLiteral\":\n      return ast.propertySignatures.slice();\n    case \"Suspend\":\n      return getPropertySignatures(ast.f());\n  }\n  return getPropertyKeys(ast).map(name => getPropertyKeyIndexedAccess(ast, name));\n};\n/** @internal */\nexport const getNumberIndexedAccess = ast => {\n  switch (ast._tag) {\n    case \"TupleType\":\n      {\n        let hasOptional = false;\n        let out = [];\n        for (const e of ast.elements) {\n          if (e.isOptional) {\n            hasOptional = true;\n          }\n          out.push(e.type);\n        }\n        if (hasOptional) {\n          out.push(undefinedKeyword);\n        }\n        out = out.concat(getRestASTs(ast.rest));\n        return Union.make(out);\n      }\n    case \"Refinement\":\n      return getNumberIndexedAccess(ast.from);\n    case \"Union\":\n      return Union.make(ast.types.map(getNumberIndexedAccess));\n    case \"Suspend\":\n      return getNumberIndexedAccess(ast.f());\n  }\n  throw new Error(errors_.getASTUnsupportedSchema(ast));\n};\n/** @internal */\nexport const getPropertyKeyIndexedAccess = (ast, name) => {\n  switch (ast._tag) {\n    case \"Declaration\":\n      {\n        const annotation = getSurrogateAnnotation(ast);\n        if (Option.isSome(annotation)) {\n          return getPropertyKeyIndexedAccess(annotation.value, name);\n        }\n        break;\n      }\n    case \"TypeLiteral\":\n      {\n        const ops = Arr.findFirst(ast.propertySignatures, ps => ps.name === name);\n        if (Option.isSome(ops)) {\n          return ops.value;\n        } else {\n          if (Predicate.isString(name)) {\n            for (const is of ast.indexSignatures) {\n              const parameterBase = getParameterBase(is.parameter);\n              switch (parameterBase._tag) {\n                case \"TemplateLiteral\":\n                  {\n                    const regex = getTemplateLiteralRegExp(parameterBase);\n                    if (regex.test(name)) {\n                      return new PropertySignature(name, is.type, false, true);\n                    }\n                    break;\n                  }\n                case \"StringKeyword\":\n                  return new PropertySignature(name, is.type, false, true);\n              }\n            }\n          } else if (Predicate.isSymbol(name)) {\n            for (const is of ast.indexSignatures) {\n              const parameterBase = getParameterBase(is.parameter);\n              if (isSymbolKeyword(parameterBase)) {\n                return new PropertySignature(name, is.type, false, true);\n              }\n            }\n          }\n        }\n        break;\n      }\n    case \"Union\":\n      return new PropertySignature(name, Union.make(ast.types.map(ast => getPropertyKeyIndexedAccess(ast, name).type)), false, true);\n    case \"Suspend\":\n      return getPropertyKeyIndexedAccess(ast.f(), name);\n  }\n  return new PropertySignature(name, neverKeyword, false, true);\n};\nconst getPropertyKeys = ast => {\n  switch (ast._tag) {\n    case \"Declaration\":\n      {\n        const annotation = getSurrogateAnnotation(ast);\n        if (Option.isSome(annotation)) {\n          return getPropertyKeys(annotation.value);\n        }\n        break;\n      }\n    case \"TypeLiteral\":\n      return ast.propertySignatures.map(ps => ps.name);\n    case \"Suspend\":\n      return getPropertyKeys(ast.f());\n    case \"Union\":\n      return ast.types.slice(1).reduce((out, ast) => Arr.intersection(out, getPropertyKeys(ast)), getPropertyKeys(ast.types[0]));\n    case \"Transformation\":\n      return getPropertyKeys(ast.to);\n  }\n  return [];\n};\n/** @internal */\nexport const record = (key, value) => {\n  const propertySignatures = [];\n  const indexSignatures = [];\n  const go = key => {\n    switch (key._tag) {\n      case \"NeverKeyword\":\n        break;\n      case \"StringKeyword\":\n      case \"SymbolKeyword\":\n      case \"TemplateLiteral\":\n      case \"Refinement\":\n        indexSignatures.push(new IndexSignature(key, value, true));\n        break;\n      case \"Literal\":\n        if (Predicate.isString(key.literal) || Predicate.isNumber(key.literal)) {\n          propertySignatures.push(new PropertySignature(key.literal, value, false, true));\n        } else {\n          throw new Error(errors_.getASTUnsupportedLiteral(key.literal));\n        }\n        break;\n      case \"Enums\":\n        {\n          for (const [_, name] of key.enums) {\n            propertySignatures.push(new PropertySignature(name, value, false, true));\n          }\n          break;\n        }\n      case \"UniqueSymbol\":\n        propertySignatures.push(new PropertySignature(key.symbol, value, false, true));\n        break;\n      case \"Union\":\n        key.types.forEach(go);\n        break;\n      default:\n        throw new Error(errors_.getASTUnsupportedKeySchema(key));\n    }\n  };\n  go(key);\n  return {\n    propertySignatures,\n    indexSignatures\n  };\n};\n/**\n * Equivalent at runtime to the built-in TypeScript utility type `Pick`.\n *\n * @since 0.67.0\n */\nexport const pick = (ast, keys) => {\n  if (isTransformation(ast)) {\n    switch (ast.transformation._tag) {\n      case \"ComposeTransformation\":\n        return new Transformation(pick(ast.from, keys), pick(ast.to, keys), composeTransformation);\n      case \"TypeLiteralTransformation\":\n        {\n          const ts = [];\n          const fromKeys = [];\n          for (const k of keys) {\n            const t = ast.transformation.propertySignatureTransformations.find(t => t.to === k);\n            if (t) {\n              ts.push(t);\n              fromKeys.push(t.from);\n            } else {\n              fromKeys.push(k);\n            }\n          }\n          return Arr.isNonEmptyReadonlyArray(ts) ? new Transformation(pick(ast.from, fromKeys), pick(ast.to, keys), new TypeLiteralTransformation(ts)) : pick(ast.from, fromKeys);\n        }\n      case \"FinalTransformation\":\n        {\n          const annotation = getSurrogateAnnotation(ast);\n          if (Option.isSome(annotation)) {\n            return pick(annotation.value, keys);\n          }\n          throw new Error(errors_.getASTUnsupportedSchema(ast));\n        }\n    }\n  }\n  return new TypeLiteral(keys.map(key => getPropertyKeyIndexedAccess(ast, key)), []);\n};\n/**\n * Equivalent at runtime to the built-in TypeScript utility type `Omit`.\n *\n * @since 0.67.0\n */\nexport const omit = (ast, keys) => pick(ast, getPropertyKeys(ast).filter(name => !keys.includes(name)));\n/** @internal */\nexport const orUndefined = ast => Union.make([ast, undefinedKeyword]);\n/**\n * Equivalent at runtime to the built-in TypeScript utility type `Partial`.\n *\n * @since 0.67.0\n */\nexport const partial = (ast, options) => {\n  const exact = options?.exact === true;\n  switch (ast._tag) {\n    case \"TupleType\":\n      return new TupleType(ast.elements.map(e => new OptionalType(exact ? e.type : orUndefined(e.type), true)), Arr.match(ast.rest, {\n        onEmpty: () => ast.rest,\n        onNonEmpty: rest => [new Type(Union.make([...getRestASTs(rest), undefinedKeyword]))]\n      }), ast.isReadonly);\n    case \"TypeLiteral\":\n      return new TypeLiteral(ast.propertySignatures.map(ps => new PropertySignature(ps.name, exact ? ps.type : orUndefined(ps.type), true, ps.isReadonly, ps.annotations)), ast.indexSignatures.map(is => new IndexSignature(is.parameter, orUndefined(is.type), is.isReadonly)));\n    case \"Union\":\n      return Union.make(ast.types.map(member => partial(member, options)));\n    case \"Suspend\":\n      return new Suspend(() => partial(ast.f(), options));\n    case \"Declaration\":\n      throw new Error(errors_.getASTUnsupportedSchema(ast));\n    case \"Refinement\":\n      throw new Error(errors_.getASTUnsupportedSchema(ast));\n    case \"Transformation\":\n      {\n        if (isTypeLiteralTransformation(ast.transformation) && ast.transformation.propertySignatureTransformations.every(isRenamingPropertySignatureTransformation)) {\n          return new Transformation(partial(ast.from, options), partial(ast.to, options), ast.transformation);\n        }\n        throw new Error(errors_.getASTUnsupportedSchema(ast));\n      }\n  }\n  return ast;\n};\n/**\n * Equivalent at runtime to the built-in TypeScript utility type `Required`.\n *\n * @since 0.67.0\n */\nexport const required = ast => {\n  switch (ast._tag) {\n    case \"TupleType\":\n      return new TupleType(ast.elements.map(e => new OptionalType(e.type, false)), ast.rest, ast.isReadonly);\n    case \"TypeLiteral\":\n      return new TypeLiteral(ast.propertySignatures.map(f => new PropertySignature(f.name, f.type, false, f.isReadonly, f.annotations)), ast.indexSignatures);\n    case \"Union\":\n      return Union.make(ast.types.map(member => required(member)));\n    case \"Suspend\":\n      return new Suspend(() => required(ast.f()));\n    case \"Declaration\":\n      throw new Error(errors_.getASTUnsupportedSchema(ast));\n    case \"Refinement\":\n      throw new Error(errors_.getASTUnsupportedSchema(ast));\n    case \"Transformation\":\n      {\n        if (isTypeLiteralTransformation(ast.transformation) && ast.transformation.propertySignatureTransformations.every(isRenamingPropertySignatureTransformation)) {\n          return new Transformation(required(ast.from), required(ast.to), ast.transformation);\n        }\n        throw new Error(errors_.getASTUnsupportedSchema(ast));\n      }\n  }\n  return ast;\n};\n/**\n * Creates a new AST with shallow mutability applied to its properties.\n *\n * @param ast - The original AST to make properties mutable (shallowly).\n *\n * @since 0.67.0\n */\nexport const mutable = ast => {\n  switch (ast._tag) {\n    case \"TupleType\":\n      return ast.isReadonly === false ? ast : new TupleType(ast.elements, ast.rest, false, ast.annotations);\n    case \"TypeLiteral\":\n      {\n        const propertySignatures = changeMap(ast.propertySignatures, ps => ps.isReadonly === false ? ps : new PropertySignature(ps.name, ps.type, ps.isOptional, false, ps.annotations));\n        const indexSignatures = changeMap(ast.indexSignatures, is => is.isReadonly === false ? is : new IndexSignature(is.parameter, is.type, false));\n        return propertySignatures === ast.propertySignatures && indexSignatures === ast.indexSignatures ? ast : new TypeLiteral(propertySignatures, indexSignatures, ast.annotations);\n      }\n    case \"Union\":\n      {\n        const types = changeMap(ast.types, mutable);\n        return types === ast.types ? ast : Union.make(types, ast.annotations);\n      }\n    case \"Suspend\":\n      return new Suspend(() => mutable(ast.f()), ast.annotations);\n    case \"Refinement\":\n      {\n        const from = mutable(ast.from);\n        return from === ast.from ? ast : new Refinement(from, ast.filter, ast.annotations);\n      }\n    case \"Transformation\":\n      {\n        const from = mutable(ast.from);\n        const to = mutable(ast.to);\n        return from === ast.from && to === ast.to ? ast : new Transformation(from, to, ast.transformation, ast.annotations);\n      }\n  }\n  return ast;\n};\n/**\n * @since 0.67.0\n */\nexport const getCompiler = match => {\n  const compile = (ast, path) => match[ast._tag](ast, compile, path);\n  return compile;\n};\n/**\n * @since 0.67.0\n */\nexport const typeAST = ast => {\n  switch (ast._tag) {\n    case \"Declaration\":\n      {\n        const typeParameters = changeMap(ast.typeParameters, typeAST);\n        return typeParameters === ast.typeParameters ? ast : new Declaration(typeParameters, ast.decodeUnknown, ast.encodeUnknown, ast.annotations);\n      }\n    case \"TupleType\":\n      {\n        const elements = changeMap(ast.elements, e => {\n          const type = typeAST(e.type);\n          return type === e.type ? e : new OptionalType(type, e.isOptional);\n        });\n        const restASTs = getRestASTs(ast.rest);\n        const rest = changeMap(restASTs, typeAST);\n        return elements === ast.elements && rest === restASTs ? ast : new TupleType(elements, rest.map(type => new Type(type)), ast.isReadonly, ast.annotations);\n      }\n    case \"TypeLiteral\":\n      {\n        const propertySignatures = changeMap(ast.propertySignatures, p => {\n          const type = typeAST(p.type);\n          return type === p.type ? p : new PropertySignature(p.name, type, p.isOptional, p.isReadonly);\n        });\n        const indexSignatures = changeMap(ast.indexSignatures, is => {\n          const type = typeAST(is.type);\n          return type === is.type ? is : new IndexSignature(is.parameter, type, is.isReadonly);\n        });\n        return propertySignatures === ast.propertySignatures && indexSignatures === ast.indexSignatures ? ast : new TypeLiteral(propertySignatures, indexSignatures, ast.annotations);\n      }\n    case \"Union\":\n      {\n        const types = changeMap(ast.types, typeAST);\n        return types === ast.types ? ast : Union.make(types, ast.annotations);\n      }\n    case \"Suspend\":\n      return new Suspend(() => typeAST(ast.f()), ast.annotations);\n    case \"Refinement\":\n      {\n        const from = typeAST(ast.from);\n        return from === ast.from ? ast : new Refinement(from, ast.filter, ast.annotations);\n      }\n    case \"Transformation\":\n      return typeAST(ast.to);\n  }\n  return ast;\n};\n/** @internal */\nexport const getJSONIdentifier = annotated => Option.orElse(getJSONIdentifierAnnotation(annotated), () => getIdentifierAnnotation(annotated));\nconst createJSONIdentifierAnnotation = annotated => Option.match(getJSONIdentifier(annotated), {\n  onNone: () => undefined,\n  onSome: identifier => ({\n    [JSONIdentifierAnnotationId]: identifier\n  })\n});\nfunction changeMap(as, f) {\n  let changed = false;\n  const out = Arr.allocate(as.length);\n  for (let i = 0; i < as.length; i++) {\n    const a = as[i];\n    const fa = f(a);\n    if (fa !== a) {\n      changed = true;\n    }\n    out[i] = fa;\n  }\n  return changed ? out : as;\n}\nconst encodedAST_ = (ast, isBound) => {\n  switch (ast._tag) {\n    case \"Declaration\":\n      {\n        const typeParameters = changeMap(ast.typeParameters, ast => encodedAST_(ast, isBound));\n        return typeParameters === ast.typeParameters ? ast : new Declaration(typeParameters, ast.decodeUnknown, ast.encodeUnknown, ast.annotations);\n      }\n    case \"TupleType\":\n      {\n        const elements = changeMap(ast.elements, e => {\n          const type = encodedAST_(e.type, isBound);\n          return type === e.type ? e : new OptionalType(type, e.isOptional);\n        });\n        const restASTs = getRestASTs(ast.rest);\n        const rest = changeMap(restASTs, ast => encodedAST_(ast, isBound));\n        return elements === ast.elements && rest === restASTs ? ast : new TupleType(elements, rest.map(ast => new Type(ast)), ast.isReadonly, createJSONIdentifierAnnotation(ast));\n      }\n    case \"TypeLiteral\":\n      {\n        const propertySignatures = changeMap(ast.propertySignatures, ps => {\n          const type = encodedAST_(ps.type, isBound);\n          return type === ps.type ? ps : new PropertySignature(ps.name, type, ps.isOptional, ps.isReadonly);\n        });\n        const indexSignatures = changeMap(ast.indexSignatures, is => {\n          const type = encodedAST_(is.type, isBound);\n          return type === is.type ? is : new IndexSignature(is.parameter, type, is.isReadonly);\n        });\n        return propertySignatures === ast.propertySignatures && indexSignatures === ast.indexSignatures ? ast : new TypeLiteral(propertySignatures, indexSignatures, createJSONIdentifierAnnotation(ast));\n      }\n    case \"Union\":\n      {\n        const types = changeMap(ast.types, ast => encodedAST_(ast, isBound));\n        return types === ast.types ? ast : Union.make(types, createJSONIdentifierAnnotation(ast));\n      }\n    case \"Suspend\":\n      return new Suspend(() => encodedAST_(ast.f(), isBound), createJSONIdentifierAnnotation(ast));\n    case \"Refinement\":\n      {\n        const from = encodedAST_(ast.from, isBound);\n        if (isBound) {\n          if (from === ast.from) {\n            return ast;\n          }\n          if (!isTransformation(ast.from)) {\n            const annotations = getStableFilterAnnotation(ast);\n            if (Option.isSome(annotations) && annotations.value === true) {\n              return new Refinement(from, ast.filter);\n            }\n          }\n        }\n        return from;\n      }\n    case \"Transformation\":\n      return encodedAST_(ast.from, isBound);\n  }\n  return ast;\n};\n/**\n * @since 0.67.0\n */\nexport const encodedAST = ast => encodedAST_(ast, false);\n/**\n * @since 0.67.0\n */\nexport const encodedBoundAST = ast => encodedAST_(ast, true);\nconst toJSONAnnotations = annotations => {\n  const out = {};\n  for (const k of Object.getOwnPropertySymbols(annotations)) {\n    out[String(k)] = annotations[k];\n  }\n  return out;\n};\n/** @internal */\nexport const getCardinality = ast => {\n  switch (ast._tag) {\n    case \"NeverKeyword\":\n      return 0;\n    case \"Literal\":\n    case \"UndefinedKeyword\":\n    case \"VoidKeyword\":\n    case \"UniqueSymbol\":\n      return 1;\n    case \"BooleanKeyword\":\n      return 2;\n    case \"StringKeyword\":\n    case \"NumberKeyword\":\n    case \"BigIntKeyword\":\n    case \"SymbolKeyword\":\n      return 3;\n    case \"ObjectKeyword\":\n      return 5;\n    case \"UnknownKeyword\":\n    case \"AnyKeyword\":\n      return 6;\n    default:\n      return 4;\n  }\n};\nconst sortPropertySignatures = /*#__PURE__*/Arr.sort( /*#__PURE__*/Order.mapInput(Number.Order, ps => getCardinality(ps.type)));\nconst sortIndexSignatures = /*#__PURE__*/Arr.sort( /*#__PURE__*/Order.mapInput(Number.Order, is => {\n  switch (getParameterBase(is.parameter)._tag) {\n    case \"StringKeyword\":\n      return 2;\n    case \"SymbolKeyword\":\n      return 3;\n    case \"TemplateLiteral\":\n      return 1;\n  }\n}));\nconst WeightOrder = /*#__PURE__*/Order.tuple(Number.Order, Number.Order, Number.Order);\nconst maxWeight = /*#__PURE__*/Order.max(WeightOrder);\nconst emptyWeight = [0, 0, 0];\nconst maxWeightAll = weights => weights.reduce(maxWeight, emptyWeight);\n/** @internal */\nexport const getWeight = ast => {\n  switch (ast._tag) {\n    case \"TupleType\":\n      {\n        return [2, ast.elements.length, ast.rest.length];\n      }\n    case \"TypeLiteral\":\n      {\n        const y = ast.propertySignatures.length;\n        const z = ast.indexSignatures.length;\n        return y + z === 0 ? [-4, 0, 0] : [4, y, z];\n      }\n    case \"Declaration\":\n      {\n        const annotation = getSurrogateAnnotation(ast);\n        if (Option.isSome(annotation)) {\n          const [_, y, z] = getWeight(annotation.value);\n          return [6, y, z];\n        }\n        return [6, 0, 0];\n      }\n    case \"Suspend\":\n      return [8, 0, 0];\n    case \"Union\":\n      return maxWeightAll(ast.types.map(getWeight));\n    case \"Refinement\":\n      {\n        const [x, y, z] = getWeight(ast.from);\n        return [x + 1, y, z];\n      }\n    case \"Transformation\":\n      return getWeight(ast.from);\n    case \"ObjectKeyword\":\n      return [-2, 0, 0];\n    case \"UnknownKeyword\":\n    case \"AnyKeyword\":\n      return [-4, 0, 0];\n    default:\n      return emptyWeight;\n  }\n};\n/** @internal */\nexport const getParameterBase = ast => {\n  switch (ast._tag) {\n    case \"StringKeyword\":\n    case \"SymbolKeyword\":\n    case \"TemplateLiteral\":\n      return ast;\n    case \"Refinement\":\n      return getParameterBase(ast.from);\n  }\n};\nconst equalsTemplateLiteralSpan = /*#__PURE__*/Arr.getEquivalence((self, that) => self.type._tag === that.type._tag && self.literal === that.literal);\nconst equalsEnums = /*#__PURE__*/Arr.getEquivalence((self, that) => that[0] === self[0] && that[1] === self[1]);\nconst equals = (self, that) => {\n  switch (self._tag) {\n    case \"Literal\":\n      return isLiteral(that) && that.literal === self.literal;\n    case \"UniqueSymbol\":\n      return isUniqueSymbol(that) && that.symbol === self.symbol;\n    case \"UndefinedKeyword\":\n    case \"VoidKeyword\":\n    case \"NeverKeyword\":\n    case \"UnknownKeyword\":\n    case \"AnyKeyword\":\n    case \"StringKeyword\":\n    case \"NumberKeyword\":\n    case \"BooleanKeyword\":\n    case \"BigIntKeyword\":\n    case \"SymbolKeyword\":\n    case \"ObjectKeyword\":\n      return that._tag === self._tag;\n    case \"TemplateLiteral\":\n      return isTemplateLiteral(that) && that.head === self.head && equalsTemplateLiteralSpan(that.spans, self.spans);\n    case \"Enums\":\n      return isEnums(that) && equalsEnums(that.enums, self.enums);\n    case \"Refinement\":\n    case \"TupleType\":\n    case \"TypeLiteral\":\n    case \"Union\":\n    case \"Suspend\":\n    case \"Transformation\":\n    case \"Declaration\":\n      return self === that;\n  }\n};\nconst intersection = /*#__PURE__*/Arr.intersectionWith(equals);\nconst _keyof = ast => {\n  switch (ast._tag) {\n    case \"Declaration\":\n      {\n        const annotation = getSurrogateAnnotation(ast);\n        if (Option.isSome(annotation)) {\n          return _keyof(annotation.value);\n        }\n        break;\n      }\n    case \"TypeLiteral\":\n      return ast.propertySignatures.map(p => Predicate.isSymbol(p.name) ? new UniqueSymbol(p.name) : new Literal(p.name)).concat(ast.indexSignatures.map(is => getParameterBase(is.parameter)));\n    case \"Suspend\":\n      return _keyof(ast.f());\n    case \"Union\":\n      return ast.types.slice(1).reduce((out, ast) => intersection(out, _keyof(ast)), _keyof(ast.types[0]));\n    case \"Transformation\":\n      return _keyof(ast.to);\n  }\n  throw new Error(errors_.getASTUnsupportedSchema(ast));\n};\n/** @internal */\nexport const compose = (ab, cd) => new Transformation(ab, cd, composeTransformation);\n/** @internal */\nexport const rename = (ast, mapping) => {\n  switch (ast._tag) {\n    case \"TypeLiteral\":\n      {\n        const propertySignatureTransformations = [];\n        for (const key of util_.ownKeys(mapping)) {\n          const name = mapping[key];\n          if (name !== undefined) {\n            propertySignatureTransformations.push(new PropertySignatureTransformation(key, name, identity, identity));\n          }\n        }\n        if (propertySignatureTransformations.length === 0) {\n          return ast;\n        }\n        return new Transformation(ast, new TypeLiteral(ast.propertySignatures.map(ps => {\n          const name = mapping[ps.name];\n          return new PropertySignature(name === undefined ? ps.name : name, typeAST(ps.type), ps.isOptional, ps.isReadonly, ps.annotations);\n        }), ast.indexSignatures), new TypeLiteralTransformation(propertySignatureTransformations));\n      }\n    case \"Union\":\n      return Union.make(ast.types.map(ast => rename(ast, mapping)));\n    case \"Suspend\":\n      return new Suspend(() => rename(ast.f(), mapping));\n    case \"Transformation\":\n      return compose(ast, rename(typeAST(ast), mapping));\n  }\n  throw new Error(errors_.getASTUnsupportedRenameSchema(ast));\n};\nconst formatKeyword = ast => Option.getOrElse(getExpected(ast), () => ast._tag);\nconst getExpected = ast => {\n  return getIdentifierAnnotation(ast).pipe(Option.orElse(() => getTitleAnnotation(ast)), Option.orElse(() => getDescriptionAnnotation(ast)));\n};\n//# sourceMappingURL=AST.js.map","/**\n * @since 0.67.0\n */\nimport * as Arr from \"effect/Array\";\nimport * as Option from \"effect/Option\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as AST from \"./AST.js\";\nimport * as FastCheck from \"./FastCheck.js\";\nimport * as errors_ from \"./internal/errors.js\";\nimport * as filters_ from \"./internal/filters.js\";\nimport * as util_ from \"./internal/util.js\";\n/**\n * @category hooks\n * @since 0.67.0\n */\nexport const ArbitraryHookId = /*#__PURE__*/Symbol.for(\"@effect/schema/ArbitraryHookId\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const arbitrary = handler => self => self.annotations({\n  [ArbitraryHookId]: handler\n});\n/**\n * Returns a LazyArbitrary for the `A` type of the provided schema.\n *\n * @category arbitrary\n * @since 0.67.0\n */\nexport const makeLazy = schema => go(schema.ast, {}, []);\n/**\n * Returns a fast-check Arbitrary for the `A` type of the provided schema.\n *\n * @category arbitrary\n * @since 0.67.0\n */\nexport const make = schema => makeLazy(schema)(FastCheck);\nconst depthSize = 1;\nconst record = (fc, key, value, options) => {\n  return (options.isSuspend ? fc.oneof({\n    depthSize\n  }, fc.constant([]), fc.array(fc.tuple(key, value), {\n    minLength: 1,\n    maxLength: 2\n  })) : fc.array(fc.tuple(key, value))).map(tuples => {\n    const out = {};\n    for (const [k, v] of tuples) {\n      out[k] = v;\n    }\n    return out;\n  });\n};\nconst getHook = /*#__PURE__*/AST.getAnnotation(ArbitraryHookId);\nconst getRefinementFromArbitrary = (ast, options, path) => {\n  const constraints = combineConstraints(options.constraints, getConstraints(ast));\n  return go(ast.from, constraints ? {\n    ...options,\n    constraints\n  } : options, path);\n};\nconst go = (ast, options, path) => {\n  const hook = getHook(ast);\n  if (Option.isSome(hook)) {\n    switch (ast._tag) {\n      case \"Declaration\":\n        return hook.value(...ast.typeParameters.map(p => go(p, options, path)));\n      case \"Refinement\":\n        return hook.value(getRefinementFromArbitrary(ast, options, path));\n      default:\n        return hook.value();\n    }\n  }\n  switch (ast._tag) {\n    case \"Declaration\":\n      {\n        throw new Error(errors_.getArbitraryMissingAnnotationErrorMessage(path, ast));\n      }\n    case \"Literal\":\n      return fc => fc.constant(ast.literal);\n    case \"UniqueSymbol\":\n      return fc => fc.constant(ast.symbol);\n    case \"UndefinedKeyword\":\n    case \"VoidKeyword\":\n      return fc => fc.constant(undefined);\n    case \"NeverKeyword\":\n      return () => {\n        throw new Error(errors_.getArbitraryUnsupportedErrorMessage(path, ast));\n      };\n    case \"UnknownKeyword\":\n    case \"AnyKeyword\":\n      return fc => fc.anything();\n    case \"StringKeyword\":\n      return fc => {\n        if (options.constraints) {\n          switch (options.constraints._tag) {\n            case \"StringConstraints\":\n              return fc.string(options.constraints.constraints);\n          }\n        }\n        return fc.string();\n      };\n    case \"NumberKeyword\":\n      return fc => {\n        if (options.constraints) {\n          switch (options.constraints._tag) {\n            case \"NumberConstraints\":\n              return fc.float(options.constraints.constraints);\n            case \"IntegerConstraints\":\n              return fc.integer(options.constraints.constraints);\n          }\n        }\n        return fc.float();\n      };\n    case \"BooleanKeyword\":\n      return fc => fc.boolean();\n    case \"BigIntKeyword\":\n      return fc => {\n        if (options.constraints) {\n          switch (options.constraints._tag) {\n            case \"BigIntConstraints\":\n              return fc.bigInt(options.constraints.constraints);\n          }\n        }\n        return fc.bigInt();\n      };\n    case \"SymbolKeyword\":\n      return fc => fc.string().map(s => Symbol.for(s));\n    case \"ObjectKeyword\":\n      return fc => fc.oneof(fc.object(), fc.array(fc.anything()));\n    case \"TemplateLiteral\":\n      {\n        return fc => {\n          const string = fc.string({\n            maxLength: 5\n          });\n          const number = fc.float({\n            noDefaultInfinity: true\n          }).filter(n => !Number.isNaN(n));\n          const components = [fc.constant(ast.head)];\n          for (const span of ast.spans) {\n            if (AST.isStringKeyword(span.type)) {\n              components.push(string);\n            } else {\n              components.push(number);\n            }\n            components.push(fc.constant(span.literal));\n          }\n          return fc.tuple(...components).map(spans => spans.join(\"\"));\n        };\n      }\n    case \"TupleType\":\n      {\n        const elements = [];\n        let hasOptionals = false;\n        let i = 0;\n        for (const element of ast.elements) {\n          elements.push(go(element.type, options, path.concat(i++)));\n          if (element.isOptional) {\n            hasOptionals = true;\n          }\n        }\n        const rest = ast.rest.map(annotatedAST => go(annotatedAST.type, options, path));\n        return fc => {\n          // ---------------------------------------------\n          // handle elements\n          // ---------------------------------------------\n          let output = fc.tuple(...elements.map(arb => arb(fc)));\n          if (hasOptionals) {\n            const indexes = fc.tuple(...ast.elements.map(element => element.isOptional ? fc.boolean() : fc.constant(true)));\n            output = output.chain(tuple => indexes.map(booleans => {\n              for (const [i, b] of booleans.reverse().entries()) {\n                if (!b) {\n                  tuple.splice(booleans.length - i, 1);\n                }\n              }\n              return tuple;\n            }));\n          }\n          // ---------------------------------------------\n          // handle rest element\n          // ---------------------------------------------\n          if (Arr.isNonEmptyReadonlyArray(rest)) {\n            const [head, ...tail] = rest;\n            const arb = head(fc);\n            const constraints = options.constraints;\n            output = output.chain(as => {\n              let out = fc.array(arb);\n              if (options.isSuspend) {\n                out = fc.oneof({\n                  depthSize\n                }, fc.constant([]), fc.array(arb, {\n                  minLength: 1,\n                  maxLength: 2\n                }));\n              } else if (constraints && constraints._tag === \"ArrayConstraints\") {\n                out = fc.array(arb, constraints.constraints);\n              }\n              return out.map(rest => [...as, ...rest]);\n            });\n            // ---------------------------------------------\n            // handle post rest elements\n            // ---------------------------------------------\n            for (let j = 0; j < tail.length; j++) {\n              output = output.chain(as => tail[j](fc).map(a => [...as, a]));\n            }\n          }\n          return output;\n        };\n      }\n    case \"TypeLiteral\":\n      {\n        const propertySignaturesTypes = ast.propertySignatures.map(ps => go(ps.type, options, path.concat(ps.name)));\n        const indexSignatures = ast.indexSignatures.map(is => [go(is.parameter, options, path), go(is.type, options, path)]);\n        return fc => {\n          const arbs = {};\n          const requiredKeys = [];\n          // ---------------------------------------------\n          // handle property signatures\n          // ---------------------------------------------\n          for (let i = 0; i < propertySignaturesTypes.length; i++) {\n            const ps = ast.propertySignatures[i];\n            const name = ps.name;\n            if (!ps.isOptional) {\n              requiredKeys.push(name);\n            }\n            arbs[name] = propertySignaturesTypes[i](fc);\n          }\n          let output = fc.record(arbs, {\n            requiredKeys\n          });\n          // ---------------------------------------------\n          // handle index signatures\n          // ---------------------------------------------\n          for (let i = 0; i < indexSignatures.length; i++) {\n            const parameter = indexSignatures[i][0](fc);\n            const type = indexSignatures[i][1](fc);\n            output = output.chain(o => {\n              return record(fc, parameter, type, options).map(d => ({\n                ...d,\n                ...o\n              }));\n            });\n          }\n          return output;\n        };\n      }\n    case \"Union\":\n      {\n        const types = ast.types.map(t => go(t, options, path));\n        return fc => fc.oneof({\n          depthSize\n        }, ...types.map(arb => arb(fc)));\n      }\n    case \"Enums\":\n      {\n        if (ast.enums.length === 0) {\n          throw new Error(errors_.getArbitraryEmptyEnumErrorMessage(path));\n        }\n        return fc => fc.oneof(...ast.enums.map(([_, value]) => fc.constant(value)));\n      }\n    case \"Refinement\":\n      {\n        const from = getRefinementFromArbitrary(ast, options, path);\n        return fc => from(fc).filter(a => Option.isNone(ast.filter(a, AST.defaultParseOption, ast)));\n      }\n    case \"Suspend\":\n      {\n        const get = util_.memoizeThunk(() => go(ast.f(), {\n          ...options,\n          isSuspend: true\n        }, path));\n        return fc => fc.constant(null).chain(() => get()(fc));\n      }\n    case \"Transformation\":\n      return go(ast.to, options, path);\n  }\n};\n/** @internal */\nexport class NumberConstraints {\n  _tag = \"NumberConstraints\";\n  constraints;\n  constructor(options) {\n    this.constraints = {};\n    if (Predicate.isNumber(options.min)) {\n      this.constraints.min = Math.fround(options.min);\n    }\n    if (Predicate.isNumber(options.max)) {\n      this.constraints.max = Math.fround(options.max);\n    }\n    if (Predicate.isBoolean(options.noNaN)) {\n      this.constraints.noNaN = options.noNaN;\n    }\n    if (Predicate.isBoolean(options.noDefaultInfinity)) {\n      this.constraints.noDefaultInfinity = options.noDefaultInfinity;\n    }\n  }\n}\n/** @internal */\nexport class StringConstraints {\n  _tag = \"StringConstraints\";\n  constraints;\n  constructor(options) {\n    this.constraints = {};\n    if (Predicate.isNumber(options.minLength)) {\n      this.constraints.minLength = options.minLength;\n    }\n    if (Predicate.isNumber(options.maxLength)) {\n      this.constraints.maxLength = options.maxLength;\n    }\n  }\n}\n/** @internal */\nexport class IntegerConstraints {\n  _tag = \"IntegerConstraints\";\n  constraints;\n  constructor(options) {\n    this.constraints = {};\n    if (Predicate.isNumber(options.min)) {\n      this.constraints.min = options.min;\n    }\n    if (Predicate.isNumber(options.max)) {\n      this.constraints.max = options.max;\n    }\n  }\n}\n/** @internal */\nexport class ArrayConstraints {\n  _tag = \"ArrayConstraints\";\n  constraints;\n  constructor(options) {\n    this.constraints = {};\n    if (Predicate.isNumber(options.minLength)) {\n      this.constraints.minLength = options.minLength;\n    }\n    if (Predicate.isNumber(options.maxLength)) {\n      this.constraints.maxLength = options.maxLength;\n    }\n  }\n}\n/** @internal */\nexport class BigIntConstraints {\n  _tag = \"BigIntConstraints\";\n  constraints;\n  constructor(options) {\n    this.constraints = {};\n    if (Predicate.isBigInt(options.min)) {\n      this.constraints.min = options.min;\n    }\n    if (Predicate.isBigInt(options.max)) {\n      this.constraints.max = options.max;\n    }\n  }\n}\n/** @internal */\nexport const getConstraints = ast => {\n  const TypeAnnotationId = ast.annotations[AST.TypeAnnotationId];\n  const jsonSchema = ast.annotations[AST.JSONSchemaAnnotationId];\n  switch (TypeAnnotationId) {\n    // int\n    case filters_.IntTypeId:\n      return new IntegerConstraints({});\n    // number\n    case filters_.GreaterThanTypeId:\n    case filters_.GreaterThanOrEqualToTypeId:\n    case filters_.LessThanTypeId:\n    case filters_.LessThanOrEqualToTypeId:\n    case filters_.BetweenTypeId:\n      return new NumberConstraints({\n        min: jsonSchema.exclusiveMinimum ?? jsonSchema.minimum,\n        max: jsonSchema.exclusiveMaximum ?? jsonSchema.maximum\n      });\n    // bigint\n    case filters_.GreaterThanBigintTypeId:\n    case filters_.GreaterThanOrEqualToBigIntTypeId:\n    case filters_.LessThanBigIntTypeId:\n    case filters_.LessThanOrEqualToBigIntTypeId:\n    case filters_.BetweenBigintTypeId:\n      {\n        const constraints = ast.annotations[TypeAnnotationId];\n        return new BigIntConstraints(constraints);\n      }\n    // string\n    case filters_.MinLengthTypeId:\n    case filters_.MaxLengthTypeId:\n    case filters_.LengthTypeId:\n      return new StringConstraints(jsonSchema);\n    // array\n    case filters_.MinItemsTypeId:\n    case filters_.MaxItemsTypeId:\n    case filters_.ItemsCountTypeId:\n      return new ArrayConstraints({\n        minLength: jsonSchema.minItems,\n        maxLength: jsonSchema.maxItems\n      });\n  }\n};\n/** @internal */\nexport const combineConstraints = (c1, c2) => {\n  if (c1 === undefined) {\n    return c2;\n  }\n  if (c2 === undefined) {\n    return c1;\n  }\n  switch (c1._tag) {\n    case \"ArrayConstraints\":\n      {\n        switch (c2._tag) {\n          case \"ArrayConstraints\":\n            return new ArrayConstraints({\n              minLength: getMax(c1.constraints.minLength, c2.constraints.minLength),\n              maxLength: getMin(c1.constraints.maxLength, c2.constraints.maxLength)\n            });\n        }\n        break;\n      }\n    case \"NumberConstraints\":\n      {\n        switch (c2._tag) {\n          case \"NumberConstraints\":\n            return new NumberConstraints({\n              min: getMax(c1.constraints.min, c2.constraints.min),\n              max: getMin(c1.constraints.max, c2.constraints.max),\n              noNaN: getOr(c1.constraints.noNaN, c2.constraints.noNaN),\n              noDefaultInfinity: getOr(c1.constraints.noDefaultInfinity, c2.constraints.noDefaultInfinity)\n            });\n          case \"IntegerConstraints\":\n            return new IntegerConstraints({\n              min: getMax(c1.constraints.min, c2.constraints.min),\n              max: getMin(c1.constraints.max, c2.constraints.max)\n            });\n        }\n        break;\n      }\n    case \"BigIntConstraints\":\n      {\n        switch (c2._tag) {\n          case \"BigIntConstraints\":\n            return new BigIntConstraints({\n              min: getMax(c1.constraints.min, c2.constraints.min),\n              max: getMin(c1.constraints.max, c2.constraints.max)\n            });\n        }\n        break;\n      }\n    case \"StringConstraints\":\n      {\n        switch (c2._tag) {\n          case \"StringConstraints\":\n            return new StringConstraints({\n              minLength: getMax(c1.constraints.minLength, c2.constraints.minLength),\n              maxLength: getMin(c1.constraints.maxLength, c2.constraints.maxLength)\n            });\n        }\n        break;\n      }\n    case \"IntegerConstraints\":\n      {\n        switch (c2._tag) {\n          case \"NumberConstraints\":\n          case \"IntegerConstraints\":\n            {\n              return new IntegerConstraints({\n                min: getMax(c1.constraints.min, c2.constraints.min),\n                max: getMin(c1.constraints.max, c2.constraints.max)\n              });\n            }\n        }\n        break;\n      }\n  }\n};\nconst getOr = (a, b) => {\n  return a === undefined ? b : b === undefined ? a : a || b;\n};\nfunction getMax(n1, n2) {\n  return n1 === undefined ? n2 : n2 === undefined ? n1 : n1 <= n2 ? n2 : n1;\n}\nfunction getMin(n1, n2) {\n  return n1 === undefined ? n2 : n2 === undefined ? n1 : n1 <= n2 ? n1 : n2;\n}\n//# sourceMappingURL=Arbitrary.js.map","/**\n * @since 0.67.0\n */\nimport * as Arr from \"effect/Array\";\nimport * as Equal from \"effect/Equal\";\nimport * as Equivalence from \"effect/Equivalence\";\nimport * as Option from \"effect/Option\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as AST from \"./AST.js\";\nimport * as errors_ from \"./internal/errors.js\";\nimport * as util_ from \"./internal/util.js\";\nimport * as ParseResult from \"./ParseResult.js\";\n/**\n * @category hooks\n * @since 0.67.0\n */\nexport const EquivalenceHookId = /*#__PURE__*/Symbol.for(\"@effect/schema/EquivalenceHookId\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const equivalence = handler => self => self.annotations({\n  [EquivalenceHookId]: handler\n});\n/**\n * @category Equivalence\n * @since 0.67.0\n */\nexport const make = schema => go(schema.ast, []);\nconst getHook = /*#__PURE__*/AST.getAnnotation(EquivalenceHookId);\nconst go = (ast, path) => {\n  const hook = getHook(ast);\n  if (Option.isSome(hook)) {\n    switch (ast._tag) {\n      case \"Declaration\":\n        return hook.value(...ast.typeParameters.map(tp => go(tp, path)));\n      case \"Refinement\":\n        return hook.value(go(ast.from, path));\n      default:\n        return hook.value();\n    }\n  }\n  switch (ast._tag) {\n    case \"NeverKeyword\":\n      throw new Error(errors_.getEquivalenceUnsupportedErrorMessage(ast, path));\n    case \"Transformation\":\n      return go(ast.to, path);\n    case \"Declaration\":\n    case \"Literal\":\n    case \"StringKeyword\":\n    case \"TemplateLiteral\":\n    case \"UniqueSymbol\":\n    case \"SymbolKeyword\":\n    case \"UnknownKeyword\":\n    case \"AnyKeyword\":\n    case \"NumberKeyword\":\n    case \"BooleanKeyword\":\n    case \"BigIntKeyword\":\n    case \"UndefinedKeyword\":\n    case \"VoidKeyword\":\n    case \"Enums\":\n    case \"ObjectKeyword\":\n      return Equal.equals;\n    case \"Refinement\":\n      return go(ast.from, path);\n    case \"Suspend\":\n      {\n        const get = util_.memoizeThunk(() => go(ast.f(), path));\n        return (a, b) => get()(a, b);\n      }\n    case \"TupleType\":\n      {\n        const elements = ast.elements.map((element, i) => go(element.type, path.concat(i)));\n        const rest = ast.rest.map(annotatedAST => go(annotatedAST.type, path));\n        return Equivalence.make((a, b) => {\n          const len = a.length;\n          if (len !== b.length) {\n            return false;\n          }\n          // ---------------------------------------------\n          // handle elements\n          // ---------------------------------------------\n          let i = 0;\n          for (; i < Math.min(len, ast.elements.length); i++) {\n            if (!elements[i](a[i], b[i])) {\n              return false;\n            }\n          }\n          // ---------------------------------------------\n          // handle rest element\n          // ---------------------------------------------\n          if (Arr.isNonEmptyReadonlyArray(rest)) {\n            const [head, ...tail] = rest;\n            for (; i < len - tail.length; i++) {\n              if (!head(a[i], b[i])) {\n                return false;\n              }\n            }\n            // ---------------------------------------------\n            // handle post rest elements\n            // ---------------------------------------------\n            for (let j = 0; j < tail.length; j++) {\n              i += j;\n              if (!tail[j](a[i], b[i])) {\n                return false;\n              }\n            }\n          }\n          return true;\n        });\n      }\n    case \"TypeLiteral\":\n      {\n        if (ast.propertySignatures.length === 0 && ast.indexSignatures.length === 0) {\n          return Equal.equals;\n        }\n        const propertySignatures = ast.propertySignatures.map(ps => go(ps.type, path.concat(ps.name)));\n        const indexSignatures = ast.indexSignatures.map(is => go(is.type, path));\n        return Equivalence.make((a, b) => {\n          const aStringKeys = Object.keys(a);\n          const aSymbolKeys = Object.getOwnPropertySymbols(a);\n          // ---------------------------------------------\n          // handle property signatures\n          // ---------------------------------------------\n          for (let i = 0; i < propertySignatures.length; i++) {\n            const ps = ast.propertySignatures[i];\n            const name = ps.name;\n            const aHas = Object.prototype.hasOwnProperty.call(a, name);\n            const bHas = Object.prototype.hasOwnProperty.call(b, name);\n            if (ps.isOptional) {\n              if (aHas !== bHas) {\n                return false;\n              }\n            }\n            if (aHas && bHas && !propertySignatures[i](a[name], b[name])) {\n              return false;\n            }\n          }\n          // ---------------------------------------------\n          // handle index signatures\n          // ---------------------------------------------\n          let bSymbolKeys;\n          let bStringKeys;\n          for (let i = 0; i < indexSignatures.length; i++) {\n            const is = ast.indexSignatures[i];\n            const base = AST.getParameterBase(is.parameter);\n            const isSymbol = AST.isSymbolKeyword(base);\n            if (isSymbol) {\n              bSymbolKeys = bSymbolKeys || Object.getOwnPropertySymbols(b);\n              if (aSymbolKeys.length !== bSymbolKeys.length) {\n                return false;\n              }\n            } else {\n              bStringKeys = bStringKeys || Object.keys(b);\n              if (aStringKeys.length !== bStringKeys.length) {\n                return false;\n              }\n            }\n            const aKeys = isSymbol ? aSymbolKeys : aStringKeys;\n            for (let j = 0; j < aKeys.length; j++) {\n              const key = aKeys[j];\n              if (!Object.prototype.hasOwnProperty.call(b, key) || !indexSignatures[i](a[key], b[key])) {\n                return false;\n              }\n            }\n          }\n          return true;\n        });\n      }\n    case \"Union\":\n      {\n        const searchTree = ParseResult.getSearchTree(ast.types, true);\n        const ownKeys = util_.ownKeys(searchTree.keys);\n        const len = ownKeys.length;\n        return Equivalence.make((a, b) => {\n          let candidates = [];\n          if (len > 0 && Predicate.isRecord(a)) {\n            for (let i = 0; i < len; i++) {\n              const name = ownKeys[i];\n              const buckets = searchTree.keys[name].buckets;\n              if (Object.prototype.hasOwnProperty.call(a, name)) {\n                const literal = String(a[name]);\n                if (Object.prototype.hasOwnProperty.call(buckets, literal)) {\n                  candidates = candidates.concat(buckets[literal]);\n                }\n              }\n            }\n          }\n          if (searchTree.otherwise.length > 0) {\n            candidates = candidates.concat(searchTree.otherwise);\n          }\n          const tuples = candidates.map(ast => [go(ast, path), ParseResult.is({\n            ast\n          })]);\n          for (let i = 0; i < tuples.length; i++) {\n            const [equivalence, is] = tuples[i];\n            if (is(a) && is(b)) {\n              if (equivalence(a, b)) {\n                return true;\n              }\n            }\n          }\n          return false;\n        });\n      }\n  }\n};\n//# sourceMappingURL=Equivalence.js.map","/**\n * @since 0.67.0\n */\n/**\n * @category re-exports\n * @since 0.67.0\n */\nexport * from \"fast-check\";\n//# sourceMappingURL=FastCheck.js.map","/**\n * @since 0.67.0\n */\nimport * as array_ from \"effect/Array\";\nimport { TaggedError } from \"effect/Data\";\nimport * as Effect from \"effect/Effect\";\nimport * as Either from \"effect/Either\";\nimport { dual } from \"effect/Function\";\nimport { globalValue } from \"effect/GlobalValue\";\nimport * as Inspectable from \"effect/Inspectable\";\nimport * as Option from \"effect/Option\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as AST from \"./AST.js\";\nimport * as util_ from \"./internal/util.js\";\nimport * as TreeFormatter from \"./TreeFormatter.js\";\n/**\n * @category model\n * @since 0.68.0\n */\nexport class Pointer {\n  path;\n  actual;\n  issue;\n  /**\n   * @since 0.68.0\n   */\n  _tag = \"Pointer\";\n  constructor(path, actual, issue) {\n    this.path = path;\n    this.actual = actual;\n    this.issue = issue;\n  }\n}\n/**\n * Error that occurs when an unexpected key or index is present.\n *\n * @category model\n * @since 0.67.0\n */\nexport class Unexpected {\n  actual;\n  message;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Unexpected\";\n  constructor(actual,\n  /**\n   * @since 0.68.0\n   */\n  message) {\n    this.actual = actual;\n    this.message = message;\n  }\n}\n/**\n * Error that occurs when a required key or index is missing.\n *\n * @category model\n * @since 0.67.0\n */\nexport class Missing {\n  ast;\n  message;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Missing\";\n  /**\n   * @since 0.68.0\n   */\n  actual = undefined;\n  constructor(\n  /**\n   * @since 0.68.0\n   */\n  ast,\n  /**\n   * @since 0.68.0\n   */\n  message) {\n    this.ast = ast;\n    this.message = message;\n  }\n}\n/**\n * Error that contains multiple issues.\n *\n * @category model\n * @since 0.68.0\n */\nexport class Composite {\n  ast;\n  actual;\n  issues;\n  output;\n  /**\n   * @since 0.68.0\n   */\n  _tag = \"Composite\";\n  constructor(ast, actual, issues, output) {\n    this.ast = ast;\n    this.actual = actual;\n    this.issues = issues;\n    this.output = output;\n  }\n}\n/**\n * Returns `true` if the value is a `Composite`.\n *\n * @category guards\n * @since 0.68.0\n */\nexport const isComposite = u => Predicate.hasProperty(u, \"_tag\");\n/**\n * Error that occurs when a refinement has an error.\n *\n * @category model\n * @since 0.67.0\n */\nexport class Refinement {\n  ast;\n  actual;\n  kind;\n  issue;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Refinement\";\n  constructor(ast, actual, kind, issue) {\n    this.ast = ast;\n    this.actual = actual;\n    this.kind = kind;\n    this.issue = issue;\n  }\n}\n/**\n * Error that occurs when a transformation has an error.\n *\n * @category model\n * @since 0.67.0\n */\nexport class Transformation {\n  ast;\n  actual;\n  kind;\n  issue;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Transformation\";\n  constructor(ast, actual, kind, issue) {\n    this.ast = ast;\n    this.actual = actual;\n    this.kind = kind;\n    this.issue = issue;\n  }\n}\n/**\n * The `Type` variant of the `ParseIssue` type represents an error that occurs when the `actual` value is not of the expected type.\n * The `ast` field specifies the expected type, and the `actual` field contains the value that caused the error.\n *\n * @category model\n * @since 0.67.0\n */\nexport class Type {\n  ast;\n  actual;\n  message;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Type\";\n  constructor(ast, actual, message) {\n    this.ast = ast;\n    this.actual = actual;\n    this.message = message;\n  }\n}\n/**\n * The `Forbidden` variant of the `ParseIssue` type represents a forbidden operation, such as when encountering an Effect that is not allowed to execute (e.g., using `runSync`).\n *\n * @category model\n * @since 0.67.0\n */\nexport class Forbidden {\n  ast;\n  actual;\n  message;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"Forbidden\";\n  constructor(ast, actual, message) {\n    this.ast = ast;\n    this.actual = actual;\n    this.message = message;\n  }\n}\n/**\n * @category type id\n * @since 0.68.0\n */\nexport const ParseErrorTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/ParseErrorTypeId\");\n/**\n * @since 0.68.0\n */\nexport const isParseError = u => Predicate.hasProperty(u, ParseErrorTypeId);\n/**\n * @since 0.67.0\n */\nexport class ParseError extends TaggedError(\"ParseError\") {\n  /**\n   * @since 0.68.0\n   */\n  [ParseErrorTypeId] = ParseErrorTypeId;\n  get message() {\n    return this.toString();\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return TreeFormatter.formatIssueSync(this.issue);\n  }\n  /**\n   * @since 0.67.0\n   */\n  toJSON() {\n    return {\n      _id: \"ParseError\",\n      message: this.toString()\n    };\n  }\n  /**\n   * @since 0.67.0\n   */\n  [Inspectable.NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n}\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const parseError = issue => new ParseError({\n  issue\n});\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const succeed = Either.right;\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const fail = Either.left;\nconst _try = Either.try;\nexport {\n/**\n * @category constructors\n * @since 0.67.0\n */\n_try as try };\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const fromOption = Either.fromOption;\n/**\n * @category optimisation\n * @since 0.67.0\n */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => {\n  const s = self;\n  if (s[\"_tag\"] === \"Left\") {\n    return s;\n  }\n  if (s[\"_tag\"] === \"Right\") {\n    return f(s.right);\n  }\n  return Effect.flatMap(self, f);\n});\n/**\n * @category optimisation\n * @since 0.67.0\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => {\n  const s = self;\n  if (s[\"_tag\"] === \"Left\") {\n    return s;\n  }\n  if (s[\"_tag\"] === \"Right\") {\n    return Either.right(f(s.right));\n  }\n  return Effect.map(self, f);\n});\n/**\n * @category optimisation\n * @since 0.67.0\n */\nexport const mapError = /*#__PURE__*/dual(2, (self, f) => {\n  const s = self;\n  if (s[\"_tag\"] === \"Left\") {\n    return Either.left(f(s.left));\n  }\n  if (s[\"_tag\"] === \"Right\") {\n    return s;\n  }\n  return Effect.mapError(self, f);\n});\n/**\n * @category optimisation\n * @since 0.67.0\n */\nexport const eitherOrUndefined = self => {\n  const s = self;\n  if (s[\"_tag\"] === \"Left\" || s[\"_tag\"] === \"Right\") {\n    return s;\n  }\n};\n/**\n * @category optimisation\n * @since 0.67.0\n */\nexport const mapBoth = /*#__PURE__*/dual(2, (self, options) => {\n  const s = self;\n  if (s[\"_tag\"] === \"Left\") {\n    return Either.left(options.onFailure(s.left));\n  }\n  if (s[\"_tag\"] === \"Right\") {\n    return Either.right(options.onSuccess(s.right));\n  }\n  return Effect.mapBoth(self, options);\n});\n/**\n * @category optimisation\n * @since 0.67.0\n */\nexport const orElse = /*#__PURE__*/dual(2, (self, f) => {\n  const s = self;\n  if (s[\"_tag\"] === \"Left\") {\n    return f(s.left);\n  }\n  if (s[\"_tag\"] === \"Right\") {\n    return s;\n  }\n  return Effect.catchAll(self, f);\n});\n/** @internal */\nexport const mergeInternalOptions = (options, overrideOptions) => {\n  if (overrideOptions === undefined || Predicate.isNumber(overrideOptions)) {\n    return options;\n  }\n  if (options === undefined) {\n    return overrideOptions;\n  }\n  return {\n    ...options,\n    ...overrideOptions\n  };\n};\nconst getEither = (ast, isDecoding, options) => {\n  const parser = goMemo(ast, isDecoding);\n  return (u, overrideOptions) => parser(u, mergeInternalOptions(options, overrideOptions));\n};\nconst getSync = (ast, isDecoding, options) => {\n  const parser = getEither(ast, isDecoding, options);\n  return (input, overrideOptions) => Either.getOrThrowWith(parser(input, overrideOptions), parseError);\n};\nconst getOption = (ast, isDecoding, options) => {\n  const parser = getEither(ast, isDecoding, options);\n  return (input, overrideOptions) => Option.getRight(parser(input, overrideOptions));\n};\nconst getEffect = (ast, isDecoding, options) => {\n  const parser = goMemo(ast, isDecoding);\n  return (input, overrideOptions) => parser(input, {\n    ...mergeInternalOptions(options, overrideOptions),\n    isEffectAllowed: true\n  });\n};\n/**\n * @throws `ParseError`\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeUnknownSync = (schema, options) => getSync(schema.ast, true, options);\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeUnknownOption = (schema, options) => getOption(schema.ast, true, options);\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeUnknownEither = (schema, options) => getEither(schema.ast, true, options);\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeUnknownPromise = (schema, options) => {\n  const parser = decodeUnknown(schema, options);\n  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));\n};\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeUnknown = (schema, options) => getEffect(schema.ast, true, options);\n/**\n * @throws `ParseError`\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeUnknownSync = (schema, options) => getSync(schema.ast, false, options);\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeUnknownOption = (schema, options) => getOption(schema.ast, false, options);\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeUnknownEither = (schema, options) => getEither(schema.ast, false, options);\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeUnknownPromise = (schema, options) => {\n  const parser = encodeUnknown(schema, options);\n  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));\n};\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeUnknown = (schema, options) => getEffect(schema.ast, false, options);\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeSync = decodeUnknownSync;\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeOption = decodeUnknownOption;\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeEither = decodeUnknownEither;\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodePromise = decodeUnknownPromise;\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decode = decodeUnknown;\n/**\n * @throws `ParseError`\n * @category validation\n * @since 0.67.0\n */\nexport const validateSync = (schema, options) => getSync(AST.typeAST(schema.ast), true, options);\n/**\n * @category validation\n * @since 0.67.0\n */\nexport const validateOption = (schema, options) => getOption(AST.typeAST(schema.ast), true, options);\n/**\n * @category validation\n * @since 0.67.0\n */\nexport const validateEither = (schema, options) => getEither(AST.typeAST(schema.ast), true, options);\n/**\n * @category validation\n * @since 0.67.0\n */\nexport const validatePromise = (schema, options) => {\n  const parser = validate(schema, options);\n  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));\n};\n/**\n * @category validation\n * @since 0.67.0\n */\nexport const validate = (schema, options) => getEffect(AST.typeAST(schema.ast), true, options);\n/**\n * By default the option `exact` is set to `true`.\n *\n * @category validation\n * @since 0.67.0\n */\nexport const is = (schema, options) => {\n  const parser = goMemo(AST.typeAST(schema.ast), true);\n  return (u, overrideOptions) => Either.isRight(parser(u, {\n    exact: true,\n    ...mergeInternalOptions(options, overrideOptions)\n  }));\n};\n/**\n * By default the option `exact` is set to `true`.\n *\n * @throws `ParseError`\n * @category validation\n * @since 0.67.0\n */\nexport const asserts = (schema, options) => {\n  const parser = goMemo(AST.typeAST(schema.ast), true);\n  return (u, overrideOptions) => {\n    const result = parser(u, {\n      exact: true,\n      ...mergeInternalOptions(options, overrideOptions)\n    });\n    if (Either.isLeft(result)) {\n      throw parseError(result.left);\n    }\n  };\n};\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeSync = encodeUnknownSync;\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeOption = encodeUnknownOption;\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeEither = encodeUnknownEither;\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodePromise = encodeUnknownPromise;\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encode = encodeUnknown;\nconst decodeMemoMap = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"@effect/schema/Parser/decodeMemoMap\"), () => new WeakMap());\nconst encodeMemoMap = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"@effect/schema/Parser/encodeMemoMap\"), () => new WeakMap());\nconst goMemo = (ast, isDecoding) => {\n  const memoMap = isDecoding ? decodeMemoMap : encodeMemoMap;\n  const memo = memoMap.get(ast);\n  if (memo) {\n    return memo;\n  }\n  const raw = go(ast, isDecoding);\n  const parseOptionsAnnotation = AST.getParseOptionsAnnotation(ast);\n  const parser = Option.isSome(parseOptionsAnnotation) ? (i, options) => raw(i, mergeInternalOptions(options, parseOptionsAnnotation.value)) : raw;\n  memoMap.set(ast, parser);\n  return parser;\n};\nconst getConcurrency = ast => Option.getOrUndefined(AST.getConcurrencyAnnotation(ast));\nconst getBatching = ast => Option.getOrUndefined(AST.getBatchingAnnotation(ast));\nconst go = (ast, isDecoding) => {\n  switch (ast._tag) {\n    case \"Refinement\":\n      {\n        if (isDecoding) {\n          const from = goMemo(ast.from, true);\n          return (i, options) => handleForbidden(flatMap(mapError(from(i, options), e => new Refinement(ast, i, \"From\", e)), a => Option.match(ast.filter(a, options ?? AST.defaultParseOption, ast), {\n            onNone: () => Either.right(a),\n            onSome: e => Either.left(new Refinement(ast, i, \"Predicate\", e))\n          })), ast, i, options);\n        } else {\n          const from = goMemo(AST.typeAST(ast), true);\n          const to = goMemo(dropRightRefinement(ast.from), false);\n          return (i, options) => handleForbidden(flatMap(from(i, options), a => to(a, options)), ast, i, options);\n        }\n      }\n    case \"Transformation\":\n      {\n        const transform = getFinalTransformation(ast.transformation, isDecoding);\n        const from = isDecoding ? goMemo(ast.from, true) : goMemo(ast.to, false);\n        const to = isDecoding ? goMemo(ast.to, true) : goMemo(ast.from, false);\n        return (i1, options) => handleForbidden(flatMap(mapError(from(i1, options), e => new Transformation(ast, i1, isDecoding ? \"Encoded\" : \"Type\", e)), a => flatMap(mapError(transform(a, options ?? AST.defaultParseOption, ast), e => new Transformation(ast, i1, \"Transformation\", e)), i2 => mapError(to(i2, options), e => new Transformation(ast, i1, isDecoding ? \"Type\" : \"Encoded\", e)))), ast, i1, options);\n      }\n    case \"Declaration\":\n      {\n        const parse = isDecoding ? ast.decodeUnknown(...ast.typeParameters) : ast.encodeUnknown(...ast.typeParameters);\n        return (i, options) => handleForbidden(parse(i, options ?? AST.defaultParseOption, ast), ast, i, options);\n      }\n    case \"Literal\":\n      return fromRefinement(ast, u => u === ast.literal);\n    case \"UniqueSymbol\":\n      return fromRefinement(ast, u => u === ast.symbol);\n    case \"UndefinedKeyword\":\n      return fromRefinement(ast, Predicate.isUndefined);\n    case \"VoidKeyword\":\n      return fromRefinement(ast, Predicate.isUndefined);\n    case \"NeverKeyword\":\n      return fromRefinement(ast, Predicate.isNever);\n    case \"UnknownKeyword\":\n    case \"AnyKeyword\":\n      return Either.right;\n    case \"StringKeyword\":\n      return fromRefinement(ast, Predicate.isString);\n    case \"NumberKeyword\":\n      return fromRefinement(ast, Predicate.isNumber);\n    case \"BooleanKeyword\":\n      return fromRefinement(ast, Predicate.isBoolean);\n    case \"BigIntKeyword\":\n      return fromRefinement(ast, Predicate.isBigInt);\n    case \"SymbolKeyword\":\n      return fromRefinement(ast, Predicate.isSymbol);\n    case \"ObjectKeyword\":\n      return fromRefinement(ast, Predicate.isObject);\n    case \"Enums\":\n      return fromRefinement(ast, u => ast.enums.some(([_, value]) => value === u));\n    case \"TemplateLiteral\":\n      {\n        const regex = AST.getTemplateLiteralRegExp(ast);\n        return fromRefinement(ast, u => Predicate.isString(u) && regex.test(u));\n      }\n    case \"TupleType\":\n      {\n        const elements = ast.elements.map(e => goMemo(e.type, isDecoding));\n        const rest = ast.rest.map(annotatedAST => goMemo(annotatedAST.type, isDecoding));\n        let requiredTypes = ast.elements.filter(e => !e.isOptional);\n        if (ast.rest.length > 0) {\n          requiredTypes = requiredTypes.concat(ast.rest.slice(1));\n        }\n        const requiredLen = requiredTypes.length;\n        const expectedIndexes = ast.elements.length > 0 ? ast.elements.map((_, i) => i).join(\" | \") : \"never\";\n        const concurrency = getConcurrency(ast);\n        const batching = getBatching(ast);\n        return (input, options) => {\n          if (!array_.isArray(input)) {\n            return Either.left(new Type(ast, input));\n          }\n          const allErrors = options?.errors === \"all\";\n          const es = [];\n          let stepKey = 0;\n          const output = [];\n          // ---------------------------------------------\n          // handle missing indexes\n          // ---------------------------------------------\n          const len = input.length;\n          for (let i = len; i <= requiredLen - 1; i++) {\n            const e = new Pointer(i, input, new Missing(requiredTypes[i - len]));\n            if (allErrors) {\n              es.push([stepKey++, e]);\n              continue;\n            } else {\n              return Either.left(new Composite(ast, input, e, output));\n            }\n          }\n          // ---------------------------------------------\n          // handle excess indexes\n          // ---------------------------------------------\n          if (ast.rest.length === 0) {\n            for (let i = ast.elements.length; i <= len - 1; i++) {\n              const e = new Pointer(i, input, new Unexpected(input[i], `is unexpected, expected: ${expectedIndexes}`));\n              if (allErrors) {\n                es.push([stepKey++, e]);\n                continue;\n              } else {\n                return Either.left(new Composite(ast, input, e, output));\n              }\n            }\n          }\n          let i = 0;\n          let queue = undefined;\n          // ---------------------------------------------\n          // handle elements\n          // ---------------------------------------------\n          for (; i < elements.length; i++) {\n            if (len < i + 1) {\n              if (ast.elements[i].isOptional) {\n                // the input element is missing\n                continue;\n              }\n            } else {\n              const parser = elements[i];\n              const te = parser(input[i], options);\n              const eu = eitherOrUndefined(te);\n              if (eu) {\n                if (Either.isLeft(eu)) {\n                  // the input element is present but is not valid\n                  const e = new Pointer(i, input, eu.left);\n                  if (allErrors) {\n                    es.push([stepKey++, e]);\n                    continue;\n                  } else {\n                    return Either.left(new Composite(ast, input, e, sortByIndex(output)));\n                  }\n                }\n                output.push([stepKey++, eu.right]);\n              } else {\n                const nk = stepKey++;\n                const index = i;\n                if (!queue) {\n                  queue = [];\n                }\n                queue.push(({\n                  es,\n                  output\n                }) => Effect.flatMap(Effect.either(te), t => {\n                  if (Either.isLeft(t)) {\n                    // the input element is present but is not valid\n                    const e = new Pointer(index, input, t.left);\n                    if (allErrors) {\n                      es.push([nk, e]);\n                      return Effect.void;\n                    } else {\n                      return Either.left(new Composite(ast, input, e, sortByIndex(output)));\n                    }\n                  }\n                  output.push([nk, t.right]);\n                  return Effect.void;\n                }));\n              }\n            }\n          }\n          // ---------------------------------------------\n          // handle rest element\n          // ---------------------------------------------\n          if (array_.isNonEmptyReadonlyArray(rest)) {\n            const [head, ...tail] = rest;\n            for (; i < len - tail.length; i++) {\n              const te = head(input[i], options);\n              const eu = eitherOrUndefined(te);\n              if (eu) {\n                if (Either.isLeft(eu)) {\n                  const e = new Pointer(i, input, eu.left);\n                  if (allErrors) {\n                    es.push([stepKey++, e]);\n                    continue;\n                  } else {\n                    return Either.left(new Composite(ast, input, e, sortByIndex(output)));\n                  }\n                } else {\n                  output.push([stepKey++, eu.right]);\n                }\n              } else {\n                const nk = stepKey++;\n                const index = i;\n                if (!queue) {\n                  queue = [];\n                }\n                queue.push(({\n                  es,\n                  output\n                }) => Effect.flatMap(Effect.either(te), t => {\n                  if (Either.isLeft(t)) {\n                    const e = new Pointer(index, input, t.left);\n                    if (allErrors) {\n                      es.push([nk, e]);\n                      return Effect.void;\n                    } else {\n                      return Either.left(new Composite(ast, input, e, sortByIndex(output)));\n                    }\n                  } else {\n                    output.push([nk, t.right]);\n                    return Effect.void;\n                  }\n                }));\n              }\n            }\n            // ---------------------------------------------\n            // handle post rest elements\n            // ---------------------------------------------\n            for (let j = 0; j < tail.length; j++) {\n              i += j;\n              if (len < i + 1) {\n                continue;\n              } else {\n                const te = tail[j](input[i], options);\n                const eu = eitherOrUndefined(te);\n                if (eu) {\n                  if (Either.isLeft(eu)) {\n                    // the input element is present but is not valid\n                    const e = new Pointer(i, input, eu.left);\n                    if (allErrors) {\n                      es.push([stepKey++, e]);\n                      continue;\n                    } else {\n                      return Either.left(new Composite(ast, input, e, sortByIndex(output)));\n                    }\n                  }\n                  output.push([stepKey++, eu.right]);\n                } else {\n                  const nk = stepKey++;\n                  const index = i;\n                  if (!queue) {\n                    queue = [];\n                  }\n                  queue.push(({\n                    es,\n                    output\n                  }) => Effect.flatMap(Effect.either(te), t => {\n                    if (Either.isLeft(t)) {\n                      // the input element is present but is not valid\n                      const e = new Pointer(index, input, t.left);\n                      if (allErrors) {\n                        es.push([nk, e]);\n                        return Effect.void;\n                      } else {\n                        return Either.left(new Composite(ast, input, e, sortByIndex(output)));\n                      }\n                    }\n                    output.push([nk, t.right]);\n                    return Effect.void;\n                  }));\n                }\n              }\n            }\n          }\n          // ---------------------------------------------\n          // compute result\n          // ---------------------------------------------\n          const computeResult = ({\n            es,\n            output\n          }) => array_.isNonEmptyArray(es) ? Either.left(new Composite(ast, input, sortByIndex(es), sortByIndex(output))) : Either.right(sortByIndex(output));\n          if (queue && queue.length > 0) {\n            const cqueue = queue;\n            return Effect.suspend(() => {\n              const state = {\n                es: array_.copy(es),\n                output: array_.copy(output)\n              };\n              return Effect.flatMap(Effect.forEach(cqueue, f => f(state), {\n                concurrency,\n                batching,\n                discard: true\n              }), () => computeResult(state));\n            });\n          }\n          return computeResult({\n            output,\n            es\n          });\n        };\n      }\n    case \"TypeLiteral\":\n      {\n        if (ast.propertySignatures.length === 0 && ast.indexSignatures.length === 0) {\n          return fromRefinement(ast, Predicate.isNotNullable);\n        }\n        const propertySignatures = [];\n        const expectedKeysMap = {};\n        const expectedKeys = [];\n        for (const ps of ast.propertySignatures) {\n          propertySignatures.push([goMemo(ps.type, isDecoding), ps]);\n          expectedKeysMap[ps.name] = null;\n          expectedKeys.push(ps.name);\n        }\n        const indexSignatures = ast.indexSignatures.map(is => [goMemo(is.parameter, isDecoding), goMemo(is.type, isDecoding), is.parameter]);\n        const expectedAST = AST.Union.make(ast.indexSignatures.map(is => is.parameter).concat(expectedKeys.map(key => Predicate.isSymbol(key) ? new AST.UniqueSymbol(key) : new AST.Literal(key))));\n        const expected = goMemo(expectedAST, isDecoding);\n        const concurrency = getConcurrency(ast);\n        const batching = getBatching(ast);\n        return (input, options) => {\n          if (!Predicate.isRecord(input)) {\n            return Either.left(new Type(ast, input));\n          }\n          const allErrors = options?.errors === \"all\";\n          const es = [];\n          let stepKey = 0;\n          // ---------------------------------------------\n          // handle excess properties\n          // ---------------------------------------------\n          const onExcessPropertyError = options?.onExcessProperty === \"error\";\n          const onExcessPropertyPreserve = options?.onExcessProperty === \"preserve\";\n          const output = {};\n          let inputKeys;\n          if (onExcessPropertyError || onExcessPropertyPreserve) {\n            inputKeys = util_.ownKeys(input);\n            for (const key of inputKeys) {\n              const eu = eitherOrUndefined(expected(key, options));\n              if (Either.isLeft(eu)) {\n                // key is unexpected\n                if (onExcessPropertyError) {\n                  const e = new Pointer(key, input, new Unexpected(input[key], `is unexpected, expected: ${String(expectedAST)}`));\n                  if (allErrors) {\n                    es.push([stepKey++, e]);\n                    continue;\n                  } else {\n                    return Either.left(new Composite(ast, input, e, output));\n                  }\n                } else {\n                  // preserve key\n                  output[key] = input[key];\n                }\n              }\n            }\n          }\n          let queue = undefined;\n          const isExact = options?.exact === true;\n          for (let i = 0; i < propertySignatures.length; i++) {\n            const ps = propertySignatures[i][1];\n            const name = ps.name;\n            const hasKey = Object.prototype.hasOwnProperty.call(input, name);\n            if (!hasKey) {\n              if (ps.isOptional) {\n                continue;\n              } else if (isExact) {\n                const e = new Pointer(name, input, new Missing(ps));\n                if (allErrors) {\n                  es.push([stepKey++, e]);\n                  continue;\n                } else {\n                  return Either.left(new Composite(ast, input, e, output));\n                }\n              }\n            }\n            const parser = propertySignatures[i][0];\n            const te = parser(input[name], options);\n            const eu = eitherOrUndefined(te);\n            if (eu) {\n              if (Either.isLeft(eu)) {\n                const e = new Pointer(name, input, hasKey ? eu.left : new Missing(ps));\n                if (allErrors) {\n                  es.push([stepKey++, e]);\n                  continue;\n                } else {\n                  return Either.left(new Composite(ast, input, e, output));\n                }\n              }\n              output[name] = eu.right;\n            } else {\n              const nk = stepKey++;\n              const index = name;\n              if (!queue) {\n                queue = [];\n              }\n              queue.push(({\n                es,\n                output\n              }) => Effect.flatMap(Effect.either(te), t => {\n                if (Either.isLeft(t)) {\n                  const e = new Pointer(index, input, hasKey ? t.left : new Missing(ps));\n                  if (allErrors) {\n                    es.push([nk, e]);\n                    return Effect.void;\n                  } else {\n                    return Either.left(new Composite(ast, input, e, output));\n                  }\n                }\n                output[index] = t.right;\n                return Effect.void;\n              }));\n            }\n          }\n          // ---------------------------------------------\n          // handle index signatures\n          // ---------------------------------------------\n          for (let i = 0; i < indexSignatures.length; i++) {\n            const indexSignature = indexSignatures[i];\n            const parameter = indexSignature[0];\n            const type = indexSignature[1];\n            const keys = util_.getKeysForIndexSignature(input, indexSignature[2]);\n            for (const key of keys) {\n              // ---------------------------------------------\n              // handle keys\n              // ---------------------------------------------\n              const keu = eitherOrUndefined(parameter(key, options));\n              if (keu && Either.isRight(keu)) {\n                // ---------------------------------------------\n                // handle values\n                // ---------------------------------------------\n                const vpr = type(input[key], options);\n                const veu = eitherOrUndefined(vpr);\n                if (veu) {\n                  if (Either.isLeft(veu)) {\n                    const e = new Pointer(key, input, veu.left);\n                    if (allErrors) {\n                      es.push([stepKey++, e]);\n                      continue;\n                    } else {\n                      return Either.left(new Composite(ast, input, e, output));\n                    }\n                  } else {\n                    if (!Object.prototype.hasOwnProperty.call(expectedKeysMap, key)) {\n                      output[key] = veu.right;\n                    }\n                  }\n                } else {\n                  const nk = stepKey++;\n                  const index = key;\n                  if (!queue) {\n                    queue = [];\n                  }\n                  queue.push(({\n                    es,\n                    output\n                  }) => Effect.flatMap(Effect.either(vpr), tv => {\n                    if (Either.isLeft(tv)) {\n                      const e = new Pointer(index, input, tv.left);\n                      if (allErrors) {\n                        es.push([nk, e]);\n                        return Effect.void;\n                      } else {\n                        return Either.left(new Composite(ast, input, e, output));\n                      }\n                    } else {\n                      if (!Object.prototype.hasOwnProperty.call(expectedKeysMap, key)) {\n                        output[key] = tv.right;\n                      }\n                      return Effect.void;\n                    }\n                  }));\n                }\n              }\n            }\n          }\n          // ---------------------------------------------\n          // compute result\n          // ---------------------------------------------\n          const computeResult = ({\n            es,\n            output\n          }) => {\n            if (array_.isNonEmptyArray(es)) {\n              return Either.left(new Composite(ast, input, sortByIndex(es), output));\n            }\n            if (options?.propertyOrder === \"original\") {\n              // preserve input keys order\n              const keys = inputKeys || util_.ownKeys(input);\n              for (const name of expectedKeys) {\n                if (keys.indexOf(name) === -1) {\n                  keys.push(name);\n                }\n              }\n              const out = {};\n              for (const key of keys) {\n                if (Object.prototype.hasOwnProperty.call(output, key)) {\n                  out[key] = output[key];\n                }\n              }\n              return Either.right(out);\n            }\n            return Either.right(output);\n          };\n          if (queue && queue.length > 0) {\n            const cqueue = queue;\n            return Effect.suspend(() => {\n              const state = {\n                es: array_.copy(es),\n                output: Object.assign({}, output)\n              };\n              return Effect.flatMap(Effect.forEach(cqueue, f => f(state), {\n                concurrency,\n                batching,\n                discard: true\n              }), () => computeResult(state));\n            });\n          }\n          return computeResult({\n            es,\n            output\n          });\n        };\n      }\n    case \"Union\":\n      {\n        const searchTree = getSearchTree(ast.types, isDecoding);\n        const ownKeys = util_.ownKeys(searchTree.keys);\n        const len = ownKeys.length;\n        const map = new Map();\n        for (let i = 0; i < ast.types.length; i++) {\n          map.set(ast.types[i], goMemo(ast.types[i], isDecoding));\n        }\n        const concurrency = getConcurrency(ast) ?? 1;\n        const batching = getBatching(ast);\n        return (input, options) => {\n          const es = [];\n          let stepKey = 0;\n          let candidates = [];\n          if (len > 0) {\n            // if there is at least one key then input must be an object\n            if (Predicate.isRecord(input)) {\n              for (let i = 0; i < len; i++) {\n                const name = ownKeys[i];\n                const buckets = searchTree.keys[name].buckets;\n                // for each property that should contain a literal, check if the input contains that property\n                if (Object.prototype.hasOwnProperty.call(input, name)) {\n                  const literal = String(input[name]);\n                  // check that the value obtained from the input for the property corresponds to an existing bucket\n                  if (Object.prototype.hasOwnProperty.call(buckets, literal)) {\n                    // retrive the minimal set of candidates for decoding\n                    candidates = candidates.concat(buckets[literal]);\n                  } else {\n                    const literals = AST.Union.make(searchTree.keys[name].literals);\n                    es.push([stepKey++, new Composite(new AST.TypeLiteral([new AST.PropertySignature(name, literals, false, true)], []), input, new Pointer(name, input, new Type(literals, input[name])))]);\n                  }\n                } else {\n                  const literals = AST.Union.make(searchTree.keys[name].literals);\n                  const fakeps = new AST.PropertySignature(name, literals, false, true); // TODO: inherit message annotation from the union?\n                  es.push([stepKey++, new Composite(new AST.TypeLiteral([fakeps], []), input, new Pointer(name, input, new Missing(fakeps)))]);\n                }\n              }\n            } else {\n              es.push([stepKey++, new Type(ast, input)]);\n            }\n          }\n          if (searchTree.otherwise.length > 0) {\n            candidates = candidates.concat(searchTree.otherwise);\n          }\n          let queue = undefined;\n          for (let i = 0; i < candidates.length; i++) {\n            const candidate = candidates[i];\n            const pr = map.get(candidate)(input, options);\n            // the members of a union are ordered based on which one should be decoded first,\n            // therefore if one member has added a task, all subsequent members must\n            // also add a task to the queue even if they are synchronous\n            const eu = !queue || queue.length === 0 ? eitherOrUndefined(pr) : undefined;\n            if (eu) {\n              if (Either.isRight(eu)) {\n                return Either.right(eu.right);\n              } else {\n                es.push([stepKey++, eu.left]);\n              }\n            } else {\n              const nk = stepKey++;\n              if (!queue) {\n                queue = [];\n              }\n              queue.push(state => Effect.suspend(() => {\n                if (\"finalResult\" in state) {\n                  return Effect.void;\n                } else {\n                  return Effect.flatMap(Effect.either(pr), t => {\n                    if (Either.isRight(t)) {\n                      state.finalResult = Either.right(t.right);\n                    } else {\n                      state.es.push([nk, t.left]);\n                    }\n                    return Effect.void;\n                  });\n                }\n              }));\n            }\n          }\n          // ---------------------------------------------\n          // compute result\n          // ---------------------------------------------\n          const computeResult = es => array_.isNonEmptyArray(es) ? es.length === 1 && es[0][1]._tag === \"Type\" ? Either.left(es[0][1]) : Either.left(new Composite(ast, input, sortByIndex(es))) :\n          // this should never happen\n          Either.left(new Type(ast, input));\n          if (queue && queue.length > 0) {\n            const cqueue = queue;\n            return Effect.suspend(() => {\n              const state = {\n                es: array_.copy(es)\n              };\n              return Effect.flatMap(Effect.forEach(cqueue, f => f(state), {\n                concurrency,\n                batching,\n                discard: true\n              }), () => {\n                if (\"finalResult\" in state) {\n                  return state.finalResult;\n                }\n                return computeResult(state.es);\n              });\n            });\n          }\n          return computeResult(es);\n        };\n      }\n    case \"Suspend\":\n      {\n        const get = util_.memoizeThunk(() => goMemo(AST.annotations(ast.f(), ast.annotations), isDecoding));\n        return (a, options) => get()(a, options);\n      }\n  }\n};\nconst fromRefinement = (ast, refinement) => u => refinement(u) ? Either.right(u) : Either.left(new Type(ast, u));\n/** @internal */\nexport const getLiterals = (ast, isDecoding) => {\n  switch (ast._tag) {\n    case \"Declaration\":\n      {\n        const annotation = AST.getSurrogateAnnotation(ast);\n        if (Option.isSome(annotation)) {\n          return getLiterals(annotation.value, isDecoding);\n        }\n        break;\n      }\n    case \"TypeLiteral\":\n      {\n        const out = [];\n        for (let i = 0; i < ast.propertySignatures.length; i++) {\n          const propertySignature = ast.propertySignatures[i];\n          const type = isDecoding ? AST.encodedAST(propertySignature.type) : AST.typeAST(propertySignature.type);\n          if (AST.isLiteral(type) && !propertySignature.isOptional) {\n            out.push([propertySignature.name, type]);\n          }\n        }\n        return out;\n      }\n    case \"Refinement\":\n      return getLiterals(ast.from, isDecoding);\n    case \"Suspend\":\n      return getLiterals(ast.f(), isDecoding);\n    case \"Transformation\":\n      return getLiterals(isDecoding ? ast.from : ast.to, isDecoding);\n  }\n  return [];\n};\n/**\n * The purpose of the algorithm is to narrow down the pool of possible candidates for decoding as much as possible.\n *\n * This function separates the schemas into two groups, `keys` and `otherwise`:\n *\n * - `keys`: the schema has at least one property with a literal value\n * - `otherwise`: the schema has no properties with a literal value\n *\n * If a schema has at least one property with a literal value, so it ends up in `keys`, first a namespace is created for\n * the name of the property containing the literal, and then within this namespace a \"bucket\" is created for the literal\n * value in which to store all the schemas that have the same property and literal value.\n *\n * @internal\n */\nexport const getSearchTree = (members, isDecoding) => {\n  const keys = {};\n  const otherwise = [];\n  for (let i = 0; i < members.length; i++) {\n    const member = members[i];\n    const tags = getLiterals(member, isDecoding);\n    if (tags.length > 0) {\n      for (let j = 0; j < tags.length; j++) {\n        const [key, literal] = tags[j];\n        const hash = String(literal.literal);\n        keys[key] = keys[key] || {\n          buckets: {},\n          literals: []\n        };\n        const buckets = keys[key].buckets;\n        if (Object.prototype.hasOwnProperty.call(buckets, hash)) {\n          if (j < tags.length - 1) {\n            continue;\n          }\n          buckets[hash].push(member);\n          keys[key].literals.push(literal);\n        } else {\n          buckets[hash] = [member];\n          keys[key].literals.push(literal);\n          break;\n        }\n      }\n    } else {\n      otherwise.push(member);\n    }\n  }\n  return {\n    keys,\n    otherwise\n  };\n};\nconst dropRightRefinement = ast => AST.isRefinement(ast) ? dropRightRefinement(ast.from) : ast;\nconst handleForbidden = (effect, ast, actual, options) => {\n  const eu = eitherOrUndefined(effect);\n  if (eu) {\n    return eu;\n  }\n  if (options?.isEffectAllowed === true) {\n    return effect;\n  }\n  try {\n    return Effect.runSync(Effect.either(effect));\n  } catch (e) {\n    return Either.left(new Forbidden(ast, actual, \"cannot be be resolved synchronously, this is caused by using runSync on an effect that performs async work\"));\n  }\n};\nconst compare = ([a], [b]) => a > b ? 1 : a < b ? -1 : 0;\nfunction sortByIndex(es) {\n  return es.sort(compare).map(t => t[1]);\n}\n// -------------------------------------------------------------------------------------\n// transformations interpreter\n// -------------------------------------------------------------------------------------\n/** @internal */\nexport const getFinalTransformation = (transformation, isDecoding) => {\n  switch (transformation._tag) {\n    case \"FinalTransformation\":\n      return isDecoding ? transformation.decode : transformation.encode;\n    case \"ComposeTransformation\":\n      return Either.right;\n    case \"TypeLiteralTransformation\":\n      return input => {\n        let out = Either.right(input);\n        // ---------------------------------------------\n        // handle property signature transformations\n        // ---------------------------------------------\n        for (const pst of transformation.propertySignatureTransformations) {\n          const [from, to] = isDecoding ? [pst.from, pst.to] : [pst.to, pst.from];\n          const transformation = isDecoding ? pst.decode : pst.encode;\n          const f = input => {\n            const o = transformation(Object.prototype.hasOwnProperty.call(input, from) ? Option.some(input[from]) : Option.none());\n            delete input[from];\n            if (Option.isSome(o)) {\n              input[to] = o.value;\n            }\n            return input;\n          };\n          out = map(out, f);\n        }\n        return out;\n      };\n  }\n};\n//# sourceMappingURL=ParseResult.js.map","/**\n * @since 0.67.0\n */\nimport * as Arr from \"effect/Array\";\nimport * as Option from \"effect/Option\";\nimport * as AST from \"./AST.js\";\nimport * as errors_ from \"./internal/errors.js\";\nimport * as util_ from \"./internal/util.js\";\nimport * as ParseResult from \"./ParseResult.js\";\n/**\n * @category hooks\n * @since 0.67.0\n */\nexport const PrettyHookId = /*#__PURE__*/Symbol.for(\"@effect/schema/PrettyHookId\");\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const pretty = handler => self => self.annotations({\n  [PrettyHookId]: handler\n});\n/**\n * @category prettify\n * @since 0.67.0\n */\nexport const make = schema => compile(schema.ast, []);\nconst getHook = /*#__PURE__*/AST.getAnnotation(PrettyHookId);\nconst getMatcher = defaultPretty => ast => Option.match(getHook(ast), {\n  onNone: () => defaultPretty,\n  onSome: handler => handler()\n});\nconst toString = /*#__PURE__*/getMatcher(a => String(a));\nconst stringify = /*#__PURE__*/getMatcher(a => JSON.stringify(a));\nconst formatUnknown = /*#__PURE__*/getMatcher(util_.formatUnknown);\n/**\n * @since 0.67.0\n */\nexport const match = {\n  \"Declaration\": (ast, go, path) => {\n    const hook = getHook(ast);\n    if (Option.isSome(hook)) {\n      return hook.value(...ast.typeParameters.map(tp => go(tp, path)));\n    }\n    throw new Error(errors_.getPrettyMissingAnnotationErrorMessage(path, ast));\n  },\n  \"VoidKeyword\": /*#__PURE__*/getMatcher(() => \"void(0)\"),\n  \"NeverKeyword\": /*#__PURE__*/getMatcher(() => {\n    throw new Error(errors_.getPrettyNeverErrorMessage);\n  }),\n  \"Literal\": /*#__PURE__*/getMatcher(literal => typeof literal === \"bigint\" ? `${String(literal)}n` : JSON.stringify(literal)),\n  \"SymbolKeyword\": toString,\n  \"UniqueSymbol\": toString,\n  \"TemplateLiteral\": stringify,\n  \"UndefinedKeyword\": toString,\n  \"UnknownKeyword\": formatUnknown,\n  \"AnyKeyword\": formatUnknown,\n  \"ObjectKeyword\": formatUnknown,\n  \"StringKeyword\": stringify,\n  \"NumberKeyword\": toString,\n  \"BooleanKeyword\": toString,\n  \"BigIntKeyword\": /*#__PURE__*/getMatcher(a => `${String(a)}n`),\n  \"Enums\": stringify,\n  \"TupleType\": (ast, go, path) => {\n    const hook = getHook(ast);\n    if (Option.isSome(hook)) {\n      return hook.value();\n    }\n    const elements = ast.elements.map((e, i) => go(e.type, path.concat(i)));\n    const rest = ast.rest.map(annotatedAST => go(annotatedAST.type, path));\n    return input => {\n      const output = [];\n      let i = 0;\n      // ---------------------------------------------\n      // handle elements\n      // ---------------------------------------------\n      for (; i < elements.length; i++) {\n        if (input.length < i + 1) {\n          if (ast.elements[i].isOptional) {\n            continue;\n          }\n        } else {\n          output.push(elements[i](input[i]));\n        }\n      }\n      // ---------------------------------------------\n      // handle rest element\n      // ---------------------------------------------\n      if (Arr.isNonEmptyReadonlyArray(rest)) {\n        const [head, ...tail] = rest;\n        for (; i < input.length - tail.length; i++) {\n          output.push(head(input[i]));\n        }\n        // ---------------------------------------------\n        // handle post rest elements\n        // ---------------------------------------------\n        for (let j = 0; j < tail.length; j++) {\n          i += j;\n          output.push(tail[j](input[i]));\n        }\n      }\n      return \"[\" + output.join(\", \") + \"]\";\n    };\n  },\n  \"TypeLiteral\": (ast, go, path) => {\n    const hook = getHook(ast);\n    if (Option.isSome(hook)) {\n      return hook.value();\n    }\n    const propertySignaturesTypes = ast.propertySignatures.map(ps => go(ps.type, path.concat(ps.name)));\n    const indexSignatureTypes = ast.indexSignatures.map(is => go(is.type, path));\n    const expectedKeys = {};\n    for (let i = 0; i < propertySignaturesTypes.length; i++) {\n      expectedKeys[ast.propertySignatures[i].name] = null;\n    }\n    return input => {\n      const output = [];\n      // ---------------------------------------------\n      // handle property signatures\n      // ---------------------------------------------\n      for (let i = 0; i < propertySignaturesTypes.length; i++) {\n        const ps = ast.propertySignatures[i];\n        const name = ps.name;\n        if (ps.isOptional && !Object.prototype.hasOwnProperty.call(input, name)) {\n          continue;\n        }\n        output.push(`${util_.formatPropertyKey(name)}: ${propertySignaturesTypes[i](input[name])}`);\n      }\n      // ---------------------------------------------\n      // handle index signatures\n      // ---------------------------------------------\n      if (indexSignatureTypes.length > 0) {\n        for (let i = 0; i < indexSignatureTypes.length; i++) {\n          const type = indexSignatureTypes[i];\n          const keys = util_.getKeysForIndexSignature(input, ast.indexSignatures[i].parameter);\n          for (const key of keys) {\n            if (Object.prototype.hasOwnProperty.call(expectedKeys, key)) {\n              continue;\n            }\n            output.push(`${util_.formatPropertyKey(key)}: ${type(input[key])}`);\n          }\n        }\n      }\n      return Arr.isNonEmptyReadonlyArray(output) ? \"{ \" + output.join(\", \") + \" }\" : \"{}\";\n    };\n  },\n  \"Union\": (ast, go, path) => {\n    const hook = getHook(ast);\n    if (Option.isSome(hook)) {\n      return hook.value();\n    }\n    const types = ast.types.map(ast => [ParseResult.is({\n      ast\n    }), go(ast, path)]);\n    return a => {\n      const index = types.findIndex(([is]) => is(a));\n      if (index === -1) {\n        throw new Error(errors_.getPrettyNoMatchingSchemaErrorMessage(a, path, ast));\n      }\n      return types[index][1](a);\n    };\n  },\n  \"Suspend\": (ast, go, path) => {\n    return Option.match(getHook(ast), {\n      onNone: () => {\n        const get = util_.memoizeThunk(() => go(ast.f(), path));\n        return a => get()(a);\n      },\n      onSome: handler => handler()\n    });\n  },\n  \"Refinement\": (ast, go, path) => {\n    return Option.match(getHook(ast), {\n      onNone: () => go(ast.from, path),\n      onSome: handler => handler()\n    });\n  },\n  \"Transformation\": (ast, go, path) => {\n    return Option.match(getHook(ast), {\n      onNone: () => go(ast.to, path),\n      onSome: handler => handler()\n    });\n  }\n};\nconst compile = /*#__PURE__*/AST.getCompiler(match);\n//# sourceMappingURL=Pretty.js.map","/**\n * @since 0.67.0\n */\nimport * as array_ from \"effect/Array\";\nimport * as bigDecimal_ from \"effect/BigDecimal\";\nimport * as bigInt_ from \"effect/BigInt\";\nimport * as boolean_ from \"effect/Boolean\";\nimport * as cause_ from \"effect/Cause\";\nimport * as chunk_ from \"effect/Chunk\";\nimport * as config_ from \"effect/Config\";\nimport * as configError_ from \"effect/ConfigError\";\nimport * as data_ from \"effect/Data\";\nimport * as duration_ from \"effect/Duration\";\nimport * as Effect from \"effect/Effect\";\nimport * as either_ from \"effect/Either\";\nimport * as Encoding from \"effect/Encoding\";\nimport * as Equal from \"effect/Equal\";\nimport * as Equivalence from \"effect/Equivalence\";\nimport * as exit_ from \"effect/Exit\";\nimport * as fiberId_ from \"effect/FiberId\";\nimport { dual, identity } from \"effect/Function\";\nimport * as hashMap_ from \"effect/HashMap\";\nimport * as hashSet_ from \"effect/HashSet\";\nimport * as list_ from \"effect/List\";\nimport * as number_ from \"effect/Number\";\nimport * as option_ from \"effect/Option\";\nimport { pipeArguments } from \"effect/Pipeable\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as redacted_ from \"effect/Redacted\";\nimport * as Request from \"effect/Request\";\nimport * as sortedSet_ from \"effect/SortedSet\";\nimport * as string_ from \"effect/String\";\nimport * as arbitrary_ from \"./Arbitrary.js\";\nimport * as AST from \"./AST.js\";\nimport * as equivalence_ from \"./Equivalence.js\";\nimport * as fastCheck_ from \"./FastCheck.js\";\nimport * as errors_ from \"./internal/errors.js\";\nimport * as filters_ from \"./internal/filters.js\";\nimport * as serializable_ from \"./internal/serializable.js\";\nimport * as util_ from \"./internal/util.js\";\nimport * as ParseResult from \"./ParseResult.js\";\nimport * as pretty_ from \"./Pretty.js\";\nimport * as TreeFormatter from \"./TreeFormatter.js\";\n/**\n * @since 0.67.0\n * @category symbol\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/Schema\");\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const make = ast => class SchemaClass {\n  [TypeId] = variance;\n  static Type;\n  static Encoded;\n  static [TypeId] = variance;\n  static ast = ast;\n  static annotations(annotations) {\n    return make(mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static pipe() {\n    return pipeArguments(this, arguments);\n  }\n  static toString() {\n    return String(ast);\n  }\n};\nconst variance = {\n  /* c8 ignore next */\n  _A: _ => _,\n  /* c8 ignore next */\n  _I: _ => _,\n  /* c8 ignore next */\n  _R: _ => _\n};\nconst toASTAnnotations = annotations => {\n  if (!annotations) {\n    return {};\n  }\n  const out = {};\n  // symbols are reserved for custom annotations\n  const custom = Object.getOwnPropertySymbols(annotations);\n  for (const sym of custom) {\n    out[sym] = annotations[sym];\n  }\n  // string keys are reserved as /schema namespace\n  if (annotations.typeId !== undefined) {\n    const typeId = annotations.typeId;\n    if (typeof typeId === \"object\") {\n      out[AST.TypeAnnotationId] = typeId.id;\n      out[typeId.id] = typeId.annotation;\n    } else {\n      out[AST.TypeAnnotationId] = typeId;\n    }\n  }\n  const move = (from, to) => {\n    if (annotations[from] !== undefined) {\n      out[to] = annotations[from];\n    }\n  };\n  move(\"message\", AST.MessageAnnotationId);\n  move(\"missingMessage\", AST.MissingMessageAnnotationId);\n  move(\"identifier\", AST.IdentifierAnnotationId);\n  move(\"title\", AST.TitleAnnotationId);\n  move(\"description\", AST.DescriptionAnnotationId);\n  move(\"examples\", AST.ExamplesAnnotationId);\n  move(\"default\", AST.DefaultAnnotationId);\n  move(\"documentation\", AST.DocumentationAnnotationId);\n  move(\"jsonSchema\", AST.JSONSchemaAnnotationId);\n  move(\"arbitrary\", arbitrary_.ArbitraryHookId);\n  move(\"pretty\", pretty_.PrettyHookId);\n  move(\"equivalence\", equivalence_.EquivalenceHookId);\n  move(\"concurrency\", AST.ConcurrencyAnnotationId);\n  move(\"batching\", AST.BatchingAnnotationId);\n  move(\"parseIssueTitle\", AST.ParseIssueTitleAnnotationId);\n  move(\"parseOptions\", AST.ParseOptionsAnnotationId);\n  return out;\n};\nconst mergeSchemaAnnotations = (ast, annotations) => AST.annotations(ast, toASTAnnotations(annotations));\n/**\n * @since 0.67.0\n */\nexport const asSchema = schema => schema;\n/**\n * @category formatting\n * @since 0.67.0\n */\nexport const format = schema => String(schema.ast);\n/**\n * The `encodedSchema` function allows you to extract the `Encoded` portion of a\n * schema, creating a new schema that conforms to the properties defined in the\n * original schema without retaining any refinements or transformations that\n * were applied previously.\n *\n * @since 0.67.0\n */\nexport const encodedSchema = schema => make(AST.encodedAST(schema.ast));\n/**\n * The `encodedBoundSchema` function is similar to `encodedSchema` but preserves\n * the refinements up to the first transformation point in the original schema.\n *\n * @since 0.67.17\n */\nexport const encodedBoundSchema = schema => make(AST.encodedBoundAST(schema.ast));\n/**\n * The `typeSchema` function allows you to extract the `Type` portion of a\n * schema, creating a new schema that conforms to the properties defined in the\n * original schema without considering the initial encoding or transformation\n * processes.\n *\n * @since 0.67.0\n */\nexport const typeSchema = schema => make(AST.typeAST(schema.ast));\n/* c8 ignore start */\nexport {\n/**\n * By default the option `exact` is set to `true`.\n *\n * @throws `ParseError`\n * @category validation\n * @since 0.67.0\n */\nasserts,\n/**\n * @category decoding\n * @since 0.67.0\n */\ndecodeOption,\n/**\n * @throws `ParseError`\n * @category decoding\n * @since 0.67.0\n */\ndecodeSync,\n/**\n * @category decoding\n * @since 0.67.0\n */\ndecodeUnknownOption,\n/**\n * @throws `ParseError`\n * @category decoding\n * @since 0.67.0\n */\ndecodeUnknownSync,\n/**\n * @category encoding\n * @since 0.67.0\n */\nencodeOption,\n/**\n * @throws `ParseError`\n * @category encoding\n * @since 0.67.0\n */\nencodeSync,\n/**\n * @category encoding\n * @since 0.67.0\n */\nencodeUnknownOption,\n/**\n * @throws `ParseError`\n * @category encoding\n * @since 0.67.0\n */\nencodeUnknownSync,\n/**\n * By default the option `exact` is set to `true`.\n *\n * @category validation\n * @since 0.67.0\n */\nis,\n/**\n * @category validation\n * @since 0.67.0\n */\nvalidateOption,\n/**\n * @throws `ParseError`\n * @category validation\n * @since 0.67.0\n */\nvalidateSync } from \"./ParseResult.js\";\n/* c8 ignore end */\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeUnknown = (schema, options) => {\n  const encodeUnknown = ParseResult.encodeUnknown(schema, options);\n  return (u, overrideOptions) => ParseResult.mapError(encodeUnknown(u, overrideOptions), ParseResult.parseError);\n};\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeUnknownEither = (schema, options) => {\n  const encodeUnknownEither = ParseResult.encodeUnknownEither(schema, options);\n  return (u, overrideOptions) => either_.mapLeft(encodeUnknownEither(u, overrideOptions), ParseResult.parseError);\n};\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeUnknownPromise = (schema, options) => {\n  const parser = encodeUnknown(schema, options);\n  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));\n};\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encode = encodeUnknown;\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodeEither = encodeUnknownEither;\n/**\n * @category encoding\n * @since 0.67.0\n */\nexport const encodePromise = encodeUnknownPromise;\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeUnknown = (schema, options) => {\n  const decodeUnknown = ParseResult.decodeUnknown(schema, options);\n  return (u, overrideOptions) => ParseResult.mapError(decodeUnknown(u, overrideOptions), ParseResult.parseError);\n};\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeUnknownEither = (schema, options) => {\n  const decodeUnknownEither = ParseResult.decodeUnknownEither(schema, options);\n  return (u, overrideOptions) => either_.mapLeft(decodeUnknownEither(u, overrideOptions), ParseResult.parseError);\n};\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeUnknownPromise = (schema, options) => {\n  const parser = decodeUnknown(schema, options);\n  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));\n};\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decode = decodeUnknown;\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodeEither = decodeUnknownEither;\n/**\n * @category decoding\n * @since 0.67.0\n */\nexport const decodePromise = decodeUnknownPromise;\n/**\n * @category validation\n * @since 0.67.0\n */\nexport const validate = (schema, options) => {\n  const validate = ParseResult.validate(schema, options);\n  return (u, overrideOptions) => ParseResult.mapError(validate(u, overrideOptions), ParseResult.parseError);\n};\n/**\n * @category validation\n * @since 0.67.0\n */\nexport const validateEither = (schema, options) => {\n  const validateEither = ParseResult.validateEither(schema, options);\n  return (u, overrideOptions) => either_.mapLeft(validateEither(u, overrideOptions), ParseResult.parseError);\n};\n/**\n * @category validation\n * @since 0.67.0\n */\nexport const validatePromise = (schema, options) => {\n  const parser = validate(schema, options);\n  return (u, overrideOptions) => Effect.runPromise(parser(u, overrideOptions));\n};\n/**\n * Tests if a value is a `Schema`.\n *\n * @category guards\n * @since 0.67.0\n */\nexport const isSchema = u => Predicate.hasProperty(u, TypeId) && Predicate.isObject(u[TypeId]);\nconst getDefaultLiteralAST = literals => AST.isMembers(literals) ? AST.Union.make(AST.mapMembers(literals, literal => new AST.Literal(literal))) : new AST.Literal(literals[0]);\nconst makeLiteralClass = (literals, ast = getDefaultLiteralAST(literals)) => class LiteralClass extends make(ast) {\n  static annotations(annotations) {\n    return makeLiteralClass(this.literals, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static literals = [...literals];\n};\nexport function Literal(...literals) {\n  return array_.isNonEmptyReadonlyArray(literals) ? makeLiteralClass(literals) : Never;\n}\n/**\n * Creates a new `Schema` from a literal schema.\n *\n * @example\n * import * as S from \"@effect/schema/Schema\"\n * import { Either } from \"effect\"\n *\n * const schema = S.Literal(\"a\", \"b\", \"c\").pipe(S.pickLiteral(\"a\", \"b\"))\n *\n * assert.deepStrictEqual(S.decodeSync(schema)(\"a\"), \"a\")\n * assert.deepStrictEqual(S.decodeSync(schema)(\"b\"), \"b\")\n * assert.strictEqual(Either.isLeft(S.decodeUnknownEither(schema)(\"c\")), true)\n *\n * @category constructors\n * @since 0.67.0\n */\nexport const pickLiteral = (...literals) => _schema => Literal(...literals);\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const UniqueSymbolFromSelf = symbol => make(new AST.UniqueSymbol(symbol));\nconst getDefaultEnumsAST = enums => new AST.Enums(Object.keys(enums).filter(key => typeof enums[enums[key]] !== \"number\").map(key => [key, enums[key]]));\nconst makeEnumsClass = (enums, ast = getDefaultEnumsAST(enums)) => class EnumsClass extends make(ast) {\n  static annotations(annotations) {\n    return makeEnumsClass(this.enums, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static enums = {\n    ...enums\n  };\n};\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const Enums = enums => makeEnumsClass(enums);\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const TemplateLiteral = (...[head, ...tail]) => {\n  let astOrs = getTemplateLiterals(getTemplateLiteralParameterAST(head));\n  for (const span of tail) {\n    astOrs = array_.flatMap(astOrs, a => getTemplateLiterals(getTemplateLiteralParameterAST(span)).map(b => combineTemplateLiterals(a, b)));\n  }\n  return make(AST.Union.make(astOrs.map(astOr => Predicate.isString(astOr) ? new AST.Literal(astOr) : astOr)));\n};\nconst getTemplateLiteralParameterAST = span => isSchema(span) ? span.ast : new AST.Literal(String(span));\nconst combineTemplateLiterals = (a, b) => {\n  if (Predicate.isString(a)) {\n    return Predicate.isString(b) ? a + b : new AST.TemplateLiteral(a + b.head, b.spans);\n  }\n  if (Predicate.isString(b)) {\n    return new AST.TemplateLiteral(a.head, array_.modifyNonEmptyLast(a.spans, span => new AST.TemplateLiteralSpan(span.type, span.literal + b)));\n  }\n  return new AST.TemplateLiteral(a.head, array_.appendAll(array_.modifyNonEmptyLast(a.spans, span => new AST.TemplateLiteralSpan(span.type, span.literal + String(b.head))), b.spans));\n};\nconst getTemplateLiterals = ast => {\n  switch (ast._tag) {\n    case \"Literal\":\n      return [String(ast.literal)];\n    case \"NumberKeyword\":\n    case \"StringKeyword\":\n      return [new AST.TemplateLiteral(\"\", [new AST.TemplateLiteralSpan(ast, \"\")])];\n    case \"Union\":\n      return array_.flatMap(ast.types, getTemplateLiterals);\n  }\n  throw new Error(errors_.getSchemaUnsupportedLiteralSpanErrorMessage(ast));\n};\nconst declareConstructor = (typeParameters, options, annotations) => make(new AST.Declaration(typeParameters.map(tp => tp.ast), (...typeParameters) => options.decode(...typeParameters.map(make)), (...typeParameters) => options.encode(...typeParameters.map(make)), toASTAnnotations(annotations)));\nconst declarePrimitive = (is, annotations) => {\n  const decodeUnknown = () => (input, _, ast) => is(input) ? ParseResult.succeed(input) : ParseResult.fail(new ParseResult.Type(ast, input));\n  const encodeUnknown = decodeUnknown;\n  return make(new AST.Declaration([], decodeUnknown, encodeUnknown, toASTAnnotations(annotations)));\n};\n/**\n * The constraint `R extends Schema.Context<P[number]>` enforces dependencies solely from `typeParameters`.\n * This ensures that when you call `Schema.to` or `Schema.from`, you receive a schema with a `never` context.\n *\n * @category constructors\n * @since 0.67.0\n */\nexport const declare = function () {\n  if (Array.isArray(arguments[0])) {\n    const typeParameters = arguments[0];\n    const options = arguments[1];\n    const annotations = arguments[2];\n    return declareConstructor(typeParameters, options, annotations);\n  }\n  const is = arguments[0];\n  const annotations = arguments[1];\n  return declarePrimitive(is, annotations);\n};\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const BrandTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Brand\");\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const fromBrand = (constructor, annotations) => self => makeBrandClass(new AST.Refinement(self.ast, function predicate(a, _, ast) {\n  const either = constructor.either(a);\n  return either_.isLeft(either) ? option_.some(new ParseResult.Type(ast, a, either.left.map(v => v.message).join(\", \"))) : option_.none();\n}, toASTAnnotations({\n  typeId: {\n    id: BrandTypeId,\n    annotation: {\n      constructor\n    }\n  },\n  ...annotations\n})));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const InstanceOfTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/InstanceOf\");\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const instanceOf = (constructor, annotations) => declare(u => u instanceof constructor, {\n  title: constructor.name,\n  description: `an instance of ${constructor.name}`,\n  pretty: () => String,\n  typeId: {\n    id: InstanceOfTypeId,\n    annotation: {\n      constructor\n    }\n  },\n  ...annotations\n});\n/**\n * @category primitives\n * @since 0.67.0\n */\nexport class Undefined extends make(AST.undefinedKeyword) {\n  static annotations = super.annotations;\n}\n/**\n * @category primitives\n * @since 0.67.0\n */\nexport class Void extends make(AST.voidKeyword) {\n  static annotations = super.annotations;\n}\n/**\n * @category primitives\n * @since 0.67.0\n */\nexport class Null extends make(AST.null) {\n  static annotations = super.annotations;\n}\n/**\n * @category primitives\n * @since 0.67.0\n */\nexport class Never extends make(AST.neverKeyword) {\n  static annotations = super.annotations;\n}\n/**\n * @category primitives\n * @since 0.67.0\n */\nexport class Unknown extends make(AST.unknownKeyword) {\n  static annotations = super.annotations;\n}\n/**\n * @category primitives\n * @since 0.67.0\n */\nexport class Any extends make(AST.anyKeyword) {\n  static annotations = super.annotations;\n}\n/**\n * @category primitives\n * @since 0.67.0\n */\nexport class BigIntFromSelf extends make(AST.bigIntKeyword) {\n  static annotations = super.annotations;\n}\n/**\n * @category primitives\n * @since 0.67.0\n */\nexport class SymbolFromSelf extends make(AST.symbolKeyword) {\n  static annotations = super.annotations;\n}\n/** @ignore */\nclass String$ extends make(AST.stringKeyword) {\n  static annotations = super.annotations;\n}\n/** @ignore */\nclass Number$ extends make(AST.numberKeyword) {\n  static annotations = super.annotations;\n}\n/** @ignore */\nclass Boolean$ extends make(AST.booleanKeyword) {\n  static annotations = super.annotations;\n}\n/** @ignore */\nclass Object$ extends make(AST.objectKeyword) {\n  static annotations = super.annotations;\n}\nexport {\n/**\n * @category primitives\n * @since 0.67.0\n */\nBoolean$ as Boolean,\n/**\n * @category primitives\n * @since 0.67.0\n */\nNumber$ as Number,\n/**\n * @category primitives\n * @since 0.67.0\n */\nObject$ as Object,\n/**\n * @category primitives\n * @since 0.67.0\n */\nString$ as String };\nconst getDefaultUnionAST = members => AST.Union.members(members.map(m => m.ast));\nconst makeUnionClass = (members, ast = getDefaultUnionAST(members)) => class UnionClass extends make(ast) {\n  static annotations(annotations) {\n    return makeUnionClass(this.members, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static members = [...members];\n};\nexport function Union(...members) {\n  return AST.isMembers(members) ? makeUnionClass(members) : array_.isNonEmptyReadonlyArray(members) ? members[0] : Never;\n}\n/**\n * @category combinators\n * @since 0.67.0\n */\nexport const NullOr = self => Union(self, Null);\n/**\n * @category combinators\n * @since 0.67.0\n */\nexport const UndefinedOr = self => Union(self, Undefined);\n/**\n * @category combinators\n * @since 0.67.0\n */\nexport const NullishOr = self => Union(self, Null, Undefined);\n/**\n * @category combinators\n * @since 0.67.0\n */\nexport const keyof = self => make(AST.keyof(self.ast));\n/**\n * @since 0.68.0\n */\nexport const element = self => new ElementImpl(new AST.OptionalType(self.ast, false), self);\n/**\n * @since 0.67.0\n */\nexport const optionalElement = self => new ElementImpl(new AST.OptionalType(self.ast, true), self);\nclass ElementImpl {\n  ast;\n  from;\n  [TypeId];\n  _Token;\n  constructor(ast, from) {\n    this.ast = ast;\n    this.from = from;\n  }\n  annotations(annotations) {\n    return new ElementImpl(new AST.OptionalType(this.ast.type, this.ast.isOptional, {\n      ...this.ast.annotations,\n      ...toASTAnnotations(annotations)\n    }), this.from);\n  }\n  toString() {\n    return `${this.ast.type}${this.ast.isOptional ? \"?\" : \"\"}`;\n  }\n}\nconst getDefaultTupleTypeAST = (elements, rest) => new AST.TupleType(elements.map(el => isSchema(el) ? new AST.OptionalType(el.ast, false) : el.ast), rest.map(el => isSchema(el) ? new AST.Type(el.ast) : el.ast), true);\nconst makeTupleTypeClass = (elements, rest, ast = getDefaultTupleTypeAST(elements, rest)) => class TupleTypeClass extends make(ast) {\n  static annotations(annotations) {\n    return makeTupleTypeClass(this.elements, this.rest, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static elements = [...elements];\n  static rest = [...rest];\n};\nexport function Tuple(...args) {\n  return Array.isArray(args[0]) ? makeTupleTypeClass(args[0], args.slice(1)) : makeTupleTypeClass(args, []);\n}\nconst makeArrayClass = (value, ast) => class ArrayClass extends makeTupleTypeClass([], [value], ast) {\n  static annotations(annotations) {\n    return makeArrayClass(this.value, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static value = value;\n};\nconst Array$ = value => makeArrayClass(value);\nexport {\n/**\n * @category constructors\n * @since 0.67.0\n */\nArray$ as Array };\nconst makeNonEmptyArrayClass = (value, ast) => class NonEmptyArrayClass extends makeTupleTypeClass([value], [value], ast) {\n  static annotations(annotations) {\n    return makeNonEmptyArrayClass(this.value, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static value = value;\n};\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const NonEmptyArray = value => makeNonEmptyArrayClass(value);\nconst formatPropertySignatureToken = isOptional => isOptional ? \"\\\"?:\\\"\" : \"\\\":\\\"\";\n/**\n * @category PropertySignature\n * @since 0.67.0\n */\nexport class PropertySignatureDeclaration extends AST.OptionalType {\n  isReadonly;\n  defaultValue;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"PropertySignatureDeclaration\";\n  constructor(type, isOptional, isReadonly, annotations, defaultValue) {\n    super(type, isOptional, annotations);\n    this.isReadonly = isReadonly;\n    this.defaultValue = defaultValue;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    const token = formatPropertySignatureToken(this.isOptional);\n    const type = String(this.type);\n    return `PropertySignature<${token}, ${type}, never, ${token}, ${type}>`;\n  }\n}\n/**\n * @category PropertySignature\n * @since 0.67.0\n */\nexport class FromPropertySignature extends AST.OptionalType {\n  isReadonly;\n  fromKey;\n  constructor(type, isOptional, isReadonly, annotations, fromKey) {\n    super(type, isOptional, annotations);\n    this.isReadonly = isReadonly;\n    this.fromKey = fromKey;\n  }\n}\n/**\n * @category PropertySignature\n * @since 0.67.0\n */\nexport class ToPropertySignature extends AST.OptionalType {\n  isReadonly;\n  defaultValue;\n  constructor(type, isOptional, isReadonly, annotations, defaultValue) {\n    super(type, isOptional, annotations);\n    this.isReadonly = isReadonly;\n    this.defaultValue = defaultValue;\n  }\n}\nconst formatPropertyKey = p => {\n  if (p === undefined) {\n    return \"never\";\n  }\n  if (Predicate.isString(p)) {\n    return JSON.stringify(p);\n  }\n  return String(p);\n};\n/**\n * @category PropertySignature\n * @since 0.67.0\n */\nexport class PropertySignatureTransformation {\n  from;\n  to;\n  decode;\n  encode;\n  /**\n   * @since 0.67.0\n   */\n  _tag = \"PropertySignatureTransformation\";\n  constructor(from, to, decode, encode) {\n    this.from = from;\n    this.to = to;\n    this.decode = decode;\n    this.encode = encode;\n  }\n  /**\n   * @since 0.67.0\n   */\n  toString() {\n    return `PropertySignature<${formatPropertySignatureToken(this.to.isOptional)}, ${this.to.type}, ${formatPropertyKey(this.from.fromKey)}, ${formatPropertySignatureToken(this.from.isOptional)}, ${this.from.type}>`;\n  }\n}\nconst mergeSignatureAnnotations = (ast, annotations) => {\n  switch (ast._tag) {\n    case \"PropertySignatureDeclaration\":\n      {\n        return new PropertySignatureDeclaration(ast.type, ast.isOptional, ast.isReadonly, {\n          ...ast.annotations,\n          ...annotations\n        }, ast.defaultValue);\n      }\n    case \"PropertySignatureTransformation\":\n      {\n        return new PropertySignatureTransformation(new FromPropertySignature(ast.from.type, ast.from.isOptional, ast.from.isReadonly, ast.from.annotations), new ToPropertySignature(ast.to.type, ast.to.isOptional, ast.to.isReadonly, {\n          ...ast.to.annotations,\n          ...annotations\n        }, ast.to.defaultValue), ast.decode, ast.encode);\n      }\n  }\n};\n/**\n * @since 0.68.0\n * @category symbol\n */\nexport const PropertySignatureTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/PropertySignature\");\nclass PropertySignatureImpl {\n  ast;\n  [TypeId];\n  [PropertySignatureTypeId] = null;\n  _TypeToken;\n  _Key;\n  _EncodedToken;\n  _HasDefault;\n  constructor(ast) {\n    this.ast = ast;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  annotations(annotations) {\n    return new PropertySignatureImpl(mergeSignatureAnnotations(this.ast, toASTAnnotations(annotations)));\n  }\n  toString() {\n    return String(this.ast);\n  }\n}\n/**\n * @category PropertySignature\n * @since 0.67.15\n */\nexport const makePropertySignature = ast => new PropertySignatureImpl(ast);\nclass PropertySignatureWithFromImpl extends PropertySignatureImpl {\n  from;\n  constructor(ast, from) {\n    super(ast);\n    this.from = from;\n  }\n  annotations(annotations) {\n    return new PropertySignatureWithFromImpl(mergeSignatureAnnotations(this.ast, toASTAnnotations(annotations)), this.from);\n  }\n}\n/**\n * Lifts a `Schema` into a `PropertySignature`.\n *\n * @category PropertySignature\n * @since 0.67.0\n */\nexport const propertySignature = self => new PropertySignatureWithFromImpl(new PropertySignatureDeclaration(self.ast, false, true, {}, undefined), self);\n/**\n * Enhances a property signature with a default constructor value.\n *\n * @category PropertySignature\n * @since 0.67.0\n */\nexport const withConstructorDefault = /*#__PURE__*/dual(2, (self, defaultValue) => {\n  const ast = self.ast;\n  switch (ast._tag) {\n    case \"PropertySignatureDeclaration\":\n      return makePropertySignature(new PropertySignatureDeclaration(ast.type, ast.isOptional, ast.isReadonly, ast.annotations, defaultValue));\n    case \"PropertySignatureTransformation\":\n      return makePropertySignature(new PropertySignatureTransformation(ast.from, new ToPropertySignature(ast.to.type, ast.to.isOptional, ast.to.isReadonly, ast.to.annotations, defaultValue), ast.decode, ast.encode));\n  }\n});\nconst applyDefaultValue = (o, defaultValue) => option_.match(o, {\n  onNone: () => option_.some(defaultValue()),\n  onSome: value => option_.some(value === undefined ? defaultValue() : value)\n});\n/**\n * Enhances a property signature with a default decoding value.\n *\n * @category PropertySignature\n * @since 0.67.0\n */\nexport const withDecodingDefault = /*#__PURE__*/dual(2, (self, defaultValue) => {\n  const ast = self.ast;\n  switch (ast._tag) {\n    case \"PropertySignatureDeclaration\":\n      return makePropertySignature(new PropertySignatureTransformation(ast, new ToPropertySignature(AST.typeAST(ast.type), false, true, {}, undefined), o => applyDefaultValue(o, defaultValue), identity));\n    case \"PropertySignatureTransformation\":\n      return makePropertySignature(new PropertySignatureTransformation(ast.from, new ToPropertySignature(ast.to.type, false, ast.to.isReadonly, ast.to.annotations, ast.to.defaultValue), o => applyDefaultValue(ast.decode(o), defaultValue), ast.encode));\n  }\n});\n/**\n * Enhances a property signature with a default decoding value and a default constructor value.\n *\n * @category PropertySignature\n * @since 0.67.0\n */\nexport const withDefaults = /*#__PURE__*/dual(2, (self, defaults) => self.pipe(withDecodingDefault(defaults.decoding), withConstructorDefault(defaults.constructor)));\n/**\n * Enhances a property signature by specifying a different key for it in the Encoded type.\n *\n * @category PropertySignature\n * @since 0.67.0\n */\nexport const fromKey = /*#__PURE__*/dual(2, (self, key) => {\n  const ast = self.ast;\n  switch (ast._tag) {\n    case \"PropertySignatureDeclaration\":\n      {\n        return makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(ast.type, ast.isOptional, ast.isReadonly, ast.annotations, key), new ToPropertySignature(AST.typeAST(ast.type), ast.isOptional, ast.isReadonly, {}, ast.defaultValue), identity, identity));\n      }\n    case \"PropertySignatureTransformation\":\n      return makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(ast.from.type, ast.from.isOptional, ast.from.isReadonly, ast.from.annotations, key), ast.to, ast.decode, ast.encode));\n  }\n});\n/**\n * Converts an optional property to a required one through a transformation `Option -> Type`.\n *\n * - `decode`: `none` as argument means the value is missing in the input.\n * - `encode`: `none` as return value means the value will be missing in the output.\n *\n * @category PropertySignature\n * @since 0.67.0\n */\nexport const optionalToRequired = (from, to, options) => makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(from.ast, true, true, {}, undefined), new ToPropertySignature(to.ast, false, true, {}, undefined), o => option_.some(options.decode(o)), option_.flatMap(options.encode)));\n/**\n * Converts an optional property to a required one through a transformation `Type -> Option`.\n *\n * - `decode`: `none` as return value means the value will be missing in the output.\n * - `encode`: `none` as argument means the value is missing in the input.\n *\n * @category PropertySignature\n * @since 0.67.15\n */\nexport const requiredToOptional = (from, to, options) => makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(from.ast, false, true, {}, undefined), new ToPropertySignature(to.ast, true, true, {}, undefined), option_.flatMap(options.decode), o => option_.some(options.encode(o))));\n/**\n * Converts an optional property to another optional property through a transformation `Option -> Option`.\n *\n * - `decode`:\n *   - `none` as argument means the value is missing in the input.\n *   - `none` as return value means the value will be missing in the output.\n * - `encode`:\n *   - `none` as argument means the value is missing in the input.\n *   - `none` as return value means the value will be missing in the output.\n *\n * @category PropertySignature\n * @since 0.67.0\n */\nexport const optionalToOptional = (from, to, options) => makePropertySignature(new PropertySignatureTransformation(new FromPropertySignature(from.ast, true, true, {}, undefined), new ToPropertySignature(to.ast, true, true, {}, undefined), options.decode, options.encode));\nconst optionalPropertySignatureAST = (from, options) => {\n  const isExact = options?.exact;\n  const defaultValue = options?.default;\n  const isNullable = options?.nullable;\n  const asOption = options?.as == \"Option\";\n  const asOptionEncode = options?.onNoneEncoding ? option_.orElse(options.onNoneEncoding) : identity;\n  if (isExact) {\n    if (defaultValue) {\n      if (isNullable) {\n        return withConstructorDefault(optionalToRequired(NullOr(from), typeSchema(from), {\n          decode: option_.match({\n            onNone: defaultValue,\n            onSome: a => a === null ? defaultValue() : a\n          }),\n          encode: option_.some\n        }), defaultValue).ast;\n      } else {\n        return withConstructorDefault(optionalToRequired(from, typeSchema(from), {\n          decode: option_.match({\n            onNone: defaultValue,\n            onSome: identity\n          }),\n          encode: option_.some\n        }), defaultValue).ast;\n      }\n    } else if (asOption) {\n      if (isNullable) {\n        return optionalToRequired(NullOr(from), OptionFromSelf(typeSchema(from)), {\n          decode: option_.filter(Predicate.isNotNull),\n          encode: asOptionEncode\n        }).ast;\n      } else {\n        return optionalToRequired(from, OptionFromSelf(typeSchema(from)), {\n          decode: identity,\n          encode: identity\n        }).ast;\n      }\n    } else {\n      if (isNullable) {\n        return optionalToOptional(NullOr(from), typeSchema(from), {\n          decode: option_.filter(Predicate.isNotNull),\n          encode: identity\n        }).ast;\n      } else {\n        return new PropertySignatureDeclaration(from.ast, true, true, {}, undefined);\n      }\n    }\n  } else {\n    if (defaultValue) {\n      if (isNullable) {\n        return withConstructorDefault(optionalToRequired(NullishOr(from), typeSchema(from), {\n          decode: option_.match({\n            onNone: defaultValue,\n            onSome: a => a == null ? defaultValue() : a\n          }),\n          encode: option_.some\n        }), defaultValue).ast;\n      } else {\n        return withConstructorDefault(optionalToRequired(UndefinedOr(from), typeSchema(from), {\n          decode: option_.match({\n            onNone: defaultValue,\n            onSome: a => a === undefined ? defaultValue() : a\n          }),\n          encode: option_.some\n        }), defaultValue).ast;\n      }\n    } else if (asOption) {\n      if (isNullable) {\n        return optionalToRequired(NullishOr(from), OptionFromSelf(typeSchema(from)), {\n          decode: option_.filter(a => a != null),\n          encode: asOptionEncode\n        }).ast;\n      } else {\n        return optionalToRequired(UndefinedOr(from), OptionFromSelf(typeSchema(from)), {\n          decode: option_.filter(Predicate.isNotUndefined),\n          encode: asOptionEncode\n        }).ast;\n      }\n    } else {\n      if (isNullable) {\n        return optionalToOptional(NullishOr(from), UndefinedOr(typeSchema(from)), {\n          decode: option_.filter(Predicate.isNotNull),\n          encode: identity\n        }).ast;\n      } else {\n        return new PropertySignatureDeclaration(UndefinedOr(from).ast, true, true, {}, undefined);\n      }\n    }\n  }\n};\n/**\n * @category PropertySignature\n * @since 0.67.0\n */\nexport const optional = /*#__PURE__*/dual(args => isSchema(args[0]), (from, options) => {\n  // Note: `Schema.All extends S ? \"you can't...` is used to prevent the case where `optional` is implicitly applied.\n  // For example: `S.String.pipe(S.optional)` would result in `S.String` being inferred as `Schema.All`,\n  // which is not the intended behavior. This is mostly an aesthetic consideration, so if it causes issues, we can remove it.\n  return new PropertySignatureWithFromImpl(optionalPropertySignatureAST(from, options), from);\n});\nconst isPropertySignature = u => Predicate.hasProperty(u, PropertySignatureTypeId);\nconst getDefaultTypeLiteralAST = (fields, records) => {\n  const ownKeys = util_.ownKeys(fields);\n  const pss = [];\n  if (ownKeys.length > 0) {\n    const from = [];\n    const to = [];\n    const transformations = [];\n    for (let i = 0; i < ownKeys.length; i++) {\n      const key = ownKeys[i];\n      const field = fields[key];\n      if (isPropertySignature(field)) {\n        const ast = field.ast;\n        switch (ast._tag) {\n          case \"PropertySignatureDeclaration\":\n            {\n              const type = ast.type;\n              const isOptional = ast.isOptional;\n              const toAnnotations = ast.annotations;\n              from.push(new AST.PropertySignature(key, type, isOptional, true));\n              to.push(new AST.PropertySignature(key, AST.typeAST(type), isOptional, true, toAnnotations));\n              pss.push(new AST.PropertySignature(key, type, isOptional, true, toAnnotations));\n              break;\n            }\n          case \"PropertySignatureTransformation\":\n            {\n              const fromKey = ast.from.fromKey ?? key;\n              from.push(new AST.PropertySignature(fromKey, ast.from.type, ast.from.isOptional, true, ast.from.annotations));\n              to.push(new AST.PropertySignature(key, ast.to.type, ast.to.isOptional, true, ast.to.annotations));\n              transformations.push(new AST.PropertySignatureTransformation(fromKey, key, ast.decode, ast.encode));\n              break;\n            }\n        }\n      } else {\n        from.push(new AST.PropertySignature(key, field.ast, false, true));\n        to.push(new AST.PropertySignature(key, AST.typeAST(field.ast), false, true));\n        pss.push(new AST.PropertySignature(key, field.ast, false, true));\n      }\n    }\n    if (array_.isNonEmptyReadonlyArray(transformations)) {\n      const issFrom = [];\n      const issTo = [];\n      for (const r of records) {\n        const {\n          indexSignatures,\n          propertySignatures\n        } = AST.record(r.key.ast, r.value.ast);\n        propertySignatures.forEach(ps => {\n          from.push(ps);\n          to.push(new AST.PropertySignature(ps.name, AST.typeAST(ps.type), ps.isOptional, ps.isReadonly, ps.annotations));\n        });\n        indexSignatures.forEach(is => {\n          issFrom.push(is);\n          issTo.push(new AST.IndexSignature(is.parameter, AST.typeAST(is.type), is.isReadonly));\n        });\n      }\n      return new AST.Transformation(new AST.TypeLiteral(from, issFrom, {\n        [AST.TitleAnnotationId]: \"Struct (Encoded side)\"\n      }), new AST.TypeLiteral(to, issTo, {\n        [AST.TitleAnnotationId]: \"Struct (Type side)\"\n      }), new AST.TypeLiteralTransformation(transformations));\n    }\n  }\n  const iss = [];\n  for (const r of records) {\n    const {\n      indexSignatures,\n      propertySignatures\n    } = AST.record(r.key.ast, r.value.ast);\n    propertySignatures.forEach(ps => pss.push(ps));\n    indexSignatures.forEach(is => iss.push(is));\n  }\n  return new AST.TypeLiteral(pss, iss);\n};\nconst lazilyMergeDefaults = (fields, out) => {\n  const ownKeys = util_.ownKeys(fields);\n  for (const key of ownKeys) {\n    const field = fields[key];\n    if (out[key] === undefined && isPropertySignature(field)) {\n      const ast = field.ast;\n      const defaultValue = ast._tag === \"PropertySignatureDeclaration\" ? ast.defaultValue : ast.to.defaultValue;\n      if (defaultValue !== undefined) {\n        out[key] = defaultValue();\n      }\n    }\n  }\n  return out;\n};\nconst makeTypeLiteralClass = (fields, records, ast = getDefaultTypeLiteralAST(fields, records)) => {\n  return class TypeLiteralClass extends make(ast) {\n    static annotations(annotations) {\n      return makeTypeLiteralClass(this.fields, this.records, mergeSchemaAnnotations(this.ast, annotations));\n    }\n    static fields = {\n      ...fields\n    };\n    static records = [...records];\n    static make = (props, options) => {\n      const propsWithDefaults = lazilyMergeDefaults(fields, {\n        ...props\n      });\n      return getDisableValidationMakeOption(options) ? propsWithDefaults : ParseResult.validateSync(this)(propsWithDefaults);\n    };\n  };\n};\nexport function Struct(fields, ...records) {\n  return makeTypeLiteralClass(fields, records);\n}\n/**\n * Returns a property signature that represents a tag.\n * A tag is a literal value that is used to distinguish between different types of objects.\n * The tag is optional when using the `make` method.\n *\n * @see {@link TaggedStruct}\n *\n * @example\n * import { Schema } from \"@effect/schema\"\n *\n * const User = Schema.Struct({\n *   _tag: Schema.tag(\"User\"),\n *   name: Schema.String,\n *   age: Schema.Number\n * })\n *\n * assert.deepStrictEqual(User.make({ name: \"John\", age: 44 }), { _tag: \"User\", name: \"John\", age: 44 })\n *\n * @since 0.67.14\n */\nexport const tag = tag => Literal(tag).pipe(propertySignature, withConstructorDefault(() => tag));\n/**\n * A tagged struct is a struct that has a tag property that is used to distinguish between different types of objects.\n *\n * The tag is optional when using the `make` method.\n *\n * @example\n * import { Schema } from \"@effect/schema\"\n *\n * const User = Schema.TaggedStruct(\"User\", {\n *   name: Schema.String,\n *   age: Schema.Number\n * })\n *\n * assert.deepStrictEqual(User.make({ name: \"John\", age: 44 }), { _tag: \"User\", name: \"John\", age: 44 })\n *\n * @category constructors\n * @since 0.67.14\n */\nexport const TaggedStruct = (value, fields) => Struct({\n  _tag: tag(value),\n  ...fields\n});\nconst makeRecordClass = (key, value, ast) => class RecordClass extends makeTypeLiteralClass({}, [{\n  key,\n  value\n}], ast) {\n  static annotations(annotations) {\n    return makeRecordClass(key, value, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static key = key;\n  static value = value;\n};\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const Record = (key, value) => makeRecordClass(key, value);\n/**\n * @category struct transformations\n * @since 0.67.0\n */\nexport const pick = (...keys) => self => make(AST.pick(self.ast, keys));\n/**\n * @category struct transformations\n * @since 0.67.0\n */\nexport const omit = (...keys) => self => make(AST.omit(self.ast, keys));\n/**\n * Given a schema `Schema<A, I, R>` and a key `key: K`, this function extracts a specific field from the `A` type,\n * producing a new schema that represents a transformation from the `{ readonly [key]: I[K] }` type to `A[K]`.\n *\n * @example\n * import * as S from \"@effect/schema/Schema\"\n *\n * // ---------------------------------------------\n * // use case: pull out a single field from a\n * // struct through a transformation\n * // ---------------------------------------------\n *\n * const mytable = S.Struct({\n *   column1: S.NumberFromString,\n *   column2: S.Number\n * })\n *\n * // const pullOutColumn: S.Schema<number, {\n * //     readonly column1: string;\n * // }, never>\n * const pullOutColumn = mytable.pipe(S.pluck(\"column1\"))\n *\n * console.log(S.decodeUnknownEither(S.Array(pullOutColumn))([{ column1: \"1\", column2: 100 }, { column1: \"2\", column2: 300 }]))\n * // Output: { _id: 'Either', _tag: 'Right', right: [ 1, 2 ] }\n *\n * @category struct transformations\n * @since 0.67.0\n */\nexport const pluck = /*#__PURE__*/dual(2, (schema, key) => {\n  const ps = AST.getPropertyKeyIndexedAccess(AST.typeAST(schema.ast), key);\n  const value = make(ps.isOptional ? AST.orUndefined(ps.type) : ps.type);\n  return transform(schema.pipe(pick(key)), value, {\n    decode: a => a[key],\n    encode: ak => ps.isOptional && ak === undefined ? {} : {\n      [key]: ak\n    }\n  });\n});\nconst makeBrandClass = ast => class BrandClass extends make(ast) {\n  static annotations(annotations) {\n    return makeBrandClass(mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static make = (a, options) => {\n    return getDisableValidationMakeOption(options) ? a : ParseResult.validateSync(this)(a);\n  };\n};\n/**\n * Returns a nominal branded schema by applying a brand to a given schema.\n *\n * ```\n * Schema<A> + B -> Schema<A & Brand<B>>\n * ```\n *\n * @param self - The input schema to be combined with the brand.\n * @param brand - The brand to apply.\n *\n * @example\n * import * as Schema from \"@effect/schema/Schema\"\n *\n * const Int = Schema.Number.pipe(Schema.int(), Schema.brand(\"Int\"))\n * type Int = Schema.Schema.Type<typeof Int> // number & Brand<\"Int\">\n *\n * @category branding\n * @since 0.67.0\n */\nexport const brand = (brand, annotations) => self => {\n  const annotation = option_.match(AST.getBrandAnnotation(self.ast), {\n    onNone: () => [brand],\n    onSome: brands => [...brands, brand]\n  });\n  const ast = AST.annotations(self.ast, toASTAnnotations({\n    // add a default title annotation containing the brand\n    title: String(self.ast) + ` & Brand<${util_.formatUnknown(brand)}>`,\n    ...annotations,\n    [AST.BrandAnnotationId]: annotation\n  }));\n  return makeBrandClass(ast);\n};\n/**\n * @category combinators\n * @since 0.67.0\n */\nexport const partial = /*#__PURE__*/dual(args => isSchema(args[0]), (self, options) => make(AST.partial(self.ast, options)));\n/**\n * @category combinators\n * @since 0.67.0\n */\nexport const required = self => make(AST.required(self.ast));\n/**\n * Creates a new schema with shallow mutability applied to its properties.\n *\n * @param schema - The original schema to make properties mutable (shallowly).\n *\n * @category combinators\n * @since 0.67.0\n */\nexport const mutable = schema => make(AST.mutable(schema.ast));\nconst intersectTypeLiterals = (x, y, path) => {\n  if (AST.isTypeLiteral(x) && AST.isTypeLiteral(y)) {\n    const propertySignatures = [...x.propertySignatures];\n    for (const ps of y.propertySignatures) {\n      const name = ps.name;\n      const i = propertySignatures.findIndex(ps => ps.name === name);\n      if (i === -1) {\n        propertySignatures.push(ps);\n      } else {\n        const {\n          isOptional,\n          type\n        } = propertySignatures[i];\n        propertySignatures[i] = new AST.PropertySignature(name, extendAST(type, ps.type, path.concat(name)), isOptional, true);\n      }\n    }\n    return new AST.TypeLiteral(propertySignatures, x.indexSignatures.concat(y.indexSignatures));\n  }\n  throw new Error(errors_.getSchemaExtendErrorMessage(x, y, path));\n};\nconst addRefinementToMembers = (refinement, asts) => asts.map(ast => new AST.Refinement(ast, refinement.filter,\n// preserve message annotation\noption_.match(AST.getMessageAnnotation(refinement), {\n  onNone: () => undefined,\n  onSome: message => ({\n    [AST.MessageAnnotationId]: message\n  })\n})));\nconst extendAST = (x, y, path) => AST.Union.make(intersectUnionMembers([x], [y], path));\nconst getTypes = ast => AST.isUnion(ast) ? ast.types : [ast];\nconst intersectUnionMembers = (xs, ys, path) => array_.flatMap(xs, x => array_.flatMap(ys, y => {\n  switch (x._tag) {\n    case \"Union\":\n      return intersectUnionMembers(x.types, getTypes(y), path);\n    case \"Suspend\":\n      return [new AST.Suspend(() => extendAST(x.f(), y, path))];\n    case \"Refinement\":\n      return addRefinementToMembers(x, intersectUnionMembers(getTypes(x.from), getTypes(y), path));\n    case \"TypeLiteral\":\n      {\n        switch (y._tag) {\n          case \"Union\":\n            return intersectUnionMembers([x], y.types, path);\n          case \"Suspend\":\n            return [new AST.Suspend(() => extendAST(x, y.f(), path))];\n          case \"Refinement\":\n            return addRefinementToMembers(y, intersectUnionMembers([x], getTypes(y.from), path));\n          case \"TypeLiteral\":\n            return [intersectTypeLiterals(x, y, path)];\n          case \"Transformation\":\n            {\n              if (AST.isTypeLiteralTransformation(y.transformation)) {\n                return [new AST.Transformation(intersectTypeLiterals(x, y.from, path), intersectTypeLiterals(AST.typeAST(x), y.to, path), new AST.TypeLiteralTransformation(y.transformation.propertySignatureTransformations))];\n              }\n              break;\n            }\n        }\n        break;\n      }\n    case \"Transformation\":\n      {\n        if (AST.isTypeLiteralTransformation(x.transformation)) {\n          switch (y._tag) {\n            case \"TypeLiteral\":\n              return [new AST.Transformation(intersectTypeLiterals(x.from, y, path), intersectTypeLiterals(x.to, AST.typeAST(y), path), new AST.TypeLiteralTransformation(x.transformation.propertySignatureTransformations))];\n            case \"Transformation\":\n              {\n                if (AST.isTypeLiteralTransformation(y.transformation)) {\n                  return [new AST.Transformation(intersectTypeLiterals(x.from, y.from, path), intersectTypeLiterals(x.to, y.to, path), new AST.TypeLiteralTransformation(x.transformation.propertySignatureTransformations.concat(y.transformation.propertySignatureTransformations)))];\n                }\n              }\n              break;\n          }\n        }\n        break;\n      }\n  }\n  throw new Error(errors_.getSchemaExtendErrorMessage(x, y, path));\n}));\n/**\n * Extends a schema by adding additional fields or index signatures.\n *\n * 1) It only supports **structs**, refinements of structs, unions of structs, suspensions of structs\n * (informally `Supported = Struct | Refinement of Supported | Union of Supported | suspend(() => Supported)`)\n * 2) The arguments must represent disjoint types (e.g., `extend(Struct({ a: String }), Struct({ a: String })))` raises an error)\n *\n * @example\n * import * as Schema from \"@effect/schema/Schema\"\n *\n * const schema = Schema.Struct({\n *   a: Schema.String,\n *   b: Schema.String\n * })\n *\n * // const extended: S.Schema<{\n * //     readonly [x: string]: string;\n * //     readonly a: string;\n * //     readonly b: string;\n * //     readonly c: string;\n * // }>\n * const extended = Schema.asSchema(schema.pipe(\n *   Schema.extend(Schema.Struct({ c: Schema.String })), // <= you can add more fields\n *   Schema.extend(Schema.Record(Schema.String, Schema.String)) // <= you can add index signatures\n * ))\n *\n * @category combinators\n * @since 0.67.0\n */\nexport const extend = /*#__PURE__*/dual(2, (self, that) => make(extendAST(self.ast, that.ast, [])));\n/**\n * @category combinators\n * @since 0.67.0\n */\nexport const compose = /*#__PURE__*/dual(args => isSchema(args[1]), (from, to) => make(AST.compose(from.ast, to.ast)));\n/**\n * @category constructors\n * @since 0.67.0\n */\nexport const suspend = f => make(new AST.Suspend(() => f().ast));\nconst makeRefineClass = (from, filter, ast) => class RefineClass extends make(ast) {\n  static annotations(annotations) {\n    return makeRefineClass(this.from, this.filter, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static from = from;\n  static filter = filter;\n  static make = (a, options) => {\n    return getDisableValidationMakeOption(options) ? a : ParseResult.validateSync(this)(a);\n  };\n};\nconst fromFilterPredicateReturnTypeItem = (item, ast, input) => {\n  if (Predicate.isBoolean(item)) {\n    return item ? option_.none() : option_.some(new ParseResult.Type(ast, input));\n  }\n  if (Predicate.isString(item)) {\n    return option_.some(new ParseResult.Type(ast, input, item));\n  }\n  if (item !== undefined) {\n    if (\"_tag\" in item) {\n      return option_.some(item);\n    }\n    const issue = new ParseResult.Type(ast, input, item.message);\n    return option_.some(array_.isNonEmptyReadonlyArray(item.path) ? new ParseResult.Pointer(item.path, input, issue) : issue);\n  }\n  return option_.none();\n};\nconst toFilterParseIssue = (out, ast, input) => {\n  if (util_.isSingle(out)) {\n    return fromFilterPredicateReturnTypeItem(out, ast, input);\n  }\n  if (array_.isNonEmptyReadonlyArray(out)) {\n    const issues = array_.filterMap(out, issue => fromFilterPredicateReturnTypeItem(issue, ast, input));\n    if (array_.isNonEmptyReadonlyArray(issues)) {\n      return option_.some(issues.length === 1 ? issues[0] : new ParseResult.Composite(ast, input, issues));\n    }\n  }\n  return option_.none();\n};\nexport function filter(predicate, annotations) {\n  return self => {\n    function filter(input, options, ast) {\n      return toFilterParseIssue(predicate(input, options, ast), ast, input);\n    }\n    const ast = new AST.Refinement(self.ast, filter, toASTAnnotations(annotations));\n    return makeRefineClass(self, filter, ast);\n  };\n}\nconst makeTransformationClass = (from, to, ast) => class TransformationClass extends make(ast) {\n  static annotations(annotations) {\n    return makeTransformationClass(this.from, this.to, mergeSchemaAnnotations(this.ast, annotations));\n  }\n  static from = from;\n  static to = to;\n};\n/**\n * Create a new `Schema` by transforming the input and output of an existing `Schema`\n * using the provided decoding functions.\n *\n * @category combinators\n * @since 0.67.0\n */\nexport const transformOrFail = /*#__PURE__*/dual(args => isSchema(args[0]) && isSchema(args[1]), (from, to, options) => makeTransformationClass(from, to, new AST.Transformation(from.ast, to.ast, new AST.FinalTransformation(options.decode, options.encode))));\n/**\n * Create a new `Schema` by transforming the input and output of an existing `Schema`\n * using the provided mapping functions.\n *\n * @category combinators\n * @since 0.67.0\n */\nexport const transform = /*#__PURE__*/dual(args => isSchema(args[0]) && isSchema(args[1]), (from, to, options) => transformOrFail(from, to, {\n  decode: fromA => ParseResult.succeed(options.decode(fromA)),\n  encode: toI => ParseResult.succeed(options.encode(toI))\n}));\n/**\n * Creates a new `Schema` which transforms literal values.\n *\n * @example\n * import * as S from \"@effect/schema/Schema\"\n *\n * const schema = S.transformLiteral(0, \"a\")\n *\n * assert.deepStrictEqual(S.decodeSync(schema)(0), \"a\")\n *\n * @category constructors\n * @since 0.67.0\n */\nexport const transformLiteral = (from, to) => transform(Literal(from), Literal(to), {\n  decode: () => to,\n  encode: () => from\n});\nexport function transformLiterals(...pairs) {\n  return Union(...pairs.map(([from, to]) => transformLiteral(from, to)));\n}\n/**\n * Attaches a property signature with the specified key and value to the schema.\n * This API is useful when you want to add a property to your schema which doesn't describe the shape of the input,\n * but rather maps to another schema, for example when you want to add a discriminant to a simple union.\n *\n * @param self - The input schema.\n * @param key - The name of the property to add to the schema.\n * @param value - The value of the property to add to the schema.\n *\n * @example\n * import * as S from \"@effect/schema/Schema\"\n * import { pipe } from \"effect/Function\"\n *\n * const Circle = S.Struct({ radius: S.Number })\n * const Square = S.Struct({ sideLength: S.Number })\n * const Shape = S.Union(\n *   Circle.pipe(S.attachPropertySignature(\"kind\", \"circle\")),\n *   Square.pipe(S.attachPropertySignature(\"kind\", \"square\"))\n * )\n *\n * assert.deepStrictEqual(S.decodeSync(Shape)({ radius: 10 }), {\n *   kind: \"circle\",\n *   radius: 10\n * })\n *\n * @category combinators\n * @since 0.67.0\n */\nexport const attachPropertySignature = /*#__PURE__*/dual(args => isSchema(args[0]), (schema, key, value, annotations) => {\n  const ast = extend(typeSchema(schema), Struct({\n    [key]: Predicate.isSymbol(value) ? UniqueSymbolFromSelf(value) : Literal(value)\n  })).ast;\n  return make(new AST.Transformation(schema.ast, annotations ? mergeSchemaAnnotations(ast, annotations) : ast, new AST.TypeLiteralTransformation([new AST.PropertySignatureTransformation(key, key, () => option_.some(value), () => option_.none())])));\n});\n/**\n * @category annotations\n * @since 0.67.0\n */\nexport const annotations = /*#__PURE__*/dual(2, (self, annotations) => self.annotations(annotations));\n/**\n * @category renaming\n * @since 0.67.0\n */\nexport const rename = /*#__PURE__*/dual(2, (self, mapping) => make(AST.rename(self.ast, mapping)));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const TrimmedTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Trimmed\");\n/**\n * Verifies that a string contains no leading or trailing whitespaces.\n *\n * Note. This combinator does not make any transformations, it only validates.\n * If what you were looking for was a combinator to trim strings, then check out the `trim` combinator.\n *\n * @category string filters\n * @since 0.67.0\n */\nexport const trimmed = annotations => self => self.pipe(filter(a => a === a.trim(), {\n  typeId: TrimmedTypeId,\n  description: \"a string with no leading or trailing whitespace\",\n  jsonSchema: {\n    pattern: \"^\\\\S[\\\\s\\\\S]*\\\\S$|^\\\\S$|^$\"\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const MaxLengthTypeId = filters_.MaxLengthTypeId;\n/**\n * @category string filters\n * @since 0.67.0\n */\nexport const maxLength = (maxLength, annotations) => self => self.pipe(filter(a => a.length <= maxLength, {\n  typeId: MaxLengthTypeId,\n  description: `a string at most ${maxLength} character(s) long`,\n  jsonSchema: {\n    maxLength\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const MinLengthTypeId = filters_.MinLengthTypeId;\n/**\n * @category string filters\n * @since 0.67.0\n */\nexport const minLength = (minLength, annotations) => self => self.pipe(filter(a => a.length >= minLength, {\n  typeId: MinLengthTypeId,\n  description: `a string at least ${minLength} character(s) long`,\n  jsonSchema: {\n    minLength\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const PatternTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Pattern\");\n/**\n * @category string filters\n * @since 0.67.0\n */\nexport const pattern = (regex, annotations) => self => {\n  const pattern = regex.source;\n  return self.pipe(filter(a => {\n    // The following line ensures that `lastIndex` is reset to `0` in case the user has specified the `g` flag\n    regex.lastIndex = 0;\n    return regex.test(a);\n  }, {\n    typeId: {\n      id: PatternTypeId,\n      annotation: {\n        regex\n      }\n    },\n    description: `a string matching the pattern ${pattern}`,\n    jsonSchema: {\n      pattern\n    },\n    arbitrary: () => fc => fc.stringMatching(regex),\n    ...annotations\n  }));\n};\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const StartsWithTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/StartsWith\");\n/**\n * @category string filters\n * @since 0.67.0\n */\nexport const startsWith = (startsWith, annotations) => self => self.pipe(filter(a => a.startsWith(startsWith), {\n  typeId: {\n    id: StartsWithTypeId,\n    annotation: {\n      startsWith\n    }\n  },\n  description: `a string starting with ${JSON.stringify(startsWith)}`,\n  jsonSchema: {\n    pattern: `^${startsWith}`\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const EndsWithTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/EndsWith\");\n/**\n * @category string filters\n * @since 0.67.0\n */\nexport const endsWith = (endsWith, annotations) => self => self.pipe(filter(a => a.endsWith(endsWith), {\n  typeId: {\n    id: EndsWithTypeId,\n    annotation: {\n      endsWith\n    }\n  },\n  description: `a string ending with ${JSON.stringify(endsWith)}`,\n  jsonSchema: {\n    pattern: `^.*${endsWith}$`\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const IncludesTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Includes\");\n/**\n * @category string filters\n * @since 0.67.0\n */\nexport const includes = (searchString, annotations) => self => self.pipe(filter(a => a.includes(searchString), {\n  typeId: {\n    id: IncludesTypeId,\n    annotation: {\n      includes: searchString\n    }\n  },\n  description: `a string including ${JSON.stringify(searchString)}`,\n  jsonSchema: {\n    pattern: `.*${searchString}.*`\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LowercasedTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Lowercased\");\n/**\n * Verifies that a string is lowercased.\n *\n * @category string filters\n * @since 0.67.0\n */\nexport const lowercased = annotations => self => self.pipe(filter(a => a === a.toLowerCase(), {\n  typeId: LowercasedTypeId,\n  description: \"a lowercase string\",\n  ...annotations\n}));\n/**\n * @category string constructors\n * @since 0.67.0\n */\nexport class Lowercased extends String$.pipe(lowercased({\n  identifier: \"Lowercased\",\n  title: \"Lowercased\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const UppercasedTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Uppercased\");\n/**\n * Verifies that a string is uppercased.\n *\n * @category string filters\n * @since 0.67.0\n */\nexport const uppercased = annotations => self => self.pipe(filter(a => a === a.toUpperCase(), {\n  typeId: UppercasedTypeId,\n  description: \"an uppercase string\",\n  ...annotations\n}));\n/**\n * @category string constructors\n * @since 0.67.0\n */\nexport class Uppercased extends String$.pipe(uppercased({\n  identifier: \"Uppercased\",\n  title: \"Uppercased\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LengthTypeId = filters_.LengthTypeId;\n/**\n * @category string filters\n * @since 0.67.0\n */\nexport const length = (length, annotations) => self => {\n  const minLength = Predicate.isObject(length) ? Math.max(0, Math.floor(length.min)) : Math.max(0, Math.floor(length));\n  const maxLength = Predicate.isObject(length) ? Math.max(minLength, Math.floor(length.max)) : minLength;\n  if (minLength !== maxLength) {\n    return self.pipe(filter(a => a.length >= minLength && a.length <= maxLength, {\n      typeId: LengthTypeId,\n      description: `a string at least ${minLength} character(s) and at most ${maxLength} character(s) long`,\n      jsonSchema: {\n        minLength,\n        maxLength\n      },\n      ...annotations\n    }));\n  }\n  return self.pipe(filter(a => a.length === minLength, {\n    typeId: LengthTypeId,\n    description: minLength === 1 ? `a single character` : `a string ${minLength} character(s) long`,\n    jsonSchema: {\n      minLength,\n      maxLength: minLength\n    },\n    ...annotations\n  }));\n};\n/**\n * A schema representing a single character.\n *\n * @category string constructors\n * @since 0.67.0\n */\nexport class Char extends String$.pipe(length(1, {\n  identifier: \"Char\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category string filters\n * @since 0.67.0\n */\nexport const nonEmpty = annotations => minLength(1, {\n  description: \"a non empty string\",\n  ...annotations\n});\n/**\n * This schema converts a string to lowercase.\n *\n * @category string transformations\n * @since 0.67.0\n */\nexport class Lowercase extends transform(String$, Lowercased, {\n  decode: s => s.toLowerCase(),\n  encode: identity\n}).annotations({\n  identifier: \"Lowercase\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * This schema converts a string to uppercase.\n *\n * @category string transformations\n * @since 0.67.0\n */\nexport class Uppercase extends transform(String$, Uppercased, {\n  decode: s => s.toUpperCase(),\n  encode: identity\n}).annotations({\n  identifier: \"Uppercase\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * @category string constructors\n * @since 0.67.0\n */\nexport class Trimmed extends String$.pipe(trimmed({\n  identifier: \"Trimmed\",\n  title: \"Trimmed\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * This schema allows removing whitespaces from the beginning and end of a string.\n *\n * @category string transformations\n * @since 0.67.0\n */\nexport class Trim extends transform(String$, Trimmed, {\n  decode: s => s.trim(),\n  encode: identity\n}).annotations({\n  identifier: \"Trim\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * Returns a schema that allows splitting a string into an array of strings.\n *\n * @category string transformations\n * @since 0.67.0\n */\nexport const split = separator => transform(String$, Array$(String$), {\n  decode: string_.split(separator),\n  encode: array_.join(separator)\n});\nconst JsonString = /*#__PURE__*/String$.annotations({\n  [AST.IdentifierAnnotationId]: \"JsonString\",\n  [AST.TitleAnnotationId]: \"JsonString\",\n  [AST.DescriptionAnnotationId]: \"a JSON string\"\n});\n/**\n * The `ParseJson` combinator provides a method to convert JSON strings into the `unknown` type using the underlying\n * functionality of `JSON.parse`. It also utilizes `JSON.stringify` for encoding.\n *\n * You can optionally provide a `ParseJsonOptions` to configure both `JSON.parse` and `JSON.stringify` executions.\n *\n * Optionally, you can pass a schema `Schema<A, I, R>` to obtain an `A` type instead of `unknown`.\n *\n * @example\n * import * as S from \"@effect/schema/Schema\"\n *\n * assert.deepStrictEqual(S.decodeUnknownSync(S.parseJson())(`{\"a\":\"1\"}`), { a: \"1\" })\n * assert.deepStrictEqual(S.decodeUnknownSync(S.parseJson(S.Struct({ a: S.NumberFromString })))(`{\"a\":\"1\"}`), { a: 1 })\n *\n * @category string transformations\n * @since 0.67.0\n */\nexport const parseJson = (schema, o) => {\n  if (isSchema(schema)) {\n    return compose(parseJson(o), schema);\n  }\n  const options = schema;\n  return transformOrFail(JsonString, Unknown, {\n    decode: (s, _, ast) => ParseResult.try({\n      try: () => JSON.parse(s, options?.reviver),\n      catch: e => new ParseResult.Type(ast, s, e.message)\n    }),\n    encode: (u, _, ast) => ParseResult.try({\n      try: () => JSON.stringify(u, options?.replacer, options?.space),\n      catch: e => new ParseResult.Type(ast, u, e.message)\n    })\n  });\n};\n/**\n * @category string constructors\n * @since 0.67.0\n */\nexport class NonEmpty extends String$.pipe(nonEmpty({\n  identifier: \"NonEmpty\",\n  title: \"NonEmpty\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const UUIDTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/UUID\");\nconst uuidRegexp = /^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$/i;\n/**\n * Represents a Universally Unique Identifier (UUID).\n *\n * This schema ensures that the provided string adheres to the standard UUID format.\n *\n * @category string constructors\n * @since 0.67.0\n */\nexport class UUID extends String$.pipe(pattern(uuidRegexp, {\n  typeId: UUIDTypeId,\n  identifier: \"UUID\",\n  title: \"UUID\",\n  description: \"a Universally Unique Identifier\",\n  arbitrary: () => fc => fc.uuid()\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const ULIDTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/ULID\");\nconst ulidRegexp = /^[0-7][0-9A-HJKMNP-TV-Z]{25}$/i;\n/**\n * Represents a Universally Unique Lexicographically Sortable Identifier (ULID).\n *\n * ULIDs are designed to be compact, URL-safe, and ordered, making them suitable for use as identifiers.\n * This schema ensures that the provided string adheres to the standard ULID format.\n *\n * @category string constructors\n * @since 0.67.0\n */\nexport class ULID extends String$.pipe(pattern(ulidRegexp, {\n  typeId: ULIDTypeId,\n  identifier: \"ULID\",\n  title: \"ULID\",\n  description: \"a Universally Unique Lexicographically Sortable Identifier\",\n  arbitrary: () => fc => fc.ulid()\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const FiniteTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Finite\");\n/**\n * Ensures that the provided value is a finite number.\n *\n * This schema filters out non-finite numeric values, allowing only finite numbers to pass through.\n *\n * @category number filters\n * @since 0.67.0\n */\nexport const finite = annotations => self => self.pipe(filter(a => Number.isFinite(a), {\n  typeId: FiniteTypeId,\n  description: \"a finite number\",\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const GreaterThanTypeId = filters_.GreaterThanTypeId;\n/**\n * This filter checks whether the provided number is greater than the specified minimum.\n *\n * @category number filters\n * @since 0.67.0\n */\nexport const greaterThan = (min, annotations) => self => self.pipe(filter(a => a > min, {\n  typeId: GreaterThanTypeId,\n  description: min === 0 ? \"a positive number\" : `a number greater than ${min}`,\n  jsonSchema: {\n    exclusiveMinimum: min\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const GreaterThanOrEqualToTypeId = filters_.GreaterThanOrEqualToTypeId;\n/**\n * This filter checks whether the provided number is greater than or equal to the specified minimum.\n *\n * @category number filters\n * @since 0.67.0\n */\nexport const greaterThanOrEqualTo = (min, annotations) => self => self.pipe(filter(a => a >= min, {\n  typeId: GreaterThanOrEqualToTypeId,\n  description: min === 0 ? \"a non-negative number\" : `a number greater than or equal to ${min}`,\n  jsonSchema: {\n    minimum: min\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const MultipleOfTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/MultipleOf\");\n/**\n * @category number filters\n * @since 0.67.0\n */\nexport const multipleOf = (divisor, annotations) => self => self.pipe(filter(a => number_.remainder(a, divisor) === 0, {\n  typeId: MultipleOfTypeId,\n  description: `a number divisible by ${divisor}`,\n  jsonSchema: {\n    multipleOf: Math.abs(divisor)\n  },\n  // spec requires positive divisor\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const IntTypeId = filters_.IntTypeId;\n/**\n * @category number filters\n * @since 0.67.0\n */\nexport const int = annotations => self => self.pipe(filter(a => Number.isSafeInteger(a), {\n  typeId: IntTypeId,\n  title: \"integer\",\n  description: \"an integer\",\n  jsonSchema: {\n    type: \"integer\"\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LessThanTypeId = filters_.LessThanTypeId;\n/**\n * This filter checks whether the provided number is less than the specified maximum.\n *\n * @category number filters\n * @since 0.67.0\n */\nexport const lessThan = (max, annotations) => self => self.pipe(filter(a => a < max, {\n  typeId: LessThanTypeId,\n  description: max === 0 ? \"a negative number\" : `a number less than ${max}`,\n  jsonSchema: {\n    exclusiveMaximum: max\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LessThanOrEqualToTypeId = filters_.LessThanOrEqualToTypeId;\n/**\n * This schema checks whether the provided number is less than or equal to the specified maximum.\n *\n * @category number filters\n * @since 0.67.0\n */\nexport const lessThanOrEqualTo = (max, annotations) => self => self.pipe(filter(a => a <= max, {\n  typeId: LessThanOrEqualToTypeId,\n  description: max === 0 ? \"a non-positive number\" : `a number less than or equal to ${max}`,\n  jsonSchema: {\n    maximum: max\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const BetweenTypeId = filters_.BetweenTypeId;\n/**\n * This filter checks whether the provided number falls within the specified minimum and maximum values.\n *\n * @category number filters\n * @since 0.67.0\n */\nexport const between = (min, max, annotations) => self => self.pipe(filter(a => a >= min && a <= max, {\n  typeId: BetweenTypeId,\n  description: `a number between ${min} and ${max}`,\n  jsonSchema: {\n    maximum: max,\n    minimum: min\n  },\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const NonNaNTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/NonNaN\");\n/**\n * @category number filters\n * @since 0.67.0\n */\nexport const nonNaN = annotations => self => self.pipe(filter(a => !Number.isNaN(a), {\n  typeId: NonNaNTypeId,\n  description: \"a number excluding NaN\",\n  ...annotations\n}));\n/**\n * @category number filters\n * @since 0.67.0\n */\nexport const positive = annotations => greaterThan(0, annotations);\n/**\n * @category number filters\n * @since 0.67.0\n */\nexport const negative = annotations => lessThan(0, annotations);\n/**\n * @category number filters\n * @since 0.67.0\n */\nexport const nonPositive = annotations => lessThanOrEqualTo(0, annotations);\n/**\n * @category number filters\n * @since 0.67.0\n */\nexport const nonNegative = annotations => greaterThanOrEqualTo(0, annotations);\n/**\n * Clamps a number between a minimum and a maximum value.\n *\n * @category number transformations\n * @since 0.67.0\n */\nexport const clamp = (minimum, maximum) => self => transform(self, self.pipe(typeSchema, between(minimum, maximum)), {\n  strict: false,\n  decode: self => number_.clamp(self, {\n    minimum,\n    maximum\n  }),\n  encode: identity\n});\n/**\n * Transforms a `string` into a `number` by parsing the string using the `parse` function of the `effect/Number` module.\n *\n * It returns an error if the value can't be converted (for example when non-numeric characters are provided).\n *\n * The following special string values are supported: \"NaN\", \"Infinity\", \"-Infinity\".\n *\n * @category number transformations\n * @since 0.67.0\n */\nexport const parseNumber = self => transformOrFail(self, Number$, {\n  strict: false,\n  decode: (s, _, ast) => ParseResult.fromOption(number_.parse(s), () => new ParseResult.Type(ast, s)),\n  encode: n => ParseResult.succeed(String(n))\n});\n/**\n * This schema transforms a `string` into a `number` by parsing the string using the `parse` function of the `effect/Number` module.\n *\n * It returns an error if the value can't be converted (for example when non-numeric characters are provided).\n *\n * The following special string values are supported: \"NaN\", \"Infinity\", \"-Infinity\".\n *\n * @category number constructors\n * @since 0.67.0\n */\nexport class NumberFromString extends parseNumber(String$).annotations({\n  identifier: \"NumberFromString\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * @category number constructors\n * @since 0.67.0\n */\nexport class Finite extends Number$.pipe(finite({\n  identifier: \"Finite\",\n  title: \"Finite\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category number constructors\n * @since 0.67.0\n */\nexport class Int extends Number$.pipe(int({\n  identifier: \"Int\",\n  title: \"Int\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category number constructors\n * @since 0.67.0\n */\nexport class NonNaN extends Number$.pipe(nonNaN({\n  identifier: \"NonNaN\",\n  title: \"NonNaN\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category number constructors\n * @since 0.67.0\n */\nexport class Positive extends Number$.pipe(positive({\n  identifier: \"Positive\",\n  title: \"Positive\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category number constructors\n * @since 0.67.0\n */\nexport class Negative extends Number$.pipe(negative({\n  identifier: \"Negative\",\n  title: \"Negative\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category number constructors\n * @since 0.67.0\n */\nexport class NonPositive extends Number$.pipe(nonPositive({\n  identifier: \"NonPositive\",\n  title: \"NonPositive\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category number constructors\n * @since 0.67.0\n */\nexport class NonNegative extends Number$.pipe(nonNegative({\n  identifier: \"NonNegative\",\n  title: \"NonNegative\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const JsonNumberTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/JsonNumber\");\n/**\n * The `JsonNumber` is a schema for representing JSON numbers. It ensures that the provided value is a valid\n * number by filtering out `NaN` and `(+/-) Infinity`. This is useful when you want to validate and represent numbers in JSON\n * format.\n *\n * @example\n * import * as S from \"@effect/schema/Schema\"\n *\n * const is = S.is(S.JsonNumber)\n *\n * assert.deepStrictEqual(is(42), true)\n * assert.deepStrictEqual(is(Number.NaN), false)\n * assert.deepStrictEqual(is(Number.POSITIVE_INFINITY), false)\n * assert.deepStrictEqual(is(Number.NEGATIVE_INFINITY), false)\n *\n * @category number constructors\n * @since 0.67.0\n */\nexport class JsonNumber extends Number$.pipe(filter(n => !Number.isNaN(n) && Number.isFinite(n), {\n  typeId: JsonNumberTypeId,\n  identifier: \"JsonNumber\",\n  title: \"JSON-compatible number\",\n  description: \"a JSON-compatible number, excluding NaN, +Infinity, and -Infinity\",\n  jsonSchema: {\n    type: \"number\"\n  }\n})) {\n  static annotations = super.annotations;\n}\n/**\n * @category boolean transformations\n * @since 0.67.0\n */\nexport class Not extends transform(Boolean$, Boolean$, {\n  decode: boolean_.not,\n  encode: boolean_.not\n}) {\n  static annotations = super.annotations;\n}\n/** @ignore */\nclass Symbol$ extends transform(String$, SymbolFromSelf, {\n  strict: false,\n  decode: s => Symbol.for(s),\n  encode: sym => sym.description\n}).annotations({\n  identifier: \"symbol\"\n}) {\n  static annotations = super.annotations;\n}\nexport {\n/**\n * This schema transforms a `string` into a `symbol`.\n *\n * @category symbol transformations\n * @since 0.67.0\n */\nSymbol$ as Symbol };\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const GreaterThanBigIntTypeId = filters_.GreaterThanBigintTypeId;\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const greaterThanBigInt = (min, annotations) => self => self.pipe(filter(a => a > min, {\n  typeId: {\n    id: GreaterThanBigIntTypeId,\n    annotation: {\n      min\n    }\n  },\n  description: min === 0n ? \"a positive bigint\" : `a bigint greater than ${min}n`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const GreaterThanOrEqualToBigIntTypeId = filters_.GreaterThanOrEqualToBigIntTypeId;\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const greaterThanOrEqualToBigInt = (min, annotations) => self => self.pipe(filter(a => a >= min, {\n  typeId: {\n    id: GreaterThanOrEqualToBigIntTypeId,\n    annotation: {\n      min\n    }\n  },\n  description: min === 0n ? \"a non-negative bigint\" : `a bigint greater than or equal to ${min}n`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LessThanBigIntTypeId = filters_.LessThanBigIntTypeId;\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const lessThanBigInt = (max, annotations) => self => self.pipe(filter(a => a < max, {\n  typeId: {\n    id: LessThanBigIntTypeId,\n    annotation: {\n      max\n    }\n  },\n  description: max === 0n ? \"a negative bigint\" : `a bigint less than ${max}n`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LessThanOrEqualToBigIntTypeId = filters_.LessThanOrEqualToBigIntTypeId;\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const lessThanOrEqualToBigInt = (max, annotations) => self => self.pipe(filter(a => a <= max, {\n  typeId: {\n    id: LessThanOrEqualToBigIntTypeId,\n    annotation: {\n      max\n    }\n  },\n  description: max === 0n ? \"a non-positive bigint\" : `a bigint less than or equal to ${max}n`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const BetweenBigIntTypeId = filters_.BetweenBigintTypeId;\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const betweenBigInt = (min, max, annotations) => self => self.pipe(filter(a => a >= min && a <= max, {\n  typeId: {\n    id: BetweenBigIntTypeId,\n    annotation: {\n      max,\n      min\n    }\n  },\n  description: `a bigint between ${min}n and ${max}n`,\n  ...annotations\n}));\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const positiveBigInt = annotations => greaterThanBigInt(0n, annotations);\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const negativeBigInt = annotations => lessThanBigInt(0n, annotations);\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const nonNegativeBigInt = annotations => greaterThanOrEqualToBigInt(0n, annotations);\n/**\n * @category bigint filters\n * @since 0.67.0\n */\nexport const nonPositiveBigInt = annotations => lessThanOrEqualToBigInt(0n, annotations);\n/**\n * Clamps a bigint between a minimum and a maximum value.\n *\n * @category bigint transformations\n * @since 0.67.0\n */\nexport const clampBigInt = (minimum, maximum) => self => transform(self, self.pipe(typeSchema, betweenBigInt(minimum, maximum)), {\n  strict: false,\n  decode: self => bigInt_.clamp(self, {\n    minimum,\n    maximum\n  }),\n  encode: identity\n});\n/** @ignore */\nclass BigInt$ extends transformOrFail(String$, BigIntFromSelf, {\n  decode: (s, _, ast) => ParseResult.fromOption(bigInt_.fromString(s), () => new ParseResult.Type(ast, s)),\n  encode: n => ParseResult.succeed(String(n))\n}).annotations({\n  identifier: \"bigint\"\n}) {\n  static annotations = super.annotations;\n}\nexport {\n/**\n * This schema transforms a `string` into a `bigint` by parsing the string using the `BigInt` function.\n *\n * It returns an error if the value can't be converted (for example when non-numeric characters are provided).\n *\n * @category bigint transformations\n * @since 0.67.0\n */\nBigInt$ as BigInt };\n/**\n * @category bigint constructors\n * @since 0.67.0\n */\nexport const PositiveBigIntFromSelf = /*#__PURE__*/BigIntFromSelf.pipe( /*#__PURE__*/positiveBigInt({\n  identifier: \"PositiveBigintFromSelf\",\n  title: \"PositiveBigintFromSelf\"\n}));\n/**\n * @category bigint constructors\n * @since 0.67.0\n */\nexport const PositiveBigInt = /*#__PURE__*/BigInt$.pipe( /*#__PURE__*/positiveBigInt({\n  identifier: \"PositiveBigint\",\n  title: \"PositiveBigint\"\n}));\n/**\n * @category bigint constructors\n * @since 0.67.0\n */\nexport const NegativeBigIntFromSelf = /*#__PURE__*/BigIntFromSelf.pipe( /*#__PURE__*/negativeBigInt({\n  identifier: \"NegativeBigintFromSelf\",\n  title: \"NegativeBigintFromSelf\"\n}));\n/**\n * @category bigint constructors\n * @since 0.67.0\n */\nexport const NegativeBigInt = /*#__PURE__*/BigInt$.pipe( /*#__PURE__*/negativeBigInt({\n  identifier: \"NegativeBigint\",\n  title: \"NegativeBigint\"\n}));\n/**\n * @category bigint constructors\n * @since 0.67.0\n */\nexport const NonPositiveBigIntFromSelf = /*#__PURE__*/BigIntFromSelf.pipe( /*#__PURE__*/nonPositiveBigInt({\n  identifier: \"NonPositiveBigintFromSelf\",\n  title: \"NonPositiveBigintFromSelf\"\n}));\n/**\n * @category bigint constructors\n * @since 0.67.0\n */\nexport const NonPositiveBigInt = /*#__PURE__*/BigInt$.pipe( /*#__PURE__*/nonPositiveBigInt({\n  identifier: \"NonPositiveBigint\",\n  title: \"NonPositiveBigint\"\n}));\n/**\n * @category bigint constructors\n * @since 0.67.0\n */\nexport const NonNegativeBigIntFromSelf = /*#__PURE__*/BigIntFromSelf.pipe( /*#__PURE__*/nonNegativeBigInt({\n  identifier: \"NonNegativeBigintFromSelf\",\n  title: \"NonNegativeBigintFromSelf\"\n}));\n/**\n * @category bigint constructors\n * @since 0.67.0\n */\nexport const NonNegativeBigInt = /*#__PURE__*/BigInt$.pipe( /*#__PURE__*/nonNegativeBigInt({\n  identifier: \"NonNegativeBigint\",\n  title: \"NonNegativeBigint\"\n}));\n/**\n * This schema transforms a `number` into a `bigint` by parsing the number using the `BigInt` function.\n *\n * It returns an error if the value can't be safely encoded as a `number` due to being out of range.\n *\n * @category bigint transformations\n * @since 0.67.0\n */\nexport class BigIntFromNumber extends transformOrFail(Number$, BigIntFromSelf, {\n  decode: (n, _, ast) => ParseResult.fromOption(bigInt_.fromNumber(n), () => new ParseResult.Type(ast, n)),\n  encode: (b, _, ast) => ParseResult.fromOption(bigInt_.toNumber(b), () => new ParseResult.Type(ast, b))\n}).annotations({\n  identifier: \"BigintFromNumber\"\n}) {\n  static annotations = super.annotations;\n}\nconst redactedArbitrary = value => fc => value(fc).map(x => redacted_.make(x));\nconst redactedParse = decodeUnknown => (u, options, ast) => redacted_.isRedacted(u) ? ParseResult.mapBoth(decodeUnknown(redacted_.value(u), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: redacted_.make\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category Redacted constructors\n * @since 0.67.21\n */\nexport const RedactedFromSelf = value => declare([value], {\n  decode: value => redactedParse(ParseResult.decodeUnknown(value)),\n  encode: value => redactedParse(ParseResult.encodeUnknown(value))\n}, {\n  description: \"Redacted(<redacted>)\",\n  pretty: () => () => \"Redacted(<redacted>)\",\n  arbitrary: redactedArbitrary,\n  equivalence: redacted_.getEquivalence\n});\n/**\n * A schema that transforms any type `A` into a `Redacted<A>`.\n *\n * @category Redacted transformations\n * @since 0.67.21\n */\nexport const Redacted = value => {\n  return transform(value, RedactedFromSelf(typeSchema(value)), {\n    decode: value => redacted_.make(value),\n    encode: value => redacted_.value(value)\n  });\n};\n/**\n * @category Duration constructors\n * @since 0.67.0\n */\nexport class DurationFromSelf extends declare(duration_.isDuration, {\n  identifier: \"DurationFromSelf\",\n  pretty: () => String,\n  arbitrary: () => fc => fc.oneof(fc.constant(duration_.infinity), fc.bigUint().map(_ => duration_.nanos(_)), fc.bigUint().map(_ => duration_.micros(_)), fc.maxSafeNat().map(_ => duration_.millis(_)), fc.maxSafeNat().map(_ => duration_.seconds(_)), fc.maxSafeNat().map(_ => duration_.minutes(_)), fc.maxSafeNat().map(_ => duration_.hours(_)), fc.maxSafeNat().map(_ => duration_.days(_)), fc.maxSafeNat().map(_ => duration_.weeks(_))),\n  equivalence: () => duration_.Equivalence\n}) {\n  static annotations = super.annotations;\n}\n/**\n * A schema that transforms a `bigint` tuple into a `Duration`.\n * Treats the value as the number of nanoseconds.\n *\n * @category Duration transformations\n * @since 0.67.0\n */\nexport class DurationFromNanos extends transformOrFail(BigIntFromSelf, DurationFromSelf, {\n  decode: nanos => ParseResult.succeed(duration_.nanos(nanos)),\n  encode: (duration, _, ast) => option_.match(duration_.toNanos(duration), {\n    onNone: () => ParseResult.fail(new ParseResult.Type(ast, duration)),\n    onSome: val => ParseResult.succeed(val)\n  })\n}).annotations({\n  identifier: \"DurationFromNanos\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * A schema that transforms a `number` tuple into a `Duration`.\n * Treats the value as the number of milliseconds.\n *\n * @category Duration transformations\n * @since 0.67.0\n */\nexport class DurationFromMillis extends transform(Number$, DurationFromSelf, {\n  decode: ms => duration_.millis(ms),\n  encode: n => duration_.toMillis(n)\n}).annotations({\n  identifier: \"DurationFromMillis\"\n}) {\n  static annotations = super.annotations;\n}\nconst hrTime = /*#__PURE__*/Tuple( /*#__PURE__*/NonNegative.pipe( /*#__PURE__*/finite({\n  [AST.TitleAnnotationId]: \"seconds\",\n  [AST.DescriptionAnnotationId]: \"seconds\"\n})), /*#__PURE__*/NonNegative.pipe( /*#__PURE__*/finite({\n  [AST.TitleAnnotationId]: \"nanos\",\n  [AST.DescriptionAnnotationId]: \"nanos\"\n})));\n/**\n * A schema that transforms a `[number, number]` tuple into a `Duration`.\n *\n * @category Duration transformations\n * @since 0.67.0\n */\nexport class Duration extends transform(hrTime, DurationFromSelf, {\n  decode: ([seconds, nanos]) => duration_.nanos(BigInt(seconds) * BigInt(1e9) + BigInt(nanos)),\n  encode: duration => duration_.toHrTime(duration)\n}).annotations({\n  identifier: \"Duration\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * Clamps a `Duration` between a minimum and a maximum value.\n *\n * @category Duration transformations\n * @since 0.67.0\n */\nexport const clampDuration = (minimum, maximum) => self => transform(self, self.pipe(typeSchema, betweenDuration(minimum, maximum)), {\n  strict: false,\n  decode: self => duration_.clamp(self, {\n    minimum,\n    maximum\n  }),\n  encode: identity\n});\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LessThanDurationTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/LessThanDuration\");\n/**\n * @category Duration filters\n * @since 0.67.0\n */\nexport const lessThanDuration = (max, annotations) => self => self.pipe(filter(a => duration_.lessThan(a, max), {\n  typeId: {\n    id: LessThanDurationTypeId,\n    annotation: {\n      max\n    }\n  },\n  description: `a Duration less than ${duration_.decode(max)}`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LessThanOrEqualToDurationTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/LessThanOrEqualToDuration\");\n/**\n * @category Duration filters\n * @since 0.67.0\n */\nexport const lessThanOrEqualToDuration = (max, annotations) => self => self.pipe(filter(a => duration_.lessThanOrEqualTo(a, max), {\n  typeId: {\n    id: LessThanDurationTypeId,\n    annotation: {\n      max\n    }\n  },\n  description: `a Duration less than or equal to ${duration_.decode(max)}`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const GreaterThanDurationTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/GreaterThanDuration\");\n/**\n * @category Duration filters\n * @since 0.67.0\n */\nexport const greaterThanDuration = (min, annotations) => self => self.pipe(filter(a => duration_.greaterThan(a, min), {\n  typeId: {\n    id: GreaterThanDurationTypeId,\n    annotation: {\n      min\n    }\n  },\n  description: `a Duration greater than ${duration_.decode(min)}`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const GreaterThanOrEqualToDurationTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/GreaterThanOrEqualToDuration\");\n/**\n * @category Duration filters\n * @since 0.67.0\n */\nexport const greaterThanOrEqualToDuration = (min, annotations) => self => self.pipe(filter(a => duration_.greaterThanOrEqualTo(a, min), {\n  typeId: {\n    id: GreaterThanOrEqualToDurationTypeId,\n    annotation: {\n      min\n    }\n  },\n  description: `a Duration greater than or equal to ${duration_.decode(min)}`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const BetweenDurationTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/BetweenDuration\");\n/**\n * @category Duration filters\n * @since 0.67.0\n */\nexport const betweenDuration = (minimum, maximum, annotations) => self => self.pipe(filter(a => duration_.between(a, {\n  minimum,\n  maximum\n}), {\n  typeId: {\n    id: BetweenDurationTypeId,\n    annotation: {\n      maximum,\n      minimum\n    }\n  },\n  description: `a Duration between ${duration_.decode(minimum)} and ${duration_.decode(maximum)}`,\n  ...annotations\n}));\n/**\n * @category Uint8Array constructors\n * @since 0.67.0\n */\nexport const Uint8ArrayFromSelf = /*#__PURE__*/declare(Predicate.isUint8Array, {\n  identifier: \"Uint8ArrayFromSelf\",\n  pretty: () => u8arr => `new Uint8Array(${JSON.stringify(Array.from(u8arr))})`,\n  arbitrary: () => fc => fc.uint8Array(),\n  equivalence: () => array_.getEquivalence(Equal.equals)\n});\nconst Uint8Array$ = /*#__PURE__*/transform(Array$(Number$.pipe(between(0, 255, {\n  title: \"8-bit unsigned integer\",\n  description: \"a 8-bit unsigned integer\"\n}))).annotations({\n  description: \"an array of 8-bit unsigned integers\"\n}), Uint8ArrayFromSelf, {\n  decode: numbers => Uint8Array.from(numbers),\n  encode: uint8Array => Array.from(uint8Array)\n}).annotations({\n  identifier: \"Uint8Array\"\n});\nexport {\n/**\n * A schema that transforms a `number` array into a `Uint8Array`.\n *\n * @category Uint8Array transformations\n * @since 0.67.0\n */\nUint8Array$ as Uint8Array };\nconst makeEncodingTransformation = (id, decode, encode) => transformOrFail(String$, Uint8ArrayFromSelf, {\n  decode: (s, _, ast) => either_.mapLeft(decode(s), decodeException => new ParseResult.Type(ast, s, decodeException.message)),\n  encode: u => ParseResult.succeed(encode(u))\n}).annotations({\n  identifier: id\n});\n/**\n * @category Encoding transformations\n * @since 0.67.0\n */\nexport const Base64 = /*#__PURE__*/makeEncodingTransformation(\"Base64\", Encoding.decodeBase64, Encoding.encodeBase64);\n/**\n * @category Encoding transformations\n * @since 0.67.0\n */\nexport const Base64Url = /*#__PURE__*/makeEncodingTransformation(\"Base64Url\", Encoding.decodeBase64Url, Encoding.encodeBase64Url);\n/**\n * @category Encoding transformations\n * @since 0.67.0\n */\nexport const Hex = /*#__PURE__*/makeEncodingTransformation(\"Hex\", Encoding.decodeHex, Encoding.encodeHex);\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const MinItemsTypeId = filters_.MinItemsTypeId;\n/**\n * @category ReadonlyArray filters\n * @since 0.67.0\n */\nexport const minItems = (n, annotations) => self => {\n  const minItems = Math.floor(n);\n  if (minItems < 1) {\n    throw new Error(errors_.getInvalidArgumentErrorMessage(`Expected an integer greater than or equal to 1, actual ${n}`));\n  }\n  return self.pipe(filter(a => a.length >= minItems, {\n    typeId: MinItemsTypeId,\n    description: `an array of at least ${minItems} items`,\n    jsonSchema: {\n      minItems\n    },\n    [AST.StableFilterAnnotationId]: true,\n    ...annotations\n  }));\n};\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const MaxItemsTypeId = filters_.MaxItemsTypeId;\n/**\n * @category ReadonlyArray filters\n * @since 0.67.0\n */\nexport const maxItems = (n, annotations) => self => self.pipe(filter(a => a.length <= n, {\n  typeId: MaxItemsTypeId,\n  description: `an array of at most ${n} items`,\n  jsonSchema: {\n    maxItems: n\n  },\n  [AST.StableFilterAnnotationId]: true,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const ItemsCountTypeId = filters_.ItemsCountTypeId;\n/**\n * @category ReadonlyArray filters\n * @since 0.67.0\n */\nexport const itemsCount = (n, annotations) => self => self.pipe(filter(a => a.length === n, {\n  typeId: ItemsCountTypeId,\n  description: `an array of exactly ${n} item(s)`,\n  jsonSchema: {\n    minItems: n,\n    maxItems: n\n  },\n  [AST.StableFilterAnnotationId]: true,\n  ...annotations\n}));\n/**\n * @category ReadonlyArray transformations\n * @since 0.67.0\n */\nexport const getNumberIndexedAccess = self => make(AST.getNumberIndexedAccess(self.ast));\n/**\n * Get the first element of a `ReadonlyArray`, or `None` if the array is empty.\n *\n * @category ReadonlyArray transformations\n * @since 0.67.0\n */\nexport const head = self => transform(self, OptionFromSelf(getNumberIndexedAccess(typeSchema(self))), {\n  decode: array_.head,\n  encode: option_.match({\n    onNone: () => [],\n    onSome: array_.of\n  })\n});\n/**\n * Retrieves the first element of a `ReadonlyArray`.\n *\n * If the array is empty, it returns the `fallback` argument if provided; otherwise, it fails.\n *\n * @category ReadonlyArray transformations\n * @since 0.67.0\n */\nexport const headOrElse = /*#__PURE__*/dual(args => isSchema(args[0]), (self, fallback) => transformOrFail(self, getNumberIndexedAccess(typeSchema(self)), {\n  decode: (as, _, ast) => as.length > 0 ? ParseResult.succeed(as[0]) : fallback ? ParseResult.succeed(fallback()) : ParseResult.fail(new ParseResult.Type(ast, as)),\n  encode: a => ParseResult.succeed(array_.of(a))\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const ValidDateTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/ValidDate\");\n/**\n * Defines a filter that specifically rejects invalid dates, such as `new\n * Date(\"Invalid Date\")`. This filter ensures that only properly formatted and\n * valid date objects are accepted, enhancing data integrity by preventing\n * erroneous date values from being processed.\n *\n * @category Date filters\n * @since 0.67.0\n */\nexport const validDate = annotations => self => self.pipe(filter(a => !Number.isNaN(a.getTime()), {\n  typeId: ValidDateTypeId,\n  description: \"a valid Date\",\n  ...annotations\n}));\n/**\n * Describes a schema that accommodates potentially invalid `Date` instances,\n * such as `new Date(\"Invalid Date\")`, without rejection.\n *\n * @category Date constructors\n * @since 0.67.0\n */\nexport class DateFromSelf extends declare(Predicate.isDate, {\n  identifier: \"DateFromSelf\",\n  description: \"a potentially invalid Date instance\",\n  pretty: () => date => `new Date(${JSON.stringify(date)})`,\n  arbitrary: () => fc => fc.date({\n    noInvalidDate: false\n  }),\n  equivalence: () => Equivalence.Date\n}) {\n  static annotations = super.annotations;\n}\n/**\n * Defines a schema that ensures only valid dates are accepted. This schema\n * rejects values like `new Date(\"Invalid Date\")`, which, despite being a `Date`\n * instance, represents an invalid date. Such stringent validation ensures that\n * all date objects processed through this schema are properly formed and\n * represent real dates.\n *\n * @category Date constructors\n * @since 0.67.0\n */\nexport class ValidDateFromSelf extends DateFromSelf.pipe(validDate({\n  identifier: \"ValidDateFromSelf\",\n  description: \"a valid Date instance\"\n})) {\n  static annotations = super.annotations;\n}\n/**\n * Defines a schema that attempts to convert a `string` to a `Date` object using\n * the `new Date` constructor. This conversion is lenient, meaning it does not\n * reject strings that do not form valid dates (e.g., using `new Date(\"Invalid\n * Date\")` results in a `Date` object, despite being invalid).\n *\n * @category Date transformations\n * @since 0.67.0\n */\nexport class DateFromString extends transform(String$, DateFromSelf, {\n  decode: s => new Date(s),\n  encode: d => d.toISOString()\n}).annotations({\n  identifier: \"DateFromString\"\n}) {\n  static annotations = super.annotations;\n}\n/** @ignore */\nclass Date$ extends DateFromString.pipe(validDate({\n  identifier: \"Date\"\n})) {\n  static annotations = super.annotations;\n}\nexport {\n/**\n * This schema converts a `string` into a `Date` object using the `new Date`\n * constructor. It ensures that only valid date strings are accepted,\n * rejecting any strings that would result in an invalid date, such as `new\n * Date(\"Invalid Date\")`.\n *\n * @category Date transformations\n * @since 0.67.0\n */\nDate$ as Date };\n/**\n * Defines a schema that converts a `number` into a `Date` object using the `new\n * Date` constructor. This schema does not validate the numerical input,\n * allowing potentially invalid values such as `NaN`, `Infinity`, and\n * `-Infinity` to be converted into `Date` objects. During the encoding process,\n * any invalid `Date` object will be encoded to `NaN`.\n *\n * @category Date transformations\n * @since 0.67.0\n */\nexport class DateFromNumber extends transform(Number$, DateFromSelf, {\n  decode: n => new Date(n),\n  encode: d => d.getTime()\n}).annotations({\n  identifier: \"DateFromNumber\"\n}) {\n  static annotations = super.annotations;\n}\nconst OptionNoneEncoded = /*#__PURE__*/Struct({\n  _tag: Literal(\"None\")\n}).annotations({\n  description: \"NoneEncoded\"\n});\nconst optionSomeEncoded = value => Struct({\n  _tag: Literal(\"Some\"),\n  value\n}).annotations({\n  description: `SomeEncoded<${format(value)}>`\n});\nconst optionEncoded = value => Union(OptionNoneEncoded, optionSomeEncoded(value)).annotations({\n  description: `OptionEncoded<${format(value)}>`\n});\nconst optionDecode = input => input._tag === \"None\" ? option_.none() : option_.some(input.value);\nconst optionArbitrary = value => fc => fc.oneof(fc.record({\n  _tag: fc.constant(\"None\")\n}), fc.record({\n  _tag: fc.constant(\"Some\"),\n  value: value(fc)\n})).map(optionDecode);\nconst optionPretty = value => option_.match({\n  onNone: () => \"none()\",\n  onSome: a => `some(${value(a)})`\n});\nconst optionParse = decodeUnknown => (u, options, ast) => option_.isOption(u) ? option_.isNone(u) ? ParseResult.succeed(option_.none()) : ParseResult.map(decodeUnknown(u.value, options), option_.some) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category Option transformations\n * @since 0.67.0\n */\nexport const OptionFromSelf = value => {\n  return declare([value], {\n    decode: value => optionParse(ParseResult.decodeUnknown(value)),\n    encode: value => optionParse(ParseResult.encodeUnknown(value))\n  }, {\n    description: `Option<${format(value)}>`,\n    pretty: optionPretty,\n    arbitrary: optionArbitrary,\n    equivalence: option_.getEquivalence\n  });\n};\nconst makeNoneEncoded = {\n  _tag: \"None\"\n};\nconst makeSomeEncoded = value => ({\n  _tag: \"Some\",\n  value\n});\n/**\n * @category Option transformations\n * @since 0.67.0\n */\nexport const Option = value => {\n  const value_ = asSchema(value);\n  return transform(optionEncoded(value_), OptionFromSelf(typeSchema(value_)), {\n    decode: optionDecode,\n    encode: option_.match({\n      onNone: () => makeNoneEncoded,\n      onSome: makeSomeEncoded\n    })\n  });\n};\n/**\n * @category Option transformations\n * @since 0.67.0\n */\nexport const OptionFromNullOr = value => {\n  const value_ = asSchema(value);\n  return transform(NullOr(value_), OptionFromSelf(typeSchema(value_)), {\n    decode: option_.fromNullable,\n    encode: option_.getOrNull\n  });\n};\n/**\n * @category Option transformations\n * @since 0.67.0\n */\nexport const OptionFromNullishOr = (value, onNoneEncoding) => {\n  const value_ = asSchema(value);\n  return transform(NullishOr(value_), OptionFromSelf(typeSchema(value_)), {\n    decode: option_.fromNullable,\n    encode: onNoneEncoding === null ? option_.getOrNull : option_.getOrUndefined\n  });\n};\n/**\n * @category Option transformations\n * @since 0.67.0\n */\nexport const OptionFromUndefinedOr = value => {\n  const value_ = asSchema(value);\n  return transform(UndefinedOr(value_), OptionFromSelf(typeSchema(value_)), {\n    decode: option_.fromNullable,\n    encode: option_.getOrUndefined\n  });\n};\nconst rightEncoded = right => Struct({\n  _tag: Literal(\"Right\"),\n  right\n}).annotations({\n  description: `RightEncoded<${format(right)}>`\n});\nconst leftEncoded = left => Struct({\n  _tag: Literal(\"Left\"),\n  left\n}).annotations({\n  description: `LeftEncoded<${format(left)}>`\n});\nconst eitherEncoded = (right, left) => Union(rightEncoded(right), leftEncoded(left)).annotations({\n  description: `EitherEncoded<${format(left)}, ${format(right)}>`\n});\nconst eitherDecode = input => input._tag === \"Left\" ? either_.left(input.left) : either_.right(input.right);\nconst eitherArbitrary = (right, left) => fc => fc.oneof(fc.record({\n  _tag: fc.constant(\"Left\"),\n  left: left(fc)\n}), fc.record({\n  _tag: fc.constant(\"Right\"),\n  right: right(fc)\n})).map(eitherDecode);\nconst eitherPretty = (right, left) => either_.match({\n  onLeft: e => `left(${left(e)})`,\n  onRight: a => `right(${right(a)})`\n});\nconst eitherParse = (parseRight, decodeUnknownLeft) => (u, options, ast) => either_.isEither(u) ? either_.match(u, {\n  onLeft: left => ParseResult.map(decodeUnknownLeft(left, options), either_.left),\n  onRight: right => ParseResult.map(parseRight(right, options), either_.right)\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category Either transformations\n * @since 0.67.0\n */\nexport const EitherFromSelf = ({\n  left,\n  right\n}) => {\n  return declare([right, left], {\n    decode: (right, left) => eitherParse(ParseResult.decodeUnknown(right), ParseResult.decodeUnknown(left)),\n    encode: (right, left) => eitherParse(ParseResult.encodeUnknown(right), ParseResult.encodeUnknown(left))\n  }, {\n    description: `Either<${format(right)}, ${format(left)}>`,\n    pretty: eitherPretty,\n    arbitrary: eitherArbitrary,\n    equivalence: (right, left) => either_.getEquivalence({\n      left,\n      right\n    })\n  });\n};\nconst makeLeftEncoded = left => ({\n  _tag: \"Left\",\n  left\n});\nconst makeRightEncoded = right => ({\n  _tag: \"Right\",\n  right\n});\n/**\n * @category Either transformations\n * @since 0.67.0\n */\nexport const Either = ({\n  left,\n  right\n}) => {\n  const right_ = asSchema(right);\n  const left_ = asSchema(left);\n  return transform(eitherEncoded(right_, left_), EitherFromSelf({\n    left: typeSchema(left_),\n    right: typeSchema(right_)\n  }), {\n    decode: eitherDecode,\n    encode: either_.match({\n      onLeft: makeLeftEncoded,\n      onRight: makeRightEncoded\n    })\n  });\n};\n/**\n * @example\n * import * as Schema from \"@effect/schema/Schema\"\n *\n * // Schema<string | number, Either<string, number>>\n * Schema.EitherFromUnion({ left: Schema.String, right: Schema.Number })\n *\n * @category Either transformations\n * @since 0.67.0\n */\nexport const EitherFromUnion = ({\n  left,\n  right\n}) => {\n  const right_ = asSchema(right);\n  const left_ = asSchema(left);\n  const toright = typeSchema(right_);\n  const toleft = typeSchema(left_);\n  const fromRight = transform(right_, rightEncoded(toright), {\n    decode: makeRightEncoded,\n    encode: r => r.right\n  });\n  const fromLeft = transform(left_, leftEncoded(toleft), {\n    decode: makeLeftEncoded,\n    encode: l => l.left\n  });\n  return transform(Union(fromRight, fromLeft), EitherFromSelf({\n    left: toleft,\n    right: toright\n  }), {\n    decode: from => from._tag === \"Left\" ? either_.left(from.left) : either_.right(from.right),\n    encode: either_.match({\n      onLeft: makeLeftEncoded,\n      onRight: makeRightEncoded\n    })\n  });\n};\nconst mapArbitrary = (key, value) => fc => fc.array(fc.tuple(key(fc), value(fc))).map(as => new Map(as));\nconst readonlyMapPretty = (key, value) => map => `new Map([${Array.from(map.entries()).map(([k, v]) => `[${key(k)}, ${value(v)}]`).join(\", \")}])`;\nconst readonlyMapEquivalence = (key, value) => {\n  const arrayEquivalence = array_.getEquivalence(Equivalence.make(([ka, va], [kb, vb]) => key(ka, kb) && value(va, vb)));\n  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a.entries()), Array.from(b.entries())));\n};\nconst readonlyMapParse = decodeUnknown => (u, options, ast) => Predicate.isMap(u) ? ParseResult.mapBoth(decodeUnknown(Array.from(u.entries()), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: as => new Map(as)\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\nconst mapFromSelf_ = (key, value, description) => declare([key, value], {\n  decode: (Key, Value) => readonlyMapParse(ParseResult.decodeUnknown(Array$(Tuple(Key, Value)))),\n  encode: (Key, Value) => readonlyMapParse(ParseResult.encodeUnknown(Array$(Tuple(Key, Value))))\n}, {\n  description,\n  pretty: readonlyMapPretty,\n  arbitrary: mapArbitrary,\n  equivalence: readonlyMapEquivalence\n});\n/**\n * @category ReadonlyMap\n * @since 0.67.0\n */\nexport const ReadonlyMapFromSelf = ({\n  key,\n  value\n}) => mapFromSelf_(key, value, `ReadonlyMap<${format(key)}, ${format(value)}>`);\n/**\n * @category Map\n * @since 0.67.0\n */\nexport const MapFromSelf = ({\n  key,\n  value\n}) => mapFromSelf_(key, value, `Map<${format(key)}, ${format(value)}>`);\n/**\n * @category ReadonlyMap transformations\n * @since 0.67.0\n */\nexport const ReadonlyMap = ({\n  key,\n  value\n}) => {\n  const key_ = asSchema(key);\n  const value_ = asSchema(value);\n  return transform(Array$(Tuple(key_, value_)), ReadonlyMapFromSelf({\n    key: typeSchema(key_),\n    value: typeSchema(value_)\n  }), {\n    decode: as => new Map(as),\n    encode: map => Array.from(map.entries())\n  });\n};\nconst map = ({\n  key,\n  value\n}) => {\n  const key_ = asSchema(key);\n  const value_ = asSchema(value);\n  return transform(Array$(Tuple(key_, value_)), MapFromSelf({\n    key: typeSchema(key_),\n    value: typeSchema(value_)\n  }), {\n    decode: as => new Map(as),\n    encode: map => Array.from(map.entries())\n  });\n};\nexport {\n/**\n * @category Map transformations\n * @since 0.67.0\n */\nmap as Map };\nconst setArbitrary = item => fc => fc.array(item(fc)).map(as => new Set(as));\nconst readonlySetPretty = item => set => `new Set([${Array.from(set.values()).map(a => item(a)).join(\", \")}])`;\nconst readonlySetEquivalence = item => {\n  const arrayEquivalence = array_.getEquivalence(item);\n  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a.values()), Array.from(b.values())));\n};\nconst readonlySetParse = decodeUnknown => (u, options, ast) => Predicate.isSet(u) ? ParseResult.mapBoth(decodeUnknown(Array.from(u.values()), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: as => new Set(as)\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\nconst setFromSelf_ = (value, description) => declare([value], {\n  decode: item => readonlySetParse(ParseResult.decodeUnknown(Array$(item))),\n  encode: item => readonlySetParse(ParseResult.encodeUnknown(Array$(item)))\n}, {\n  description,\n  pretty: readonlySetPretty,\n  arbitrary: setArbitrary,\n  equivalence: readonlySetEquivalence\n});\n/**\n * @category ReadonlySet\n * @since 0.67.0\n */\nexport const ReadonlySetFromSelf = value => setFromSelf_(value, `ReadonlySet<${format(value)}>`);\n/**\n * @category Set\n * @since 0.67.0\n */\nexport const SetFromSelf = value => setFromSelf_(value, `Set<${format(value)}>`);\n/**\n * @category ReadonlySet transformations\n * @since 0.67.0\n */\nexport const ReadonlySet = value => {\n  const value_ = asSchema(value);\n  return transform(Array$(value_), ReadonlySetFromSelf(typeSchema(value_)), {\n    decode: as => new Set(as),\n    encode: set => Array.from(set)\n  });\n};\nconst set = value => {\n  const value_ = asSchema(value);\n  return transform(Array$(value_), SetFromSelf(typeSchema(value_)), {\n    decode: as => new Set(as),\n    encode: set => Array.from(set)\n  });\n};\nexport {\n/**\n * @category Set transformations\n * @since 0.67.0\n */\nset as Set };\nconst bigDecimalPretty = () => val => `BigDecimal(${bigDecimal_.format(bigDecimal_.normalize(val))})`;\nconst bigDecimalArbitrary = () => fc => fc.tuple(fc.bigInt(), fc.integer()).map(([value, scale]) => bigDecimal_.make(value, scale));\n/**\n * @category BigDecimal constructors\n * @since 0.67.0\n */\nexport class BigDecimalFromSelf extends declare(bigDecimal_.isBigDecimal, {\n  identifier: \"BigDecimalFromSelf\",\n  pretty: bigDecimalPretty,\n  arbitrary: bigDecimalArbitrary,\n  equivalence: () => bigDecimal_.Equivalence\n}) {\n  static annotations = super.annotations;\n}\n/**\n * @category BigDecimal transformations\n * @since 0.67.0\n */\nexport class BigDecimal extends transformOrFail(String$, BigDecimalFromSelf, {\n  decode: (num, _, ast) => bigDecimal_.fromString(num).pipe(option_.match({\n    onNone: () => ParseResult.fail(new ParseResult.Type(ast, num)),\n    onSome: val => ParseResult.succeed(bigDecimal_.normalize(val))\n  })),\n  encode: val => ParseResult.succeed(bigDecimal_.format(bigDecimal_.normalize(val)))\n}).annotations({\n  identifier: \"BigDecimal\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * A schema that transforms a `number` into a `BigDecimal`.\n * When encoding, this Schema will produce incorrect results if the BigDecimal exceeds the 64-bit range of a number.\n *\n * @category BigDecimal transformations\n * @since 0.67.0\n */\nexport class BigDecimalFromNumber extends transformOrFail(Number$, BigDecimalFromSelf, {\n  decode: num => ParseResult.succeed(bigDecimal_.fromNumber(num)),\n  encode: val => ParseResult.succeed(bigDecimal_.unsafeToNumber(val))\n}).annotations({\n  identifier: \"BigDecimalFromNumber\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const GreaterThanBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/GreaterThanBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const greaterThanBigDecimal = (min, annotations) => self => self.pipe(filter(a => bigDecimal_.greaterThan(a, min), {\n  typeId: {\n    id: GreaterThanBigDecimalTypeId,\n    annotation: {\n      min\n    }\n  },\n  description: `a BigDecimal greater than ${bigDecimal_.format(min)}`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const GreaterThanOrEqualToBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/GreaterThanOrEqualToBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const greaterThanOrEqualToBigDecimal = (min, annotations) => self => self.pipe(filter(a => bigDecimal_.greaterThanOrEqualTo(a, min), {\n  typeId: {\n    id: GreaterThanOrEqualToBigDecimalTypeId,\n    annotation: {\n      min\n    }\n  },\n  description: `a BigDecimal greater than or equal to ${bigDecimal_.format(min)}`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LessThanBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/LessThanBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const lessThanBigDecimal = (max, annotations) => self => self.pipe(filter(a => bigDecimal_.lessThan(a, max), {\n  typeId: {\n    id: LessThanBigDecimalTypeId,\n    annotation: {\n      max\n    }\n  },\n  description: `a BigDecimal less than ${bigDecimal_.format(max)}`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const LessThanOrEqualToBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/LessThanOrEqualToBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const lessThanOrEqualToBigDecimal = (max, annotations) => self => self.pipe(filter(a => bigDecimal_.lessThanOrEqualTo(a, max), {\n  typeId: {\n    id: LessThanOrEqualToBigDecimalTypeId,\n    annotation: {\n      max\n    }\n  },\n  description: `a BigDecimal less than or equal to ${bigDecimal_.format(max)}`,\n  ...annotations\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const PositiveBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/PositiveBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const positiveBigDecimal = annotations => self => self.pipe(filter(a => bigDecimal_.isPositive(a), {\n  typeId: {\n    id: PositiveBigDecimalTypeId,\n    annotation: {}\n  },\n  description: `a positive BigDecimal`,\n  ...annotations\n}));\n/**\n * @category BigDecimal constructors\n * @since 0.67.0\n */\nexport const PositiveBigDecimalFromSelf = /*#__PURE__*/BigDecimalFromSelf.pipe( /*#__PURE__*/positiveBigDecimal({\n  identifier: \"PositiveBigDecimalFromSelf\",\n  title: \"PositiveBigDecimalFromSelf\"\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const NonNegativeBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/NonNegativeBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const nonNegativeBigDecimal = annotations => self => self.pipe(filter(a => a.value >= 0n, {\n  typeId: {\n    id: NonNegativeBigDecimalTypeId,\n    annotation: {}\n  },\n  description: `a non-negative BigDecimal`,\n  ...annotations\n}));\n/**\n * @category BigDecimal constructors\n * @since 0.67.0\n */\nexport const NonNegativeBigDecimalFromSelf = /*#__PURE__*/BigDecimalFromSelf.pipe( /*#__PURE__*/nonNegativeBigDecimal({\n  identifier: \"NonNegativeBigDecimalFromSelf\",\n  title: \"NonNegativeBigDecimalFromSelf\"\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const NegativeBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/NegativeBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const negativeBigDecimal = annotations => self => self.pipe(filter(a => bigDecimal_.isNegative(a), {\n  typeId: {\n    id: NegativeBigDecimalTypeId,\n    annotation: {}\n  },\n  description: `a negative BigDecimal`,\n  ...annotations\n}));\n/**\n * @category BigDecimal constructors\n * @since 0.67.0\n */\nexport const NegativeBigDecimalFromSelf = /*#__PURE__*/BigDecimalFromSelf.pipe( /*#__PURE__*/negativeBigDecimal({\n  identifier: \"NegativeBigDecimalFromSelf\",\n  title: \"NegativeBigDecimalFromSelf\"\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const NonPositiveBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/NonPositiveBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const nonPositiveBigDecimal = annotations => self => self.pipe(filter(a => a.value <= 0n, {\n  typeId: {\n    id: NonPositiveBigDecimalTypeId,\n    annotation: {}\n  },\n  description: `a non-positive BigDecimal`,\n  ...annotations\n}));\n/**\n * @category BigDecimal constructors\n * @since 0.67.0\n */\nexport const NonPositiveBigDecimalFromSelf = /*#__PURE__*/BigDecimalFromSelf.pipe( /*#__PURE__*/nonPositiveBigDecimal({\n  identifier: \"NonPositiveBigDecimalFromSelf\",\n  title: \"NonPositiveBigDecimalFromSelf\"\n}));\n/**\n * @category type id\n * @since 0.67.0\n */\nexport const BetweenBigDecimalTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/BetweenBigDecimal\");\n/**\n * @category BigDecimal filters\n * @since 0.67.0\n */\nexport const betweenBigDecimal = (minimum, maximum, annotations) => self => self.pipe(filter(a => bigDecimal_.between(a, {\n  minimum,\n  maximum\n}), {\n  typeId: {\n    id: BetweenBigDecimalTypeId,\n    annotation: {\n      maximum,\n      minimum\n    }\n  },\n  description: `a BigDecimal between ${bigDecimal_.format(minimum)} and ${bigDecimal_.format(maximum)}`,\n  ...annotations\n}));\n/**\n * Clamps a `BigDecimal` between a minimum and a maximum value.\n *\n * @category BigDecimal transformations\n * @since 0.67.0\n */\nexport const clampBigDecimal = (minimum, maximum) => self => transform(self, self.pipe(typeSchema, betweenBigDecimal(minimum, maximum)), {\n  strict: false,\n  decode: self => bigDecimal_.clamp(self, {\n    minimum,\n    maximum\n  }),\n  encode: identity\n});\nconst chunkArbitrary = item => fc => fc.array(item(fc)).map(chunk_.fromIterable);\nconst chunkPretty = item => c => `Chunk(${chunk_.toReadonlyArray(c).map(item).join(\", \")})`;\nconst chunkParse = decodeUnknown => (u, options, ast) => chunk_.isChunk(u) ? chunk_.isEmpty(u) ? ParseResult.succeed(chunk_.empty()) : ParseResult.mapBoth(decodeUnknown(chunk_.toReadonlyArray(u), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: chunk_.fromIterable\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category Chunk\n * @since 0.67.0\n */\nexport const ChunkFromSelf = value => {\n  return declare([value], {\n    decode: item => chunkParse(ParseResult.decodeUnknown(Array$(item))),\n    encode: item => chunkParse(ParseResult.encodeUnknown(Array$(item)))\n  }, {\n    description: `Chunk<${format(value)}>`,\n    pretty: chunkPretty,\n    arbitrary: chunkArbitrary,\n    equivalence: chunk_.getEquivalence\n  });\n};\n/**\n * @category Chunk transformations\n * @since 0.67.0\n */\nexport const Chunk = value => {\n  const value_ = asSchema(value);\n  return transform(Array$(value_), ChunkFromSelf(typeSchema(value_)), {\n    decode: as => as.length === 0 ? chunk_.empty() : chunk_.fromIterable(as),\n    encode: chunk_.toReadonlyArray\n  });\n};\nconst nonEmptyChunkArbitrary = item => fc => fastCheck_.array(item(fc), {\n  minLength: 1\n}).map(as => chunk_.unsafeFromNonEmptyArray(as));\nconst nonEmptyChunkPretty = item => c => `NonEmptyChunk(${chunk_.toReadonlyArray(c).map(item).join(\", \")})`;\nconst nonEmptyChunkParse = decodeUnknown => (u, options, ast) => chunk_.isChunk(u) && chunk_.isNonEmpty(u) ? ParseResult.mapBoth(decodeUnknown(chunk_.toReadonlyArray(u), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: chunk_.unsafeFromNonEmptyArray\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category Chunk\n * @since 0.67.23\n */\nexport const NonEmptyChunkFromSelf = value => {\n  return declare([value], {\n    decode: item => nonEmptyChunkParse(ParseResult.decodeUnknown(NonEmptyArray(item))),\n    encode: item => nonEmptyChunkParse(ParseResult.encodeUnknown(NonEmptyArray(item)))\n  }, {\n    description: `NonEmptyChunk<${format(value)}>`,\n    pretty: nonEmptyChunkPretty,\n    arbitrary: nonEmptyChunkArbitrary,\n    equivalence: chunk_.getEquivalence\n  });\n};\n/**\n * @category Chunk transformations\n * @since 0.67.23\n */\nexport const NonEmptyChunk = value => {\n  const value_ = asSchema(value);\n  return transform(NonEmptyArray(value_), NonEmptyChunkFromSelf(typeSchema(value_)), {\n    decode: chunk_.unsafeFromNonEmptyArray,\n    encode: chunk_.toReadonlyArray\n  });\n};\nconst toData = a => Array.isArray(a) ? data_.array(a) : data_.struct(a);\nconst dataArbitrary = item => fc => item(fc).map(toData);\nconst dataPretty = item => d => `Data(${item(d)})`;\nconst dataParse = decodeUnknown => (u, options, ast) => Equal.isEqual(u) ? ParseResult.mapBoth(decodeUnknown(u, options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: toData\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category Data transformations\n * @since 0.67.0\n */\nexport const DataFromSelf = item => declare([item], {\n  decode: item => dataParse(ParseResult.decodeUnknown(item)),\n  encode: item => dataParse(ParseResult.encodeUnknown(item))\n}, {\n  description: `Data<${format(item)}>`,\n  pretty: dataPretty,\n  arbitrary: dataArbitrary\n});\n/**\n * @category Data transformations\n * @since 0.67.0\n */\nexport const Data = item => transform(item, DataFromSelf(typeSchema(item)), {\n  strict: false,\n  decode: toData,\n  encode: a => Array.isArray(a) ? Array.from(a) : Object.assign({}, a)\n});\nconst isField = u => isSchema(u) || isPropertySignature(u);\nconst isFields = fields => util_.ownKeys(fields).every(key => isField(fields[key]));\nconst getFields = hasFields => \"fields\" in hasFields ? hasFields.fields : getFields(hasFields.from);\nconst getSchemaFromFieldsOr = fieldsOr => isFields(fieldsOr) ? Struct(fieldsOr) : isSchema(fieldsOr) ? fieldsOr : Struct(getFields(fieldsOr));\nconst getFieldsFromFieldsOr = fieldsOr => isFields(fieldsOr) ? fieldsOr : getFields(fieldsOr);\n/**\n * @category classes\n * @since 0.67.0\n */\nexport const Class = identifier => (fieldsOr, annotations) => makeClass({\n  kind: \"Class\",\n  identifier,\n  schema: getSchemaFromFieldsOr(fieldsOr),\n  fields: getFieldsFromFieldsOr(fieldsOr),\n  Base: data_.Class,\n  annotations\n});\n/** @internal */\nexport const getClassTag = tag => withConstructorDefault(propertySignature(Literal(tag)), () => tag);\n/**\n * @category classes\n * @since 0.67.0\n */\nexport const TaggedClass = identifier => (tag, fieldsOr, annotations) => {\n  const fields = getFieldsFromFieldsOr(fieldsOr);\n  const schema = getSchemaFromFieldsOr(fieldsOr);\n  const newFields = {\n    _tag: getClassTag(tag)\n  };\n  const taggedFields = extendFields(newFields, fields);\n  return class TaggedClass extends makeClass({\n    kind: \"TaggedClass\",\n    identifier: identifier ?? tag,\n    schema: extend(schema, Struct(newFields)),\n    fields: taggedFields,\n    Base: data_.Class,\n    annotations\n  }) {\n    static _tag = tag;\n  };\n};\n/**\n * @category classes\n * @since 0.67.0\n */\nexport const TaggedError = identifier => (tag, fieldsOr, annotations) => {\n  class Base extends data_.Error {}\n  ;\n  Base.prototype.name = tag;\n  const fields = getFieldsFromFieldsOr(fieldsOr);\n  const schema = getSchemaFromFieldsOr(fieldsOr);\n  const newFields = {\n    _tag: getClassTag(tag)\n  };\n  const taggedFields = extendFields(newFields, fields);\n  return class TaggedErrorClass extends makeClass({\n    kind: \"TaggedError\",\n    identifier: identifier ?? tag,\n    schema: extend(schema, Struct(newFields)),\n    fields: taggedFields,\n    Base,\n    annotations,\n    toStringOverride(self) {\n      if (Predicate.isString(self.message) && self.message.length > 0) {\n        let message = `${self._tag}: ${self.message}`;\n        if (Predicate.isString(self.stack)) {\n          message = `${message}\\n${self.stack.split(\"\\n\").slice(1).join(\"\\n\")}`;\n        }\n        return message;\n      }\n    }\n  }) {\n    static _tag = tag;\n  };\n};\n/**\n * @category classes\n * @since 0.67.0\n */\nexport const TaggedRequest = identifier => (tag, Failure, Success, fields, annotations) => {\n  class SerializableRequest extends Request.Class {\n    get [serializable_.symbol]() {\n      return this.constructor;\n    }\n    get [serializable_.symbolResult]() {\n      return {\n        Failure,\n        Success\n      };\n    }\n  }\n  const taggedFields = extendFields({\n    _tag: getClassTag(tag)\n  }, fields);\n  return class TaggedRequestClass extends makeClass({\n    kind: \"TaggedRequest\",\n    identifier: identifier ?? tag,\n    schema: Struct(taggedFields),\n    fields: taggedFields,\n    Base: SerializableRequest,\n    annotations\n  }) {\n    static _tag = tag;\n  };\n};\nconst extendFields = (a, b) => {\n  const out = {\n    ...a\n  };\n  for (const key of util_.ownKeys(b)) {\n    if (key in a) {\n      throw new Error(errors_.getASTDuplicatePropertySignatureErrorMessage(key));\n    }\n    out[key] = b[key];\n  }\n  return out;\n};\n// does not overwrite existing title annotation\nconst orElseTitleAnnotation = (schema, title) => {\n  const annotation = AST.getTitleAnnotation(schema.ast);\n  if (option_.isNone(annotation)) {\n    return schema.annotations({\n      title\n    });\n  }\n  return schema;\n};\nconst getDisableValidationMakeOption = options => Predicate.isBoolean(options) ? options : options?.disableValidation ?? false;\nconst makeClass = ({\n  Base,\n  annotations,\n  fields,\n  identifier,\n  kind,\n  schema,\n  toStringOverride\n}) => {\n  const classSymbol = Symbol.for(`@effect/schema/${kind}/${identifier}`);\n  const validateSchema = orElseTitleAnnotation(schema, `${identifier} (Constructor)`);\n  const encodedSide = orElseTitleAnnotation(schema, `${identifier} (Encoded side)`);\n  const typeSide = orElseTitleAnnotation(typeSchema(schema), `${identifier} (Type side)`);\n  const fallbackInstanceOf = u => Predicate.hasProperty(u, classSymbol) && ParseResult.is(typeSide)(u);\n  return class extends Base {\n    constructor(props = {}, options = false) {\n      props = {\n        ...props\n      };\n      if (kind !== \"Class\") {\n        delete props[\"_tag\"];\n      }\n      props = lazilyMergeDefaults(fields, props);\n      if (!getDisableValidationMakeOption(options)) {\n        props = ParseResult.validateSync(validateSchema)(props);\n      }\n      super(props, true);\n    }\n    // ----------------\n    // Schema interface\n    // ----------------\n    static [TypeId] = variance;\n    static get ast() {\n      const declaration = declare([typeSide], {\n        decode: () => (input, _, ast) => input instanceof this || fallbackInstanceOf(input) ? ParseResult.succeed(input) : ParseResult.fail(new ParseResult.Type(ast, input)),\n        encode: () => (input, options) => input instanceof this ? ParseResult.succeed(input) : ParseResult.map(ParseResult.encodeUnknown(typeSide)(input, options), props => new this(props, true))\n      }, {\n        identifier,\n        title: identifier,\n        description: `an instance of ${identifier}`,\n        pretty: pretty => self => `${identifier}(${pretty(self)})`,\n        arbitrary: arb => fc => arb(fc).map(props => new this(props)),\n        equivalence: identity,\n        [AST.SurrogateAnnotationId]: typeSide.ast,\n        ...annotations\n      });\n      const transformation = transform(encodedSide, declaration, {\n        decode: input => new this(input, true),\n        encode: identity\n      }).annotations({\n        [AST.SurrogateAnnotationId]: schema.ast\n      });\n      return transformation.ast;\n    }\n    static pipe() {\n      return pipeArguments(this, arguments);\n    }\n    static annotations(annotations) {\n      return make(this.ast).annotations(annotations);\n    }\n    static toString() {\n      return `(${String(encodedSide)} <-> ${identifier})`;\n    }\n    // ----------------\n    // Class interface\n    // ----------------\n    static fields = {\n      ...fields\n    };\n    static identifier = identifier;\n    static extend(identifier) {\n      return (newFieldsOr, annotations) => {\n        const newFields = getFieldsFromFieldsOr(newFieldsOr);\n        const newSchema = getSchemaFromFieldsOr(newFieldsOr);\n        const extendedFields = extendFields(fields, newFields);\n        return makeClass({\n          kind,\n          identifier,\n          schema: extend(schema, newSchema),\n          fields: extendedFields,\n          Base: this,\n          annotations\n        });\n      };\n    }\n    static transformOrFail(identifier) {\n      return (newFields, options, annotations) => {\n        const transformedFields = extendFields(fields, newFields);\n        return makeClass({\n          kind,\n          identifier,\n          schema: transformOrFail(schema, typeSchema(Struct(transformedFields)), options),\n          fields: transformedFields,\n          Base: this,\n          annotations\n        });\n      };\n    }\n    static transformOrFailFrom(identifier) {\n      return (newFields, options, annotations) => {\n        const transformedFields = extendFields(fields, newFields);\n        return makeClass({\n          kind,\n          identifier,\n          schema: transformOrFail(encodedSchema(schema), Struct(transformedFields), options),\n          fields: transformedFields,\n          Base: this,\n          annotations\n        });\n      };\n    }\n    // ----------------\n    // other\n    // ----------------\n    get [classSymbol]() {\n      return classSymbol;\n    }\n    toString() {\n      if (toStringOverride !== undefined) {\n        const out = toStringOverride(this);\n        if (out !== undefined) {\n          return out;\n        }\n      }\n      return `${identifier}({ ${util_.ownKeys(fields).map(p => `${util_.formatPropertyKey(p)}: ${util_.formatUnknown(this[p])}`).join(\", \")} })`;\n    }\n  };\n};\nconst FiberIdNoneEncoded = /*#__PURE__*/Struct({\n  _tag: Literal(\"None\")\n}).annotations({\n  identifier: \"FiberIdNoneEncoded\"\n});\nconst FiberIdRuntimeEncoded = /*#__PURE__*/Struct({\n  _tag: Literal(\"Runtime\"),\n  id: Int.annotations({\n    title: \"id\",\n    description: \"id\"\n  }),\n  startTimeMillis: Int.annotations({\n    title: \"startTimeMillis\",\n    description: \"startTimeMillis\"\n  })\n}).annotations({\n  identifier: \"FiberIdRuntimeEncoded\"\n});\nconst FiberIdCompositeEncoded = /*#__PURE__*/Struct({\n  _tag: Literal(\"Composite\"),\n  left: suspend(() => FiberIdEncoded),\n  right: suspend(() => FiberIdEncoded)\n}).annotations({\n  identifier: \"FiberIdCompositeEncoded\"\n});\nconst FiberIdEncoded = /*#__PURE__*/Union(FiberIdNoneEncoded, FiberIdRuntimeEncoded, FiberIdCompositeEncoded).annotations({\n  identifier: \"FiberIdEncoded\"\n});\nconst fiberIdArbitrary = fc => fc.letrec(tie => ({\n  None: fc.record({\n    _tag: fc.constant(\"None\")\n  }),\n  Runtime: fc.record({\n    _tag: fc.constant(\"Runtime\"),\n    id: fc.integer(),\n    startTimeMillis: fc.integer()\n  }),\n  Composite: fc.record({\n    _tag: fc.constant(\"Composite\"),\n    left: tie(\"FiberId\"),\n    right: tie(\"FiberId\")\n  }),\n  FiberId: fc.oneof(tie(\"None\"), tie(\"Runtime\"), tie(\"Composite\"))\n})).FiberId.map(fiberIdDecode);\nconst fiberIdPretty = fiberId => {\n  switch (fiberId._tag) {\n    case \"None\":\n      return \"FiberId.none\";\n    case \"Runtime\":\n      return `FiberId.runtime(${fiberId.id}, ${fiberId.startTimeMillis})`;\n    case \"Composite\":\n      return `FiberId.composite(${fiberIdPretty(fiberId.right)}, ${fiberIdPretty(fiberId.left)})`;\n  }\n};\n/**\n * @category FiberId constructors\n * @since 0.67.0\n */\nexport class FiberIdFromSelf extends declare(fiberId_.isFiberId, {\n  identifier: \"FiberIdFromSelf\",\n  pretty: () => fiberIdPretty,\n  arbitrary: () => fiberIdArbitrary\n}) {\n  static annotations = super.annotations;\n}\nconst fiberIdDecode = input => {\n  switch (input._tag) {\n    case \"None\":\n      return fiberId_.none;\n    case \"Runtime\":\n      return fiberId_.runtime(input.id, input.startTimeMillis);\n    case \"Composite\":\n      return fiberId_.composite(fiberIdDecode(input.left), fiberIdDecode(input.right));\n  }\n};\nconst fiberIdEncode = input => {\n  switch (input._tag) {\n    case \"None\":\n      return {\n        _tag: \"None\"\n      };\n    case \"Runtime\":\n      return {\n        _tag: \"Runtime\",\n        id: input.id,\n        startTimeMillis: input.startTimeMillis\n      };\n    case \"Composite\":\n      return {\n        _tag: \"Composite\",\n        left: fiberIdEncode(input.left),\n        right: fiberIdEncode(input.right)\n      };\n  }\n};\n/**\n * @category FiberId transformations\n * @since 0.67.0\n */\nexport class FiberId extends transform(FiberIdEncoded, FiberIdFromSelf, {\n  decode: fiberIdDecode,\n  encode: fiberIdEncode\n}).annotations({\n  identifier: \"FiberId\"\n}) {\n  static annotations = super.annotations;\n}\nconst causeDieEncoded = defect => Struct({\n  _tag: Literal(\"Die\"),\n  defect\n});\nconst CauseEmptyEncoded = /*#__PURE__*/Struct({\n  _tag: /*#__PURE__*/Literal(\"Empty\")\n});\nconst causeFailEncoded = error => Struct({\n  _tag: Literal(\"Fail\"),\n  error\n});\nconst CauseInterruptEncoded = /*#__PURE__*/Struct({\n  _tag: /*#__PURE__*/Literal(\"Interrupt\"),\n  fiberId: FiberIdEncoded\n});\nconst causeParallelEncoded = causeEncoded => Struct({\n  _tag: Literal(\"Parallel\"),\n  left: causeEncoded,\n  right: causeEncoded\n});\nconst causeSequentialEncoded = causeEncoded => Struct({\n  _tag: Literal(\"Sequential\"),\n  left: causeEncoded,\n  right: causeEncoded\n});\nconst causeEncoded = (error, defect) => {\n  const recur = suspend(() => out);\n  const out = Union(CauseEmptyEncoded, causeFailEncoded(error), causeDieEncoded(defect), CauseInterruptEncoded, causeSequentialEncoded(recur), causeParallelEncoded(recur)).annotations({\n    description: `CauseEncoded<${format(error)}>`\n  });\n  return out;\n};\nconst causeArbitrary = (error, defect) => fc => fc.letrec(tie => ({\n  Empty: fc.record({\n    _tag: fc.constant(\"Empty\")\n  }),\n  Fail: fc.record({\n    _tag: fc.constant(\"Fail\"),\n    error: error(fc)\n  }),\n  Die: fc.record({\n    _tag: fc.constant(\"Die\"),\n    defect: defect(fc)\n  }),\n  Interrupt: fc.record({\n    _tag: fc.constant(\"Interrupt\"),\n    fiberId: fiberIdArbitrary(fc)\n  }),\n  Sequential: fc.record({\n    _tag: fc.constant(\"Sequential\"),\n    left: tie(\"Cause\"),\n    right: tie(\"Cause\")\n  }),\n  Parallel: fc.record({\n    _tag: fc.constant(\"Parallel\"),\n    left: tie(\"Cause\"),\n    right: tie(\"Cause\")\n  }),\n  Cause: fc.oneof(tie(\"Empty\"), tie(\"Fail\"), tie(\"Die\"), tie(\"Interrupt\"), tie(\"Sequential\"), tie(\"Parallel\"))\n})).Cause.map(causeDecode);\nconst causePretty = error => cause => {\n  const f = cause => {\n    switch (cause._tag) {\n      case \"Empty\":\n        return \"Cause.empty\";\n      case \"Fail\":\n        return `Cause.fail(${error(cause.error)})`;\n      case \"Die\":\n        return `Cause.die(${cause_.pretty(cause)})`;\n      case \"Interrupt\":\n        return `Cause.interrupt(${fiberIdPretty(cause.fiberId)})`;\n      case \"Sequential\":\n        return `Cause.sequential(${f(cause.left)}, ${f(cause.right)})`;\n      case \"Parallel\":\n        return `Cause.parallel(${f(cause.left)}, ${f(cause.right)})`;\n    }\n  };\n  return f(cause);\n};\nconst causeParse = decodeUnknown => (u, options, ast) => cause_.isCause(u) ? ParseResult.mapBoth(decodeUnknown(causeEncode(u), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: causeDecode\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category Cause transformations\n * @since 0.67.0\n */\nexport const CauseFromSelf = ({\n  defect = Unknown,\n  error\n}) => {\n  return declare([error, defect], {\n    decode: (error, defect) => causeParse(ParseResult.decodeUnknown(causeEncoded(error, defect))),\n    encode: (error, defect) => causeParse(ParseResult.encodeUnknown(causeEncoded(error, defect)))\n  }, {\n    description: `Cause<${format(error)}>`,\n    pretty: causePretty,\n    arbitrary: causeArbitrary\n  });\n};\nfunction causeDecode(cause) {\n  switch (cause._tag) {\n    case \"Empty\":\n      return cause_.empty;\n    case \"Fail\":\n      return cause_.fail(cause.error);\n    case \"Die\":\n      return cause_.die(cause.defect);\n    case \"Interrupt\":\n      return cause_.interrupt(fiberIdDecode(cause.fiberId));\n    case \"Sequential\":\n      return cause_.sequential(causeDecode(cause.left), causeDecode(cause.right));\n    case \"Parallel\":\n      return cause_.parallel(causeDecode(cause.left), causeDecode(cause.right));\n  }\n}\nfunction causeEncode(cause) {\n  switch (cause._tag) {\n    case \"Empty\":\n      return {\n        _tag: \"Empty\"\n      };\n    case \"Fail\":\n      return {\n        _tag: \"Fail\",\n        error: cause.error\n      };\n    case \"Die\":\n      return {\n        _tag: \"Die\",\n        defect: cause.defect\n      };\n    case \"Interrupt\":\n      return {\n        _tag: \"Interrupt\",\n        fiberId: cause.fiberId\n      };\n    case \"Sequential\":\n      return {\n        _tag: \"Sequential\",\n        left: causeEncode(cause.left),\n        right: causeEncode(cause.right)\n      };\n    case \"Parallel\":\n      return {\n        _tag: \"Parallel\",\n        left: causeEncode(cause.left),\n        right: causeEncode(cause.right)\n      };\n  }\n}\n/**\n * @category Cause transformations\n * @since 0.67.0\n */\nexport const CauseDefectUnknown = /*#__PURE__*/transform(Unknown, Unknown, {\n  decode: u => {\n    if (Predicate.isObject(u) && \"message\" in u && typeof u.message === \"string\") {\n      const err = new Error(u.message, {\n        cause: u\n      });\n      if (\"name\" in u && typeof u.name === \"string\") {\n        err.name = u.name;\n      }\n      err.stack = \"stack\" in u && typeof u.stack === \"string\" ? u.stack : \"\";\n      return err;\n    }\n    return String(u);\n  },\n  encode: defect => {\n    if (defect instanceof Error) {\n      return {\n        name: defect.name,\n        message: defect.message\n      };\n    }\n    return String(defect);\n  }\n});\n/**\n * @category Cause transformations\n * @since 0.67.0\n */\nexport const Cause = ({\n  defect = CauseDefectUnknown,\n  error\n}) => {\n  const error_ = asSchema(error);\n  return transform(causeEncoded(error_, defect), CauseFromSelf({\n    error: typeSchema(error_),\n    defect: typeSchema(defect)\n  }), {\n    decode: causeDecode,\n    encode: causeEncode\n  });\n};\nconst exitFailureEncoded = (error, defect) => Struct({\n  _tag: Literal(\"Failure\"),\n  cause: causeEncoded(error, defect)\n}).annotations({\n  description: `FailureEncoded<${format(error)}>`\n});\nconst exitSuccessEncoded = value => Struct({\n  _tag: Literal(\"Success\"),\n  value\n}).annotations({\n  description: `SuccessEncoded<${format(value)}>`\n});\nconst exitEncoded = (value, error, defect) => Union(exitFailureEncoded(error, defect), exitSuccessEncoded(value)).annotations({\n  description: `ExitEncoded<${format(value)}, ${format(error)}>`\n});\nconst exitDecode = input => {\n  switch (input._tag) {\n    case \"Failure\":\n      return exit_.failCause(causeDecode(input.cause));\n    case \"Success\":\n      return exit_.succeed(input.value);\n  }\n};\nconst exitArbitrary = (value, error, defect) => fc => fc.oneof(fc.record({\n  _tag: fc.constant(\"Failure\"),\n  cause: causeArbitrary(error, defect)(fc)\n}), fc.record({\n  _tag: fc.constant(\"Success\"),\n  value: value(fc)\n})).map(exitDecode);\nconst exitPretty = (value, error) => exit => exit._tag === \"Failure\" ? `Exit.failCause(${causePretty(error)(exit.cause)})` : `Exit.succeed(${value(exit.value)})`;\nconst exitParse = (decodeUnknownValue, decodeUnknownCause) => (u, options, ast) => exit_.isExit(u) ? exit_.match(u, {\n  onFailure: cause => ParseResult.map(decodeUnknownCause(cause, options), exit_.failCause),\n  onSuccess: value => ParseResult.map(decodeUnknownValue(value, options), exit_.succeed)\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category Exit transformations\n * @since 0.67.0\n */\nexport const ExitFromSelf = ({\n  defect = Unknown,\n  failure,\n  success\n}) => declare([success, failure, defect], {\n  decode: (success, failure, defect) => exitParse(ParseResult.decodeUnknown(success), ParseResult.decodeUnknown(CauseFromSelf({\n    error: failure,\n    defect\n  }))),\n  encode: (success, failure, defect) => exitParse(ParseResult.encodeUnknown(success), ParseResult.encodeUnknown(CauseFromSelf({\n    error: failure,\n    defect\n  })))\n}, {\n  description: `Exit<${format(success)}, ${format(failure)}>`,\n  pretty: exitPretty,\n  arbitrary: exitArbitrary\n});\n/**\n * @category Exit transformations\n * @since 0.67.0\n */\nexport const Exit = ({\n  defect = CauseDefectUnknown,\n  failure,\n  success\n}) => {\n  const success_ = asSchema(success);\n  const failure_ = asSchema(failure);\n  return transform(exitEncoded(success_, failure_, defect), ExitFromSelf({\n    failure: typeSchema(failure_),\n    success: typeSchema(success_),\n    defect: typeSchema(defect)\n  }), {\n    decode: exitDecode,\n    encode: exit => exit._tag === \"Failure\" ? {\n      _tag: \"Failure\",\n      cause: exit.cause\n    } : {\n      _tag: \"Success\",\n      value: exit.value\n    }\n  });\n};\nconst hashSetArbitrary = item => fc => fc.array(item(fc)).map(as => hashSet_.fromIterable(as));\nconst hashSetPretty = item => set => `HashSet(${Array.from(set).map(a => item(a)).join(\", \")})`;\nconst hashSetEquivalence = item => {\n  const arrayEquivalence = array_.getEquivalence(item);\n  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a), Array.from(b)));\n};\nconst hashSetParse = decodeUnknown => (u, options, ast) => hashSet_.isHashSet(u) ? ParseResult.mapBoth(decodeUnknown(Array.from(u), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: hashSet_.fromIterable\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category HashSet transformations\n * @since 0.67.0\n */\nexport const HashSetFromSelf = value => {\n  return declare([value], {\n    decode: item => hashSetParse(ParseResult.decodeUnknown(Array$(item))),\n    encode: item => hashSetParse(ParseResult.encodeUnknown(Array$(item)))\n  }, {\n    description: `HashSet<${format(value)}>`,\n    pretty: hashSetPretty,\n    arbitrary: hashSetArbitrary,\n    equivalence: hashSetEquivalence\n  });\n};\n/**\n * @category HashSet transformations\n * @since 0.67.0\n */\nexport const HashSet = value => {\n  const value_ = asSchema(value);\n  return transform(Array$(value_), HashSetFromSelf(typeSchema(value_)), {\n    decode: as => hashSet_.fromIterable(as),\n    encode: set => Array.from(set)\n  });\n};\nconst hashMapArbitrary = (key, value) => fc => fc.array(fc.tuple(key(fc), value(fc))).map(as => hashMap_.fromIterable(as));\nconst hashMapPretty = (key, value) => map => `HashMap([${Array.from(map).map(([k, v]) => `[${key(k)}, ${value(v)}]`).join(\", \")}])`;\nconst hashMapEquivalence = (key, value) => {\n  const arrayEquivalence = array_.getEquivalence(Equivalence.make(([ka, va], [kb, vb]) => key(ka, kb) && value(va, vb)));\n  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a), Array.from(b)));\n};\nconst hashMapParse = decodeUnknown => (u, options, ast) => hashMap_.isHashMap(u) ? ParseResult.mapBoth(decodeUnknown(Array.from(u), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: hashMap_.fromIterable\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category HashMap transformations\n * @since 0.67.0\n */\nexport const HashMapFromSelf = ({\n  key,\n  value\n}) => {\n  return declare([key, value], {\n    decode: (key, value) => hashMapParse(ParseResult.decodeUnknown(Array$(Tuple(key, value)))),\n    encode: (key, value) => hashMapParse(ParseResult.encodeUnknown(Array$(Tuple(key, value))))\n  }, {\n    description: `HashMap<${format(key)}, ${format(value)}>`,\n    pretty: hashMapPretty,\n    arbitrary: hashMapArbitrary,\n    equivalence: hashMapEquivalence\n  });\n};\n/**\n * @category HashMap transformations\n * @since 0.67.0\n */\nexport const HashMap = ({\n  key,\n  value\n}) => {\n  const key_ = asSchema(key);\n  const value_ = asSchema(value);\n  return transform(Array$(Tuple(key_, value_)), HashMapFromSelf({\n    key: typeSchema(key_),\n    value: typeSchema(value_)\n  }), {\n    decode: as => hashMap_.fromIterable(as),\n    encode: map => Array.from(map)\n  });\n};\nconst listArbitrary = item => fc => fc.array(item(fc)).map(as => list_.fromIterable(as));\nconst listPretty = item => set => `List(${Array.from(set).map(a => item(a)).join(\", \")})`;\nconst listEquivalence = item => {\n  const arrayEquivalence = array_.getEquivalence(item);\n  return Equivalence.make((a, b) => arrayEquivalence(Array.from(a), Array.from(b)));\n};\nconst listParse = decodeUnknown => (u, options, ast) => list_.isList(u) ? ParseResult.mapBoth(decodeUnknown(Array.from(u), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: list_.fromIterable\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category List transformations\n * @since 0.67.0\n */\nexport const ListFromSelf = value => {\n  return declare([value], {\n    decode: item => listParse(ParseResult.decodeUnknown(Array$(item))),\n    encode: item => listParse(ParseResult.encodeUnknown(Array$(item)))\n  }, {\n    description: `List<${format(value)}>`,\n    pretty: listPretty,\n    arbitrary: listArbitrary,\n    equivalence: listEquivalence\n  });\n};\n/**\n * @category List transformations\n * @since 0.67.0\n */\nexport const List = value => {\n  const value_ = asSchema(value);\n  return transform(Array$(value_), ListFromSelf(typeSchema(value_)), {\n    decode: as => list_.fromIterable(as),\n    encode: set => Array.from(set)\n  });\n};\nconst sortedSetArbitrary = (item, ord) => fc => fc.array(item(fc)).map(as => sortedSet_.fromIterable(as, ord));\nconst sortedSetPretty = item => set => `new SortedSet([${Array.from(sortedSet_.values(set)).map(a => item(a)).join(\", \")}])`;\nconst sortedSetParse = (decodeUnknown, ord) => (u, options, ast) => sortedSet_.isSortedSet(u) ? ParseResult.mapBoth(decodeUnknown(Array.from(sortedSet_.values(u)), options), {\n  onFailure: e => new ParseResult.Composite(ast, u, e),\n  onSuccess: as => sortedSet_.fromIterable(as, ord)\n}) : ParseResult.fail(new ParseResult.Type(ast, u));\n/**\n * @category SortedSet transformations\n * @since 0.67.0\n */\nexport const SortedSetFromSelf = (value, ordA, ordI) => {\n  return declare([value], {\n    decode: item => sortedSetParse(ParseResult.decodeUnknown(Array$(item)), ordA),\n    encode: item => sortedSetParse(ParseResult.encodeUnknown(Array$(item)), ordI)\n  }, {\n    description: `SortedSet<${format(value)}>`,\n    pretty: sortedSetPretty,\n    arbitrary: arb => sortedSetArbitrary(arb, ordA),\n    equivalence: () => sortedSet_.getEquivalence()\n  });\n};\n/**\n * @category SortedSet transformations\n * @since 0.67.0\n */\nexport const SortedSet = (value, ordA) => {\n  const value_ = asSchema(value);\n  const to = typeSchema(value_);\n  return transform(Array$(value_), SortedSetFromSelf(to, ordA, ordA), {\n    decode: as => sortedSet_.fromIterable(as, ordA),\n    encode: set => Array.from(sortedSet_.values(set))\n  });\n};\n/**\n * Converts an arbitrary value to a `boolean` by testing whether it is truthy.\n * Uses `!!val` to coerce the value to a `boolean`.\n *\n * @see https://developer.mozilla.org/docs/Glossary/Truthy\n * @category boolean constructors\n * @since 0.67.0\n */\nexport class BooleanFromUnknown extends transform(Unknown, Boolean$, {\n  decode: Predicate.isTruthy,\n  encode: identity\n}).annotations({\n  identifier: \"BooleanFromUnknown\"\n}) {\n  static annotations = super.annotations;\n}\n/**\n * @category Config validations\n * @since 0.67.12\n */\nexport const Config = (name, schema) => {\n  const decodeEither_ = decodeEither(schema);\n  return config_.string(name).pipe(config_.mapOrFail(a => decodeEither_(a).pipe(either_.mapLeft(error => configError_.InvalidData([], TreeFormatter.formatErrorSync(error))))));\n};\n//# sourceMappingURL=Schema.js.map","/**\n * @since 0.67.0\n */\nimport * as Effect from \"effect/Effect\";\nimport * as Option from \"effect/Option\";\nimport * as Predicate from \"effect/Predicate\";\nimport * as AST from \"./AST.js\";\nimport * as util_ from \"./internal/util.js\";\nconst make = (value, forest = []) => ({\n  value,\n  forest\n});\n/**\n * @category formatting\n * @since 0.67.0\n */\nexport const formatIssue = issue => Effect.map(go(issue), tree => drawTree(tree));\n/**\n * @category formatting\n * @since 0.67.0\n */\nexport const formatIssueSync = issue => Effect.runSync(formatIssue(issue));\n/**\n * @category formatting\n * @since 0.67.0\n */\nexport const formatError = error => formatIssue(error.issue);\n/**\n * @category formatting\n * @since 0.67.0\n */\nexport const formatErrorSync = error => formatIssueSync(error.issue);\nconst drawTree = tree => tree.value + draw(\"\\n\", tree.forest);\nconst draw = (indentation, forest) => {\n  let r = \"\";\n  const len = forest.length;\n  let tree;\n  for (let i = 0; i < len; i++) {\n    tree = forest[i];\n    const isLast = i === len - 1;\n    r += indentation + (isLast ? \"\" : \"\") + \" \" + tree.value;\n    r += draw(indentation + (len > 1 && !isLast ? \"  \" : \"   \"), tree.forest);\n  }\n  return r;\n};\nconst formatTransformationKind = kind => {\n  switch (kind) {\n    case \"Encoded\":\n      return \"Encoded side transformation failure\";\n    case \"Transformation\":\n      return \"Transformation process failure\";\n    case \"Type\":\n      return \"Type side transformation failure\";\n  }\n};\nconst formatRefinementKind = kind => {\n  switch (kind) {\n    case \"From\":\n      return \"From side refinement failure\";\n    case \"Predicate\":\n      return \"Predicate refinement failure\";\n  }\n};\nconst getInnerMessage = issue => {\n  switch (issue._tag) {\n    case \"Refinement\":\n      {\n        if (issue.kind === \"From\") {\n          return getMessage(issue.issue);\n        }\n        break;\n      }\n    case \"Transformation\":\n      {\n        return getMessage(issue.issue);\n      }\n  }\n  return Option.none();\n};\nconst getAnnotated = issue => {\n  if (\"ast\" in issue) {\n    return Option.some(issue.ast);\n  }\n  return Option.none();\n};\nconst getCurrentMessage = issue => getAnnotated(issue).pipe(Option.flatMap(AST.getMessageAnnotation), Effect.flatMap(annotation => {\n  const out = annotation(issue);\n  return Predicate.isString(out) ? Effect.succeed({\n    message: out,\n    override: false\n  }) : Effect.isEffect(out) ? Effect.map(out, message => ({\n    message,\n    override: false\n  })) : Predicate.isString(out.message) ? Effect.succeed({\n    message: out.message,\n    override: out.override\n  }) : Effect.map(out.message, message => ({\n    message,\n    override: out.override\n  }));\n}));\n/** @internal */\nexport const getMessage = issue => {\n  const current = getCurrentMessage(issue);\n  return getInnerMessage(issue).pipe(Effect.flatMap(inner => Effect.map(current, current => current.override ? current.message : inner)), Effect.catchAll(() => Effect.flatMap(current, current => {\n    if (!current.override && (issue._tag === \"Refinement\" && issue.kind !== \"Predicate\" || issue._tag === \"Transformation\" && issue.kind !== \"Transformation\")) {\n      return Option.none();\n    }\n    return Effect.succeed(current.message);\n  })));\n};\nconst getParseIssueTitleAnnotation = issue => getAnnotated(issue).pipe(Option.flatMap(AST.getParseIssueTitleAnnotation), Option.filterMap(annotation => Option.fromNullable(annotation(issue))));\n/** @internal */\nexport const formatTypeMessage = e => getMessage(e).pipe(Effect.orElse(() => getParseIssueTitleAnnotation(e)), Effect.catchAll(() => Effect.succeed(e.message ?? `Expected ${String(e.ast)}, actual ${util_.formatUnknown(e.actual)}`)));\nconst getParseIssueTitle = issue => Option.getOrElse(getParseIssueTitleAnnotation(issue), () => String(issue.ast));\n/** @internal */\nexport const formatForbiddenMessage = e => e.message ?? \"is forbidden\";\n/** @internal */\nexport const formatUnexpectedMessage = e => e.message ?? \"is unexpected\";\n/** @internal */\nexport const formatMissingMessage = e => AST.getMissingMessageAnnotation(e.ast).pipe(Effect.flatMap(annotation => {\n  const out = annotation();\n  return Predicate.isString(out) ? Effect.succeed(out) : out;\n}), Effect.catchAll(() => Effect.succeed(e.message ?? \"is missing\")));\nconst getTree = (issue, onFailure) => Effect.matchEffect(getMessage(issue), {\n  onFailure,\n  onSuccess: message => Effect.succeed(make(message))\n});\nconst go = e => {\n  switch (e._tag) {\n    case \"Type\":\n      return Effect.map(formatTypeMessage(e), make);\n    case \"Forbidden\":\n      return Effect.succeed(make(getParseIssueTitle(e), [make(formatForbiddenMessage(e))]));\n    case \"Unexpected\":\n      return Effect.succeed(make(formatUnexpectedMessage(e)));\n    case \"Missing\":\n      return Effect.map(formatMissingMessage(e), make);\n    case \"Transformation\":\n      return getTree(e, () => Effect.map(go(e.issue), tree => make(getParseIssueTitle(e), [make(formatTransformationKind(e.kind), [tree])])));\n    case \"Refinement\":\n      return getTree(e, () => Effect.map(go(e.issue), tree => make(getParseIssueTitle(e), [make(formatRefinementKind(e.kind), [tree])])));\n    case \"Pointer\":\n      return Effect.map(go(e.issue), tree => make(util_.formatPath(e.path), [tree]));\n    case \"Composite\":\n      {\n        const parseIssueTitle = getParseIssueTitle(e);\n        return getTree(e, () => util_.isNonEmpty(e.issues) ? Effect.map(Effect.forEach(e.issues, go), forest => make(parseIssueTitle, forest)) : Effect.map(go(e.issues), tree => make(parseIssueTitle, [tree])));\n      }\n  }\n};\n//# sourceMappingURL=TreeFormatter.js.map","import * as array_ from \"effect/Array\";\nimport * as util_ from \"./util.js\";\nconst getErrorMessage = (reason, details, path, ast) => {\n  let out = reason;\n  if (path && array_.isNonEmptyReadonlyArray(path)) {\n    out += `\\nat path: ${util_.formatPath(path)}`;\n  }\n  if (details !== undefined) {\n    out += `\\ndetails: ${details}`;\n  }\n  if (ast) {\n    out += `\\nschema (${ast._tag}): ${ast}`;\n  }\n  return out;\n};\n// ---------------------------------------------\n// generic\n// ---------------------------------------------\n/** @internal */\nexport const getInvalidArgumentErrorMessage = details => getErrorMessage(\"Invalid Argument\", details);\nconst getUnsupportedSchemaErrorMessage = (details, path, ast) => getErrorMessage(\"Unsupported schema\", details, path, ast);\nconst getMissingAnnotationErrorMessage = (details, path, ast) => getErrorMessage(\"Missing annotation\", details, path, ast);\n// ---------------------------------------------\n// Arbitrary\n// ---------------------------------------------\n/** @internal */\nexport const getArbitraryUnsupportedErrorMessage = (path, ast) => getUnsupportedSchemaErrorMessage(\"Cannot build an Arbitrary for this schema\", path, ast);\n/** @internal */\nexport const getArbitraryMissingAnnotationErrorMessage = (path, ast) => getMissingAnnotationErrorMessage(`Generating an Arbitrary for this schema requires an \"arbitrary\" annotation`, path, ast);\n/** @internal */\nexport const getArbitraryEmptyEnumErrorMessage = path => getErrorMessage(\"Empty Enums schema\", \"Generating an Arbitrary for this schema requires at least one enum\", path);\n// ---------------------------------------------\n// Equivalence\n// ---------------------------------------------\n/** @internal */\nexport const getEquivalenceUnsupportedErrorMessage = (ast, path) => getUnsupportedSchemaErrorMessage(\"Cannot build an Equivalence\", path, ast);\n// ---------------------------------------------\n// JSON Schema\n// ---------------------------------------------\n/** @internal */\nexport const getJSONSchemaMissingAnnotationErrorMessage = (path, ast) => getMissingAnnotationErrorMessage(`Generating a JSON Schema for this schema requires a \"jsonSchema\" annotation`, path, ast);\n/** @internal */\nexport const getJSONSchemaMissingIdentifierAnnotationErrorMessage = (path, ast) => getMissingAnnotationErrorMessage(`Generating a JSON Schema for this schema requires an \"identifier\" annotation`, path, ast);\n/** @internal */\nexport const getJSONSchemaUnsupportedParameterErrorMessage = (path, parameter) => getErrorMessage(\"Unsupported index signature parameter\", undefined, path, parameter);\n/** @internal */\nexport const getJSONSchemaUnsupportedPostRestElementsErrorMessage = path => getErrorMessage(\"Generating a JSON Schema for post-rest elements is not currently supported. You're welcome to contribute by submitting a Pull Request\", undefined, path);\n/** @internal */\nexport const getJSONSchemaUnsupportedKeyErrorMessage = (key, path) => getErrorMessage(\"Unsupported key\", `Cannot encode ${util_.formatPropertyKey(key)} key to JSON Schema`, path);\n// ---------------------------------------------\n// Pretty\n// ---------------------------------------------\n/** @internal */\nexport const getPrettyMissingAnnotationErrorMessage = (path, ast) => getMissingAnnotationErrorMessage(`Generating a Pretty for this schema requires a \"pretty\" annotation`, path, ast);\n/** @internal */\nexport const getPrettyNeverErrorMessage = \"Cannot pretty print a `never` value\";\n/** @internal */\nexport const getPrettyNoMatchingSchemaErrorMessage = (actual, path, ast) => getErrorMessage(\"Unexpected Error\", `Cannot find a matching schema for ${util_.formatUnknown(actual)}`, path, ast);\n// ---------------------------------------------\n// Schema\n// ---------------------------------------------\n/** @internal */\nexport const getSchemaExtendErrorMessage = (x, y, path) => getErrorMessage(\"Unsupported schema or overlapping types\", `cannot extend ${x} with ${y}`, path);\n/** @internal */\nexport const getSchemaUnsupportedLiteralSpanErrorMessage = ast => getErrorMessage(\"Unsupported template literal span\", undefined, undefined, ast);\n// ---------------------------------------------\n// AST\n// ---------------------------------------------\n/** @internal */\nexport const getASTUnsupportedSchema = ast => getUnsupportedSchemaErrorMessage(undefined, undefined, ast);\n/** @internal */\nexport const getASTUnsupportedKeySchema = ast => getErrorMessage(\"Unsupported key schema\", undefined, undefined, ast);\n/** @internal */\nexport const getASTUnsupportedLiteral = literal => getErrorMessage(\"Unsupported literal\", `literal value: ${util_.formatUnknown(literal)}`);\n/** @internal */\nexport const getASTDuplicateIndexSignatureErrorMessage = type => getErrorMessage(\"Duplicate index signature\", `${type} index signature`);\n/** @internal */\nexport const getASTIndexSignatureParameterErrorMessage = /*#__PURE__*/getErrorMessage(\"Unsupported index signature parameter\", \"An index signature parameter type must be `string`, `symbol`, a template literal type or a refinement of the previous types\");\n/** @internal */\nexport const getASTRequiredElementFollowinAnOptionalElementErrorMessage = /*#__PURE__*/getErrorMessage(\"Invalid element\", \"A required element cannot follow an optional element. ts(1257)\");\n/** @internal */\nexport const getASTDuplicatePropertySignatureTransformationErrorMessage = key => getErrorMessage(\"Duplicate property signature transformation\", `Duplicate key ${util_.formatUnknown(key)}`);\n/** @internal */\nexport const getASTUnsupportedRenameSchema = ast => getUnsupportedSchemaErrorMessage(undefined, undefined, ast);\n/** @internal */\nexport const getASTDuplicatePropertySignatureErrorMessage = key => getErrorMessage(\"Duplicate property signature\", `Duplicate key ${util_.formatUnknown(key)}`);\n//# sourceMappingURL=errors.js.map","/** @internal */\nexport const GreaterThanTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/GreaterThan\");\n/** @internal */\nexport const GreaterThanOrEqualToTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/GreaterThanOrEqualTo\");\n/** @internal */\nexport const LessThanTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/LessThan\");\n/** @internal */\nexport const LessThanOrEqualToTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/LessThanOrEqualTo\");\n/** @internal */\nexport const IntTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Int\");\n/** @internal */\nexport const BetweenTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Between\");\n/** @internal */\nexport const GreaterThanBigintTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/GreaterThanBigint\");\n/** @internal */\nexport const GreaterThanOrEqualToBigIntTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/GreaterThanOrEqualToBigint\");\n/** @internal */\nexport const LessThanBigIntTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/LessThanBigint\");\n/** @internal */\nexport const LessThanOrEqualToBigIntTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/LessThanOrEqualToBigint\");\n/** @internal */\nexport const BetweenBigintTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/BetweenBigint\");\n/** @internal */\nexport const MinLengthTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/MinLength\");\n/** @internal */\nexport const MaxLengthTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/MaxLength\");\n/** @internal */\nexport const LengthTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/Length\");\n/** @internal */\nexport const MinItemsTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/MinItems\");\n/** @internal */\nexport const MaxItemsTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/MaxItems\");\n/** @internal */\nexport const ItemsCountTypeId = /*#__PURE__*/Symbol.for(\"@effect/schema/TypeId/ItemsCount\");\n//# sourceMappingURL=filters.js.map","/** @internal */\nexport const symbol = /*#__PURE__*/Symbol.for(\"@effect/schema/Serializable/symbol\");\n/** @internal */\nexport const symbolResult = /*#__PURE__*/Symbol.for(\"@effect/schema/Serializable/symbolResult\");\n//# sourceMappingURL=serializable.js.map","import * as array_ from \"effect/Array\";\nimport * as Predicate from \"effect/Predicate\";\n/** @internal */\nexport const getKeysForIndexSignature = (input, parameter) => {\n  switch (parameter._tag) {\n    case \"StringKeyword\":\n    case \"TemplateLiteral\":\n      return Object.keys(input);\n    case \"SymbolKeyword\":\n      return Object.getOwnPropertySymbols(input);\n    case \"Refinement\":\n      return getKeysForIndexSignature(input, parameter.from);\n  }\n};\n/** @internal */\nexport const ownKeys = o => Object.keys(o).concat(Object.getOwnPropertySymbols(o));\n/** @internal */\nexport const memoizeThunk = f => {\n  let done = false;\n  let a;\n  return () => {\n    if (done) {\n      return a;\n    }\n    a = f();\n    done = true;\n    return a;\n  };\n};\n/** @internal */\nexport const formatUnknown = u => {\n  if (Predicate.isString(u)) {\n    return JSON.stringify(u);\n  } else if (Predicate.isNumber(u) || u == null || Predicate.isBoolean(u) || Predicate.isSymbol(u) || Predicate.isDate(u)) {\n    return String(u);\n  } else if (Predicate.isBigInt(u)) {\n    return String(u) + \"n\";\n  } else if (!array_.isArray(u) && Predicate.hasProperty(u, \"toString\") && Predicate.isFunction(u[\"toString\"]) && u[\"toString\"] !== Object.prototype.toString) {\n    return u[\"toString\"]();\n  }\n  try {\n    JSON.stringify(u);\n    if (array_.isArray(u)) {\n      return `[${u.map(formatUnknown).join(\",\")}]`;\n    } else {\n      return `{${ownKeys(u).map(k => `${Predicate.isString(k) ? JSON.stringify(k) : String(k)}:${formatUnknown(u[k])}`).join(\",\")}}`;\n    }\n  } catch (e) {\n    return String(u);\n  }\n};\n/** @internal */\nexport const formatPropertyKey = name => typeof name === \"string\" ? JSON.stringify(name) : String(name);\n/** @internal */\nexport const isNonEmpty = x => Array.isArray(x);\n/** @internal */\nexport const isSingle = x => !Array.isArray(x);\n/** @internal */\nexport const formatPathKey = key => `[${formatPropertyKey(key)}]`;\n/** @internal */\nexport const formatPath = path => isNonEmpty(path) ? path.map(formatPathKey).join(\"\") : formatPathKey(path);\n//# sourceMappingURL=util.js.map","/* eslint-disable @typescript-eslint/no-unsafe-assignment */\n/* eslint-disable @typescript-eslint/no-unsafe-argument */\nimport { Config, createRuntime, ensureTransferableError } from \"@evolu/common\";\nimport * as Effect from \"effect/Effect\";\nimport { nanoid } from \"nanoid\";\nexport const wrap = (worker) => {\n    const callbacks = new Map();\n    worker.onmessage = ({ data: message }) => {\n        const callback = callbacks.get(message.id);\n        if (callback) {\n            callback(message.response);\n            callbacks.delete(message.id);\n        }\n    };\n    const proxy = new Proxy(worker, {\n        get(target, name) {\n            return (...argsMaybeWithCallback) => Effect.flatMap(Config, (config) => Effect.async((resume) => {\n                const ports = [];\n                const args = argsMaybeWithCallback.map((arg) => {\n                    if (typeof arg !== \"function\")\n                        return arg;\n                    const channel = new MessageChannel();\n                    channel.port1.onmessage = ({ data }) => {\n                        // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                        arg(...data);\n                    };\n                    ports.push(channel.port2);\n                    return channel.port2;\n                });\n                // Nanoid is pretty fast. No reason to use incremented counter.\n                const id = nanoid();\n                callbacks.set(id, (response) => {\n                    resume(Effect[response._tag](response.value));\n                });\n                const message = { id, name, args, config };\n                target.postMessage(message, ports);\n            }));\n        },\n    });\n    return proxy;\n};\n/** Expose an object with functions returning Effect. */\nexport const expose = (object) => {\n    let runtime = null;\n    onmessage = ({ data: { id, name, args, config }, }) => {\n        if (runtime == null)\n            runtime = createRuntime(config);\n        const argsMaybeWithCallback = args.map((arg) => {\n            if (!(arg instanceof MessagePort))\n                return arg;\n            return (...args) => {\n                arg.postMessage(args);\n            };\n        });\n        runtime.runFork(object[name](...argsMaybeWithCallback).pipe(Effect.map((value) => ({ id, response: { _tag: \"succeed\", value } })), Effect.catchAll((value) => Effect.succeed({ id, response: { _tag: \"fail\", value } })), Effect.catchAllDefect((error) => Effect.succeed({\n            id,\n            response: { _tag: \"die\", value: ensureTransferableError(error) },\n        })), Effect.tap((message) => postMessage(message))));\n    };\n};\n","import * as Context from \"effect/Context\";\nimport * as Layer from \"effect/Layer\";\nimport * as LogLevel from \"effect/LogLevel\";\nimport * as Logger from \"effect/Logger\";\nimport * as ManagedRuntime from \"effect/ManagedRuntime\";\nimport * as Match from \"effect/Match\";\nexport const Config = Context.GenericTag(\"Config\");\nexport const defaultConfig = {\n    reloadUrl: \"/\",\n    syncUrl: \"https://evolu.world\",\n    name: \"Evolu\",\n    maxDrift: 5 * 60 * 1000,\n    minimumLogLevel: \"none\",\n};\n/** https://effect.website/docs/guides/runtime */\nexport const createRuntime = (partialConfig) => {\n    const config = { ...defaultConfig, ...partialConfig };\n    const ConfigLive = Layer.succeed(Config, config);\n    const minimumLogLevel = Match.value(config.minimumLogLevel).pipe(Match.when(\"debug\", () => LogLevel.Debug), Match.when(\"none\", () => LogLevel.None), Match.when(\"trace\", () => LogLevel.Trace), Match.when(\"warning\", () => LogLevel.Warning), Match.exhaustive);\n    const evoluLayer = config.minimumLogLevel === \"none\"\n        ? ConfigLive\n        : Layer.mergeAll(ConfigLive, Logger.minimumLogLevel(minimumLogLevel), Logger.replace(Logger.defaultLogger, makeEvoluLogger(config.name)));\n    return ManagedRuntime.make(evoluLayer);\n};\n// TODO: Spans and Effect native variadic log args.\nconst makeEvoluLogger = (name) => Logger.make(({ logLevel, message, date }) => {\n    const fn = logLevel._tag === \"Warning\"\n        ? \"warn\"\n        : logLevel._tag === \"Error\"\n            ? \"error\"\n            : \"log\";\n    const hours = date.getHours().toString().padStart(2, \"0\");\n    const minutes = date.getMinutes().toString().padStart(2, \"0\");\n    const seconds = date.getSeconds().toString().padStart(2, \"0\");\n    const milliseconds = date.getMilliseconds().toString().padStart(3, \"0\");\n    const formattedDate = `${hours}:${minutes}:${seconds}:${milliseconds}`;\n    const messages = Array.isArray(message) ? message : [message];\n    globalThis.console[fn](`${formattedDate} [${name}]`, ...messages);\n});\n","import * as S from \"@effect/schema/Schema\";\nimport * as Arr from \"effect/Array\";\nimport * as Context from \"effect/Context\";\nimport * as Effect from \"effect/Effect\";\nimport * as Either from \"effect/Either\";\nimport { pipe } from \"effect/Function\";\nimport * as Layer from \"effect/Layer\";\nimport * as Number from \"effect/Number\";\nimport * as Option from \"effect/Option\";\nimport * as String from \"effect/String\";\nimport { Config } from \"./Config.js\";\nimport { NanoIdGenerator, NodeId } from \"./Crypto.js\";\nimport { murmurhash } from \"./Murmurhash.js\";\nexport const AllowedTimeRange = {\n    greaterThan: 860934419999,\n    lessThan: 2582803260000,\n};\n/**\n * Millis represents a time that is valid for usage with the Merkle tree. It\n * must be between Apr 13, 1997, and Nov 05, 2051, to ensure MinutesBase3 length\n * equals 16. We can find diff for two Merkle trees only within this range. If\n * the device clock is out of range, Evolu will not store data until it's\n * fixed.\n */\nexport const Millis = S.Number.pipe(S.greaterThan(AllowedTimeRange.greaterThan), S.lessThan(AllowedTimeRange.lessThan), S.brand(\"Millis\"));\nexport const initialMillis = S.decodeSync(Millis)(AllowedTimeRange.greaterThan + 1);\nexport const Counter = S.Number.pipe(S.between(0, 65535), S.brand(\"Counter\"));\nconst initialCounter = S.decodeSync(Counter)(0);\nexport const timestampToString = (t) => [\n    new Date(t.millis).toISOString(),\n    t.counter.toString(16).toUpperCase().padStart(4, \"0\"),\n    t.node,\n].join(\"-\");\nexport const unsafeTimestampFromString = (s) => {\n    const a = s.split(\"-\");\n    return {\n        millis: Date.parse(a.slice(0, 3).join(\"-\")).valueOf(),\n        counter: parseInt(a[3], 16),\n        node: a[4],\n    };\n};\nexport const timestampToHash = (t) => murmurhash(timestampToString(t));\nconst syncNodeId = S.decodeSync(NodeId)(\"0000000000000000\");\nexport const makeSyncTimestamp = (millis = initialMillis) => ({\n    millis,\n    counter: initialCounter,\n    node: syncNodeId,\n});\nexport const makeInitialTimestamp = NanoIdGenerator.pipe(Effect.flatMap(({ nodeId }) => nodeId), Effect.map((node) => ({\n    millis: initialMillis,\n    counter: initialCounter,\n    node,\n})));\nexport class Time extends Context.Tag(\"Time\")() {\n}\nTime.Live = Layer.succeed(Time, {\n    now: Effect.suspend(() => S.decode(Millis)(Date.now())).pipe(Effect.catchTag(\"ParseError\", () => Effect.fail({\n        _tag: \"TimestampTimeOutOfRangeError\",\n    }))),\n});\nconst getNextMillis = (millis) => Effect.gen(function* () {\n    const time = yield* Time;\n    const config = yield* Config;\n    const now = yield* time.now;\n    const next = Math.max(now, ...millis);\n    if (next - now > config.maxDrift)\n        yield* Effect.fail({\n            _tag: \"TimestampDriftError\",\n            now,\n            next,\n        });\n    return next;\n});\nconst incrementCounter = (counter) => pipe(Number.increment(counter), S.decodeEither(Counter), Either.mapLeft(() => ({\n    _tag: \"TimestampCounterOverflowError\",\n})));\nconst counterMin = S.decodeSync(Counter)(0);\nexport const sendTimestamp = (timestamp) => Effect.gen(function* () {\n    const millis = yield* getNextMillis([timestamp.millis]);\n    const counter = millis === timestamp.millis\n        ? yield* incrementCounter(timestamp.counter)\n        : counterMin;\n    return { ...timestamp, millis, counter };\n});\nexport const receiveTimestamp = ({ local, remote, }) => Effect.gen(function* (_) {\n    if (local.node === remote.node)\n        yield* Effect.fail({\n            _tag: \"TimestampDuplicateNodeError\",\n            node: local.node,\n        });\n    const millis = yield* getNextMillis([local.millis, remote.millis]);\n    const counter = yield* millis === local.millis && millis === remote.millis\n        ? incrementCounter(Math.max(local.counter, remote.counter))\n        : millis === local.millis\n            ? incrementCounter(local.counter)\n            : millis === remote.millis\n                ? incrementCounter(remote.counter)\n                : Either.right(counterMin);\n    return { ...local, millis, counter };\n});\nexport const initialMerkleTree = Object.create(null);\nexport const millisToMerkleTreePath = (millis) => Math.floor(millis / 1000 / 60)\n    .toString(3)\n    .split(\"\");\nconst merkleTreePathToMillis = (path) => path.length === 0\n    ? initialMillis\n    : // 16 is the length of the base 3 value of the current time in minutes.\n        // Ensure it's padded to create the full value.\n        (parseInt(path.join(\"\").padEnd(16, \"0\"), 3) * 1000 * 60);\nconst xorTimestampHashes = (a, b) => ((a || 0) ^ b);\nconst insertKey = (tree, path, hash) => {\n    if (path.length === 0)\n        return tree;\n    const key = path[0];\n    const child = tree[key] || {};\n    return {\n        ...tree,\n        [key]: {\n            ...child,\n            ...insertKey(child, path.slice(1), hash),\n            hash: xorTimestampHashes(child.hash, hash),\n        },\n    };\n};\nexport const insertIntoMerkleTree = (tree, timestamp) => {\n    const path = millisToMerkleTreePath(timestamp.millis);\n    const hash = timestampToHash(timestamp);\n    return insertKey({ ...tree, hash: xorTimestampHashes(tree.hash, hash) }, path, hash);\n};\nconst sortedMerkleTreeKeys = [\"0\", \"1\", \"2\"];\nconst getSortedMerkleTreeKeys = (tree) => sortedMerkleTreeKeys.filter((key) => key in tree);\nexport const diffMerkleTrees = (tree1, tree2) => {\n    if (tree1.hash === tree2.hash)\n        return Option.none();\n    let node1 = tree1;\n    let node2 = tree2;\n    let diffPath = [];\n    // This loop will eventually stop when it traverses down to find\n    // where the hashes differ, or otherwise when there are no leaves\n    // left (this shouldn't happen, if that's the case the hash check at\n    // the top of this function should pass)\n    // eslint-disable-next-line no-constant-condition\n    while (1) {\n        const keys = Arr.dedupeWith(getSortedMerkleTreeKeys(node1).concat(getSortedMerkleTreeKeys(node2)), String.Equivalence);\n        let diffKey = null;\n        // Traverse down the trie through keys that are different. We\n        // traverse down the keys in order. Stop in two cases: either one\n        // of the nodes doesn't have the key or a different key isn't\n        // found. For the former case, we have to do that because pruning is\n        // lossy. We don't know if we've pruned off a changed key, so we\n        // can't traverse down anymore. For the latter case, it means two\n        // things: either we've hit the bottom of the tree, or the changed\n        // key has been pruned off. In the latter case, we have a \"partial\"\n        // key and will fill the rest with 0s. If multiple older\n        // messages were added into one trie, we might likely\n        // generate a time that only encompasses *some* of those\n        // messages. Pruning is lossy, and we traverse down the left-most\n        // changed time that we know of, because of pruning, it might take\n        // multiple passes to sync up a trie.\n        for (let i = 0; i < keys.length; i++) {\n            const key = keys[i];\n            const next1 = node1[key];\n            const next2 = node2[key];\n            if (!next1 || !next2)\n                break;\n            if (next1.hash !== next2.hash) {\n                diffKey = key;\n                break;\n            }\n        }\n        if (!diffKey) {\n            return Option.some(merkleTreePathToMillis(diffPath));\n        }\n        diffPath = [...diffPath, diffKey];\n        node1 = node1[diffKey] || initialMerkleTree;\n        node2 = node2[diffKey] || initialMerkleTree;\n    }\n    return Option.none();\n};\nexport const merkleTreeToString = (m) => JSON.stringify(m);\nexport const unsafeMerkleTreeFromString = (m) => JSON.parse(m);\n","import * as S from \"@effect/schema/Schema\";\nimport { secretbox } from \"@noble/ciphers/salsa\";\nimport { concatBytes } from \"@noble/ciphers/utils\";\nimport { hmac } from \"@noble/hashes/hmac\";\nimport { sha512 } from \"@noble/hashes/sha512\";\nimport { randomBytes } from \"@noble/hashes/utils\";\nimport * as bip39 from \"@scure/bip39\";\nimport { wordlist } from \"@scure/bip39/wordlists/english\";\nimport * as Context from \"effect/Context\";\nimport * as Effect from \"effect/Effect\";\nimport * as Layer from \"effect/Layer\";\n/**\n * Mnemonic is a password generated by Evolu in BIP39 format.\n *\n * A mnemonic, also known as a \"seed phrase,\" is a set of 12 words in a specific\n * order chosen from a predefined list. The purpose of the BIP39 mnemonic is to\n * provide a human-readable way of storing a private key.\n */\nexport const createMnemonic = () => bip39.generateMnemonic(wordlist, 128);\n/** Parse a string to {@link Mnemonic}. */\nexport const parseMnemonic = (mnemonic) => {\n    const mnemonicTrimmed = mnemonic.trim();\n    return bip39.validateMnemonic(mnemonicTrimmed, wordlist)\n        ? Effect.succeed(mnemonicTrimmed)\n        : Effect.fail({\n            _tag: \"InvalidMnemonicError\",\n        });\n};\nexport const mnemonicToSeed = (mnemonic) => bip39.mnemonicToSeedSync(mnemonic);\nexport class NanoIdGenerator extends Context.Tag(\"NanoIdGenerator\")() {\n}\nexport const createNanoIdGeneratorLive = (customAlphabet, nanoid) => {\n    const nanoidForNodeId = customAlphabet(\"0123456789abcdef\", 16);\n    return Layer.succeed(NanoIdGenerator, NanoIdGenerator.of({\n        nanoid: Effect.sync(() => nanoid()),\n        nodeId: Effect.sync(() => nanoidForNodeId()),\n        rowId: Effect.sync(() => nanoid()),\n    }));\n};\nexport const NodeId = S.String.pipe(S.pattern(/^[\\w-]{16}$/), S.brand(\"NodeId\"));\n// SLIP-21 implementation\n// https://github.com/satoshilabs/slips/blob/master/slip-0021.md\nexport const slip21Derive = (seed, path) => Effect.sync(() => {\n    let m = hmac(sha512, \"Symmetric key seed\", seed);\n    for (let i = 0; i < path.length; i++) {\n        const p = new TextEncoder().encode(path[i]);\n        const e = new Uint8Array(p.byteLength + 1);\n        e[0] = 0;\n        e.set(p, 1);\n        m = hmac(sha512, m.slice(0, 32), e);\n    }\n    return m.slice(32, 64);\n});\nexport class SecretBox extends Context.Tag(\"SecretBox\")() {\n}\nSecretBox.Live = Layer.succeed(SecretBox, SecretBox.of({\n    seal: (key, plaintext) => Effect.sync(() => {\n        const nonce = randomBytes(24);\n        const ciphertext = secretbox(key, nonce).seal(plaintext);\n        return concatBytes(nonce, ciphertext);\n    }),\n    open: (key, ciphertext) => Effect.sync(() => {\n        const nonce = ciphertext.subarray(0, 24);\n        const ciphertextWithoutNonce = ciphertext.subarray(24);\n        return secretbox(key, nonce).open(ciphertextWithoutNonce);\n    }),\n}));\n","export const makeUnexpectedError = (error) => ({\n    _tag: \"UnexpectedError\",\n    error,\n});\n/** Error isn't a structured cloneable object. */\nexport const ensureTransferableError = (error) => {\n    if (error instanceof Error)\n        return {\n            message: error.message,\n            name: error.name,\n            stack: error.stack,\n        };\n    return error;\n};\n","// https://github.com/garycourt/murmurhash-js/blob/master/murmurhash3_gc.js\nexport const murmurhash = (key, seed = 0) => {\n    let h1, h1b, k1, i;\n    const remainder = key.length & 3; // key.length % 4\n    const bytes = key.length - remainder;\n    h1 = seed;\n    const c1 = 0xcc9e2d51;\n    const c2 = 0x1b873593;\n    i = 0;\n    while (i < bytes) {\n        k1 =\n            (key.charCodeAt(i) & 0xff) |\n                ((key.charCodeAt(++i) & 0xff) << 8) |\n                ((key.charCodeAt(++i) & 0xff) << 16) |\n                ((key.charCodeAt(++i) & 0xff) << 24);\n        ++i;\n        k1 =\n            ((k1 & 0xffff) * c1 + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;\n        k1 = (k1 << 15) | (k1 >>> 17);\n        k1 =\n            ((k1 & 0xffff) * c2 + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;\n        h1 ^= k1;\n        h1 = (h1 << 13) | (h1 >>> 19);\n        h1b =\n            ((h1 & 0xffff) * 5 + ((((h1 >>> 16) * 5) & 0xffff) << 16)) & 0xffffffff;\n        h1 = (h1b & 0xffff) + 0x6b64 + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16);\n    }\n    k1 = 0;\n    switch (remainder) {\n        case 3:\n            k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;\n        // eslint-disable-next-line no-fallthrough\n        case 2:\n            k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;\n        // eslint-disable-next-line no-fallthrough\n        case 1:\n            k1 ^= key.charCodeAt(i) & 0xff;\n            k1 =\n                ((k1 & 0xffff) * c1 + ((((k1 >>> 16) * c1) & 0xffff) << 16)) &\n                    0xffffffff;\n            k1 = (k1 << 15) | (k1 >>> 17);\n            k1 =\n                ((k1 & 0xffff) * c2 + ((((k1 >>> 16) * c2) & 0xffff) << 16)) &\n                    0xffffffff;\n            h1 ^= k1;\n    }\n    h1 ^= key.length;\n    h1 ^= h1 >>> 16;\n    h1 =\n        ((h1 & 0xffff) * 0x85ebca6b +\n            ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) &\n            0xffffffff;\n    h1 ^= h1 >>> 13;\n    h1 =\n        ((h1 & 0xffff) * 0xc2b2ae35 +\n            ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16)) &\n            0xffffffff;\n    h1 ^= h1 >>> 16;\n    return h1 >>> 0;\n};\n","import * as Context from \"effect/Context\";\nimport * as Effect from \"effect/Effect\";\nimport { createMnemonic, mnemonicToSeed, slip21Derive, } from \"./Crypto.js\";\nexport const Owner = Context.GenericTag(\"Owner\");\nexport const makeOwner = (mnemonic) => Effect.gen(function* (_) {\n    if (mnemonic == null)\n        mnemonic = createMnemonic();\n    const seed = mnemonicToSeed(mnemonic);\n    const id = yield* Effect.map(slip21Derive(seed, [\"Evolu\", \"Owner Id\"]), (key) => {\n        // convert key to nanoid\n        let id = \"\";\n        for (let i = 0; i < 21; i++) {\n            id += urlAlphabet[key[i] & 63];\n        }\n        return id;\n    });\n    const encryptionKey = yield* slip21Derive(seed, [\n        \"Evolu\",\n        \"Encryption Key\",\n    ]);\n    return { mnemonic, id, encryptionKey };\n});\n// From https://github.com/ai/nanoid/blob/main/url-alphabet/index.js\n// It's copy-pasted for now because NanoId import breaks Metro bundler.\n// https://github.com/ai/nanoid/issues/468\nconst urlAlphabet = \"useandom-26T198340PX75pxJACKVERYMINDBUSHWOLF_GQZbfghjklqvwyzrict\";\n","/* eslint-disable */\n// @generated by protobuf-ts 2.9.3 with parameter eslint_disable,optimize_code_size\n// @generated from protobuf file \"Protobuf.proto\" (syntax proto3)\n// tslint:disable\nimport { MessageType } from \"@protobuf-ts/runtime\";\n// @generated message type with reflection information, may provide speed optimized methods\nclass SyncRequest$Type extends MessageType {\n    constructor() {\n        super(\"SyncRequest\", [\n            {\n                no: 1,\n                name: \"messages\",\n                kind: \"message\",\n                repeat: 1 /*RepeatType.PACKED*/,\n                T: () => EncryptedMessage,\n            },\n            { no: 2, name: \"userId\", kind: \"scalar\", T: 9 /*ScalarType.STRING*/ },\n            { no: 3, name: \"nodeId\", kind: \"scalar\", T: 9 /*ScalarType.STRING*/ },\n            { no: 4, name: \"merkleTree\", kind: \"scalar\", T: 9 /*ScalarType.STRING*/ },\n        ]);\n    }\n}\n/** @generated MessageType for protobuf message SyncRequest */\nexport const SyncRequest = new SyncRequest$Type();\n// @generated message type with reflection information, may provide speed optimized methods\nclass SyncResponse$Type extends MessageType {\n    constructor() {\n        super(\"SyncResponse\", [\n            {\n                no: 1,\n                name: \"messages\",\n                kind: \"message\",\n                repeat: 1 /*RepeatType.PACKED*/,\n                T: () => EncryptedMessage,\n            },\n            { no: 2, name: \"merkleTree\", kind: \"scalar\", T: 9 /*ScalarType.STRING*/ },\n        ]);\n    }\n}\n/** @generated MessageType for protobuf message SyncResponse */\nexport const SyncResponse = new SyncResponse$Type();\n// @generated message type with reflection information, may provide speed optimized methods\nclass EncryptedMessage$Type extends MessageType {\n    constructor() {\n        super(\"EncryptedMessage\", [\n            { no: 1, name: \"timestamp\", kind: \"scalar\", T: 9 /*ScalarType.STRING*/ },\n            { no: 2, name: \"content\", kind: \"scalar\", T: 12 /*ScalarType.BYTES*/ },\n        ]);\n    }\n}\n/** @generated MessageType for protobuf message EncryptedMessage */\nexport const EncryptedMessage = new EncryptedMessage$Type();\n// @generated message type with reflection information, may provide speed optimized methods\nclass MessageContent$Type extends MessageType {\n    constructor() {\n        super(\"MessageContent\", [\n            { no: 1, name: \"table\", kind: \"scalar\", T: 9 /*ScalarType.STRING*/ },\n            { no: 2, name: \"row\", kind: \"scalar\", T: 9 /*ScalarType.STRING*/ },\n            { no: 3, name: \"column\", kind: \"scalar\", T: 9 /*ScalarType.STRING*/ },\n            {\n                no: 4,\n                name: \"stringValue\",\n                kind: \"scalar\",\n                oneof: \"value\",\n                T: 9 /*ScalarType.STRING*/,\n            },\n            {\n                no: 5,\n                name: \"numberValue\",\n                kind: \"scalar\",\n                oneof: \"value\",\n                T: 9 /*ScalarType.STRING*/,\n            },\n            {\n                no: 6,\n                name: \"bytesValue\",\n                kind: \"scalar\",\n                oneof: \"value\",\n                T: 12 /*ScalarType.BYTES*/,\n            },\n            {\n                no: 7,\n                name: \"jsonValue\",\n                kind: \"scalar\",\n                oneof: \"value\",\n                T: 9 /*ScalarType.STRING*/,\n            },\n        ]);\n    }\n}\n/** @generated MessageType for protobuf message MessageContent */\nexport const MessageContent = new MessageContent$Type();\n","import * as Platform from \"@effect/platform\";\nimport * as S from \"@effect/schema/Schema\";\nimport { concatBytes } from \"@noble/ciphers/utils\";\nimport { BinaryReader, BinaryWriter } from \"@protobuf-ts/runtime\";\nimport * as Arr from \"effect/Array\";\nimport * as Context from \"effect/Context\";\nimport * as Deferred from \"effect/Deferred\";\nimport * as Effect from \"effect/Effect\";\nimport { absurd } from \"effect/Function\";\nimport * as Option from \"effect/Option\";\nimport * as Predicate from \"effect/Predicate\";\nimport { Config } from \"./Config.js\";\nimport { merkleTreeToString, unsafeMerkleTreeFromString, } from \"./Crdt.js\";\nimport { SecretBox } from \"./Crypto.js\";\nimport { Owner } from \"./Owner.js\";\nimport * as Protobuf from \"./Protobuf.js\";\nexport const Sync = Context.GenericTag(\"Sync\");\n// To preserve identity.\nexport const initialSyncState = { _tag: \"SyncStateInitial\" };\nexport class SyncFactory extends Context.Tag(\"SyncFactory\")() {\n}\nexport const createSync = Effect.gen(function* () {\n    const initContext = Context.empty().pipe(Context.add(SecretBox, yield* SecretBox));\n    const afterInitContext = yield* Deferred.make();\n    return Sync.of({\n        init: (owner) => Effect.logDebug([\"Sync init\", { owner }]).pipe(Effect.tap(Deferred.succeed(afterInitContext, initContext.pipe(Context.add(Owner, owner))))),\n        sync: ({ merkleTree, timestamp, messages }) => Effect.gen(function* () {\n            yield* Effect.logDebug([\n                \"Sync request\",\n                { merkleTree, timestamp, messages },\n            ]);\n            const secretBox = yield* SecretBox;\n            const owner = yield* Owner;\n            const config = yield* Config;\n            return yield* Effect.forEach(messages || [], ({ timestamp, ...newMessage }) => Effect.map(secretBox.seal(owner.encryptionKey, newMessageToBinary(newMessage)), (content) => ({ timestamp, content }))).pipe(Effect.map((encrypedMessages) => Protobuf.SyncRequest.toBinary({\n                messages: encrypedMessages,\n                userId: owner.id,\n                nodeId: timestamp.node,\n                merkleTree: merkleTreeToString(merkleTree),\n            }, binaryWriteOptions)), Effect.flatMap((body) => Platform.HttpClientRequest.post(config.syncUrl).pipe(Platform.HttpClientRequest.uint8ArrayBody(body, \"application/x-protobuf\"), Platform.HttpClient.fetchOk, Platform.HttpClientResponse.arrayBuffer)), Effect.map((buffer) => Protobuf.SyncResponse.fromBinary(new Uint8Array(buffer), binaryReadOptions)), Effect.flatMap((syncResponse) => Effect.forEach(syncResponse.messages, (encrypedMessage) => Effect.map(secretBox.open(owner.encryptionKey, encrypedMessage.content), (binary) => [binary, encrypedMessage.timestamp])).pipe(Effect.map(Arr.filterMap(([binary, timestamp]) => Option.map(newMessageFromBinary(binary), (newMessage) => ({ ...newMessage, timestamp })))), Effect.map((messages) => ({\n                messages,\n                merkleTree: unsafeMerkleTreeFromString(syncResponse.merkleTree),\n            })), Effect.tap((response) => Effect.logDebug([\"Sync response\", response])))), Effect.catchTag(\"RequestError\", () => Effect.fail({\n                _tag: \"SyncStateIsNotSynced\",\n                error: { _tag: \"NetworkError\" },\n            })), Effect.catchTag(\"ResponseError\", ({ response: { status } }) => {\n                switch (status) {\n                    case 402:\n                        return Effect.fail({\n                            _tag: \"SyncStateIsNotSynced\",\n                            error: { _tag: \"PaymentRequiredError\" },\n                        });\n                    default:\n                        return Effect.fail({\n                            _tag: \"SyncStateIsNotSynced\",\n                            error: { _tag: \"ServerError\", status },\n                        });\n                }\n            }));\n        }).pipe((effect) => Effect.flatMap(Deferred.await(afterInitContext), (context) => Effect.provide(effect, context))),\n    });\n});\nconst newMessageToBinary = ({ value, ...rest }) => concatBytes(version1, Protobuf.MessageContent.toBinary({ value: valueToProtobuf(value), ...rest }, binaryWriteOptions));\nconst version1 = new Uint8Array([0, 1]);\nconst valueToProtobuf = (value) => {\n    switch (typeof value) {\n        case \"string\":\n            return { oneofKind: \"stringValue\", stringValue: value };\n        case \"number\":\n            return {\n                oneofKind: \"numberValue\",\n                numberValue: S.encodeSync(S.NumberFromString)(value),\n            };\n    }\n    if (value == null)\n        return { oneofKind: undefined };\n    if (Predicate.isUint8Array(value))\n        return { oneofKind: \"bytesValue\", bytesValue: value };\n    return { oneofKind: \"jsonValue\", jsonValue: JSON.stringify(value) };\n};\n// The 'protobuf-ts' uses TextEncoder, but polyfill fast-text-encoding\n// doesn't support the fatal option.\n// https://github.com/timostamm/protobuf-ts/issues/184#issuecomment-1658443836\nconst binaryWriteOptions = {\n    writerFactory: () => new BinaryWriter({\n        encode: (input) => new TextEncoder().encode(input),\n    }),\n};\nconst binaryReadOptions = {\n    readerFactory: (bytes) => new BinaryReader(bytes, {\n        decode: (input) => new TextDecoder().decode(input),\n    }),\n};\nconst newMessageFromBinary = (binary) => {\n    if (!startsWithArray(binary, version1))\n        return Option.none();\n    const { value, ...content } = Protobuf.MessageContent.fromBinary(binary.slice(version1.length), binaryReadOptions);\n    return Option.some({ value: valueFromProtobuf(value), ...content });\n};\nconst startsWithArray = (array, prefix) => {\n    if (prefix.length > array.length)\n        return false;\n    for (let i = 0; i < prefix.length; i++) {\n        if (array[i] !== prefix[i])\n            return false;\n    }\n    return true;\n};\nconst valueFromProtobuf = (value) => {\n    switch (value.oneofKind) {\n        case \"numberValue\":\n            return S.decodeSync(S.NumberFromString)(value.numberValue);\n        case \"stringValue\":\n            return value.stringValue;\n        case \"bytesValue\":\n            return value.bytesValue;\n        case \"jsonValue\":\n            return JSON.parse(value.jsonValue);\n        case undefined:\n            return null;\n        default:\n            return absurd(value);\n    }\n};\n","// Basic utils for ARX (add-rotate-xor) salsa and chacha ciphers.\nimport { number as anumber, bytes as abytes, bool as abool } from './_assert.js';\nimport { checkOpts, u32 } from './utils.js';\n/*\nRFC8439 requires multi-step cipher stream, where\nauthKey starts with counter: 0, actual msg with counter: 1.\n\nFor this, we need a way to re-use nonce / counter:\n\n    const counter = new Uint8Array(4);\n    chacha(..., counter, ...); // counter is now 1\n    chacha(..., counter, ...); // counter is now 2\n\nThis is complicated:\n\n- 32-bit counters are enough, no need for 64-bit: max ArrayBuffer size in JS is 4GB\n- Original papers don't allow mutating counters\n- Counter overflow is undefined [^1]\n- Idea A: allow providing (nonce | counter) instead of just nonce, re-use it\n- Caveat: Cannot be re-used through all cases:\n- * chacha has (counter | nonce)\n- * xchacha has (nonce16 | counter | nonce16)\n- Idea B: separate nonce / counter and provide separate API for counter re-use\n- Caveat: there are different counter sizes depending on an algorithm.\n- salsa & chacha also differ in structures of key & sigma:\n  salsa20:      s[0] | k(4) | s[1] | nonce(2) | ctr(2) | s[2] | k(4) | s[3]\n  chacha:       s(4) | k(8) | ctr(1) | nonce(3)\n  chacha20orig: s(4) | k(8) | ctr(2) | nonce(2)\n- Idea C: helper method such as `setSalsaState(key, nonce, sigma, data)`\n- Caveat: we can't re-use counter array\n\nxchacha [^2] uses the subkey and remaining 8 byte nonce with ChaCha20 as normal\n(prefixed by 4 NUL bytes, since [RFC8439] specifies a 12-byte nonce).\n\n[^1]: https://mailarchive.ietf.org/arch/msg/cfrg/gsOnTJzcbgG6OqD8Sc0GO5aR_tU/\n[^2]: https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-xchacha#appendix-A.2\n*/\n// We can't make top-level var depend on utils.utf8ToBytes\n// because it's not present in all envs. Creating a similar fn here\nconst _utf8ToBytes = (str) => Uint8Array.from(str.split('').map((c) => c.charCodeAt(0)));\nconst sigma16 = _utf8ToBytes('expand 16-byte k');\nconst sigma32 = _utf8ToBytes('expand 32-byte k');\nconst sigma16_32 = u32(sigma16);\nconst sigma32_32 = u32(sigma32);\nexport const sigma = sigma32_32.slice();\nexport function rotl(a, b) {\n    return (a << b) | (a >>> (32 - b));\n}\n// Is byte array aligned to 4 byte offset (u32)?\nfunction isAligned32(b) {\n    return b.byteOffset % 4 === 0;\n}\n// Salsa and Chacha block length is always 512-bit\nconst BLOCK_LEN = 64;\nconst BLOCK_LEN32 = 16;\n// new Uint32Array([2**32])   // => Uint32Array(1) [ 0 ]\n// new Uint32Array([2**32-1]) // => Uint32Array(1) [ 4294967295 ]\nconst MAX_COUNTER = 2 ** 32 - 1;\nconst U32_EMPTY = new Uint32Array();\nfunction runCipher(core, sigma, key, nonce, data, output, counter, rounds) {\n    const len = data.length;\n    const block = new Uint8Array(BLOCK_LEN);\n    const b32 = u32(block);\n    // Make sure that buffers aligned to 4 bytes\n    const isAligned = isAligned32(data) && isAligned32(output);\n    const d32 = isAligned ? u32(data) : U32_EMPTY;\n    const o32 = isAligned ? u32(output) : U32_EMPTY;\n    for (let pos = 0; pos < len; counter++) {\n        core(sigma, key, nonce, b32, counter, rounds);\n        if (counter >= MAX_COUNTER)\n            throw new Error('arx: counter overflow');\n        const take = Math.min(BLOCK_LEN, len - pos);\n        // aligned to 4 bytes\n        if (isAligned && take === BLOCK_LEN) {\n            const pos32 = pos / 4;\n            if (pos % 4 !== 0)\n                throw new Error('arx: invalid block position');\n            for (let j = 0, posj; j < BLOCK_LEN32; j++) {\n                posj = pos32 + j;\n                o32[posj] = d32[posj] ^ b32[j];\n            }\n            pos += BLOCK_LEN;\n            continue;\n        }\n        for (let j = 0, posj; j < take; j++) {\n            posj = pos + j;\n            output[posj] = data[posj] ^ block[j];\n        }\n        pos += take;\n    }\n}\nexport function createCipher(core, opts) {\n    const { allowShortKeys, extendNonceFn, counterLength, counterRight, rounds } = checkOpts({ allowShortKeys: false, counterLength: 8, counterRight: false, rounds: 20 }, opts);\n    if (typeof core !== 'function')\n        throw new Error('core must be a function');\n    anumber(counterLength);\n    anumber(rounds);\n    abool(counterRight);\n    abool(allowShortKeys);\n    return (key, nonce, data, output, counter = 0) => {\n        abytes(key);\n        abytes(nonce);\n        abytes(data);\n        const len = data.length;\n        if (!output)\n            output = new Uint8Array(len);\n        abytes(output);\n        anumber(counter);\n        if (counter < 0 || counter >= MAX_COUNTER)\n            throw new Error('arx: counter overflow');\n        if (output.length < len)\n            throw new Error(`arx: output (${output.length}) is shorter than data (${len})`);\n        const toClean = [];\n        // Key & sigma\n        // key=16 -> sigma16, k=key|key\n        // key=32 -> sigma32, k=key\n        let l = key.length, k, sigma;\n        if (l === 32) {\n            k = key.slice();\n            toClean.push(k);\n            sigma = sigma32_32;\n        }\n        else if (l === 16 && allowShortKeys) {\n            k = new Uint8Array(32);\n            k.set(key);\n            k.set(key, 16);\n            sigma = sigma16_32;\n            toClean.push(k);\n        }\n        else {\n            throw new Error(`arx: invalid 32-byte key, got length=${l}`);\n        }\n        // Nonce\n        // salsa20:      8   (8-byte counter)\n        // chacha20orig: 8   (8-byte counter)\n        // chacha20:     12  (4-byte counter)\n        // xsalsa20:     24  (16 -> hsalsa,  8 -> old nonce)\n        // xchacha20:    24  (16 -> hchacha, 8 -> old nonce)\n        // Align nonce to 4 bytes\n        if (!isAligned32(nonce)) {\n            nonce = nonce.slice();\n            toClean.push(nonce);\n        }\n        const k32 = u32(k);\n        // hsalsa & hchacha: handle extended nonce\n        if (extendNonceFn) {\n            if (nonce.length !== 24)\n                throw new Error(`arx: extended nonce must be 24 bytes`);\n            extendNonceFn(sigma, k32, u32(nonce.subarray(0, 16)), k32);\n            nonce = nonce.subarray(16);\n        }\n        // Handle nonce counter\n        const nonceNcLen = 16 - counterLength;\n        if (nonceNcLen !== nonce.length)\n            throw new Error(`arx: nonce must be ${nonceNcLen} or 16 bytes`);\n        // Pad counter when nonce is 64 bit\n        if (nonceNcLen !== 12) {\n            const nc = new Uint8Array(12);\n            nc.set(nonce, counterRight ? 0 : 12 - nonce.length);\n            nonce = nc;\n            toClean.push(nonce);\n        }\n        const n32 = u32(nonce);\n        runCipher(core, sigma, k32, n32, data, output, counter, rounds);\n        while (toClean.length > 0)\n            toClean.pop().fill(0);\n        return output;\n    };\n}\n//# sourceMappingURL=_arx.js.map","function number(n) {\n    if (!Number.isSafeInteger(n) || n < 0)\n        throw new Error(`positive integer expected, not ${n}`);\n}\nfunction bool(b) {\n    if (typeof b !== 'boolean')\n        throw new Error(`boolean expected, not ${b}`);\n}\nexport function isBytes(a) {\n    return (a instanceof Uint8Array ||\n        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));\n}\nfunction bytes(b, ...lengths) {\n    if (!isBytes(b))\n        throw new Error('Uint8Array expected');\n    if (lengths.length > 0 && !lengths.includes(b.length))\n        throw new Error(`Uint8Array expected of length ${lengths}, not of length=${b.length}`);\n}\nfunction hash(hash) {\n    if (typeof hash !== 'function' || typeof hash.create !== 'function')\n        throw new Error('hash must be wrapped by utils.wrapConstructor');\n    number(hash.outputLen);\n    number(hash.blockLen);\n}\nfunction exists(instance, checkFinished = true) {\n    if (instance.destroyed)\n        throw new Error('Hash instance has been destroyed');\n    if (checkFinished && instance.finished)\n        throw new Error('Hash#digest() has already been called');\n}\nfunction output(out, instance) {\n    bytes(out);\n    const min = instance.outputLen;\n    if (out.length < min) {\n        throw new Error(`digestInto() expects output buffer of length at least ${min}`);\n    }\n}\nexport { number, bool, bytes, hash, exists, output };\nconst assert = { number, bool, bytes, hash, exists, output };\nexport default assert;\n//# sourceMappingURL=_assert.js.map","import { exists as aexists, bytes as abytes, output as aoutput } from './_assert.js';\nimport { toBytes } from './utils.js';\n// Poly1305 is a fast and parallel secret-key message-authentication code.\n// https://cr.yp.to/mac.html, https://cr.yp.to/mac/poly1305-20050329.pdf\n// https://datatracker.ietf.org/doc/html/rfc8439\n// Based on Public Domain poly1305-donna https://github.com/floodyberry/poly1305-donna\nconst u8to16 = (a, i) => (a[i++] & 0xff) | ((a[i++] & 0xff) << 8);\nclass Poly1305 {\n    constructor(key) {\n        this.blockLen = 16;\n        this.outputLen = 16;\n        this.buffer = new Uint8Array(16);\n        this.r = new Uint16Array(10);\n        this.h = new Uint16Array(10);\n        this.pad = new Uint16Array(8);\n        this.pos = 0;\n        this.finished = false;\n        key = toBytes(key);\n        abytes(key, 32);\n        const t0 = u8to16(key, 0);\n        const t1 = u8to16(key, 2);\n        const t2 = u8to16(key, 4);\n        const t3 = u8to16(key, 6);\n        const t4 = u8to16(key, 8);\n        const t5 = u8to16(key, 10);\n        const t6 = u8to16(key, 12);\n        const t7 = u8to16(key, 14);\n        // https://github.com/floodyberry/poly1305-donna/blob/e6ad6e091d30d7f4ec2d4f978be1fcfcbce72781/poly1305-donna-16.h#L47\n        this.r[0] = t0 & 0x1fff;\n        this.r[1] = ((t0 >>> 13) | (t1 << 3)) & 0x1fff;\n        this.r[2] = ((t1 >>> 10) | (t2 << 6)) & 0x1f03;\n        this.r[3] = ((t2 >>> 7) | (t3 << 9)) & 0x1fff;\n        this.r[4] = ((t3 >>> 4) | (t4 << 12)) & 0x00ff;\n        this.r[5] = (t4 >>> 1) & 0x1ffe;\n        this.r[6] = ((t4 >>> 14) | (t5 << 2)) & 0x1fff;\n        this.r[7] = ((t5 >>> 11) | (t6 << 5)) & 0x1f81;\n        this.r[8] = ((t6 >>> 8) | (t7 << 8)) & 0x1fff;\n        this.r[9] = (t7 >>> 5) & 0x007f;\n        for (let i = 0; i < 8; i++)\n            this.pad[i] = u8to16(key, 16 + 2 * i);\n    }\n    process(data, offset, isLast = false) {\n        const hibit = isLast ? 0 : 1 << 11;\n        const { h, r } = this;\n        const r0 = r[0];\n        const r1 = r[1];\n        const r2 = r[2];\n        const r3 = r[3];\n        const r4 = r[4];\n        const r5 = r[5];\n        const r6 = r[6];\n        const r7 = r[7];\n        const r8 = r[8];\n        const r9 = r[9];\n        const t0 = u8to16(data, offset + 0);\n        const t1 = u8to16(data, offset + 2);\n        const t2 = u8to16(data, offset + 4);\n        const t3 = u8to16(data, offset + 6);\n        const t4 = u8to16(data, offset + 8);\n        const t5 = u8to16(data, offset + 10);\n        const t6 = u8to16(data, offset + 12);\n        const t7 = u8to16(data, offset + 14);\n        let h0 = h[0] + (t0 & 0x1fff);\n        let h1 = h[1] + (((t0 >>> 13) | (t1 << 3)) & 0x1fff);\n        let h2 = h[2] + (((t1 >>> 10) | (t2 << 6)) & 0x1fff);\n        let h3 = h[3] + (((t2 >>> 7) | (t3 << 9)) & 0x1fff);\n        let h4 = h[4] + (((t3 >>> 4) | (t4 << 12)) & 0x1fff);\n        let h5 = h[5] + ((t4 >>> 1) & 0x1fff);\n        let h6 = h[6] + (((t4 >>> 14) | (t5 << 2)) & 0x1fff);\n        let h7 = h[7] + (((t5 >>> 11) | (t6 << 5)) & 0x1fff);\n        let h8 = h[8] + (((t6 >>> 8) | (t7 << 8)) & 0x1fff);\n        let h9 = h[9] + ((t7 >>> 5) | hibit);\n        let c = 0;\n        let d0 = c + h0 * r0 + h1 * (5 * r9) + h2 * (5 * r8) + h3 * (5 * r7) + h4 * (5 * r6);\n        c = d0 >>> 13;\n        d0 &= 0x1fff;\n        d0 += h5 * (5 * r5) + h6 * (5 * r4) + h7 * (5 * r3) + h8 * (5 * r2) + h9 * (5 * r1);\n        c += d0 >>> 13;\n        d0 &= 0x1fff;\n        let d1 = c + h0 * r1 + h1 * r0 + h2 * (5 * r9) + h3 * (5 * r8) + h4 * (5 * r7);\n        c = d1 >>> 13;\n        d1 &= 0x1fff;\n        d1 += h5 * (5 * r6) + h6 * (5 * r5) + h7 * (5 * r4) + h8 * (5 * r3) + h9 * (5 * r2);\n        c += d1 >>> 13;\n        d1 &= 0x1fff;\n        let d2 = c + h0 * r2 + h1 * r1 + h2 * r0 + h3 * (5 * r9) + h4 * (5 * r8);\n        c = d2 >>> 13;\n        d2 &= 0x1fff;\n        d2 += h5 * (5 * r7) + h6 * (5 * r6) + h7 * (5 * r5) + h8 * (5 * r4) + h9 * (5 * r3);\n        c += d2 >>> 13;\n        d2 &= 0x1fff;\n        let d3 = c + h0 * r3 + h1 * r2 + h2 * r1 + h3 * r0 + h4 * (5 * r9);\n        c = d3 >>> 13;\n        d3 &= 0x1fff;\n        d3 += h5 * (5 * r8) + h6 * (5 * r7) + h7 * (5 * r6) + h8 * (5 * r5) + h9 * (5 * r4);\n        c += d3 >>> 13;\n        d3 &= 0x1fff;\n        let d4 = c + h0 * r4 + h1 * r3 + h2 * r2 + h3 * r1 + h4 * r0;\n        c = d4 >>> 13;\n        d4 &= 0x1fff;\n        d4 += h5 * (5 * r9) + h6 * (5 * r8) + h7 * (5 * r7) + h8 * (5 * r6) + h9 * (5 * r5);\n        c += d4 >>> 13;\n        d4 &= 0x1fff;\n        let d5 = c + h0 * r5 + h1 * r4 + h2 * r3 + h3 * r2 + h4 * r1;\n        c = d5 >>> 13;\n        d5 &= 0x1fff;\n        d5 += h5 * r0 + h6 * (5 * r9) + h7 * (5 * r8) + h8 * (5 * r7) + h9 * (5 * r6);\n        c += d5 >>> 13;\n        d5 &= 0x1fff;\n        let d6 = c + h0 * r6 + h1 * r5 + h2 * r4 + h3 * r3 + h4 * r2;\n        c = d6 >>> 13;\n        d6 &= 0x1fff;\n        d6 += h5 * r1 + h6 * r0 + h7 * (5 * r9) + h8 * (5 * r8) + h9 * (5 * r7);\n        c += d6 >>> 13;\n        d6 &= 0x1fff;\n        let d7 = c + h0 * r7 + h1 * r6 + h2 * r5 + h3 * r4 + h4 * r3;\n        c = d7 >>> 13;\n        d7 &= 0x1fff;\n        d7 += h5 * r2 + h6 * r1 + h7 * r0 + h8 * (5 * r9) + h9 * (5 * r8);\n        c += d7 >>> 13;\n        d7 &= 0x1fff;\n        let d8 = c + h0 * r8 + h1 * r7 + h2 * r6 + h3 * r5 + h4 * r4;\n        c = d8 >>> 13;\n        d8 &= 0x1fff;\n        d8 += h5 * r3 + h6 * r2 + h7 * r1 + h8 * r0 + h9 * (5 * r9);\n        c += d8 >>> 13;\n        d8 &= 0x1fff;\n        let d9 = c + h0 * r9 + h1 * r8 + h2 * r7 + h3 * r6 + h4 * r5;\n        c = d9 >>> 13;\n        d9 &= 0x1fff;\n        d9 += h5 * r4 + h6 * r3 + h7 * r2 + h8 * r1 + h9 * r0;\n        c += d9 >>> 13;\n        d9 &= 0x1fff;\n        c = ((c << 2) + c) | 0;\n        c = (c + d0) | 0;\n        d0 = c & 0x1fff;\n        c = c >>> 13;\n        d1 += c;\n        h[0] = d0;\n        h[1] = d1;\n        h[2] = d2;\n        h[3] = d3;\n        h[4] = d4;\n        h[5] = d5;\n        h[6] = d6;\n        h[7] = d7;\n        h[8] = d8;\n        h[9] = d9;\n    }\n    finalize() {\n        const { h, pad } = this;\n        const g = new Uint16Array(10);\n        let c = h[1] >>> 13;\n        h[1] &= 0x1fff;\n        for (let i = 2; i < 10; i++) {\n            h[i] += c;\n            c = h[i] >>> 13;\n            h[i] &= 0x1fff;\n        }\n        h[0] += c * 5;\n        c = h[0] >>> 13;\n        h[0] &= 0x1fff;\n        h[1] += c;\n        c = h[1] >>> 13;\n        h[1] &= 0x1fff;\n        h[2] += c;\n        g[0] = h[0] + 5;\n        c = g[0] >>> 13;\n        g[0] &= 0x1fff;\n        for (let i = 1; i < 10; i++) {\n            g[i] = h[i] + c;\n            c = g[i] >>> 13;\n            g[i] &= 0x1fff;\n        }\n        g[9] -= 1 << 13;\n        let mask = (c ^ 1) - 1;\n        for (let i = 0; i < 10; i++)\n            g[i] &= mask;\n        mask = ~mask;\n        for (let i = 0; i < 10; i++)\n            h[i] = (h[i] & mask) | g[i];\n        h[0] = (h[0] | (h[1] << 13)) & 0xffff;\n        h[1] = ((h[1] >>> 3) | (h[2] << 10)) & 0xffff;\n        h[2] = ((h[2] >>> 6) | (h[3] << 7)) & 0xffff;\n        h[3] = ((h[3] >>> 9) | (h[4] << 4)) & 0xffff;\n        h[4] = ((h[4] >>> 12) | (h[5] << 1) | (h[6] << 14)) & 0xffff;\n        h[5] = ((h[6] >>> 2) | (h[7] << 11)) & 0xffff;\n        h[6] = ((h[7] >>> 5) | (h[8] << 8)) & 0xffff;\n        h[7] = ((h[8] >>> 8) | (h[9] << 5)) & 0xffff;\n        let f = h[0] + pad[0];\n        h[0] = f & 0xffff;\n        for (let i = 1; i < 8; i++) {\n            f = (((h[i] + pad[i]) | 0) + (f >>> 16)) | 0;\n            h[i] = f & 0xffff;\n        }\n    }\n    update(data) {\n        aexists(this);\n        const { buffer, blockLen } = this;\n        data = toBytes(data);\n        const len = data.length;\n        for (let pos = 0; pos < len;) {\n            const take = Math.min(blockLen - this.pos, len - pos);\n            // Fast path: we have at least one block in input\n            if (take === blockLen) {\n                for (; blockLen <= len - pos; pos += blockLen)\n                    this.process(data, pos);\n                continue;\n            }\n            buffer.set(data.subarray(pos, pos + take), this.pos);\n            this.pos += take;\n            pos += take;\n            if (this.pos === blockLen) {\n                this.process(buffer, 0, false);\n                this.pos = 0;\n            }\n        }\n        return this;\n    }\n    destroy() {\n        this.h.fill(0);\n        this.r.fill(0);\n        this.buffer.fill(0);\n        this.pad.fill(0);\n    }\n    digestInto(out) {\n        aexists(this);\n        aoutput(out, this);\n        this.finished = true;\n        const { buffer, h } = this;\n        let { pos } = this;\n        if (pos) {\n            buffer[pos++] = 1;\n            // buffer.subarray(pos).fill(0);\n            for (; pos < 16; pos++)\n                buffer[pos] = 0;\n            this.process(buffer, 0, true);\n        }\n        this.finalize();\n        let opos = 0;\n        for (let i = 0; i < 8; i++) {\n            out[opos++] = h[i] >>> 0;\n            out[opos++] = h[i] >>> 8;\n        }\n        return out;\n    }\n    digest() {\n        const { buffer, outputLen } = this;\n        this.digestInto(buffer);\n        const res = buffer.slice(0, outputLen);\n        this.destroy();\n        return res;\n    }\n}\nexport function wrapConstructorWithKey(hashCons) {\n    const hashC = (msg, key) => hashCons(key).update(toBytes(msg)).digest();\n    const tmp = hashCons(new Uint8Array(32));\n    hashC.outputLen = tmp.outputLen;\n    hashC.blockLen = tmp.blockLen;\n    hashC.create = (key) => hashCons(key);\n    return hashC;\n}\nexport const poly1305 = wrapConstructorWithKey((key) => new Poly1305(key));\n//# sourceMappingURL=_poly1305.js.map","import { bytes as abytes } from './_assert.js';\nimport { createCipher, rotl } from './_arx.js';\nimport { poly1305 } from './_poly1305.js';\nimport { wrapCipher, equalBytes } from './utils.js';\n// Salsa20 stream cipher was released in 2005.\n// Salsa's goal was to implement AES replacement that does not rely on S-Boxes,\n// which are hard to implement in a constant-time manner.\n// https://cr.yp.to/snuffle.html, https://cr.yp.to/snuffle/salsafamily-20071225.pdf\n/**\n * Salsa20 core function.\n */\n// prettier-ignore\nfunction salsaCore(s, k, n, out, cnt, rounds = 20) {\n    // Based on https://cr.yp.to/salsa20.html\n    let y00 = s[0], y01 = k[0], y02 = k[1], y03 = k[2], // \"expa\" Key     Key     Key\n    y04 = k[3], y05 = s[1], y06 = n[0], y07 = n[1], // Key    \"nd 3\"  Nonce   Nonce\n    y08 = cnt, y09 = 0, y10 = s[2], y11 = k[4], // Pos.   Pos.    \"2-by\"\tKey\n    y12 = k[5], y13 = k[6], y14 = k[7], y15 = s[3]; // Key    Key     Key     \"te k\"\n    // Save state to temporary variables\n    let x00 = y00, x01 = y01, x02 = y02, x03 = y03, x04 = y04, x05 = y05, x06 = y06, x07 = y07, x08 = y08, x09 = y09, x10 = y10, x11 = y11, x12 = y12, x13 = y13, x14 = y14, x15 = y15;\n    for (let r = 0; r < rounds; r += 2) {\n        x04 ^= rotl(x00 + x12 | 0, 7);\n        x08 ^= rotl(x04 + x00 | 0, 9);\n        x12 ^= rotl(x08 + x04 | 0, 13);\n        x00 ^= rotl(x12 + x08 | 0, 18);\n        x09 ^= rotl(x05 + x01 | 0, 7);\n        x13 ^= rotl(x09 + x05 | 0, 9);\n        x01 ^= rotl(x13 + x09 | 0, 13);\n        x05 ^= rotl(x01 + x13 | 0, 18);\n        x14 ^= rotl(x10 + x06 | 0, 7);\n        x02 ^= rotl(x14 + x10 | 0, 9);\n        x06 ^= rotl(x02 + x14 | 0, 13);\n        x10 ^= rotl(x06 + x02 | 0, 18);\n        x03 ^= rotl(x15 + x11 | 0, 7);\n        x07 ^= rotl(x03 + x15 | 0, 9);\n        x11 ^= rotl(x07 + x03 | 0, 13);\n        x15 ^= rotl(x11 + x07 | 0, 18);\n        x01 ^= rotl(x00 + x03 | 0, 7);\n        x02 ^= rotl(x01 + x00 | 0, 9);\n        x03 ^= rotl(x02 + x01 | 0, 13);\n        x00 ^= rotl(x03 + x02 | 0, 18);\n        x06 ^= rotl(x05 + x04 | 0, 7);\n        x07 ^= rotl(x06 + x05 | 0, 9);\n        x04 ^= rotl(x07 + x06 | 0, 13);\n        x05 ^= rotl(x04 + x07 | 0, 18);\n        x11 ^= rotl(x10 + x09 | 0, 7);\n        x08 ^= rotl(x11 + x10 | 0, 9);\n        x09 ^= rotl(x08 + x11 | 0, 13);\n        x10 ^= rotl(x09 + x08 | 0, 18);\n        x12 ^= rotl(x15 + x14 | 0, 7);\n        x13 ^= rotl(x12 + x15 | 0, 9);\n        x14 ^= rotl(x13 + x12 | 0, 13);\n        x15 ^= rotl(x14 + x13 | 0, 18);\n    }\n    // Write output\n    let oi = 0;\n    out[oi++] = (y00 + x00) | 0;\n    out[oi++] = (y01 + x01) | 0;\n    out[oi++] = (y02 + x02) | 0;\n    out[oi++] = (y03 + x03) | 0;\n    out[oi++] = (y04 + x04) | 0;\n    out[oi++] = (y05 + x05) | 0;\n    out[oi++] = (y06 + x06) | 0;\n    out[oi++] = (y07 + x07) | 0;\n    out[oi++] = (y08 + x08) | 0;\n    out[oi++] = (y09 + x09) | 0;\n    out[oi++] = (y10 + x10) | 0;\n    out[oi++] = (y11 + x11) | 0;\n    out[oi++] = (y12 + x12) | 0;\n    out[oi++] = (y13 + x13) | 0;\n    out[oi++] = (y14 + x14) | 0;\n    out[oi++] = (y15 + x15) | 0;\n}\n/**\n * hsalsa hashing function, used primarily in xsalsa, to hash\n * key and nonce into key' and nonce'.\n * Same as salsaCore, but there doesn't seem to be a way to move the block\n * out without 25% performance hit.\n */\n// prettier-ignore\nexport function hsalsa(s, k, i, o32) {\n    let x00 = s[0], x01 = k[0], x02 = k[1], x03 = k[2], x04 = k[3], x05 = s[1], x06 = i[0], x07 = i[1], x08 = i[2], x09 = i[3], x10 = s[2], x11 = k[4], x12 = k[5], x13 = k[6], x14 = k[7], x15 = s[3];\n    for (let r = 0; r < 20; r += 2) {\n        x04 ^= rotl(x00 + x12 | 0, 7);\n        x08 ^= rotl(x04 + x00 | 0, 9);\n        x12 ^= rotl(x08 + x04 | 0, 13);\n        x00 ^= rotl(x12 + x08 | 0, 18);\n        x09 ^= rotl(x05 + x01 | 0, 7);\n        x13 ^= rotl(x09 + x05 | 0, 9);\n        x01 ^= rotl(x13 + x09 | 0, 13);\n        x05 ^= rotl(x01 + x13 | 0, 18);\n        x14 ^= rotl(x10 + x06 | 0, 7);\n        x02 ^= rotl(x14 + x10 | 0, 9);\n        x06 ^= rotl(x02 + x14 | 0, 13);\n        x10 ^= rotl(x06 + x02 | 0, 18);\n        x03 ^= rotl(x15 + x11 | 0, 7);\n        x07 ^= rotl(x03 + x15 | 0, 9);\n        x11 ^= rotl(x07 + x03 | 0, 13);\n        x15 ^= rotl(x11 + x07 | 0, 18);\n        x01 ^= rotl(x00 + x03 | 0, 7);\n        x02 ^= rotl(x01 + x00 | 0, 9);\n        x03 ^= rotl(x02 + x01 | 0, 13);\n        x00 ^= rotl(x03 + x02 | 0, 18);\n        x06 ^= rotl(x05 + x04 | 0, 7);\n        x07 ^= rotl(x06 + x05 | 0, 9);\n        x04 ^= rotl(x07 + x06 | 0, 13);\n        x05 ^= rotl(x04 + x07 | 0, 18);\n        x11 ^= rotl(x10 + x09 | 0, 7);\n        x08 ^= rotl(x11 + x10 | 0, 9);\n        x09 ^= rotl(x08 + x11 | 0, 13);\n        x10 ^= rotl(x09 + x08 | 0, 18);\n        x12 ^= rotl(x15 + x14 | 0, 7);\n        x13 ^= rotl(x12 + x15 | 0, 9);\n        x14 ^= rotl(x13 + x12 | 0, 13);\n        x15 ^= rotl(x14 + x13 | 0, 18);\n    }\n    let oi = 0;\n    o32[oi++] = x00;\n    o32[oi++] = x05;\n    o32[oi++] = x10;\n    o32[oi++] = x15;\n    o32[oi++] = x06;\n    o32[oi++] = x07;\n    o32[oi++] = x08;\n    o32[oi++] = x09;\n}\n/**\n * Salsa20 from original paper.\n * With 12-byte nonce, it's not safe to use fill it with random (CSPRNG), due to collision chance.\n */\nexport const salsa20 = /* @__PURE__ */ createCipher(salsaCore, {\n    allowShortKeys: true,\n    counterRight: true,\n});\n/**\n * xsalsa20 eXtended-nonce salsa.\n * With 24-byte nonce, it's safe to use fill it with random (CSPRNG).\n */\nexport const xsalsa20 = /* @__PURE__ */ createCipher(salsaCore, {\n    counterRight: true,\n    extendNonceFn: hsalsa,\n});\n/**\n * xsalsa20-poly1305 eXtended-nonce salsa.\n * With 24-byte nonce, it's safe to use fill it with random (CSPRNG).\n * Also known as secretbox from libsodium / nacl.\n */\nexport const xsalsa20poly1305 = /* @__PURE__ */ wrapCipher({ blockSize: 64, nonceLength: 24, tagLength: 16 }, (key, nonce) => {\n    const tagLength = 16;\n    abytes(key, 32);\n    abytes(nonce, 24);\n    return {\n        encrypt: (plaintext, output) => {\n            abytes(plaintext);\n            // This is small optimization (calculate auth key with same call as encryption itself) makes it hard\n            // to separate tag calculation and encryption itself, since 32 byte is half-block of salsa (64 byte)\n            const clength = plaintext.length + 32;\n            if (output) {\n                abytes(output, clength);\n            }\n            else {\n                output = new Uint8Array(clength);\n            }\n            output.set(plaintext, 32);\n            xsalsa20(key, nonce, output, output);\n            const authKey = output.subarray(0, 32);\n            const tag = poly1305(output.subarray(32), authKey);\n            // Clean auth key, even though JS provides no guarantees about memory cleaning\n            output.set(tag, tagLength);\n            output.subarray(0, tagLength).fill(0);\n            return output.subarray(tagLength);\n        },\n        decrypt: (ciphertext) => {\n            abytes(ciphertext);\n            const clength = ciphertext.length;\n            if (clength < tagLength)\n                throw new Error('encrypted data should be at least 16 bytes');\n            // Create new ciphertext array:\n            // auth tag      auth tag from ciphertext ciphertext\n            // [bytes 0..16] [bytes 16..32]           [bytes 32..]\n            // 16 instead of 32, because we already have 16 byte tag\n            const ciphertext_ = new Uint8Array(clength + tagLength); // alloc\n            ciphertext_.set(ciphertext, tagLength);\n            // Each xsalsa20 calls to hsalsa to calculate key, but seems not much perf difference\n            // Separate call to calculate authkey, since first bytes contains tag\n            const authKey = xsalsa20(key, nonce, new Uint8Array(32)); // alloc(32)\n            const tag = poly1305(ciphertext_.subarray(32), authKey);\n            if (!equalBytes(ciphertext_.subarray(16, 32), tag))\n                throw new Error('invalid tag');\n            const plaintext = xsalsa20(key, nonce, ciphertext_); // alloc\n            // Clean auth key, even though JS provides no guarantees about memory cleaning\n            plaintext.subarray(0, 32).fill(0);\n            authKey.fill(0);\n            return plaintext.subarray(32);\n        },\n    };\n});\n/**\n * Alias to xsalsa20poly1305, for compatibility with libsodium / nacl\n */\nexport function secretbox(key, nonce) {\n    const xs = xsalsa20poly1305(key, nonce);\n    return { seal: xs.encrypt, open: xs.decrypt };\n}\n//# sourceMappingURL=salsa.js.map","/*! noble-ciphers - MIT License (c) 2023 Paul Miller (paulmillr.com) */\nimport { bytes as abytes, isBytes } from './_assert.js';\n// Cast array to different type\nexport const u8 = (arr) => new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);\nexport const u16 = (arr) => new Uint16Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 2));\nexport const u32 = (arr) => new Uint32Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 4));\n// Cast array to view\nexport const createView = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);\n// big-endian hardware is rare. Just in case someone still decides to run ciphers:\n// early-throw an error because we don't support BE yet.\nexport const isLE = new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;\nif (!isLE)\n    throw new Error('Non little-endian hardware is not supported');\n// Array where index 0xf0 (240) is mapped to string 'f0'\nconst hexes = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, '0'));\n/**\n * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'\n */\nexport function bytesToHex(bytes) {\n    abytes(bytes);\n    // pre-caching improves the speed 6x\n    let hex = '';\n    for (let i = 0; i < bytes.length; i++) {\n        hex += hexes[bytes[i]];\n    }\n    return hex;\n}\n// We use optimized technique to convert hex string to byte array\nconst asciis = { _0: 48, _9: 57, _A: 65, _F: 70, _a: 97, _f: 102 };\nfunction asciiToBase16(char) {\n    if (char >= asciis._0 && char <= asciis._9)\n        return char - asciis._0;\n    if (char >= asciis._A && char <= asciis._F)\n        return char - (asciis._A - 10);\n    if (char >= asciis._a && char <= asciis._f)\n        return char - (asciis._a - 10);\n    return;\n}\n/**\n * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])\n */\nexport function hexToBytes(hex) {\n    if (typeof hex !== 'string')\n        throw new Error('hex string expected, got ' + typeof hex);\n    const hl = hex.length;\n    const al = hl / 2;\n    if (hl % 2)\n        throw new Error('padded hex string expected, got unpadded hex of length ' + hl);\n    const array = new Uint8Array(al);\n    for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {\n        const n1 = asciiToBase16(hex.charCodeAt(hi));\n        const n2 = asciiToBase16(hex.charCodeAt(hi + 1));\n        if (n1 === undefined || n2 === undefined) {\n            const char = hex[hi] + hex[hi + 1];\n            throw new Error('hex string expected, got non-hex character \"' + char + '\" at index ' + hi);\n        }\n        array[ai] = n1 * 16 + n2;\n    }\n    return array;\n}\nexport function hexToNumber(hex) {\n    if (typeof hex !== 'string')\n        throw new Error('hex string expected, got ' + typeof hex);\n    // Big Endian\n    return BigInt(hex === '' ? '0' : `0x${hex}`);\n}\n// BE: Big Endian, LE: Little Endian\nexport function bytesToNumberBE(bytes) {\n    return hexToNumber(bytesToHex(bytes));\n}\nexport function numberToBytesBE(n, len) {\n    return hexToBytes(n.toString(16).padStart(len * 2, '0'));\n}\n// There is no setImmediate in browser and setTimeout is slow.\n// call of async fn will return Promise, which will be fullfiled only on\n// next scheduler queue processing step and this is exactly what we need.\nexport const nextTick = async () => { };\n// Returns control to thread each 'tick' ms to avoid blocking\nexport async function asyncLoop(iters, tick, cb) {\n    let ts = Date.now();\n    for (let i = 0; i < iters; i++) {\n        cb(i);\n        // Date.now() is not monotonic, so in case if clock goes backwards we return return control too\n        const diff = Date.now() - ts;\n        if (diff >= 0 && diff < tick)\n            continue;\n        await nextTick();\n        ts += diff;\n    }\n}\n/**\n * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])\n */\nexport function utf8ToBytes(str) {\n    if (typeof str !== 'string')\n        throw new Error(`string expected, got ${typeof str}`);\n    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809\n}\n/**\n * @example bytesToUtf8(new Uint8Array([97, 98, 99])) // 'abc'\n */\nexport function bytesToUtf8(bytes) {\n    return new TextDecoder().decode(bytes);\n}\n/**\n * Normalizes (non-hex) string or Uint8Array to Uint8Array.\n * Warning: when Uint8Array is passed, it would NOT get copied.\n * Keep in mind for future mutable operations.\n */\nexport function toBytes(data) {\n    if (typeof data === 'string')\n        data = utf8ToBytes(data);\n    else if (isBytes(data))\n        data = data.slice();\n    else\n        throw new Error(`Uint8Array expected, got ${typeof data}`);\n    return data;\n}\n/**\n * Copies several Uint8Arrays into one.\n */\nexport function concatBytes(...arrays) {\n    let sum = 0;\n    for (let i = 0; i < arrays.length; i++) {\n        const a = arrays[i];\n        abytes(a);\n        sum += a.length;\n    }\n    const res = new Uint8Array(sum);\n    for (let i = 0, pad = 0; i < arrays.length; i++) {\n        const a = arrays[i];\n        res.set(a, pad);\n        pad += a.length;\n    }\n    return res;\n}\nexport function checkOpts(defaults, opts) {\n    if (opts == null || typeof opts !== 'object')\n        throw new Error('options must be defined');\n    const merged = Object.assign(defaults, opts);\n    return merged;\n}\n// Compares 2 u8a-s in kinda constant time\nexport function equalBytes(a, b) {\n    if (a.length !== b.length)\n        return false;\n    let diff = 0;\n    for (let i = 0; i < a.length; i++)\n        diff |= a[i] ^ b[i];\n    return diff === 0;\n}\n// For runtime check if class implements interface\nexport class Hash {\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nexport const wrapCipher = (params, c) => {\n    Object.assign(c, params);\n    return c;\n};\n// Polyfill for Safari 14\nexport function setBigUint64(view, byteOffset, value, isLE) {\n    if (typeof view.setBigUint64 === 'function')\n        return view.setBigUint64(byteOffset, value, isLE);\n    const _32n = BigInt(32);\n    const _u32_max = BigInt(0xffffffff);\n    const wh = Number((value >> _32n) & _u32_max);\n    const wl = Number(value & _u32_max);\n    const h = isLE ? 4 : 0;\n    const l = isLE ? 0 : 4;\n    view.setUint32(byteOffset + h, wh, isLE);\n    view.setUint32(byteOffset + l, wl, isLE);\n}\nexport function u64Lengths(ciphertext, AAD) {\n    const num = new Uint8Array(16);\n    const view = createView(num);\n    setBigUint64(view, 0, BigInt(AAD ? AAD.length : 0), true);\n    setBigUint64(view, 8, BigInt(ciphertext.length), true);\n    return num;\n}\n//# sourceMappingURL=utils.js.map","function number(n) {\n    if (!Number.isSafeInteger(n) || n < 0)\n        throw new Error(`positive integer expected, not ${n}`);\n}\nfunction bool(b) {\n    if (typeof b !== 'boolean')\n        throw new Error(`boolean expected, not ${b}`);\n}\n// copied from utils\nexport function isBytes(a) {\n    return (a instanceof Uint8Array ||\n        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));\n}\nfunction bytes(b, ...lengths) {\n    if (!isBytes(b))\n        throw new Error('Uint8Array expected');\n    if (lengths.length > 0 && !lengths.includes(b.length))\n        throw new Error(`Uint8Array expected of length ${lengths}, not of length=${b.length}`);\n}\nfunction hash(h) {\n    if (typeof h !== 'function' || typeof h.create !== 'function')\n        throw new Error('Hash should be wrapped by utils.wrapConstructor');\n    number(h.outputLen);\n    number(h.blockLen);\n}\nfunction exists(instance, checkFinished = true) {\n    if (instance.destroyed)\n        throw new Error('Hash instance has been destroyed');\n    if (checkFinished && instance.finished)\n        throw new Error('Hash#digest() has already been called');\n}\nfunction output(out, instance) {\n    bytes(out);\n    const min = instance.outputLen;\n    if (out.length < min) {\n        throw new Error(`digestInto() expects output buffer of length at least ${min}`);\n    }\n}\nexport { number, bool, bytes, hash, exists, output };\nconst assert = { number, bool, bytes, hash, exists, output };\nexport default assert;\n//# sourceMappingURL=_assert.js.map","import { exists, output } from './_assert.js';\nimport { Hash, createView, toBytes } from './utils.js';\n// Polyfill for Safari 14\nfunction setBigUint64(view, byteOffset, value, isLE) {\n    if (typeof view.setBigUint64 === 'function')\n        return view.setBigUint64(byteOffset, value, isLE);\n    const _32n = BigInt(32);\n    const _u32_max = BigInt(0xffffffff);\n    const wh = Number((value >> _32n) & _u32_max);\n    const wl = Number(value & _u32_max);\n    const h = isLE ? 4 : 0;\n    const l = isLE ? 0 : 4;\n    view.setUint32(byteOffset + h, wh, isLE);\n    view.setUint32(byteOffset + l, wl, isLE);\n}\n// Choice: a ? b : c\nexport const Chi = (a, b, c) => (a & b) ^ (~a & c);\n// Majority function, true if any two inpust is true\nexport const Maj = (a, b, c) => (a & b) ^ (a & c) ^ (b & c);\n/**\n * Merkle-Damgard hash construction base class.\n * Could be used to create MD5, RIPEMD, SHA1, SHA2.\n */\nexport class HashMD extends Hash {\n    constructor(blockLen, outputLen, padOffset, isLE) {\n        super();\n        this.blockLen = blockLen;\n        this.outputLen = outputLen;\n        this.padOffset = padOffset;\n        this.isLE = isLE;\n        this.finished = false;\n        this.length = 0;\n        this.pos = 0;\n        this.destroyed = false;\n        this.buffer = new Uint8Array(blockLen);\n        this.view = createView(this.buffer);\n    }\n    update(data) {\n        exists(this);\n        const { view, buffer, blockLen } = this;\n        data = toBytes(data);\n        const len = data.length;\n        for (let pos = 0; pos < len;) {\n            const take = Math.min(blockLen - this.pos, len - pos);\n            // Fast path: we have at least one block in input, cast it to view and process\n            if (take === blockLen) {\n                const dataView = createView(data);\n                for (; blockLen <= len - pos; pos += blockLen)\n                    this.process(dataView, pos);\n                continue;\n            }\n            buffer.set(data.subarray(pos, pos + take), this.pos);\n            this.pos += take;\n            pos += take;\n            if (this.pos === blockLen) {\n                this.process(view, 0);\n                this.pos = 0;\n            }\n        }\n        this.length += data.length;\n        this.roundClean();\n        return this;\n    }\n    digestInto(out) {\n        exists(this);\n        output(out, this);\n        this.finished = true;\n        // Padding\n        // We can avoid allocation of buffer for padding completely if it\n        // was previously not allocated here. But it won't change performance.\n        const { buffer, view, blockLen, isLE } = this;\n        let { pos } = this;\n        // append the bit '1' to the message\n        buffer[pos++] = 0b10000000;\n        this.buffer.subarray(pos).fill(0);\n        // we have less than padOffset left in buffer, so we cannot put length in\n        // current block, need process it and pad again\n        if (this.padOffset > blockLen - pos) {\n            this.process(view, 0);\n            pos = 0;\n        }\n        // Pad until full block byte with zeros\n        for (let i = pos; i < blockLen; i++)\n            buffer[i] = 0;\n        // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that\n        // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.\n        // So we just write lowest 64 bits of that value.\n        setBigUint64(view, blockLen - 8, BigInt(this.length * 8), isLE);\n        this.process(view, 0);\n        const oview = createView(out);\n        const len = this.outputLen;\n        // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT\n        if (len % 4)\n            throw new Error('_sha2: outputLen should be aligned to 32bit');\n        const outLen = len / 4;\n        const state = this.get();\n        if (outLen > state.length)\n            throw new Error('_sha2: outputLen bigger than state');\n        for (let i = 0; i < outLen; i++)\n            oview.setUint32(4 * i, state[i], isLE);\n    }\n    digest() {\n        const { buffer, outputLen } = this;\n        this.digestInto(buffer);\n        const res = buffer.slice(0, outputLen);\n        this.destroy();\n        return res;\n    }\n    _cloneInto(to) {\n        to || (to = new this.constructor());\n        to.set(...this.get());\n        const { blockLen, buffer, length, finished, destroyed, pos } = this;\n        to.length = length;\n        to.pos = pos;\n        to.finished = finished;\n        to.destroyed = destroyed;\n        if (length % blockLen)\n            to.buffer.set(buffer);\n        return to;\n    }\n}\n//# sourceMappingURL=_md.js.map","const U32_MASK64 = /* @__PURE__ */ BigInt(2 ** 32 - 1);\nconst _32n = /* @__PURE__ */ BigInt(32);\n// We are not using BigUint64Array, because they are extremely slow as per 2022\nfunction fromBig(n, le = false) {\n    if (le)\n        return { h: Number(n & U32_MASK64), l: Number((n >> _32n) & U32_MASK64) };\n    return { h: Number((n >> _32n) & U32_MASK64) | 0, l: Number(n & U32_MASK64) | 0 };\n}\nfunction split(lst, le = false) {\n    let Ah = new Uint32Array(lst.length);\n    let Al = new Uint32Array(lst.length);\n    for (let i = 0; i < lst.length; i++) {\n        const { h, l } = fromBig(lst[i], le);\n        [Ah[i], Al[i]] = [h, l];\n    }\n    return [Ah, Al];\n}\nconst toBig = (h, l) => (BigInt(h >>> 0) << _32n) | BigInt(l >>> 0);\n// for Shift in [0, 32)\nconst shrSH = (h, _l, s) => h >>> s;\nconst shrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);\n// Right rotate for Shift in [1, 32)\nconst rotrSH = (h, l, s) => (h >>> s) | (l << (32 - s));\nconst rotrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);\n// Right rotate for Shift in (32, 64), NOTE: 32 is special case.\nconst rotrBH = (h, l, s) => (h << (64 - s)) | (l >>> (s - 32));\nconst rotrBL = (h, l, s) => (h >>> (s - 32)) | (l << (64 - s));\n// Right rotate for shift===32 (just swaps l&h)\nconst rotr32H = (_h, l) => l;\nconst rotr32L = (h, _l) => h;\n// Left rotate for Shift in [1, 32)\nconst rotlSH = (h, l, s) => (h << s) | (l >>> (32 - s));\nconst rotlSL = (h, l, s) => (l << s) | (h >>> (32 - s));\n// Left rotate for Shift in (32, 64), NOTE: 32 is special case.\nconst rotlBH = (h, l, s) => (l << (s - 32)) | (h >>> (64 - s));\nconst rotlBL = (h, l, s) => (h << (s - 32)) | (l >>> (64 - s));\n// JS uses 32-bit signed integers for bitwise operations which means we cannot\n// simple take carry out of low bit sum by shift, we need to use division.\nfunction add(Ah, Al, Bh, Bl) {\n    const l = (Al >>> 0) + (Bl >>> 0);\n    return { h: (Ah + Bh + ((l / 2 ** 32) | 0)) | 0, l: l | 0 };\n}\n// Addition with more than 2 elements\nconst add3L = (Al, Bl, Cl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0);\nconst add3H = (low, Ah, Bh, Ch) => (Ah + Bh + Ch + ((low / 2 ** 32) | 0)) | 0;\nconst add4L = (Al, Bl, Cl, Dl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0);\nconst add4H = (low, Ah, Bh, Ch, Dh) => (Ah + Bh + Ch + Dh + ((low / 2 ** 32) | 0)) | 0;\nconst add5L = (Al, Bl, Cl, Dl, El) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0) + (El >>> 0);\nconst add5H = (low, Ah, Bh, Ch, Dh, Eh) => (Ah + Bh + Ch + Dh + Eh + ((low / 2 ** 32) | 0)) | 0;\n// prettier-ignore\nexport { fromBig, split, toBig, shrSH, shrSL, rotrSH, rotrSL, rotrBH, rotrBL, rotr32H, rotr32L, rotlSH, rotlSL, rotlBH, rotlBL, add, add3L, add3H, add4L, add4H, add5H, add5L, };\n// prettier-ignore\nconst u64 = {\n    fromBig, split, toBig,\n    shrSH, shrSL,\n    rotrSH, rotrSL, rotrBH, rotrBL,\n    rotr32H, rotr32L,\n    rotlSH, rotlSL, rotlBH, rotlBL,\n    add, add3L, add3H, add4L, add4H, add5H, add5L,\n};\nexport default u64;\n//# sourceMappingURL=_u64.js.map","export const crypto = typeof globalThis === 'object' && 'crypto' in globalThis ? globalThis.crypto : undefined;\n//# sourceMappingURL=crypto.js.map","import { hash as assertHash, bytes as assertBytes, exists as assertExists } from './_assert.js';\nimport { Hash, toBytes } from './utils.js';\n// HMAC (RFC 2104)\nexport class HMAC extends Hash {\n    constructor(hash, _key) {\n        super();\n        this.finished = false;\n        this.destroyed = false;\n        assertHash(hash);\n        const key = toBytes(_key);\n        this.iHash = hash.create();\n        if (typeof this.iHash.update !== 'function')\n            throw new Error('Expected instance of class which extends utils.Hash');\n        this.blockLen = this.iHash.blockLen;\n        this.outputLen = this.iHash.outputLen;\n        const blockLen = this.blockLen;\n        const pad = new Uint8Array(blockLen);\n        // blockLen can be bigger than outputLen\n        pad.set(key.length > blockLen ? hash.create().update(key).digest() : key);\n        for (let i = 0; i < pad.length; i++)\n            pad[i] ^= 0x36;\n        this.iHash.update(pad);\n        // By doing update (processing of first block) of outer hash here we can re-use it between multiple calls via clone\n        this.oHash = hash.create();\n        // Undo internal XOR && apply outer XOR\n        for (let i = 0; i < pad.length; i++)\n            pad[i] ^= 0x36 ^ 0x5c;\n        this.oHash.update(pad);\n        pad.fill(0);\n    }\n    update(buf) {\n        assertExists(this);\n        this.iHash.update(buf);\n        return this;\n    }\n    digestInto(out) {\n        assertExists(this);\n        assertBytes(out, this.outputLen);\n        this.finished = true;\n        this.iHash.digestInto(out);\n        this.oHash.update(out);\n        this.oHash.digestInto(out);\n        this.destroy();\n    }\n    digest() {\n        const out = new Uint8Array(this.oHash.outputLen);\n        this.digestInto(out);\n        return out;\n    }\n    _cloneInto(to) {\n        // Create new instance without calling constructor since key already in state and we don't know it.\n        to || (to = Object.create(Object.getPrototypeOf(this), {}));\n        const { oHash, iHash, finished, destroyed, blockLen, outputLen } = this;\n        to = to;\n        to.finished = finished;\n        to.destroyed = destroyed;\n        to.blockLen = blockLen;\n        to.outputLen = outputLen;\n        to.oHash = oHash._cloneInto(to.oHash);\n        to.iHash = iHash._cloneInto(to.iHash);\n        return to;\n    }\n    destroy() {\n        this.destroyed = true;\n        this.oHash.destroy();\n        this.iHash.destroy();\n    }\n}\n/**\n * HMAC: RFC2104 message authentication code.\n * @param hash - function that would be used e.g. sha256\n * @param key - message key\n * @param message - message data\n */\nexport const hmac = (hash, key, message) => new HMAC(hash, key).update(message).digest();\nhmac.create = (hash, key) => new HMAC(hash, key);\n//# sourceMappingURL=hmac.js.map","import { hash as assertHash, number as assertNumber } from './_assert.js';\nimport { hmac } from './hmac.js';\nimport { createView, toBytes, checkOpts, asyncLoop } from './utils.js';\n// Common prologue and epilogue for sync/async functions\nfunction pbkdf2Init(hash, _password, _salt, _opts) {\n    assertHash(hash);\n    const opts = checkOpts({ dkLen: 32, asyncTick: 10 }, _opts);\n    const { c, dkLen, asyncTick } = opts;\n    assertNumber(c);\n    assertNumber(dkLen);\n    assertNumber(asyncTick);\n    if (c < 1)\n        throw new Error('PBKDF2: iterations (c) should be >= 1');\n    const password = toBytes(_password);\n    const salt = toBytes(_salt);\n    // DK = PBKDF2(PRF, Password, Salt, c, dkLen);\n    const DK = new Uint8Array(dkLen);\n    // U1 = PRF(Password, Salt + INT_32_BE(i))\n    const PRF = hmac.create(hash, password);\n    const PRFSalt = PRF._cloneInto().update(salt);\n    return { c, dkLen, asyncTick, DK, PRF, PRFSalt };\n}\nfunction pbkdf2Output(PRF, PRFSalt, DK, prfW, u) {\n    PRF.destroy();\n    PRFSalt.destroy();\n    if (prfW)\n        prfW.destroy();\n    u.fill(0);\n    return DK;\n}\n/**\n * PBKDF2-HMAC: RFC 2898 key derivation function\n * @param hash - hash function that would be used e.g. sha256\n * @param password - password from which a derived key is generated\n * @param salt - cryptographic salt\n * @param opts - {c, dkLen} where c is work factor and dkLen is output message size\n */\nexport function pbkdf2(hash, password, salt, opts) {\n    const { c, dkLen, DK, PRF, PRFSalt } = pbkdf2Init(hash, password, salt, opts);\n    let prfW; // Working copy\n    const arr = new Uint8Array(4);\n    const view = createView(arr);\n    const u = new Uint8Array(PRF.outputLen);\n    // DK = T1 + T2 +  + Tdklen/hlen\n    for (let ti = 1, pos = 0; pos < dkLen; ti++, pos += PRF.outputLen) {\n        // Ti = F(Password, Salt, c, i)\n        const Ti = DK.subarray(pos, pos + PRF.outputLen);\n        view.setInt32(0, ti, false);\n        // F(Password, Salt, c, i) = U1 ^ U2 ^  ^ Uc\n        // U1 = PRF(Password, Salt + INT_32_BE(i))\n        (prfW = PRFSalt._cloneInto(prfW)).update(arr).digestInto(u);\n        Ti.set(u.subarray(0, Ti.length));\n        for (let ui = 1; ui < c; ui++) {\n            // Uc = PRF(Password, Uc1)\n            PRF._cloneInto(prfW).update(u).digestInto(u);\n            for (let i = 0; i < Ti.length; i++)\n                Ti[i] ^= u[i];\n        }\n    }\n    return pbkdf2Output(PRF, PRFSalt, DK, prfW, u);\n}\nexport async function pbkdf2Async(hash, password, salt, opts) {\n    const { c, dkLen, asyncTick, DK, PRF, PRFSalt } = pbkdf2Init(hash, password, salt, opts);\n    let prfW; // Working copy\n    const arr = new Uint8Array(4);\n    const view = createView(arr);\n    const u = new Uint8Array(PRF.outputLen);\n    // DK = T1 + T2 +  + Tdklen/hlen\n    for (let ti = 1, pos = 0; pos < dkLen; ti++, pos += PRF.outputLen) {\n        // Ti = F(Password, Salt, c, i)\n        const Ti = DK.subarray(pos, pos + PRF.outputLen);\n        view.setInt32(0, ti, false);\n        // F(Password, Salt, c, i) = U1 ^ U2 ^  ^ Uc\n        // U1 = PRF(Password, Salt + INT_32_BE(i))\n        (prfW = PRFSalt._cloneInto(prfW)).update(arr).digestInto(u);\n        Ti.set(u.subarray(0, Ti.length));\n        await asyncLoop(c - 1, asyncTick, () => {\n            // Uc = PRF(Password, Uc1)\n            PRF._cloneInto(prfW).update(u).digestInto(u);\n            for (let i = 0; i < Ti.length; i++)\n                Ti[i] ^= u[i];\n        });\n    }\n    return pbkdf2Output(PRF, PRFSalt, DK, prfW, u);\n}\n//# sourceMappingURL=pbkdf2.js.map","import { HashMD, Chi, Maj } from './_md.js';\nimport { rotr, wrapConstructor } from './utils.js';\n// SHA2-256 need to try 2^128 hashes to execute birthday attack.\n// BTC network is doing 2^67 hashes/sec as per early 2023.\n// Round constants:\n// first 32 bits of the fractional parts of the cube roots of the first 64 primes 2..311)\n// prettier-ignore\nconst SHA256_K = /* @__PURE__ */ new Uint32Array([\n    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2\n]);\n// Initial state:\n// first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19\n// prettier-ignore\nconst SHA256_IV = /* @__PURE__ */ new Uint32Array([\n    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19\n]);\n// Temporary buffer, not used to store anything between runs\n// Named this way because it matches specification.\nconst SHA256_W = /* @__PURE__ */ new Uint32Array(64);\nclass SHA256 extends HashMD {\n    constructor() {\n        super(64, 32, 8, false);\n        // We cannot use array here since array allows indexing by variable\n        // which means optimizer/compiler cannot use registers.\n        this.A = SHA256_IV[0] | 0;\n        this.B = SHA256_IV[1] | 0;\n        this.C = SHA256_IV[2] | 0;\n        this.D = SHA256_IV[3] | 0;\n        this.E = SHA256_IV[4] | 0;\n        this.F = SHA256_IV[5] | 0;\n        this.G = SHA256_IV[6] | 0;\n        this.H = SHA256_IV[7] | 0;\n    }\n    get() {\n        const { A, B, C, D, E, F, G, H } = this;\n        return [A, B, C, D, E, F, G, H];\n    }\n    // prettier-ignore\n    set(A, B, C, D, E, F, G, H) {\n        this.A = A | 0;\n        this.B = B | 0;\n        this.C = C | 0;\n        this.D = D | 0;\n        this.E = E | 0;\n        this.F = F | 0;\n        this.G = G | 0;\n        this.H = H | 0;\n    }\n    process(view, offset) {\n        // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array\n        for (let i = 0; i < 16; i++, offset += 4)\n            SHA256_W[i] = view.getUint32(offset, false);\n        for (let i = 16; i < 64; i++) {\n            const W15 = SHA256_W[i - 15];\n            const W2 = SHA256_W[i - 2];\n            const s0 = rotr(W15, 7) ^ rotr(W15, 18) ^ (W15 >>> 3);\n            const s1 = rotr(W2, 17) ^ rotr(W2, 19) ^ (W2 >>> 10);\n            SHA256_W[i] = (s1 + SHA256_W[i - 7] + s0 + SHA256_W[i - 16]) | 0;\n        }\n        // Compression function main loop, 64 rounds\n        let { A, B, C, D, E, F, G, H } = this;\n        for (let i = 0; i < 64; i++) {\n            const sigma1 = rotr(E, 6) ^ rotr(E, 11) ^ rotr(E, 25);\n            const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;\n            const sigma0 = rotr(A, 2) ^ rotr(A, 13) ^ rotr(A, 22);\n            const T2 = (sigma0 + Maj(A, B, C)) | 0;\n            H = G;\n            G = F;\n            F = E;\n            E = (D + T1) | 0;\n            D = C;\n            C = B;\n            B = A;\n            A = (T1 + T2) | 0;\n        }\n        // Add the compressed chunk to the current hash value\n        A = (A + this.A) | 0;\n        B = (B + this.B) | 0;\n        C = (C + this.C) | 0;\n        D = (D + this.D) | 0;\n        E = (E + this.E) | 0;\n        F = (F + this.F) | 0;\n        G = (G + this.G) | 0;\n        H = (H + this.H) | 0;\n        this.set(A, B, C, D, E, F, G, H);\n    }\n    roundClean() {\n        SHA256_W.fill(0);\n    }\n    destroy() {\n        this.set(0, 0, 0, 0, 0, 0, 0, 0);\n        this.buffer.fill(0);\n    }\n}\n// Constants from https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf\nclass SHA224 extends SHA256 {\n    constructor() {\n        super();\n        this.A = 0xc1059ed8 | 0;\n        this.B = 0x367cd507 | 0;\n        this.C = 0x3070dd17 | 0;\n        this.D = 0xf70e5939 | 0;\n        this.E = 0xffc00b31 | 0;\n        this.F = 0x68581511 | 0;\n        this.G = 0x64f98fa7 | 0;\n        this.H = 0xbefa4fa4 | 0;\n        this.outputLen = 28;\n    }\n}\n/**\n * SHA2-256 hash function\n * @param message - data that would be hashed\n */\nexport const sha256 = /* @__PURE__ */ wrapConstructor(() => new SHA256());\nexport const sha224 = /* @__PURE__ */ wrapConstructor(() => new SHA224());\n//# sourceMappingURL=sha256.js.map","import { HashMD } from './_md.js';\nimport u64 from './_u64.js';\nimport { wrapConstructor } from './utils.js';\n// Round contants (first 32 bits of the fractional parts of the cube roots of the first 80 primes 2..409):\n// prettier-ignore\nconst [SHA512_Kh, SHA512_Kl] = /* @__PURE__ */ (() => u64.split([\n    '0x428a2f98d728ae22', '0x7137449123ef65cd', '0xb5c0fbcfec4d3b2f', '0xe9b5dba58189dbbc',\n    '0x3956c25bf348b538', '0x59f111f1b605d019', '0x923f82a4af194f9b', '0xab1c5ed5da6d8118',\n    '0xd807aa98a3030242', '0x12835b0145706fbe', '0x243185be4ee4b28c', '0x550c7dc3d5ffb4e2',\n    '0x72be5d74f27b896f', '0x80deb1fe3b1696b1', '0x9bdc06a725c71235', '0xc19bf174cf692694',\n    '0xe49b69c19ef14ad2', '0xefbe4786384f25e3', '0x0fc19dc68b8cd5b5', '0x240ca1cc77ac9c65',\n    '0x2de92c6f592b0275', '0x4a7484aa6ea6e483', '0x5cb0a9dcbd41fbd4', '0x76f988da831153b5',\n    '0x983e5152ee66dfab', '0xa831c66d2db43210', '0xb00327c898fb213f', '0xbf597fc7beef0ee4',\n    '0xc6e00bf33da88fc2', '0xd5a79147930aa725', '0x06ca6351e003826f', '0x142929670a0e6e70',\n    '0x27b70a8546d22ffc', '0x2e1b21385c26c926', '0x4d2c6dfc5ac42aed', '0x53380d139d95b3df',\n    '0x650a73548baf63de', '0x766a0abb3c77b2a8', '0x81c2c92e47edaee6', '0x92722c851482353b',\n    '0xa2bfe8a14cf10364', '0xa81a664bbc423001', '0xc24b8b70d0f89791', '0xc76c51a30654be30',\n    '0xd192e819d6ef5218', '0xd69906245565a910', '0xf40e35855771202a', '0x106aa07032bbd1b8',\n    '0x19a4c116b8d2d0c8', '0x1e376c085141ab53', '0x2748774cdf8eeb99', '0x34b0bcb5e19b48a8',\n    '0x391c0cb3c5c95a63', '0x4ed8aa4ae3418acb', '0x5b9cca4f7763e373', '0x682e6ff3d6b2b8a3',\n    '0x748f82ee5defb2fc', '0x78a5636f43172f60', '0x84c87814a1f0ab72', '0x8cc702081a6439ec',\n    '0x90befffa23631e28', '0xa4506cebde82bde9', '0xbef9a3f7b2c67915', '0xc67178f2e372532b',\n    '0xca273eceea26619c', '0xd186b8c721c0c207', '0xeada7dd6cde0eb1e', '0xf57d4f7fee6ed178',\n    '0x06f067aa72176fba', '0x0a637dc5a2c898a6', '0x113f9804bef90dae', '0x1b710b35131c471b',\n    '0x28db77f523047d84', '0x32caab7b40c72493', '0x3c9ebe0a15c9bebc', '0x431d67c49c100d4c',\n    '0x4cc5d4becb3e42b6', '0x597f299cfc657e2a', '0x5fcb6fab3ad6faec', '0x6c44198c4a475817'\n].map(n => BigInt(n))))();\n// Temporary buffer, not used to store anything between runs\nconst SHA512_W_H = /* @__PURE__ */ new Uint32Array(80);\nconst SHA512_W_L = /* @__PURE__ */ new Uint32Array(80);\nexport class SHA512 extends HashMD {\n    constructor() {\n        super(128, 64, 16, false);\n        // We cannot use array here since array allows indexing by variable which means optimizer/compiler cannot use registers.\n        // Also looks cleaner and easier to verify with spec.\n        // Initial state (first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19):\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = 0x6a09e667 | 0;\n        this.Al = 0xf3bcc908 | 0;\n        this.Bh = 0xbb67ae85 | 0;\n        this.Bl = 0x84caa73b | 0;\n        this.Ch = 0x3c6ef372 | 0;\n        this.Cl = 0xfe94f82b | 0;\n        this.Dh = 0xa54ff53a | 0;\n        this.Dl = 0x5f1d36f1 | 0;\n        this.Eh = 0x510e527f | 0;\n        this.El = 0xade682d1 | 0;\n        this.Fh = 0x9b05688c | 0;\n        this.Fl = 0x2b3e6c1f | 0;\n        this.Gh = 0x1f83d9ab | 0;\n        this.Gl = 0xfb41bd6b | 0;\n        this.Hh = 0x5be0cd19 | 0;\n        this.Hl = 0x137e2179 | 0;\n    }\n    // prettier-ignore\n    get() {\n        const { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;\n        return [Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl];\n    }\n    // prettier-ignore\n    set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl) {\n        this.Ah = Ah | 0;\n        this.Al = Al | 0;\n        this.Bh = Bh | 0;\n        this.Bl = Bl | 0;\n        this.Ch = Ch | 0;\n        this.Cl = Cl | 0;\n        this.Dh = Dh | 0;\n        this.Dl = Dl | 0;\n        this.Eh = Eh | 0;\n        this.El = El | 0;\n        this.Fh = Fh | 0;\n        this.Fl = Fl | 0;\n        this.Gh = Gh | 0;\n        this.Gl = Gl | 0;\n        this.Hh = Hh | 0;\n        this.Hl = Hl | 0;\n    }\n    process(view, offset) {\n        // Extend the first 16 words into the remaining 64 words w[16..79] of the message schedule array\n        for (let i = 0; i < 16; i++, offset += 4) {\n            SHA512_W_H[i] = view.getUint32(offset);\n            SHA512_W_L[i] = view.getUint32((offset += 4));\n        }\n        for (let i = 16; i < 80; i++) {\n            // s0 := (w[i-15] rightrotate 1) xor (w[i-15] rightrotate 8) xor (w[i-15] rightshift 7)\n            const W15h = SHA512_W_H[i - 15] | 0;\n            const W15l = SHA512_W_L[i - 15] | 0;\n            const s0h = u64.rotrSH(W15h, W15l, 1) ^ u64.rotrSH(W15h, W15l, 8) ^ u64.shrSH(W15h, W15l, 7);\n            const s0l = u64.rotrSL(W15h, W15l, 1) ^ u64.rotrSL(W15h, W15l, 8) ^ u64.shrSL(W15h, W15l, 7);\n            // s1 := (w[i-2] rightrotate 19) xor (w[i-2] rightrotate 61) xor (w[i-2] rightshift 6)\n            const W2h = SHA512_W_H[i - 2] | 0;\n            const W2l = SHA512_W_L[i - 2] | 0;\n            const s1h = u64.rotrSH(W2h, W2l, 19) ^ u64.rotrBH(W2h, W2l, 61) ^ u64.shrSH(W2h, W2l, 6);\n            const s1l = u64.rotrSL(W2h, W2l, 19) ^ u64.rotrBL(W2h, W2l, 61) ^ u64.shrSL(W2h, W2l, 6);\n            // SHA256_W[i] = s0 + s1 + SHA256_W[i - 7] + SHA256_W[i - 16];\n            const SUMl = u64.add4L(s0l, s1l, SHA512_W_L[i - 7], SHA512_W_L[i - 16]);\n            const SUMh = u64.add4H(SUMl, s0h, s1h, SHA512_W_H[i - 7], SHA512_W_H[i - 16]);\n            SHA512_W_H[i] = SUMh | 0;\n            SHA512_W_L[i] = SUMl | 0;\n        }\n        let { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;\n        // Compression function main loop, 80 rounds\n        for (let i = 0; i < 80; i++) {\n            // S1 := (e rightrotate 14) xor (e rightrotate 18) xor (e rightrotate 41)\n            const sigma1h = u64.rotrSH(Eh, El, 14) ^ u64.rotrSH(Eh, El, 18) ^ u64.rotrBH(Eh, El, 41);\n            const sigma1l = u64.rotrSL(Eh, El, 14) ^ u64.rotrSL(Eh, El, 18) ^ u64.rotrBL(Eh, El, 41);\n            //const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;\n            const CHIh = (Eh & Fh) ^ (~Eh & Gh);\n            const CHIl = (El & Fl) ^ (~El & Gl);\n            // T1 = H + sigma1 + Chi(E, F, G) + SHA512_K[i] + SHA512_W[i]\n            // prettier-ignore\n            const T1ll = u64.add5L(Hl, sigma1l, CHIl, SHA512_Kl[i], SHA512_W_L[i]);\n            const T1h = u64.add5H(T1ll, Hh, sigma1h, CHIh, SHA512_Kh[i], SHA512_W_H[i]);\n            const T1l = T1ll | 0;\n            // S0 := (a rightrotate 28) xor (a rightrotate 34) xor (a rightrotate 39)\n            const sigma0h = u64.rotrSH(Ah, Al, 28) ^ u64.rotrBH(Ah, Al, 34) ^ u64.rotrBH(Ah, Al, 39);\n            const sigma0l = u64.rotrSL(Ah, Al, 28) ^ u64.rotrBL(Ah, Al, 34) ^ u64.rotrBL(Ah, Al, 39);\n            const MAJh = (Ah & Bh) ^ (Ah & Ch) ^ (Bh & Ch);\n            const MAJl = (Al & Bl) ^ (Al & Cl) ^ (Bl & Cl);\n            Hh = Gh | 0;\n            Hl = Gl | 0;\n            Gh = Fh | 0;\n            Gl = Fl | 0;\n            Fh = Eh | 0;\n            Fl = El | 0;\n            ({ h: Eh, l: El } = u64.add(Dh | 0, Dl | 0, T1h | 0, T1l | 0));\n            Dh = Ch | 0;\n            Dl = Cl | 0;\n            Ch = Bh | 0;\n            Cl = Bl | 0;\n            Bh = Ah | 0;\n            Bl = Al | 0;\n            const All = u64.add3L(T1l, sigma0l, MAJl);\n            Ah = u64.add3H(All, T1h, sigma0h, MAJh);\n            Al = All | 0;\n        }\n        // Add the compressed chunk to the current hash value\n        ({ h: Ah, l: Al } = u64.add(this.Ah | 0, this.Al | 0, Ah | 0, Al | 0));\n        ({ h: Bh, l: Bl } = u64.add(this.Bh | 0, this.Bl | 0, Bh | 0, Bl | 0));\n        ({ h: Ch, l: Cl } = u64.add(this.Ch | 0, this.Cl | 0, Ch | 0, Cl | 0));\n        ({ h: Dh, l: Dl } = u64.add(this.Dh | 0, this.Dl | 0, Dh | 0, Dl | 0));\n        ({ h: Eh, l: El } = u64.add(this.Eh | 0, this.El | 0, Eh | 0, El | 0));\n        ({ h: Fh, l: Fl } = u64.add(this.Fh | 0, this.Fl | 0, Fh | 0, Fl | 0));\n        ({ h: Gh, l: Gl } = u64.add(this.Gh | 0, this.Gl | 0, Gh | 0, Gl | 0));\n        ({ h: Hh, l: Hl } = u64.add(this.Hh | 0, this.Hl | 0, Hh | 0, Hl | 0));\n        this.set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl);\n    }\n    roundClean() {\n        SHA512_W_H.fill(0);\n        SHA512_W_L.fill(0);\n    }\n    destroy() {\n        this.buffer.fill(0);\n        this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    }\n}\nclass SHA512_224 extends SHA512 {\n    constructor() {\n        super();\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = 0x8c3d37c8 | 0;\n        this.Al = 0x19544da2 | 0;\n        this.Bh = 0x73e19966 | 0;\n        this.Bl = 0x89dcd4d6 | 0;\n        this.Ch = 0x1dfab7ae | 0;\n        this.Cl = 0x32ff9c82 | 0;\n        this.Dh = 0x679dd514 | 0;\n        this.Dl = 0x582f9fcf | 0;\n        this.Eh = 0x0f6d2b69 | 0;\n        this.El = 0x7bd44da8 | 0;\n        this.Fh = 0x77e36f73 | 0;\n        this.Fl = 0x04c48942 | 0;\n        this.Gh = 0x3f9d85a8 | 0;\n        this.Gl = 0x6a1d36c8 | 0;\n        this.Hh = 0x1112e6ad | 0;\n        this.Hl = 0x91d692a1 | 0;\n        this.outputLen = 28;\n    }\n}\nclass SHA512_256 extends SHA512 {\n    constructor() {\n        super();\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = 0x22312194 | 0;\n        this.Al = 0xfc2bf72c | 0;\n        this.Bh = 0x9f555fa3 | 0;\n        this.Bl = 0xc84c64c2 | 0;\n        this.Ch = 0x2393b86b | 0;\n        this.Cl = 0x6f53b151 | 0;\n        this.Dh = 0x96387719 | 0;\n        this.Dl = 0x5940eabd | 0;\n        this.Eh = 0x96283ee2 | 0;\n        this.El = 0xa88effe3 | 0;\n        this.Fh = 0xbe5e1e25 | 0;\n        this.Fl = 0x53863992 | 0;\n        this.Gh = 0x2b0199fc | 0;\n        this.Gl = 0x2c85b8aa | 0;\n        this.Hh = 0x0eb72ddc | 0;\n        this.Hl = 0x81c52ca2 | 0;\n        this.outputLen = 32;\n    }\n}\nclass SHA384 extends SHA512 {\n    constructor() {\n        super();\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = 0xcbbb9d5d | 0;\n        this.Al = 0xc1059ed8 | 0;\n        this.Bh = 0x629a292a | 0;\n        this.Bl = 0x367cd507 | 0;\n        this.Ch = 0x9159015a | 0;\n        this.Cl = 0x3070dd17 | 0;\n        this.Dh = 0x152fecd8 | 0;\n        this.Dl = 0xf70e5939 | 0;\n        this.Eh = 0x67332667 | 0;\n        this.El = 0xffc00b31 | 0;\n        this.Fh = 0x8eb44a87 | 0;\n        this.Fl = 0x68581511 | 0;\n        this.Gh = 0xdb0c2e0d | 0;\n        this.Gl = 0x64f98fa7 | 0;\n        this.Hh = 0x47b5481d | 0;\n        this.Hl = 0xbefa4fa4 | 0;\n        this.outputLen = 48;\n    }\n}\nexport const sha512 = /* @__PURE__ */ wrapConstructor(() => new SHA512());\nexport const sha512_224 = /* @__PURE__ */ wrapConstructor(() => new SHA512_224());\nexport const sha512_256 = /* @__PURE__ */ wrapConstructor(() => new SHA512_256());\nexport const sha384 = /* @__PURE__ */ wrapConstructor(() => new SHA384());\n//# sourceMappingURL=sha512.js.map","/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.\n// node.js versions earlier than v19 don't declare it in global scope.\n// For node.js, package.json#exports field mapping rewrites import\n// from `crypto` to `cryptoNode`, which imports native module.\n// Makes the utils un-importable in browsers without a bundler.\n// Once node.js 18 is deprecated (2025-04-30), we can just drop the import.\nimport { crypto } from '@noble/hashes/crypto';\nimport { bytes as abytes } from './_assert.js';\n// export { isBytes } from './_assert.js';\n// We can't reuse isBytes from _assert, because somehow this causes huge perf issues\nexport function isBytes(a) {\n    return (a instanceof Uint8Array ||\n        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));\n}\n// Cast array to different type\nexport const u8 = (arr) => new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);\nexport const u32 = (arr) => new Uint32Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 4));\n// Cast array to view\nexport const createView = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);\n// The rotate right (circular right shift) operation for uint32\nexport const rotr = (word, shift) => (word << (32 - shift)) | (word >>> shift);\n// The rotate left (circular left shift) operation for uint32\nexport const rotl = (word, shift) => (word << shift) | ((word >>> (32 - shift)) >>> 0);\nexport const isLE = new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;\n// The byte swap operation for uint32\nexport const byteSwap = (word) => ((word << 24) & 0xff000000) |\n    ((word << 8) & 0xff0000) |\n    ((word >>> 8) & 0xff00) |\n    ((word >>> 24) & 0xff);\n// Conditionally byte swap if on a big-endian platform\nexport const byteSwapIfBE = isLE ? (n) => n : (n) => byteSwap(n);\n// In place byte swap for Uint32Array\nexport function byteSwap32(arr) {\n    for (let i = 0; i < arr.length; i++) {\n        arr[i] = byteSwap(arr[i]);\n    }\n}\n// Array where index 0xf0 (240) is mapped to string 'f0'\nconst hexes = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, '0'));\n/**\n * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'\n */\nexport function bytesToHex(bytes) {\n    abytes(bytes);\n    // pre-caching improves the speed 6x\n    let hex = '';\n    for (let i = 0; i < bytes.length; i++) {\n        hex += hexes[bytes[i]];\n    }\n    return hex;\n}\n// We use optimized technique to convert hex string to byte array\nconst asciis = { _0: 48, _9: 57, _A: 65, _F: 70, _a: 97, _f: 102 };\nfunction asciiToBase16(char) {\n    if (char >= asciis._0 && char <= asciis._9)\n        return char - asciis._0;\n    if (char >= asciis._A && char <= asciis._F)\n        return char - (asciis._A - 10);\n    if (char >= asciis._a && char <= asciis._f)\n        return char - (asciis._a - 10);\n    return;\n}\n/**\n * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])\n */\nexport function hexToBytes(hex) {\n    if (typeof hex !== 'string')\n        throw new Error('hex string expected, got ' + typeof hex);\n    const hl = hex.length;\n    const al = hl / 2;\n    if (hl % 2)\n        throw new Error('padded hex string expected, got unpadded hex of length ' + hl);\n    const array = new Uint8Array(al);\n    for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {\n        const n1 = asciiToBase16(hex.charCodeAt(hi));\n        const n2 = asciiToBase16(hex.charCodeAt(hi + 1));\n        if (n1 === undefined || n2 === undefined) {\n            const char = hex[hi] + hex[hi + 1];\n            throw new Error('hex string expected, got non-hex character \"' + char + '\" at index ' + hi);\n        }\n        array[ai] = n1 * 16 + n2;\n    }\n    return array;\n}\n// There is no setImmediate in browser and setTimeout is slow.\n// call of async fn will return Promise, which will be fullfiled only on\n// next scheduler queue processing step and this is exactly what we need.\nexport const nextTick = async () => { };\n// Returns control to thread each 'tick' ms to avoid blocking\nexport async function asyncLoop(iters, tick, cb) {\n    let ts = Date.now();\n    for (let i = 0; i < iters; i++) {\n        cb(i);\n        // Date.now() is not monotonic, so in case if clock goes backwards we return return control too\n        const diff = Date.now() - ts;\n        if (diff >= 0 && diff < tick)\n            continue;\n        await nextTick();\n        ts += diff;\n    }\n}\n/**\n * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])\n */\nexport function utf8ToBytes(str) {\n    if (typeof str !== 'string')\n        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);\n    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809\n}\n/**\n * Normalizes (non-hex) string or Uint8Array to Uint8Array.\n * Warning: when Uint8Array is passed, it would NOT get copied.\n * Keep in mind for future mutable operations.\n */\nexport function toBytes(data) {\n    if (typeof data === 'string')\n        data = utf8ToBytes(data);\n    abytes(data);\n    return data;\n}\n/**\n * Copies several Uint8Arrays into one.\n */\nexport function concatBytes(...arrays) {\n    let sum = 0;\n    for (let i = 0; i < arrays.length; i++) {\n        const a = arrays[i];\n        abytes(a);\n        sum += a.length;\n    }\n    const res = new Uint8Array(sum);\n    for (let i = 0, pad = 0; i < arrays.length; i++) {\n        const a = arrays[i];\n        res.set(a, pad);\n        pad += a.length;\n    }\n    return res;\n}\n// For runtime check if class implements interface\nexport class Hash {\n    // Safe version that clones internal state\n    clone() {\n        return this._cloneInto();\n    }\n}\nconst toStr = {}.toString;\nexport function checkOpts(defaults, opts) {\n    if (opts !== undefined && toStr.call(opts) !== '[object Object]')\n        throw new Error('Options should be object or undefined');\n    const merged = Object.assign(defaults, opts);\n    return merged;\n}\nexport function wrapConstructor(hashCons) {\n    const hashC = (msg) => hashCons().update(toBytes(msg)).digest();\n    const tmp = hashCons();\n    hashC.outputLen = tmp.outputLen;\n    hashC.blockLen = tmp.blockLen;\n    hashC.create = () => hashCons();\n    return hashC;\n}\nexport function wrapConstructorWithOpts(hashCons) {\n    const hashC = (msg, opts) => hashCons(opts).update(toBytes(msg)).digest();\n    const tmp = hashCons({});\n    hashC.outputLen = tmp.outputLen;\n    hashC.blockLen = tmp.blockLen;\n    hashC.create = (opts) => hashCons(opts);\n    return hashC;\n}\nexport function wrapXOFConstructorWithOpts(hashCons) {\n    const hashC = (msg, opts) => hashCons(opts).update(toBytes(msg)).digest();\n    const tmp = hashCons({});\n    hashC.outputLen = tmp.outputLen;\n    hashC.blockLen = tmp.blockLen;\n    hashC.create = (opts) => hashCons(opts);\n    return hashC;\n}\n/**\n * Secure PRNG. Uses `crypto.getRandomValues`, which defers to OS.\n */\nexport function randomBytes(bytesLength = 32) {\n    if (crypto && typeof crypto.getRandomValues === 'function') {\n        return crypto.getRandomValues(new Uint8Array(bytesLength));\n    }\n    throw new Error('crypto.getRandomValues must be defined');\n}\n//# sourceMappingURL=utils.js.map","/*! scure-base - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// Utilities\n/**\n * @__NO_SIDE_EFFECTS__\n */\nexport function assertNumber(n) {\n    if (!Number.isSafeInteger(n))\n        throw new Error(`Wrong integer: ${n}`);\n}\nfunction isBytes(a) {\n    return (a instanceof Uint8Array ||\n        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction chain(...args) {\n    const id = (a) => a;\n    // Wrap call in closure so JIT can inline calls\n    const wrap = (a, b) => (c) => a(b(c));\n    // Construct chain of args[-1].encode(args[-2].encode([...]))\n    const encode = args.map((x) => x.encode).reduceRight(wrap, id);\n    // Construct chain of args[0].decode(args[1].decode(...))\n    const decode = args.map((x) => x.decode).reduce(wrap, id);\n    return { encode, decode };\n}\n/**\n * Encodes integer radix representation to array of strings using alphabet and back\n * @__NO_SIDE_EFFECTS__\n */\nfunction alphabet(alphabet) {\n    return {\n        encode: (digits) => {\n            if (!Array.isArray(digits) || (digits.length && typeof digits[0] !== 'number'))\n                throw new Error('alphabet.encode input should be an array of numbers');\n            return digits.map((i) => {\n                assertNumber(i);\n                if (i < 0 || i >= alphabet.length)\n                    throw new Error(`Digit index outside alphabet: ${i} (alphabet: ${alphabet.length})`);\n                return alphabet[i];\n            });\n        },\n        decode: (input) => {\n            if (!Array.isArray(input) || (input.length && typeof input[0] !== 'string'))\n                throw new Error('alphabet.decode input should be array of strings');\n            return input.map((letter) => {\n                if (typeof letter !== 'string')\n                    throw new Error(`alphabet.decode: not string element=${letter}`);\n                const index = alphabet.indexOf(letter);\n                if (index === -1)\n                    throw new Error(`Unknown letter: \"${letter}\". Allowed: ${alphabet}`);\n                return index;\n            });\n        },\n    };\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction join(separator = '') {\n    if (typeof separator !== 'string')\n        throw new Error('join separator should be string');\n    return {\n        encode: (from) => {\n            if (!Array.isArray(from) || (from.length && typeof from[0] !== 'string'))\n                throw new Error('join.encode input should be array of strings');\n            for (let i of from)\n                if (typeof i !== 'string')\n                    throw new Error(`join.encode: non-string input=${i}`);\n            return from.join(separator);\n        },\n        decode: (to) => {\n            if (typeof to !== 'string')\n                throw new Error('join.decode input should be string');\n            return to.split(separator);\n        },\n    };\n}\n/**\n * Pad strings array so it has integer number of bits\n * @__NO_SIDE_EFFECTS__\n */\nfunction padding(bits, chr = '=') {\n    assertNumber(bits);\n    if (typeof chr !== 'string')\n        throw new Error('padding chr should be string');\n    return {\n        encode(data) {\n            if (!Array.isArray(data) || (data.length && typeof data[0] !== 'string'))\n                throw new Error('padding.encode input should be array of strings');\n            for (let i of data)\n                if (typeof i !== 'string')\n                    throw new Error(`padding.encode: non-string input=${i}`);\n            while ((data.length * bits) % 8)\n                data.push(chr);\n            return data;\n        },\n        decode(input) {\n            if (!Array.isArray(input) || (input.length && typeof input[0] !== 'string'))\n                throw new Error('padding.encode input should be array of strings');\n            for (let i of input)\n                if (typeof i !== 'string')\n                    throw new Error(`padding.decode: non-string input=${i}`);\n            let end = input.length;\n            if ((end * bits) % 8)\n                throw new Error('Invalid padding: string should have whole number of bytes');\n            for (; end > 0 && input[end - 1] === chr; end--) {\n                if (!(((end - 1) * bits) % 8))\n                    throw new Error('Invalid padding: string has too much padding');\n            }\n            return input.slice(0, end);\n        },\n    };\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction normalize(fn) {\n    if (typeof fn !== 'function')\n        throw new Error('normalize fn should be function');\n    return { encode: (from) => from, decode: (to) => fn(to) };\n}\n/**\n * Slow: O(n^2) time complexity\n * @__NO_SIDE_EFFECTS__\n */\nfunction convertRadix(data, from, to) {\n    // base 1 is impossible\n    if (from < 2)\n        throw new Error(`convertRadix: wrong from=${from}, base cannot be less than 2`);\n    if (to < 2)\n        throw new Error(`convertRadix: wrong to=${to}, base cannot be less than 2`);\n    if (!Array.isArray(data))\n        throw new Error('convertRadix: data should be array');\n    if (!data.length)\n        return [];\n    let pos = 0;\n    const res = [];\n    const digits = Array.from(data);\n    digits.forEach((d) => {\n        assertNumber(d);\n        if (d < 0 || d >= from)\n            throw new Error(`Wrong integer: ${d}`);\n    });\n    while (true) {\n        let carry = 0;\n        let done = true;\n        for (let i = pos; i < digits.length; i++) {\n            const digit = digits[i];\n            const digitBase = from * carry + digit;\n            if (!Number.isSafeInteger(digitBase) ||\n                (from * carry) / from !== carry ||\n                digitBase - digit !== from * carry) {\n                throw new Error('convertRadix: carry overflow');\n            }\n            carry = digitBase % to;\n            const rounded = Math.floor(digitBase / to);\n            digits[i] = rounded;\n            if (!Number.isSafeInteger(rounded) || rounded * to + carry !== digitBase)\n                throw new Error('convertRadix: carry overflow');\n            if (!done)\n                continue;\n            else if (!rounded)\n                pos = i;\n            else\n                done = false;\n        }\n        res.push(carry);\n        if (done)\n            break;\n    }\n    for (let i = 0; i < data.length - 1 && data[i] === 0; i++)\n        res.push(0);\n    return res.reverse();\n}\nconst gcd = /* @__NO_SIDE_EFFECTS__ */ (a, b) => (!b ? a : gcd(b, a % b));\nconst radix2carry = /*@__NO_SIDE_EFFECTS__ */ (from, to) => from + (to - gcd(from, to));\n/**\n * Implemented with numbers, because BigInt is 5x slower\n * @__NO_SIDE_EFFECTS__\n */\nfunction convertRadix2(data, from, to, padding) {\n    if (!Array.isArray(data))\n        throw new Error('convertRadix2: data should be array');\n    if (from <= 0 || from > 32)\n        throw new Error(`convertRadix2: wrong from=${from}`);\n    if (to <= 0 || to > 32)\n        throw new Error(`convertRadix2: wrong to=${to}`);\n    if (radix2carry(from, to) > 32) {\n        throw new Error(`convertRadix2: carry overflow from=${from} to=${to} carryBits=${radix2carry(from, to)}`);\n    }\n    let carry = 0;\n    let pos = 0; // bitwise position in current element\n    const mask = 2 ** to - 1;\n    const res = [];\n    for (const n of data) {\n        assertNumber(n);\n        if (n >= 2 ** from)\n            throw new Error(`convertRadix2: invalid data word=${n} from=${from}`);\n        carry = (carry << from) | n;\n        if (pos + from > 32)\n            throw new Error(`convertRadix2: carry overflow pos=${pos} from=${from}`);\n        pos += from;\n        for (; pos >= to; pos -= to)\n            res.push(((carry >> (pos - to)) & mask) >>> 0);\n        carry &= 2 ** pos - 1; // clean carry, otherwise it will cause overflow\n    }\n    carry = (carry << (to - pos)) & mask;\n    if (!padding && pos >= from)\n        throw new Error('Excess padding');\n    if (!padding && carry)\n        throw new Error(`Non-zero padding: ${carry}`);\n    if (padding && pos > 0)\n        res.push(carry >>> 0);\n    return res;\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction radix(num) {\n    assertNumber(num);\n    return {\n        encode: (bytes) => {\n            if (!isBytes(bytes))\n                throw new Error('radix.encode input should be Uint8Array');\n            return convertRadix(Array.from(bytes), 2 ** 8, num);\n        },\n        decode: (digits) => {\n            if (!Array.isArray(digits) || (digits.length && typeof digits[0] !== 'number'))\n                throw new Error('radix.decode input should be array of numbers');\n            return Uint8Array.from(convertRadix(digits, num, 2 ** 8));\n        },\n    };\n}\n/**\n * If both bases are power of same number (like `2**8 <-> 2**64`),\n * there is a linear algorithm. For now we have implementation for power-of-two bases only.\n * @__NO_SIDE_EFFECTS__\n */\nfunction radix2(bits, revPadding = false) {\n    assertNumber(bits);\n    if (bits <= 0 || bits > 32)\n        throw new Error('radix2: bits should be in (0..32]');\n    if (radix2carry(8, bits) > 32 || radix2carry(bits, 8) > 32)\n        throw new Error('radix2: carry overflow');\n    return {\n        encode: (bytes) => {\n            if (!isBytes(bytes))\n                throw new Error('radix2.encode input should be Uint8Array');\n            return convertRadix2(Array.from(bytes), 8, bits, !revPadding);\n        },\n        decode: (digits) => {\n            if (!Array.isArray(digits) || (digits.length && typeof digits[0] !== 'number'))\n                throw new Error('radix2.decode input should be array of numbers');\n            return Uint8Array.from(convertRadix2(digits, bits, 8, revPadding));\n        },\n    };\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction unsafeWrapper(fn) {\n    if (typeof fn !== 'function')\n        throw new Error('unsafeWrapper fn should be function');\n    return function (...args) {\n        try {\n            return fn.apply(null, args);\n        }\n        catch (e) { }\n    };\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction checksum(len, fn) {\n    assertNumber(len);\n    if (typeof fn !== 'function')\n        throw new Error('checksum fn should be function');\n    return {\n        encode(data) {\n            if (!isBytes(data))\n                throw new Error('checksum.encode: input should be Uint8Array');\n            const checksum = fn(data).slice(0, len);\n            const res = new Uint8Array(data.length + len);\n            res.set(data);\n            res.set(checksum, data.length);\n            return res;\n        },\n        decode(data) {\n            if (!isBytes(data))\n                throw new Error('checksum.decode: input should be Uint8Array');\n            const payload = data.slice(0, -len);\n            const newChecksum = fn(payload).slice(0, len);\n            const oldChecksum = data.slice(-len);\n            for (let i = 0; i < len; i++)\n                if (newChecksum[i] !== oldChecksum[i])\n                    throw new Error('Invalid checksum');\n            return payload;\n        },\n    };\n}\n// prettier-ignore\nexport const utils = {\n    alphabet, chain, checksum, convertRadix, convertRadix2, radix, radix2, join, padding,\n};\n// RFC 4648 aka RFC 3548\n// ---------------------\nexport const base16 = /* @__PURE__ */ chain(radix2(4), alphabet('0123456789ABCDEF'), join(''));\nexport const base32 = /* @__PURE__ */ chain(radix2(5), alphabet('ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'), padding(5), join(''));\nexport const base32nopad = /* @__PURE__ */ chain(radix2(5), alphabet('ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'), join(''));\nexport const base32hex = /* @__PURE__ */ chain(radix2(5), alphabet('0123456789ABCDEFGHIJKLMNOPQRSTUV'), padding(5), join(''));\nexport const base32hexnopad = /* @__PURE__ */ chain(radix2(5), alphabet('0123456789ABCDEFGHIJKLMNOPQRSTUV'), join(''));\nexport const base32crockford = /* @__PURE__ */ chain(radix2(5), alphabet('0123456789ABCDEFGHJKMNPQRSTVWXYZ'), join(''), normalize((s) => s.toUpperCase().replace(/O/g, '0').replace(/[IL]/g, '1')));\nexport const base64 = /* @__PURE__ */ chain(radix2(6), alphabet('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'), padding(6), join(''));\nexport const base64nopad = /* @__PURE__ */ chain(radix2(6), alphabet('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'), join(''));\nexport const base64url = /* @__PURE__ */ chain(radix2(6), alphabet('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'), padding(6), join(''));\nexport const base64urlnopad = /* @__PURE__ */ chain(radix2(6), alphabet('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'), join(''));\n// base58 code\n// -----------\nconst genBase58 = (abc) => chain(radix(58), alphabet(abc), join(''));\nexport const base58 = /* @__PURE__ */ genBase58('123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz');\nexport const base58flickr = /* @__PURE__ */ genBase58('123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ');\nexport const base58xrp = /* @__PURE__ */ genBase58('rpshnaf39wBUDNEGHJKLM4PQRST7VWXYZ2bcdeCg65jkm8oFqi1tuvAxyz');\n// xmr ver is done in 8-byte blocks (which equals 11 chars in decoding). Last (non-full) block padded with '1' to size in XMR_BLOCK_LEN.\n// Block encoding significantly reduces quadratic complexity of base58.\n// Data len (index) -> encoded block len\nconst XMR_BLOCK_LEN = [0, 2, 3, 5, 6, 7, 9, 10, 11];\nexport const base58xmr = {\n    encode(data) {\n        let res = '';\n        for (let i = 0; i < data.length; i += 8) {\n            const block = data.subarray(i, i + 8);\n            res += base58.encode(block).padStart(XMR_BLOCK_LEN[block.length], '1');\n        }\n        return res;\n    },\n    decode(str) {\n        let res = [];\n        for (let i = 0; i < str.length; i += 11) {\n            const slice = str.slice(i, i + 11);\n            const blockLen = XMR_BLOCK_LEN.indexOf(slice.length);\n            const block = base58.decode(slice);\n            for (let j = 0; j < block.length - blockLen; j++) {\n                if (block[j] !== 0)\n                    throw new Error('base58xmr: wrong padding');\n            }\n            res = res.concat(Array.from(block.slice(block.length - blockLen)));\n        }\n        return Uint8Array.from(res);\n    },\n};\nexport const createBase58check = (sha256) => chain(checksum(4, (data) => sha256(sha256(data))), base58);\n// legacy export, bad name\nexport const base58check = createBase58check;\nconst BECH_ALPHABET = /* @__PURE__ */ chain(alphabet('qpzry9x8gf2tvdw0s3jn54khce6mua7l'), join(''));\nconst POLYMOD_GENERATORS = [0x3b6a57b2, 0x26508e6d, 0x1ea119fa, 0x3d4233dd, 0x2a1462b3];\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction bech32Polymod(pre) {\n    const b = pre >> 25;\n    let chk = (pre & 0x1ffffff) << 5;\n    for (let i = 0; i < POLYMOD_GENERATORS.length; i++) {\n        if (((b >> i) & 1) === 1)\n            chk ^= POLYMOD_GENERATORS[i];\n    }\n    return chk;\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction bechChecksum(prefix, words, encodingConst = 1) {\n    const len = prefix.length;\n    let chk = 1;\n    for (let i = 0; i < len; i++) {\n        const c = prefix.charCodeAt(i);\n        if (c < 33 || c > 126)\n            throw new Error(`Invalid prefix (${prefix})`);\n        chk = bech32Polymod(chk) ^ (c >> 5);\n    }\n    chk = bech32Polymod(chk);\n    for (let i = 0; i < len; i++)\n        chk = bech32Polymod(chk) ^ (prefix.charCodeAt(i) & 0x1f);\n    for (let v of words)\n        chk = bech32Polymod(chk) ^ v;\n    for (let i = 0; i < 6; i++)\n        chk = bech32Polymod(chk);\n    chk ^= encodingConst;\n    return BECH_ALPHABET.encode(convertRadix2([chk % 2 ** 30], 30, 5, false));\n}\n/**\n * @__NO_SIDE_EFFECTS__\n */\nfunction genBech32(encoding) {\n    const ENCODING_CONST = encoding === 'bech32' ? 1 : 0x2bc830a3;\n    const _words = radix2(5);\n    const fromWords = _words.decode;\n    const toWords = _words.encode;\n    const fromWordsUnsafe = unsafeWrapper(fromWords);\n    function encode(prefix, words, limit = 90) {\n        if (typeof prefix !== 'string')\n            throw new Error(`bech32.encode prefix should be string, not ${typeof prefix}`);\n        if (!Array.isArray(words) || (words.length && typeof words[0] !== 'number'))\n            throw new Error(`bech32.encode words should be array of numbers, not ${typeof words}`);\n        if (prefix.length === 0)\n            throw new TypeError(`Invalid prefix length ${prefix.length}`);\n        const actualLength = prefix.length + 7 + words.length;\n        if (limit !== false && actualLength > limit)\n            throw new TypeError(`Length ${actualLength} exceeds limit ${limit}`);\n        const lowered = prefix.toLowerCase();\n        const sum = bechChecksum(lowered, words, ENCODING_CONST);\n        return `${lowered}1${BECH_ALPHABET.encode(words)}${sum}`;\n    }\n    function decode(str, limit = 90) {\n        if (typeof str !== 'string')\n            throw new Error(`bech32.decode input should be string, not ${typeof str}`);\n        if (str.length < 8 || (limit !== false && str.length > limit))\n            throw new TypeError(`Wrong string length: ${str.length} (${str}). Expected (8..${limit})`);\n        // don't allow mixed case\n        const lowered = str.toLowerCase();\n        if (str !== lowered && str !== str.toUpperCase())\n            throw new Error(`String must be lowercase or uppercase`);\n        const sepIndex = lowered.lastIndexOf('1');\n        if (sepIndex === 0 || sepIndex === -1)\n            throw new Error(`Letter \"1\" must be present between prefix and data only`);\n        const prefix = lowered.slice(0, sepIndex);\n        const data = lowered.slice(sepIndex + 1);\n        if (data.length < 6)\n            throw new Error('Data must be at least 6 characters long');\n        const words = BECH_ALPHABET.decode(data).slice(0, -6);\n        const sum = bechChecksum(prefix, words, ENCODING_CONST);\n        if (!data.endsWith(sum))\n            throw new Error(`Invalid checksum in ${str}: expected \"${sum}\"`);\n        return { prefix, words };\n    }\n    const decodeUnsafe = unsafeWrapper(decode);\n    function decodeToBytes(str) {\n        const { prefix, words } = decode(str, false);\n        return { prefix, words, bytes: fromWords(words) };\n    }\n    return { encode, decode, decodeToBytes, decodeUnsafe, fromWords, fromWordsUnsafe, toWords };\n}\nexport const bech32 = /* @__PURE__ */ genBech32('bech32');\nexport const bech32m = /* @__PURE__ */ genBech32('bech32m');\nexport const utf8 = {\n    encode: (data) => new TextDecoder().decode(data),\n    decode: (str) => new TextEncoder().encode(str),\n};\nexport const hex = /* @__PURE__ */ chain(radix2(4), alphabet('0123456789abcdef'), join(''), normalize((s) => {\n    if (typeof s !== 'string' || s.length % 2)\n        throw new TypeError(`hex.decode: expected string, got ${typeof s} with length ${s.length}`);\n    return s.toLowerCase();\n}));\n// prettier-ignore\nconst CODERS = {\n    utf8, hex, base16, base32, base64, base64url, base58, base58xmr\n};\nconst coderTypeError = 'Invalid encoding type. Available types: utf8, hex, base16, base32, base64, base64url, base58, base58xmr';\nexport const bytesToString = (type, bytes) => {\n    if (typeof type !== 'string' || !CODERS.hasOwnProperty(type))\n        throw new TypeError(coderTypeError);\n    if (!isBytes(bytes))\n        throw new TypeError('bytesToString() expects Uint8Array');\n    return CODERS[type].encode(bytes);\n};\nexport const str = bytesToString; // as in python, but for bytes only\nexport const stringToBytes = (type, str) => {\n    if (!CODERS.hasOwnProperty(type))\n        throw new TypeError(coderTypeError);\n    if (typeof str !== 'string')\n        throw new TypeError('stringToBytes() expects string');\n    return CODERS[type].decode(str);\n};\nexport const bytes = stringToBytes;\n//# sourceMappingURL=index.js.map","/*! scure-bip39 - MIT License (c) 2022 Patricio Palladino, Paul Miller (paulmillr.com) */\nimport { bytes as assertBytes, number as assertNumber } from '@noble/hashes/_assert';\nimport { pbkdf2, pbkdf2Async } from '@noble/hashes/pbkdf2';\nimport { sha256 } from '@noble/hashes/sha256';\nimport { sha512 } from '@noble/hashes/sha512';\nimport { randomBytes } from '@noble/hashes/utils';\nimport { utils as baseUtils } from '@scure/base';\n// Japanese wordlist\nconst isJapanese = (wordlist) => wordlist[0] === '\\u3042\\u3044\\u3053\\u304f\\u3057\\u3093';\n// Normalization replaces equivalent sequences of characters\n// so that any two texts that are equivalent will be reduced\n// to the same sequence of code points, called the normal form of the original text.\n// https://tonsky.me/blog/unicode/#why-is-a----\nfunction nfkd(str) {\n    if (typeof str !== 'string')\n        throw new TypeError(`Invalid mnemonic type: ${typeof str}`);\n    return str.normalize('NFKD');\n}\nfunction normalize(str) {\n    const norm = nfkd(str);\n    const words = norm.split(' ');\n    if (![12, 15, 18, 21, 24].includes(words.length))\n        throw new Error('Invalid mnemonic');\n    return { nfkd: norm, words };\n}\nfunction assertEntropy(entropy) {\n    assertBytes(entropy, 16, 20, 24, 28, 32);\n}\n/**\n * Generate x random words. Uses Cryptographically-Secure Random Number Generator.\n * @param wordlist imported wordlist for specific language\n * @param strength mnemonic strength 128-256 bits\n * @example\n * generateMnemonic(wordlist, 128)\n * // 'legal winner thank year wave sausage worth useful legal winner thank yellow'\n */\nexport function generateMnemonic(wordlist, strength = 128) {\n    assertNumber(strength);\n    if (strength % 32 !== 0 || strength > 256)\n        throw new TypeError('Invalid entropy');\n    return entropyToMnemonic(randomBytes(strength / 8), wordlist);\n}\nconst calcChecksum = (entropy) => {\n    // Checksum is ent.length/4 bits long\n    const bitsLeft = 8 - entropy.length / 4;\n    // Zero rightmost \"bitsLeft\" bits in byte\n    // For example: bitsLeft=4 val=10111101 -> 10110000\n    return new Uint8Array([(sha256(entropy)[0] >> bitsLeft) << bitsLeft]);\n};\nfunction getCoder(wordlist) {\n    if (!Array.isArray(wordlist) || wordlist.length !== 2048 || typeof wordlist[0] !== 'string')\n        throw new Error('Wordlist: expected array of 2048 strings');\n    wordlist.forEach((i) => {\n        if (typeof i !== 'string')\n            throw new Error(`Wordlist: non-string element: ${i}`);\n    });\n    return baseUtils.chain(baseUtils.checksum(1, calcChecksum), baseUtils.radix2(11, true), baseUtils.alphabet(wordlist));\n}\n/**\n * Reversible: Converts mnemonic string to raw entropy in form of byte array.\n * @param mnemonic 12-24 words\n * @param wordlist imported wordlist for specific language\n * @example\n * const mnem = 'legal winner thank year wave sausage worth useful legal winner thank yellow';\n * mnemonicToEntropy(mnem, wordlist)\n * // Produces\n * new Uint8Array([\n *   0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f,\n *   0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f\n * ])\n */\nexport function mnemonicToEntropy(mnemonic, wordlist) {\n    const { words } = normalize(mnemonic);\n    const entropy = getCoder(wordlist).decode(words);\n    assertEntropy(entropy);\n    return entropy;\n}\n/**\n * Reversible: Converts raw entropy in form of byte array to mnemonic string.\n * @param entropy byte array\n * @param wordlist imported wordlist for specific language\n * @returns 12-24 words\n * @example\n * const ent = new Uint8Array([\n *   0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f,\n *   0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f, 0x7f\n * ]);\n * entropyToMnemonic(ent, wordlist);\n * // 'legal winner thank year wave sausage worth useful legal winner thank yellow'\n */\nexport function entropyToMnemonic(entropy, wordlist) {\n    assertEntropy(entropy);\n    const words = getCoder(wordlist).encode(entropy);\n    return words.join(isJapanese(wordlist) ? '\\u3000' : ' ');\n}\n/**\n * Validates mnemonic for being 12-24 words contained in `wordlist`.\n */\nexport function validateMnemonic(mnemonic, wordlist) {\n    try {\n        mnemonicToEntropy(mnemonic, wordlist);\n    }\n    catch (e) {\n        return false;\n    }\n    return true;\n}\nconst salt = (passphrase) => nfkd(`mnemonic${passphrase}`);\n/**\n * Irreversible: Uses KDF to derive 64 bytes of key data from mnemonic + optional password.\n * @param mnemonic 12-24 words\n * @param passphrase string that will additionally protect the key\n * @returns 64 bytes of key data\n * @example\n * const mnem = 'legal winner thank year wave sausage worth useful legal winner thank yellow';\n * await mnemonicToSeed(mnem, 'password');\n * // new Uint8Array([...64 bytes])\n */\nexport function mnemonicToSeed(mnemonic, passphrase = '') {\n    return pbkdf2Async(sha512, normalize(mnemonic).nfkd, salt(passphrase), { c: 2048, dkLen: 64 });\n}\n/**\n * Irreversible: Uses KDF to derive 64 bytes of key data from mnemonic + optional password.\n * @param mnemonic 12-24 words\n * @param passphrase string that will additionally protect the key\n * @returns 64 bytes of key data\n * @example\n * const mnem = 'legal winner thank year wave sausage worth useful legal winner thank yellow';\n * mnemonicToSeedSync(mnem, 'password');\n * // new Uint8Array([...64 bytes])\n */\nexport function mnemonicToSeedSync(mnemonic, passphrase = '') {\n    return pbkdf2(sha512, normalize(mnemonic).nfkd, salt(passphrase), { c: 2048, dkLen: 64 });\n}\n","export const wordlist = `abandon\nability\nable\nabout\nabove\nabsent\nabsorb\nabstract\nabsurd\nabuse\naccess\naccident\naccount\naccuse\nachieve\nacid\nacoustic\nacquire\nacross\nact\naction\nactor\nactress\nactual\nadapt\nadd\naddict\naddress\nadjust\nadmit\nadult\nadvance\nadvice\naerobic\naffair\nafford\nafraid\nagain\nage\nagent\nagree\nahead\naim\nair\nairport\naisle\nalarm\nalbum\nalcohol\nalert\nalien\nall\nalley\nallow\nalmost\nalone\nalpha\nalready\nalso\nalter\nalways\namateur\namazing\namong\namount\namused\nanalyst\nanchor\nancient\nanger\nangle\nangry\nanimal\nankle\nannounce\nannual\nanother\nanswer\nantenna\nantique\nanxiety\nany\napart\napology\nappear\napple\napprove\napril\narch\narctic\narea\narena\nargue\narm\narmed\narmor\narmy\naround\narrange\narrest\narrive\narrow\nart\nartefact\nartist\nartwork\nask\naspect\nassault\nasset\nassist\nassume\nasthma\nathlete\natom\nattack\nattend\nattitude\nattract\nauction\naudit\naugust\naunt\nauthor\nauto\nautumn\naverage\navocado\navoid\nawake\naware\naway\nawesome\nawful\nawkward\naxis\nbaby\nbachelor\nbacon\nbadge\nbag\nbalance\nbalcony\nball\nbamboo\nbanana\nbanner\nbar\nbarely\nbargain\nbarrel\nbase\nbasic\nbasket\nbattle\nbeach\nbean\nbeauty\nbecause\nbecome\nbeef\nbefore\nbegin\nbehave\nbehind\nbelieve\nbelow\nbelt\nbench\nbenefit\nbest\nbetray\nbetter\nbetween\nbeyond\nbicycle\nbid\nbike\nbind\nbiology\nbird\nbirth\nbitter\nblack\nblade\nblame\nblanket\nblast\nbleak\nbless\nblind\nblood\nblossom\nblouse\nblue\nblur\nblush\nboard\nboat\nbody\nboil\nbomb\nbone\nbonus\nbook\nboost\nborder\nboring\nborrow\nboss\nbottom\nbounce\nbox\nboy\nbracket\nbrain\nbrand\nbrass\nbrave\nbread\nbreeze\nbrick\nbridge\nbrief\nbright\nbring\nbrisk\nbroccoli\nbroken\nbronze\nbroom\nbrother\nbrown\nbrush\nbubble\nbuddy\nbudget\nbuffalo\nbuild\nbulb\nbulk\nbullet\nbundle\nbunker\nburden\nburger\nburst\nbus\nbusiness\nbusy\nbutter\nbuyer\nbuzz\ncabbage\ncabin\ncable\ncactus\ncage\ncake\ncall\ncalm\ncamera\ncamp\ncan\ncanal\ncancel\ncandy\ncannon\ncanoe\ncanvas\ncanyon\ncapable\ncapital\ncaptain\ncar\ncarbon\ncard\ncargo\ncarpet\ncarry\ncart\ncase\ncash\ncasino\ncastle\ncasual\ncat\ncatalog\ncatch\ncategory\ncattle\ncaught\ncause\ncaution\ncave\nceiling\ncelery\ncement\ncensus\ncentury\ncereal\ncertain\nchair\nchalk\nchampion\nchange\nchaos\nchapter\ncharge\nchase\nchat\ncheap\ncheck\ncheese\nchef\ncherry\nchest\nchicken\nchief\nchild\nchimney\nchoice\nchoose\nchronic\nchuckle\nchunk\nchurn\ncigar\ncinnamon\ncircle\ncitizen\ncity\ncivil\nclaim\nclap\nclarify\nclaw\nclay\nclean\nclerk\nclever\nclick\nclient\ncliff\nclimb\nclinic\nclip\nclock\nclog\nclose\ncloth\ncloud\nclown\nclub\nclump\ncluster\nclutch\ncoach\ncoast\ncoconut\ncode\ncoffee\ncoil\ncoin\ncollect\ncolor\ncolumn\ncombine\ncome\ncomfort\ncomic\ncommon\ncompany\nconcert\nconduct\nconfirm\ncongress\nconnect\nconsider\ncontrol\nconvince\ncook\ncool\ncopper\ncopy\ncoral\ncore\ncorn\ncorrect\ncost\ncotton\ncouch\ncountry\ncouple\ncourse\ncousin\ncover\ncoyote\ncrack\ncradle\ncraft\ncram\ncrane\ncrash\ncrater\ncrawl\ncrazy\ncream\ncredit\ncreek\ncrew\ncricket\ncrime\ncrisp\ncritic\ncrop\ncross\ncrouch\ncrowd\ncrucial\ncruel\ncruise\ncrumble\ncrunch\ncrush\ncry\ncrystal\ncube\nculture\ncup\ncupboard\ncurious\ncurrent\ncurtain\ncurve\ncushion\ncustom\ncute\ncycle\ndad\ndamage\ndamp\ndance\ndanger\ndaring\ndash\ndaughter\ndawn\nday\ndeal\ndebate\ndebris\ndecade\ndecember\ndecide\ndecline\ndecorate\ndecrease\ndeer\ndefense\ndefine\ndefy\ndegree\ndelay\ndeliver\ndemand\ndemise\ndenial\ndentist\ndeny\ndepart\ndepend\ndeposit\ndepth\ndeputy\nderive\ndescribe\ndesert\ndesign\ndesk\ndespair\ndestroy\ndetail\ndetect\ndevelop\ndevice\ndevote\ndiagram\ndial\ndiamond\ndiary\ndice\ndiesel\ndiet\ndiffer\ndigital\ndignity\ndilemma\ndinner\ndinosaur\ndirect\ndirt\ndisagree\ndiscover\ndisease\ndish\ndismiss\ndisorder\ndisplay\ndistance\ndivert\ndivide\ndivorce\ndizzy\ndoctor\ndocument\ndog\ndoll\ndolphin\ndomain\ndonate\ndonkey\ndonor\ndoor\ndose\ndouble\ndove\ndraft\ndragon\ndrama\ndrastic\ndraw\ndream\ndress\ndrift\ndrill\ndrink\ndrip\ndrive\ndrop\ndrum\ndry\nduck\ndumb\ndune\nduring\ndust\ndutch\nduty\ndwarf\ndynamic\neager\neagle\nearly\nearn\nearth\neasily\neast\neasy\necho\necology\neconomy\nedge\nedit\neducate\neffort\negg\neight\neither\nelbow\nelder\nelectric\nelegant\nelement\nelephant\nelevator\nelite\nelse\nembark\nembody\nembrace\nemerge\nemotion\nemploy\nempower\nempty\nenable\nenact\nend\nendless\nendorse\nenemy\nenergy\nenforce\nengage\nengine\nenhance\nenjoy\nenlist\nenough\nenrich\nenroll\nensure\nenter\nentire\nentry\nenvelope\nepisode\nequal\nequip\nera\nerase\nerode\nerosion\nerror\nerupt\nescape\nessay\nessence\nestate\neternal\nethics\nevidence\nevil\nevoke\nevolve\nexact\nexample\nexcess\nexchange\nexcite\nexclude\nexcuse\nexecute\nexercise\nexhaust\nexhibit\nexile\nexist\nexit\nexotic\nexpand\nexpect\nexpire\nexplain\nexpose\nexpress\nextend\nextra\neye\neyebrow\nfabric\nface\nfaculty\nfade\nfaint\nfaith\nfall\nfalse\nfame\nfamily\nfamous\nfan\nfancy\nfantasy\nfarm\nfashion\nfat\nfatal\nfather\nfatigue\nfault\nfavorite\nfeature\nfebruary\nfederal\nfee\nfeed\nfeel\nfemale\nfence\nfestival\nfetch\nfever\nfew\nfiber\nfiction\nfield\nfigure\nfile\nfilm\nfilter\nfinal\nfind\nfine\nfinger\nfinish\nfire\nfirm\nfirst\nfiscal\nfish\nfit\nfitness\nfix\nflag\nflame\nflash\nflat\nflavor\nflee\nflight\nflip\nfloat\nflock\nfloor\nflower\nfluid\nflush\nfly\nfoam\nfocus\nfog\nfoil\nfold\nfollow\nfood\nfoot\nforce\nforest\nforget\nfork\nfortune\nforum\nforward\nfossil\nfoster\nfound\nfox\nfragile\nframe\nfrequent\nfresh\nfriend\nfringe\nfrog\nfront\nfrost\nfrown\nfrozen\nfruit\nfuel\nfun\nfunny\nfurnace\nfury\nfuture\ngadget\ngain\ngalaxy\ngallery\ngame\ngap\ngarage\ngarbage\ngarden\ngarlic\ngarment\ngas\ngasp\ngate\ngather\ngauge\ngaze\ngeneral\ngenius\ngenre\ngentle\ngenuine\ngesture\nghost\ngiant\ngift\ngiggle\nginger\ngiraffe\ngirl\ngive\nglad\nglance\nglare\nglass\nglide\nglimpse\nglobe\ngloom\nglory\nglove\nglow\nglue\ngoat\ngoddess\ngold\ngood\ngoose\ngorilla\ngospel\ngossip\ngovern\ngown\ngrab\ngrace\ngrain\ngrant\ngrape\ngrass\ngravity\ngreat\ngreen\ngrid\ngrief\ngrit\ngrocery\ngroup\ngrow\ngrunt\nguard\nguess\nguide\nguilt\nguitar\ngun\ngym\nhabit\nhair\nhalf\nhammer\nhamster\nhand\nhappy\nharbor\nhard\nharsh\nharvest\nhat\nhave\nhawk\nhazard\nhead\nhealth\nheart\nheavy\nhedgehog\nheight\nhello\nhelmet\nhelp\nhen\nhero\nhidden\nhigh\nhill\nhint\nhip\nhire\nhistory\nhobby\nhockey\nhold\nhole\nholiday\nhollow\nhome\nhoney\nhood\nhope\nhorn\nhorror\nhorse\nhospital\nhost\nhotel\nhour\nhover\nhub\nhuge\nhuman\nhumble\nhumor\nhundred\nhungry\nhunt\nhurdle\nhurry\nhurt\nhusband\nhybrid\nice\nicon\nidea\nidentify\nidle\nignore\nill\nillegal\nillness\nimage\nimitate\nimmense\nimmune\nimpact\nimpose\nimprove\nimpulse\ninch\ninclude\nincome\nincrease\nindex\nindicate\nindoor\nindustry\ninfant\ninflict\ninform\ninhale\ninherit\ninitial\ninject\ninjury\ninmate\ninner\ninnocent\ninput\ninquiry\ninsane\ninsect\ninside\ninspire\ninstall\nintact\ninterest\ninto\ninvest\ninvite\ninvolve\niron\nisland\nisolate\nissue\nitem\nivory\njacket\njaguar\njar\njazz\njealous\njeans\njelly\njewel\njob\njoin\njoke\njourney\njoy\njudge\njuice\njump\njungle\njunior\njunk\njust\nkangaroo\nkeen\nkeep\nketchup\nkey\nkick\nkid\nkidney\nkind\nkingdom\nkiss\nkit\nkitchen\nkite\nkitten\nkiwi\nknee\nknife\nknock\nknow\nlab\nlabel\nlabor\nladder\nlady\nlake\nlamp\nlanguage\nlaptop\nlarge\nlater\nlatin\nlaugh\nlaundry\nlava\nlaw\nlawn\nlawsuit\nlayer\nlazy\nleader\nleaf\nlearn\nleave\nlecture\nleft\nleg\nlegal\nlegend\nleisure\nlemon\nlend\nlength\nlens\nleopard\nlesson\nletter\nlevel\nliar\nliberty\nlibrary\nlicense\nlife\nlift\nlight\nlike\nlimb\nlimit\nlink\nlion\nliquid\nlist\nlittle\nlive\nlizard\nload\nloan\nlobster\nlocal\nlock\nlogic\nlonely\nlong\nloop\nlottery\nloud\nlounge\nlove\nloyal\nlucky\nluggage\nlumber\nlunar\nlunch\nluxury\nlyrics\nmachine\nmad\nmagic\nmagnet\nmaid\nmail\nmain\nmajor\nmake\nmammal\nman\nmanage\nmandate\nmango\nmansion\nmanual\nmaple\nmarble\nmarch\nmargin\nmarine\nmarket\nmarriage\nmask\nmass\nmaster\nmatch\nmaterial\nmath\nmatrix\nmatter\nmaximum\nmaze\nmeadow\nmean\nmeasure\nmeat\nmechanic\nmedal\nmedia\nmelody\nmelt\nmember\nmemory\nmention\nmenu\nmercy\nmerge\nmerit\nmerry\nmesh\nmessage\nmetal\nmethod\nmiddle\nmidnight\nmilk\nmillion\nmimic\nmind\nminimum\nminor\nminute\nmiracle\nmirror\nmisery\nmiss\nmistake\nmix\nmixed\nmixture\nmobile\nmodel\nmodify\nmom\nmoment\nmonitor\nmonkey\nmonster\nmonth\nmoon\nmoral\nmore\nmorning\nmosquito\nmother\nmotion\nmotor\nmountain\nmouse\nmove\nmovie\nmuch\nmuffin\nmule\nmultiply\nmuscle\nmuseum\nmushroom\nmusic\nmust\nmutual\nmyself\nmystery\nmyth\nnaive\nname\nnapkin\nnarrow\nnasty\nnation\nnature\nnear\nneck\nneed\nnegative\nneglect\nneither\nnephew\nnerve\nnest\nnet\nnetwork\nneutral\nnever\nnews\nnext\nnice\nnight\nnoble\nnoise\nnominee\nnoodle\nnormal\nnorth\nnose\nnotable\nnote\nnothing\nnotice\nnovel\nnow\nnuclear\nnumber\nnurse\nnut\noak\nobey\nobject\noblige\nobscure\nobserve\nobtain\nobvious\noccur\nocean\noctober\nodor\noff\noffer\noffice\noften\noil\nokay\nold\nolive\nolympic\nomit\nonce\none\nonion\nonline\nonly\nopen\nopera\nopinion\noppose\noption\norange\norbit\norchard\norder\nordinary\norgan\norient\noriginal\norphan\nostrich\nother\noutdoor\nouter\noutput\noutside\noval\noven\nover\nown\nowner\noxygen\noyster\nozone\npact\npaddle\npage\npair\npalace\npalm\npanda\npanel\npanic\npanther\npaper\nparade\nparent\npark\nparrot\nparty\npass\npatch\npath\npatient\npatrol\npattern\npause\npave\npayment\npeace\npeanut\npear\npeasant\npelican\npen\npenalty\npencil\npeople\npepper\nperfect\npermit\nperson\npet\nphone\nphoto\nphrase\nphysical\npiano\npicnic\npicture\npiece\npig\npigeon\npill\npilot\npink\npioneer\npipe\npistol\npitch\npizza\nplace\nplanet\nplastic\nplate\nplay\nplease\npledge\npluck\nplug\nplunge\npoem\npoet\npoint\npolar\npole\npolice\npond\npony\npool\npopular\nportion\nposition\npossible\npost\npotato\npottery\npoverty\npowder\npower\npractice\npraise\npredict\nprefer\nprepare\npresent\npretty\nprevent\nprice\npride\nprimary\nprint\npriority\nprison\nprivate\nprize\nproblem\nprocess\nproduce\nprofit\nprogram\nproject\npromote\nproof\nproperty\nprosper\nprotect\nproud\nprovide\npublic\npudding\npull\npulp\npulse\npumpkin\npunch\npupil\npuppy\npurchase\npurity\npurpose\npurse\npush\nput\npuzzle\npyramid\nquality\nquantum\nquarter\nquestion\nquick\nquit\nquiz\nquote\nrabbit\nraccoon\nrace\nrack\nradar\nradio\nrail\nrain\nraise\nrally\nramp\nranch\nrandom\nrange\nrapid\nrare\nrate\nrather\nraven\nraw\nrazor\nready\nreal\nreason\nrebel\nrebuild\nrecall\nreceive\nrecipe\nrecord\nrecycle\nreduce\nreflect\nreform\nrefuse\nregion\nregret\nregular\nreject\nrelax\nrelease\nrelief\nrely\nremain\nremember\nremind\nremove\nrender\nrenew\nrent\nreopen\nrepair\nrepeat\nreplace\nreport\nrequire\nrescue\nresemble\nresist\nresource\nresponse\nresult\nretire\nretreat\nreturn\nreunion\nreveal\nreview\nreward\nrhythm\nrib\nribbon\nrice\nrich\nride\nridge\nrifle\nright\nrigid\nring\nriot\nripple\nrisk\nritual\nrival\nriver\nroad\nroast\nrobot\nrobust\nrocket\nromance\nroof\nrookie\nroom\nrose\nrotate\nrough\nround\nroute\nroyal\nrubber\nrude\nrug\nrule\nrun\nrunway\nrural\nsad\nsaddle\nsadness\nsafe\nsail\nsalad\nsalmon\nsalon\nsalt\nsalute\nsame\nsample\nsand\nsatisfy\nsatoshi\nsauce\nsausage\nsave\nsay\nscale\nscan\nscare\nscatter\nscene\nscheme\nschool\nscience\nscissors\nscorpion\nscout\nscrap\nscreen\nscript\nscrub\nsea\nsearch\nseason\nseat\nsecond\nsecret\nsection\nsecurity\nseed\nseek\nsegment\nselect\nsell\nseminar\nsenior\nsense\nsentence\nseries\nservice\nsession\nsettle\nsetup\nseven\nshadow\nshaft\nshallow\nshare\nshed\nshell\nsheriff\nshield\nshift\nshine\nship\nshiver\nshock\nshoe\nshoot\nshop\nshort\nshoulder\nshove\nshrimp\nshrug\nshuffle\nshy\nsibling\nsick\nside\nsiege\nsight\nsign\nsilent\nsilk\nsilly\nsilver\nsimilar\nsimple\nsince\nsing\nsiren\nsister\nsituate\nsix\nsize\nskate\nsketch\nski\nskill\nskin\nskirt\nskull\nslab\nslam\nsleep\nslender\nslice\nslide\nslight\nslim\nslogan\nslot\nslow\nslush\nsmall\nsmart\nsmile\nsmoke\nsmooth\nsnack\nsnake\nsnap\nsniff\nsnow\nsoap\nsoccer\nsocial\nsock\nsoda\nsoft\nsolar\nsoldier\nsolid\nsolution\nsolve\nsomeone\nsong\nsoon\nsorry\nsort\nsoul\nsound\nsoup\nsource\nsouth\nspace\nspare\nspatial\nspawn\nspeak\nspecial\nspeed\nspell\nspend\nsphere\nspice\nspider\nspike\nspin\nspirit\nsplit\nspoil\nsponsor\nspoon\nsport\nspot\nspray\nspread\nspring\nspy\nsquare\nsqueeze\nsquirrel\nstable\nstadium\nstaff\nstage\nstairs\nstamp\nstand\nstart\nstate\nstay\nsteak\nsteel\nstem\nstep\nstereo\nstick\nstill\nsting\nstock\nstomach\nstone\nstool\nstory\nstove\nstrategy\nstreet\nstrike\nstrong\nstruggle\nstudent\nstuff\nstumble\nstyle\nsubject\nsubmit\nsubway\nsuccess\nsuch\nsudden\nsuffer\nsugar\nsuggest\nsuit\nsummer\nsun\nsunny\nsunset\nsuper\nsupply\nsupreme\nsure\nsurface\nsurge\nsurprise\nsurround\nsurvey\nsuspect\nsustain\nswallow\nswamp\nswap\nswarm\nswear\nsweet\nswift\nswim\nswing\nswitch\nsword\nsymbol\nsymptom\nsyrup\nsystem\ntable\ntackle\ntag\ntail\ntalent\ntalk\ntank\ntape\ntarget\ntask\ntaste\ntattoo\ntaxi\nteach\nteam\ntell\nten\ntenant\ntennis\ntent\nterm\ntest\ntext\nthank\nthat\ntheme\nthen\ntheory\nthere\nthey\nthing\nthis\nthought\nthree\nthrive\nthrow\nthumb\nthunder\nticket\ntide\ntiger\ntilt\ntimber\ntime\ntiny\ntip\ntired\ntissue\ntitle\ntoast\ntobacco\ntoday\ntoddler\ntoe\ntogether\ntoilet\ntoken\ntomato\ntomorrow\ntone\ntongue\ntonight\ntool\ntooth\ntop\ntopic\ntopple\ntorch\ntornado\ntortoise\ntoss\ntotal\ntourist\ntoward\ntower\ntown\ntoy\ntrack\ntrade\ntraffic\ntragic\ntrain\ntransfer\ntrap\ntrash\ntravel\ntray\ntreat\ntree\ntrend\ntrial\ntribe\ntrick\ntrigger\ntrim\ntrip\ntrophy\ntrouble\ntruck\ntrue\ntruly\ntrumpet\ntrust\ntruth\ntry\ntube\ntuition\ntumble\ntuna\ntunnel\nturkey\nturn\nturtle\ntwelve\ntwenty\ntwice\ntwin\ntwist\ntwo\ntype\ntypical\nugly\numbrella\nunable\nunaware\nuncle\nuncover\nunder\nundo\nunfair\nunfold\nunhappy\nuniform\nunique\nunit\nuniverse\nunknown\nunlock\nuntil\nunusual\nunveil\nupdate\nupgrade\nuphold\nupon\nupper\nupset\nurban\nurge\nusage\nuse\nused\nuseful\nuseless\nusual\nutility\nvacant\nvacuum\nvague\nvalid\nvalley\nvalve\nvan\nvanish\nvapor\nvarious\nvast\nvault\nvehicle\nvelvet\nvendor\nventure\nvenue\nverb\nverify\nversion\nvery\nvessel\nveteran\nviable\nvibrant\nvicious\nvictory\nvideo\nview\nvillage\nvintage\nviolin\nvirtual\nvirus\nvisa\nvisit\nvisual\nvital\nvivid\nvocal\nvoice\nvoid\nvolcano\nvolume\nvote\nvoyage\nwage\nwagon\nwait\nwalk\nwall\nwalnut\nwant\nwarfare\nwarm\nwarrior\nwash\nwasp\nwaste\nwater\nwave\nway\nwealth\nweapon\nwear\nweasel\nweather\nweb\nwedding\nweekend\nweird\nwelcome\nwest\nwet\nwhale\nwhat\nwheat\nwheel\nwhen\nwhere\nwhip\nwhisper\nwide\nwidth\nwife\nwild\nwill\nwin\nwindow\nwine\nwing\nwink\nwinner\nwinter\nwire\nwisdom\nwise\nwish\nwitness\nwolf\nwoman\nwonder\nwood\nwool\nword\nwork\nworld\nworry\nworth\nwrap\nwreck\nwrestle\nwrist\nwrite\nwrong\nyard\nyear\nyellow\nyou\nyoung\nyouth\nzebra\nzero\nzone\nzoo`.split('\\n');\n","/**\n * This module provides utility functions for working with arrays in TypeScript.\n *\n * @since 2.0.0\n */\nimport * as E from \"./Either.js\";\nimport * as Equal from \"./Equal.js\";\nimport * as Equivalence from \"./Equivalence.js\";\nimport { dual, identity } from \"./Function.js\";\nimport * as readonlyArray from \"./internal/array.js\";\nimport * as doNotation from \"./internal/doNotation.js\";\nimport * as EffectIterable from \"./Iterable.js\";\nimport * as O from \"./Option.js\";\nimport * as Order from \"./Order.js\";\nimport { isBoolean } from \"./Predicate.js\";\nimport * as Record from \"./Record.js\";\nimport * as Tuple from \"./Tuple.js\";\n/**\n * Builds a `NonEmptyArray` from an non-empty collection of elements.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.make(1, 2, 3)\n * assert.deepStrictEqual(result, [1, 2, 3])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const make = (...elements) => elements;\n/**\n * Creates a new `Array` of the specified length.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.allocate<number>(3)\n * assert.deepStrictEqual(result.length, 3)\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const allocate = n => new Array(n);\n/**\n * Return a `NonEmptyArray` of length `n` with element `i` initialized with `f(i)`.\n *\n * **Note**. `n` is normalized to an integer >= 1.\n *\n * @example\n * import { makeBy } from \"effect/Array\"\n *\n * assert.deepStrictEqual(makeBy(5, n => n * 2), [0, 2, 4, 6, 8])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const makeBy = (n, f) => {\n  const max = Math.max(1, Math.floor(n));\n  const out = new Array(max);\n  for (let i = 0; i < max; i++) {\n    out[i] = f(i);\n  }\n  return out;\n};\n/**\n * Return a `NonEmptyArray` containing a range of integers, including both endpoints.\n *\n * @example\n * import { range } from \"effect/Array\"\n *\n * assert.deepStrictEqual(range(1, 3), [1, 2, 3])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const range = (start, end) => start <= end ? makeBy(end - start + 1, i => start + i) : [start];\n/**\n * Return a `NonEmptyArray` containing a value repeated the specified number of times.\n *\n * **Note**. `n` is normalized to an integer >= 1.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * assert.deepStrictEqual(Array.replicate(\"a\", 3), [\"a\", \"a\", \"a\"])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const replicate = /*#__PURE__*/dual(2, (a, n) => makeBy(n, () => a));\n/**\n * Creates a new `Array` from an iterable collection of values.\n * If the input is already an array, it returns the input as-is.\n * Otherwise, it converts the iterable collection to an array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const set = new Set([1, 2, 3])\n * const result = Array.fromIterable(set)\n * assert.deepStrictEqual(result, [1, 2, 3])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const fromIterable = collection => Array.isArray(collection) ? collection : Array.from(collection);\n/**\n * Creates a new `Array` from a value that might not be an iterable.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * assert.deepStrictEqual(Array.ensure(\"a\"), [\"a\"])\n * assert.deepStrictEqual(Array.ensure([\"a\"]), [\"a\"])\n * assert.deepStrictEqual(Array.ensure([\"a\", \"b\", \"c\"]), [\"a\", \"b\", \"c\"])\n *\n * @category constructors\n * @since 3.3.0\n */\nexport const ensure = self => Array.isArray(self) ? self : [self];\n/**\n * Takes a record and returns an array of tuples containing its keys and values.\n *\n * @param self - The record to transform.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const x = { a: 1, b: 2, c: 3 }\n * assert.deepStrictEqual(Array.fromRecord(x), [[\"a\", 1], [\"b\", 2], [\"c\", 3]])\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const fromRecord = Record.toEntries;\n/**\n * Converts an `Option` to an array.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * assert.deepStrictEqual(Array.fromOption(Option.some(1)), [1])\n * assert.deepStrictEqual(Array.fromOption(Option.none()), [])\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const fromOption = O.toArray;\n/**\n * Matches the elements of an array, applying functions to cases of empty and non-empty arrays.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const match = Array.match({\n *   onEmpty: () => \"empty\",\n *   onNonEmpty: ([head, ...tail]) => `head: ${head}, tail: ${tail.length}`\n * })\n * assert.deepStrictEqual(match([]), \"empty\")\n * assert.deepStrictEqual(match([1, 2, 3]), \"head: 1, tail: 2\")\n *\n * @category pattern matching\n * @since 2.0.0\n */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onEmpty,\n  onNonEmpty\n}) => isNonEmptyReadonlyArray(self) ? onNonEmpty(self) : onEmpty());\n/**\n * Matches the elements of an array from the left, applying functions to cases of empty and non-empty arrays.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const matchLeft = Array.matchLeft({\n *   onEmpty: () => \"empty\",\n *   onNonEmpty: (head, tail) => `head: ${head}, tail: ${tail.length}`\n * })\n * assert.deepStrictEqual(matchLeft([]), \"empty\")\n * assert.deepStrictEqual(matchLeft([1, 2, 3]), \"head: 1, tail: 2\")\n *\n * @category pattern matching\n * @since 2.0.0\n */\nexport const matchLeft = /*#__PURE__*/dual(2, (self, {\n  onEmpty,\n  onNonEmpty\n}) => isNonEmptyReadonlyArray(self) ? onNonEmpty(headNonEmpty(self), tailNonEmpty(self)) : onEmpty());\n/**\n * Matches the elements of an array from the right, applying functions to cases of empty and non-empty arrays.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const matchRight = Array.matchRight({\n *   onEmpty: () => \"empty\",\n *   onNonEmpty: (init, last) => `init: ${init.length}, last: ${last}`\n * })\n * assert.deepStrictEqual(matchRight([]), \"empty\")\n * assert.deepStrictEqual(matchRight([1, 2, 3]), \"init: 2, last: 3\")\n *\n * @category pattern matching\n * @since 2.0.0\n */\nexport const matchRight = /*#__PURE__*/dual(2, (self, {\n  onEmpty,\n  onNonEmpty\n}) => isNonEmptyReadonlyArray(self) ? onNonEmpty(initNonEmpty(self), lastNonEmpty(self)) : onEmpty());\n/**\n * Prepend an element to the front of an `Iterable`, creating a new `NonEmptyArray`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const original = [2, 3, 4];\n * const result = Array.prepend(original, 1);\n * assert.deepStrictEqual(result, [1, 2, 3, 4]);\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prepend = /*#__PURE__*/dual(2, (self, head) => [head, ...self]);\n/**\n * Prepends the specified prefix array (or iterable) to the beginning of the specified array (or iterable).\n * If either array is non-empty, the result is also a non-empty array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const prefix = [0, 1];\n * const array = [2, 3];\n * const result = Array.prependAll(array, prefix);\n * assert.deepStrictEqual(result, [0, 1, 2, 3]);\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prependAll = /*#__PURE__*/dual(2, (self, that) => fromIterable(that).concat(fromIterable(self)));\n/**\n * Append an element to the end of an `Iterable`, creating a new `NonEmptyArray`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const original = [1, 2, 3];\n * const result = Array.append(original, 4);\n * assert.deepStrictEqual(result, [1, 2, 3, 4]);\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const append = /*#__PURE__*/dual(2, (self, last) => [...self, last]);\n/**\n * Concatenates two arrays (or iterables), combining their elements.\n * If either array is non-empty, the result is also a non-empty array.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const appendAll = /*#__PURE__*/dual(2, (self, that) => fromIterable(self).concat(fromIterable(that)));\n/**\n * Accumulates values from an `Iterable` starting from the left, storing\n * each intermediate result in an array. Useful for tracking the progression of\n * a value through a series of transformations.\n *\n * @example\n * import { Array } from \"effect\";\n *\n * const numbers = [1, 2, 3, 4]\n * const result = Array.scan(numbers, 0, (acc, value) => acc + value)\n * assert.deepStrictEqual(result, [0, 1, 3, 6, 10])\n *\n * // Explanation:\n * // This function starts with the initial value (0 in this case)\n * // and adds each element of the array to this accumulator one by one,\n * // keeping track of the cumulative sum after each addition.\n * // Each of these sums is captured in the resulting array.\n *\n * @category folding\n * @since 2.0.0\n */\nexport const scan = /*#__PURE__*/dual(3, (self, b, f) => {\n  const out = [b];\n  let i = 0;\n  for (const a of self) {\n    out[i + 1] = f(out[i], a);\n    i++;\n  }\n  return out;\n});\n/**\n * Accumulates values from an `Iterable` starting from the right, storing\n * each intermediate result in an array. Useful for tracking the progression of\n * a value through a series of transformations.\n *\n * @example\n * import { Array } from \"effect\";\n *\n * const numbers = [1, 2, 3, 4]\n * const result = Array.scanRight(numbers, 0, (acc, value) => acc + value)\n * assert.deepStrictEqual(result, [10, 9, 7, 4, 0])\n *\n * @category folding\n * @since 2.0.0\n */\nexport const scanRight = /*#__PURE__*/dual(3, (self, b, f) => {\n  const input = fromIterable(self);\n  const out = new Array(input.length + 1);\n  out[input.length] = b;\n  for (let i = input.length - 1; i >= 0; i--) {\n    out[i] = f(out[i + 1], input[i]);\n  }\n  return out;\n});\n/**\n * Determine if `unknown` is an Array.\n *\n * @param self - The value to check.\n *\n * @example\n * import { isArray } from \"effect/Array\"\n *\n * assert.deepStrictEqual(isArray(null), false);\n * assert.deepStrictEqual(isArray([1, 2, 3]), true);\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isArray = Array.isArray;\n/**\n * Determine if an `Array` is empty narrowing down the type to `[]`.\n *\n * @param self - The `Array` to check.\n *\n * @example\n * import { isEmptyArray } from \"effect/Array\"\n *\n * assert.deepStrictEqual(isEmptyArray([]), true);\n * assert.deepStrictEqual(isEmptyArray([1, 2, 3]), false);\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isEmptyArray = self => self.length === 0;\n/**\n * Determine if a `ReadonlyArray` is empty narrowing down the type to `readonly []`.\n *\n * @param self - The `ReadonlyArray` to check.\n *\n * @example\n * import { isEmptyReadonlyArray } from \"effect/Array\"\n *\n * assert.deepStrictEqual(isEmptyReadonlyArray([]), true);\n * assert.deepStrictEqual(isEmptyReadonlyArray([1, 2, 3]), false);\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isEmptyReadonlyArray = isEmptyArray;\n/**\n * Determine if an `Array` is non empty narrowing down the type to `NonEmptyArray`.\n *\n * An `Array` is considered to be a `NonEmptyArray` if it contains at least one element.\n *\n * @param self - The `Array` to check.\n *\n * @example\n * import { isNonEmptyArray } from \"effect/Array\"\n *\n * assert.deepStrictEqual(isNonEmptyArray([]), false);\n * assert.deepStrictEqual(isNonEmptyArray([1, 2, 3]), true);\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNonEmptyArray = readonlyArray.isNonEmptyArray;\n/**\n * Determine if a `ReadonlyArray` is non empty narrowing down the type to `NonEmptyReadonlyArray`.\n *\n * A `ReadonlyArray` is considered to be a `NonEmptyReadonlyArray` if it contains at least one element.\n *\n * @param self - The `ReadonlyArray` to check.\n *\n * @example\n * import { isNonEmptyReadonlyArray } from \"effect/Array\"\n *\n * assert.deepStrictEqual(isNonEmptyReadonlyArray([]), false);\n * assert.deepStrictEqual(isNonEmptyReadonlyArray([1, 2, 3]), true);\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNonEmptyReadonlyArray = readonlyArray.isNonEmptyArray;\n/**\n * Return the number of elements in a `ReadonlyArray`.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const length = self => self.length;\nconst isOutOfBound = (i, as) => i < 0 || i >= as.length;\nconst clamp = (i, as) => Math.floor(Math.min(Math.max(0, i), as.length));\n/**\n * This function provides a safe way to read a value at a particular index from a `ReadonlyArray`.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const get = /*#__PURE__*/dual(2, (self, index) => {\n  const i = Math.floor(index);\n  return isOutOfBound(i, self) ? O.none() : O.some(self[i]);\n});\n/**\n * Gets an element unsafely, will throw on out of bounds.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeGet = /*#__PURE__*/dual(2, (self, index) => {\n  const i = Math.floor(index);\n  if (isOutOfBound(i, self)) {\n    throw new Error(`Index ${i} out of bounds`);\n  }\n  return self[i];\n});\n/**\n * Return a tuple containing the first element, and a new `Array` of the remaining elements, if any.\n *\n * @example\n * import { Array } from \"effect\";\n *\n * const result = Array.unprepend([1, 2, 3, 4])\n * assert.deepStrictEqual(result, [1, [2, 3, 4]])\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const unprepend = self => [headNonEmpty(self), tailNonEmpty(self)];\n/**\n * Return a tuple containing a copy of the `NonEmptyReadonlyArray` without its last element, and that last element.\n *\n * @example\n * import { Array } from \"effect\";\n *\n * const result = Array.unappend([1, 2, 3, 4])\n * assert.deepStrictEqual(result, [[1, 2, 3], 4])\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const unappend = self => [initNonEmpty(self), lastNonEmpty(self)];\n/**\n * Get the first element of a `ReadonlyArray`, or `None` if the `ReadonlyArray` is empty.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const head = /*#__PURE__*/get(0);\n/**\n * Get the first element of a non empty array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.headNonEmpty([1, 2, 3, 4])\n * assert.deepStrictEqual(result, 1)\n *\n * @category getters\n * @since 2.0.0\n */\nexport const headNonEmpty = /*#__PURE__*/unsafeGet(0);\n/**\n * Get the last element in a `ReadonlyArray`, or `None` if the `ReadonlyArray` is empty.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const last = self => isNonEmptyReadonlyArray(self) ? O.some(lastNonEmpty(self)) : O.none();\n/**\n * Get the last element of a non empty array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.lastNonEmpty([1, 2, 3, 4])\n * assert.deepStrictEqual(result, 4)\n *\n * @category getters\n * @since 2.0.0\n */\nexport const lastNonEmpty = self => self[self.length - 1];\n/**\n * Get all but the first element of an `Iterable`, creating a new `Array`, or `None` if the `Iterable` is empty.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const tail = self => {\n  const input = fromIterable(self);\n  return isNonEmptyReadonlyArray(input) ? O.some(tailNonEmpty(input)) : O.none();\n};\n/**\n * Get all but the first element of a `NonEmptyReadonlyArray`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.tailNonEmpty([1, 2, 3, 4])\n * assert.deepStrictEqual(result, [2, 3, 4])\n *\n * @category getters\n * @since 2.0.0\n */\nexport const tailNonEmpty = self => self.slice(1);\n/**\n * Get all but the last element of an `Iterable`, creating a new `Array`, or `None` if the `Iterable` is empty.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const init = self => {\n  const input = fromIterable(self);\n  return isNonEmptyReadonlyArray(input) ? O.some(initNonEmpty(input)) : O.none();\n};\n/**\n * Get all but the last element of a non empty array, creating a new array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.initNonEmpty([1, 2, 3, 4])\n * assert.deepStrictEqual(result, [1, 2, 3])\n *\n * @category getters\n * @since 2.0.0\n */\nexport const initNonEmpty = self => self.slice(0, -1);\n/**\n * Keep only a max number of elements from the start of an `Iterable`, creating a new `Array`.\n *\n * **Note**. `n` is normalized to a non negative integer.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.take(numbers, 3)\n * assert.deepStrictEqual(result, [1, 2, 3])\n *\n * @category getters\n * @since 2.0.0\n */\nexport const take = /*#__PURE__*/dual(2, (self, n) => {\n  const input = fromIterable(self);\n  return input.slice(0, clamp(n, input));\n});\n/**\n * Keep only a max number of elements from the end of an `Iterable`, creating a new `Array`.\n *\n * **Note**. `n` is normalized to a non negative integer.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.takeRight(numbers, 3)\n * assert.deepStrictEqual(result, [3, 4, 5])\n *\n * @category getters\n * @since 2.0.0\n */\nexport const takeRight = /*#__PURE__*/dual(2, (self, n) => {\n  const input = fromIterable(self);\n  const i = clamp(n, input);\n  return i === 0 ? [] : input.slice(-i);\n});\n/**\n * Calculate the longest initial subarray for which all element satisfy the specified predicate, creating a new `Array`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 3, 2, 4, 1, 2]\n * const result = Array.takeWhile(numbers, x => x < 4)\n * assert.deepStrictEqual(result, [1, 3, 2])\n *\n * // Explanation:\n * // - The function starts with the first element (`1`), which is less than `4`, so it adds `1` to the result.\n * // - The next element (`3`) is also less than `4`, so it adds `3`.\n * // - The next element (`2`) is again less than `4`, so it adds `2`.\n * // - The function then encounters `4`, which is not less than `4`. At this point, it stops checking further elements and finalizes the result.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const takeWhile = /*#__PURE__*/dual(2, (self, predicate) => {\n  let i = 0;\n  const out = [];\n  for (const a of self) {\n    if (!predicate(a, i)) {\n      break;\n    }\n    out.push(a);\n    i++;\n  }\n  return out;\n});\nconst spanIndex = (self, predicate) => {\n  let i = 0;\n  for (const a of self) {\n    if (!predicate(a, i)) {\n      break;\n    }\n    i++;\n  }\n  return i;\n};\n/**\n * Split an `Iterable` into two parts:\n *\n * 1. the longest initial subarray for which all elements satisfy the specified predicate\n * 2. the remaining elements\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const span = /*#__PURE__*/dual(2, (self, predicate) => splitAt(self, spanIndex(self, predicate)));\n/**\n * Drop a max number of elements from the start of an `Iterable`, creating a new `Array`.\n *\n * **Note**. `n` is normalized to a non negative integer.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.drop(numbers, 2)\n * assert.deepStrictEqual(result, [3, 4, 5])\n *\n * @category getters\n * @since 2.0.0\n */\nexport const drop = /*#__PURE__*/dual(2, (self, n) => {\n  const input = fromIterable(self);\n  return input.slice(clamp(n, input), input.length);\n});\n/**\n * Drop a max number of elements from the end of an `Iterable`, creating a new `Array`.\n *\n * **Note**. `n` is normalized to a non negative integer.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.dropRight(numbers, 2)\n * assert.deepStrictEqual(result, [1, 2, 3])\n *\n * @category getters\n * @since 2.0.0\n */\nexport const dropRight = /*#__PURE__*/dual(2, (self, n) => {\n  const input = fromIterable(self);\n  return input.slice(0, input.length - clamp(n, input));\n});\n/**\n * Remove the longest initial subarray for which all element satisfy the specified predicate, creating a new `Array`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.dropWhile(numbers, x => x < 4)\n * assert.deepStrictEqual(result, [4, 5])\n *\n * @category getters\n * @since 2.0.0\n */\nexport const dropWhile = /*#__PURE__*/dual(2, (self, predicate) => fromIterable(self).slice(spanIndex(self, predicate)));\n/**\n * Return the first index for which a predicate holds.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * const numbers = [5, 3, 8, 9]\n * const result = Array.findFirstIndex(numbers, x => x > 5)\n * assert.deepStrictEqual(result, Option.some(2))\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findFirstIndex = /*#__PURE__*/dual(2, (self, predicate) => {\n  let i = 0;\n  for (const a of self) {\n    if (predicate(a, i)) {\n      return O.some(i);\n    }\n    i++;\n  }\n  return O.none();\n});\n/**\n * Return the last index for which a predicate holds.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * const numbers = [1, 3, 8, 9]\n * const result = Array.findLastIndex(numbers, x => x < 5)\n * assert.deepStrictEqual(result, Option.some(1))\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findLastIndex = /*#__PURE__*/dual(2, (self, predicate) => {\n  const input = fromIterable(self);\n  for (let i = input.length - 1; i >= 0; i--) {\n    if (predicate(input[i], i)) {\n      return O.some(i);\n    }\n  }\n  return O.none();\n});\n/**\n * Returns the first element that satisfies the specified\n * predicate, or `None` if no such element exists.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.findFirst(numbers, x => x > 3)\n * assert.deepStrictEqual(result, Option.some(4))\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findFirst = EffectIterable.findFirst;\n/**\n * Finds the last element in an iterable collection that satisfies the given predicate or refinement.\n * Returns an `Option` containing the found element, or `Option.none` if no element matches.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.findLast(numbers, n => n % 2 === 0)\n * assert.deepStrictEqual(result, Option.some(4))\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findLast = /*#__PURE__*/dual(2, (self, f) => {\n  const input = fromIterable(self);\n  for (let i = input.length - 1; i >= 0; i--) {\n    const a = input[i];\n    const o = f(a, i);\n    if (isBoolean(o)) {\n      if (o) {\n        return O.some(a);\n      }\n    } else {\n      if (O.isSome(o)) {\n        return o;\n      }\n    }\n  }\n  return O.none();\n});\n/**\n * Insert an element at the specified index, creating a new `NonEmptyArray`,\n * or return `None` if the index is out of bounds.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * const letters = ['a', 'b', 'c', 'e']\n * const result = Array.insertAt(letters, 3, 'd')\n * assert.deepStrictEqual(result, Option.some(['a', 'b', 'c', 'd', 'e']))\n *\n * @since 2.0.0\n */\nexport const insertAt = /*#__PURE__*/dual(3, (self, i, b) => {\n  const out = Array.from(self);\n  //             v--- `= self.length` is ok, it means inserting in last position\n  if (i < 0 || i > out.length) {\n    return O.none();\n  }\n  out.splice(i, 0, b);\n  return O.some(out);\n});\n/**\n * Change the element at the specified index, creating a new `Array`,\n * or return a copy of the input if the index is out of bounds.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const letters = ['a', 'b', 'c', 'd']\n * const result = Array.replace(1, 'z')(letters)\n * assert.deepStrictEqual(result, ['a', 'z', 'c', 'd'])\n *\n * @since 2.0.0\n */\nexport const replace = /*#__PURE__*/dual(3, (self, i, b) => modify(self, i, () => b));\n/**\n * Replaces an element in an array with the given value, returning an option of the updated array.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * const result = Array.replaceOption(numbers, 1, 4)\n * assert.deepStrictEqual(result, Option.some([1, 4, 3]))\n *\n * @since 2.0.0\n */\nexport const replaceOption = /*#__PURE__*/dual(3, (self, i, b) => modifyOption(self, i, () => b));\n/**\n * Apply a function to the element at the specified index, creating a new `Array`,\n * or return a copy of the input if the index is out of bounds.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4]\n * const result = Array.modify(numbers, 2, (n) => n * 2)\n * assert.deepStrictEqual(result, [1, 2, 6, 4])\n *\n * @since 2.0.0\n */\nexport const modify = /*#__PURE__*/dual(3, (self, i, f) => O.getOrElse(modifyOption(self, i, f), () => Array.from(self)));\n/**\n * Apply a function to the element at the specified index, creating a new `Array`,\n * or return `None` if the index is out of bounds.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4]\n * const result = Array.modifyOption(numbers, 2, (n) => n * 2)\n * assert.deepStrictEqual(result, Option.some([1, 2, 6, 4]))\n *\n * const outOfBoundsResult = Array.modifyOption(numbers, 5, (n) => n * 2)\n * assert.deepStrictEqual(outOfBoundsResult, Option.none())\n *\n * @since 2.0.0\n */\nexport const modifyOption = /*#__PURE__*/dual(3, (self, i, f) => {\n  const out = Array.from(self);\n  if (isOutOfBound(i, out)) {\n    return O.none();\n  }\n  const next = f(out[i]);\n  // @ts-expect-error\n  out[i] = next;\n  return O.some(out);\n});\n/**\n * Delete the element at the specified index, creating a new `Array`,\n * or return a copy of the input if the index is out of bounds.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4]\n * const result = Array.remove(numbers, 2)\n * assert.deepStrictEqual(result, [1, 2, 4])\n *\n * const outOfBoundsResult = Array.remove(numbers, 5)\n * assert.deepStrictEqual(outOfBoundsResult, [1, 2, 3, 4])\n *\n * @since 2.0.0\n */\nexport const remove = /*#__PURE__*/dual(2, (self, i) => {\n  const out = Array.from(self);\n  if (isOutOfBound(i, out)) {\n    return out;\n  }\n  out.splice(i, 1);\n  return out;\n});\n/**\n * Reverse an `Iterable`, creating a new `Array`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4]\n * const result = Array.reverse(numbers)\n * assert.deepStrictEqual(result, [4, 3, 2, 1])\n *\n * @category elements\n * @since 2.0.0\n */\nexport const reverse = self => Array.from(self).reverse();\n/**\n * Create a new array with elements sorted in increasing order based on the specified comparator.\n * If the input is a `NonEmptyReadonlyArray`, the output will also be a `NonEmptyReadonlyArray`.\n *\n * @category sorting\n * @since 2.0.0\n */\nexport const sort = /*#__PURE__*/dual(2, (self, O) => {\n  const out = Array.from(self);\n  out.sort(O);\n  return out;\n});\n/**\n * Sorts an array based on a provided mapping function and order. The mapping\n * function transforms the elements into a value that can be compared, and the\n * order defines how those values should be sorted.\n *\n * @example\n * import { Array, Order } from \"effect\"\n *\n * const strings = [\"aaa\", \"b\", \"cc\"]\n * const result = Array.sortWith(strings, (s) => s.length, Order.number)\n * assert.deepStrictEqual(result, [\"b\", \"cc\", \"aaa\"])\n *\n * // Explanation:\n * // The array of strings is sorted based on their lengths. The mapping function `(s) => s.length`\n * // converts each string into its length, and the `Order.number` specifies that the lengths should\n * // be sorted in ascending order.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const sortWith = /*#__PURE__*/dual(3, (self, f, order) => sort(self, Order.mapInput(order, f)));\n/**\n * Sorts the elements of an `Iterable` in increasing order based on the provided\n * orders. The elements are compared using the first order in `orders`, then the\n * second order if the first comparison is equal, and so on.\n *\n * @example\n * import { Array, Order } from \"effect\"\n *\n * const users = [\n *   { name: \"Alice\", age: 30 },\n *   { name: \"Bob\", age: 25 },\n *   { name: \"Charlie\", age: 30 }\n * ]\n *\n * const result = Array.sortBy(\n *   Order.mapInput(Order.number, (user: (typeof users)[number]) => user.age),\n *   Order.mapInput(Order.string, (user: (typeof users)[number]) => user.name)\n * )(users)\n *\n * assert.deepStrictEqual(result, [\n *   { name: \"Bob\", age: 25 },\n *   { name: \"Alice\", age: 30 },\n *   { name: \"Charlie\", age: 30 }\n * ])\n *\n * // Explanation:\n * // The array of users is sorted first by age in ascending order. When ages are equal,\n * // the users are further sorted by name in ascending order.\n *\n * @category sorting\n * @since 2.0.0\n */\nexport const sortBy = (...orders) => {\n  const sortByAll = sort(Order.combineAll(orders));\n  return self => {\n    const input = fromIterable(self);\n    if (isNonEmptyReadonlyArray(input)) {\n      return sortByAll(input);\n    }\n    return [];\n  };\n};\n/**\n * Takes two `Iterable`s and returns an `Array` of corresponding pairs.\n * If one input `Iterable` is short, excess elements of the\n * longer `Iterable` are discarded.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2, 3]\n * const array2 = ['a', 'b']\n * const result = Array.zip(array1, array2)\n * assert.deepStrictEqual(result, [[1, 'a'], [2, 'b']])\n *\n * @category zipping\n * @since 2.0.0\n */\nexport const zip = /*#__PURE__*/dual(2, (self, that) => zipWith(self, that, Tuple.make));\n/**\n * Apply a function to pairs of elements at the same index in two `Iterable`s, collecting the results in a new `Array`. If one\n * input `Iterable` is short, excess elements of the longer `Iterable` are discarded.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2, 3]\n * const array2 = [4, 5, 6]\n * const result = Array.zipWith(array1, array2, (a, b) => a + b)\n * assert.deepStrictEqual(result, [5, 7, 9])\n *\n * @category zipping\n * @since 2.0.0\n */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => {\n  const as = fromIterable(self);\n  const bs = fromIterable(that);\n  if (isNonEmptyReadonlyArray(as) && isNonEmptyReadonlyArray(bs)) {\n    const out = [f(headNonEmpty(as), headNonEmpty(bs))];\n    const len = Math.min(as.length, bs.length);\n    for (let i = 1; i < len; i++) {\n      out[i] = f(as[i], bs[i]);\n    }\n    return out;\n  }\n  return [];\n});\n/**\n * This function is the inverse of `zip`. Takes an `Iterable` of pairs and return two corresponding `Array`s.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.unzip([[1, \"a\"], [2, \"b\"], [3, \"c\"]])\n * assert.deepStrictEqual(result, [[1, 2, 3], ['a', 'b', 'c']])\n *\n * @since 2.0.0\n */\nexport const unzip = self => {\n  const input = fromIterable(self);\n  if (isNonEmptyReadonlyArray(input)) {\n    const fa = [input[0][0]];\n    const fb = [input[0][1]];\n    for (let i = 1; i < input.length; i++) {\n      fa[i] = input[i][0];\n      fb[i] = input[i][1];\n    }\n    return [fa, fb];\n  }\n  return [[], []];\n};\n/**\n * Places an element in between members of an `Iterable`.\n * If the input is a non-empty array, the result is also a non-empty array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * const result = Array.intersperse(numbers, 0)\n * assert.deepStrictEqual(result, [1, 0, 2, 0, 3])\n *\n * @since 2.0.0\n */\nexport const intersperse = /*#__PURE__*/dual(2, (self, middle) => {\n  const input = fromIterable(self);\n  if (isNonEmptyReadonlyArray(input)) {\n    const out = [headNonEmpty(input)];\n    const tail = tailNonEmpty(input);\n    for (let i = 0; i < tail.length; i++) {\n      if (i < tail.length) {\n        out.push(middle);\n      }\n      out.push(tail[i]);\n    }\n    return out;\n  }\n  return [];\n});\n/**\n * Apply a function to the head, creating a new `NonEmptyReadonlyArray`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.modifyNonEmptyHead([1, 2, 3], n => n * 10)\n * assert.deepStrictEqual(result, [10, 2, 3])\n *\n * @since 2.0.0\n */\nexport const modifyNonEmptyHead = /*#__PURE__*/dual(2, (self, f) => [f(headNonEmpty(self)), ...tailNonEmpty(self)]);\n/**\n * Change the head, creating a new `NonEmptyReadonlyArray`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.setNonEmptyHead([1, 2, 3], 10)\n * assert.deepStrictEqual(result, [10, 2, 3])\n *\n * @since 2.0.0\n */\nexport const setNonEmptyHead = /*#__PURE__*/dual(2, (self, b) => modifyNonEmptyHead(self, () => b));\n/**\n * Apply a function to the last element, creating a new `NonEmptyReadonlyArray`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.modifyNonEmptyLast([1, 2, 3], n => n * 2)\n * assert.deepStrictEqual(result, [1, 2, 6])\n *\n * @since 2.0.0\n */\nexport const modifyNonEmptyLast = /*#__PURE__*/dual(2, (self, f) => append(initNonEmpty(self), f(lastNonEmpty(self))));\n/**\n * Change the last element, creating a new `NonEmptyReadonlyArray`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.setNonEmptyLast([1, 2, 3], 4)\n * assert.deepStrictEqual(result, [1, 2, 4])\n *\n * @since 2.0.0\n */\nexport const setNonEmptyLast = /*#__PURE__*/dual(2, (self, b) => modifyNonEmptyLast(self, () => b));\n/**\n * Rotate an `Iterable` by `n` steps.\n * If the input is a non-empty array, the result is also a non-empty array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const letters = ['a', 'b', 'c', 'd']\n * const result = Array.rotate(letters, 2)\n * assert.deepStrictEqual(result, ['c', 'd', 'a', 'b'])\n *\n * @since 2.0.0\n */\nexport const rotate = /*#__PURE__*/dual(2, (self, n) => {\n  const input = fromIterable(self);\n  if (isNonEmptyReadonlyArray(input)) {\n    const len = input.length;\n    const m = Math.round(n) % len;\n    if (isOutOfBound(Math.abs(m), input) || m === 0) {\n      return copy(input);\n    }\n    if (m < 0) {\n      const [f, s] = splitNonEmptyAt(input, -m);\n      return appendAll(s, f);\n    } else {\n      return rotate(self, m - len);\n    }\n  }\n  return [];\n});\n/**\n * Returns a function that checks if a `ReadonlyArray` contains a given value using a provided `isEquivalent` function.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4]\n * const isEquivalent = (a: number, b: number) => a === b\n * const containsNumber = Array.containsWith(isEquivalent)\n * const result = containsNumber(3)(numbers)\n * assert.deepStrictEqual(result, true)\n *\n * @category elements\n * @since 2.0.0\n */\nexport const containsWith = isEquivalent => dual(2, (self, a) => {\n  for (const i of self) {\n    if (isEquivalent(a, i)) {\n      return true;\n    }\n  }\n  return false;\n});\nconst _equivalence = /*#__PURE__*/Equal.equivalence();\n/**\n * Returns a function that checks if a `ReadonlyArray` contains a given value using the default `Equivalence`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const letters = ['a', 'b', 'c', 'd']\n * const result = Array.contains('c')(letters)\n * assert.deepStrictEqual(result, true)\n *\n * @category elements\n * @since 2.0.0\n */\nexport const contains = /*#__PURE__*/containsWith(_equivalence);\n/**\n * A useful recursion pattern for processing an `Iterable` to produce a new `Array`, often used for \"chopping\" up the input\n * `Iterable`. Typically chop is called with some function that will consume an initial prefix of the `Iterable` and produce a\n * value and the rest of the `Array`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.chop(numbers, (as): [number, Array<number>] => [as[0] * 2, as.slice(1)])\n * assert.deepStrictEqual(result, [2, 4, 6, 8, 10])\n *\n * // Explanation:\n * // The `chopFunction` takes the first element of the array, doubles it, and then returns it along with the rest of the array.\n * // The `chop` function applies this `chopFunction` recursively to the input array `[1, 2, 3, 4, 5]`,\n * // resulting in a new array `[2, 4, 6, 8, 10]`.\n *\n * @since 2.0.0\n */\nexport const chop = /*#__PURE__*/dual(2, (self, f) => {\n  const input = fromIterable(self);\n  if (isNonEmptyReadonlyArray(input)) {\n    const [b, rest] = f(input);\n    const out = [b];\n    let next = rest;\n    while (readonlyArray.isNonEmptyArray(next)) {\n      const [b, rest] = f(next);\n      out.push(b);\n      next = rest;\n    }\n    return out;\n  }\n  return [];\n});\n/**\n * Splits an `Iterable` into two segments, with the first segment containing a maximum of `n` elements.\n * The value of `n` can be `0`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.splitAt(numbers, 3)\n * assert.deepStrictEqual(result, [[1, 2, 3], [4, 5]])\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const splitAt = /*#__PURE__*/dual(2, (self, n) => {\n  const input = Array.from(self);\n  const _n = Math.floor(n);\n  if (isNonEmptyReadonlyArray(input)) {\n    if (_n >= 1) {\n      return splitNonEmptyAt(input, _n);\n    }\n    return [[], input];\n  }\n  return [input, []];\n});\n/**\n * Splits a `NonEmptyReadonlyArray` into two segments, with the first segment containing a maximum of `n` elements.\n * The value of `n` must be `>= 1`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.splitNonEmptyAt([\"a\", \"b\", \"c\", \"d\", \"e\"], 3)\n * assert.deepStrictEqual(result, [[\"a\", \"b\", \"c\"], [\"d\", \"e\"]])\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const splitNonEmptyAt = /*#__PURE__*/dual(2, (self, n) => {\n  const _n = Math.max(1, Math.floor(n));\n  return _n >= self.length ? [copy(self), []] : [prepend(self.slice(1, _n), headNonEmpty(self)), self.slice(_n)];\n});\n/**\n * Splits this iterable into `n` equally sized arrays.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5, 6, 7, 8]\n * const result = Array.split(numbers, 3)\n * assert.deepStrictEqual(result, [[1, 2, 3], [4, 5, 6], [7, 8]])\n *\n * @since 2.0.0\n * @category splitting\n */\nexport const split = /*#__PURE__*/dual(2, (self, n) => {\n  const input = fromIterable(self);\n  return chunksOf(input, Math.ceil(input.length / Math.floor(n)));\n});\n/**\n * Splits this iterable on the first element that matches this predicate.\n * Returns a tuple containing two arrays: the first one is before the match, and the second one is from the match onward.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.splitWhere(numbers, n => n > 3)\n * assert.deepStrictEqual(result, [[1, 2, 3], [4, 5]])\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const splitWhere = /*#__PURE__*/dual(2, (self, predicate) => span(self, (a, i) => !predicate(a, i)));\n/**\n * Copies an array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * const copy = Array.copy(numbers)\n * assert.deepStrictEqual(copy, [1, 2, 3])\n *\n * @since 2.0.0\n */\nexport const copy = self => self.slice();\n/**\n * Splits an `Iterable` into length-`n` pieces. The last piece will be shorter if `n` does not evenly divide the length of\n * the `Iterable`. Note that `chunksOf(n)([])` is `[]`, not `[[]]`. This is intentional, and is consistent with a recursive\n * definition of `chunksOf`; it satisfies the property that\n *\n * ```ts\n * chunksOf(n)(xs).concat(chunksOf(n)(ys)) == chunksOf(n)(xs.concat(ys)))\n * ```\n *\n * whenever `n` evenly divides the length of `self`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4, 5]\n * const result = Array.chunksOf(numbers, 2)\n * assert.deepStrictEqual(result, [[1, 2], [3, 4], [5]])\n *\n * // Explanation:\n * // The `chunksOf` function takes an array of numbers `[1, 2, 3, 4, 5]` and a number `2`.\n * // It splits the array into chunks of length 2. Since the array length is not evenly divisible by 2,\n * // the last chunk contains the remaining elements.\n * // The result is `[[1, 2], [3, 4], [5]]`.\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const chunksOf = /*#__PURE__*/dual(2, (self, n) => {\n  const input = fromIterable(self);\n  if (isNonEmptyReadonlyArray(input)) {\n    return chop(input, splitNonEmptyAt(n));\n  }\n  return [];\n});\n/**\n * Group equal, consecutive elements of a `NonEmptyReadonlyArray` into `NonEmptyArray`s using the provided `isEquivalent` function.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.groupWith([\"a\", \"a\", \"b\", \"b\", \"b\", \"c\", \"a\"], (x, y) => x === y)\n * assert.deepStrictEqual(result, [[\"a\", \"a\"], [\"b\", \"b\", \"b\"], [\"c\"], [\"a\"]])\n *\n * @category grouping\n * @since 2.0.0\n */\nexport const groupWith = /*#__PURE__*/dual(2, (self, isEquivalent) => chop(self, as => {\n  const h = headNonEmpty(as);\n  const out = [h];\n  let i = 1;\n  for (; i < as.length; i++) {\n    const a = as[i];\n    if (isEquivalent(a, h)) {\n      out.push(a);\n    } else {\n      break;\n    }\n  }\n  return [out, as.slice(i)];\n}));\n/**\n * Group equal, consecutive elements of a `NonEmptyReadonlyArray` into `NonEmptyArray`s.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const result = Array.group([1, 1, 2, 2, 2, 3, 1])\n * assert.deepStrictEqual(result, [[1, 1], [2, 2, 2], [3], [1]])\n *\n * @category grouping\n * @since 2.0.0\n */\nexport const group = /*#__PURE__*/groupWith( /*#__PURE__*/Equal.equivalence());\n/**\n * Splits an `Iterable` into sub-non-empty-arrays stored in an object, based on the result of calling a `string`-returning\n * function on each element, and grouping the results according to values returned\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const people = [\n *   { name: \"Alice\", group: \"A\" },\n *   { name: \"Bob\", group: \"B\" },\n *   { name: \"Charlie\", group: \"A\" }\n * ]\n * const result = Array.groupBy(people, person => person.group)\n * assert.deepStrictEqual(result, {\n *   A: [{ name: \"Alice\", group: \"A\" }, { name: \"Charlie\", group: \"A\" }],\n *   B: [{ name: \"Bob\", group: \"B\" }]\n * })\n *\n * @category grouping\n * @since 2.0.0\n */\nexport const groupBy = /*#__PURE__*/dual(2, (self, f) => {\n  const out = {};\n  for (const a of self) {\n    const k = f(a);\n    if (Object.prototype.hasOwnProperty.call(out, k)) {\n      out[k].push(a);\n    } else {\n      out[k] = [a];\n    }\n  }\n  return out;\n});\n/**\n * Calculates the union of two arrays using the provided equivalence relation.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2]\n * const array2 = [2, 3]\n * const union = Array.unionWith(array1, array2, (a, b) => a === b)\n * assert.deepStrictEqual(union, [1, 2, 3])\n *\n * @since 2.0.0\n */\nexport const unionWith = /*#__PURE__*/dual(3, (self, that, isEquivalent) => {\n  const a = fromIterable(self);\n  const b = fromIterable(that);\n  if (isNonEmptyReadonlyArray(a)) {\n    if (isNonEmptyReadonlyArray(b)) {\n      const dedupe = dedupeWith(isEquivalent);\n      return dedupe(appendAll(a, b));\n    }\n    return a;\n  }\n  return b;\n});\n/**\n * Creates a union of two arrays, removing duplicates.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2]\n * const array2 = [2, 3]\n * const result = Array.union(array1, array2)\n * assert.deepStrictEqual(result, [1, 2, 3])\n *\n * @since 2.0.0\n */\nexport const union = /*#__PURE__*/dual(2, (self, that) => unionWith(self, that, _equivalence));\n/**\n * Creates an `Array` of unique values that are included in all given `Iterable`s using the provided `isEquivalent` function.\n * The order and references of result values are determined by the first `Iterable`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [{ id: 1 }, { id: 2 }, { id: 3 }]\n * const array2 = [{ id: 3 }, { id: 4 }, { id: 1 }]\n * const isEquivalent = (a: { id: number }, b: { id: number }) => a.id === b.id\n * const result = Array.intersectionWith(isEquivalent)(array2)(array1)\n * assert.deepStrictEqual(result, [{ id: 1 }, { id: 3 }])\n *\n * @since 2.0.0\n */\nexport const intersectionWith = isEquivalent => {\n  const has = containsWith(isEquivalent);\n  return dual(2, (self, that) => fromIterable(self).filter(a => has(that, a)));\n};\n/**\n * Creates an `Array` of unique values that are included in all given `Iterable`s.\n * The order and references of result values are determined by the first `Iterable`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2, 3]\n * const array2 = [3, 4, 1]\n * const result = Array.intersection(array1, array2)\n * assert.deepStrictEqual(result, [1, 3])\n *\n * @since 2.0.0\n */\nexport const intersection = /*#__PURE__*/intersectionWith(_equivalence);\n/**\n * Creates a `Array` of values not included in the other given `Iterable` using the provided `isEquivalent` function.\n * The order and references of result values are determined by the first `Iterable`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2, 3]\n * const array2 = [2, 3, 4]\n * const difference = Array.differenceWith<number>((a, b) => a === b)(array1, array2)\n * assert.deepStrictEqual(difference, [1])\n *\n * @since 2.0.0\n */\nexport const differenceWith = isEquivalent => {\n  const has = containsWith(isEquivalent);\n  return dual(2, (self, that) => fromIterable(self).filter(a => !has(that, a)));\n};\n/**\n * Creates a `Array` of values not included in the other given `Iterable`.\n * The order and references of result values are determined by the first `Iterable`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2, 3]\n * const array2 = [2, 3, 4]\n * const difference = Array.difference(array1, array2)\n * assert.deepStrictEqual(difference, [1])\n *\n * @since 2.0.0\n */\nexport const difference = /*#__PURE__*/differenceWith(_equivalence);\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const empty = () => [];\n/**\n * Constructs a new `NonEmptyArray<A>` from the specified value.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const of = a => [a];\n/**\n * @category mapping\n * @since 2.0.0\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => self.map(f));\n/**\n * Applies a function to each element in an array and returns a new array containing the concatenated mapped elements.\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => {\n  if (isEmptyReadonlyArray(self)) {\n    return [];\n  }\n  const out = [];\n  for (let i = 0; i < self.length; i++) {\n    const inner = f(self[i], i);\n    for (let j = 0; j < inner.length; j++) {\n      out.push(inner[j]);\n    }\n  }\n  return out;\n});\n/**\n * Combines multiple arrays into a single array by concatenating all elements\n * from each nested array. This function ensures that the structure of nested\n * arrays is collapsed into a single, flat array.\n *\n * @example\n * import { Array } from \"effect\";\n *\n * const nestedArrays = [[1, 2], [], [3, 4], [], [5, 6]]\n * const result = Array.flatten(nestedArrays)\n *\n * assert.deepStrictEqual(result, [1, 2, 3, 4, 5, 6]);\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatten = /*#__PURE__*/flatMap(identity);\n/**\n * Applies a function to each element of the `Iterable` and filters based on the result, keeping the transformed values where the function returns `Some`.\n * This method combines filtering and mapping functionalities, allowing transformations and filtering of elements based on a single function pass.\n *\n * @example\n * import { Array, Option } from \"effect\";\n *\n * const data = [1, 2, 3, 4, 5];\n * const evenSquares = (x: number) => x % 2 === 0 ? Option.some(x * x) : Option.none();\n * const result = Array.filterMap(data, evenSquares);\n *\n * assert.deepStrictEqual(result, [4, 16]);\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const filterMap = /*#__PURE__*/dual(2, (self, f) => {\n  const as = fromIterable(self);\n  const out = [];\n  for (let i = 0; i < as.length; i++) {\n    const o = f(as[i], i);\n    if (O.isSome(o)) {\n      out.push(o.value);\n    }\n  }\n  return out;\n});\n/**\n * Applies a function to each element of the array and filters based on the result, stopping when a condition is not met.\n * This method combines filtering and mapping in a single pass, and short-circuits, i.e., stops processing, as soon as the function returns `None`.\n * This is useful when you need to transform an array but only up to the point where a certain condition holds true.\n *\n * @example\n * import { Array, Option } from \"effect\";\n *\n * const data = [2, 4, 5];\n * const toSquareTillOdd = (x: number) => x % 2 === 0 ? Option.some(x * x) : Option.none();\n * const result = Array.filterMapWhile(data, toSquareTillOdd);\n *\n * assert.deepStrictEqual(result, [4, 16]);\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const filterMapWhile = /*#__PURE__*/dual(2, (self, f) => {\n  let i = 0;\n  const out = [];\n  for (const a of self) {\n    const b = f(a, i);\n    if (O.isSome(b)) {\n      out.push(b.value);\n    } else {\n      break;\n    }\n    i++;\n  }\n  return out;\n});\n/**\n * Applies a function to each element of the `Iterable`, categorizing the results into two separate arrays.\n * This function is particularly useful for operations where each element can result in two possible types,\n * and you want to separate these types into different collections. For instance, separating validation results\n * into successes and failures.\n *\n * @example\n * import { Array, Either } from \"effect\";\n *\n * const data = [1, 2, 3, 4, 5]\n * const isEven = (x: number) => x % 2 === 0\n * const partitioned = Array.partitionMap(data, x =>\n *   isEven(x) ? Either.right(x) : Either.left(x)\n * )\n *\n * assert.deepStrictEqual(partitioned, [\n *   [1, 3, 5],\n *   [2, 4]\n * ])\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const partitionMap = /*#__PURE__*/dual(2, (self, f) => {\n  const left = [];\n  const right = [];\n  const as = fromIterable(self);\n  for (let i = 0; i < as.length; i++) {\n    const e = f(as[i], i);\n    if (E.isLeft(e)) {\n      left.push(e.left);\n    } else {\n      right.push(e.right);\n    }\n  }\n  return [left, right];\n});\n/**\n * Retrieves the `Some` values from an `Iterable` of `Option`s, collecting them into an array.\n *\n * @example\n * import { Array, Option } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Array.getSomes([Option.some(1), Option.none(), Option.some(2)]),\n *   [1, 2]\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getSomes = /*#__PURE__*/filterMap(identity);\n/**\n * Retrieves the `Left` values from an `Iterable` of `Either`s, collecting them into an array.\n *\n * @example\n * import { Array, Either } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Array.getLefts([Either.right(1), Either.left(\"err\"), Either.right(2)]),\n *   [\"err\"]\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getLefts = self => {\n  const out = [];\n  for (const a of self) {\n    if (E.isLeft(a)) {\n      out.push(a.left);\n    }\n  }\n  return out;\n};\n/**\n * Retrieves the `Right` values from an `Iterable` of `Either`s, collecting them into an array.\n *\n * @example\n * import { Array, Either } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Array.getRights([Either.right(1), Either.left(\"err\"), Either.right(2)]),\n *   [1, 2]\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getRights = self => {\n  const out = [];\n  for (const a of self) {\n    if (E.isRight(a)) {\n      out.push(a.right);\n    }\n  }\n  return out;\n};\n/**\n * @category filtering\n * @since 2.0.0\n */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => {\n  const as = fromIterable(self);\n  const out = [];\n  for (let i = 0; i < as.length; i++) {\n    if (predicate(as[i], i)) {\n      out.push(as[i]);\n    }\n  }\n  return out;\n});\n/**\n * Separate elements based on a predicate that also exposes the index of the element.\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const partition = /*#__PURE__*/dual(2, (self, predicate) => {\n  const left = [];\n  const right = [];\n  const as = fromIterable(self);\n  for (let i = 0; i < as.length; i++) {\n    if (predicate(as[i], i)) {\n      right.push(as[i]);\n    } else {\n      left.push(as[i]);\n    }\n  }\n  return [left, right];\n});\n/**\n * Separates an `Iterable` into two arrays based on a predicate.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3, 4]\n * const result = Array.partition(numbers, n => n % 2 === 0)\n * assert.deepStrictEqual(result, [[1, 3], [2, 4]])\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const separate = /*#__PURE__*/partitionMap(identity);\n/**\n * Reduces an array from the left.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * const result = Array.reduce(numbers, 0, (acc, n) => acc + n)\n * assert.deepStrictEqual(result, 6)\n *\n * @category folding\n * @since 2.0.0\n */\nexport const reduce = /*#__PURE__*/dual(3, (self, b, f) => fromIterable(self).reduce((b, a, i) => f(b, a, i), b));\n/**\n * Reduces an array from the right.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * const result = Array.reduceRight(numbers, 0, (acc, n) => acc + n)\n * assert.deepStrictEqual(result, 6)\n *\n * @category folding\n * @since 2.0.0\n */\nexport const reduceRight = /*#__PURE__*/dual(3, (self, b, f) => fromIterable(self).reduceRight((b, a, i) => f(b, a, i), b));\n/**\n * Lifts a predicate into an array.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const isEven = (n: number) => n % 2 === 0\n * const to = Array.liftPredicate(isEven)\n * assert.deepStrictEqual(to(1), [])\n * assert.deepStrictEqual(to(2), [2])\n *\n * @category lifting\n * @since 2.0.0\n */\nexport const liftPredicate = predicate => b => predicate(b) ? [b] : [];\n/**\n * @category lifting\n * @since 2.0.0\n */\nexport const liftOption = f => (...a) => fromOption(f(...a));\n/**\n * @category conversions\n * @since 2.0.0\n */\nexport const fromNullable = a => a == null ? empty() : [a];\n/**\n * @category lifting\n * @since 2.0.0\n */\nexport const liftNullable = f => (...a) => fromNullable(f(...a));\n/**\n * Maps over an array and flattens the result, removing null and undefined values.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * const result = Array.flatMapNullable(numbers, n => (n % 2 === 0 ? null : n))\n * assert.deepStrictEqual(result, [1, 3])\n *\n * // Explanation:\n * // The array of numbers [1, 2, 3] is mapped with a function that returns null for even numbers\n * // and the number itself for odd numbers. The resulting array [1, null, 3] is then flattened\n * // to remove null values, resulting in [1, 3].\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatMapNullable = /*#__PURE__*/dual(2, (self, f) => flatMap(self, a => fromNullable(f(a))));\n/**\n * Lifts a function that returns an `Either` into a function that returns an array.\n * If the `Either` is a left, it returns an empty array.\n * If the `Either` is a right, it returns an array with the right value.\n *\n * @example\n * import { Array, Either } from \"effect\"\n *\n * const parseNumber = (s: string): Either.Either<number, Error> =>\n *   isNaN(Number(s)) ? Either.left(new Error(\"Not a number\")) : Either.right(Number(s))\n *\n * const liftedParseNumber = Array.liftEither(parseNumber)\n *\n * const result1 = liftedParseNumber(\"42\")\n * assert.deepStrictEqual(result1, [42])\n *\n * const result2 = liftedParseNumber(\"not a number\")\n * assert.deepStrictEqual(result2, [])\n *\n * // Explanation:\n * // The function parseNumber is lifted to return an array.\n * // When parsing \"42\", it returns an Either.left with the number 42, resulting in [42].\n * // When parsing \"not a number\", it returns an Either.right with an error, resulting in an empty array [].\n *\n * @category lifting\n * @since 2.0.0\n */\nexport const liftEither = f => (...a) => {\n  const e = f(...a);\n  return E.isLeft(e) ? [] : [e.right];\n};\n/**\n * Check if a predicate holds true for every `ReadonlyArray` element.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const every = /*#__PURE__*/dual(2, (self, refinement) => self.every(refinement));\n/**\n * Check if a predicate holds true for some `ReadonlyArray` element.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const some = /*#__PURE__*/dual(2, (self, predicate) => self.some(predicate));\n/**\n * Extends an array with a function that maps each subarray to a value.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * const result = Array.extend(numbers, as => as.length)\n * assert.deepStrictEqual(result, [3, 2, 1])\n *\n * // Explanation:\n * // The function maps each subarray starting from each element to its length.\n * // The subarrays are: [1, 2, 3], [2, 3], [3].\n * // The lengths are: 3, 2, 1.\n * // Therefore, the result is [3, 2, 1].\n *\n * @since 2.0.0\n */\nexport const extend = /*#__PURE__*/dual(2, (self, f) => self.map((_, i, as) => f(as.slice(i))));\n/**\n * Finds the minimum element in an array based on a comparator.\n *\n * @example\n * import { Array, Order } from \"effect\"\n *\n * const min = Array.min([3, 1, 2], Order.number)\n * assert.deepStrictEqual(min, 1)\n *\n * @since 2.0.0\n */\nexport const min = /*#__PURE__*/dual(2, (self, O) => self.reduce(Order.min(O)));\n/**\n * Finds the maximum element in an array based on a comparator.\n *\n * @example\n * import { Array, Order } from \"effect\"\n *\n * const max = Array.max([3, 1, 2], Order.number)\n * assert.deepStrictEqual(max, 3)\n *\n * @since 2.0.0\n */\nexport const max = /*#__PURE__*/dual(2, (self, O) => self.reduce(Order.max(O)));\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const unfold = (b, f) => {\n  const out = [];\n  let next = b;\n  let o;\n  while (O.isSome(o = f(next))) {\n    const [a, b] = o.value;\n    out.push(a);\n    next = b;\n  }\n  return out;\n};\n/**\n * This function creates and returns a new `Order` for an array of values based on a given `Order` for the elements of the array.\n * The returned `Order` compares two arrays by applying the given `Order` to each element in the arrays.\n * If all elements are equal, the arrays are then compared based on their length.\n * It is useful when you need to compare two arrays of the same type and you have a specific way of comparing each element of the array.\n *\n * @category instances\n * @since 2.0.0\n */\nexport const getOrder = Order.array;\n/**\n * Creates an equivalence relation for arrays.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers1 = [1, 2, 3]\n * const numbers2 = [1, 2, 3]\n * const eq = Array.getEquivalence<number>((a, b) => a === b)\n * assert.deepStrictEqual(eq(numbers1, numbers2), true)\n *\n * @category instances\n * @since 2.0.0\n */\nexport const getEquivalence = Equivalence.array;\n/**\n * Performs a side-effect for each element of the `Iterable`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * Array.forEach(numbers, n => console.log(n)) // 1, 2, 3\n *\n * @since 2.0.0\n */\nexport const forEach = /*#__PURE__*/dual(2, (self, f) => fromIterable(self).forEach((a, i) => f(a, i)));\n/**\n * Remove duplicates from an `Iterable` using the provided `isEquivalent` function,\n * preserving the order of the first occurrence of each element.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 2, 3, 3, 3]\n * const unique = Array.dedupeWith(numbers, (a, b) => a === b)\n * assert.deepStrictEqual(unique, [1, 2, 3])\n *\n * @since 2.0.0\n */\nexport const dedupeWith = /*#__PURE__*/dual(2, (self, isEquivalent) => {\n  const input = fromIterable(self);\n  if (isNonEmptyReadonlyArray(input)) {\n    const out = [headNonEmpty(input)];\n    const rest = tailNonEmpty(input);\n    for (const r of rest) {\n      if (out.every(a => !isEquivalent(r, a))) {\n        out.push(r);\n      }\n    }\n    return out;\n  }\n  return [];\n});\n/**\n * Remove duplicates from an `Iterable`, preserving the order of the first occurrence of each element.\n * The equivalence used to compare elements is provided by `Equal.equivalence()` from the `Equal` module.\n *\n * @since 2.0.0\n */\nexport const dedupe = self => dedupeWith(self, Equal.equivalence());\n/**\n * Deduplicates adjacent elements that are identical using the provided `isEquivalent` function.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 1, 2, 2, 3, 3]\n * const unique = Array.dedupeAdjacentWith(numbers, (a, b) => a === b)\n * assert.deepStrictEqual(unique, [1, 2, 3])\n *\n * @since 2.0.0\n */\nexport const dedupeAdjacentWith = /*#__PURE__*/dual(2, (self, isEquivalent) => {\n  const out = [];\n  let lastA = O.none();\n  for (const a of self) {\n    if (O.isNone(lastA) || !isEquivalent(a, lastA.value)) {\n      out.push(a);\n      lastA = O.some(a);\n    }\n  }\n  return out;\n});\n/**\n * Deduplicates adjacent elements that are identical.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 1, 2, 2, 3, 3]\n * const unique = Array.dedupeAdjacent(numbers)\n * assert.deepStrictEqual(unique, [1, 2, 3])\n *\n * @since 2.0.0\n */\nexport const dedupeAdjacent = /*#__PURE__*/dedupeAdjacentWith( /*#__PURE__*/Equal.equivalence());\n/**\n * Joins the elements together with \"sep\" in the middle.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const strings = [\"a\", \"b\", \"c\"]\n * const joined = Array.join(strings, \"-\")\n * assert.deepStrictEqual(joined, \"a-b-c\")\n *\n * @since 2.0.0\n * @category folding\n */\nexport const join = /*#__PURE__*/dual(2, (self, sep) => fromIterable(self).join(sep));\n/**\n * Statefully maps over the chunk, producing new elements of type `B`.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n * const result = Array.mapAccum(numbers, 0, (acc, n) => [acc + n, acc + n])\n * assert.deepStrictEqual(result, [6, [1, 3, 6]])\n *\n * @since 2.0.0\n * @category folding\n */\nexport const mapAccum = /*#__PURE__*/dual(3, (self, s, f) => {\n  let i = 0;\n  let s1 = s;\n  const out = [];\n  for (const a of self) {\n    const r = f(s1, a, i);\n    s1 = r[0];\n    out.push(r[1]);\n    i++;\n  }\n  return [s1, out];\n});\n/**\n * Zips this chunk crosswise with the specified chunk using the specified combiner.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2]\n * const array2 = [\"a\", \"b\"]\n * const product = Array.cartesianWith(array1, array2, (a, b) => `${a}-${b}`)\n * assert.deepStrictEqual(product, [\"1-a\", \"1-b\", \"2-a\", \"2-b\"])\n *\n * @since 2.0.0\n * @category elements\n */\nexport const cartesianWith = /*#__PURE__*/dual(3, (self, that, f) => flatMap(self, a => map(that, b => f(a, b))));\n/**\n * Zips this chunk crosswise with the specified chunk.\n *\n * @example\n * import { Array } from \"effect\"\n *\n * const array1 = [1, 2]\n * const array2 = [\"a\", \"b\"]\n * const product = Array.cartesian(array1, array2)\n * assert.deepStrictEqual(product, [[1, \"a\"], [1, \"b\"], [2, \"a\"], [2, \"b\"]])\n *\n * @since 2.0.0\n * @category elements\n */\nexport const cartesian = /*#__PURE__*/dual(2, (self, that) => cartesianWith(self, that, (a, b) => [a, b]));\n// -------------------------------------------------------------------------------------\n// do notation\n// -------------------------------------------------------------------------------------\n/**\n * The \"do simulation\" for array allows you to sequentially apply operations to the elements of arrays, just as nested loops allow you to go through all combinations of elements in an arrays.\n *\n * It can be used to simulate \"array comprehension\".\n * It's a technique that allows you to create new arrays by iterating over existing ones and applying specific **conditions** or **transformations** to the elements. It's like assembling a new collection from pieces of other collections based on certain rules.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Array` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n * 5. Regular `Option` functions like `map` and `filter` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope\n *\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link let_ let}\n *\n * @example\n * import { Array as Arr, pipe } from \"effect\"\n * const doResult = pipe(\n *   Arr.Do,\n *   Arr.bind(\"x\", () => [1, 3, 5]),\n *   Arr.bind(\"y\", () => [2, 4, 6]),\n *   Arr.filter(({ x, y }) => x < y), // condition\n *   Arr.map(({ x, y }) => [x, y] as const) // transformation\n * )\n * assert.deepStrictEqual(doResult, [[1, 2], [1, 4], [1, 6], [3, 4], [3, 6], [5, 6]])\n *\n * // equivalent\n * const x = [1, 3, 5],\n *       y = [2, 4, 6],\n *       result = [];\n * for(let i = 0; i < x.length; i++) {\n *   for(let j = 0; j < y.length; j++) {\n *     const _x = x[i], _y = y[j];\n *     if(_x < _y) result.push([_x, _y] as const)\n *   }\n * }\n *\n * @category do notation\n * @since 3.2.0\n */\nexport const Do = /*#__PURE__*/of({});\n/**\n * The \"do simulation\" for array allows you to sequentially apply operations to the elements of arrays, just as nested loops allow you to go through all combinations of elements in an arrays.\n *\n * It can be used to simulate \"array comprehension\".\n * It's a technique that allows you to create new arrays by iterating over existing ones and applying specific **conditions** or **transformations** to the elements. It's like assembling a new collection from pieces of other collections based on certain rules.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Array` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n * 5. Regular `Option` functions like `map` and `filter` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope\n *\n * @see {@link bindTo}\n * @see {@link Do}\n * @see {@link let_ let}\n *\n * @example\n * import { Array as Arr, pipe } from \"effect\"\n * const doResult = pipe(\n *   Arr.Do,\n *   Arr.bind(\"x\", () => [1, 3, 5]),\n *   Arr.bind(\"y\", () => [2, 4, 6]),\n *   Arr.filter(({ x, y }) => x < y), // condition\n *   Arr.map(({ x, y }) => [x, y] as const) // transformation\n * )\n * assert.deepStrictEqual(doResult, [[1, 2], [1, 4], [1, 6], [3, 4], [3, 6], [5, 6]])\n *\n * // equivalent\n * const x = [1, 3, 5],\n *       y = [2, 4, 6],\n *       result = [];\n * for(let i = 0; i < x.length; i++) {\n *   for(let j = 0; j < y.length; j++) {\n *     const _x = x[i], _y = y[j];\n *     if(_x < _y) result.push([_x, _y] as const)\n *   }\n * }\n *\n * @category do notation\n * @since 3.2.0\n */\nexport const bind = /*#__PURE__*/doNotation.bind(map, flatMap);\n/**\n * The \"do simulation\" for array allows you to sequentially apply operations to the elements of arrays, just as nested loops allow you to go through all combinations of elements in an arrays.\n *\n * It can be used to simulate \"array comprehension\".\n * It's a technique that allows you to create new arrays by iterating over existing ones and applying specific **conditions** or **transformations** to the elements. It's like assembling a new collection from pieces of other collections based on certain rules.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Array` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n * 5. Regular `Option` functions like `map` and `filter` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope\n *\n * @see {@link bindTo}\n * @see {@link Do}\n * @see {@link let_ let}\n *\n * @example\n * import { Array as Arr, pipe } from \"effect\"\n * const doResult = pipe(\n *   Arr.Do,\n *   Arr.bind(\"x\", () => [1, 3, 5]),\n *   Arr.bind(\"y\", () => [2, 4, 6]),\n *   Arr.filter(({ x, y }) => x < y), // condition\n *   Arr.map(({ x, y }) => [x, y] as const) // transformation\n * )\n * assert.deepStrictEqual(doResult, [[1, 2], [1, 4], [1, 6], [3, 4], [3, 6], [5, 6]])\n *\n * // equivalent\n * const x = [1, 3, 5],\n *       y = [2, 4, 6],\n *       result = [];\n * for(let i = 0; i < x.length; i++) {\n *   for(let j = 0; j < y.length; j++) {\n *     const _x = x[i], _y = y[j];\n *     if(_x < _y) result.push([_x, _y] as const)\n *   }\n * }\n *\n * @category do notation\n * @since 3.2.0\n */\nexport const bindTo = /*#__PURE__*/doNotation.bindTo(map);\nconst let_ = /*#__PURE__*/doNotation.let_(map);\nexport {\n/**\n * The \"do simulation\" for array allows you to sequentially apply operations to the elements of arrays, just as nested loops allow you to go through all combinations of elements in an arrays.\n *\n * It can be used to simulate \"array comprehension\".\n * It's a technique that allows you to create new arrays by iterating over existing ones and applying specific **conditions** or **transformations** to the elements. It's like assembling a new collection from pieces of other collections based on certain rules.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Array` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n * 5. Regular `Option` functions like `map` and `filter` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope\n *\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link Do}\n *\n * @example\n * import { Array as Arr, pipe } from \"effect\"\n * const doResult = pipe(\n *   Arr.Do,\n *   Arr.bind(\"x\", () => [1, 3, 5]),\n *   Arr.bind(\"y\", () => [2, 4, 6]),\n *   Arr.filter(({ x, y }) => x < y), // condition\n *   Arr.map(({ x, y }) => [x, y] as const) // transformation\n * )\n * assert.deepStrictEqual(doResult, [[1, 2], [1, 4], [1, 6], [3, 4], [3, 6], [5, 6]])\n *\n * // equivalent\n * const x = [1, 3, 5],\n *       y = [2, 4, 6],\n *       result = [];\n * for(let i = 0; i < x.length; i++) {\n *   for(let j = 0; j < y.length; j++) {\n *     const _x = x[i], _y = y[j];\n *     if(_x < _y) result.push([_x, _y] as const)\n *   }\n * }\n *\n * @category do notation\n * @since 3.2.0\n */\nlet_ as let };\n//# sourceMappingURL=Array.js.map","/**\n * This module provides utility functions and type class instances for working with the `BigDecimal` type in TypeScript.\n * It includes functions for basic arithmetic operations, as well as type class instances for `Equivalence` and `Order`.\n *\n * A `BigDecimal` allows storing any real number to arbitrary precision; which avoids common floating point errors\n * (such as 0.1 + 0.2  0.3) at the cost of complexity.\n *\n * Internally, `BigDecimal` uses a `BigInt` object, paired with a 64-bit integer which determines the position of the\n * decimal point. Therefore, the precision *is not* actually arbitrary, but limited to 2<sup>63</sup> decimal places.\n *\n * It is not recommended to convert a floating point number to a decimal directly, as the floating point representation\n * may be unexpected.\n *\n * @since 2.0.0\n */\nimport * as Equal from \"./Equal.js\";\nimport * as equivalence from \"./Equivalence.js\";\nimport { dual, pipe } from \"./Function.js\";\nimport * as Hash from \"./Hash.js\";\nimport { NodeInspectSymbol } from \"./Inspectable.js\";\nimport * as Option from \"./Option.js\";\nimport * as order from \"./Order.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nimport { hasProperty } from \"./Predicate.js\";\nconst DEFAULT_PRECISION = 100;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/BigDecimal\");\nconst BigDecimalProto = {\n  [TypeId]: TypeId,\n  [Hash.symbol]() {\n    const normalized = normalize(this);\n    return pipe(Hash.hash(normalized.value), Hash.combine(Hash.number(normalized.scale)), Hash.cached(this));\n  },\n  [Equal.symbol](that) {\n    return isBigDecimal(that) && equals(this, that);\n  },\n  toString() {\n    return `BigDecimal(${format(this)})`;\n  },\n  toJSON() {\n    return {\n      _id: \"BigDecimal\",\n      value: String(this.value),\n      scale: this.scale\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/**\n * Checks if a given value is a `BigDecimal`.\n *\n * @param u - The value to check.\n *\n * @since 2.0.0\n * @category guards\n */\nexport const isBigDecimal = u => hasProperty(u, TypeId);\n/**\n * Creates a `BigDecimal` from a `bigint` value and a scale.\n *\n * @param value - The `bigint` value to create a `BigDecimal` from.\n * @param scale - The scale of the `BigDecimal`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = (value, scale) => {\n  const o = Object.create(BigDecimalProto);\n  o.value = value;\n  o.scale = scale;\n  return o;\n};\n/**\n * Internal function used to create pre-normalized `BigDecimal`s.\n *\n * @internal\n */\nexport const unsafeMakeNormalized = (value, scale) => {\n  if (value !== bigint0 && value % bigint10 === bigint0) {\n    throw new RangeError(\"Value must be normalized\");\n  }\n  const o = make(value, scale);\n  o.normalized = o;\n  return o;\n};\nconst bigint0 = /*#__PURE__*/BigInt(0);\nconst bigint1 = /*#__PURE__*/BigInt(1);\nconst bigint10 = /*#__PURE__*/BigInt(10);\nconst zero = /*#__PURE__*/unsafeMakeNormalized(bigint0, 0);\n/**\n * Normalizes a given `BigDecimal` by removing trailing zeros.\n *\n * @param self - The `BigDecimal` to normalize.\n *\n * @example\n * import { normalize, make, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(normalize(unsafeFromString(\"123.00000\")), normalize(make(123n, 0)))\n * assert.deepStrictEqual(normalize(unsafeFromString(\"12300000\")), normalize(make(123n, -5)))\n *\n * @since 2.0.0\n * @category scaling\n */\nexport const normalize = self => {\n  if (self.normalized === undefined) {\n    if (self.value === bigint0) {\n      self.normalized = zero;\n    } else {\n      const digits = `${self.value}`;\n      let trail = 0;\n      for (let i = digits.length - 1; i >= 0; i--) {\n        if (digits[i] === \"0\") {\n          trail++;\n        } else {\n          break;\n        }\n      }\n      if (trail === 0) {\n        self.normalized = self;\n      }\n      const value = BigInt(digits.substring(0, digits.length - trail));\n      const scale = self.scale - trail;\n      self.normalized = unsafeMakeNormalized(value, scale);\n    }\n  }\n  return self.normalized;\n};\n/**\n * Scales a given `BigDecimal` to the specified scale.\n *\n * If the given scale is smaller than the current scale, the value will be rounded down to\n * the nearest integer.\n *\n * @param self - The `BigDecimal` to scale.\n * @param scale - The scale to scale to.\n *\n * @since 2.0.0\n * @category scaling\n */\nexport const scale = (self, scale) => {\n  if (scale > self.scale) {\n    return make(self.value * bigint10 ** BigInt(scale - self.scale), scale);\n  }\n  if (scale < self.scale) {\n    return make(self.value / bigint10 ** BigInt(self.scale - scale), scale);\n  }\n  return self;\n};\n/**\n * Provides an addition operation on `BigDecimal`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { sum, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(sum(unsafeFromString(\"2\"), unsafeFromString(\"3\")), unsafeFromString(\"5\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const sum = /*#__PURE__*/dual(2, (self, that) => {\n  if (that.value === bigint0) {\n    return self;\n  }\n  if (self.value === bigint0) {\n    return that;\n  }\n  if (self.scale > that.scale) {\n    return make(scale(that, self.scale).value + self.value, self.scale);\n  }\n  if (self.scale < that.scale) {\n    return make(scale(self, that.scale).value + that.value, that.scale);\n  }\n  return make(self.value + that.value, self.scale);\n});\n/**\n * Provides a multiplication operation on `BigDecimal`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { multiply, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(multiply(unsafeFromString(\"2\"), unsafeFromString(\"3\")), unsafeFromString(\"6\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const multiply = /*#__PURE__*/dual(2, (self, that) => {\n  if (that.value === bigint0 || self.value === bigint0) {\n    return zero;\n  }\n  return make(self.value * that.value, self.scale + that.scale);\n});\n/**\n * Provides a subtraction operation on `BigDecimal`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { subtract, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(subtract(unsafeFromString(\"2\"), unsafeFromString(\"3\")), unsafeFromString(\"-1\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const subtract = /*#__PURE__*/dual(2, (self, that) => {\n  if (that.value === bigint0) {\n    return self;\n  }\n  if (self.value === bigint0) {\n    return make(-that.value, that.scale);\n  }\n  if (self.scale > that.scale) {\n    return make(self.value - scale(that, self.scale).value, self.scale);\n  }\n  if (self.scale < that.scale) {\n    return make(scale(self, that.scale).value - that.value, that.scale);\n  }\n  return make(self.value - that.value, self.scale);\n});\n/**\n * Internal function used for arbitrary precision division.\n */\nconst divideWithPrecision = (num, den, scale, precision) => {\n  const numNegative = num < bigint0;\n  const denNegative = den < bigint0;\n  const negateResult = numNegative !== denNegative;\n  num = numNegative ? -num : num;\n  den = denNegative ? -den : den;\n  // Shift digits until numerator is larger than denominator (set scale appropriately).\n  while (num < den) {\n    num *= bigint10;\n    scale++;\n  }\n  // First division.\n  let quotient = num / den;\n  let remainder = num % den;\n  if (remainder === bigint0) {\n    // No remainder, return immediately.\n    return make(negateResult ? -quotient : quotient, scale);\n  }\n  // The quotient is guaranteed to be non-negative at this point. No need to consider sign.\n  let count = `${quotient}`.length;\n  // Shift the remainder by 1 decimal; The quotient will be 1 digit upon next division.\n  remainder *= bigint10;\n  while (remainder !== bigint0 && count < precision) {\n    const q = remainder / den;\n    const r = remainder % den;\n    quotient = quotient * bigint10 + q;\n    remainder = r * bigint10;\n    count++;\n    scale++;\n  }\n  if (remainder !== bigint0) {\n    // Round final number with remainder.\n    quotient += roundTerminal(remainder / den);\n  }\n  return make(negateResult ? -quotient : quotient, scale);\n};\n/**\n * Internal function used for rounding.\n *\n * Returns 1 if the most significant digit is >= 5, otherwise 0.\n *\n * This is used after dividing a number by a power of ten and rounding the last digit.\n *\n * @internal\n */\nexport const roundTerminal = n => {\n  const pos = n >= bigint0 ? 0 : 1;\n  return Number(`${n}`[pos]) < 5 ? bigint0 : bigint1;\n};\n/**\n * Provides a division operation on `BigDecimal`s.\n *\n * If the dividend is not a multiple of the divisor the result will be a `BigDecimal` value\n * which represents the integer division rounded down to the nearest integer.\n *\n * If the divisor is `0`, the result will be `None`.\n *\n * @param self - The dividend operand.\n * @param that - The divisor operand.\n *\n * @example\n * import { BigDecimal, Option } from \"effect\"\n *\n * assert.deepStrictEqual(BigDecimal.divide(BigDecimal.unsafeFromString(\"6\"), BigDecimal.unsafeFromString(\"3\")), Option.some(BigDecimal.unsafeFromString(\"2\")))\n * assert.deepStrictEqual(BigDecimal.divide(BigDecimal.unsafeFromString(\"6\"), BigDecimal.unsafeFromString(\"4\")), Option.some(BigDecimal.unsafeFromString(\"1.5\")))\n * assert.deepStrictEqual(BigDecimal.divide(BigDecimal.unsafeFromString(\"6\"), BigDecimal.unsafeFromString(\"0\")), Option.none())\n *\n * @since 2.0.0\n * @category math\n */\nexport const divide = /*#__PURE__*/dual(2, (self, that) => {\n  if (that.value === bigint0) {\n    return Option.none();\n  }\n  if (self.value === bigint0) {\n    return Option.some(zero);\n  }\n  const scale = self.scale - that.scale;\n  if (self.value === that.value) {\n    return Option.some(make(bigint1, scale));\n  }\n  return Option.some(divideWithPrecision(self.value, that.value, scale, DEFAULT_PRECISION));\n});\n/**\n * Provides an unsafe division operation on `BigDecimal`s.\n *\n * If the dividend is not a multiple of the divisor the result will be a `BigDecimal` value\n * which represents the integer division rounded down to the nearest integer.\n *\n * Throws a `RangeError` if the divisor is `0`.\n *\n * @param self - The dividend operand.\n * @param that - The divisor operand.as\n *\n * @example\n * import { unsafeDivide, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(unsafeDivide(unsafeFromString(\"6\"), unsafeFromString(\"3\")), unsafeFromString(\"2\"))\n * assert.deepStrictEqual(unsafeDivide(unsafeFromString(\"6\"), unsafeFromString(\"4\")), unsafeFromString(\"1.5\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const unsafeDivide = /*#__PURE__*/dual(2, (self, that) => {\n  if (that.value === bigint0) {\n    throw new RangeError(\"Division by zero\");\n  }\n  if (self.value === bigint0) {\n    return zero;\n  }\n  const scale = self.scale - that.scale;\n  if (self.value === that.value) {\n    return make(bigint1, scale);\n  }\n  return divideWithPrecision(self.value, that.value, scale, DEFAULT_PRECISION);\n});\n/**\n * @since 2.0.0\n * @category instances\n */\nexport const Order = /*#__PURE__*/order.make((self, that) => {\n  const scmp = order.number(sign(self), sign(that));\n  if (scmp !== 0) {\n    return scmp;\n  }\n  if (self.scale > that.scale) {\n    return order.bigint(self.value, scale(that, self.scale).value);\n  }\n  if (self.scale < that.scale) {\n    return order.bigint(scale(self, that.scale).value, that.value);\n  }\n  return order.bigint(self.value, that.value);\n});\n/**\n * Returns `true` if the first argument is less than the second, otherwise `false`.\n *\n * @param self - The first argument.\n * @param that - The second argument.\n *\n * @example\n * import { lessThan, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(lessThan(unsafeFromString(\"2\"), unsafeFromString(\"3\")), true)\n * assert.deepStrictEqual(lessThan(unsafeFromString(\"3\"), unsafeFromString(\"3\")), false)\n * assert.deepStrictEqual(lessThan(unsafeFromString(\"4\"), unsafeFromString(\"3\")), false)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const lessThan = /*#__PURE__*/order.lessThan(Order);\n/**\n * Checks if a given `BigDecimal` is less than or equal to the provided one.\n *\n * @param self - The first `BigDecimal` to compare with.\n * @param that - The second `BigDecimal` to compare with.\n *\n * @example\n * import { lessThanOrEqualTo, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(lessThanOrEqualTo(unsafeFromString(\"2\"), unsafeFromString(\"3\")), true)\n * assert.deepStrictEqual(lessThanOrEqualTo(unsafeFromString(\"3\"), unsafeFromString(\"3\")), true)\n * assert.deepStrictEqual(lessThanOrEqualTo(unsafeFromString(\"4\"), unsafeFromString(\"3\")), false)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const lessThanOrEqualTo = /*#__PURE__*/order.lessThanOrEqualTo(Order);\n/**\n * Returns `true` if the first argument is greater than the second, otherwise `false`.\n *\n * @param self - The first argument.\n * @param that - The second argument.\n *\n * @example\n * import { greaterThan, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(greaterThan(unsafeFromString(\"2\"), unsafeFromString(\"3\")), false)\n * assert.deepStrictEqual(greaterThan(unsafeFromString(\"3\"), unsafeFromString(\"3\")), false)\n * assert.deepStrictEqual(greaterThan(unsafeFromString(\"4\"), unsafeFromString(\"3\")), true)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const greaterThan = /*#__PURE__*/order.greaterThan(Order);\n/**\n * Checks if a given `BigDecimal` is greater than or equal to the provided one.\n *\n * @param self - The first `BigDecimal` to compare with.\n * @param that - The second `BigDecimal` to compare with.\n *\n * @example\n * import { greaterThanOrEqualTo, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(greaterThanOrEqualTo(unsafeFromString(\"2\"), unsafeFromString(\"3\")), false)\n * assert.deepStrictEqual(greaterThanOrEqualTo(unsafeFromString(\"3\"), unsafeFromString(\"3\")), true)\n * assert.deepStrictEqual(greaterThanOrEqualTo(unsafeFromString(\"4\"), unsafeFromString(\"3\")), true)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const greaterThanOrEqualTo = /*#__PURE__*/order.greaterThanOrEqualTo(Order);\n/**\n * Checks if a `BigDecimal` is between a `minimum` and `maximum` value (inclusive).\n *\n * @param self - The `number` to check.\n * @param minimum - The `minimum` value to check.\n * @param maximum - The `maximum` value to check.\n *\n * @example\n * import { BigDecimal } from \"effect\"\n *\n * const between = BigDecimal.between({\n *   minimum: BigDecimal.unsafeFromString(\"1\"),\n *   maximum: BigDecimal.unsafeFromString(\"5\") }\n * )\n *\n * assert.deepStrictEqual(between(BigDecimal.unsafeFromString(\"3\")), true)\n * assert.deepStrictEqual(between(BigDecimal.unsafeFromString(\"0\")), false)\n * assert.deepStrictEqual(between(BigDecimal.unsafeFromString(\"6\")), false)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const between = /*#__PURE__*/order.between(Order);\n/**\n * Restricts the given `BigDecimal` to be within the range specified by the `minimum` and `maximum` values.\n *\n * - If the `BigDecimal` is less than the `minimum` value, the function returns the `minimum` value.\n * - If the `BigDecimal` is greater than the `maximum` value, the function returns the `maximum` value.\n * - Otherwise, it returns the original `BigDecimal`.\n *\n * @param self - The `BigDecimal` to be clamped.\n * @param minimum - The lower end of the range.\n * @param maximum - The upper end of the range.\n *\n * @example\n * import { BigDecimal } from \"effect\"\n *\n * const clamp = BigDecimal.clamp({\n *   minimum: BigDecimal.unsafeFromString(\"1\"),\n *   maximum: BigDecimal.unsafeFromString(\"5\") }\n * )\n *\n * assert.deepStrictEqual(clamp(BigDecimal.unsafeFromString(\"3\")), BigDecimal.unsafeFromString(\"3\"))\n * assert.deepStrictEqual(clamp(BigDecimal.unsafeFromString(\"0\")), BigDecimal.unsafeFromString(\"1\"))\n * assert.deepStrictEqual(clamp(BigDecimal.unsafeFromString(\"6\")), BigDecimal.unsafeFromString(\"5\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const clamp = /*#__PURE__*/order.clamp(Order);\n/**\n * Returns the minimum between two `BigDecimal`s.\n *\n * @param self - The first `BigDecimal`.\n * @param that - The second `BigDecimal`.\n *\n * @example\n * import { min, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(min(unsafeFromString(\"2\"), unsafeFromString(\"3\")), unsafeFromString(\"2\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const min = /*#__PURE__*/order.min(Order);\n/**\n * Returns the maximum between two `BigDecimal`s.\n *\n * @param self - The first `BigDecimal`.\n * @param that - The second `BigDecimal`.\n *\n * @example\n * import { max, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(max(unsafeFromString(\"2\"), unsafeFromString(\"3\")), unsafeFromString(\"3\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const max = /*#__PURE__*/order.max(Order);\n/**\n * Determines the sign of a given `BigDecimal`.\n *\n * @param n - The `BigDecimal` to determine the sign of.\n *\n * @example\n * import { sign, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(sign(unsafeFromString(\"-5\")), -1)\n * assert.deepStrictEqual(sign(unsafeFromString(\"0\")), 0)\n * assert.deepStrictEqual(sign(unsafeFromString(\"5\")), 1)\n *\n * @since 2.0.0\n * @category math\n */\nexport const sign = n => n.value === bigint0 ? 0 : n.value < bigint0 ? -1 : 1;\n/**\n * Determines the absolute value of a given `BigDecimal`.\n *\n * @param n - The `BigDecimal` to determine the absolute value of.\n *\n * @example\n * import { abs, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(abs(unsafeFromString(\"-5\")), unsafeFromString(\"5\"))\n * assert.deepStrictEqual(abs(unsafeFromString(\"0\")), unsafeFromString(\"0\"))\n * assert.deepStrictEqual(abs(unsafeFromString(\"5\")), unsafeFromString(\"5\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const abs = n => n.value < bigint0 ? make(-n.value, n.scale) : n;\n/**\n * Provides a negate operation on `BigDecimal`s.\n *\n * @param n - The `BigDecimal` to negate.\n *\n * @example\n * import { negate, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(negate(unsafeFromString(\"3\")), unsafeFromString(\"-3\"))\n * assert.deepStrictEqual(negate(unsafeFromString(\"-6\")), unsafeFromString(\"6\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const negate = n => make(-n.value, n.scale);\n/**\n * Returns the remainder left over when one operand is divided by a second operand.\n *\n * If the divisor is `0`, the result will be `None`.\n *\n * @param self - The dividend.\n * @param divisor - The divisor.\n *\n * @example\n * import { BigDecimal, Option } from \"effect\"\n *\n * assert.deepStrictEqual(BigDecimal.remainder(BigDecimal.unsafeFromString(\"2\"), BigDecimal.unsafeFromString(\"2\")), Option.some(BigDecimal.unsafeFromString(\"0\")))\n * assert.deepStrictEqual(BigDecimal.remainder(BigDecimal.unsafeFromString(\"3\"), BigDecimal.unsafeFromString(\"2\")), Option.some(BigDecimal.unsafeFromString(\"1\")))\n * assert.deepStrictEqual(BigDecimal.remainder(BigDecimal.unsafeFromString(\"-4\"), BigDecimal.unsafeFromString(\"2\")), Option.some(BigDecimal.unsafeFromString(\"0\")))\n *\n * @since 2.0.0\n * @category math\n */\nexport const remainder = /*#__PURE__*/dual(2, (self, divisor) => {\n  if (divisor.value === bigint0) {\n    return Option.none();\n  }\n  const max = Math.max(self.scale, divisor.scale);\n  return Option.some(make(scale(self, max).value % scale(divisor, max).value, max));\n});\n/**\n * Returns the remainder left over when one operand is divided by a second operand.\n *\n * Throws a `RangeError` if the divisor is `0`.\n *\n * @param self - The dividend.\n * @param divisor - The divisor.\n *\n * @example\n * import { unsafeRemainder, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(unsafeRemainder(unsafeFromString(\"2\"), unsafeFromString(\"2\")), unsafeFromString(\"0\"))\n * assert.deepStrictEqual(unsafeRemainder(unsafeFromString(\"3\"), unsafeFromString(\"2\")), unsafeFromString(\"1\"))\n * assert.deepStrictEqual(unsafeRemainder(unsafeFromString(\"-4\"), unsafeFromString(\"2\")), unsafeFromString(\"0\"))\n *\n * @since 2.0.0\n * @category math\n */\nexport const unsafeRemainder = /*#__PURE__*/dual(2, (self, divisor) => {\n  if (divisor.value === bigint0) {\n    throw new RangeError(\"Division by zero\");\n  }\n  const max = Math.max(self.scale, divisor.scale);\n  return make(scale(self, max).value % scale(divisor, max).value, max);\n});\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Equivalence = /*#__PURE__*/equivalence.make((self, that) => {\n  if (self.scale > that.scale) {\n    return scale(that, self.scale).value === self.value;\n  }\n  if (self.scale < that.scale) {\n    return scale(self, that.scale).value === that.value;\n  }\n  return self.value === that.value;\n});\n/**\n * Checks if two `BigDecimal`s are equal.\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const equals = /*#__PURE__*/dual(2, (self, that) => Equivalence(self, that));\n/**\n * Creates a `BigDecimal` from a `bigint` value.\n *\n * @param value - The `bigint` value to create a `BigDecimal` from.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromBigInt = n => make(n, 0);\n/**\n * Creates a `BigDecimal` from a `number` value.\n *\n * It is not recommended to convert a floating point number to a decimal directly,\n * as the floating point representation may be unexpected.\n *\n * @param value - The `number` value to create a `BigDecimal` from.\n *\n * @example\n * import { fromNumber, make } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(fromNumber(123), make(123n, 0))\n * assert.deepStrictEqual(fromNumber(123.456), make(123456n, 3))\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromNumber = n => {\n  const [lead, trail = \"\"] = `${n}`.split(\".\");\n  return make(BigInt(`${lead}${trail}`), trail.length);\n};\n/**\n * Parses a numerical `string` into a `BigDecimal`.\n *\n * @param s - The `string` to parse.\n *\n * @example\n * import { BigDecimal, Option } from \"effect\"\n *\n * assert.deepStrictEqual(BigDecimal.fromString(\"123\"), Option.some(BigDecimal.make(123n, 0)))\n * assert.deepStrictEqual(BigDecimal.fromString(\"123.456\"), Option.some(BigDecimal.make(123456n, 3)))\n * assert.deepStrictEqual(BigDecimal.fromString(\"123.abc\"), Option.none())\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromString = s => {\n  let digits;\n  let scale;\n  const dot = s.search(/\\./);\n  if (dot !== -1) {\n    const lead = s.slice(0, dot);\n    const trail = s.slice(dot + 1);\n    digits = `${lead}${trail}`;\n    scale = trail.length;\n  } else {\n    digits = s;\n    scale = 0;\n  }\n  if (digits === \"\") {\n    // TODO: This mimics the BigInt constructor behavior. Should this be `Option.none()`?\n    return Option.some(zero);\n  }\n  if (!/^(?:\\+|-)?\\d+$/.test(digits)) {\n    return Option.none();\n  }\n  return Option.some(make(BigInt(digits), scale));\n};\n/**\n * Parses a numerical `string` into a `BigDecimal`.\n *\n * @param s - The `string` to parse.\n *\n * @example\n * import { unsafeFromString, make } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(unsafeFromString(\"123\"), make(123n, 0))\n * assert.deepStrictEqual(unsafeFromString(\"123.456\"), make(123456n, 3))\n * assert.throws(() => unsafeFromString(\"123.abc\"))\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unsafeFromString = s => Option.getOrThrowWith(fromString(s), () => new Error(\"Invalid numerical string\"));\n/**\n * Formats a given `BigDecimal` as a `string`.\n *\n * @param normalized - The `BigDecimal` to format.\n *\n * @example\n * import { format, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(format(unsafeFromString(\"-5\")), \"-5\")\n * assert.deepStrictEqual(format(unsafeFromString(\"123.456\")), \"123.456\")\n * assert.deepStrictEqual(format(unsafeFromString(\"-0.00000123\")), \"-0.00000123\")\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const format = n => {\n  const negative = n.value < bigint0;\n  const absolute = negative ? `${n.value}`.substring(1) : `${n.value}`;\n  let before;\n  let after;\n  if (n.scale >= absolute.length) {\n    before = \"0\";\n    after = \"0\".repeat(n.scale - absolute.length) + absolute;\n  } else {\n    const location = absolute.length - n.scale;\n    if (location > absolute.length) {\n      const zeros = location - absolute.length;\n      before = `${absolute}${\"0\".repeat(zeros)}`;\n      after = \"\";\n    } else {\n      after = absolute.slice(location);\n      before = absolute.slice(0, location);\n    }\n  }\n  const complete = after === \"\" ? before : `${before}.${after}`;\n  return negative ? `-${complete}` : complete;\n};\n/**\n * Converts a `BigDecimal` to a `number`.\n *\n * This function will produce incorrect results if the `BigDecimal` exceeds the 64-bit range of a `number`.\n *\n * @param n - The `BigDecimal` to convert.\n *\n * @example\n * import { unsafeToNumber, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(unsafeToNumber(unsafeFromString(\"123.456\")), 123.456)\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const unsafeToNumber = n => Number(format(n));\n/**\n * Checks if a given `BigDecimal` is an integer.\n *\n * @param n - The `BigDecimal` to check.\n *\n * @example\n * import { isInteger, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(isInteger(unsafeFromString(\"0\")), true)\n * assert.deepStrictEqual(isInteger(unsafeFromString(\"1\")), true)\n * assert.deepStrictEqual(isInteger(unsafeFromString(\"1.1\")), false)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const isInteger = n => normalize(n).scale <= 0;\n/**\n * Checks if a given `BigDecimal` is `0`.\n *\n * @param n - The `BigDecimal` to check.\n *\n * @example\n * import { isZero, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(isZero(unsafeFromString(\"0\")), true)\n * assert.deepStrictEqual(isZero(unsafeFromString(\"1\")), false)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const isZero = n => n.value === bigint0;\n/**\n * Checks if a given `BigDecimal` is negative.\n *\n * @param n - The `BigDecimal` to check.\n *\n * @example\n * import { isNegative, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(isNegative(unsafeFromString(\"-1\")), true)\n * assert.deepStrictEqual(isNegative(unsafeFromString(\"0\")), false)\n * assert.deepStrictEqual(isNegative(unsafeFromString(\"1\")), false)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const isNegative = n => n.value < bigint0;\n/**\n * Checks if a given `BigDecimal` is positive.\n *\n * @param n - The `BigDecimal` to check.\n *\n * @example\n * import { isPositive, unsafeFromString } from \"effect/BigDecimal\"\n *\n * assert.deepStrictEqual(isPositive(unsafeFromString(\"-1\")), false)\n * assert.deepStrictEqual(isPositive(unsafeFromString(\"0\")), false)\n * assert.deepStrictEqual(isPositive(unsafeFromString(\"1\")), true)\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const isPositive = n => n.value > bigint0;\n//# sourceMappingURL=BigDecimal.js.map","/**\n * This module provides utility functions and type class instances for working with the `bigint` type in TypeScript.\n * It includes functions for basic arithmetic operations, as well as type class instances for\n * `Equivalence` and `Order`.\n *\n * @since 2.0.0\n */\nimport * as equivalence from \"./Equivalence.js\";\nimport { dual } from \"./Function.js\";\nimport * as Option from \"./Option.js\";\nimport * as order from \"./Order.js\";\nimport * as predicate from \"./Predicate.js\";\nconst bigint0 = /*#__PURE__*/BigInt(0);\nconst bigint1 = /*#__PURE__*/BigInt(1);\nconst bigint2 = /*#__PURE__*/BigInt(2);\n/**\n * Tests if a value is a `bigint`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isBigInt } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(isBigInt(1n), true)\n * assert.deepStrictEqual(isBigInt(1), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isBigInt = predicate.isBigInt;\n/**\n * Provides an addition operation on `bigint`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { sum } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(sum(2n, 3n), 5n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const sum = /*#__PURE__*/dual(2, (self, that) => self + that);\n/**\n * Provides a multiplication operation on `bigint`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { multiply } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(multiply(2n, 3n), 6n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const multiply = /*#__PURE__*/dual(2, (self, that) => self * that);\n/**\n * Provides a subtraction operation on `bigint`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { subtract } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(subtract(2n, 3n), -1n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const subtract = /*#__PURE__*/dual(2, (self, that) => self - that);\n/**\n * Provides a division operation on `bigint`s.\n *\n * If the dividend is not a multiple of the divisor the result will be a `bigint` value\n * which represents the integer division rounded down to the nearest integer.\n *\n * Returns `None` if the divisor is `0n`.\n *\n * @param self - The dividend operand.\n * @param that - The divisor operand.\n *\n * @example\n * import { BigInt, Option } from \"effect\"\n *\n * assert.deepStrictEqual(BigInt.divide(6n, 3n), Option.some(2n))\n * assert.deepStrictEqual(BigInt.divide(6n, 0n), Option.none())\n *\n * @category math\n * @since 2.0.0\n */\nexport const divide = /*#__PURE__*/dual(2, (self, that) => that === bigint0 ? Option.none() : Option.some(self / that));\n/**\n * Provides a division operation on `bigint`s.\n *\n * If the dividend is not a multiple of the divisor the result will be a `bigint` value\n * which represents the integer division rounded down to the nearest integer.\n *\n * Throws a `RangeError` if the divisor is `0n`.\n *\n * @param self - The dividend operand.\n * @param that - The divisor operand.\n *\n * @example\n * import { unsafeDivide } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(unsafeDivide(6n, 3n), 2n)\n * assert.deepStrictEqual(unsafeDivide(6n, 4n), 1n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const unsafeDivide = /*#__PURE__*/dual(2, (self, that) => self / that);\n/**\n * Returns the result of adding `1n` to a given number.\n *\n * @param n - A `bigint` to be incremented.\n *\n * @example\n * import { increment } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(increment(2n), 3n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const increment = n => n + bigint1;\n/**\n * Decrements a number by `1n`.\n *\n * @param n - A `bigint` to be decremented.\n *\n * @example\n * import { decrement } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(decrement(3n), 2n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const decrement = n => n - bigint1;\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Equivalence = equivalence.bigint;\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Order = order.bigint;\n/**\n * Returns `true` if the first argument is less than the second, otherwise `false`.\n *\n * @param self - The first argument.\n * @param that - The second argument.\n *\n * @example\n * import { lessThan } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(lessThan(2n, 3n), true)\n * assert.deepStrictEqual(lessThan(3n, 3n), false)\n * assert.deepStrictEqual(lessThan(4n, 3n), false)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const lessThan = /*#__PURE__*/order.lessThan(Order);\n/**\n * Returns a function that checks if a given `bigint` is less than or equal to the provided one.\n *\n * @param self - The first `bigint` to compare with.\n * @param that - The second `bigint` to compare with.\n *\n * @example\n * import { lessThanOrEqualTo } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(lessThanOrEqualTo(2n, 3n), true)\n * assert.deepStrictEqual(lessThanOrEqualTo(3n, 3n), true)\n * assert.deepStrictEqual(lessThanOrEqualTo(4n, 3n), false)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const lessThanOrEqualTo = /*#__PURE__*/order.lessThanOrEqualTo(Order);\n/**\n * Returns `true` if the first argument is greater than the second, otherwise `false`.\n *\n * @param self - The first argument.\n * @param that - The second argument.\n *\n * @example\n * import { greaterThan } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(greaterThan(2n, 3n), false)\n * assert.deepStrictEqual(greaterThan(3n, 3n), false)\n * assert.deepStrictEqual(greaterThan(4n, 3n), true)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const greaterThan = /*#__PURE__*/order.greaterThan(Order);\n/**\n * Returns a function that checks if a given `bigint` is greater than or equal to the provided one.\n *\n * @param self - The first `bigint` to compare with.\n * @param that - The second `bigint` to compare with.\n *\n * @example\n * import { greaterThanOrEqualTo } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(greaterThanOrEqualTo(2n, 3n), false)\n * assert.deepStrictEqual(greaterThanOrEqualTo(3n, 3n), true)\n * assert.deepStrictEqual(greaterThanOrEqualTo(4n, 3n), true)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const greaterThanOrEqualTo = /*#__PURE__*/order.greaterThanOrEqualTo(Order);\n/**\n * Checks if a `bigint` is between a `minimum` and `maximum` value (inclusive).\n *\n * @param self - The `number` to check.\n * @param minimum - The `minimum` value to check.\n * @param maximum - The `maximum` value to check.\n *\n * @example\n * import { BigInt } from \"effect\"\n *\n * const between = BigInt.between({ minimum: 0n, maximum: 5n })\n *\n * assert.deepStrictEqual(between(3n), true)\n * assert.deepStrictEqual(between(-1n), false)\n * assert.deepStrictEqual(between(6n), false)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const between = /*#__PURE__*/order.between(Order);\n/**\n * Restricts the given `bigint` to be within the range specified by the `minimum` and `maximum` values.\n *\n * - If the `bigint` is less than the `minimum` value, the function returns the `minimum` value.\n * - If the `bigint` is greater than the `maximum` value, the function returns the `maximum` value.\n * - Otherwise, it returns the original `bigint`.\n *\n * @param self - The `bigint` to be clamped.\n * @param minimum - The lower end of the range.\n * @param maximum - The upper end of the range.\n *\n * @example\n * import { BigInt } from \"effect\"\n *\n * const clamp = BigInt.clamp({ minimum: 1n, maximum: 5n })\n *\n * assert.equal(clamp(3n), 3n)\n * assert.equal(clamp(0n), 1n)\n * assert.equal(clamp(6n), 5n)\n *\n * @since 2.0.0\n */\nexport const clamp = /*#__PURE__*/order.clamp(Order);\n/**\n * Returns the minimum between two `bigint`s.\n *\n * @param self - The first `bigint`.\n * @param that - The second `bigint`.\n *\n * @example\n * import { min } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(min(2n, 3n), 2n)\n *\n * @since 2.0.0\n */\nexport const min = /*#__PURE__*/order.min(Order);\n/**\n * Returns the maximum between two `bigint`s.\n *\n * @param self - The first `bigint`.\n * @param that - The second `bigint`.\n *\n * @example\n * import { max } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(max(2n, 3n), 3n)\n *\n * @since 2.0.0\n */\nexport const max = /*#__PURE__*/order.max(Order);\n/**\n * Determines the sign of a given `bigint`.\n *\n * @param n - The `bigint` to determine the sign of.\n *\n * @example\n * import { sign } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(sign(-5n), -1)\n * assert.deepStrictEqual(sign(0n), 0)\n * assert.deepStrictEqual(sign(5n), 1)\n *\n * @category math\n * @since 2.0.0\n */\nexport const sign = n => Order(n, bigint0);\n/**\n * Determines the absolute value of a given `bigint`.\n *\n * @param n - The `bigint` to determine the absolute value of.\n *\n * @example\n * import { abs } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(abs(-5n), 5n)\n * assert.deepStrictEqual(abs(0n), 0n)\n * assert.deepStrictEqual(abs(5n), 5n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const abs = n => n < bigint0 ? -n : n;\n/**\n * Determines the greatest common divisor of two `bigint`s.\n *\n * @param a - The first `bigint`.\n * @param b - The second `bigint`.\n *\n * @example\n * import { gcd } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(gcd(2n, 3n), 1n)\n * assert.deepStrictEqual(gcd(2n, 4n), 2n)\n * assert.deepStrictEqual(gcd(16n, 24n), 8n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const gcd = /*#__PURE__*/dual(2, (self, that) => {\n  while (that !== bigint0) {\n    const t = that;\n    that = self % that;\n    self = t;\n  }\n  return self;\n});\n/**\n * Determines the least common multiple of two `bigint`s.\n *\n * @param a - The first `bigint`.\n * @param b - The second `bigint`.\n *\n * @example\n * import { lcm } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(lcm(2n, 3n), 6n)\n * assert.deepStrictEqual(lcm(2n, 4n), 4n)\n * assert.deepStrictEqual(lcm(16n, 24n), 48n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const lcm = /*#__PURE__*/dual(2, (self, that) => self * that / gcd(self, that));\n/**\n * Determines the square root of a given `bigint` unsafely. Throws if the given `bigint` is negative.\n *\n * @param n - The `bigint` to determine the square root of.\n *\n * @example\n * import { unsafeSqrt } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(unsafeSqrt(4n), 2n)\n * assert.deepStrictEqual(unsafeSqrt(9n), 3n)\n * assert.deepStrictEqual(unsafeSqrt(16n), 4n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const unsafeSqrt = n => {\n  if (n < bigint0) {\n    throw new RangeError(\"Cannot take the square root of a negative number\");\n  }\n  if (n < bigint2) {\n    return n;\n  }\n  let x = n / bigint2;\n  while (x * x > n) {\n    x = (n / x + x) / bigint2;\n  }\n  return x;\n};\n/**\n * Determines the square root of a given `bigint` safely. Returns `none` if the given `bigint` is negative.\n *\n * @param n - The `bigint` to determine the square root of.\n *\n * @example\n * import { BigInt, Option } from \"effect\"\n *\n * assert.deepStrictEqual(BigInt.sqrt(4n), Option.some(2n))\n * assert.deepStrictEqual(BigInt.sqrt(9n), Option.some(3n))\n * assert.deepStrictEqual(BigInt.sqrt(16n), Option.some(4n))\n * assert.deepStrictEqual(BigInt.sqrt(-1n), Option.none())\n *\n * @category math\n * @since 2.0.0\n */\nexport const sqrt = n => greaterThanOrEqualTo(n, bigint0) ? Option.some(unsafeSqrt(n)) : Option.none();\n/**\n * Takes an `Iterable` of `bigint`s and returns their sum as a single `bigint\n *\n * @param collection - The collection of `bigint`s to sum.\n *\n * @example\n * import { sumAll } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(sumAll([2n, 3n, 4n]), 9n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const sumAll = collection => {\n  let out = bigint0;\n  for (const n of collection) {\n    out += n;\n  }\n  return out;\n};\n/**\n * Takes an `Iterable` of `bigint`s and returns their multiplication as a single `number`.\n *\n * @param collection - The collection of `bigint`s to multiply.\n *\n * @example\n * import { multiplyAll } from \"effect/BigInt\"\n *\n * assert.deepStrictEqual(multiplyAll([2n, 3n, 4n]), 24n)\n *\n * @category math\n * @since 2.0.0\n */\nexport const multiplyAll = collection => {\n  let out = bigint1;\n  for (const n of collection) {\n    if (n === bigint0) {\n      return bigint0;\n    }\n    out *= n;\n  }\n  return out;\n};\n/**\n * Takes a `bigint` and returns an `Option` of `number`.\n *\n * If the `bigint` is outside the safe integer range for JavaScript (`Number.MAX_SAFE_INTEGER`\n * and `Number.MIN_SAFE_INTEGER`), it returns `Option.none()`. Otherwise, it converts the `bigint`\n * to a number and returns `Option.some(number)`.\n *\n * @param b - The `bigint` to be converted to a `number`.\n *\n * @example\n * import { BigInt as BI, Option } from \"effect\"\n *\n * assert.deepStrictEqual(BI.toNumber(BigInt(42)), Option.some(42))\n * assert.deepStrictEqual(BI.toNumber(BigInt(Number.MAX_SAFE_INTEGER) + BigInt(1)), Option.none())\n * assert.deepStrictEqual(BI.toNumber(BigInt(Number.MIN_SAFE_INTEGER) - BigInt(1)), Option.none())\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const toNumber = b => {\n  if (b > BigInt(Number.MAX_SAFE_INTEGER) || b < BigInt(Number.MIN_SAFE_INTEGER)) {\n    return Option.none();\n  }\n  return Option.some(Number(b));\n};\n/**\n * Takes a string and returns an `Option` of `bigint`.\n *\n * If the string is empty or contains characters that cannot be converted into a `bigint`,\n * it returns `Option.none()`, otherwise, it returns `Option.some(bigint)`.\n *\n * @param s - The string to be converted to a `bigint`.\n *\n * @example\n * import { BigInt as BI, Option } from \"effect\"\n *\n * assert.deepStrictEqual(BI.fromString(\"42\"), Option.some(BigInt(42)))\n * assert.deepStrictEqual(BI.fromString(\" \"), Option.none())\n * assert.deepStrictEqual(BI.fromString(\"a\"), Option.none())\n *\n * @category conversions\n * @since 2.4.12\n */\nexport const fromString = s => {\n  try {\n    return s.trim() === \"\" ? Option.none() : Option.some(BigInt(s));\n  } catch (_) {\n    return Option.none();\n  }\n};\n/**\n * Takes a number and returns an `Option` of `bigint`.\n *\n * If the number is outside the safe integer range for JavaScript (`Number.MAX_SAFE_INTEGER`\n * and `Number.MIN_SAFE_INTEGER`), it returns `Option.none()`. Otherwise, it attempts to\n * convert the number to a `bigint` and returns `Option.some(bigint)`.\n *\n * @param n - The number to be converted to a `bigint`.\n *\n * @example\n * import { BigInt as BI, Option } from \"effect\"\n *\n * assert.deepStrictEqual(BI.fromNumber(42), Option.some(BigInt(42)))\n * assert.deepStrictEqual(BI.fromNumber(Number.MAX_SAFE_INTEGER + 1), Option.none())\n * assert.deepStrictEqual(BI.fromNumber(Number.MIN_SAFE_INTEGER - 1), Option.none())\n *\n * @category conversions\n * @since 2.4.12\n */\nexport const fromNumber = n => {\n  if (n > Number.MAX_SAFE_INTEGER || n < Number.MIN_SAFE_INTEGER) {\n    return Option.none();\n  }\n  try {\n    return Option.some(BigInt(n));\n  } catch (_) {\n    return Option.none();\n  }\n};\n//# sourceMappingURL=BigInt.js.map","/**\n * This module provides utility functions and type class instances for working with the `boolean` type in TypeScript.\n * It includes functions for basic boolean operations, as well as type class instances for\n * `Equivalence` and `Order`.\n *\n * @since 2.0.0\n */\nimport * as equivalence from \"./Equivalence.js\";\nimport { dual } from \"./Function.js\";\nimport * as order from \"./Order.js\";\nimport * as predicate from \"./Predicate.js\";\n/**\n * Tests if a value is a `boolean`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isBoolean } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(isBoolean(true), true)\n * assert.deepStrictEqual(isBoolean(\"true\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isBoolean = predicate.isBoolean;\n/**\n * This function returns the result of either of the given functions depending on the value of the boolean parameter.\n * It is useful when you have to run one of two functions depending on the boolean value.\n *\n * @param value - the boolean value that decides which function will be executed.\n * @param onFalse - a lazy evaluation function that will be executed when the `value` is `false`.\n * @param onTrue - a lazy evaluation function that will be executed when the `value` is `true`.\n *\n * @example\n * import { Boolean } from \"effect\"\n *\n * assert.deepStrictEqual(Boolean.match(true, { onFalse: () => \"It's false!\", onTrue: () => \"It's true!\" }), \"It's true!\")\n *\n * @category pattern matching\n * @since 2.0.0\n */\nexport const match = /*#__PURE__*/dual(2, (value, options) => value ? options.onTrue() : options.onFalse());\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Equivalence = equivalence.boolean;\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Order = order.boolean;\n/**\n * Negates the given boolean: `!self`\n *\n * @example\n * import { not } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(not(true), false)\n * assert.deepStrictEqual(not(false), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const not = self => !self;\n/**\n * Combines two boolean using AND: `self && that`.\n *\n * @example\n * import { and } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(and(true, true), true)\n * assert.deepStrictEqual(and(true, false), false)\n * assert.deepStrictEqual(and(false, true), false)\n * assert.deepStrictEqual(and(false, false), false)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const and = /*#__PURE__*/dual(2, (self, that) => self && that);\n/**\n * Combines two boolean using NAND: `!(self && that)`.\n *\n * @example\n * import { nand } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(nand(true, true), false)\n * assert.deepStrictEqual(nand(true, false), true)\n * assert.deepStrictEqual(nand(false, true), true)\n * assert.deepStrictEqual(nand(false, false), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const nand = /*#__PURE__*/dual(2, (self, that) => !(self && that));\n/**\n * Combines two boolean using OR: `self || that`.\n *\n * @example\n * import { or } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(or(true, true), true)\n * assert.deepStrictEqual(or(true, false), true)\n * assert.deepStrictEqual(or(false, true), true)\n * assert.deepStrictEqual(or(false, false), false)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const or = /*#__PURE__*/dual(2, (self, that) => self || that);\n/**\n * Combines two booleans using NOR: `!(self || that)`.\n *\n * @example\n * import { nor } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(nor(true, true), false)\n * assert.deepStrictEqual(nor(true, false), false)\n * assert.deepStrictEqual(nor(false, true), false)\n * assert.deepStrictEqual(nor(false, false), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const nor = /*#__PURE__*/dual(2, (self, that) => !(self || that));\n/**\n * Combines two booleans using XOR: `(!self && that) || (self && !that)`.\n *\n * @example\n * import { xor } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(xor(true, true), false)\n * assert.deepStrictEqual(xor(true, false), true)\n * assert.deepStrictEqual(xor(false, true), true)\n * assert.deepStrictEqual(xor(false, false), false)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const xor = /*#__PURE__*/dual(2, (self, that) => !self && that || self && !that);\n/**\n * Combines two booleans using EQV (aka XNOR): `!xor(self, that)`.\n *\n * @example\n * import { eqv } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(eqv(true, true), true)\n * assert.deepStrictEqual(eqv(true, false), false)\n * assert.deepStrictEqual(eqv(false, true), false)\n * assert.deepStrictEqual(eqv(false, false), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const eqv = /*#__PURE__*/dual(2, (self, that) => !xor(self, that));\n/**\n * Combines two booleans using an implication: `(!self || that)`.\n *\n * @example\n * import { implies } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(implies(true, true), true)\n * assert.deepStrictEqual(implies(true, false), false)\n * assert.deepStrictEqual(implies(false, true), true)\n * assert.deepStrictEqual(implies(false, false), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const implies = /*#__PURE__*/dual(2, (self, that) => self ? that : true);\n/**\n * This utility function is used to check if all the elements in a collection of boolean values are `true`.\n *\n * @param collection - An iterable collection of booleans.\n *\n * @example\n * import { every } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(every([true, true, true]), true)\n * assert.deepStrictEqual(every([true, false, true]), false)\n *\n * @since 2.0.0\n */\nexport const every = collection => {\n  for (const b of collection) {\n    if (!b) {\n      return false;\n    }\n  }\n  return true;\n};\n/**\n * This utility function is used to check if at least one of the elements in a collection of boolean values is `true`.\n *\n * @param collection - An iterable collection of booleans.\n *\n * @example\n * import { some } from \"effect/Boolean\"\n *\n * assert.deepStrictEqual(some([true, false, true]), true)\n * assert.deepStrictEqual(some([false, false, false]), false)\n *\n * @since 2.0.0\n */\nexport const some = collection => {\n  for (const b of collection) {\n    if (b) {\n      return true;\n    }\n  }\n  return false;\n};\n//# sourceMappingURL=Boolean.js.map","/**\n * This module provides types and utility functions to create and work with branded types,\n * which are TypeScript types with an added type tag to prevent accidental usage of a value in the wrong context.\n *\n * The `refined` and `nominal` functions are both used to create branded types in TypeScript.\n * The main difference between them is that `refined` allows for validation of the data, while `nominal` does not.\n *\n * The `nominal` function is used to create a new branded type that has the same underlying type as the input, but with a different name.\n * This is useful when you want to distinguish between two values of the same type that have different meanings.\n * The `nominal` function does not perform any validation of the input data.\n *\n * On the other hand, the `refined` function is used to create a new branded type that has the same underlying type as the input,\n * but with a different name, and it also allows for validation of the input data.\n * The `refined` function takes a predicate that is used to validate the input data.\n * If the input data fails the validation, a `BrandErrors` is returned, which provides information about the specific validation failure.\n *\n * @since 2.0.0\n */\nimport * as Arr from \"./Array.js\";\nimport * as Either from \"./Either.js\";\nimport { identity } from \"./Function.js\";\nimport * as Option from \"./Option.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const BrandTypeId = /*#__PURE__*/Symbol.for(\"effect/Brand\");\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const RefinedConstructorsTypeId = /*#__PURE__*/Symbol.for(\"effect/Brand/Refined\");\n/**\n * Returns a `BrandErrors` that contains a single `RefinementError`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const error = (message, meta) => [{\n  message,\n  meta\n}];\n/**\n * Takes a variable number of `BrandErrors` and returns a single `BrandErrors` that contains all refinement errors.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const errors = (...errors) => Arr.flatten(errors);\nexport function refined(...args) {\n  const either = args.length === 2 ? unbranded => args[0](unbranded) ? Either.right(unbranded) : Either.left(args[1](unbranded)) : unbranded => {\n    return Option.match(args[0](unbranded), {\n      onNone: () => Either.right(unbranded),\n      onSome: Either.left\n    });\n  };\n  return Object.assign(unbranded => Either.getOrThrowWith(either(unbranded), identity), {\n    [RefinedConstructorsTypeId]: RefinedConstructorsTypeId,\n    option: args => Option.getRight(either(args)),\n    either,\n    is: args => Either.isRight(either(args))\n  });\n}\n/**\n * This function returns a `Brand.Constructor` that **does not apply any runtime checks**, it just returns the provided value.\n * It can be used to create nominal types that allow distinguishing between two values of the same type but with different meanings.\n *\n * If you also want to perform some validation, see {@link refined}.\n *\n * @example\n * import { Brand } from \"effect\"\n *\n * type UserId = number & Brand.Brand<\"UserId\">\n *\n * const UserId = Brand.nominal<UserId>()\n *\n * assert.strictEqual(UserId(1), 1)\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const nominal = () => {\n  // @ts-expect-error\n  return Object.assign(args => args, {\n    [RefinedConstructorsTypeId]: RefinedConstructorsTypeId,\n    option: args => Option.some(args),\n    either: args => Either.right(args),\n    is: _args => true\n  });\n};\n/**\n * Combines two or more brands together to form a single branded type.\n * This API is useful when you want to validate that the input data passes multiple brand validators.\n *\n * @example\n * import { Brand } from \"effect\"\n *\n * type Int = number & Brand.Brand<\"Int\">\n * const Int = Brand.refined<Int>(\n *   (n) => Number.isInteger(n),\n *   (n) => Brand.error(`Expected ${n} to be an integer`)\n * )\n * type Positive = number & Brand.Brand<\"Positive\">\n * const Positive = Brand.refined<Positive>(\n *   (n) => n > 0,\n *   (n) => Brand.error(`Expected ${n} to be positive`)\n * )\n *\n * const PositiveInt = Brand.all(Int, Positive)\n *\n * assert.strictEqual(PositiveInt(1), 1)\n * assert.throws(() => PositiveInt(1.1))\n *\n * @since 2.0.0\n * @category combining\n */\nexport const all = (...brands) => {\n  const either = args => {\n    let result = Either.right(args);\n    for (const brand of brands) {\n      const nextResult = brand.either(args);\n      if (Either.isLeft(result) && Either.isLeft(nextResult)) {\n        result = Either.left([...result.left, ...nextResult.left]);\n      } else {\n        result = Either.isLeft(result) ? result : nextResult;\n      }\n    }\n    return result;\n  };\n  // @ts-expect-error\n  return Object.assign(args => Either.match(either(args), {\n    onLeft: e => {\n      throw e;\n    },\n    onRight: identity\n  }), {\n    [RefinedConstructorsTypeId]: RefinedConstructorsTypeId,\n    option: args => Option.getRight(either(args)),\n    either,\n    is: args => Either.isRight(either(args))\n  });\n};\n//# sourceMappingURL=Brand.js.map","import * as internal from \"./internal/cause.js\";\nimport * as core from \"./internal/core.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const CauseTypeId = internal.CauseTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const RuntimeExceptionTypeId = core.RuntimeExceptionTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const InterruptedExceptionTypeId = core.InterruptedExceptionTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const IllegalArgumentExceptionTypeId = core.IllegalArgumentExceptionTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const NoSuchElementExceptionTypeId = core.NoSuchElementExceptionTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const InvalidPubSubCapacityExceptionTypeId = core.InvalidPubSubCapacityExceptionTypeId;\n/**\n * @since 3.5.0\n * @category symbols\n */\nexport const ExceededCapacityExceptionTypeId = core.ExceededCapacityExceptionTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const TimeoutExceptionTypeId = core.TimeoutExceptionTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const UnknownExceptionTypeId = core.UnknownExceptionTypeId;\n/**\n * Represents a generic checked exception which occurs at runtime.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const YieldableError = core.YieldableError;\n/**\n * Constructs a new `Empty` cause.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * Constructs a new `Fail` cause from the specified `error`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = internal.fail;\n/**\n * Constructs a new `Die` cause from the specified `defect`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const die = internal.die;\n/**\n * Constructs a new `Interrupt` cause from the specified `fiberId`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const interrupt = internal.interrupt;\n/**\n * Constructs a new `Parallel` cause from the specified `left` and `right`\n * causes.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const parallel = internal.parallel;\n/**\n * Constructs a new `Sequential` cause from the specified pecified `left` and\n * `right` causes.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sequential = internal.sequential;\n/**\n * Returns `true` if the specified value is a `Cause`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isCause = internal.isCause;\n/**\n * Returns `true` if the specified `Cause` is an `Empty` type, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isEmptyType = internal.isEmptyType;\n/**\n * Returns `true` if the specified `Cause` is a `Fail` type, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isFailType = internal.isFailType;\n/**\n * Returns `true` if the specified `Cause` is a `Die` type, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isDieType = internal.isDieType;\n/**\n * Returns `true` if the specified `Cause` is an `Interrupt` type, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isInterruptType = internal.isInterruptType;\n/**\n * Returns `true` if the specified `Cause` is a `Sequential` type, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isSequentialType = internal.isSequentialType;\n/**\n * Returns `true` if the specified `Cause` is a `Parallel` type, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isParallelType = internal.isParallelType;\n/**\n * Returns the size of the cause, calculated as the number of individual `Cause`\n * nodes found in the `Cause` semiring structure.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const size = internal.size;\n/**\n * Returns `true` if the specified cause is empty, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isEmpty = internal.isEmpty;\n/**\n * Returns `true` if the specified cause contains a failure, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isFailure = internal.isFailure;\n/**\n * Returns `true` if the specified cause contains a defect, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isDie = internal.isDie;\n/**\n * Returns `true` if the specified cause contains an interruption, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isInterrupted = internal.isInterrupted;\n/**\n * Returns `true` if the specified cause contains only interruptions (without\n * any `Die` or `Fail` causes), `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isInterruptedOnly = internal.isInterruptedOnly;\n/**\n * Returns a `List` of all recoverable errors of type `E` in the specified\n * cause.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const failures = internal.failures;\n/**\n * Returns a `List` of all unrecoverable defects in the specified cause.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const defects = internal.defects;\n/**\n * Returns a `HashSet` of `FiberId`s for all fibers that interrupted the fiber\n * described by the specified cause.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const interruptors = internal.interruptors;\n/**\n * Returns the `E` associated with the first `Fail` in this `Cause`, if one\n * exists.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const failureOption = internal.failureOption;\n/**\n * Returns the first checked error on the `Left` if available, if there are\n * no checked errors return the rest of the `Cause` that is known to contain\n * only `Die` or `Interrupt` causes.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const failureOrCause = internal.failureOrCause;\n/**\n * Converts the specified `Cause<Option<E>>` to an `Option<Cause<E>>` by\n * recursively stripping out any failures with the error `None`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const flipCauseOption = internal.flipCauseOption;\n/**\n * Returns the defect associated with the first `Die` in this `Cause`, if one\n * exists.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const dieOption = internal.dieOption;\n/**\n * Returns the `FiberId` associated with the first `Interrupt` in the specified\n * cause, if one exists.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const interruptOption = internal.interruptOption;\n/**\n * Remove all `Fail` and `Interrupt` nodes from the specified cause, and return\n * a cause containing only `Die` cause/finalizer defects.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const keepDefects = internal.keepDefects;\n/**\n * Linearizes the specified cause into a `HashSet` of parallel causes where each\n * parallel cause contains a linear sequence of failures.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const linearize = internal.linearize;\n/**\n * Remove all `Fail` and `Interrupt` nodes from the specified cause, and return\n * a cause containing only `Die` cause/finalizer defects.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const stripFailures = internal.stripFailures;\n/**\n * Remove all `Die` causes that the specified partial function is defined at,\n * returning `Some` with the remaining causes or `None` if there are no\n * remaining causes.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const stripSomeDefects = internal.stripSomeDefects;\n/**\n * @since 2.0.0\n * @category mapping\n */\nexport const as = internal.as;\n/**\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = internal.flatMap;\n/**\n * Executes a sequence of two `Cause`s. The second `Cause` can be dependent on the result of the first `Cause`.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const andThen = internal.andThen;\n/**\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatten = internal.flatten;\n/**\n * Returns `true` if the `self` cause contains or is equal to `that` cause,\n * `false` otherwise.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const contains = internal.contains;\n/**\n * Squashes a `Cause` down to a single defect, chosen to be the \"most important\"\n * defect.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const squash = core.causeSquash;\n/**\n * Squashes a `Cause` down to a single defect, chosen to be the \"most important\"\n * defect. If a recoverable error is found, the provided function will be used\n * to map the error a defect, and the resulting value will be returned.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const squashWith = core.causeSquashWith;\n/**\n * Uses the provided partial function to search the specified cause and attempt\n * to extract information from it.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const find = internal.find;\n/**\n * Filters causes which match the provided predicate out of the specified cause.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filter = internal.filter;\n/**\n * Folds the specified cause into a value of type `Z`.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const match = internal.match;\n/**\n * Reduces the specified cause into a value of type `Z`, beginning with the\n * provided `zero` value.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduce = internal.reduce;\n/**\n * Reduces the specified cause into a value of type `Z` using a `Cause.Reducer`.\n * Also allows for accessing the provided context during reduction.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduceWithContext = internal.reduceWithContext;\n/**\n * Represents a checked exception which occurs when a `Fiber` is interrupted.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const InterruptedException = core.InterruptedException;\n/**\n * Returns `true` if the specified value is an `InterruptedException`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isInterruptedException = core.isInterruptedException;\n/**\n * Represents a checked exception which occurs when an invalid argument is\n * provided to a method.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const IllegalArgumentException = core.IllegalArgumentException;\n/**\n * Returns `true` if the specified value is an `IllegalArgumentException`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isIllegalArgumentException = core.isIllegalArgumentException;\n/**\n * Represents a checked exception which occurs when an expected element was\n * unable to be found.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const NoSuchElementException = core.NoSuchElementException;\n/**\n * Returns `true` if the specified value is an `NoSuchElementException`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isNoSuchElementException = core.isNoSuchElementException;\n/**\n * Represents a generic checked exception which occurs at runtime.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const RuntimeException = core.RuntimeException;\n/**\n * Returns `true` if the specified value is an `RuntimeException`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isRuntimeException = core.isRuntimeException;\n/**\n * Represents a checked exception which occurs when a computation doesn't\n * finish on schedule.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const TimeoutException = core.TimeoutException;\n/**\n * Represents a checked exception which occurs when an unknown error is thrown, such as\n * from a rejected promise.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const UnknownException = core.UnknownException;\n/**\n * Returns `true` if the specified value is an `UnknownException`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isUnknownException = core.isUnknownException;\n/**\n * Represents a checked exception which occurs when a resources capacity has\n * been exceeded.\n *\n * @since 3.5.0\n * @category errors\n */\nexport const ExceededCapacityException = core.ExceededCapacityException;\n/**\n * Returns `true` if the specified value is an `ExceededCapacityException`, `false`\n * otherwise.\n *\n * @since 3.5.0\n * @category refinements\n */\nexport const isExceededCapacityException = core.isExceededCapacityException;\n/**\n * Returns the specified `Cause` as a pretty-printed string.\n *\n * @since 2.0.0\n * @category rendering\n */\nexport const pretty = internal.pretty;\n/**\n * Returns the specified `Cause` as a pretty-printed string.\n *\n * @since 3.2.0\n * @category rendering\n */\nexport const prettyErrors = internal.prettyErrors;\n/**\n * Returns the original, unproxied, instance of a thrown error\n *\n * @since 2.0.0\n * @category errors\n */\nexport const originalError = core.originalInstance;\n//# sourceMappingURL=Cause.js.map","import * as channel from \"./internal/channel.js\";\nimport * as core from \"./internal/core-stream.js\";\nimport * as sink from \"./internal/sink.js\";\nimport * as stream from \"./internal/stream.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const ChannelTypeId = core.ChannelTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const ChannelExceptionTypeId = channel.ChannelExceptionTypeId;\n/**\n * @since 3.5.4\n * @category refinements\n */\nexport const isChannel = core.isChannel;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const acquireUseRelease = channel.acquireUseRelease;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const acquireReleaseOut = core.acquireReleaseOut;\n/**\n * Returns a new channel that is the same as this one, except the terminal\n * value of the channel is the specified constant value.\n *\n * This method produces the same result as mapping this channel to the\n * specified constant value.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const as = channel.as;\n/**\n * @since 2.0.0\n * @category mapping\n */\nexport const asVoid = channel.asVoid;\n/**\n * Creates a channel backed by a buffer. When the buffer is empty, the channel\n * will simply passthrough its input as output. However, when the buffer is\n * non-empty, the value inside the buffer will be passed along as output.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const buffer = channel.buffer;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const bufferChunk = channel.bufferChunk;\n/**\n * Returns a new channel that is the same as this one, except if this channel\n * errors for any typed error, then the returned channel will switch over to\n * using the fallback channel returned by the specified error handler.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAll = channel.catchAll;\n/**\n * Returns a new channel that is the same as this one, except if this channel\n * errors for any typed error, then the returned channel will switch over to\n * using the fallback channel returned by the specified error handler.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAllCause = core.catchAllCause;\n/**\n * Concat sequentially a channel of channels.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const concatAll = core.concatAll;\n/**\n * Concat sequentially a channel of channels.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const concatAllWith = core.concatAllWith;\n/**\n * Returns a new channel whose outputs are fed to the specified factory\n * function, which creates new channels in response. These new channels are\n * sequentially concatenated together, and all their outputs appear as outputs\n * of the newly returned channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const concatMap = channel.concatMap;\n/**\n * Returns a new channel whose outputs are fed to the specified factory\n * function, which creates new channels in response. These new channels are\n * sequentially concatenated together, and all their outputs appear as outputs\n * of the newly returned channel. The provided merging function is used to\n * merge the terminal values of all channels into the single terminal value of\n * the returned channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const concatMapWith = core.concatMapWith;\n/**\n * Returns a new channel whose outputs are fed to the specified factory\n * function, which creates new channels in response. These new channels are\n * sequentially concatenated together, and all their outputs appear as outputs\n * of the newly returned channel. The provided merging function is used to\n * merge the terminal values of all channels into the single terminal value of\n * the returned channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const concatMapWithCustom = core.concatMapWithCustom;\n/**\n * Returns a new channel, which is the same as this one, except its outputs\n * are filtered and transformed by the specified partial function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const collect = channel.collect;\n/**\n * Returns a new channel, which is the concatenation of all the channels that\n * are written out by this channel. This method may only be called on channels\n * that output other channels.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const concatOut = channel.concatOut;\n/**\n * Returns a new channel which is the same as this one but applies the given\n * function to the input channel's done value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapInput = channel.mapInput;\n/**\n * Returns a new channel which is the same as this one but applies the given\n * effectual function to the input channel's done value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapInputEffect = channel.mapInputEffect;\n/**\n * Returns a new channel which is the same as this one but applies the given\n * function to the input channel's error value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapInputError = channel.mapInputError;\n/**\n * Returns a new channel which is the same as this one but applies the given\n * effectual function to the input channel's error value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapInputErrorEffect = channel.mapInputErrorEffect;\n/**\n * Returns a new channel which is the same as this one but applies the given\n * function to the input channel's output elements.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapInputIn = channel.mapInputIn;\n/**\n * Returns a new channel which is the same as this one but applies the given\n * effectual function to the input channel's output elements.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapInputInEffect = channel.mapInputInEffect;\n/**\n * Returns a new channel, which is the same as this one, except that all the\n * outputs are collected and bundled into a tuple together with the terminal\n * value of this channel.\n *\n * As the channel returned from this channel collects all of this channel's\n * output into an in- memory chunk, it is not safe to call this method on\n * channels that output a large or unbounded number of values.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const doneCollect = channel.doneCollect;\n/**\n * Returns a new channel which reads all the elements from upstream's output\n * channel and ignores them, then terminates with the upstream result value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const drain = channel.drain;\n/**\n * Returns a new channel which connects the given `AsyncInputProducer` as\n * this channel's input.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const embedInput = core.embedInput;\n/**\n * Returns a new channel that collects the output and terminal value of this\n * channel, which it then writes as output of the returned channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const emitCollect = channel.emitCollect;\n/**\n * Returns a new channel with an attached finalizer. The finalizer is\n * guaranteed to be executed so long as the channel begins execution (and\n * regardless of whether or not it completes).\n *\n * @since 2.0.0\n * @category utils\n */\nexport const ensuring = channel.ensuring;\n/**\n * Returns a new channel with an attached finalizer. The finalizer is\n * guaranteed to be executed so long as the channel begins execution (and\n * regardless of whether or not it completes).\n *\n * @since 2.0.0\n * @category utils\n */\nexport const ensuringWith = core.ensuringWith;\n/**\n * Accesses the whole context of the channel.\n *\n * @since 2.0.0\n * @category context\n */\nexport const context = channel.context;\n/**\n * Accesses the context of the channel with the specified function.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWith = channel.contextWith;\n/**\n * Accesses the context of the channel in the context of a channel.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWithChannel = channel.contextWithChannel;\n/**\n * Accesses the context of the channel in the context of an effect.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWithEffect = channel.contextWithEffect;\n/**\n * Constructs a channel that fails immediately with the specified error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = core.fail;\n/**\n * Constructs a channel that succeeds immediately with the specified lazily\n * evaluated value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failSync = core.failSync;\n/**\n * Constructs a channel that fails immediately with the specified `Cause`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCause = core.failCause;\n/**\n * Constructs a channel that succeeds immediately with the specified lazily\n * evaluated `Cause`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCauseSync = core.failCauseSync;\n/**\n * Returns a new channel, which sequentially combines this channel, together\n * with the provided factory function, which creates a second channel based on\n * the terminal value of this channel. The result is a channel that will first\n * perform the functions of this channel, before performing the functions of\n * the created channel (including yielding its terminal value).\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = core.flatMap;\n/**\n * Returns a new channel, which flattens the terminal value of this channel.\n * This function may only be called if the terminal value of this channel is\n * another channel of compatible types.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatten = channel.flatten;\n/**\n * Folds over the result of this channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const foldChannel = channel.foldChannel;\n/**\n * Folds over the result of this channel including any cause of termination.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const foldCauseChannel = core.foldCauseChannel;\n/**\n * Use an effect to end a channel.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromEffect = core.fromEffect;\n/**\n * Constructs a channel from an `Either`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromEither = channel.fromEither;\n/**\n * Construct a `Channel` from an `AsyncInputConsumer`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromInput = channel.fromInput;\n/**\n * Construct a `Channel` from a `PubSub`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromPubSub = channel.fromPubSub;\n/**\n * Construct a `Channel` from a `PubSub` within a scoped effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromPubSubScoped = channel.fromPubSubScoped;\n/**\n * Construct a `Channel` from an `Option`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromOption = channel.fromOption;\n/**\n * Construct a `Channel` from a `Queue`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromQueue = channel.fromQueue;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const identity = channel.identityChannel;\n/**\n * Returns a new channel, which is the same as this one, except it will be\n * interrupted when the specified effect completes. If the effect completes\n * successfully before the underlying channel is done, then the returned\n * channel will yield the success value of the effect as its terminal value.\n * On the other hand, if the underlying channel finishes first, then the\n * returned channel will yield the success value of the underlying channel as\n * its terminal value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptWhen = channel.interruptWhen;\n/**\n * Returns a new channel, which is the same as this one, except it will be\n * interrupted when the specified deferred is completed. If the deferred is\n * completed before the underlying channel is done, then the returned channel\n * will yield the value of the deferred. Otherwise, if the underlying channel\n * finishes first, then the returned channel will yield the value of the\n * underlying channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptWhenDeferred = channel.interruptWhenDeferred;\n/**\n * Returns a new channel, which is the same as this one, except the terminal\n * value of the returned channel is created by applying the specified function\n * to the terminal value of this channel.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = channel.map;\n/**\n * Returns a new channel, which is the same as this one, except the terminal\n * value of the returned channel is created by applying the specified\n * effectful function to the terminal value of this channel.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapEffect = channel.mapEffect;\n/**\n * Returns a new channel, which is the same as this one, except the failure\n * value of the returned channel is created by applying the specified function\n * to the failure value of this channel.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapError = channel.mapError;\n/**\n * A more powerful version of `mapError` which also surfaces the `Cause`\n * of the channel failure.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapErrorCause = channel.mapErrorCause;\n/**\n * Maps the output of this channel using the specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapOut = channel.mapOut;\n/**\n * Creates a channel that is like this channel but the given effectful function\n * gets applied to each emitted output element.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapOutEffect = channel.mapOutEffect;\n/**\n * Creates a channel that is like this channel but the given ZIO function gets\n * applied to each emitted output element, taking `n` elements at once and\n * mapping them in parallel.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapOutEffectPar = channel.mapOutEffectPar;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const mergeAll = channel.mergeAll;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const mergeAllUnbounded = channel.mergeAllUnbounded;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const mergeAllUnboundedWith = channel.mergeAllUnboundedWith;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const mergeAllWith = channel.mergeAllWith;\n/**\n * Returns a new channel which creates a new channel for each emitted element\n * and merges some of them together. Different merge strategies control what\n * happens if there are more than the given maximum number of channels gets\n * created. See `Channel.mergeAll`.\n *\n * @param n The maximum number of channels to merge.\n * @param f The function that creates a new channel from each emitted element.\n * @since 2.0.0\n * @category mapping\n */\nexport const mergeMap = channel.mergeMap;\n/**\n * Returns a new channel which merges a number of channels emitted by this\n * channel using the back pressuring merge strategy. See `Channel.mergeAll`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeOut = channel.mergeOut;\n/**\n * Returns a new channel which merges a number of channels emitted by this\n * channel using the back pressuring merge strategy and uses a given function\n * to merge each completed subchannel's result value. See\n * `Channel.mergeAll`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeOutWith = channel.mergeOutWith;\n/**\n * Returns a new channel, which is the merge of this channel and the specified\n * channel, where the behavior of the returned channel on left or right early\n * termination is decided by the specified `leftDone` and `rightDone` merge\n * decisions.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeWith = channel.mergeWith;\n/**\n * Returns a channel that never completes\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const never = channel.never;\n/**\n * Translates channel failure into death of the fiber, making all failures\n * unchecked and not a part of the type of the channel.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orDie = channel.orDie;\n/**\n * Keeps none of the errors, and terminates the fiber with them, using the\n * specified function to convert the `OutErr` into a defect.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orDieWith = channel.orDieWith;\n/**\n * Returns a new channel that will perform the operations of this one, until\n * failure, and then it will switch over to the operations of the specified\n * fallback channel.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElse = channel.orElse;\n/**\n * Returns a new channel that pipes the output of this channel into the\n * specified channel. The returned channel has the input type of this channel,\n * and the output type of the specified channel, terminating with the value of\n * the specified channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const pipeTo = core.pipeTo;\n/**\n * Returns a new channel that pipes the output of this channel into the\n * specified channel and preserves this channel's failures without providing\n * them to the other channel for observation.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const pipeToOrFail = channel.pipeToOrFail;\n/**\n * Provides the channel with its required context, which eliminates its\n * dependency on `Env`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideContext = core.provideContext;\n/**\n * Provides a layer to the channel, which translates it to another level.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideLayer = channel.provideLayer;\n/**\n * Transforms the context being provided to the channel with the specified\n * function.\n *\n * @since 2.0.0\n * @category context\n */\nexport const mapInputContext = channel.mapInputContext;\n/**\n * Splits the context into two parts, providing one part using the\n * specified layer and leaving the remainder `Env0`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideSomeLayer = channel.provideSomeLayer;\n/**\n * Provides the effect with the single service it requires. If the effect\n * requires more than one service use `provideContext` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideService = channel.provideService;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const read = channel.read;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const readOrFail = core.readOrFail;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const readWith = core.readWith;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const readWithCause = core.readWithCause;\n/**\n * Creates a channel which repeatedly runs this channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeated = channel.repeated;\n/**\n * Runs a channel until the end is received.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const run = channel.run;\n/**\n * Run the channel until it finishes with a done value or fails with an error\n * and collects its emitted output elements.\n *\n * The channel must not read any input.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runCollect = channel.runCollect;\n/**\n * Runs a channel until the end is received.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runDrain = channel.runDrain;\n/**\n * Use a scoped effect to emit an output element.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const scoped = channel.scoped;\n/**\n * Splits strings on newlines. Handles both Windows newlines (`\\r\\n`) and UNIX\n * newlines (`\\n`).\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const splitLines = channel.splitLines;\n/**\n * Constructs a channel that succeeds immediately with the specified value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = core.succeed;\n/**\n * Lazily constructs a channel from the given side effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const suspend = core.suspend;\n/**\n * Constructs a channel that succeeds immediately with the specified lazy value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sync = core.sync;\n/**\n * Converts a `Channel` to a `PubSub`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toPubSub = channel.toPubSub;\n/**\n * Returns a scoped `Effect` that can be used to repeatedly pull elements from\n * the constructed `Channel`. The pull effect fails with the channel's failure\n * in case the channel fails, or returns either the channel's done value or an\n * emitted element.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toPull = channel.toPull;\n/**\n * Converts a `Channel` to a `Queue`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toQueue = channel.toQueue;\n/** Converts this channel to a `Sink`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toSink = sink.channelToSink;\n/**\n * Converts this channel to a `Stream`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toStream = stream.channelToStream;\nconst void_ = core.void;\nexport {\n/**\n * @since 2.0.0\n * @category constructors\n */\nvoid_ as void };\n/**\n * Makes a channel from an effect that returns a channel in case of success.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrap = channel.unwrap;\n/**\n * Makes a channel from a managed that returns a channel in case of success.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrapScoped = channel.unwrapScoped;\n/**\n * Updates a service in the context of this channel.\n *\n * @since 2.0.0\n * @category context\n */\nexport const updateService = channel.updateService;\n/**\n * Wraps the channel with a new span for tracing.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const withSpan = channel.withSpan;\n/**\n * Writes a single value to the channel.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const write = core.write;\n/**\n * Writes a sequence of values to the channel.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const writeAll = channel.writeAll;\n/**\n * Writes a `Chunk` of values to the channel.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const writeChunk = channel.writeChunk;\n/**\n * Returns a new channel that is the sequential composition of this channel\n * and the specified channel. The returned channel terminates with a tuple of\n * the terminal values of both channels.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = channel.zip;\n/**\n * Returns a new channel that is the sequential composition of this channel\n * and the specified channel. The returned channel terminates with the\n * terminal value of this channel.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = channel.zipLeft;\n/**\n * Returns a new channel that is the sequential composition of this channel\n * and the specified channel. The returned channel terminates with the\n * terminal value of that channel.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = channel.zipRight;\n/**\n * Represents a generic checked exception which occurs when a `Channel` is\n * executed.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const ChannelException = channel.ChannelException;\n/**\n * Returns `true` if the specified value is an `ChannelException`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isChannelException = channel.isChannelException;\n//# sourceMappingURL=Channel.js.map","/**\n * @since 2.0.0\n */\nimport * as RA from \"./Array.js\";\nimport * as Equal from \"./Equal.js\";\nimport * as Equivalence from \"./Equivalence.js\";\nimport { dual, identity, pipe } from \"./Function.js\";\nimport * as Hash from \"./Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"./Inspectable.js\";\nimport * as O from \"./Option.js\";\nimport * as Order from \"./Order.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nimport { hasProperty } from \"./Predicate.js\";\nconst TypeId = /*#__PURE__*/Symbol.for(\"effect/Chunk\");\nfunction copy(src, srcPos, dest, destPos, len) {\n  for (let i = srcPos; i < Math.min(src.length, srcPos + len); i++) {\n    dest[destPos + i - srcPos] = src[i];\n  }\n  return dest;\n}\nconst emptyArray = [];\n/**\n * Compares the two chunks of equal length using the specified function\n *\n * @category equivalence\n * @since 2.0.0\n */\nexport const getEquivalence = isEquivalent => Equivalence.make((self, that) => self.length === that.length && toReadonlyArray(self).every((value, i) => isEquivalent(value, unsafeGet(that, i))));\nconst _equivalence = /*#__PURE__*/getEquivalence(Equal.equals);\nconst ChunkProto = {\n  [TypeId]: {\n    _A: _ => _\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"Chunk\",\n      values: toReadonlyArray(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  [Equal.symbol](that) {\n    return isChunk(that) && _equivalence(this, that);\n  },\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.array(toReadonlyArray(this)));\n  },\n  [Symbol.iterator]() {\n    switch (this.backing._tag) {\n      case \"IArray\":\n        {\n          return this.backing.array[Symbol.iterator]();\n        }\n      case \"IEmpty\":\n        {\n          return emptyArray[Symbol.iterator]();\n        }\n      default:\n        {\n          return toReadonlyArray(this)[Symbol.iterator]();\n        }\n    }\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst makeChunk = backing => {\n  const chunk = Object.create(ChunkProto);\n  chunk.backing = backing;\n  switch (backing._tag) {\n    case \"IEmpty\":\n      {\n        chunk.length = 0;\n        chunk.depth = 0;\n        chunk.left = chunk;\n        chunk.right = chunk;\n        break;\n      }\n    case \"IConcat\":\n      {\n        chunk.length = backing.left.length + backing.right.length;\n        chunk.depth = 1 + Math.max(backing.left.depth, backing.right.depth);\n        chunk.left = backing.left;\n        chunk.right = backing.right;\n        break;\n      }\n    case \"IArray\":\n      {\n        chunk.length = backing.array.length;\n        chunk.depth = 0;\n        chunk.left = _empty;\n        chunk.right = _empty;\n        break;\n      }\n    case \"ISingleton\":\n      {\n        chunk.length = 1;\n        chunk.depth = 0;\n        chunk.left = _empty;\n        chunk.right = _empty;\n        break;\n      }\n    case \"ISlice\":\n      {\n        chunk.length = backing.length;\n        chunk.depth = backing.chunk.depth + 1;\n        chunk.left = _empty;\n        chunk.right = _empty;\n        break;\n      }\n  }\n  return chunk;\n};\n/**\n * Checks if `u` is a `Chunk<unknown>`\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const isChunk = u => hasProperty(u, TypeId);\nconst _empty = /*#__PURE__*/makeChunk({\n  _tag: \"IEmpty\"\n});\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const empty = () => _empty;\n/**\n * Builds a `NonEmptyChunk` from an non-empty collection of elements.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const make = (...as) => as.length === 1 ? of(as[0]) : unsafeFromNonEmptyArray(as);\n/**\n * Builds a `NonEmptyChunk` from a single element.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const of = a => makeChunk({\n  _tag: \"ISingleton\",\n  a\n});\n/**\n * Creates a new `Chunk` from an iterable collection of values.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const fromIterable = self => isChunk(self) ? self : makeChunk({\n  _tag: \"IArray\",\n  array: RA.fromIterable(self)\n});\nconst copyToArray = (self, array, initial) => {\n  switch (self.backing._tag) {\n    case \"IArray\":\n      {\n        copy(self.backing.array, 0, array, initial, self.length);\n        break;\n      }\n    case \"IConcat\":\n      {\n        copyToArray(self.left, array, initial);\n        copyToArray(self.right, array, initial + self.left.length);\n        break;\n      }\n    case \"ISingleton\":\n      {\n        array[initial] = self.backing.a;\n        break;\n      }\n    case \"ISlice\":\n      {\n        let i = 0;\n        let j = initial;\n        while (i < self.length) {\n          array[j] = unsafeGet(self, i);\n          i += 1;\n          j += 1;\n        }\n        break;\n      }\n  }\n};\nconst toArray_ = self => toReadonlyArray(self).slice();\n/**\n * Converts a `Chunk` into an `Array`. If the provided `Chunk` is non-empty\n * (`NonEmptyChunk`), the function will return a `NonEmptyArray`, ensuring the\n * non-empty property is preserved.\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const toArray = toArray_;\nconst toReadonlyArray_ = self => {\n  switch (self.backing._tag) {\n    case \"IEmpty\":\n      {\n        return emptyArray;\n      }\n    case \"IArray\":\n      {\n        return self.backing.array;\n      }\n    default:\n      {\n        const arr = new Array(self.length);\n        copyToArray(self, arr, 0);\n        self.backing = {\n          _tag: \"IArray\",\n          array: arr\n        };\n        self.left = _empty;\n        self.right = _empty;\n        self.depth = 0;\n        return arr;\n      }\n  }\n};\n/**\n * Converts a `Chunk` into a `ReadonlyArray`. If the provided `Chunk` is\n * non-empty (`NonEmptyChunk`), the function will return a\n * `NonEmptyReadonlyArray`, ensuring the non-empty property is preserved.\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const toReadonlyArray = toReadonlyArray_;\nconst reverseChunk = self => {\n  switch (self.backing._tag) {\n    case \"IEmpty\":\n    case \"ISingleton\":\n      return self;\n    case \"IArray\":\n      {\n        return makeChunk({\n          _tag: \"IArray\",\n          array: RA.reverse(self.backing.array)\n        });\n      }\n    case \"IConcat\":\n      {\n        return makeChunk({\n          _tag: \"IConcat\",\n          left: reverse(self.backing.right),\n          right: reverse(self.backing.left)\n        });\n      }\n    case \"ISlice\":\n      return unsafeFromArray(RA.reverse(toReadonlyArray(self)));\n  }\n};\n/**\n * Reverses the order of elements in a `Chunk`.\n * Importantly, if the input chunk is a `NonEmptyChunk`, the reversed chunk will also be a `NonEmptyChunk`.\n *\n * @example\n * import { Chunk } from \"effect\"\n *\n * const numbers = Chunk.make(1, 2, 3)\n * const reversedNumbers = Chunk.reverse(numbers)\n * assert.deepStrictEqual(reversedNumbers, Chunk.make(3, 2, 1))\n *\n * @since 2.0.0\n * @category elements\n */\nexport const reverse = reverseChunk;\n/**\n * This function provides a safe way to read a value at a particular index from a `Chunk`.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const get = /*#__PURE__*/dual(2, (self, index) => index < 0 || index >= self.length ? O.none() : O.some(unsafeGet(self, index)));\n/**\n * Wraps an array into a chunk without copying, unsafe on mutable arrays\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeFromArray = self => makeChunk({\n  _tag: \"IArray\",\n  array: self\n});\n/**\n * Wraps an array into a chunk without copying, unsafe on mutable arrays\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeFromNonEmptyArray = self => unsafeFromArray(self);\n/**\n * Gets an element unsafely, will throw on out of bounds\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeGet = /*#__PURE__*/dual(2, (self, index) => {\n  switch (self.backing._tag) {\n    case \"IEmpty\":\n      {\n        throw new Error(`Index out of bounds`);\n      }\n    case \"ISingleton\":\n      {\n        if (index !== 0) {\n          throw new Error(`Index out of bounds`);\n        }\n        return self.backing.a;\n      }\n    case \"IArray\":\n      {\n        if (index >= self.length || index < 0) {\n          throw new Error(`Index out of bounds`);\n        }\n        return self.backing.array[index];\n      }\n    case \"IConcat\":\n      {\n        return index < self.left.length ? unsafeGet(self.left, index) : unsafeGet(self.right, index - self.left.length);\n      }\n    case \"ISlice\":\n      {\n        return unsafeGet(self.backing.chunk, index + self.backing.offset);\n      }\n  }\n});\n/**\n * Appends the specified element to the end of the `Chunk`.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const append = /*#__PURE__*/dual(2, (self, a) => appendAll(self, of(a)));\n/**\n * Prepend an element to the front of a `Chunk`, creating a new `NonEmptyChunk`.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prepend = /*#__PURE__*/dual(2, (self, elem) => appendAll(of(elem), self));\n/**\n * Takes the first up to `n` elements from the chunk\n *\n * @since 2.0.0\n */\nexport const take = /*#__PURE__*/dual(2, (self, n) => {\n  if (n <= 0) {\n    return _empty;\n  } else if (n >= self.length) {\n    return self;\n  } else {\n    switch (self.backing._tag) {\n      case \"ISlice\":\n        {\n          return makeChunk({\n            _tag: \"ISlice\",\n            chunk: self.backing.chunk,\n            length: n,\n            offset: self.backing.offset\n          });\n        }\n      case \"IConcat\":\n        {\n          if (n > self.left.length) {\n            return makeChunk({\n              _tag: \"IConcat\",\n              left: self.left,\n              right: take(self.right, n - self.left.length)\n            });\n          }\n          return take(self.left, n);\n        }\n      default:\n        {\n          return makeChunk({\n            _tag: \"ISlice\",\n            chunk: self,\n            offset: 0,\n            length: n\n          });\n        }\n    }\n  }\n});\n/**\n * Drops the first up to `n` elements from the chunk\n *\n * @since 2.0.0\n */\nexport const drop = /*#__PURE__*/dual(2, (self, n) => {\n  if (n <= 0) {\n    return self;\n  } else if (n >= self.length) {\n    return _empty;\n  } else {\n    switch (self.backing._tag) {\n      case \"ISlice\":\n        {\n          return makeChunk({\n            _tag: \"ISlice\",\n            chunk: self.backing.chunk,\n            offset: self.backing.offset + n,\n            length: self.backing.length - n\n          });\n        }\n      case \"IConcat\":\n        {\n          if (n > self.left.length) {\n            return drop(self.right, n - self.left.length);\n          }\n          return makeChunk({\n            _tag: \"IConcat\",\n            left: drop(self.left, n),\n            right: self.right\n          });\n        }\n      default:\n        {\n          return makeChunk({\n            _tag: \"ISlice\",\n            chunk: self,\n            offset: n,\n            length: self.length - n\n          });\n        }\n    }\n  }\n});\n/**\n * Drops the last `n` elements.\n *\n * @since 2.0.0\n */\nexport const dropRight = /*#__PURE__*/dual(2, (self, n) => take(self, Math.max(0, self.length - n)));\n/**\n * Drops all elements so long as the predicate returns true.\n *\n * @since 2.0.0\n */\nexport const dropWhile = /*#__PURE__*/dual(2, (self, predicate) => {\n  const arr = toReadonlyArray(self);\n  const len = arr.length;\n  let i = 0;\n  while (i < len && predicate(arr[i])) {\n    i++;\n  }\n  return drop(self, i);\n});\n/**\n * Prepends the specified prefix chunk to the beginning of the specified chunk.\n * If either chunk is non-empty, the result is also a non-empty chunk.\n *\n * @example\n * import { Chunk } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Chunk.make(1, 2).pipe(Chunk.prependAll(Chunk.make(\"a\", \"b\")), Chunk.toArray),\n *   [\"a\", \"b\", 1, 2]\n * )\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prependAll = /*#__PURE__*/dual(2, (self, that) => appendAll(that, self));\n/**\n * Concatenates two chunks, combining their elements.\n * If either chunk is non-empty, the result is also a non-empty chunk.\n *\n * @example\n * import { Chunk } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Chunk.make(1, 2).pipe(Chunk.appendAll(Chunk.make(\"a\", \"b\")), Chunk.toArray),\n *   [1, 2, \"a\", \"b\"]\n * )\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const appendAll = /*#__PURE__*/dual(2, (self, that) => {\n  if (self.backing._tag === \"IEmpty\") {\n    return that;\n  }\n  if (that.backing._tag === \"IEmpty\") {\n    return self;\n  }\n  const diff = that.depth - self.depth;\n  if (Math.abs(diff) <= 1) {\n    return makeChunk({\n      _tag: \"IConcat\",\n      left: self,\n      right: that\n    });\n  } else if (diff < -1) {\n    if (self.left.depth >= self.right.depth) {\n      const nr = appendAll(self.right, that);\n      return makeChunk({\n        _tag: \"IConcat\",\n        left: self.left,\n        right: nr\n      });\n    } else {\n      const nrr = appendAll(self.right.right, that);\n      if (nrr.depth === self.depth - 3) {\n        const nr = makeChunk({\n          _tag: \"IConcat\",\n          left: self.right.left,\n          right: nrr\n        });\n        return makeChunk({\n          _tag: \"IConcat\",\n          left: self.left,\n          right: nr\n        });\n      } else {\n        const nl = makeChunk({\n          _tag: \"IConcat\",\n          left: self.left,\n          right: self.right.left\n        });\n        return makeChunk({\n          _tag: \"IConcat\",\n          left: nl,\n          right: nrr\n        });\n      }\n    }\n  } else {\n    if (that.right.depth >= that.left.depth) {\n      const nl = appendAll(self, that.left);\n      return makeChunk({\n        _tag: \"IConcat\",\n        left: nl,\n        right: that.right\n      });\n    } else {\n      const nll = appendAll(self, that.left.left);\n      if (nll.depth === that.depth - 3) {\n        const nl = makeChunk({\n          _tag: \"IConcat\",\n          left: nll,\n          right: that.left.right\n        });\n        return makeChunk({\n          _tag: \"IConcat\",\n          left: nl,\n          right: that.right\n        });\n      } else {\n        const nr = makeChunk({\n          _tag: \"IConcat\",\n          left: that.left.right,\n          right: that.right\n        });\n        return makeChunk({\n          _tag: \"IConcat\",\n          left: nll,\n          right: nr\n        });\n      }\n    }\n  }\n});\n/**\n * Returns a filtered and mapped subset of the elements.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filterMap = /*#__PURE__*/dual(2, (self, f) => unsafeFromArray(RA.filterMap(self, f)));\n/**\n * Returns a filtered and mapped subset of the elements.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => unsafeFromArray(RA.filter(self, predicate)));\n/**\n * Transforms all elements of the chunk for as long as the specified function returns some value\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filterMapWhile = /*#__PURE__*/dual(2, (self, f) => unsafeFromArray(RA.filterMapWhile(self, f)));\n/**\n * Filter out optional values\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const compact = self => filterMap(self, identity);\n/**\n * Applies a function to each element in a chunk and returns a new chunk containing the concatenated mapped elements.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => {\n  if (self.backing._tag === \"ISingleton\") {\n    return f(self.backing.a, 0);\n  }\n  let out = _empty;\n  let i = 0;\n  for (const k of self) {\n    out = appendAll(out, f(k, i++));\n  }\n  return out;\n});\n/**\n * Applies the specified function to each element of the `List`.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const forEach = /*#__PURE__*/dual(2, (self, f) => toReadonlyArray(self).forEach(f));\n/**\n * Flattens a chunk of chunks into a single chunk by concatenating all chunks.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatten = /*#__PURE__*/flatMap(identity);\n/**\n * Groups elements in chunks of up to `n` elements.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const chunksOf = /*#__PURE__*/dual(2, (self, n) => {\n  const gr = [];\n  let current = [];\n  toReadonlyArray(self).forEach(a => {\n    current.push(a);\n    if (current.length >= n) {\n      gr.push(unsafeFromArray(current));\n      current = [];\n    }\n  });\n  if (current.length > 0) {\n    gr.push(unsafeFromArray(current));\n  }\n  return unsafeFromArray(gr);\n});\n/**\n * Creates a Chunk of unique values that are included in all given Chunks.\n *\n * The order and references of result values are determined by the Chunk.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const intersection = /*#__PURE__*/dual(2, (self, that) => unsafeFromArray(RA.intersection(toReadonlyArray(self), toReadonlyArray(that))));\n/**\n * Determines if the chunk is empty.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const isEmpty = self => self.length === 0;\n/**\n * Determines if the chunk is not empty.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const isNonEmpty = self => self.length > 0;\n/**\n * Returns the first element of this chunk if it exists.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const head = /*#__PURE__*/get(0);\n/**\n * Returns the first element of this chunk.\n *\n * It will throw an error if the chunk is empty.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeHead = self => unsafeGet(self, 0);\n/**\n * Returns the first element of this non empty chunk.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const headNonEmpty = unsafeHead;\n/**\n * Returns the last element of this chunk if it exists.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const last = self => get(self, self.length - 1);\n/**\n * Returns the last element of this chunk.\n *\n * It will throw an error if the chunk is empty.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeLast = self => unsafeGet(self, self.length - 1);\n/**\n * Returns the last element of this non empty chunk.\n *\n * @since 3.4.0\n * @category elements\n */\nexport const lastNonEmpty = unsafeLast;\n/**\n * Transforms the elements of a chunk using the specified mapping function.\n * If the input chunk is non-empty, the resulting chunk will also be non-empty.\n *\n * @example\n * import { Chunk } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Chunk.map(Chunk.make(1, 2), (n) => n + 1),\n *   Chunk.make(2, 3)\n * )\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => self.backing._tag === \"ISingleton\" ? of(f(self.backing.a, 0)) : unsafeFromArray(pipe(toReadonlyArray(self), RA.map((a, i) => f(a, i)))));\n/**\n * Statefully maps over the chunk, producing new elements of type `B`.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const mapAccum = /*#__PURE__*/dual(3, (self, s, f) => {\n  const [s1, as] = RA.mapAccum(self, s, f);\n  return [s1, unsafeFromArray(as)];\n});\n/**\n * Separate elements based on a predicate that also exposes the index of the element.\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const partition = /*#__PURE__*/dual(2, (self, predicate) => pipe(RA.partition(toReadonlyArray(self), predicate), ([l, r]) => [unsafeFromArray(l), unsafeFromArray(r)]));\n/**\n * Partitions the elements of this chunk into two chunks using f.\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const partitionMap = /*#__PURE__*/dual(2, (self, f) => pipe(RA.partitionMap(toReadonlyArray(self), f), ([l, r]) => [unsafeFromArray(l), unsafeFromArray(r)]));\n/**\n * Partitions the elements of this chunk into two chunks.\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const separate = self => pipe(RA.separate(toReadonlyArray(self)), ([l, r]) => [unsafeFromArray(l), unsafeFromArray(r)]);\n/**\n * Retireves the size of the chunk\n *\n * @since 2.0.0\n * @category elements\n */\nexport const size = self => self.length;\n/**\n * Sort the elements of a Chunk in increasing order, creating a new Chunk.\n *\n * @since 2.0.0\n * @category sorting\n */\nexport const sort = /*#__PURE__*/dual(2, (self, O) => unsafeFromArray(RA.sort(toReadonlyArray(self), O)));\n/**\n * @since 2.0.0\n * @category sorting\n */\nexport const sortWith = /*#__PURE__*/dual(3, (self, f, order) => sort(self, Order.mapInput(order, f)));\n/**\n *  Returns two splits of this chunk at the specified index.\n *\n * @since 2.0.0\n * @category splitting\n */\nexport const splitAt = /*#__PURE__*/dual(2, (self, n) => [take(self, n), drop(self, n)]);\n/**\n * Splits a `NonEmptyChunk` into two segments, with the first segment containing a maximum of `n` elements.\n * The value of `n` must be `>= 1`.\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const splitNonEmptyAt = /*#__PURE__*/dual(2, (self, n) => {\n  const _n = Math.max(1, Math.floor(n));\n  return _n >= self.length ? [self, empty()] : [take(self, _n), drop(self, _n)];\n});\n/**\n * Splits this chunk into `n` equally sized chunks.\n *\n * @since 2.0.0\n * @category splitting\n */\nexport const split = /*#__PURE__*/dual(2, (self, n) => chunksOf(self, Math.ceil(self.length / Math.floor(n))));\n/**\n * Splits this chunk on the first element that matches this predicate.\n * Returns a tuple containing two chunks: the first one is before the match, and the second one is from the match onward.\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const splitWhere = /*#__PURE__*/dual(2, (self, predicate) => {\n  let i = 0;\n  for (const a of toReadonlyArray(self)) {\n    if (predicate(a)) {\n      break;\n    } else {\n      i++;\n    }\n  }\n  return splitAt(self, i);\n});\n/**\n * Returns every elements after the first.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const tail = self => self.length > 0 ? O.some(drop(self, 1)) : O.none();\n/**\n * Returns every elements after the first.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const tailNonEmpty = self => drop(self, 1);\n/**\n * Takes the last `n` elements.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const takeRight = /*#__PURE__*/dual(2, (self, n) => drop(self, self.length - n));\n/**\n * Takes all elements so long as the predicate returns true.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const takeWhile = /*#__PURE__*/dual(2, (self, predicate) => {\n  const out = [];\n  for (const a of toReadonlyArray(self)) {\n    if (predicate(a)) {\n      out.push(a);\n    } else {\n      break;\n    }\n  }\n  return unsafeFromArray(out);\n});\n/**\n * Creates a Chunks of unique values, in order, from all given Chunks.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const union = /*#__PURE__*/dual(2, (self, that) => unsafeFromArray(RA.union(toReadonlyArray(self), toReadonlyArray(that))));\n/**\n * Remove duplicates from an array, keeping the first occurrence of an element.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const dedupe = self => unsafeFromArray(RA.dedupe(toReadonlyArray(self)));\n/**\n * Deduplicates adjacent elements that are identical.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const dedupeAdjacent = self => unsafeFromArray(RA.dedupeAdjacent(self));\n/**\n * Takes a `Chunk` of pairs and return two corresponding `Chunk`s.\n *\n * Note: The function is reverse of `zip`.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const unzip = self => {\n  const [left, right] = RA.unzip(self);\n  return [unsafeFromArray(left), unsafeFromArray(right)];\n};\n/**\n * Zips this chunk pointwise with the specified chunk using the specified combiner.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => unsafeFromArray(RA.zipWith(self, that, f)));\n/**\n * Zips this chunk pointwise with the specified chunk.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = /*#__PURE__*/dual(2, (self, that) => zipWith(self, that, (a, b) => [a, b]));\n/**\n * Delete the element at the specified index, creating a new `Chunk`,\n * or returning the input if the index is out of bounds.\n *\n * @since 2.0.0\n */\nexport const remove = /*#__PURE__*/dual(2, (self, i) => unsafeFromArray(RA.remove(toReadonlyArray(self), i)));\n/**\n * @since 2.0.0\n */\nexport const modifyOption = /*#__PURE__*/dual(3, (self, i, f) => O.map(RA.modifyOption(toReadonlyArray(self), i, f), unsafeFromArray));\n/**\n * Apply a function to the element at the specified index, creating a new `Chunk`,\n * or returning the input if the index is out of bounds.\n *\n * @since 2.0.0\n */\nexport const modify = /*#__PURE__*/dual(3, (self, i, f) => O.getOrElse(modifyOption(self, i, f), () => self));\n/**\n * Change the element at the specified index, creating a new `Chunk`,\n * or returning the input if the index is out of bounds.\n *\n * @since 2.0.0\n */\nexport const replace = /*#__PURE__*/dual(3, (self, i, b) => modify(self, i, () => b));\n/**\n * @since 2.0.0\n */\nexport const replaceOption = /*#__PURE__*/dual(3, (self, i, b) => modifyOption(self, i, () => b));\n/**\n * Return a Chunk of length n with element i initialized with f(i).\n *\n * **Note**. `n` is normalized to an integer >= 1.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const makeBy = /*#__PURE__*/dual(2, (n, f) => fromIterable(RA.makeBy(n, f)));\n/**\n * Create a non empty `Chunk` containing a range of integers, including both endpoints.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const range = (start, end) => start <= end ? makeBy(end - start + 1, i => start + i) : of(start);\n// -------------------------------------------------------------------------------------\n// re-exports from ReadonlyArray\n// -------------------------------------------------------------------------------------\n/**\n * Returns a function that checks if a `Chunk` contains a given value using the default `Equivalence`.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const contains = RA.contains;\n/**\n * Returns a function that checks if a `Chunk` contains a given value using a provided `isEquivalent` function.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const containsWith = RA.containsWith;\n/**\n * Returns the first element that satisfies the specified\n * predicate, or `None` if no such element exists.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findFirst = RA.findFirst;\n/**\n * Return the first index for which a predicate holds.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findFirstIndex = RA.findFirstIndex;\n/**\n * Find the last element for which a predicate holds.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findLast = RA.findLast;\n/**\n * Return the last index for which a predicate holds.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findLastIndex = RA.findLastIndex;\n/**\n * Check if a predicate holds true for every `Chunk` element.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const every = /*#__PURE__*/dual(2, (self, refinement) => RA.fromIterable(self).every(refinement));\n/**\n * Check if a predicate holds true for some `Chunk` element.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const some = /*#__PURE__*/dual(2, (self, predicate) => RA.fromIterable(self).some(predicate));\n/**\n * Joins the elements together with \"sep\" in the middle.\n *\n * @category folding\n * @since 2.0.0\n */\nexport const join = RA.join;\n/**\n * @category folding\n * @since 2.0.0\n */\nexport const reduce = RA.reduce;\n/**\n * @category folding\n * @since 2.0.0\n */\nexport const reduceRight = RA.reduceRight;\n/**\n * Creates a `Chunk` of values not included in the other given `Chunk` using the provided `isEquivalent` function.\n * The order and references of result values are determined by the first `Chunk`.\n *\n * @since 3.2.0\n */\nexport const differenceWith = isEquivalent => {\n  return dual(2, (self, that) => unsafeFromArray(RA.differenceWith(isEquivalent)(that, self)));\n};\n/**\n * Creates a `Chunk` of values not included in the other given `Chunk`.\n * The order and references of result values are determined by the first `Chunk`.\n *\n * @since 3.2.0\n */\nexport const difference = /*#__PURE__*/dual(2, (self, that) => unsafeFromArray(RA.difference(that, self)));\n//# sourceMappingURL=Chunk.js.map","import * as internal from \"./internal/clock.js\";\nimport * as defaultServices from \"./internal/defaultServices.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const ClockTypeId = internal.ClockTypeId;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const sleep = defaultServices.sleep;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const currentTimeMillis = defaultServices.currentTimeMillis;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const currentTimeNanos = defaultServices.currentTimeNanos;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const clockWith = defaultServices.clockWith;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const Clock = internal.clockTag;\n//# sourceMappingURL=Clock.js.map","import * as internal from \"./internal/config.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const ConfigTypeId = internal.ConfigTypeId;\n/**\n * Constructs a config from a tuple / struct / arguments of configs.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const all = internal.all;\n/**\n * Constructs a config for an array of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const array = internal.array;\n/**\n * Constructs a config for a boolean value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const boolean = internal.boolean;\n/**\n * Constructs a config for a sequence of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const chunk = internal.chunk;\n/**\n * Constructs a config for a date value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const date = internal.date;\n/**\n * Constructs a config that fails with the specified message.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = internal.fail;\n/**\n * Constructs a config for a float value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const number = internal.number;\n/**\n * Constructs a config for a integer value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const integer = internal.integer;\n/**\n * Constructs a config for a literal value.\n *\n * @example\n * import { Config } from \"effect\"\n *\n * const config = Config.literal(\"http\", \"https\")(\"PROTOCOL\")\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const literal = internal.literal;\n/**\n * Constructs a config for a `LogLevel` value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const logLevel = internal.logLevel;\n/**\n * Constructs a config for a duration value.\n *\n * @since 2.5.0\n * @category constructors\n */\nexport const duration = internal.duration;\n/**\n * This function returns `true` if the specified value is an `Config` value,\n * `false` otherwise.\n *\n * This function can be useful for checking the type of a value before\n * attempting to operate on it as an `Config` value. For example, you could\n * use `isConfig` to check the type of a value before using it as an\n * argument to a function that expects an `Config` value.\n *\n * @param u - The value to check for being a `Config` value.\n *\n * @returns `true` if the specified value is a `Config` value, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isConfig = internal.isConfig;\n/**\n * Returns a  config whose structure is the same as this one, but which produces\n * a different value, constructed using the specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * Returns a config whose structure is the same as this one, but which may\n * produce a different value, constructed using the specified function, which\n * may throw exceptions that will be translated into validation errors.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapAttempt = internal.mapAttempt;\n/**\n * Returns a new config whose structure is the samea as this one, but which\n * may produce a different value, constructed using the specified fallible\n * function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapOrFail = internal.mapOrFail;\n/**\n * Returns a config that has this configuration nested as a property of the\n * specified name.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const nested = internal.nested;\n/**\n * Returns a config whose structure is preferentially described by this\n * config, but which falls back to the specified config if there is an issue\n * reading from this config.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const orElse = internal.orElse;\n/**\n * Returns configuration which reads from this configuration, but which falls\n * back to the specified configuration if reading from this configuration\n * fails with an error satisfying the specified predicate.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const orElseIf = internal.orElseIf;\n/**\n * Returns an optional version of this config, which will be `None` if the\n * data is missing from configuration, and `Some` otherwise.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const option = internal.option;\n/**\n * Constructs a new primitive config.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const primitive = internal.primitive;\n/**\n * Returns a config that describes a sequence of values, each of which has the\n * structure of this config.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeat = internal.repeat;\n/**\n * Constructs a config for a secret value.\n *\n * @since 2.0.0\n * @category constructors\n * @deprecated\n */\nexport const secret = internal.secret;\n/**\n * Constructs a config for a redacted value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const redacted = internal.redacted;\n/**\n * Constructs a config for a sequence of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const hashSet = internal.hashSet;\n/**\n * Constructs a config for a string value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const string = internal.string;\n/**\n * Constructs a config which contains the specified value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = internal.succeed;\n/**\n * Lazily constructs a config.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const suspend = internal.suspend;\n/**\n * Constructs a config which contains the specified lazy value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sync = internal.sync;\n/**\n * Constructs a config for a sequence of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const hashMap = internal.hashMap;\n/**\n * Constructs a config from some configuration wrapped with the `Wrap<A>` utility type.\n *\n * For example:\n *\n * ```\n * import { Config, unwrap } from \"./Config\"\n *\n * interface Options { key: string }\n *\n * const makeConfig = (config: Config.Wrap<Options>): Config<Options> => unwrap(config)\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrap = internal.unwrap;\n/**\n * Returns a config that describes the same structure as this one, but which\n * performs validation during loading.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const validate = internal.validate;\n/**\n * Returns a config that describes the same structure as this one, but has the\n * specified default value in case the information cannot be found.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const withDefault = internal.withDefault;\n/**\n * Adds a description to this configuration, which is intended for humans.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const withDescription = internal.withDescription;\n/**\n * Returns a config that is the composition of this config and the specified\n * config.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = internal.zip;\n/**\n * Returns a config that is the composes this config and the specified config\n * using the provided function.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = internal.zipWith;\n//# sourceMappingURL=Config.js.map","import * as internal from \"./internal/configError.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const ConfigErrorTypeId = internal.ConfigErrorTypeId;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const And = internal.And;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Or = internal.Or;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const MissingData = internal.MissingData;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const InvalidData = internal.InvalidData;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const SourceUnavailable = internal.SourceUnavailable;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Unsupported = internal.Unsupported;\n/**\n * Returns `true` if the specified value is a `ConfigError`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isConfigError = internal.isConfigError;\n/**\n * Returns `true` if the specified `ConfigError` is an `And`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isAnd = internal.isAnd;\n/**\n * Returns `true` if the specified `ConfigError` is an `Or`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isOr = internal.isOr;\n/**\n * Returns `true` if the specified `ConfigError` is an `InvalidData`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isInvalidData = internal.isInvalidData;\n/**\n * Returns `true` if the specified `ConfigError` is an `MissingData`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isMissingData = internal.isMissingData;\n/**\n * Returns `true` if the specified `ConfigError` contains only `MissingData` errors, `false` otherwise.\n *\n * @since 2.0.0\n * @categer getters\n */\nexport const isMissingDataOnly = internal.isMissingDataOnly;\n/**\n * Returns `true` if the specified `ConfigError` is a `SourceUnavailable`,\n * `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isSourceUnavailable = internal.isSourceUnavailable;\n/**\n * Returns `true` if the specified `ConfigError` is an `Unsupported`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isUnsupported = internal.isUnsupported;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const prefixed = internal.prefixed;\n/**\n * @since 2.0.0\n * @category folding\n */\nexport const reduceWithContext = internal.reduceWithContext;\n//# sourceMappingURL=ConfigError.js.map","import * as internal from \"./internal/context.js\";\nconst TagTypeId = internal.TagTypeId;\n/**\n * Creates a new `Tag` instance with an optional key parameter.\n *\n * @param key - A key that will be used to compare tags.\n *\n * @example\n * import { Context } from \"effect\"\n *\n * assert.strictEqual(Context.GenericTag(\"PORT\").key === Context.GenericTag(\"PORT\").key, true)\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const GenericTag = internal.makeGenericTag;\nconst TypeId = internal.TypeId;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const unsafeMake = internal.makeContext;\n/**\n * Checks if the provided argument is a `Context`.\n *\n * @param input - The value to be checked if it is a `Context`.\n *\n * @example\n * import { Context } from \"effect\"\n *\n * assert.strictEqual(Context.isContext(Context.empty()), true)\n *\n * @since 2.0.0\n * @category guards\n */\nexport const isContext = internal.isContext;\n/**\n * Checks if the provided argument is a `Tag`.\n *\n * @param input - The value to be checked if it is a `Tag`.\n *\n * @example\n * import { Context } from \"effect\"\n *\n * assert.strictEqual(Context.isTag(Context.GenericTag(\"Tag\")), true)\n *\n * @since 2.0.0\n * @category guards\n */\nexport const isTag = internal.isTag;\n/**\n * Returns an empty `Context`.\n *\n * @example\n * import { Context } from \"effect\"\n *\n * assert.strictEqual(Context.isContext(Context.empty()), true)\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * Creates a new `Context` with a single service associated to the tag.\n *\n * @example\n * import { Context } from \"effect\"\n *\n * const Port = Context.GenericTag<{ PORT: number }>(\"Port\")\n *\n * const Services = Context.make(Port, { PORT: 8080 })\n *\n * assert.deepStrictEqual(Context.get(Services, Port), { PORT: 8080 })\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * Adds a service to a given `Context`.\n *\n * @example\n * import { Context, pipe } from \"effect\"\n *\n * const Port = Context.GenericTag<{ PORT: number }>(\"Port\")\n * const Timeout = Context.GenericTag<{ TIMEOUT: number }>(\"Timeout\")\n *\n * const someContext = Context.make(Port, { PORT: 8080 })\n *\n * const Services = pipe(\n *   someContext,\n *   Context.add(Timeout, { TIMEOUT: 5000 })\n * )\n *\n * assert.deepStrictEqual(Context.get(Services, Port), { PORT: 8080 })\n * assert.deepStrictEqual(Context.get(Services, Timeout), { TIMEOUT: 5000 })\n *\n * @since 2.0.0\n */\nexport const add = internal.add;\n/**\n * Get a service from the context that corresponds to the given tag.\n *\n * @param self - The `Context` to search for the service.\n * @param tag - The `Tag` of the service to retrieve.\n *\n * @example\n * import { pipe, Context } from \"effect\"\n *\n * const Port = Context.GenericTag<{ PORT: number }>(\"Port\")\n * const Timeout = Context.GenericTag<{ TIMEOUT: number }>(\"Timeout\")\n *\n * const Services = pipe(\n *   Context.make(Port, { PORT: 8080 }),\n *   Context.add(Timeout, { TIMEOUT: 5000 })\n * )\n *\n * assert.deepStrictEqual(Context.get(Services, Timeout), { TIMEOUT: 5000 })\n *\n * @since 2.0.0\n * @category getters\n */\nexport const get = internal.get;\n/**\n * Get a service from the context that corresponds to the given tag.\n * This function is unsafe because if the tag is not present in the context, a runtime error will be thrown.\n *\n * For a safer version see {@link getOption}.\n *\n * @param self - The `Context` to search for the service.\n * @param tag - The `Tag` of the service to retrieve.\n *\n * @example\n * import { Context } from \"effect\"\n *\n * const Port = Context.GenericTag<{ PORT: number }>(\"Port\")\n * const Timeout = Context.GenericTag<{ TIMEOUT: number }>(\"Timeout\")\n *\n * const Services = Context.make(Port, { PORT: 8080 })\n *\n * assert.deepStrictEqual(Context.unsafeGet(Services, Port), { PORT: 8080 })\n * assert.throws(() => Context.unsafeGet(Services, Timeout))\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeGet = internal.unsafeGet;\n/**\n * Get the value associated with the specified tag from the context wrapped in an `Option` object. If the tag is not\n * found, the `Option` object will be `None`.\n *\n * @param self - The `Context` to search for the service.\n * @param tag - The `Tag` of the service to retrieve.\n *\n * @example\n * import { Context, Option } from \"effect\"\n *\n * const Port = Context.GenericTag<{ PORT: number }>(\"Port\")\n * const Timeout = Context.GenericTag<{ TIMEOUT: number }>(\"Timeout\")\n *\n * const Services = Context.make(Port, { PORT: 8080 })\n *\n * assert.deepStrictEqual(Context.getOption(Services, Port), Option.some({ PORT: 8080 }))\n * assert.deepStrictEqual(Context.getOption(Services, Timeout), Option.none())\n *\n * @since 2.0.0\n * @category getters\n */\nexport const getOption = internal.getOption;\n/**\n * Merges two `Context`s, returning a new `Context` containing the services of both.\n *\n * @param self - The first `Context` to merge.\n * @param that - The second `Context` to merge.\n *\n * @example\n * import { Context } from \"effect\"\n *\n * const Port = Context.GenericTag<{ PORT: number }>(\"Port\")\n * const Timeout = Context.GenericTag<{ TIMEOUT: number }>(\"Timeout\")\n *\n * const firstContext = Context.make(Port, { PORT: 8080 })\n * const secondContext = Context.make(Timeout, { TIMEOUT: 5000 })\n *\n * const Services = Context.merge(firstContext, secondContext)\n *\n * assert.deepStrictEqual(Context.get(Services, Port), { PORT: 8080 })\n * assert.deepStrictEqual(Context.get(Services, Timeout), { TIMEOUT: 5000 })\n *\n * @since 2.0.0\n */\nexport const merge = internal.merge;\n/**\n * Returns a new `Context` that contains only the specified services.\n *\n * @param self - The `Context` to prune services from.\n * @param tags - The list of `Tag`s to be included in the new `Context`.\n *\n * @example\n * import { pipe, Context, Option } from \"effect\"\n *\n * const Port = Context.GenericTag<{ PORT: number }>(\"Port\")\n * const Timeout = Context.GenericTag<{ TIMEOUT: number }>(\"Timeout\")\n *\n * const someContext = pipe(\n *   Context.make(Port, { PORT: 8080 }),\n *   Context.add(Timeout, { TIMEOUT: 5000 })\n * )\n *\n * const Services = pipe(someContext, Context.pick(Port))\n *\n * assert.deepStrictEqual(Context.getOption(Services, Port), Option.some({ PORT: 8080 }))\n * assert.deepStrictEqual(Context.getOption(Services, Timeout), Option.none())\n *\n * @since 2.0.0\n */\nexport const pick = internal.pick;\n/**\n * @since 2.0.0\n */\nexport const omit = internal.omit;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Tag = internal.Tag;\n//# sourceMappingURL=Context.js.map","/**\n * @since 2.0.0\n */\nimport * as Arr from \"./Array.js\";\nimport * as Either from \"./Either.js\";\nimport * as Equal from \"./Equal.js\";\nimport * as equivalence from \"./Equivalence.js\";\nimport { dual, pipe } from \"./Function.js\";\nimport * as Hash from \"./Hash.js\";\nimport { format, NodeInspectSymbol } from \"./Inspectable.js\";\nimport * as N from \"./Number.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nimport { hasProperty } from \"./Predicate.js\";\nimport * as String from \"./String.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/Cron\");\nconst CronProto = {\n  [TypeId]: TypeId,\n  [Equal.symbol](that) {\n    return isCron(that) && equals(this, that);\n  },\n  [Hash.symbol]() {\n    return pipe(Hash.array(Arr.fromIterable(this.minutes)), Hash.combine(Hash.array(Arr.fromIterable(this.hours))), Hash.combine(Hash.array(Arr.fromIterable(this.days))), Hash.combine(Hash.array(Arr.fromIterable(this.months))), Hash.combine(Hash.array(Arr.fromIterable(this.weekdays))), Hash.cached(this));\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"Cron\",\n      minutes: Arr.fromIterable(this.minutes),\n      hours: Arr.fromIterable(this.hours),\n      days: Arr.fromIterable(this.days),\n      months: Arr.fromIterable(this.months),\n      weekdays: Arr.fromIterable(this.weekdays)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/**\n * Checks if a given value is a `Cron` instance.\n *\n * @param u - The value to check.\n *\n * @since 2.0.0\n * @category guards\n */\nexport const isCron = u => hasProperty(u, TypeId);\n/**\n * Creates a `Cron` instance from.\n *\n * @param constraints - The cron constraints.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = ({\n  days,\n  hours,\n  minutes,\n  months,\n  weekdays\n}) => {\n  const o = Object.create(CronProto);\n  o.minutes = new Set(Arr.sort(minutes, N.Order));\n  o.hours = new Set(Arr.sort(hours, N.Order));\n  o.days = new Set(Arr.sort(days, N.Order));\n  o.months = new Set(Arr.sort(months, N.Order));\n  o.weekdays = new Set(Arr.sort(weekdays, N.Order));\n  return o;\n};\n/**\n * @since 2.0.0\n * @category symbol\n */\nexport const ParseErrorTypeId = /*#__PURE__*/Symbol.for(\"effect/Cron/errors/ParseError\");\nconst ParseErrorProto = {\n  _tag: \"ParseError\",\n  [ParseErrorTypeId]: ParseErrorTypeId\n};\nconst ParseError = (message, input) => {\n  const o = Object.create(ParseErrorProto);\n  o.message = message;\n  if (input !== undefined) {\n    o.input = input;\n  }\n  return o;\n};\n/**\n * Returns `true` if the specified value is an `ParseError`, `false` otherwise.\n *\n * @param u - The value to check.\n *\n * @since 2.0.0\n * @category guards\n */\nexport const isParseError = u => hasProperty(u, ParseErrorTypeId);\n/**\n * Parses a cron expression into a `Cron` instance.\n *\n * @param cron - The cron expression to parse.\n *\n * @example\n * import { Cron, Either } from \"effect\"\n *\n * // At 04:00 on every day-of-month from 8 through 14.\n * assert.deepStrictEqual(Cron.parse(\"0 4 8-14 * *\"), Either.right(Cron.make({\n *   minutes: [0],\n *   hours: [4],\n *   days: [8, 9, 10, 11, 12, 13, 14],\n *   months: [],\n *   weekdays: []\n * })))\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const parse = cron => {\n  const segments = cron.split(\" \").filter(String.isNonEmpty);\n  if (segments.length !== 5) {\n    return Either.left(ParseError(`Invalid number of segments in cron expression`, cron));\n  }\n  const [minutes, hours, days, months, weekdays] = segments;\n  return Either.all({\n    minutes: parseSegment(minutes, minuteOptions),\n    hours: parseSegment(hours, hourOptions),\n    days: parseSegment(days, dayOptions),\n    months: parseSegment(months, monthOptions),\n    weekdays: parseSegment(weekdays, weekdayOptions)\n  }).pipe(Either.map(segments => make(segments)));\n};\n/**\n * Checks if a given `Date` falls within an active `Cron` time window.\n *\n * @param cron - The `Cron` instance.\n * @param date - The `Date` to check against.\n *\n * @example\n * import { Cron, Either } from \"effect\"\n *\n * const cron = Either.getOrThrow(Cron.parse(\"0 4 8-14 * *\"))\n * assert.deepStrictEqual(Cron.match(cron, new Date(\"2021-01-08 04:00:00\")), true)\n * assert.deepStrictEqual(Cron.match(cron, new Date(\"2021-01-08 05:00:00\")), false)\n *\n * @since 2.0.0\n */\nexport const match = (cron, date) => {\n  const {\n    days,\n    hours,\n    minutes,\n    months,\n    weekdays\n  } = cron;\n  const minute = date.getMinutes();\n  if (minutes.size !== 0 && !minutes.has(minute)) {\n    return false;\n  }\n  const hour = date.getHours();\n  if (hours.size !== 0 && !hours.has(hour)) {\n    return false;\n  }\n  const month = date.getMonth() + 1;\n  if (months.size !== 0 && !months.has(month)) {\n    return false;\n  }\n  if (days.size === 0 && weekdays.size === 0) {\n    return true;\n  }\n  const day = date.getDate();\n  if (weekdays.size === 0) {\n    return days.has(day);\n  }\n  const weekday = date.getDay();\n  if (days.size === 0) {\n    return weekdays.has(weekday);\n  }\n  return days.has(day) || weekdays.has(weekday);\n};\n/**\n * Returns the next run `Date` for the given `Cron` instance.\n *\n * Uses the current time as a starting point if no value is provided for `now`.\n *\n * @example\n * import { Cron, Either } from \"effect\"\n *\n * const after = new Date(\"2021-01-01 00:00:00\")\n * const cron = Either.getOrThrow(Cron.parse(\"0 4 8-14 * *\"))\n * assert.deepStrictEqual(Cron.next(cron, after), new Date(\"2021-01-08 04:00:00\"))\n *\n * @param cron - The `Cron` instance.\n * @param now - The `Date` to start searching from.\n *\n * @since 2.0.0\n */\nexport const next = (cron, now) => {\n  const {\n    days,\n    hours,\n    minutes,\n    months,\n    weekdays\n  } = cron;\n  const restrictMinutes = minutes.size !== 0;\n  const restrictHours = hours.size !== 0;\n  const restrictDays = days.size !== 0;\n  const restrictMonths = months.size !== 0;\n  const restrictWeekdays = weekdays.size !== 0;\n  const current = now ? new Date(now.getTime()) : new Date();\n  // Increment by one minute to ensure we don't match the current date.\n  current.setMinutes(current.getMinutes() + 1);\n  current.setSeconds(0);\n  current.setMilliseconds(0);\n  // Only search 8 years into the future.\n  const limit = new Date(current).setFullYear(current.getFullYear() + 8);\n  while (current.getTime() <= limit) {\n    if (restrictMonths && !months.has(current.getMonth() + 1)) {\n      current.setMonth(current.getMonth() + 1);\n      current.setDate(1);\n      current.setHours(0);\n      current.setMinutes(0);\n      continue;\n    }\n    if (restrictDays && restrictWeekdays) {\n      if (!days.has(current.getDate()) && !weekdays.has(current.getDay())) {\n        current.setDate(current.getDate() + 1);\n        current.setHours(0);\n        current.setMinutes(0);\n        continue;\n      }\n    } else if (restrictDays) {\n      if (!days.has(current.getDate())) {\n        current.setDate(current.getDate() + 1);\n        current.setHours(0);\n        current.setMinutes(0);\n        continue;\n      }\n    } else if (restrictWeekdays) {\n      if (!weekdays.has(current.getDay())) {\n        current.setDate(current.getDate() + 1);\n        current.setHours(0);\n        current.setMinutes(0);\n        continue;\n      }\n    }\n    if (restrictHours && !hours.has(current.getHours())) {\n      current.setHours(current.getHours() + 1);\n      current.setMinutes(0);\n      continue;\n    }\n    if (restrictMinutes && !minutes.has(current.getMinutes())) {\n      current.setMinutes(current.getMinutes() + 1);\n      continue;\n    }\n    return current;\n  }\n  throw new Error(\"Unable to find next cron date\");\n};\n/**\n * Returns an `IterableIterator` which yields the sequence of `Date`s that match the `Cron` instance.\n *\n * @param cron - The `Cron` instance.\n * @param now - The `Date` to start searching from.\n *\n * @since 2.0.0\n */\nexport const sequence = function* (cron, now) {\n  while (true) {\n    yield now = next(cron, now);\n  }\n};\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Equivalence = /*#__PURE__*/equivalence.make((self, that) => restrictionsEquals(self.minutes, that.minutes) && restrictionsEquals(self.hours, that.hours) && restrictionsEquals(self.days, that.days) && restrictionsEquals(self.months, that.months) && restrictionsEquals(self.weekdays, that.weekdays));\nconst restrictionsArrayEquals = /*#__PURE__*/equivalence.array(equivalence.number);\nconst restrictionsEquals = (self, that) => restrictionsArrayEquals(Arr.fromIterable(self), Arr.fromIterable(that));\n/**\n * Checks if two `Cron`s are equal.\n *\n * @since 2.0.0\n * @category predicates\n */\nexport const equals = /*#__PURE__*/dual(2, (self, that) => Equivalence(self, that));\nconst minuteOptions = {\n  segment: \"minute\",\n  min: 0,\n  max: 59\n};\nconst hourOptions = {\n  segment: \"hour\",\n  min: 0,\n  max: 23\n};\nconst dayOptions = {\n  segment: \"day\",\n  min: 1,\n  max: 31\n};\nconst monthOptions = {\n  segment: \"month\",\n  min: 1,\n  max: 12,\n  aliases: {\n    jan: 1,\n    feb: 2,\n    mar: 3,\n    apr: 4,\n    may: 5,\n    jun: 6,\n    jul: 7,\n    aug: 8,\n    sep: 9,\n    oct: 10,\n    nov: 11,\n    dec: 12\n  }\n};\nconst weekdayOptions = {\n  segment: \"weekday\",\n  min: 0,\n  max: 6,\n  aliases: {\n    sun: 0,\n    mon: 1,\n    tue: 2,\n    wed: 3,\n    thu: 4,\n    fri: 5,\n    sat: 6\n  }\n};\nconst parseSegment = (input, options) => {\n  const capacity = options.max - options.min + 1;\n  const values = new Set();\n  const fields = input.split(\",\");\n  for (const field of fields) {\n    const [raw, step] = splitStep(field);\n    if (raw === \"*\" && step === undefined) {\n      return Either.right(new Set());\n    }\n    if (step !== undefined) {\n      if (!Number.isInteger(step)) {\n        return Either.left(ParseError(`Expected step value to be a positive integer`, input));\n      }\n      if (step < 1) {\n        return Either.left(ParseError(`Expected step value to be greater than 0`, input));\n      }\n      if (step > options.max) {\n        return Either.left(ParseError(`Expected step value to be less than ${options.max}`, input));\n      }\n    }\n    if (raw === \"*\") {\n      for (let i = options.min; i <= options.max; i += step ?? 1) {\n        values.add(i);\n      }\n    } else {\n      const [left, right] = splitRange(raw, options.aliases);\n      if (!Number.isInteger(left)) {\n        return Either.left(ParseError(`Expected a positive integer`, input));\n      }\n      if (left < options.min || left > options.max) {\n        return Either.left(ParseError(`Expected a value between ${options.min} and ${options.max}`, input));\n      }\n      if (right === undefined) {\n        values.add(left);\n      } else {\n        if (!Number.isInteger(right)) {\n          return Either.left(ParseError(`Expected a positive integer`, input));\n        }\n        if (right < options.min || right > options.max) {\n          return Either.left(ParseError(`Expected a value between ${options.min} and ${options.max}`, input));\n        }\n        if (left > right) {\n          return Either.left(ParseError(`Invalid value range`, input));\n        }\n        for (let i = left; i <= right; i += step ?? 1) {\n          values.add(i);\n        }\n      }\n    }\n    if (values.size >= capacity) {\n      return Either.right(new Set());\n    }\n  }\n  return Either.right(values);\n};\nconst splitStep = input => {\n  const seperator = input.indexOf(\"/\");\n  if (seperator !== -1) {\n    return [input.slice(0, seperator), Number(input.slice(seperator + 1))];\n  }\n  return [input, undefined];\n};\nconst splitRange = (input, aliases) => {\n  const seperator = input.indexOf(\"-\");\n  if (seperator !== -1) {\n    return [aliasOrValue(input.slice(0, seperator), aliases), aliasOrValue(input.slice(seperator + 1), aliases)];\n  }\n  return [aliasOrValue(input, aliases), undefined];\n};\nfunction aliasOrValue(field, aliases) {\n  return aliases?.[field.toLocaleLowerCase()] ?? Number(field);\n}\n//# sourceMappingURL=Cron.js.map","import * as core from \"./internal/core.js\";\nimport * as internal from \"./internal/data.js\";\nimport { StructuralPrototype } from \"./internal/effectable.js\";\nimport * as Predicate from \"./Predicate.js\";\n/**\n * @example\n * import { Data, Equal } from \"effect\"\n *\n * const alice = Data.struct({ name: \"Alice\", age: 30 })\n *\n * const bob = Data.struct({ name: \"Bob\", age: 40 })\n *\n * assert.deepStrictEqual(Equal.equals(alice, alice), true)\n * assert.deepStrictEqual(Equal.equals(alice, Data.struct({ name: \"Alice\", age: 30 })), true)\n *\n * assert.deepStrictEqual(Equal.equals(alice, { name: \"Alice\", age: 30 }), false)\n * assert.deepStrictEqual(Equal.equals(alice, bob), false)\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const struct = internal.struct;\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const unsafeStruct = as => Object.setPrototypeOf(as, StructuralPrototype);\n/**\n * @example\n * import { Data, Equal } from \"effect\"\n *\n * const alice = Data.tuple(\"Alice\", 30)\n *\n * const bob = Data.tuple(\"Bob\", 40)\n *\n * assert.deepStrictEqual(Equal.equals(alice, alice), true)\n * assert.deepStrictEqual(Equal.equals(alice, Data.tuple(\"Alice\", 30)), true)\n *\n * assert.deepStrictEqual(Equal.equals(alice, [\"Alice\", 30]), false)\n * assert.deepStrictEqual(Equal.equals(alice, bob), false)\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const tuple = (...as) => unsafeArray(as);\n/**\n * @example\n * import { Data, Equal } from \"effect\"\n *\n * const alice = Data.struct({ name: \"Alice\", age: 30 })\n * const bob = Data.struct({ name: \"Bob\", age: 40 })\n *\n * const persons = Data.array([alice, bob])\n *\n * assert.deepStrictEqual(\n *   Equal.equals(\n *     persons,\n *     Data.array([\n *       Data.struct({ name: \"Alice\", age: 30 }),\n *       Data.struct({ name: \"Bob\", age: 40 })\n *     ])\n *   ),\n *   true\n * )\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const array = as => unsafeArray(as.slice(0));\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const unsafeArray = as => Object.setPrototypeOf(as, internal.ArrayProto);\nconst _case = () => args => args === undefined ? Object.create(StructuralPrototype) : struct(args);\nexport {\n/**\n * Provides a constructor for the specified `Case`.\n *\n * @example\n * import { Data, Equal } from \"effect\"\n *\n * interface Person {\n *   readonly name: string\n * }\n *\n * // Creating a constructor for the specified Case\n * const Person = Data.case<Person>()\n *\n * // Creating instances of Person\n * const mike1 = Person({ name: \"Mike\" })\n * const mike2 = Person({ name: \"Mike\" })\n * const john = Person({ name: \"John\" })\n *\n * // Checking equality\n * assert.deepStrictEqual(Equal.equals(mike1, mike2), true)\n * assert.deepStrictEqual(Equal.equals(mike1, john), false)\n *\n * @since 2.0.0\n * @category constructors\n */\n_case as case };\n/**\n * Provides a tagged constructor for the specified `Case`.\n *\n * @example\n * import { Data } from \"effect\"\n *\n * interface Person {\n *   readonly _tag: \"Person\" // the tag\n *   readonly name: string\n * }\n *\n * const Person = Data.tagged<Person>(\"Person\")\n *\n * const mike = Person({ name: \"Mike\" })\n *\n * assert.deepEqual(mike, { _tag: \"Person\", name: \"Mike\" })\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const tagged = tag => args => {\n  const value = args === undefined ? Object.create(StructuralPrototype) : struct(args);\n  value._tag = tag;\n  return value;\n};\n/**\n * Provides a constructor for a Case Class.\n *\n * @example\n * import { Data, Equal } from \"effect\"\n *\n * class Person extends Data.Class<{ readonly name: string }> {}\n *\n * // Creating instances of Person\n * const mike1 = new Person({ name: \"Mike\" })\n * const mike2 = new Person({ name: \"Mike\" })\n * const john = new Person({ name: \"John\" })\n *\n * // Checking equality\n * assert.deepStrictEqual(Equal.equals(mike1, mike2), true)\n * assert.deepStrictEqual(Equal.equals(mike1, john), false)\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const Class = internal.Structural;\n/**\n * Provides a Tagged constructor for a Case Class.\n *\n * @example\n * import { Data, Equal } from \"effect\"\n *\n * class Person extends Data.TaggedClass(\"Person\")<{ readonly name: string }> {}\n *\n * // Creating instances of Person\n * const mike1 = new Person({ name: \"Mike\" })\n * const mike2 = new Person({ name: \"Mike\" })\n * const john = new Person({ name: \"John\" })\n *\n * // Checking equality\n * assert.deepStrictEqual(Equal.equals(mike1, mike2), true)\n * assert.deepStrictEqual(Equal.equals(mike1, john), false)\n *\n * assert.deepStrictEqual(mike1._tag, \"Person\")\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const TaggedClass = tag => {\n  class Base extends Class {\n    _tag = tag;\n  }\n  return Base;\n};\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Structural = internal.Structural;\n/**\n * Create a constructor for a tagged union of `Data` structs.\n *\n * You can also pass a `TaggedEnum.WithGenerics` if you want to add generics to\n * the constructor.\n *\n * @example\n * import { Data } from \"effect\"\n *\n * const { BadRequest, NotFound } = Data.taggedEnum<\n *   | { readonly _tag: \"BadRequest\"; readonly status: 400; readonly message: string }\n *   | { readonly _tag: \"NotFound\"; readonly status: 404; readonly message: string }\n * >()\n *\n * const notFound = NotFound({ status: 404, message: \"Not Found\" })\n *\n * @example\n * import { Data } from \"effect\"\n *\n * type MyResult<E, A> = Data.TaggedEnum<{\n *   Failure: { readonly error: E }\n *   Success: { readonly value: A }\n * }>\n * interface MyResultDefinition extends Data.TaggedEnum.WithGenerics<2> {\n *   readonly taggedEnum: MyResult<this[\"A\"], this[\"B\"]>\n * }\n * const { Failure, Success } = Data.taggedEnum<MyResultDefinition>()\n *\n * const success = Success({ value: 1 })\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const taggedEnum = () => new Proxy({}, {\n  get(_target, tag, _receiver) {\n    if (tag === \"$is\") {\n      return Predicate.isTagged;\n    } else if (tag === \"$match\") {\n      return taggedMatch;\n    }\n    return tagged(tag);\n  }\n});\nfunction taggedMatch() {\n  if (arguments.length === 1) {\n    const cases = arguments[0];\n    return function (value) {\n      return cases[value._tag](value);\n    };\n  }\n  const value = arguments[0];\n  const cases = arguments[1];\n  return cases[value._tag](value);\n}\n/**\n * Provides a constructor for a Case Class.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const Error = /*#__PURE__*/function () {\n  return class Base extends core.YieldableError {\n    constructor(args) {\n      super(args?.message, args?.cause ? {\n        cause: args.cause\n      } : undefined);\n      if (args) {\n        Object.assign(this, args);\n      }\n    }\n  };\n}();\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const TaggedError = tag => {\n  class Base extends Error {\n    _tag = tag;\n  }\n  ;\n  Base.prototype.name = tag;\n  return Base;\n};\n//# sourceMappingURL=Data.js.map","import * as core from \"./internal/core.js\";\nimport * as internal from \"./internal/deferred.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const DeferredTypeId = internal.DeferredTypeId;\n/**\n * Creates a new `Deferred`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = core.deferredMake;\n/**\n * Creates a new `Deferred` from the specified `FiberId`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const makeAs = core.deferredMakeAs;\nconst _await = core.deferredAwait;\nexport {\n/**\n * Retrieves the value of the `Deferred`, suspending the fiber running the\n * workflow until the result is available.\n *\n * @since 2.0.0\n * @category getters\n */\n_await as await };\n/**\n * Completes the deferred with the result of the specified effect. If the\n * deferred has already been completed, the method will produce false.\n *\n * Note that `Deferred.completeWith` will be much faster, so consider using\n * that if you do not need to memoize the result of the specified effect.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const complete = core.deferredComplete;\n/**\n * Completes the deferred with the result of the specified effect. If the\n * deferred has already been completed, the method will produce false.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const completeWith = core.deferredCompleteWith;\n/**\n * Exits the `Deferred` with the specified `Exit` value, which will be\n * propagated to all fibers waiting on the value of the `Deferred`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const done = core.deferredDone;\n/**\n * Fails the `Deferred` with the specified error, which will be propagated to\n * all fibers waiting on the value of the `Deferred`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const fail = core.deferredFail;\n/**\n * Fails the `Deferred` with the specified error, which will be propagated to\n * all fibers waiting on the value of the `Deferred`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const failSync = core.deferredFailSync;\n/**\n * Fails the `Deferred` with the specified `Cause`, which will be propagated to\n * all fibers waiting on the value of the `Deferred`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const failCause = core.deferredFailCause;\n/**\n * Fails the `Deferred` with the specified `Cause`, which will be propagated to\n * all fibers waiting on the value of the `Deferred`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const failCauseSync = core.deferredFailCauseSync;\n/**\n * Kills the `Deferred` with the specified defect, which will be propagated to\n * all fibers waiting on the value of the `Deferred`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const die = core.deferredDie;\n/**\n * Kills the `Deferred` with the specified defect, which will be propagated to\n * all fibers waiting on the value of the `Deferred`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dieSync = core.deferredDieSync;\n/**\n * Completes the `Deferred` with interruption. This will interrupt all fibers\n * waiting on the value of the `Deferred` with the `FiberId` of the fiber\n * calling this method.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interrupt = core.deferredInterrupt;\n/**\n * Completes the `Deferred` with interruption. This will interrupt all fibers\n * waiting on the value of the `Deferred` with the specified `FiberId`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptWith = core.deferredInterruptWith;\n/**\n * Returns `true` if this `Deferred` has already been completed with a value or\n * an error, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isDone = core.deferredIsDone;\n/**\n * Returns a `Some<Effect<A, E, R>>` from the `Deferred` if this `Deferred` has\n * already been completed, `None` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const poll = core.deferredPoll;\n/**\n * Completes the `Deferred` with the specified value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const succeed = core.deferredSucceed;\n/**\n * Completes the `Deferred` with the specified lazily evaluated value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const sync = core.deferredSync;\n/**\n * Unsafely creates a new `Deferred` from the specified `FiberId`.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeMake = core.deferredUnsafeMake;\n/**\n * Unsafely exits the `Deferred` with the specified `Exit` value, which will be\n * propagated to all fibers waiting on the value of the `Deferred`.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeDone = core.deferredUnsafeDone;\n//# sourceMappingURL=Deferred.js.map","import * as Dual from \"./Function.js\";\nimport * as internal from \"./internal/differ.js\";\nimport * as ChunkPatch from \"./internal/differ/chunkPatch.js\";\nimport * as ContextPatch from \"./internal/differ/contextPatch.js\";\nimport * as HashMapPatch from \"./internal/differ/hashMapPatch.js\";\nimport * as HashSetPatch from \"./internal/differ/hashSetPatch.js\";\nimport * as OrPatch from \"./internal/differ/orPatch.js\";\nimport * as ReadonlyArrayPatch from \"./internal/differ/readonlyArrayPatch.js\";\n/**\n * @since 2.0.0\n * @category symbol\n */\nexport const TypeId = internal.DifferTypeId;\nconst ChunkPatchTypeId = ChunkPatch.ChunkPatchTypeId;\nconst ContextPatchTypeId = ContextPatch.ContextPatchTypeId;\nconst HashMapPatchTypeId = HashMapPatch.HashMapPatchTypeId;\nconst HashSetPatchTypeId = HashSetPatch.HashSetPatchTypeId;\nconst OrPatchTypeId = OrPatch.OrPatchTypeId;\nconst ReadonlyArrayPatchTypeId = ReadonlyArrayPatch.ReadonlyArrayPatchTypeId;\n/**\n * An empty patch that describes no changes.\n *\n * @since 2.0.0\n * @category patch\n */\nexport const empty = self => self.empty;\n/**\n * @since 2.0.0\n * @category patch\n */\nexport const diff = /*#__PURE__*/Dual.dual(3, (self, oldValue, newValue) => self.diff(oldValue, newValue));\n/**\n * Combines two patches to produce a new patch that describes the updates of\n * the first patch and then the updates of the second patch. The combine\n * operation should be associative. In addition, if the combine operation is\n * commutative then joining multiple fibers concurrently will result in\n * deterministic `FiberRef` values.\n *\n * @since 2.0.0\n * @category patch\n */\nexport const combine = /*#__PURE__*/Dual.dual(3, (self, first, second) => self.combine(first, second));\n/**\n * Applies a patch to an old value to produce a new value that is equal to the\n * old value with the updates described by the patch.\n *\n * @since 2.0.0\n * @category patch\n */\nexport const patch = /*#__PURE__*/Dual.dual(3, (self, patch, oldValue) => self.patch(patch, oldValue));\n/**\n * Constructs a new `Differ`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * Constructs a differ that knows how to diff `Env` values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const environment = internal.environment;\n/**\n * Constructs a differ that knows how to diff a `Chunk` of values given a\n * differ that knows how to diff the values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const chunk = internal.chunk;\n/**\n * Constructs a differ that knows how to diff a `HashMap` of keys and values given\n * a differ that knows how to diff the values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const hashMap = internal.hashMap;\n/**\n * Constructs a differ that knows how to diff a `HashSet` of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const hashSet = internal.hashSet;\n/**\n * Combines this differ and the specified differ to produce a differ that\n * knows how to diff the sum of their values.\n *\n * @since 2.0.0\n */\nexport const orElseEither = internal.orElseEither;\n/**\n * Constructs a differ that knows how to diff a `ReadonlyArray` of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const readonlyArray = internal.readonlyArray;\n/**\n * Transforms the type of values that this differ knows how to differ using\n * the specified functions that map the new and old value types to each other.\n *\n * @since 2.0.0\n */\nexport const transform = internal.transform;\n/**\n * Constructs a differ that just diffs two values by returning a function that\n * sets the value to the new value. This differ does not support combining\n * multiple updates to the value compositionally and should only be used when\n * there is no compositional way to update them.\n *\n * @since 2.0.0\n */\nexport const update = internal.update;\n/**\n * A variant of `update` that allows specifying the function that will be used\n * to combine old values with new values.\n *\n * @since 2.0.0\n */\nexport const updateWith = internal.updateWith;\n/**\n * Combines this differ and the specified differ to produce a new differ that\n * knows how to diff the product of their values.\n *\n * @since 2.0.0\n */\nexport const zip = internal.zip;\n//# sourceMappingURL=Differ.js.map","/**\n * @since 2.0.0\n */\nimport * as Equal from \"./Equal.js\";\nimport { dual } from \"./Function.js\";\nimport * as Hash from \"./Hash.js\";\nimport { NodeInspectSymbol } from \"./Inspectable.js\";\nimport * as Option from \"./Option.js\";\nimport * as order from \"./Order.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nimport { hasProperty, isBigInt, isNumber, isString } from \"./Predicate.js\";\nconst TypeId = /*#__PURE__*/Symbol.for(\"effect/Duration\");\nconst bigint0 = /*#__PURE__*/BigInt(0);\nconst bigint24 = /*#__PURE__*/BigInt(24);\nconst bigint60 = /*#__PURE__*/BigInt(60);\nconst bigint1e3 = /*#__PURE__*/BigInt(1_000);\nconst bigint1e6 = /*#__PURE__*/BigInt(1_000_000);\nconst bigint1e9 = /*#__PURE__*/BigInt(1_000_000_000);\nconst DURATION_REGEX = /^(-?\\d+(?:\\.\\d+)?)\\s+(nanos?|micros?|millis?|seconds?|minutes?|hours?|days?|weeks?)$/;\n/**\n * @since 2.0.0\n */\nexport const decode = input => {\n  if (isDuration(input)) {\n    return input;\n  } else if (isNumber(input)) {\n    return millis(input);\n  } else if (isBigInt(input)) {\n    return nanos(input);\n  } else if (Array.isArray(input)) {\n    if (input.length === 2 && isNumber(input[0]) && isNumber(input[1])) {\n      return nanos(BigInt(input[0]) * bigint1e9 + BigInt(input[1]));\n    }\n  } else if (isString(input)) {\n    DURATION_REGEX.lastIndex = 0; // Reset the lastIndex before each use\n    const match = DURATION_REGEX.exec(input);\n    if (match) {\n      const [_, valueStr, unit] = match;\n      const value = Number(valueStr);\n      switch (unit) {\n        case \"nano\":\n        case \"nanos\":\n          return nanos(BigInt(valueStr));\n        case \"micro\":\n        case \"micros\":\n          return micros(BigInt(valueStr));\n        case \"milli\":\n        case \"millis\":\n          return millis(value);\n        case \"second\":\n        case \"seconds\":\n          return seconds(value);\n        case \"minute\":\n        case \"minutes\":\n          return minutes(value);\n        case \"hour\":\n        case \"hours\":\n          return hours(value);\n        case \"day\":\n        case \"days\":\n          return days(value);\n        case \"week\":\n        case \"weeks\":\n          return weeks(value);\n      }\n    }\n  }\n  throw new Error(\"Invalid DurationInput\");\n};\n/**\n * @since 2.5.0\n */\nexport const decodeUnknown = /*#__PURE__*/Option.liftThrowable(decode);\nconst zeroValue = {\n  _tag: \"Millis\",\n  millis: 0\n};\nconst infinityValue = {\n  _tag: \"Infinity\"\n};\nconst DurationProto = {\n  [TypeId]: TypeId,\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.structure(this.value));\n  },\n  [Equal.symbol](that) {\n    return isDuration(that) && equals(this, that);\n  },\n  toString() {\n    return `Duration(${format(this)})`;\n  },\n  toJSON() {\n    switch (this.value._tag) {\n      case \"Millis\":\n        return {\n          _id: \"Duration\",\n          _tag: \"Millis\",\n          millis: this.value.millis\n        };\n      case \"Nanos\":\n        return {\n          _id: \"Duration\",\n          _tag: \"Nanos\",\n          hrtime: toHrTime(this)\n        };\n      case \"Infinity\":\n        return {\n          _id: \"Duration\",\n          _tag: \"Infinity\"\n        };\n    }\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst make = input => {\n  const duration = Object.create(DurationProto);\n  if (isNumber(input)) {\n    if (isNaN(input) || input <= 0) {\n      duration.value = zeroValue;\n    } else if (!Number.isFinite(input)) {\n      duration.value = infinityValue;\n    } else if (!Number.isInteger(input)) {\n      duration.value = {\n        _tag: \"Nanos\",\n        nanos: BigInt(Math.round(input * 1_000_000))\n      };\n    } else {\n      duration.value = {\n        _tag: \"Millis\",\n        millis: input\n      };\n    }\n  } else if (input <= bigint0) {\n    duration.value = zeroValue;\n  } else {\n    duration.value = {\n      _tag: \"Nanos\",\n      nanos: input\n    };\n  }\n  return duration;\n};\n/**\n * @since 2.0.0\n * @category guards\n */\nexport const isDuration = u => hasProperty(u, TypeId);\n/**\n * @since 2.0.0\n * @category guards\n */\nexport const isFinite = self => self.value._tag !== \"Infinity\";\n/**\n * @since 3.5.0\n * @category guards\n */\nexport const isZero = self => {\n  switch (self.value._tag) {\n    case \"Millis\":\n      {\n        return self.value.millis === 0;\n      }\n    case \"Nanos\":\n      {\n        return self.value.nanos === bigint0;\n      }\n    case \"Infinity\":\n      {\n        return false;\n      }\n  }\n};\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const zero = /*#__PURE__*/make(0);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const infinity = /*#__PURE__*/make(Infinity);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const nanos = nanos => make(nanos);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const micros = micros => make(micros * bigint1e3);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const millis = millis => make(millis);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const seconds = seconds => make(seconds * 1000);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const minutes = minutes => make(minutes * 60_000);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const hours = hours => make(hours * 3_600_000);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const days = days => make(days * 86_400_000);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const weeks = weeks => make(weeks * 604_800_000);\n/**\n * @since 2.0.0\n * @category getters\n */\nexport const toMillis = self => {\n  const _self = decode(self);\n  switch (_self.value._tag) {\n    case \"Infinity\":\n      return Infinity;\n    case \"Nanos\":\n      return Number(_self.value.nanos) / 1_000_000;\n    case \"Millis\":\n      return _self.value.millis;\n  }\n};\n/**\n * @since 2.0.0\n * @category getters\n */\nexport const toSeconds = self => toMillis(self) / 1_000;\n/**\n * Get the duration in nanoseconds as a bigint.\n *\n * If the duration is infinite, returns `Option.none()`\n *\n * @since 2.0.0\n * @category getters\n */\nexport const toNanos = self => {\n  const _self = decode(self);\n  switch (_self.value._tag) {\n    case \"Infinity\":\n      return Option.none();\n    case \"Nanos\":\n      return Option.some(_self.value.nanos);\n    case \"Millis\":\n      return Option.some(BigInt(Math.round(_self.value.millis * 1_000_000)));\n  }\n};\n/**\n * Get the duration in nanoseconds as a bigint.\n *\n * If the duration is infinite, it throws an error.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const unsafeToNanos = self => {\n  const _self = decode(self);\n  switch (_self.value._tag) {\n    case \"Infinity\":\n      throw new Error(\"Cannot convert infinite duration to nanos\");\n    case \"Nanos\":\n      return _self.value.nanos;\n    case \"Millis\":\n      return BigInt(Math.round(_self.value.millis * 1_000_000));\n  }\n};\n/**\n * @since 2.0.0\n * @category getters\n */\nexport const toHrTime = self => {\n  const _self = decode(self);\n  switch (_self.value._tag) {\n    case \"Infinity\":\n      return [Infinity, 0];\n    case \"Nanos\":\n      return [Number(_self.value.nanos / bigint1e9), Number(_self.value.nanos % bigint1e9)];\n    case \"Millis\":\n      return [Math.floor(_self.value.millis / 1000), Math.round(_self.value.millis % 1000 * 1_000_000)];\n  }\n};\n/**\n * @since 2.0.0\n * @category pattern matching\n */\nexport const match = /*#__PURE__*/dual(2, (self, options) => {\n  const _self = decode(self);\n  switch (_self.value._tag) {\n    case \"Nanos\":\n      return options.onNanos(_self.value.nanos);\n    case \"Infinity\":\n      return options.onMillis(Infinity);\n    case \"Millis\":\n      return options.onMillis(_self.value.millis);\n  }\n});\n/**\n * @since 2.0.0\n * @category pattern matching\n */\nexport const matchWith = /*#__PURE__*/dual(3, (self, that, options) => {\n  const _self = decode(self);\n  const _that = decode(that);\n  if (_self.value._tag === \"Infinity\" || _that.value._tag === \"Infinity\") {\n    return options.onMillis(toMillis(_self), toMillis(_that));\n  } else if (_self.value._tag === \"Nanos\" || _that.value._tag === \"Nanos\") {\n    const selfNanos = _self.value._tag === \"Nanos\" ? _self.value.nanos : BigInt(Math.round(_self.value.millis * 1_000_000));\n    const thatNanos = _that.value._tag === \"Nanos\" ? _that.value.nanos : BigInt(Math.round(_that.value.millis * 1_000_000));\n    return options.onNanos(selfNanos, thatNanos);\n  }\n  return options.onMillis(_self.value.millis, _that.value.millis);\n});\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Order = /*#__PURE__*/order.make((self, that) => matchWith(self, that, {\n  onMillis: (self, that) => self < that ? -1 : self > that ? 1 : 0,\n  onNanos: (self, that) => self < that ? -1 : self > that ? 1 : 0\n}));\n/**\n * Checks if a `Duration` is between a `minimum` and `maximum` value.\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const between = /*#__PURE__*/order.between( /*#__PURE__*/order.mapInput(Order, decode));\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Equivalence = (self, that) => matchWith(self, that, {\n  onMillis: (self, that) => self === that,\n  onNanos: (self, that) => self === that\n});\nconst _min = /*#__PURE__*/order.min(Order);\n/**\n * @since 2.0.0\n */\nexport const min = /*#__PURE__*/dual(2, (self, that) => _min(decode(self), decode(that)));\nconst _max = /*#__PURE__*/order.max(Order);\n/**\n * @since 2.0.0\n */\nexport const max = /*#__PURE__*/dual(2, (self, that) => _max(decode(self), decode(that)));\nconst _clamp = /*#__PURE__*/order.clamp(Order);\n/**\n * @since 2.0.0\n */\nexport const clamp = /*#__PURE__*/dual(2, (self, options) => _clamp(decode(self), {\n  minimum: decode(options.minimum),\n  maximum: decode(options.maximum)\n}));\n/**\n * @since 2.4.19\n * @category math\n */\nexport const divide = /*#__PURE__*/dual(2, (self, by) => match(self, {\n  onMillis: millis => {\n    if (by === 0 || isNaN(by) || !Number.isFinite(by)) {\n      return Option.none();\n    }\n    return Option.some(make(millis / by));\n  },\n  onNanos: nanos => {\n    if (isNaN(by) || by <= 0 || !Number.isFinite(by)) {\n      return Option.none();\n    }\n    try {\n      return Option.some(make(nanos / BigInt(by)));\n    } catch (e) {\n      return Option.none();\n    }\n  }\n}));\n/**\n * @since 2.4.19\n * @category math\n */\nexport const unsafeDivide = /*#__PURE__*/dual(2, (self, by) => match(self, {\n  onMillis: millis => make(millis / by),\n  onNanos: nanos => {\n    if (isNaN(by) || by < 0 || Object.is(by, -0)) {\n      return zero;\n    } else if (Object.is(by, 0) || !Number.isFinite(by)) {\n      return infinity;\n    }\n    return make(nanos / BigInt(by));\n  }\n}));\n/**\n * @since 2.0.0\n * @category math\n */\nexport const times = /*#__PURE__*/dual(2, (self, times) => match(self, {\n  onMillis: millis => make(millis * times),\n  onNanos: nanos => make(nanos * BigInt(times))\n}));\n/**\n * @since 2.0.0\n * @category math\n */\nexport const subtract = /*#__PURE__*/dual(2, (self, that) => matchWith(self, that, {\n  onMillis: (self, that) => make(self - that),\n  onNanos: (self, that) => make(self - that)\n}));\n/**\n * @since 2.0.0\n * @category math\n */\nexport const sum = /*#__PURE__*/dual(2, (self, that) => matchWith(self, that, {\n  onMillis: (self, that) => make(self + that),\n  onNanos: (self, that) => make(self + that)\n}));\n/**\n * @since 2.0.0\n * @category predicates\n */\nexport const lessThan = /*#__PURE__*/dual(2, (self, that) => matchWith(self, that, {\n  onMillis: (self, that) => self < that,\n  onNanos: (self, that) => self < that\n}));\n/**\n * @since 2.0.0\n * @category predicates\n */\nexport const lessThanOrEqualTo = /*#__PURE__*/dual(2, (self, that) => matchWith(self, that, {\n  onMillis: (self, that) => self <= that,\n  onNanos: (self, that) => self <= that\n}));\n/**\n * @since 2.0.0\n * @category predicates\n */\nexport const greaterThan = /*#__PURE__*/dual(2, (self, that) => matchWith(self, that, {\n  onMillis: (self, that) => self > that,\n  onNanos: (self, that) => self > that\n}));\n/**\n * @since 2.0.0\n * @category predicates\n */\nexport const greaterThanOrEqualTo = /*#__PURE__*/dual(2, (self, that) => matchWith(self, that, {\n  onMillis: (self, that) => self >= that,\n  onNanos: (self, that) => self >= that\n}));\n/**\n * @since 2.0.0\n * @category predicates\n */\nexport const equals = /*#__PURE__*/dual(2, (self, that) => Equivalence(decode(self), decode(that)));\n/**\n * Converts a `Duration` to a human readable string.\n * @since 2.0.0\n *\n * @example\n * import { Duration } from \"effect\"\n *\n * Duration.format(Duration.millis(1000)) // \"1s\"\n * Duration.format(Duration.millis(1001)) // \"1s 1ms\"\n */\nexport const format = self => {\n  const duration = decode(self);\n  const parts = [];\n  if (duration.value._tag === \"Infinity\") {\n    return \"Infinity\";\n  }\n  const nanos = unsafeToNanos(duration);\n  if (nanos % bigint1e6) {\n    parts.push(`${nanos % bigint1e6}ns`);\n  }\n  const ms = nanos / bigint1e6;\n  if (ms % bigint1e3 !== bigint0) {\n    parts.push(`${ms % bigint1e3}ms`);\n  }\n  const sec = ms / bigint1e3;\n  if (sec % bigint60 !== bigint0) {\n    parts.push(`${sec % bigint60}s`);\n  }\n  const min = sec / bigint60;\n  if (min % bigint60 !== bigint0) {\n    parts.push(`${min % bigint60}m`);\n  }\n  const hr = min / bigint60;\n  if (hr % bigint24 !== bigint0) {\n    parts.push(`${hr % bigint24}h`);\n  }\n  const days = hr / bigint24;\n  if (days !== bigint0) {\n    parts.push(`${days}d`);\n  }\n  return parts.reverse().join(\" \");\n};\n//# sourceMappingURL=Duration.js.map","import { dual } from \"./Function.js\";\nimport * as _console from \"./internal/console.js\";\nimport { TagProto } from \"./internal/context.js\";\nimport * as effect from \"./internal/core-effect.js\";\nimport * as core from \"./internal/core.js\";\nimport * as defaultServices from \"./internal/defaultServices.js\";\nimport * as circular from \"./internal/effect/circular.js\";\nimport * as fiberRuntime from \"./internal/fiberRuntime.js\";\nimport * as layer from \"./internal/layer.js\";\nimport * as query from \"./internal/query.js\";\nimport * as _runtime from \"./internal/runtime.js\";\nimport * as _schedule from \"./internal/schedule.js\";\nimport * as Request from \"./Request.js\";\nimport * as Scheduler from \"./Scheduler.js\";\n// -------------------------------------------------------------------------------------\n// models\n// -------------------------------------------------------------------------------------\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const EffectTypeId = core.EffectTypeId;\n// -------------------------------------------------------------------------------------\n// refinements\n// -------------------------------------------------------------------------------------\n/**\n * This function returns `true` if the specified value is an `Effect` value,\n * `false` otherwise.\n *\n * This function can be useful for checking the type of a value before\n * attempting to operate on it as an `Effect` value. For example, you could\n * use `isEffect` to check the type of a value before using it as an\n * argument to a function that expects an `Effect` value.\n *\n * @param u - The value to check for being an `Effect` value.\n *\n * @returns `true` if the specified value is an `Effect` value, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isEffect = core.isEffect;\n// -------------------------------------------------------------------------------------\n// caching\n// -------------------------------------------------------------------------------------\n/**\n * Returns an effect that caches its result for a specified duration, known as\n * the `timeToLive`. When the cache expires after the duration, the effect will be\n * recomputed upon next evaluation.\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * let i = 1\n * const expensiveTask = Effect.promise<string>(() => {\n *   console.log(\"expensive task...\")\n *   return new Promise((resolve) => {\n *     setTimeout(() => {\n *       resolve(`result ${i++}`)\n *     }, 100)\n *   })\n * })\n *\n * const program = Effect.gen(function* () {\n *   const cached = yield* Effect.cachedWithTTL(expensiveTask, \"150 millis\")\n *   yield* cached.pipe(Effect.andThen(Console.log))\n *   yield* cached.pipe(Effect.andThen(Console.log))\n *   yield* Effect.sleep(\"100 millis\")\n *   yield* cached.pipe(Effect.andThen(Console.log))\n * })\n *\n * Effect.runFork(program)\n * // Output:\n * // expensive task...\n * // result 1\n * // result 1\n * // expensive task...\n * // result 2\n *\n * @since 2.0.0\n * @category caching\n */\nexport const cachedWithTTL = circular.cached;\n/**\n * Similar to {@link cachedWithTTL}, this function caches an effect's result for a\n * specified duration. It also includes an additional effect for manually\n * invalidating the cached value before it naturally expires.\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * let i = 1\n * const expensiveTask = Effect.promise<string>(() => {\n *   console.log(\"expensive task...\")\n *   return new Promise((resolve) => {\n *     setTimeout(() => {\n *       resolve(`result ${i++}`)\n *     }, 100)\n *   })\n * })\n *\n * const program = Effect.gen(function* () {\n *   const [cached, invalidate] = yield* Effect.cachedInvalidateWithTTL(\n *     expensiveTask,\n *     \"1 hour\"\n *   )\n *   yield* cached.pipe(Effect.andThen(Console.log))\n *   yield* cached.pipe(Effect.andThen(Console.log))\n *   yield* invalidate\n *   yield* cached.pipe(Effect.andThen(Console.log))\n * })\n *\n * Effect.runFork(program)\n * // Output:\n * // expensive task...\n * // result 1\n * // result 1\n * // expensive task...\n * // result 2\n *\n * @since 2.0.0\n * @category caching\n */\nexport const cachedInvalidateWithTTL = circular.cachedInvalidateWithTTL;\n/**\n * Returns an effect that computes a result lazily and caches it. Subsequent\n * evaluations of this effect will return the cached result without re-executing\n * the logic.\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * let i = 1\n * const expensiveTask = Effect.promise<string>(() => {\n *   console.log(\"expensive task...\")\n *   return new Promise((resolve) => {\n *     setTimeout(() => {\n *       resolve(`result ${i++}`)\n *     }, 100)\n *   })\n * })\n *\n * const program = Effect.gen(function* () {\n *   console.log(\"non-cached version:\")\n *   yield* expensiveTask.pipe(Effect.andThen(Console.log))\n *   yield* expensiveTask.pipe(Effect.andThen(Console.log))\n *   console.log(\"cached version:\")\n *   const cached = yield* Effect.cached(expensiveTask)\n *   yield* cached.pipe(Effect.andThen(Console.log))\n *   yield* cached.pipe(Effect.andThen(Console.log))\n * })\n *\n * Effect.runFork(program)\n * // Output:\n * // non-cached version:\n * // expensive task...\n * // result 1\n * // expensive task...\n * // result 2\n * // cached version:\n * // expensive task...\n * // result 3\n * // result 3\n *\n * @since 2.0.0\n * @category caching\n */\nexport const cached = effect.memoize;\n/**\n * Returns a memoized version of a function with effects. Memoization ensures\n * that results are stored and reused for the same inputs, reducing the need to\n * recompute them.\n *\n * @example\n * import { Effect, Random } from \"effect\"\n *\n * const program = Effect.gen(function* () {\n *   const randomNumber = (n: number) => Random.nextIntBetween(1, n)\n *   console.log(\"non-memoized version:\")\n *   console.log(yield* randomNumber(10))\n *   console.log(yield* randomNumber(10))\n *\n *   console.log(\"memoized version:\")\n *   const memoized = yield* Effect.cachedFunction(randomNumber)\n *   console.log(yield* memoized(10))\n *   console.log(yield* memoized(10))\n * })\n *\n * Effect.runFork(program)\n * // Example Output:\n * // non-memoized version:\n * // 2\n * // 8\n * // memoized version:\n * // 5\n * // 5\n *\n * @since 2.0.0\n * @category caching\n */\nexport const cachedFunction = circular.cachedFunction;\n/**\n * Returns an effect that executes only once, regardless of how many times it's\n * called.\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * const program = Effect.gen(function* () {\n *   const task1 = Console.log(\"task1\")\n *   yield* Effect.repeatN(task1, 2)\n *   const task2 = yield* Effect.once(Console.log(\"task2\"))\n *   yield* Effect.repeatN(task2, 2)\n * })\n *\n * Effect.runFork(program)\n * // Output:\n * // task1\n * // task1\n * // task1\n * // task2\n *\n * @since 2.0.0\n * @category caching\n */\nexport const once = effect.once;\n// -------------------------------------------------------------------------------------\n// collecting & elements\n// -------------------------------------------------------------------------------------\n/**\n * Runs all the provided effects in sequence respecting the structure provided in input.\n *\n * Supports multiple arguments, a single argument tuple / array or record / struct.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const all = fiberRuntime.all;\n/**\n * Data-last variant of `Effect.all`.\n *\n * Runs all the provided effects in sequence respecting the structure provided in input.\n *\n * Supports multiple arguments, a single argument tuple / array or record / struct.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const allWith = fiberRuntime.allWith;\n/**\n * Evaluate and run each effect in the structure and collect the results,\n * discarding results from failed effects.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const allSuccesses = fiberRuntime.allSuccesses;\n/**\n * Drops all elements until the effectful predicate returns true.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const dropUntil = effect.dropUntil;\n/**\n * Drops all elements so long as the predicate returns true.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const dropWhile = effect.dropWhile;\n/**\n * Determines whether all elements of the `Collection<A>` satisfies the effectual\n * predicate `f`.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const every = effect.every;\n/**\n * Determines whether any element of the `Iterable<A>` satisfies the effectual\n * predicate `f`.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const exists = fiberRuntime.exists;\n/**\n * Filters the collection using the specified effectful predicate.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const filter = fiberRuntime.filter;\n/**\n * Performs a filter and map in a single step.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const filterMap = effect.filterMap;\n/**\n * Returns the first element that satisfies the effectful predicate.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const findFirst = effect.findFirst;\n/**\n * This function takes an iterable of `Effect` values and returns a new\n * `Effect` value that represents the first `Effect` value in the iterable\n * that succeeds. If all of the `Effect` values in the iterable fail, then\n * the resulting `Effect` value will fail as well.\n *\n * This function is sequential, meaning that the `Effect` values in the\n * iterable will be executed in sequence, and the first one that succeeds\n * will determine the outcome of the resulting `Effect` value.\n *\n * @param effects - The iterable of `Effect` values to evaluate.\n *\n * @returns A new `Effect` value that represents the first successful\n * `Effect` value in the iterable, or a failed `Effect` value if all of the\n * `Effect` values in the iterable fail.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const firstSuccessOf = effect.firstSuccessOf;\n/**\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const forEach = fiberRuntime.forEach;\n/**\n * Returns a successful effect with the head of the collection if the collection\n * is non-empty, or fails with the error `None` if the collection is empty.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const head = effect.head;\n/**\n * Merges an `Iterable<Effect<A, E, R>>` to a single effect, working\n * sequentially.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const mergeAll = fiberRuntime.mergeAll;\n/**\n * Feeds elements of type `A` to a function `f` that returns an effect.\n * Collects all successes and failures in a tupled fashion.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const partition = fiberRuntime.partition;\n/**\n * Folds an `Iterable<A>` using an effectual function f, working sequentially\n * from left to right.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const reduce = effect.reduce;\n/**\n * Reduces an `Iterable<Effect<A, E, R>>` to a single effect.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const reduceEffect = fiberRuntime.reduceEffect;\n/**\n * Folds an `Iterable<A>` using an effectual function f, working sequentially from left to right.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const reduceRight = effect.reduceRight;\n/**\n * Folds over the elements in this chunk from the left, stopping the fold early\n * when the predicate is not satisfied.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const reduceWhile = effect.reduceWhile;\n/**\n * Replicates the given effect `n` times.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const replicate = fiberRuntime.replicate;\n/**\n * Performs this effect the specified number of times and collects the\n * results.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const replicateEffect = fiberRuntime.replicateEffect;\n/**\n * Takes elements until the effectual predicate returns true.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const takeUntil = effect.takeUntil;\n/**\n * Takes all elements so long as the effectual predicate returns true.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const takeWhile = effect.takeWhile;\n/**\n * Feeds elements of type `A` to `f` and accumulates all errors in error\n * channel or successes in success channel.\n *\n * This combinator is lossy meaning that if there are errors all successes\n * will be lost. To retain all information please use `partition`.\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const validateAll = fiberRuntime.validateAll;\n/**\n * Feeds elements of type `A` to `f` until it succeeds. Returns first success\n * or the accumulation of all errors.\n *\n * If `elements` is empty then `Effect.fail([])` is returned.\n *\n * @example\n * import { Effect, Exit } from \"effect\"\n *\n * const f = (n: number) => (n > 0 ? Effect.succeed(n) : Effect.fail(`${n} is negative`))\n *\n * assert.deepStrictEqual(Effect.runSyncExit(Effect.validateFirst([], f)), Exit.fail([]))\n * assert.deepStrictEqual(Effect.runSyncExit(Effect.validateFirst([1, 2], f)), Exit.succeed(1))\n * assert.deepStrictEqual(Effect.runSyncExit(Effect.validateFirst([1, -1], f)), Exit.succeed(1))\n * assert.deepStrictEqual(Effect.runSyncExit(Effect.validateFirst([-1, 2], f)), Exit.succeed(2))\n * assert.deepStrictEqual(Effect.runSyncExit(Effect.validateFirst([-1, -2], f)), Exit.fail(['-1 is negative', '-2 is negative']))\n *\n * @since 2.0.0\n * @category collecting & elements\n */\nexport const validateFirst = fiberRuntime.validateFirst;\n// -------------------------------------------------------------------------------------\n// constructors\n// -------------------------------------------------------------------------------------\n/**\n * Imports an asynchronous side-effect into a pure `Effect` value. The callback\n * function `Effect<A, E, R> => void` **MUST** be called at most once.\n *\n * The registration function can optionally return an Effect, which will be\n * executed if the `Fiber` executing this Effect is interrupted.\n *\n * The registration function can also receive an `AbortSignal` if required for\n * interruption.\n *\n * The `FiberId` of the fiber that may complete the async callback may also be\n * specified. This is called the \"blocking fiber\" because it suspends the fiber\n * executing the `async` Effect (i.e. semantically blocks the fiber from making\n * progress). Specifying this fiber id in cases where it is known will improve\n * diagnostics, but not affect the behavior of the returned effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const async = core.async;\n/**\n * Converts an asynchronous, callback-style API into an `Effect`, which will\n * be executed asynchronously.\n *\n * With this variant, the registration function may return a an `Effect`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const asyncEffect = _runtime.asyncEffect;\n/**\n * Low level constructor that enables for custom stack tracing cutpoints.\n *\n * It is meant to be called with a bag of instructions that become available in the \"this\" of the effect.\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * const throwingFunction = () => { throw new Error() }\n * const blowUp = Effect.custom(throwingFunction, function() {\n *   return Effect.succeed(this.effect_instruction_i0())\n * })\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const custom = core.custom;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const withFiberRuntime = core.withFiberRuntime;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = core.fail;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const failSync = core.failSync;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const failCause = core.failCause;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const failCauseSync = core.failCauseSync;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const die = core.die;\n/**\n * Returns an effect that dies with a `RuntimeException` having the specified\n * text message. This method can be used for terminating a fiber because a\n * defect has been detected in the code.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dieMessage = core.dieMessage;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const dieSync = core.dieSync;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const gen = effect.gen;\n/**\n * Returns an effect that will never produce anything. The moral equivalent of\n * `while(true) {}`, only without the wasted CPU cycles.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const never = core.never;\n/**\n * Requires the option produced by this value to be `None`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const none = effect.none;\n/**\n * Like `tryPromise` but produces a defect in case of errors.\n *\n * An optional `AbortSignal` can be provided to allow for interruption of the\n * wrapped Promise api.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const promise = effect.promise;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = core.succeed;\n/**\n * Returns an effect which succeeds with `None`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeedNone = effect.succeedNone;\n/**\n * Returns an effect which succeeds with the value wrapped in a `Some`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeedSome = effect.succeedSome;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const suspend = core.suspend;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const sync = core.sync;\nconst _void = core.void;\nexport {\n/**\n * @since 2.0.0\n * @category constructors\n */\n_void as void };\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const yieldNow = core.yieldNow;\n// -------------------------------------------------------------------------------------\n// error handling\n// -------------------------------------------------------------------------------------\nconst _catch = effect._catch;\nexport {\n/**\n * Recovers from specified error.\n *\n * @since 2.0.0\n * @category error handling\n */\n_catch as catch };\n/**\n * Recovers from all recoverable errors.\n *\n * **Note**: that `Effect.catchAll` will not recover from unrecoverable defects. To\n * recover from both recoverable and unrecoverable errors use\n * `Effect.catchAllCause`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAll = core.catchAll;\n/**\n * Recovers from both recoverable and unrecoverable errors.\n *\n * See `sandbox`, `mapErrorCause` for other functions that can\n * recover from defects.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAllCause = core.catchAllCause;\n/**\n * Recovers from all defects with provided function.\n *\n * **WARNING**: There is no sensible way to recover from defects. This\n * method should be used only at the boundary between Effect and an external\n * system, to transmit information on a defect for diagnostic or explanatory\n * purposes.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAllDefect = effect.catchAllDefect;\n/**\n * Recovers from errors that match the given predicate.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchIf = core.catchIf;\n/**\n * Recovers from some or all of the error cases.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchSome = core.catchSome;\n/**\n * Recovers from some or all of the error cases with provided cause.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchSomeCause = effect.catchSomeCause;\n/**\n * Recovers from some or all of the defects with provided partial function.\n *\n * **WARNING**: There is no sensible way to recover from defects. This\n * method should be used only at the boundary between Effect and an external\n * system, to transmit information on a defect for diagnostic or explanatory\n * purposes.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchSomeDefect = effect.catchSomeDefect;\n/**\n * Recovers from the specified tagged error.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchTag = effect.catchTag;\n/**\n * Recovers from the specified tagged errors.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchTags = effect.catchTags;\n/**\n * Returns an effect that succeeds with the cause of failure of this effect,\n * or `Cause.empty` if the effect did succeed.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const cause = effect.cause;\n/**\n * Returns an effect that ignores errors and runs repeatedly until it\n * eventually succeeds.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const eventually = effect.eventually;\n/**\n * Returns a new effect that ignores the success or failure of this effect.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const ignore = effect.ignore;\n/**\n * Returns a new effect that ignores the success or failure of this effect,\n * but which also logs failures at the Debug level, just in case the failure\n * turns out to be important.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const ignoreLogged = effect.ignoreLogged;\n/**\n * Exposes all parallel errors in a single call.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const parallelErrors = effect.parallelErrors;\n/**\n * Exposes the full `Cause` of failure for the specified effect.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const sandbox = effect.sandbox;\n/**\n * Retries according to the options provided\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const retry = _schedule.retry_combined;\n/**\n * Retries with the specified schedule, until it fails, and then both the\n * value produced by the schedule together with the last error are passed to\n * the recovery function.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const retryOrElse = _schedule.retryOrElse_Effect;\nconst try_ = effect.try_;\nexport {\n/**\n * Imports a synchronous side-effect into a pure `Effect` value, translating any\n * thrown exceptions into typed failed effects creating with `Effect.fail`.\n *\n * @since 2.0.0\n * @category error handling\n */\ntry_ as try };\n/**\n * Returns an effect whose success is mapped by the specified side effecting\n * `try` function, translating any promise rejections into typed failed effects\n * via the `catch` function.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const tryMap = effect.tryMap;\n/**\n * Returns an effect whose success is mapped by the specified side effecting\n * `try` function, translating any promise rejections into typed failed effects\n * via the `catch` function.\n *\n * An optional `AbortSignal` can be provided to allow for interruption of the\n * wrapped Promise api.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const tryMapPromise = effect.tryMapPromise;\n/**\n * Create an `Effect` that when executed will construct `promise` and wait for\n * its result, errors will produce failure as `unknown`.\n *\n * An optional `AbortSignal` can be provided to allow for interruption of the\n * wrapped Promise api.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const tryPromise = effect.tryPromise;\n/**\n * The inverse operation `sandbox(effect)`\n *\n * Terminates with exceptions on the `Left` side of the `Either` error, if it\n * exists. Otherwise extracts the contained `Effect<A, E, R>`\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const unsandbox = effect.unsandbox;\n// -------------------------------------------------------------------------------------\n// interuption\n// -------------------------------------------------------------------------------------\n/**\n * This function checks if any fibers are attempting to interrupt the current\n * fiber, and if so, performs self-interruption.\n *\n * Note that this allows for interruption to occur in uninterruptible regions.\n *\n * @returns A new `Effect` value that represents the check for interruption\n * and the potential self-interruption of the current fiber.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const allowInterrupt = effect.allowInterrupt;\n/**\n * Checks the interrupt status, and produces the effect returned by the\n * specified callback.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const checkInterruptible = core.checkInterruptible;\n/**\n * Returns an effect whose interruption will be disconnected from the\n * fiber's own interruption, being performed in the background without\n * slowing down the fiber's interruption.\n *\n * This method is useful to create \"fast interrupting\" effects. For\n * example, if you call this on a bracketed effect, then even if the\n * effect is \"stuck\" in acquire or release, its interruption will return\n * immediately, while the acquire / release are performed in the\n * background.\n *\n * See timeout and race for other applications.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const disconnect = fiberRuntime.disconnect;\n/**\n * @since 2.0.0\n * @category interruption\n */\nexport const interrupt = core.interrupt;\n/**\n * @since 2.0.0\n * @category interruption\n */\nexport const interruptWith = core.interruptWith;\n/**\n * @since 2.0.0\n * @category interruption\n */\nexport const interruptible = core.interruptible;\n/**\n * @since 2.0.0\n * @category interruption\n */\nexport const interruptibleMask = core.interruptibleMask;\n/**\n * @since 2.0.0\n * @category interruption\n */\nexport const onInterrupt = core.onInterrupt;\n/**\n * @since 2.0.0\n * @category interruption\n */\nexport const uninterruptible = core.uninterruptible;\n/**\n * @since 2.0.0\n * @category interruption\n */\nexport const uninterruptibleMask = core.uninterruptibleMask;\n// -------------------------------------------------------------------------------------\n// lifting\n// -------------------------------------------------------------------------------------\n/**\n * Transforms a `Predicate` function into an `Effect` returning the input value if the predicate returns `true`\n * or failing with specified error if the predicate fails\n *\n * @param predicate - A `Predicate` function that takes in a value of type `A` and returns a boolean.\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * const isPositive = (n: number): boolean => n > 0\n *\n * // succeeds with `1`\n * Effect.liftPredicate(1, isPositive, n => `${n} is not positive`)\n *\n * // fails with `\"0 is not positive\"`\n * Effect.liftPredicate(0, isPositive, n => `${n} is not positive`)\n *\n * @category lifting\n * @since 3.4.0\n */\nexport const liftPredicate = effect.liftPredicate;\n// -------------------------------------------------------------------------------------\n// mapping\n// -------------------------------------------------------------------------------------\n/**\n * This function maps the success value of an `Effect` value to a specified\n * constant value.\n *\n * @param value - The constant value that the success value of the `Effect`\n * value will be mapped to.\n * @param self - The `Effect` value whose success value will be mapped to the\n * specified constant value.\n *\n * @returns A new `Effect` value that represents the mapping of the success\n * value of the original `Effect` value to the specified constant value.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const as = core.as;\n/**\n * This function maps the success value of an `Effect` value to a `Some` value\n * in an `Option` value. If the original `Effect` value fails, the returned\n * `Effect` value will also fail.\n *\n * @param self - The `Effect` value whose success value will be mapped to a\n * `Some` value in an `Option` value.\n *\n * @returns A new `Effect` value that represents the mapping of the success\n * value of the original `Effect` value to a `Some` value in an `Option`\n * value. The returned `Effect` value may fail if the original `Effect` value\n * fails.\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const asSome = effect.asSome;\n/**\n * This function maps the error value of an `Effect` value to a `Some` value\n * in an `Option` value. If the original `Effect` value succeeds, the returned\n * `Effect` value will also succeed.\n *\n * @param self - The `Effect` value whose error value will be mapped to a\n * `Some` value in an `Option` value.\n *\n * @returns A new `Effect` value that represents the mapping of the error\n * value of the original `Effect` value to a `Some` value in an `Option`\n * value. The returned `Effect` value may succeed if the original `Effect`\n * value succeeds.\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const asSomeError = effect.asSomeError;\n/**\n * This function maps the success value of an `Effect` value to `void`. If the\n * original `Effect` value succeeds, the returned `Effect` value will also\n * succeed. If the original `Effect` value fails, the returned `Effect` value\n * will fail with the same error.\n *\n * @param self - The `Effect` value whose success value will be mapped to `void`.\n *\n * @returns A new `Effect` value that represents the mapping of the success\n * value of the original `Effect` value to `void`.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const asVoid = core.asVoid;\n/**\n * Returns an effect that swaps the error/success cases. This allows you to\n * use all methods on the error channel, possibly before flipping back.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const flip = core.flip;\n/**\n * Swaps the error/value parameters, applies the function `f` and flips the\n * parameters back\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const flipWith = effect.flipWith;\n/**\n * @since 2.0.0\n * @category mapping\n */\nexport const map = core.map;\n/**\n * Statefully and effectfully maps over the elements of this chunk to produce\n * new elements.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapAccum = effect.mapAccum;\n/**\n * Returns an effect whose failure and success channels have been mapped by\n * the specified `onFailure` and `onSuccess` functions.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapBoth = core.mapBoth;\n/**\n * Returns an effect with its error channel mapped using the specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapError = core.mapError;\n/**\n * Returns an effect with its full cause of failure mapped using the specified\n * function. This can be used to transform errors while preserving the\n * original structure of `Cause`.\n *\n * See `sandbox`, `catchAllCause` for other functions for dealing\n * with defects.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapErrorCause = effect.mapErrorCause;\n/**\n * Returns a new effect where the error channel has been merged into the\n * success channel to their common combined type.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const merge = effect.merge;\n/**\n * Returns a new effect where boolean value of this effect is negated.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const negate = effect.negate;\n// -------------------------------------------------------------------------------------\n// scoping, resources & finalization\n// -------------------------------------------------------------------------------------\n/**\n * This function constructs a scoped resource from an `acquire` and `release`\n * `Effect` value.\n *\n * If the `acquire` `Effect` value successfully completes execution, then the\n * `release` `Effect` value will be added to the finalizers associated with the\n * scope of this `Effect` value, and it is guaranteed to be run when the scope\n * is closed.\n *\n * The `acquire` and `release` `Effect` values will be run uninterruptibly.\n * Additionally, the `release` `Effect` value may depend on the `Exit` value\n * specified when the scope is closed.\n *\n * @param acquire - The `Effect` value that acquires the resource.\n * @param release - The `Effect` value that releases the resource.\n *\n * @returns A new `Effect` value that represents the scoped resource.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const acquireRelease = fiberRuntime.acquireRelease;\n/**\n * This function constructs a scoped resource from an `acquire` and `release`\n * `Effect` value.\n *\n * If the `acquire` `Effect` value successfully completes execution, then the\n * `release` `Effect` value will be added to the finalizers associated with the\n * scope of this `Effect` value, and it is guaranteed to be run when the scope\n * is closed.\n *\n * The `acquire` `Effect` values will be run interruptibly.\n * The `release` `Effect` values will be run uninterruptibly.\n *\n * Additionally, the `release` `Effect` value may depend on the `Exit` value\n * specified when the scope is closed.\n *\n * @param acquire - The `Effect` value that acquires the resource.\n * @param release - The `Effect` value that releases the resource.\n *\n * @returns A new `Effect` value that represents the scoped resource.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const acquireReleaseInterruptible = fiberRuntime.acquireReleaseInterruptible;\n/**\n * This function is used to ensure that an `Effect` value that represents the\n * acquisition of a resource (for example, opening a file, launching a thread,\n * etc.) will not be interrupted, and that the resource will always be released\n * when the `Effect` value completes execution.\n *\n * `acquireUseRelease` does the following:\n *\n *   1. Ensures that the `Effect` value that acquires the resource will not be\n *      interrupted. Note that acquisition may still fail due to internal\n *      reasons (such as an uncaught exception).\n *   2. Ensures that the `release` `Effect` value will not be interrupted,\n *      and will be executed as long as the acquisition `Effect` value\n *      successfully acquires the resource.\n *\n * During the time period between the acquisition and release of the resource,\n * the `use` `Effect` value will be executed.\n *\n * If the `release` `Effect` value fails, then the entire `Effect` value will\n * fail, even if the `use` `Effect` value succeeds. If this fail-fast behavior\n * is not desired, errors produced by the `release` `Effect` value can be caught\n * and ignored.\n *\n * @param acquire - The `Effect` value that acquires the resource.\n * @param use - The `Effect` value that is executed between the acquisition\n * and release of the resource.\n * @param release - The `Effect` value that releases the resource.\n *\n * @returns A new `Effect` value that represents the acquisition, use, and\n * release of the resource.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const acquireUseRelease = core.acquireUseRelease;\n/**\n * This function adds a finalizer to the scope of the calling `Effect` value.\n * The finalizer is guaranteed to be run when the scope is closed, and it may\n * depend on the `Exit` value that the scope is closed with.\n *\n * @param finalizer - The finalizer to add to the scope of the calling\n * `Effect` value. This function must take an `Exit` value as its parameter,\n * and return a new `Effect` value.\n *\n * @returns A new `Effect` value that represents the addition of the finalizer\n * to the scope of the calling `Effect` value.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const addFinalizer = fiberRuntime.addFinalizer;\n/**\n * Returns an effect that, if this effect _starts_ execution, then the\n * specified `finalizer` is guaranteed to be executed, whether this effect\n * succeeds, fails, or is interrupted.\n *\n * For use cases that need access to the effect's result, see `onExit`.\n *\n * Finalizers offer very powerful guarantees, but they are low-level, and\n * should generally not be used for releasing resources. For higher-level\n * logic built on `ensuring`, see the `acquireRelease` family of methods.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const ensuring = fiberRuntime.ensuring;\n/**\n * Runs the specified effect if this effect fails, providing the error to the\n * effect if it exists. The provided effect will not be interrupted.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const onError = core.onError;\n/**\n * Ensures that a cleanup functions runs, whether this effect succeeds, fails,\n * or is interrupted.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const onExit = core.onExit;\n/**\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const parallelFinalizers = fiberRuntime.parallelFinalizers;\n/**\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const finalizersMask = fiberRuntime.finalizersMask;\n/**\n * Returns a new scoped workflow that runs finalizers added to the scope of\n * this workflow sequentially in the reverse of the order in which they were\n * added. Note that finalizers are run sequentially by default so this only\n * has meaning if used within a scope where finalizers are being run in\n * parallel.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const sequentialFinalizers = fiberRuntime.sequentialFinalizers;\n/**\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const scope = fiberRuntime.scope;\n/**\n * Accesses the current scope and uses it to perform the specified effect.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const scopeWith = fiberRuntime.scopeWith;\n/**\n * Scopes all resources used in this workflow to the lifetime of the workflow,\n * ensuring that their finalizers are run as soon as this workflow completes\n * execution, whether by success, failure, or interruption.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const scoped = fiberRuntime.scopedEffect;\n/**\n * Scopes all resources acquired by `resource` to the lifetime of `use`\n * without effecting the scope of any resources acquired by `use`.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const using = fiberRuntime.using;\n/**\n * Returns a new scoped workflow that returns the result of this workflow as\n * well as a finalizer that can be run to close the scope of this workflow.\n *\n * @since 2.0.0\n * @category scoping, resources & finalization\n */\nexport const withEarlyRelease = fiberRuntime.withEarlyRelease;\n// -------------------------------------------------------------------------------------\n// supervision & fibers\n// -------------------------------------------------------------------------------------\n/**\n * Returns a new effect that will not succeed with its value before first\n * waiting for the end of all child fibers forked by the effect.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const awaitAllChildren = circular.awaitAllChildren;\n/**\n * Returns a new workflow that will not supervise any fibers forked by this\n * workflow.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const daemonChildren = fiberRuntime.daemonChildren;\n/**\n * Constructs an effect with information about the current `Fiber`.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const descriptor = effect.descriptor;\n/**\n * Constructs an effect based on information about the current `Fiber`.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const descriptorWith = effect.descriptorWith;\n/**\n * Returns a new workflow that executes this one and captures the changes in\n * `FiberRef` values.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const diffFiberRefs = effect.diffFiberRefs;\n/**\n * Acts on the children of this fiber (collected into a single fiber),\n * guaranteeing the specified callback will be invoked, whether or not this\n * effect succeeds.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const ensuringChild = circular.ensuringChild;\n/**\n * Acts on the children of this fiber, guaranteeing the specified callback\n * will be invoked, whether or not this effect succeeds.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const ensuringChildren = circular.ensuringChildren;\n/**\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const fiberId = core.fiberId;\n/**\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const fiberIdWith = core.fiberIdWith;\n/**\n * Returns an effect that forks this effect into its own separate fiber,\n * returning the fiber immediately, without waiting for it to begin executing\n * the effect.\n *\n * You can use the `fork` method whenever you want to execute an effect in a\n * new fiber, concurrently and without \"blocking\" the fiber executing other\n * effects. Using fibers can be tricky, so instead of using this method\n * directly, consider other higher-level methods, such as `raceWith`,\n * `zipPar`, and so forth.\n *\n * The fiber returned by this method has methods to interrupt the fiber and to\n * wait for it to finish executing the effect. See `Fiber` for more\n * information.\n *\n * Whenever you use this method to launch a new fiber, the new fiber is\n * attached to the parent fiber's scope. This means when the parent fiber\n * terminates, the child fiber will be terminated as well, ensuring that no\n * fibers leak. This behavior is called \"auto supervision\", and if this\n * behavior is not desired, you may use the `forkDaemon` or `forkIn` methods.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const fork = fiberRuntime.fork;\n/**\n * Forks the effect into a new fiber attached to the global scope. Because the\n * new fiber is attached to the global scope, when the fiber executing the\n * returned effect terminates, the forked fiber will continue running.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const forkDaemon = fiberRuntime.forkDaemon;\n/**\n * Returns an effect that forks all of the specified values, and returns a\n * composite fiber that produces a list of their results, in order.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const forkAll = circular.forkAll;\n/**\n * Forks the effect in the specified scope. The fiber will be interrupted\n * when the scope is closed.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const forkIn = circular.forkIn;\n/**\n * Forks the fiber in a `Scope`, interrupting it when the scope is closed.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const forkScoped = circular.forkScoped;\n/**\n * Like fork but handles an error with the provided handler.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const forkWithErrorHandler = fiberRuntime.forkWithErrorHandler;\n/**\n * Creates an `Effect` value that represents the exit value of the specified\n * fiber.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const fromFiber = circular.fromFiber;\n/**\n * Creates an `Effect` value that represents the exit value of the specified\n * fiber.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const fromFiberEffect = circular.fromFiberEffect;\n/**\n * Returns an effect with the behavior of this one, but where all child fibers\n * forked in the effect are reported to the specified supervisor.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const supervised = circular.supervised;\n/**\n * Transplants specified effects so that when those effects fork other\n * effects, the forked effects will be governed by the scope of the fiber that\n * executes this effect.\n *\n * This can be used to \"graft\" deep grandchildren onto a higher-level scope,\n * effectively extending their lifespans into the parent scope.\n *\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const transplant = core.transplant;\n/**\n * @since 2.0.0\n * @category supervision & fibers\n */\nexport const withConcurrency = core.withConcurrency;\n// ---------------------------------------------------------------------------------------\n// scheduler\n// ---------------------------------------------------------------------------------------\n/**\n * Sets the provided scheduler for usage in the wrapped effect\n *\n * @since 2.0.0\n * @category scheduler\n */\nexport const withScheduler = Scheduler.withScheduler;\n/**\n * Sets the scheduling priority used when yielding\n *\n * @since 2.0.0\n * @category utils\n */\nexport const withSchedulingPriority = core.withSchedulingPriority;\n/**\n * Sets the maximum number of operations before yield by the default schedulers\n *\n * @since 2.0.0\n * @category utils\n */\nexport const withMaxOpsBeforeYield = core.withMaxOpsBeforeYield;\n// ---------------------------------------------------------------------------------------\n// clock\n// ---------------------------------------------------------------------------------------\n/**\n * Retreives the `Clock` service from the context\n *\n * @since 2.0.0\n * @category clock\n */\nexport const clock = effect.clock;\n/**\n * Retreives the `Clock` service from the context and provides it to the\n * specified effectful function.\n *\n * @since 2.0.0\n * @category clock\n */\nexport const clockWith = effect.clockWith;\n/**\n * Sets the implementation of the clock service to the specified value and\n * restores it to its original value when the scope is closed.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const withClockScoped = fiberRuntime.withClockScoped;\n/**\n * Executes the specified workflow with the specified implementation of the\n * clock service.\n *\n * @since 2.0.0\n * @category clock\n */\nexport const withClock = defaultServices.withClock;\n// -------------------------------------------------------------------------------------\n// console\n// -------------------------------------------------------------------------------------\n/**\n * Retreives the `Console` service from the context\n *\n * @since 2.0.0\n * @category console\n */\nexport const console = _console.console;\n/**\n * Retreives the `Console` service from the context and provides it to the\n * specified effectful function.\n *\n * @since 2.0.0\n * @category console\n */\nexport const consoleWith = _console.consoleWith;\n/**\n * Sets the implementation of the console service to the specified value and\n * restores it to its original value when the scope is closed.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const withConsoleScoped = _console.withConsoleScoped;\n/**\n * Executes the specified workflow with the specified implementation of the\n * console service.\n *\n * @since 2.0.0\n * @category console\n */\nexport const withConsole = _console.withConsole;\n// ---------------------------------------------------------------------------------------\n// delays & timeouts\n// ---------------------------------------------------------------------------------------\n/**\n * Returns an effect that is delayed from this effect by the specified\n * `Duration`.\n *\n * @since 2.0.0\n * @category delays & timeouts\n */\nexport const delay = effect.delay;\n/**\n * Returns an effect that suspends for the specified duration. This method is\n * asynchronous, and does not actually block the fiber executing the effect.\n *\n * @since 2.0.0\n * @category delays & timeouts\n */\nexport const sleep = effect.sleep;\n/**\n * Returns a new effect that executes this one and times the execution.\n *\n * @since 2.0.0\n * @category delays & timeouts\n */\nexport const timed = effect.timed;\n/**\n * A more powerful variation of `timed` that allows specifying the clock.\n *\n * @since 2.0.0\n * @category delays & timeouts\n */\nexport const timedWith = effect.timedWith;\n/**\n * Returns an effect that will timeout this effect, failing with a `Cause.TimeoutException`\n * if the timeout elapses before the effect has produced a value.\n *\n * If the timeout elapses without producing a value, the running effect will\n * be safely interrupted.\n *\n * WARNING: The effect returned by this method will not itself return until\n * the underlying effect is actually interrupted. This leads to more\n * predictable resource utilization. If early return is desired, then instead\n * of using `effect.timeout(d)`, use `effect.disconnect.timeout(d)`, which\n * first disconnects the effect's interruption signal before performing the\n * timeout, resulting in earliest possible return, before an underlying effect\n * has been successfully interrupted.\n *\n * @since 2.0.0\n * @category delays & timeouts\n */\nexport const timeout = circular.timeout;\n/**\n * Returns an effect that will timeout this effect, returning `None` if the\n * timeout elapses before the effect has produced a value; and returning\n * `Some` of the produced value otherwise.\n *\n * If the timeout elapses without producing a value, the running effect will\n * be safely interrupted.\n *\n * WARNING: The effect returned by this method will not itself return until\n * the underlying effect is actually interrupted. This leads to more\n * predictable resource utilization. If early return is desired, then instead\n * of using `effect.timeout(d)`, use `effect.disconnect.timeout(d)`, which\n * first disconnects the effect's interruption signal before performing the\n * timeout, resulting in earliest possible return, before an underlying effect\n * has been successfully interrupted.\n *\n * @since 3.1.0\n * @category delays & timeouts\n */\nexport const timeoutOption = circular.timeoutOption;\n/**\n * The same as `timeout`, but instead of producing a `None` in the event of\n * timeout, it will produce the specified error.\n *\n * @since 2.0.0\n * @category delays & timeouts\n */\nexport const timeoutFail = circular.timeoutFail;\n/**\n * The same as `timeout`, but instead of producing a `None` in the event of\n * timeout, it will produce the specified failure.\n *\n * @since 2.0.0\n * @category delays & timeouts\n */\nexport const timeoutFailCause = circular.timeoutFailCause;\n/**\n * Returns an effect that will timeout this effect, returning either the\n * default value if the timeout elapses before the effect has produced a\n * value or returning the result of applying the function `onSuccess` to the\n * success value of the effect.\n *\n * If the timeout elapses without producing a value, the running effect will\n * be safely interrupted.\n *\n * @since 2.0.0\n * @category delays & timeouts\n */\nexport const timeoutTo = circular.timeoutTo;\n// -------------------------------------------------------------------------------------\n// config\n// -------------------------------------------------------------------------------------\n/**\n * Retrieves the default config provider, and passes it to the specified\n * function, which may return an effect that uses the provider to perform some\n * work or compute some value.\n *\n * @since 2.0.0\n * @category config\n */\nexport const configProviderWith = defaultServices.configProviderWith;\n/**\n * Executes the specified workflow with the specified configuration provider.\n *\n * @since 2.0.0\n * @category config\n */\nexport const withConfigProvider = defaultServices.withConfigProvider;\n/**\n * Sets the configuration provider to the specified value and restores it to its original value\n * when the scope is closed.\n *\n * @since 2.0.0\n * @category config\n */\nexport const withConfigProviderScoped = fiberRuntime.withConfigProviderScoped;\n// -------------------------------------------------------------------------------------\n// context\n// -------------------------------------------------------------------------------------\n/**\n * @since 2.0.0\n * @category context\n */\nexport const context = core.context;\n/**\n * Accesses the context of the effect.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWith = effect.contextWith;\n/**\n * Effectually accesses the context of the effect.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWithEffect = core.contextWithEffect;\n/**\n * Provides some of the context required to run this effect,\n * leaving the remainder `R0`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const mapInputContext = core.mapInputContext;\n/**\n * Splits the context into two parts, providing one part using the\n * specified layer/context/runtime and leaving the remainder `R0`\n *\n * @since 2.0.0\n * @category context\n */\nexport const provide = layer.effect_provide;\n/**\n * Provides the effect with the single service it requires. If the effect\n * requires more than one service use `provide` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideService = effect.provideService;\n/**\n * Provides the effect with the single service it requires. If the effect\n * requires more than one service use `provide` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideServiceEffect = effect.provideServiceEffect;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const serviceFunction = effect.serviceFunction;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const serviceFunctionEffect = effect.serviceFunctionEffect;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const serviceFunctions = effect.serviceFunctions;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const serviceConstants = effect.serviceConstants;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const serviceMembers = effect.serviceMembers;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const serviceOption = effect.serviceOption;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const serviceOptional = effect.serviceOptional;\n/**\n * Updates the service with the required service entry.\n *\n * @since 2.0.0\n * @category context\n */\nexport const updateService = effect.updateService;\n// -------------------------------------------------------------------------------------\n// do notation\n// -------------------------------------------------------------------------------------\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Effect` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link bind}\n * @see {@link bindTo}\n * @see {@link let_ let}\n *\n * @example\n * import { Effect, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Effect.Do,\n *   Effect.bind(\"x\", () => Effect.succeed(2)),\n *   Effect.bind(\"y\", () => Effect.succeed(3)),\n *   Effect.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(result), { x: 2, y: 3, sum: 5 })\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const Do = effect.Do;\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Effect` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link let_ let}\n *\n * @example\n * import { Effect, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Effect.Do,\n *   Effect.bind(\"x\", () => Effect.succeed(2)),\n *   Effect.bind(\"y\", () => Effect.succeed(3)),\n *   Effect.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(result), { x: 2, y: 3, sum: 5 })\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bind = effect.bind;\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Effect` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bind}\n * @see {@link let_ let}\n *\n * @example\n * import { Effect, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Effect.Do,\n *   Effect.bind(\"x\", () => Effect.succeed(2)),\n *   Effect.bind(\"y\", () => Effect.succeed(3)),\n *   Effect.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(result), { x: 2, y: 3, sum: 5 })\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bindTo = effect.bindTo;\nconst let_ = effect.let_;\nexport {\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Effect` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bind}\n * @see {@link bindTo}\n *\n * @example\n * import { Effect, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Effect.Do,\n *   Effect.bind(\"x\", () => Effect.succeed(2)),\n *   Effect.bind(\"y\", () => Effect.succeed(3)),\n *   Effect.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(result), { x: 2, y: 3, sum: 5 })\n *\n * @category do notation\n * @since 2.0.0\n */\nlet_ as let };\n// -------------------------------------------------------------------------------------\n// conversions\n// -------------------------------------------------------------------------------------\n/**\n * Returns an effect whose failure and success have been lifted into an\n * `Either`. The resulting effect cannot fail, because the failure case has\n * been exposed as part of the `Either` success case.\n *\n * This method is useful for recovering from effects that may fail.\n *\n * The error parameter of the returned `Effect` is `never`, since it is\n * guaranteed the effect does not model failure.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const either = core.either;\n/**\n * @since 2.0.0\n * @category conversions\n */\nexport const exit = core.exit;\n/**\n * Returns an effect that will succeed or fail the specified `Deferred` based\n * upon the result of the effect. Also synchronizes interruption, so if the\n * provided effect is interrupted, the specified `Deferred` will be interrupted\n * as well.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const intoDeferred = core.intoDeferred;\n/**\n * Executes this effect, skipping the error but returning optionally the\n * success.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const option = effect.option;\n// -------------------------------------------------------------------------------------\n// filtering & conditionals\n// -------------------------------------------------------------------------------------\nconst if_ = core.if_;\nexport {\n/**\n * Runs `onTrue` if the result of `self` is `true` and `onFalse` otherwise.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nif_ as if };\n/**\n * Filter the specified effect with the provided function, dying with specified\n * defect if the predicate fails.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const filterOrDie = effect.filterOrDie;\n/**\n * Filter the specified effect with the provided function, dying with specified\n * message if the predicate fails.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const filterOrDieMessage = effect.filterOrDieMessage;\n/**\n * Filters the specified effect with the provided function returning the value\n * of the effect if it is successful, otherwise returns the value of `orElse`.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const filterOrElse = effect.filterOrElse;\n/**\n * Filter the specified effect with the provided function, failing with specified\n * error if the predicate fails.\n *\n * In addition to the filtering capabilities discussed earlier, you have the option to further\n * refine and narrow down the type of the success channel by providing a\n * [user-defined type guard](https://www.typescriptlang.org/docs/handbook/2/narrowing.html#using-type-predicates).\n * Let's explore this concept through an example:\n *\n * @example\n * import { Effect, pipe } from \"effect\"\n *\n * // Define a user interface\n * interface User {\n *   readonly name: string\n * }\n *\n * // Assume an asynchronous authentication function\n * declare const auth: () => Promise<User | null>\n *\n * const program = pipe(\n *   Effect.promise(() => auth()),\n *   Effect.filterOrFail(\n *     // Define a guard to narrow down the type\n *     (user): user is User => user !== null,\n *     () => new Error(\"Unauthorized\")\n *   ),\n *   Effect.map((user) => user.name) // The 'user' here has type `User`, not `User | null`\n * )\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const filterOrFail = effect.filterOrFail;\n/**\n * The moral equivalent of `if (!p) exp`.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const unless = effect.unless;\n/**\n * The moral equivalent of `if (!p) exp` when `p` has side-effects.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const unlessEffect = effect.unlessEffect;\n/**\n * The moral equivalent of `if (p) exp`.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const when = effect.when;\n/**\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const whenEffect = core.whenEffect;\n/**\n * Executes this workflow when value of the specified `FiberRef` satisfies the\n * predicate.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const whenFiberRef = effect.whenFiberRef;\n/**\n * Executes this workflow when the value of the `Ref` satisfies the predicate.\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const whenRef = effect.whenRef;\n// -------------------------------------------------------------------------------------\n// sequencing\n// -------------------------------------------------------------------------------------\n/**\n * This function is a pipeable operator that maps over an `Effect` value,\n * flattening the result of the mapping function into a new `Effect` value.\n *\n * @param f - The mapping function to apply to the `Effect` value.\n * This function must return another `Effect` value.\n *\n * @returns A new `Effect` value that is the result of flattening the\n * mapped `Effect` value.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = core.flatMap;\n/**\n * Executes a sequence of two actions, typically two `Effect`s, where the second action can depend on the result of the first action.\n *\n * The `that` action can take various forms:\n *\n * - a value\n * - a function returning a value\n * - a promise\n * - a function returning a promise\n * - an effect\n * - a function returning an effect\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * assert.deepStrictEqual(Effect.runSync(Effect.succeed(\"aa\").pipe(Effect.andThen(1))), 1)\n * assert.deepStrictEqual(Effect.runSync(Effect.succeed(\"aa\").pipe(Effect.andThen((s) => s.length))), 2)\n *\n * assert.deepStrictEqual(await Effect.runPromise(Effect.succeed(\"aa\").pipe(Effect.andThen(Promise.resolve(1)))), 1)\n * assert.deepStrictEqual(await Effect.runPromise(Effect.succeed(\"aa\").pipe(Effect.andThen((s) => Promise.resolve(s.length)))), 2)\n *\n * assert.deepStrictEqual(Effect.runSync(Effect.succeed(\"aa\").pipe(Effect.andThen(Effect.succeed(1)))), 1)\n * assert.deepStrictEqual(Effect.runSync(Effect.succeed(\"aa\").pipe(Effect.andThen((s) => Effect.succeed(s.length)))), 2)\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const andThen = core.andThen;\n/**\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatten = core.flatten;\n/**\n * Returns an effect that races this effect with all the specified effects,\n * yielding the value of the first effect to succeed with a value. Losers of\n * the race will be interrupted immediately\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const raceAll = fiberRuntime.raceAll;\n/**\n * Returns an effect that races this effect with the specified effect,\n * returning the first successful `A` from the faster side. If one effect\n * succeeds, the other will be interrupted. If neither succeeds, then the\n * effect will fail with some error.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const race = fiberRuntime.race;\n/**\n * Returns an effect that races this effect with the specified effect,\n * yielding the first result to complete, whether by success or failure. If\n * neither effect completes, then the composed effect will not complete.\n *\n * WARNING: The raced effect will safely interrupt the \"loser\", but will not\n * resume until the loser has been cleanly terminated. If early return is\n * desired, then instead of performing `l raceFirst r`, perform\n * `l.disconnect raceFirst r.disconnect`, which disconnects left and right\n * interrupt signal, allowing a fast return, with interruption performed\n * in the background.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const raceFirst = circular.raceFirst;\n/**\n * Returns an effect that races this effect with the specified effect, calling\n * the specified finisher as soon as one result or the other has been computed.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const raceWith = fiberRuntime.raceWith;\n/**\n * Summarizes a effect by computing some value before and after execution, and\n * then combining the values to produce a summary, together with the result of\n * execution.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const summarized = effect.summarized;\n/**\n * @since 2.0.0\n * @category sequencing\n */\nexport const tap = core.tap;\n/**\n * Inspects both success and failure outcomes of an effect, performing different actions based on the result.\n *\n * @example\n * import { Effect, Random, Console } from \"effect\"\n *\n * // Simulate an effect that might fail\n * const task = Effect.filterOrFail(\n *   Random.nextRange(-1, 1),\n *   (n) => n >= 0,\n *   () => \"random number is negative\"\n * )\n *\n * // Define an effect that logs both success and failure outcomes of the 'task'\n * const tapping = Effect.tapBoth(task, {\n *   onFailure: (error) => Console.log(`failure: ${error}`),\n *   onSuccess: (randomNumber) => Console.log(`random number: ${randomNumber}`)\n * })\n *\n * Effect.runFork(tapping)\n * // Example Output:\n * // failure: random number is negative\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapBoth = effect.tapBoth;\n/**\n * Specifically inspects non-recoverable failures or defects in an effect (i.e., one or more `Die` causes).\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * // Create an effect that is designed to fail, simulating an occurrence of a network error\n * const task1: Effect.Effect<number, string> = Effect.fail(\"NetworkError\")\n *\n * // this won't log anything because is not a defect\n * const tapping1 = Effect.tapDefect(task1, (cause) =>\n *   Console.log(`defect: ${cause}`)\n * )\n *\n * Effect.runFork(tapping1)\n * // No Output\n *\n * // Simulate a severe failure in the system by causing a defect with a specific message.\n * const task2: Effect.Effect<number, string> = Effect.dieMessage(\n *   \"Something went wrong\"\n * )\n *\n * // This will only log defects, not errors\n * const tapping2 = Effect.tapDefect(task2, (cause) =>\n *   Console.log(`defect: ${cause}`)\n * )\n *\n * Effect.runFork(tapping2)\n * // Output:\n * // defect: RuntimeException: Something went wrong\n * //   ... stack trace ...\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapDefect = effect.tapDefect;\n/**\n * Executes an effectful operation to inspect the failure of an effect without altering it.\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * // Create an effect that is designed to fail, simulating an occurrence of a network error\n * const task: Effect.Effect<number, string> = Effect.fail(\"NetworkError\")\n *\n * // Log the error message if the task fails. This function only executes if there is an error,\n * // providing a method to handle or inspect errors without altering the outcome of the original effect.\n * const tapping = Effect.tapError(task, (error) =>\n *   Console.log(`expected error: ${error}`)\n * )\n *\n * Effect.runFork(tapping)\n * // Output:\n * // expected error: NetworkError\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapError = effect.tapError;\n/**\n * Specifically inspects a failure with a particular tag, allowing focused error handling.\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * class NetworkError {\n *   readonly _tag = \"NetworkError\"\n *   constructor(readonly statusCode: number) {}\n * }\n * class ValidationError {\n *   readonly _tag = \"ValidationError\"\n *   constructor(readonly field: string) {}\n * }\n *\n * // Create an effect that is designed to fail, simulating an occurrence of a network error\n * const task: Effect.Effect<number, NetworkError | ValidationError> =\n *   Effect.fail(new NetworkError(504))\n *\n * // Apply an error handling function only to errors tagged as \"NetworkError\",\n * // and log the corresponding status code of the error.\n * const tapping = Effect.tapErrorTag(task, \"NetworkError\", (error) =>\n *   Console.log(`expected error: ${error.statusCode}`)\n * )\n *\n * Effect.runFork(tapping)\n * // Output:\n * // expected error: 504\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapErrorTag = effect.tapErrorTag;\n/**\n * Inspects the underlying cause of an effect's failure.\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * // Create an effect that is designed to fail, simulating an occurrence of a network error\n * const task1: Effect.Effect<number, string> = Effect.fail(\"NetworkError\")\n *\n * // This will log the cause of any expected error or defect\n * const tapping1 = Effect.tapErrorCause(task1, (cause) =>\n *   Console.log(`error cause: ${cause}`)\n * )\n *\n * Effect.runFork(tapping1)\n * // Output:\n * // error cause: Error: NetworkError\n *\n * // Simulate a severe failure in the system by causing a defect with a specific message.\n * const task2: Effect.Effect<number, string> = Effect.dieMessage(\n *   \"Something went wrong\"\n * )\n *\n * // This will log the cause of any expected error or defect\n * const tapping2 = Effect.tapErrorCause(task2, (cause) =>\n *   Console.log(`error cause: ${cause}`)\n * )\n *\n * Effect.runFork(tapping2)\n * // Output:\n * // error cause: RuntimeException: Something went wrong\n * //   ... stack trace ...\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapErrorCause = effect.tapErrorCause;\n// -------------------------------------------------------------------------------------\n// repetition / recursion\n// -------------------------------------------------------------------------------------\n/**\n * Repeats this effect forever (until the first error).\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const forever = effect.forever;\n/**\n * The `Effect.iterate` function allows you to iterate with an effectful operation. It uses an effectful `body` operation to change the state during each iteration and continues the iteration as long as the `while` function evaluates to `true`:\n *\n * ```ts\n * Effect.iterate(initial, options: { while, body })\n * ```\n *\n * We can think of `Effect.iterate` as equivalent to a `while` loop in JavaScript:\n *\n * ```ts\n * let result = initial\n *\n * while (options.while(result)) {\n *   result = options.body(result)\n * }\n *\n * return result\n * ```\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const iterate = effect.iterate;\n/**\n * The `Effect.loop` function allows you to repeatedly change the state based on an `step` function until a condition given by the `while` function is evaluated to `true`:\n *\n * ```ts\n * Effect.loop(initial, options: { while, step, body })\n * ```\n *\n * It collects all intermediate states in an array and returns it as the final result.\n *\n * We can think of Effect.loop as equivalent to a while loop in JavaScript:\n *\n * ```ts\n * let state = initial\n * const result = []\n *\n * while (options.while(state)) {\n *   result.push(options.body(state))\n *   state = options.step(state)\n * }\n *\n * return result\n * ```\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const loop = effect.loop;\n/**\n * The `repeat` function returns a new effect that repeats the given effect\n * according to a specified schedule or until the first failure. The scheduled\n * recurrences are in addition to the initial execution, so `Effect.repeat(action,\n * Schedule.once)` executes `action` once initially, and if it succeeds, repeats it\n * an additional time.\n *\n * @example\n * // Success Example\n * import { Effect, Schedule, Console } from \"effect\"\n *\n * const action = Console.log(\"success\")\n * const policy = Schedule.addDelay(Schedule.recurs(2), () => \"100 millis\")\n * const program = Effect.repeat(action, policy)\n *\n * Effect.runPromise(program).then((n) => console.log(`repetitions: ${n}`))\n *\n * @example\n * // Failure Example\n * import { Effect, Schedule } from \"effect\"\n *\n * let count = 0\n *\n * // Define an async effect that simulates an action with possible failures\n * const action = Effect.async<string, string>((resume) => {\n *   if (count > 1) {\n *     console.log(\"failure\")\n *     resume(Effect.fail(\"Uh oh!\"))\n *   } else {\n *     count++\n *     console.log(\"success\")\n *     resume(Effect.succeed(\"yay!\"))\n *   }\n * })\n *\n * const policy = Schedule.addDelay(Schedule.recurs(2), () => \"100 millis\")\n * const program = Effect.repeat(action, policy)\n *\n * Effect.runPromiseExit(program).then(console.log)\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const repeat = _schedule.repeat_combined;\n/**\n * The `repeatN` function returns a new effect that repeats the specified effect a\n * given number of times or until the first failure. The repeats are in addition\n * to the initial execution, so `Effect.repeatN(action, 1)` executes `action` once\n * initially and then repeats it one additional time if it succeeds.\n *\n * @example\n * import { Effect, Console } from \"effect\"\n *\n * const action = Console.log(\"success\")\n * const program = Effect.repeatN(action, 2)\n *\n * Effect.runPromise(program)\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const repeatN = effect.repeatN;\n/**\n * The `repeatOrElse` function returns a new effect that repeats the specified\n * effect according to the given schedule or until the first failure. When a\n * failure occurs, the failure value and schedule output are passed to a\n * specified handler. Scheduled recurrences are in addition to the initial\n * execution, so `Effect.repeat(action, Schedule.once)` executes `action` once\n * initially and then repeats it an additional time if it succeeds.\n *\n * @example\n * import { Effect, Schedule } from \"effect\"\n *\n * let count = 0\n *\n * // Define an async effect that simulates an action with possible failures\n * const action = Effect.async<string, string>((resume) => {\n *   if (count > 1) {\n *     console.log(\"failure\")\n *     resume(Effect.fail(\"Uh oh!\"))\n *   } else {\n *     count++\n *     console.log(\"success\")\n *     resume(Effect.succeed(\"yay!\"))\n *   }\n * })\n *\n * const policy = Schedule.addDelay(\n *   Schedule.recurs(2), // Repeat for a maximum of 2 times\n *   () => \"100 millis\" // Add a delay of 100 milliseconds between repetitions\n * )\n *\n * const program = Effect.repeatOrElse(action, policy, () =>\n *   Effect.sync(() => {\n *     console.log(\"orElse\")\n *     return count - 1\n *   })\n * )\n *\n * Effect.runPromise(program).then((n) => console.log(`repetitions: ${n}`))\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const repeatOrElse = _schedule.repeatOrElse_Effect;\n/**\n * Runs this effect according to the specified schedule.\n *\n * See `scheduleFrom` for a variant that allows the schedule's decision to\n * depend on the result of this effect.\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const schedule = _schedule.schedule_Effect;\n/**\n * Runs this effect according to the specified schedule in a new fiber\n * attached to the current scope.\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const scheduleForked = circular.scheduleForked;\n/**\n * Runs this effect according to the specified schedule starting from the\n * specified input value.\n *\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const scheduleFrom = _schedule.scheduleFrom_Effect;\n/**\n * @since 2.0.0\n * @category repetition / recursion\n */\nexport const whileLoop = core.whileLoop;\n// -------------------------------------------------------------------------------------\n// fiber refs\n// -------------------------------------------------------------------------------------\n/**\n * Returns a collection of all `FiberRef` values for the fiber running this\n * effect.\n *\n * @since 2.0.0\n * @category fiber refs\n */\nexport const getFiberRefs = effect.fiberRefs;\n/**\n * Inherits values from all `FiberRef` instances into current fiber.\n *\n * @since 2.0.0\n * @category fiber refs\n */\nexport const inheritFiberRefs = effect.inheritFiberRefs;\n/**\n * @since 2.0.0\n * @category fiber refs\n */\nexport const locally = core.fiberRefLocally;\n/**\n * @since 2.0.0\n * @category fiber refs\n */\nexport const locallyWith = core.fiberRefLocallyWith;\n/**\n * @since 2.0.0\n * @category fiber refs\n */\nexport const locallyScoped = fiberRuntime.fiberRefLocallyScoped;\n/**\n * @since 2.0.0\n * @category fiber refs\n */\nexport const locallyScopedWith = fiberRuntime.fiberRefLocallyScopedWith;\n/**\n * Applies the specified changes to the `FiberRef` values for the fiber\n * running this workflow.\n *\n * @since 2.0.0\n * @category fiber refs\n */\nexport const patchFiberRefs = effect.patchFiberRefs;\n/**\n * Sets the `FiberRef` values for the fiber running this effect to the values\n * in the specified collection of `FiberRef` values.\n *\n * @since 2.0.0\n * @category fiber refs\n */\nexport const setFiberRefs = effect.setFiberRefs;\n/**\n * Updates the `FiberRef` values for the fiber running this effect using the\n * specified function.\n *\n * @since 2.0.0\n * @category fiber refs\n */\nexport const updateFiberRefs = effect.updateFiberRefs;\n// -------------------------------------------------------------------------------------\n// getters & folding\n// -------------------------------------------------------------------------------------\n/**\n * Returns `true` if this effect is a failure, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters & folding\n */\nexport const isFailure = effect.isFailure;\n/**\n * Returns `true` if this effect is a success, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters & folding\n */\nexport const isSuccess = effect.isSuccess;\n/**\n * Folds over the failure value or the success value to yield an effect that\n * does not fail, but succeeds with the value returned by the left or right\n * function passed to `match`.\n *\n * @since 2.0.0\n * @category getters & folding\n */\nexport const match = effect.match;\n/**\n * @since 2.0.0\n * @category getters & folding\n */\nexport const matchCause = core.matchCause;\n/**\n * @since 2.0.0\n * @category getters & folding\n */\nexport const matchCauseEffect = core.matchCauseEffect;\n/**\n * @since 2.0.0\n * @category getters & folding\n */\nexport const matchEffect = core.matchEffect;\n// -------------------------------------------------------------------------------------\n// logging\n// -------------------------------------------------------------------------------------\n/**\n * Logs one or more messages or error causes at the current log level, which is INFO by default.\n * This function allows logging multiple items at once and can include detailed error information using `Cause` instances.\n *\n * To adjust the log level, use the `Logger.withMinimumLogLevel` function.\n *\n * @example\n * import { Cause, Effect } from \"effect\"\n *\n * const program = Effect.log(\n *   \"message1\",\n *   \"message2\",\n *   Cause.die(\"Oh no!\"),\n *   Cause.die(\"Oh uh!\")\n * )\n *\n * // Effect.runFork(program)\n * // Output:\n * // timestamp=... level=INFO fiber=#0 message=message1 message=message2 cause=\"Error: Oh no!\n * // Error: Oh uh!\"\n *\n * @since 2.0.0\n * @category logging\n */\nexport const log = effect.log;\n/**\n * Logs the specified message or cause at the specified log level.\n *\n * @since 2.0.0\n * @category logging\n */\nexport const logWithLevel = (level, ...message) => effect.logWithLevel(level)(...message);\n/**\n * Logs the specified message or cause at the Trace log level.\n *\n * @since 2.0.0\n * @category logging\n */\nexport const logTrace = effect.logTrace;\n/**\n * Logs the specified messages at the DEBUG log level.\n * DEBUG messages are not shown by default.\n *\n * To view DEBUG messages, adjust the logging settings using\n * `Logger.withMinimumLogLevel` and set the log level to `LogLevel.Debug`.\n *\n * @example\n * import { Effect, Logger, LogLevel } from \"effect\"\n *\n * const program = Effect.logDebug(\"message1\").pipe(Logger.withMinimumLogLevel(LogLevel.Debug))\n *\n * // Effect.runFork(program)\n * // timestamp=... level=DEBUG fiber=#0 message=message1\n *\n * @since 2.0.0\n * @category logging\n */\nexport const logDebug = effect.logDebug;\n/**\n * Logs the specified message or cause at the Info log level.\n *\n * @since 2.0.0\n * @category logging\n */\nexport const logInfo = effect.logInfo;\n/**\n * Logs the specified message or cause at the Warning log level.\n *\n * @since 2.0.0\n * @category logging\n */\nexport const logWarning = effect.logWarning;\n/**\n * Logs the specified message or cause at the Error log level.\n *\n * @since 2.0.0\n * @category logging\n */\nexport const logError = effect.logError;\n/**\n * Logs the specified message or cause at the Fatal log level.\n *\n * @since 2.0.0\n * @category logging\n */\nexport const logFatal = effect.logFatal;\n/**\n * Adds a log span to your effects, which tracks and logs the duration of\n * operations or tasks. This is useful for performance monitoring and debugging\n * time-sensitive processes.\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * const program = Effect.gen(function*() {\n *   yield* Effect.sleep(\"1 second\")\n *   yield* Effect.log(\"The job is finished!\")\n * }).pipe(Effect.withLogSpan(\"myspan\"))\n *\n * // Effect.runFork(program)\n * // timestamp=... level=INFO fiber=#0 message=\"The job is finished!\" myspan=1011ms\n *\n * @since 2.0.0\n * @category logging\n */\nexport const withLogSpan = effect.withLogSpan;\n/**\n * Augments log outputs by appending custom annotations to log entries generated\n * within an effect. This function provides a way to add more context and detail\n * to log messages, making them more informative and easier to trace.\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * const program = Effect.gen(function*() {\n *   yield* Effect.log(\"message1\")\n *   yield* Effect.log(\"message2\")\n * }).pipe(Effect.annotateLogs(\"key\", \"value\")) // Annotation as key/value pair\n *\n * // Effect.runFork(program)\n * // timestamp=... level=INFO fiber=#0 message=message1 key=value\n * // timestamp=... level=INFO fiber=#0 message=message2 key=value\n *\n * @since 2.0.0\n * @category logging\n */\nexport const annotateLogs = effect.annotateLogs;\n/**\n * Applies log annotations with a limited scope, restricting their appearance to\n * specific sections of your effect computations. Use\n * `Effect.annotateLogsScoped` to add metadata to logs that only appear within a\n * defined `Scope`, making it easier to manage context-specific logging.\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * const program = Effect.gen(function*() {\n *   yield* Effect.log(\"no annotations\")\n *   yield* Effect.annotateLogsScoped({ key: \"value\" })\n *   yield* Effect.log(\"message1\") // Annotation is applied to this log\n *   yield* Effect.log(\"message2\") // Annotation is applied to this log\n * }).pipe(Effect.scoped, Effect.andThen(Effect.log(\"no annotations again\")))\n *\n * // Effect.runFork(program)\n * // timestamp=... level=INFO fiber=#0 message=\"no annotations\"\n * // timestamp=... level=INFO fiber=#0 message=message1 key=value\n * // timestamp=... level=INFO fiber=#0 message=message2 key=value\n * // timestamp=... level=INFO fiber=#0 message=\"no annotations again\"\n *\n * @since 3.1.0\n * @category logging\n */\nexport const annotateLogsScoped = fiberRuntime.annotateLogsScoped;\n/**\n * Retrieves the log annotations associated with the current scope.\n *\n * @since 2.0.0\n * @category logging\n */\nexport const logAnnotations = effect.logAnnotations;\n/**\n * Decides wether child fibers will report or not unhandled errors via the logger\n *\n * @since 2.0.0\n * @category logging\n */\nexport const withUnhandledErrorLogLevel = core.withUnhandledErrorLogLevel;\n// -------------------------------------------------------------------------------------\n// alternatives\n// -------------------------------------------------------------------------------------\n/**\n * Translates effect failure into death of the fiber, making all failures\n * unchecked and not a part of the type of the effect.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const orDie = core.orDie;\n/**\n * Keeps none of the errors, and terminates the fiber with them, using the\n * specified function to convert the `E` into a `Throwable`.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const orDieWith = core.orDieWith;\n/**\n * Executes this effect and returns its value, if it succeeds, but otherwise\n * executes the specified effect.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const orElse = core.orElse;\n/**\n * Executes this effect and returns its value, if it succeeds, but otherwise\n * fails with the specified error.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const orElseFail = effect.orElseFail;\n/**\n * Executes this effect and returns its value, if it succeeds, but\n * otherwise succeeds with the specified value.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const orElseSucceed = effect.orElseSucceed;\n// -------------------------------------------------------------------------------------\n// random\n// -------------------------------------------------------------------------------------\n/**\n * Retreives the `Random` service from the context.\n *\n * @since 2.0.0\n * @category random\n */\nexport const random = effect.random;\n/**\n * Retreives the `Random` service from the context and uses it to run the\n * specified workflow.\n *\n * @since 2.0.0\n * @category random\n */\nexport const randomWith = defaultServices.randomWith;\n/**\n * Executes the specified workflow with the specified implementation of the\n * random service.\n *\n * @since 2.0.0\n * @category random\n */\nexport const withRandom = defaultServices.withRandom;\n/**\n * Sets the implementation of the random service to the specified value and\n * restores it to its original value when the scope is closed.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const withRandomScoped = fiberRuntime.withRandomScoped;\n// -------------------------------------------------------------------------------------\n// runtime\n// -------------------------------------------------------------------------------------\n/**\n * Returns an effect that accesses the runtime, which can be used to\n * (unsafely) execute tasks. This is useful for integration with legacy code\n * that must call back into Effect code.\n *\n * @since 2.0.0\n * @category runtime\n */\nexport const runtime = _runtime.runtime;\n/**\n * Retrieves an effect that succeeds with the current runtime flags, which\n * govern behavior and features of the runtime system.\n *\n * @since 2.0.0\n * @category runtime\n */\nexport const getRuntimeFlags = core.runtimeFlags;\n/**\n * @since 2.0.0\n * @category runtime\n */\nexport const patchRuntimeFlags = core.updateRuntimeFlags;\n/**\n * @since 2.0.0\n * @category runtime\n */\nexport const withRuntimeFlagsPatch = core.withRuntimeFlags;\n/**\n * @since 2.0.0\n * @category runtime\n */\nexport const withRuntimeFlagsPatchScoped = fiberRuntime.withRuntimeFlagsScoped;\n// -------------------------------------------------------------------------------------\n// metrics\n// -------------------------------------------------------------------------------------\n/**\n * Tags each metric in this effect with the specific tag.\n *\n * @since 2.0.0\n * @category metrics\n */\nexport const tagMetrics = effect.tagMetrics;\n/**\n * Tags each metric in this effect with the specific tag.\n *\n * @since 2.0.0\n * @category metrics\n */\nexport const labelMetrics = effect.labelMetrics;\n/**\n * Tags each metric in a scope with a the specific tag.\n *\n * @since 2.0.0\n * @category metrics\n */\nexport const tagMetricsScoped = fiberRuntime.tagMetricsScoped;\n/**\n * Tags each metric in a scope with a the specific tag.\n *\n * @since 2.0.0\n * @category metrics\n */\nexport const labelMetricsScoped = fiberRuntime.labelMetricsScoped;\n/**\n * Retrieves the metric labels associated with the current scope.\n *\n * @since 2.0.0\n * @category metrics\n */\nexport const metricLabels = core.metricLabels;\n/**\n * @since 2.0.0\n * @category metrics\n */\nexport const withMetric = effect.withMetric;\n/**\n * Unsafely creates a new Semaphore\n *\n * @since 2.0.0\n * @category semaphore\n */\nexport const unsafeMakeSemaphore = circular.unsafeMakeSemaphore;\n/**\n * Creates a new Semaphore\n *\n * @since 2.0.0\n * @category semaphore\n */\nexport const makeSemaphore = circular.makeSemaphore;\n// -------------------------------------------------------------------------------------\n// execution\n// -------------------------------------------------------------------------------------\n/**\n * @since 2.0.0\n * @category execution\n */\nexport const runFork = _runtime.unsafeForkEffect;\n/**\n * @since 2.0.0\n * @category execution\n */\nexport const runCallback = _runtime.unsafeRunEffect;\n/**\n * Runs an `Effect` workflow, returning a `Promise` which resolves with the\n * result of the workflow or rejects with an error.\n *\n * @since 2.0.0\n * @category execution\n */\nexport const runPromise = _runtime.unsafeRunPromiseEffect;\n/**\n * Runs an `Effect` workflow, returning a `Promise` which resolves with the\n * `Exit` value of the workflow.\n *\n * @since 2.0.0\n * @category execution\n */\nexport const runPromiseExit = _runtime.unsafeRunPromiseExitEffect;\n/**\n * @since 2.0.0\n * @category execution\n */\nexport const runSync = _runtime.unsafeRunSyncEffect;\n/**\n * @since 2.0.0\n * @category execution\n */\nexport const runSyncExit = _runtime.unsafeRunSyncExitEffect;\n// -------------------------------------------------------------------------------------\n// zipping\n// -------------------------------------------------------------------------------------\n/**\n * Sequentially zips the this result with the specified result. Combines both\n * `Cause`s when both effects fail.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const validate = fiberRuntime.validate;\n/**\n * Sequentially zips this effect with the specified effect using the specified\n * combiner function. Combines the causes in case both effect fail.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const validateWith = fiberRuntime.validateWith;\n/**\n * The `Effect.zip` function allows you to combine two effects into a single\n * effect. This combined effect yields a tuple containing the results of both\n * input effects once they succeed.\n *\n * Note that `Effect.zip` processes effects sequentially: it first completes the\n * effect on the left and then the effect on the right.\n *\n * If you want to run the effects concurrently, you can use the `concurrent` option.\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * const task1 = Effect.succeed(1).pipe(\n *   Effect.delay(\"200 millis\"),\n *   Effect.tap(Effect.log(\"task1 done\"))\n * )\n * const task2 = Effect.succeed(\"hello\").pipe(\n *   Effect.delay(\"100 millis\"),\n *   Effect.tap(Effect.log(\"task2 done\"))\n * )\n *\n * const task3 = Effect.zip(task1, task2)\n *\n * Effect.runPromise(task3).then(console.log)\n * // Output:\n * // timestamp=... level=INFO fiber=#0 message=\"task1 done\"\n * // timestamp=... level=INFO fiber=#0 message=\"task2 done\"\n * // [ 1, 'hello' ]\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * const task1 = Effect.succeed(1).pipe(\n *   Effect.delay(\"200 millis\"),\n *   Effect.tap(Effect.log(\"task1 done\"))\n * )\n * const task2 = Effect.succeed(\"hello\").pipe(\n *   Effect.delay(\"100 millis\"),\n *   Effect.tap(Effect.log(\"task2 done\"))\n * )\n *\n * const task3 = Effect.zip(task1, task2, { concurrent: true })\n *\n * Effect.runPromise(task3).then(console.log)\n * // Output:\n * // timestamp=... level=INFO fiber=#0 message=\"task2 done\"\n * // timestamp=... level=INFO fiber=#0 message=\"task1 done\"\n * // [ 1, 'hello' ]\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = fiberRuntime.zipOptions;\n/**\n * Sequentially run this effect with the specified effect, _discarding_ the result\n * of the second effect (`that`) in the chain.\n *\n * `{ concurrent: true }` can be passed to the options to make it a concurrent execution\n * of both effects instead of sequential.\n *\n * @example\n *\n * import { Effect } from 'effect';\n *\n * const effect = Effect.succeed(\"a message\").pipe(\n *   Effect.zipLeft(Effect.succeed(42)),\n * )\n *\n * assert.deepStrictEqual(Effect.runSync(effect), \"a message\");\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = fiberRuntime.zipLeftOptions;\n/**\n * Sequentially run this effect with the specified effect, _returning_ the result\n * of the second effect (`that`) in the chain.\n *\n * `{ concurrent: true }` can be passed to the options to make it a concurrent execution\n * of both effects instead of sequential.\n *\n * @example\n *\n * import { Effect } from 'effect';\n *\n * const effect = Effect.succeed(\"a message\").pipe(\n *   Effect.zipRight(Effect.succeed(42)),\n * )\n *\n * assert.deepStrictEqual(Effect.runSync(effect), 42);\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = fiberRuntime.zipRightOptions;\n/**\n * The `Effect.zipWith` function operates similarly to {@link zip} by combining\n * two effects. However, instead of returning a tuple, it allows you to apply a\n * function to the results of the combined effects, transforming them into a\n * single value\n *\n * @example\n * import { Effect } from \"effect\"\n *\n * const task1 = Effect.succeed(1).pipe(\n *   Effect.delay(\"200 millis\"),\n *   Effect.tap(Effect.log(\"task1 done\"))\n * )\n * const task2 = Effect.succeed(\"hello\").pipe(\n *   Effect.delay(\"100 millis\"),\n *   Effect.tap(Effect.log(\"task2 done\"))\n * )\n *\n * const task3 = Effect.zipWith(\n *   task1,\n *   task2,\n *   (number, string) => number + string.length\n * )\n *\n * Effect.runPromise(task3).then(console.log)\n * // Output:\n * // timestamp=... level=INFO fiber=#3 message=\"task1 done\"\n * // timestamp=... level=INFO fiber=#2 message=\"task2 done\"\n * // 6\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = fiberRuntime.zipWithOptions;\n// -------------------------------------------------------------------------------------\n// applicatives\n// -------------------------------------------------------------------------------------\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const ap = /*#__PURE__*/dual(2, (self, that) => zipWith(self, that, (f, a) => f(a)));\n// -------------------------------------------------------------------------------------\n// requests & batching\n// -------------------------------------------------------------------------------------\n/**\n * @category requests & batching\n * @since 2.0.0\n */\nexport const blocked = core.blocked;\n/**\n * @category requests & batching\n * @since 2.0.0\n */\nexport const runRequestBlock = core.runRequestBlock;\n/**\n * @category requests & batching\n * @since 2.0.0\n */\nexport const step = core.step;\n/**\n * @since 2.0.0\n * @category requests & batching\n */\nexport const request = /*#__PURE__*/dual(args => Request.isRequest(args[0]), query.fromRequest);\n/**\n * @since 2.0.0\n * @category requests & batching\n */\nexport const cacheRequestResult = query.cacheRequest;\n/**\n * @since 2.0.0\n * @category requests & batching\n */\nexport const withRequestBatching = core.withRequestBatching;\n/**\n * @since 2.0.0\n * @category requests & batching\n */\nexport const withRequestCaching = query.withRequestCaching;\n/**\n * @since 2.0.0\n * @category requests & batching\n */\nexport const withRequestCache = query.withRequestCache;\n// -------------------------------------------------------------------------------------\n// tracing\n// -------------------------------------------------------------------------------------\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const tracer = effect.tracer;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const tracerWith = defaultServices.tracerWith;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const withTracer = defaultServices.withTracer;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const withTracerScoped = fiberRuntime.withTracerScoped;\n/**\n * Disable the tracer for the given Effect.\n *\n * @since 2.0.0\n * @category tracing\n * @example\n * import { Effect } from \"effect\"\n *\n * Effect.succeed(42).pipe(\n *   Effect.withSpan(\"my-span\"),\n *   // the span will not be registered with the tracer\n *   Effect.withTracerEnabled(false)\n * )\n */\nexport const withTracerEnabled = core.withTracerEnabled;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const withTracerTiming = core.withTracerTiming;\n/**\n * Adds an annotation to each span in this effect.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const annotateSpans = effect.annotateSpans;\n/**\n * Adds an annotation to the current span if available\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const annotateCurrentSpan = effect.annotateCurrentSpan;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const currentSpan = effect.currentSpan;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const currentParentSpan = effect.currentParentSpan;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const spanAnnotations = effect.spanAnnotations;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const spanLinks = effect.spanLinks;\n/**\n * For all spans in this effect, add a link with the provided span.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const linkSpans = effect.linkSpans;\n/**\n * Create a new span for tracing.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const makeSpan = effect.makeSpan;\n/**\n * Create a new span for tracing, and automatically close it when the Scope\n * finalizes.\n *\n * The span is not added to the current span stack, so no child spans will be\n * created for it.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const makeSpanScoped = fiberRuntime.makeSpanScoped;\n/**\n * Create a new span for tracing, and automatically close it when the effect\n * completes.\n *\n * The span is not added to the current span stack, so no child spans will be\n * created for it.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const useSpan = effect.useSpan;\n/**\n * Wraps the effect with a new span for tracing.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const withSpan = effect.withSpan;\n/**\n * Wraps a function that returns an effect with a new span for tracing.\n *\n * @since 3.2.0\n * @category tracing\n * @example\n * import { Effect } from \"effect\"\n *\n * const getTodo = Effect.functionWithSpan({\n *   body: (id: number) => Effect.succeed(`Got todo ${id}!`),\n *   options: (id) => ({\n *     name: `getTodo-${id}`,\n *     attributes: { id }\n *   })\n * })\n */\nexport const functionWithSpan = effect.functionWithSpan;\n/**\n * Wraps the effect with a new span for tracing.\n *\n * The span is ended when the Scope is finalized.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const withSpanScoped = fiberRuntime.withSpanScoped;\n/**\n * Adds the provided span to the current span stack.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const withParentSpan = effect.withParentSpan;\n// -------------------------------------------------------------------------------------\n// optionality\n// -------------------------------------------------------------------------------------\n/**\n * Returns an effect that errors with `NoSuchElementException` if the value is\n * null or undefined, otherwise succeeds with the value.\n *\n * @since 2.0.0\n * @category optionality\n */\nexport const fromNullable = effect.fromNullable;\n/**\n * Wraps the success value of this effect with `Option.some`, and maps\n * `Cause.NoSuchElementException` to `Option.none`.\n *\n * @since 2.0.0\n * @category optionality\n */\nexport const optionFromOptional = effect.optionFromOptional;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Tag = id => () => {\n  const limit = Error.stackTraceLimit;\n  Error.stackTraceLimit = 2;\n  const creationError = new Error();\n  Error.stackTraceLimit = limit;\n  function TagClass() {}\n  Object.setPrototypeOf(TagClass, TagProto);\n  TagClass.key = id;\n  Object.defineProperty(TagClass, \"stack\", {\n    get() {\n      return creationError.stack;\n    }\n  });\n  const cache = new Map();\n  const done = new Proxy(TagClass, {\n    get(_target, prop, _receiver) {\n      if (prop === \"use\") {\n        // @ts-expect-error\n        return body => core.andThen(TagClass, body);\n      }\n      if (prop in TagClass) {\n        // @ts-expect-error\n        return TagClass[prop];\n      }\n      if (cache.has(prop)) {\n        return cache.get(prop);\n      }\n      const fn = (...args) =>\n      // @ts-expect-error\n      core.andThen(TagClass, s => {\n        if (typeof s[prop] === \"function\") {\n          // @ts-expect-error\n          cache.set(prop, (...args) => core.andThen(TagClass, s => s[prop](...args)));\n          return s[prop](...args);\n        }\n        // @ts-expect-error\n        cache.set(prop, core.andThen(TagClass, s => s[prop]));\n        return s[prop];\n      });\n      // @ts-expect-error\n      const cn = core.andThen(TagClass, s => s[prop]);\n      Object.assign(fn, cn);\n      Object.setPrototypeOf(fn, Object.getPrototypeOf(cn));\n      cache.set(prop, fn);\n      return fn;\n    }\n  });\n  return done;\n};\n//# sourceMappingURL=Effect.js.map","import * as internal from \"./internal/effectable.js\";\n/**\n * @since 2.0.0\n * @category type ids\n */\nexport const EffectTypeId = internal.EffectTypeId;\n/**\n * @since 2.0.0\n * @category type ids\n */\nexport const StreamTypeId = internal.StreamTypeId;\n/**\n * @since 2.0.0\n * @category type ids\n */\nexport const SinkTypeId = internal.SinkTypeId;\n/**\n * @since 2.0.0\n * @category type ids\n */\nexport const ChannelTypeId = internal.ChannelTypeId;\n/**\n * @since 2.0.0\n * @category prototypes\n */\nexport const EffectPrototype = internal.EffectPrototype;\n/**\n * @since 2.0.0\n * @category prototypes\n */\nexport const CommitPrototype = internal.CommitPrototype;\n/**\n * @since 2.0.0\n * @category prototypes\n */\nexport const StructuralCommitPrototype = internal.StructuralCommitPrototype;\nconst Base = internal.Base;\nconst StructuralBase = internal.StructuralBase;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport class Class extends Base {}\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport class StructuralClass extends StructuralBase {}\n//# sourceMappingURL=Effectable.js.map","/**\n * @since 2.0.0\n */\nimport * as Equivalence from \"./Equivalence.js\";\nimport { constNull, constUndefined, dual, identity } from \"./Function.js\";\nimport * as doNotation from \"./internal/doNotation.js\";\nimport * as either from \"./internal/either.js\";\nimport { isFunction } from \"./Predicate.js\";\nimport * as Gen from \"./Utils.js\";\n/**\n * @category symbols\n * @since 2.0.0\n */\nexport const TypeId = either.TypeId;\n/**\n * Constructs a new `Either` holding a `Right` value. This usually represents a successful value due to the right bias\n * of this structure.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const right = either.right;\n/**\n * Constructs a new `Either` holding a `Left` value. This usually represents a failure, due to the right-bias of this\n * structure.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const left = either.left;\n/**\n * Takes a lazy default and a nullable value, if the value is not nully (`null` or `undefined`), turn it into a `Right`, if the value is nully use\n * the provided default as a `Left`.\n *\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.fromNullable(1, () => 'fallback'), Either.right(1))\n * assert.deepStrictEqual(Either.fromNullable(null, () => 'fallback'), Either.left('fallback'))\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const fromNullable = /*#__PURE__*/dual(2, (self, onNullable) => self == null ? left(onNullable(self)) : right(self));\n/**\n * @example\n * import { Either, Option } from \"effect\"\n *\n * assert.deepStrictEqual(Either.fromOption(Option.some(1), () => 'error'), Either.right(1))\n * assert.deepStrictEqual(Either.fromOption(Option.none(), () => 'error'), Either.left('error'))\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const fromOption = either.fromOption;\nconst try_ = evaluate => {\n  if (isFunction(evaluate)) {\n    try {\n      return right(evaluate());\n    } catch (e) {\n      return left(e);\n    }\n  } else {\n    try {\n      return right(evaluate.try());\n    } catch (e) {\n      return left(evaluate.catch(e));\n    }\n  }\n};\nexport {\n/**\n * Imports a synchronous side-effect into a pure `Either` value, translating any\n * thrown exceptions into typed failed eithers creating with `Either.left`.\n *\n * @category constructors\n * @since 2.0.0\n */\ntry_ as try };\n/**\n * Tests if a value is a `Either`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.isEither(Either.right(1)), true)\n * assert.deepStrictEqual(Either.isEither(Either.left(\"a\")), true)\n * assert.deepStrictEqual(Either.isEither({ right: 1 }), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isEither = either.isEither;\n/**\n * Determine if a `Either` is a `Left`.\n *\n * @param self - The `Either` to check.\n *\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.isLeft(Either.right(1)), false)\n * assert.deepStrictEqual(Either.isLeft(Either.left(\"a\")), true)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isLeft = either.isLeft;\n/**\n * Determine if a `Either` is a `Right`.\n *\n * @param self - The `Either` to check.\n *\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.isRight(Either.right(1)), true)\n * assert.deepStrictEqual(Either.isRight(Either.left(\"a\")), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isRight = either.isRight;\n/**\n * Converts a `Either` to an `Option` discarding the `Left`.\n *\n * Alias of {@link toOption}.\n *\n * @example\n * import { Either, Option } from \"effect\"\n *\n * assert.deepStrictEqual(Either.getRight(Either.right('ok')), Option.some('ok'))\n * assert.deepStrictEqual(Either.getRight(Either.left('err')), Option.none())\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getRight = either.getRight;\n/**\n * Converts a `Either` to an `Option` discarding the value.\n *\n * @example\n * import { Either, Option } from \"effect\"\n *\n * assert.deepStrictEqual(Either.getLeft(Either.right('ok')), Option.none())\n * assert.deepStrictEqual(Either.getLeft(Either.left('err')), Option.some('err'))\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getLeft = either.getLeft;\n/**\n * @category equivalence\n * @since 2.0.0\n */\nexport const getEquivalence = ({\n  left,\n  right\n}) => Equivalence.make((x, y) => isLeft(x) ? isLeft(y) && left(x.left, y.left) : isRight(y) && right(x.right, y.right));\n/**\n * @category mapping\n * @since 2.0.0\n */\nexport const mapBoth = /*#__PURE__*/dual(2, (self, {\n  onLeft,\n  onRight\n}) => isLeft(self) ? left(onLeft(self.left)) : right(onRight(self.right)));\n/**\n * Maps the `Left` side of an `Either` value to a new `Either` value.\n *\n * @param self - The input `Either` value to map.\n * @param f - A transformation function to apply to the `Left` value of the input `Either`.\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const mapLeft = /*#__PURE__*/dual(2, (self, f) => isLeft(self) ? left(f(self.left)) : right(self.right));\n/**\n * Maps the `Right` side of an `Either` value to a new `Either` value.\n *\n * @param self - An `Either` to map\n * @param f - The function to map over the value of the `Either`\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => isRight(self) ? right(f(self.right)) : left(self.left));\n/**\n * Takes two functions and an `Either` value, if the value is a `Left` the inner value is applied to the `onLeft function,\n * if the value is a `Right` the inner value is applied to the `onRight` function.\n *\n * @example\n * import { pipe, Either } from \"effect\"\n *\n * const onLeft  = (strings: ReadonlyArray<string>): string => `strings: ${strings.join(', ')}`\n *\n * const onRight = (value: number): string => `Ok: ${value}`\n *\n * assert.deepStrictEqual(pipe(Either.right(1), Either.match({ onLeft, onRight })), 'Ok: 1')\n * assert.deepStrictEqual(\n *   pipe(Either.left(['string 1', 'string 2']), Either.match({ onLeft, onRight })),\n *   'strings: string 1, string 2'\n * )\n *\n * @category pattern matching\n * @since 2.0.0\n */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onLeft,\n  onRight\n}) => isLeft(self) ? onLeft(self.left) : onRight(self.right));\n/**\n * Transforms a `Predicate` function into a `Right` of the input value if the predicate returns `true`\n * or `Left` of the result of the provided function if the predicate returns false\n *\n * @param predicate - A `Predicate` function that takes in a value of type `A` and returns a boolean.\n *\n * @example\n * import { pipe, Either } from \"effect\"\n *\n * const isPositive = (n: number): boolean => n > 0\n *\n * assert.deepStrictEqual(\n *   pipe(\n *     1,\n *     Either.liftPredicate(isPositive, n => `${n} is not positive`)\n *   ),\n *   Either.right(1)\n * )\n * assert.deepStrictEqual(\n *   pipe(\n *     0,\n *     Either.liftPredicate(isPositive, n => `${n} is not positive`)\n *   ),\n *   Either.left(\"0 is not positive\")\n * )\n *\n * @category lifting\n * @since 3.4.0\n */\nexport const liftPredicate = /*#__PURE__*/dual(3, (a, predicate, orLeftWith) => predicate(a) ? right(a) : left(orLeftWith(a)));\n/**\n * Filter the right value with the provided function.\n * If the predicate fails, set the left value with the result of the provided function.\n *\n * @example\n * import { pipe, Either } from \"effect\"\n *\n * const isPositive = (n: number): boolean => n > 0\n *\n * assert.deepStrictEqual(\n *   pipe(\n *     Either.right(1),\n *     Either.filterOrLeft(isPositive, n => `${n} is not positive`)\n *   ),\n *   Either.right(1)\n * )\n * assert.deepStrictEqual(\n *   pipe(\n *     Either.right(0),\n *     Either.filterOrLeft(isPositive, n => `${n} is not positive`)\n *   ),\n *   Either.left(\"0 is not positive\")\n * )\n *\n * @since 2.0.0\n * @category filtering & conditionals\n */\nexport const filterOrLeft = /*#__PURE__*/dual(3, (self, predicate, orLeftWith) => flatMap(self, r => predicate(r) ? right(r) : left(orLeftWith(r))));\n/**\n * @category getters\n * @since 2.0.0\n */\nexport const merge = /*#__PURE__*/match({\n  onLeft: identity,\n  onRight: identity\n});\n/**\n * Returns the wrapped value if it's a `Right` or a default value if is a `Left`.\n *\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.getOrElse(Either.right(1), (error) => error + \"!\"), 1)\n * assert.deepStrictEqual(Either.getOrElse(Either.left(\"not a number\"), (error) => error + \"!\"), \"not a number!\")\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getOrElse = /*#__PURE__*/dual(2, (self, onLeft) => isLeft(self) ? onLeft(self.left) : self.right);\n/**\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.getOrNull(Either.right(1)), 1)\n * assert.deepStrictEqual(Either.getOrNull(Either.left(\"a\")), null)\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getOrNull = /*#__PURE__*/getOrElse(constNull);\n/**\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.getOrUndefined(Either.right(1)), 1)\n * assert.deepStrictEqual(Either.getOrUndefined(Either.left(\"a\")), undefined)\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getOrUndefined = /*#__PURE__*/getOrElse(constUndefined);\n/**\n * Extracts the value of an `Either` or throws if the `Either` is `Left`.\n *\n * If a default error is sufficient for your use case and you don't need to configure the thrown error, see {@link getOrThrow}.\n *\n * @param self - The `Either` to extract the value from.\n * @param onLeft - A function that will be called if the `Either` is `Left`. It returns the error to be thrown.\n *\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Either.getOrThrowWith(Either.right(1), () => new Error('Unexpected Left')),\n *   1\n * )\n * assert.throws(() => Either.getOrThrowWith(Either.left(\"error\"), () => new Error('Unexpected Left')))\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getOrThrowWith = /*#__PURE__*/dual(2, (self, onLeft) => {\n  if (isRight(self)) {\n    return self.right;\n  }\n  throw onLeft(self.left);\n});\n/**\n * Extracts the value of an `Either` or throws if the `Either` is `Left`.\n *\n * The thrown error is a default error. To configure the error thrown, see  {@link getOrThrowWith}.\n *\n * @param self - The `Either` to extract the value from.\n * @throws `Error(\"getOrThrow called on a Left\")`\n *\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.getOrThrow(Either.right(1)), 1)\n * assert.throws(() => Either.getOrThrow(Either.left(\"error\")))\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getOrThrow = /*#__PURE__*/getOrThrowWith(() => new Error(\"getOrThrow called on a Left\"));\n/**\n * Returns `self` if it is a `Right` or `that` otherwise.\n *\n * @param self - The input `Either` value to check and potentially return.\n * @param that - A function that takes the error value from `self` (if it's a `Left`) and returns a new `Either` value.\n *\n * @category error handling\n * @since 2.0.0\n */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => isLeft(self) ? that(self.left) : right(self.right));\n/**\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => isLeft(self) ? left(self.left) : f(self.right));\n/**\n * Executes a sequence of two `Either`s. The second `Either` can be dependent on the result of the first `Either`.\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const andThen = /*#__PURE__*/dual(2, (self, f) => flatMap(self, a => {\n  const b = isFunction(f) ? f(a) : f;\n  return isEither(b) ? b : right(b);\n}));\n/**\n * @category zipping\n * @since 2.0.0\n */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => flatMap(self, r => map(that, r2 => f(r, r2))));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const ap = /*#__PURE__*/dual(2, (self, that) => zipWith(self, that, (f, a) => f(a)));\n/**\n * Takes a structure of `Either`s and returns an `Either` of values with the same structure.\n *\n * - If a tuple is supplied, then the returned `Either` will contain a tuple with the same length.\n * - If a struct is supplied, then the returned `Either` will contain a struct with the same keys.\n * - If an iterable is supplied, then the returned `Either` will contain an array.\n *\n * @param fields - the struct of `Either`s to be sequenced.\n *\n * @example\n * import { Either } from \"effect\"\n *\n * assert.deepStrictEqual(Either.all([Either.right(1), Either.right(2)]), Either.right([1, 2]))\n * assert.deepStrictEqual(Either.all({ right: Either.right(1), b: Either.right(\"hello\") }), Either.right({ right: 1, b: \"hello\" }))\n * assert.deepStrictEqual(Either.all({ right: Either.right(1), b: Either.left(\"error\") }), Either.left(\"error\"))\n *\n * @category combining\n * @since 2.0.0\n */\n// @ts-expect-error\nexport const all = input => {\n  if (Symbol.iterator in input) {\n    const out = [];\n    for (const e of input) {\n      if (isLeft(e)) {\n        return e;\n      }\n      out.push(e.right);\n    }\n    return right(out);\n  }\n  const out = {};\n  for (const key of Object.keys(input)) {\n    const e = input[key];\n    if (isLeft(e)) {\n      return e;\n    }\n    out[key] = e.right;\n  }\n  return right(out);\n};\n/**\n * Returns an `Either` that swaps the error/success cases. This allows you to\n * use all methods on the error channel, possibly before flipping back.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const flip = self => isLeft(self) ? right(self.left) : left(self.right);\nconst adapter = /*#__PURE__*/Gen.adapter();\n/**\n * @category generators\n * @since 2.0.0\n */\nexport const gen = (...args) => {\n  const f = args.length === 1 ? args[0] : args[1].bind(args[0]);\n  const iterator = f(adapter);\n  let state = iterator.next();\n  if (state.done) {\n    return right(state.value);\n  } else {\n    let current = state.value;\n    if (Gen.isGenKind(current)) {\n      current = current.value;\n    } else {\n      current = Gen.yieldWrapGet(current);\n    }\n    if (isLeft(current)) {\n      return current;\n    }\n    while (!state.done) {\n      state = iterator.next(current.right);\n      if (!state.done) {\n        current = state.value;\n        if (Gen.isGenKind(current)) {\n          current = current.value;\n        } else {\n          current = Gen.yieldWrapGet(current);\n        }\n        if (isLeft(current)) {\n          return current;\n        }\n      }\n    }\n    return right(state.value);\n  }\n};\n// -------------------------------------------------------------------------------------\n// do notation\n// -------------------------------------------------------------------------------------\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Either` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link bind}\n * @see {@link bindTo}\n * @see {@link let_ let}\n *\n * @example\n * import { Either, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Either.Do,\n *   Either.bind(\"x\", () => Either.right(2)),\n *   Either.bind(\"y\", () => Either.right(3)),\n *   Either.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(result, Either.right({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const Do = /*#__PURE__*/right({});\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Either` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link let_ let}\n *\n * @example\n * import { Either, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Either.Do,\n *   Either.bind(\"x\", () => Either.right(2)),\n *   Either.bind(\"y\", () => Either.right(3)),\n *   Either.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(result, Either.right({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bind = /*#__PURE__*/doNotation.bind(map, flatMap);\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Either` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bind}\n * @see {@link let_ let}\n *\n * @example\n * import { Either, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Either.Do,\n *   Either.bind(\"x\", () => Either.right(2)),\n *   Either.bind(\"y\", () => Either.right(3)),\n *   Either.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(result, Either.right({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bindTo = /*#__PURE__*/doNotation.bindTo(map);\nconst let_ = /*#__PURE__*/doNotation.let_(map);\nexport {\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Either` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link bind}\n *\n * @example\n * import { Either, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Either.Do,\n *   Either.bind(\"x\", () => Either.right(2)),\n *   Either.bind(\"y\", () => Either.right(3)),\n *   Either.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(result, Either.right({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nlet_ as let };\n//# sourceMappingURL=Either.js.map","/**\n * This module provides encoding & decoding functionality for:\n *\n * - base64 (RFC4648)\n * - base64 (URL)\n * - hex\n *\n * @since 2.0.0\n */\nimport * as Either from \"./Either.js\";\nimport * as Base64 from \"./internal/encoding/base64.js\";\nimport * as Base64Url from \"./internal/encoding/base64Url.js\";\nimport * as Common from \"./internal/encoding/common.js\";\nimport * as Hex from \"./internal/encoding/hex.js\";\n/**\n * Encodes the given value into a base64 (RFC4648) `string`.\n *\n * @category encoding\n * @since 2.0.0\n */\nexport const encodeBase64 = input => typeof input === \"string\" ? Base64.encode(Common.encoder.encode(input)) : Base64.encode(input);\n/**\n * Decodes a base64 (RFC4648) encoded `string` into a `Uint8Array`.\n *\n * @category decoding\n * @since 2.0.0\n */\nexport const decodeBase64 = str => Base64.decode(str);\n/**\n * Decodes a base64 (RFC4648) encoded `string` into a UTF-8 `string`.\n *\n * @category decoding\n * @since 2.0.0\n */\nexport const decodeBase64String = str => Either.map(decodeBase64(str), _ => Common.decoder.decode(_));\n/**\n * Encodes the given value into a base64 (URL) `string`.\n *\n * @category encoding\n * @since 2.0.0\n */\nexport const encodeBase64Url = input => typeof input === \"string\" ? Base64Url.encode(Common.encoder.encode(input)) : Base64Url.encode(input);\n/**\n * Decodes a base64 (URL) encoded `string` into a `Uint8Array`.\n *\n * @category decoding\n * @since 2.0.0\n */\nexport const decodeBase64Url = str => Base64Url.decode(str);\n/**\n * Decodes a base64 (URL) encoded `string` into a UTF-8 `string`.\n *\n * @category decoding\n * @since 2.0.0\n */\nexport const decodeBase64UrlString = str => Either.map(decodeBase64Url(str), _ => Common.decoder.decode(_));\n/**\n * Encodes the given value into a hex `string`.\n *\n * @category encoding\n * @since 2.0.0\n */\nexport const encodeHex = input => typeof input === \"string\" ? Hex.encode(Common.encoder.encode(input)) : Hex.encode(input);\n/**\n * Decodes a hex encoded `string` into a `Uint8Array`.\n *\n * @category decoding\n * @since 2.0.0\n */\nexport const decodeHex = str => Hex.decode(str);\n/**\n * Decodes a hex encoded `string` into a UTF-8 `string`.\n *\n * @category decoding\n * @since 2.0.0\n */\nexport const decodeHexString = str => Either.map(decodeHex(str), _ => Common.decoder.decode(_));\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const DecodeExceptionTypeId = Common.DecodeExceptionTypeId;\n/**\n * Creates a checked exception which occurs when decoding fails.\n *\n * @since 2.0.0\n * @category errors\n */\nexport const DecodeException = Common.DecodeException;\n/**\n * Returns `true` if the specified value is an `DecodeException`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isDecodeException = Common.isDecodeException;\n//# sourceMappingURL=Encoding.js.map","import * as Hash from \"./Hash.js\";\nimport { hasProperty } from \"./Predicate.js\";\nimport { structuralRegionState } from \"./Utils.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const symbol = /*#__PURE__*/Symbol.for(\"effect/Equal\");\nexport function equals() {\n  if (arguments.length === 1) {\n    return self => compareBoth(self, arguments[0]);\n  }\n  return compareBoth(arguments[0], arguments[1]);\n}\nfunction compareBoth(self, that) {\n  if (self === that) {\n    return true;\n  }\n  const selfType = typeof self;\n  if (selfType !== typeof that) {\n    return false;\n  }\n  if (selfType === \"object\" || selfType === \"function\") {\n    if (self !== null && that !== null) {\n      if (isEqual(self) && isEqual(that)) {\n        if (Hash.hash(self) === Hash.hash(that) && self[symbol](that)) {\n          return true;\n        } else {\n          return structuralRegionState.enabled && structuralRegionState.tester ? structuralRegionState.tester(self, that) : false;\n        }\n      } else if (self instanceof Date && that instanceof Date) {\n        return self.toISOString() === that.toISOString();\n      }\n    }\n    if (structuralRegionState.enabled) {\n      if (Array.isArray(self) && Array.isArray(that)) {\n        return self.length === that.length && self.every((v, i) => compareBoth(v, that[i]));\n      }\n      if (Object.getPrototypeOf(self) === Object.prototype && Object.getPrototypeOf(self) === Object.prototype) {\n        const keysSelf = Object.keys(self);\n        const keysThat = Object.keys(that);\n        if (keysSelf.length === keysThat.length) {\n          for (const key of keysSelf) {\n            // @ts-expect-error\n            if (!(key in that && compareBoth(self[key], that[key]))) {\n              return structuralRegionState.tester ? structuralRegionState.tester(self, that) : false;\n            }\n          }\n          return true;\n        }\n      }\n      return structuralRegionState.tester ? structuralRegionState.tester(self, that) : false;\n    }\n  }\n  return structuralRegionState.enabled && structuralRegionState.tester ? structuralRegionState.tester(self, that) : false;\n}\n/**\n * @since 2.0.0\n * @category guards\n */\nexport const isEqual = u => hasProperty(u, symbol);\n/**\n * @since 2.0.0\n * @category instances\n */\nexport const equivalence = () => equals;\n//# sourceMappingURL=Equal.js.map","/**\n * This module provides an implementation of the `Equivalence` type class, which defines a binary relation\n * that is reflexive, symmetric, and transitive. In other words, it defines a notion of equivalence between values of a certain type.\n * These properties are also known in mathematics as an \"equivalence relation\".\n *\n * @since 2.0.0\n */\nimport { dual } from \"./Function.js\";\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const make = isEquivalent => (self, that) => self === that || isEquivalent(self, that);\nconst isStrictEquivalent = (x, y) => x === y;\n/**\n * Return an `Equivalence` that uses strict equality (===) to compare values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const strict = () => isStrictEquivalent;\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const string = /*#__PURE__*/strict();\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const number = /*#__PURE__*/strict();\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const boolean = /*#__PURE__*/strict();\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const bigint = /*#__PURE__*/strict();\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const symbol = /*#__PURE__*/strict();\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const combine = /*#__PURE__*/dual(2, (self, that) => make((x, y) => self(x, y) && that(x, y)));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const combineMany = /*#__PURE__*/dual(2, (self, collection) => make((x, y) => {\n  if (!self(x, y)) {\n    return false;\n  }\n  for (const equivalence of collection) {\n    if (!equivalence(x, y)) {\n      return false;\n    }\n  }\n  return true;\n}));\nconst isAlwaysEquivalent = (_x, _y) => true;\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const combineAll = collection => combineMany(isAlwaysEquivalent, collection);\n/**\n * @category mapping\n * @since 2.0.0\n */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => make((x, y) => self(f(x), f(y))));\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Date = /*#__PURE__*/mapInput(number, date => date.getTime());\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const product = /*#__PURE__*/dual(2, (self, that) => make(([xa, xb], [ya, yb]) => self(xa, ya) && that(xb, yb)));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const all = collection => {\n  return make((x, y) => {\n    const len = Math.min(x.length, y.length);\n    let collectionLength = 0;\n    for (const equivalence of collection) {\n      if (collectionLength >= len) {\n        break;\n      }\n      if (!equivalence(x[collectionLength], y[collectionLength])) {\n        return false;\n      }\n      collectionLength++;\n    }\n    return true;\n  });\n};\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const productMany = (self, collection) => {\n  const equivalence = all(collection);\n  return make((x, y) => !self(x[0], y[0]) ? false : equivalence(x.slice(1), y.slice(1)));\n};\n/**\n * Similar to `Promise.all` but operates on `Equivalence`s.\n *\n * ```\n * [Equivalence<A>, Equivalence<B>, ...] -> Equivalence<[A, B, ...]>\n * ```\n *\n * Given a tuple of `Equivalence`s returns a new `Equivalence` that compares values of a tuple\n * by applying each `Equivalence` to the corresponding element of the tuple.\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const tuple = (...elements) => all(elements);\n/**\n * Creates a new `Equivalence` for an array of values based on a given `Equivalence` for the elements of the array.\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const array = item => make((self, that) => {\n  if (self.length !== that.length) {\n    return false;\n  }\n  for (let i = 0; i < self.length; i++) {\n    const isEq = item(self[i], that[i]);\n    if (!isEq) {\n      return false;\n    }\n  }\n  return true;\n});\n/**\n * Given a struct of `Equivalence`s returns a new `Equivalence` that compares values of a struct\n * by applying each `Equivalence` to the corresponding property of the struct.\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const struct = fields => {\n  const keys = Object.keys(fields);\n  return make((self, that) => {\n    for (const key of keys) {\n      if (!fields[key](self[key], that[key])) {\n        return false;\n      }\n    }\n    return true;\n  });\n};\n//# sourceMappingURL=Equivalence.js.map","import * as internal from \"./internal/executionStrategy.js\";\n/**\n * Execute effects sequentially.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sequential = internal.sequential;\n/**\n * Execute effects in parallel.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const parallel = internal.parallel;\n/**\n * Execute effects in parallel, up to the specified number of concurrent fibers.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const parallelN = internal.parallelN;\n/**\n * Returns `true` if the specified `ExecutionStrategy` is an instance of\n * `Sequential`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isSequential = internal.isSequential;\n/**\n * Returns `true` if the specified `ExecutionStrategy` is an instance of\n * `Sequential`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isParallel = internal.isParallel;\n/**\n * Returns `true` if the specified `ExecutionStrategy` is an instance of\n * `Sequential`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isParallelN = internal.isParallelN;\n/**\n * Folds over the specified `ExecutionStrategy` using the provided case\n * functions.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const match = internal.match;\n//# sourceMappingURL=ExecutionStrategy.js.map","import * as core from \"./internal/core.js\";\n/**\n * Returns `true` if the specified value is an `Exit`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isExit = core.exitIsExit;\n/**\n * Returns `true` if the specified `Exit` is a `Failure`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isFailure = core.exitIsFailure;\n/**\n * Returns `true` if the specified `Exit` is a `Success`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isSuccess = core.exitIsSuccess;\n/**\n * Returns `true` if the specified exit is a `Failure` **and** the `Cause` of\n * the failure was due to interruption, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isInterrupted = core.exitIsInterrupted;\n/**\n * Maps the `Success` value of the specified exit to the provided constant\n * value.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const as = core.exitAs;\n/**\n * Maps the `Success` value of the specified exit to a void.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const asVoid = core.exitAsVoid;\n/**\n * Returns a `Some<Cause<E>>` if the specified exit is a `Failure`, `None`\n * otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const causeOption = core.exitCauseOption;\n/**\n * Collects all of the specified exit values into a `Some<Exit<List<A>, E>>`. If\n * the provided iterable contains no elements, `None` will be returned.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const all = core.exitCollectAll;\n/**\n * Constructs a new `Exit.Failure` from the specified unrecoverable defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const die = core.exitDie;\n/**\n * Executes the predicate on the value of the specified exit if it is a\n * `Success`, otherwise returns `false`.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const exists = core.exitExists;\n/**\n * Constructs a new `Exit.Failure` from the specified recoverable error of type\n * `E`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = core.exitFail;\n/**\n * Constructs a new `Exit.Failure` from the specified `Cause` of type `E`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCause = core.exitFailCause;\n/**\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = core.exitFlatMap;\n/**\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMapEffect = core.exitFlatMapEffect;\n/**\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatten = core.exitFlatten;\n/**\n * @since 2.0.0\n * @category traversing\n */\nexport const forEachEffect = core.exitForEachEffect;\n/**\n * Converts an `Either<R, L>` into an `Exit<R, L>`.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const fromEither = core.exitFromEither;\n/**\n * Converts an `Option<A>` into an `Exit<void, A>`.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const fromOption = core.exitFromOption;\n/**\n * Returns the `A` if specified exit is a `Success`, otherwise returns the\n * alternate `A` value computed from the specified function which receives the\n * `Cause<E>` of the exit `Failure`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const getOrElse = core.exitGetOrElse;\n/**\n * Constructs a new `Exit.Failure` from the specified `FiberId` indicating that\n * the `Fiber` running an `Effect` workflow was terminated due to interruption.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const interrupt = core.exitInterrupt;\n/**\n * Maps over the `Success` value of the specified exit using the provided\n * function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = core.exitMap;\n/**\n * Maps over the `Success` and `Failure` cases of the specified exit using the\n * provided functions.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapBoth = core.exitMapBoth;\n/**\n * Maps over the error contained in the `Failure` of the specified exit using\n * the provided function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapError = core.exitMapError;\n/**\n * Maps over the `Cause` contained in the `Failure` of the specified exit using\n * the provided function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapErrorCause = core.exitMapErrorCause;\n/**\n * @since 2.0.0\n * @category folding\n */\nexport const match = core.exitMatch;\n/**\n * @since 2.0.0\n * @category folding\n */\nexport const matchEffect = core.exitMatchEffect;\n/**\n * Constructs a new `Exit.Success` containing the specified value of type `A`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = core.exitSucceed;\nconst void_ = core.exitVoid;\nexport {\n/**\n * Represents an `Exit` which succeeds with `undefined`.\n *\n * @since 2.0.0\n * @category constructors\n */\nvoid_ as void };\n/**\n * Sequentially zips the this result with the specified result or else returns\n * the failed `Cause<E | E2>`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = core.exitZip;\n/**\n * Sequentially zips the this result with the specified result discarding the\n * second element of the tuple or else returns the failed `Cause<E | E2>`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = core.exitZipLeft;\n/**\n * Sequentially zips the this result with the specified result discarding the\n * first element of the tuple or else returns the failed `Cause<E | E2>`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = core.exitZipRight;\n/**\n * Parallelly zips the this result with the specified result or else returns\n * the failed `Cause<E | E2>`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipPar = core.exitZipPar;\n/**\n * Parallelly zips the this result with the specified result discarding the\n * second element of the tuple or else returns the failed `Cause<E | E2>`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipParLeft = core.exitZipParLeft;\n/**\n * Parallelly zips the this result with the specified result discarding the\n * first element of the tuple or else returns the failed `Cause<E | E2>`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipParRight = core.exitZipParRight;\n/**\n * Zips this exit together with that exit using the specified combination\n * functions.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = core.exitZipWith;\n//# sourceMappingURL=Exit.js.map","import * as core from \"./internal/core.js\";\nimport * as circular from \"./internal/effect/circular.js\";\nimport * as internal from \"./internal/fiber.js\";\nimport * as fiberRuntime from \"./internal/fiberRuntime.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const FiberTypeId = internal.FiberTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const RuntimeFiberTypeId = internal.RuntimeFiberTypeId;\n/**\n * @since 2.0.0\n * @category instances\n */\nexport const Order = internal.Order;\n/**\n * Returns `true` if the specified value is a `Fiber`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isFiber = internal.isFiber;\n/**\n * Returns `true` if the specified `Fiber` is a `RuntimeFiber`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isRuntimeFiber = internal.isRuntimeFiber;\n/**\n * The identity of the fiber.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const id = internal.id;\nconst _await = internal._await;\nexport {\n/**\n * Awaits the fiber, which suspends the awaiting fiber until the result of the\n * fiber has been determined.\n *\n * @since 2.0.0\n * @category getters\n */\n_await as await };\n/**\n * Awaits on all fibers to be completed, successfully or not.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const awaitAll = fiberRuntime.fiberAwaitAll;\n/**\n * Retrieves the immediate children of the fiber.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const children = internal.children;\n/**\n * Collects all fibers into a single fiber producing an in-order list of the\n * results.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const all = fiberRuntime.fiberAll;\n/**\n * A fiber that is done with the specified `Exit` value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const done = internal.done;\n/**\n * @since 2.0.0\n * @category destructors\n */\nexport const dump = internal.dump;\n/**\n * @since 2.0.0\n * @category destructors\n */\nexport const dumpAll = internal.dumpAll;\n/**\n * A fiber that has already failed with the specified value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = internal.fail;\n/**\n * Creates a `Fiber` that has already failed with the specified cause.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCause = internal.failCause;\n/**\n * Lifts an `Effect` into a `Fiber`.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const fromEffect = internal.fromEffect;\n/**\n * Gets the current fiber if one is running.\n *\n * @since 2.0.0\n * @category utilities\n */\nexport const getCurrentFiber = internal.getCurrentFiber;\n/**\n * Inherits values from all `FiberRef` instances into current fiber. This\n * will resume immediately.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const inheritAll = internal.inheritAll;\n/**\n * Interrupts the fiber from whichever fiber is calling this method. If the\n * fiber has already exited, the returned effect will resume immediately.\n * Otherwise, the effect will resume when the fiber exits.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const interrupt = core.interruptFiber;\n/**\n * Constructrs a `Fiber` that is already interrupted.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const interrupted = internal.interrupted;\n/**\n * Interrupts the fiber as if interrupted from the specified fiber. If the\n * fiber has already exited, the returned effect will resume immediately.\n * Otherwise, the effect will resume when the fiber exits.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const interruptAs = core.interruptAsFiber;\n/**\n * Interrupts the fiber as if interrupted from the specified fiber. If the\n * fiber has already exited, the returned effect will resume immediately.\n * Otherwise, the effect will resume when the fiber exits.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const interruptAsFork = internal.interruptAsFork;\n/**\n * Interrupts all fibers, awaiting their interruption.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const interruptAll = internal.interruptAll;\n/**\n * Interrupts all fibers as by the specified fiber, awaiting their\n * interruption.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const interruptAllAs = internal.interruptAllAs;\n/**\n * Interrupts the fiber from whichever fiber is calling this method. The\n * interruption will happen in a separate daemon fiber, and the returned\n * effect will always resume immediately without waiting.\n *\n * @since 2.0.0\n * @category interruption\n */\nexport const interruptFork = fiberRuntime.fiberInterruptFork;\n/**\n * Joins the fiber, which suspends the joining fiber until the result of the\n * fiber has been determined. Attempting to join a fiber that has erred will\n * result in a catchable error. Joining an interrupted fiber will result in an\n * \"inner interruption\" of this fiber, unlike interruption triggered by\n * another fiber, \"inner interruption\" can be caught and recovered.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const join = internal.join;\n/**\n * Joins all fibers, awaiting their _successful_ completion. Attempting to\n * join a fiber that has erred will result in a catchable error, _if_ that\n * error does not result from interruption.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const joinAll = fiberRuntime.fiberJoinAll;\n/**\n * Maps over the value the Fiber computes.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * Effectually maps over the value the fiber computes.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapEffect = internal.mapEffect;\n/**\n * Passes the success of this fiber to the specified callback, and continues\n * with the fiber that it returns.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapFiber = internal.mapFiber;\n/**\n * Folds over the `Fiber` or `RuntimeFiber`.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const match = internal.match;\n/**\n * A fiber that never fails or succeeds.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const never = internal.never;\n/**\n * Returns a fiber that prefers `this` fiber, but falls back to the `that` one\n * when `this` one fails. Interrupting the returned fiber will interrupt both\n * fibers, sequentially, from left to right.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const orElse = internal.orElse;\n/**\n * Returns a fiber that prefers `this` fiber, but falls back to the `that` one\n * when `this` one fails. Interrupting the returned fiber will interrupt both\n * fibers, sequentially, from left to right.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const orElseEither = internal.orElseEither;\n/**\n * Tentatively observes the fiber, but returns immediately if it is not\n * already done.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const poll = internal.poll;\n/**\n * Pretty-prints a `RuntimeFiber`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const pretty = internal.pretty;\n/**\n * Returns a chunk containing all root fibers.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const roots = internal.roots;\n/**\n * Returns a chunk containing all root fibers.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unsafeRoots = internal.unsafeRoots;\n/**\n * Converts this fiber into a scoped effect. The fiber is interrupted when the\n * scope is closed.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const scoped = fiberRuntime.fiberScoped;\n/**\n * Returns the `FiberStatus` of a `RuntimeFiber`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const status = internal.status;\n/**\n * Returns a fiber that has already succeeded with the specified value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = internal.succeed;\nconst void_ = internal.void;\nexport {\n/**\n * A fiber that has already succeeded with unit.\n *\n * @since 2.0.0\n * @category constructors\n */\nvoid_ as void };\n/**\n * Zips this fiber and the specified fiber together, producing a tuple of\n * their output.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = circular.zipFiber;\n/**\n * Same as `zip` but discards the output of that `Fiber`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = circular.zipLeftFiber;\n/**\n * Same as `zip` but discards the output of this `Fiber`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = circular.zipRightFiber;\n/**\n * Zips this fiber with the specified fiber, combining their results using the\n * specified combiner function. Both joins and interruptions are performed in\n * sequential order from left to right.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = circular.zipWithFiber;\n//# sourceMappingURL=Fiber.js.map","import * as internal from \"./internal/fiberId.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const FiberIdTypeId = internal.FiberIdTypeId;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const none = internal.none;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const runtime = internal.runtime;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const composite = internal.composite;\n/**\n * Returns `true` if the specified unknown value is a `FiberId`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isFiberId = internal.isFiberId;\n/**\n * Returns `true` if the `FiberId` is a `None`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isNone = internal.isNone;\n/**\n * Returns `true` if the `FiberId` is a `Runtime`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isRuntime = internal.isRuntime;\n/**\n * Returns `true` if the `FiberId` is a `Composite`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isComposite = internal.isComposite;\n/**\n * Combine two `FiberId`s.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const combine = internal.combine;\n/**\n * Combines a set of `FiberId`s into a single `FiberId`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const combineAll = internal.combineAll;\n/**\n * Returns this `FiberId` if it is not `None`, otherwise returns that `FiberId`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const getOrElse = internal.getOrElse;\n/**\n * Get the set of identifiers for this `FiberId`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const ids = internal.ids;\n/**\n * Creates a new `FiberId`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * Creates a string representing the name of the current thread of execution\n * represented by the specified `FiberId`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const threadName = internal.threadName;\n/**\n * Convert a `FiberId` into an `Option<FiberId>`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toOption = internal.toOption;\n/**\n * Convert a `FiberId` into a `HashSet<FiberId>`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toSet = internal.toSet;\n/**\n * Unsafely creates a new `FiberId`.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeMake = internal.unsafeMake;\n//# sourceMappingURL=FiberId.js.map","import * as core from \"./internal/core.js\";\nimport * as fiberRuntime from \"./internal/fiberRuntime.js\";\nimport * as query from \"./internal/query.js\";\nimport * as Scheduler from \"./Scheduler.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const FiberRefTypeId = core.FiberRefTypeId;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = fiberRuntime.fiberRefMake;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const makeWith = fiberRuntime.fiberRefMakeWith;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const makeContext = fiberRuntime.fiberRefMakeContext;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const makeRuntimeFlags = fiberRuntime.fiberRefMakeRuntimeFlags;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const unsafeMake = core.fiberRefUnsafeMake;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const unsafeMakeHashSet = core.fiberRefUnsafeMakeHashSet;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const unsafeMakeContext = core.fiberRefUnsafeMakeContext;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const unsafeMakeSupervisor = fiberRuntime.fiberRefUnsafeMakeSupervisor;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const unsafeMakePatch = core.fiberRefUnsafeMakePatch;\n/**\n * @since 2.0.0\n * @category getters\n */\nexport const get = core.fiberRefGet;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const getAndSet = core.fiberRefGetAndSet;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const getAndUpdate = core.fiberRefGetAndUpdate;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const getAndUpdateSome = core.fiberRefGetAndUpdateSome;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const getWith = core.fiberRefGetWith;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const set = core.fiberRefSet;\nconst _delete = core.fiberRefDelete;\nexport {\n/**\n * @since 2.0.0\n * @category utils\n */\n_delete as delete };\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const reset = core.fiberRefReset;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const modify = core.fiberRefModify;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const modifySome = core.fiberRefModifySome;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const update = core.fiberRefUpdate;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const updateSome = core.fiberRefUpdateSome;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const updateAndGet = core.fiberRefUpdateAndGet;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const updateSomeAndGet = core.fiberRefUpdateSomeAndGet;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentConcurrency = core.currentConcurrency;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentRequestBatchingEnabled = core.currentRequestBatching;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentRequestCache = query.currentCache;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentRequestCacheEnabled = query.currentCacheEnabled;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentContext = core.currentContext;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentSchedulingPriority = core.currentSchedulingPriority;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentMaxOpsBeforeYield = core.currentMaxOpsBeforeYield;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const unhandledErrorLogLevel = core.currentUnhandledErrorLogLevel;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentLogAnnotations = core.currentLogAnnotations;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentLoggers = fiberRuntime.currentLoggers;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentLogLevel = core.currentLogLevel;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentMinimumLogLevel = fiberRuntime.currentMinimumLogLevel;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentLogSpan = core.currentLogSpan;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentRuntimeFlags = fiberRuntime.currentRuntimeFlags;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentScheduler = Scheduler.currentScheduler;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentSupervisor = fiberRuntime.currentSupervisor;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentMetricLabels = core.currentMetricLabels;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentTracerEnabled = core.currentTracerEnabled;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentTracerTimingEnabled = core.currentTracerTimingEnabled;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentTracerSpanAnnotations = core.currentTracerSpanAnnotations;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentTracerSpanLinks = core.currentTracerSpanLinks;\n/**\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const interruptedCause = core.currentInterruptedCause;\n//# sourceMappingURL=FiberRef.js.map","import * as internal from \"./internal/fiberRefs.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const FiberRefsSym = internal.FiberRefsSym;\nconst delete_ = internal.delete_;\nexport {\n/**\n * Deletes the specified `FiberRef` from the `FibterRefs`.\n *\n * @since 2.0.0\n * @category utils\n */\ndelete_ as delete };\n/**\n * Returns a set of each `FiberRef` in this collection.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const fiberRefs = internal.fiberRefs;\n/**\n * Forks this collection of fiber refs as the specified child fiber id. This\n * will potentially modify the value of the fiber refs, as determined by the\n * individual fiber refs that make up the collection.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const forkAs = internal.forkAs;\n/**\n * Gets the value of the specified `FiberRef` in this collection of `FiberRef`\n * values if it exists or `None` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const get = internal.get;\n/**\n * Gets the value of the specified `FiberRef` in this collection of `FiberRef`\n * values if it exists or the `initial` value of the `FiberRef` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const getOrDefault = internal.getOrDefault;\n/**\n * Joins this collection of fiber refs to the specified collection, as the\n * specified fiber id. This will perform diffing and merging to ensure\n * preservation of maximum information from both child and parent refs.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const joinAs = internal.joinAs;\n/**\n * Set each ref to either its value or its default.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const setAll = internal.setAll;\n/**\n * Updates the value of the specified `FiberRef` using the provided `FiberId`\n *\n * @since 2.0.0\n * @category utils\n */\nexport const updateAs = internal.updateAs;\n/**\n * Updates the values of the specified `FiberRef` & value pairs using the provided `FiberId`\n *\n * @since 2.0.0\n * @category utils\n */\nexport const updateManyAs = internal.updateManyAs;\n/**\n * Note: it will not copy the provided Map, make sure to provide a fresh one.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeMake = internal.unsafeMake;\n/**\n * The empty collection of `FiberRef` values.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const empty = internal.empty;\n//# sourceMappingURL=FiberRefs.js.map","import * as internal from \"./internal/fiberRefs/patch.js\";\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * Constructs a patch that describes the changes between the specified\n * collections of `FiberRef`\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const diff = internal.diff;\n/**\n * Combines this patch and the specified patch to create a new patch that\n * describes applying the changes from this patch and the specified patch\n * sequentially.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const combine = internal.combine;\n/**\n * Applies the changes described by this patch to the specified collection\n * of `FiberRef` values.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const patch = internal.patch;\n//# sourceMappingURL=FiberRefsPatch.js.map","import * as internal from \"./internal/fiberStatus.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const FiberStatusTypeId = internal.FiberStatusTypeId;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const done = internal.done;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const running = internal.running;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const suspended = internal.suspended;\n/**\n * Returns `true` if the specified value is a `FiberStatus`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isFiberStatus = internal.isFiberStatus;\n/**\n * Returns `true` if the specified `FiberStatus` is `Done`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isDone = internal.isDone;\n/**\n * Returns `true` if the specified `FiberStatus` is `Running`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isRunning = internal.isRunning;\n/**\n * Returns `true` if the specified `FiberStatus` is `Suspended`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isSuspended = internal.isSuspended;\n//# sourceMappingURL=FiberStatus.js.map","/**\n * Tests if a value is a `function`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isFunction } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isFunction(isFunction), true)\n * assert.deepStrictEqual(isFunction(\"function\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isFunction = input => typeof input === \"function\";\n/**\n * Creates a function that can be used in a data-last (aka `pipe`able) or\n * data-first style.\n *\n * The first parameter to `dual` is either the arity of the uncurried function\n * or a predicate that determines if the function is being used in a data-first\n * or data-last style.\n *\n * Using the arity is the most common use case, but there are some cases where\n * you may want to use a predicate. For example, if you have a function that\n * takes an optional argument, you can use a predicate to determine if the\n * function is being used in a data-first or data-last style.\n *\n * @param arity - Either the arity of the uncurried function or a predicate\n *                which determines if the function is being used in a data-first\n *                or data-last style.\n * @param body - The definition of the uncurried function.\n *\n * @example\n * import { dual, pipe } from \"effect/Function\"\n *\n * // Exampe using arity to determine data-first or data-last style\n * const sum: {\n *   (that: number): (self: number) => number\n *   (self: number, that: number): number\n * } = dual(2, (self: number, that: number): number => self + that)\n *\n * assert.deepStrictEqual(sum(2, 3), 5)\n * assert.deepStrictEqual(pipe(2, sum(3)), 5)\n *\n * // Example using a predicate to determine data-first or data-last style\n * const sum2: {\n *   (that: number): (self: number) => number\n *   (self: number, that: number): number\n * } = dual((args) => args.length === 1, (self: number, that: number): number => self + that)\n *\n * assert.deepStrictEqual(sum(2, 3), 5)\n * assert.deepStrictEqual(pipe(2, sum(3)), 5)\n *\n * @since 2.0.0\n */\nexport const dual = function (arity, body) {\n  if (typeof arity === \"function\") {\n    return function () {\n      if (arity(arguments)) {\n        // @ts-expect-error\n        return body.apply(this, arguments);\n      }\n      return self => body(self, ...arguments);\n    };\n  }\n  switch (arity) {\n    case 0:\n    case 1:\n      throw new RangeError(`Invalid arity ${arity}`);\n    case 2:\n      return function (a, b) {\n        if (arguments.length >= 2) {\n          return body(a, b);\n        }\n        return function (self) {\n          return body(self, a);\n        };\n      };\n    case 3:\n      return function (a, b, c) {\n        if (arguments.length >= 3) {\n          return body(a, b, c);\n        }\n        return function (self) {\n          return body(self, a, b);\n        };\n      };\n    case 4:\n      return function (a, b, c, d) {\n        if (arguments.length >= 4) {\n          return body(a, b, c, d);\n        }\n        return function (self) {\n          return body(self, a, b, c);\n        };\n      };\n    case 5:\n      return function (a, b, c, d, e) {\n        if (arguments.length >= 5) {\n          return body(a, b, c, d, e);\n        }\n        return function (self) {\n          return body(self, a, b, c, d);\n        };\n      };\n    default:\n      return function () {\n        if (arguments.length >= arity) {\n          // @ts-expect-error\n          return body.apply(this, arguments);\n        }\n        const args = arguments;\n        return function (self) {\n          return body(self, ...args);\n        };\n      };\n  }\n};\n/**\n * Apply a function to a given value.\n *\n * @param a - The value that the function will be applied to.\n * @param self - The function to be applied to a value.\n *\n * @example\n * import { pipe, apply } from \"effect/Function\"\n * import { length } from \"effect/String\"\n *\n * assert.deepStrictEqual(pipe(length, apply(\"hello\")), 5)\n *\n * @since 2.0.0\n */\nexport const apply = a => self => self(a);\n/**\n * The identity function, i.e. A function that returns its input argument.\n *\n * @param a - The input argument.\n *\n * @example\n * import { identity } from \"effect/Function\"\n *\n * assert.deepStrictEqual(identity(5), 5)\n *\n * @since 2.0.0\n */\nexport const identity = a => a;\n/**\n * A function that ensures that the type of an expression matches some type,\n * without changing the resulting type of that expression.\n *\n * @example\n * import { satisfies } from \"effect/Function\"\n *\n * const test1 = satisfies<number>()(5 as const)\n *     //^? const test: 5\n *     // @ts-expect-error\n * const test2 = satisfies<string>()(5)\n *     //^? Argument of type 'number' is not assignable to parameter of type 'string'\n *\n * assert.deepStrictEqual(satisfies<number>()(5), 5)\n *\n * @since 2.0.0\n */\nexport const satisfies = () => b => b;\n/**\n * Casts the result to the specified type.\n *\n * @param a - The value to be casted to the target type.\n *\n * @example\n * import { unsafeCoerce, identity } from \"effect/Function\"\n *\n * assert.deepStrictEqual(unsafeCoerce, identity)\n *\n * @since 2.0.0\n */\nexport const unsafeCoerce = identity;\n/**\n * Creates a constant value that never changes.\n *\n * This is useful when you want to pass a value to a higher-order function (a function that takes another function as its argument)\n * and want that inner function to always use the same value, no matter how many times it is called.\n *\n * @param value - The constant value to be returned.\n *\n * @example\n * import { constant } from \"effect/Function\"\n *\n * const constNull = constant(null)\n *\n * assert.deepStrictEqual(constNull(), null)\n * assert.deepStrictEqual(constNull(), null)\n *\n * @since 2.0.0\n */\nexport const constant = value => () => value;\n/**\n * A thunk that returns always `true`.\n *\n * @example\n * import { constTrue } from \"effect/Function\"\n *\n * assert.deepStrictEqual(constTrue(), true)\n *\n * @since 2.0.0\n */\nexport const constTrue = /*#__PURE__*/constant(true);\n/**\n * A thunk that returns always `false`.\n *\n * @example\n * import { constFalse } from \"effect/Function\"\n *\n * assert.deepStrictEqual(constFalse(), false)\n *\n * @since 2.0.0\n */\nexport const constFalse = /*#__PURE__*/constant(false);\n/**\n * A thunk that returns always `null`.\n *\n * @example\n * import { constNull } from \"effect/Function\"\n *\n * assert.deepStrictEqual(constNull(), null)\n *\n * @since 2.0.0\n */\nexport const constNull = /*#__PURE__*/constant(null);\n/**\n * A thunk that returns always `undefined`.\n *\n * @example\n * import { constUndefined } from \"effect/Function\"\n *\n * assert.deepStrictEqual(constUndefined(), undefined)\n *\n * @since 2.0.0\n */\nexport const constUndefined = /*#__PURE__*/constant(undefined);\n/**\n * A thunk that returns always `void`.\n *\n * @example\n * import { constVoid } from \"effect/Function\"\n *\n * assert.deepStrictEqual(constVoid(), undefined)\n *\n * @since 2.0.0\n */\nexport const constVoid = constUndefined;\n/**\n * Reverses the order of arguments for a curried function.\n *\n * @param f - A curried function that takes multiple arguments.\n *\n * @example\n * import { flip } from \"effect/Function\"\n *\n * const f = (a: number) => (b: string) => a - b.length\n *\n * assert.deepStrictEqual(flip(f)('aaa')(2), -1)\n *\n * @since 2.0.0\n */\nexport const flip = f => (...b) => (...a) => f(...a)(...b);\n/**\n * Composes two functions, `ab` and `bc` into a single function that takes in an argument `a` of type `A` and returns a result of type `C`.\n * The result is obtained by first applying the `ab` function to `a` and then applying the `bc` function to the result of `ab`.\n *\n * @param ab - A function that maps from `A` to `B`.\n * @param bc - A function that maps from `B` to `C`.\n *\n * @example\n * import { compose } from \"effect/Function\"\n *\n * const increment = (n: number) => n + 1;\n * const square = (n: number) => n * n;\n *\n * assert.strictEqual(compose(increment, square)(2), 9);\n *\n * @since 2.0.0\n */\nexport const compose = /*#__PURE__*/dual(2, (ab, bc) => a => bc(ab(a)));\n/**\n * The `absurd` function is a stub for cases where a value of type `never` is encountered in your code,\n * meaning that it should be impossible for this code to be executed.\n *\n * This function is particularly when it's necessary to specify that certain cases are impossible.\n *\n * @since 2.0.0\n */\nexport const absurd = _ => {\n  throw new Error(\"Called `absurd` function which should be uncallable\");\n};\n/**\n * Creates a tupled version of this function: instead of `n` arguments, it accepts a single tuple argument.\n *\n * @example\n * import { tupled } from \"effect/Function\"\n *\n * const sumTupled = tupled((x: number, y: number): number => x + y)\n *\n * assert.deepStrictEqual(sumTupled([1, 2]), 3)\n *\n * @since 2.0.0\n */\nexport const tupled = f => a => f(...a);\n/**\n * Inverse function of `tupled`\n *\n * @example\n * import { untupled } from \"effect/Function\"\n *\n * const getFirst = untupled(<A, B>(tuple: [A, B]): A => tuple[0])\n *\n * assert.deepStrictEqual(getFirst(1, 2), 1)\n *\n * @since 2.0.0\n */\nexport const untupled = f => (...a) => f(a);\nexport function pipe(a, ab, bc, cd, de, ef, fg, gh, hi) {\n  switch (arguments.length) {\n    case 1:\n      return a;\n    case 2:\n      return ab(a);\n    case 3:\n      return bc(ab(a));\n    case 4:\n      return cd(bc(ab(a)));\n    case 5:\n      return de(cd(bc(ab(a))));\n    case 6:\n      return ef(de(cd(bc(ab(a)))));\n    case 7:\n      return fg(ef(de(cd(bc(ab(a))))));\n    case 8:\n      return gh(fg(ef(de(cd(bc(ab(a)))))));\n    case 9:\n      return hi(gh(fg(ef(de(cd(bc(ab(a))))))));\n    default:\n      {\n        let ret = arguments[0];\n        for (let i = 1; i < arguments.length; i++) {\n          ret = arguments[i](ret);\n        }\n        return ret;\n      }\n  }\n}\nexport function flow(ab, bc, cd, de, ef, fg, gh, hi, ij) {\n  switch (arguments.length) {\n    case 1:\n      return ab;\n    case 2:\n      return function () {\n        return bc(ab.apply(this, arguments));\n      };\n    case 3:\n      return function () {\n        return cd(bc(ab.apply(this, arguments)));\n      };\n    case 4:\n      return function () {\n        return de(cd(bc(ab.apply(this, arguments))));\n      };\n    case 5:\n      return function () {\n        return ef(de(cd(bc(ab.apply(this, arguments)))));\n      };\n    case 6:\n      return function () {\n        return fg(ef(de(cd(bc(ab.apply(this, arguments))))));\n      };\n    case 7:\n      return function () {\n        return gh(fg(ef(de(cd(bc(ab.apply(this, arguments)))))));\n      };\n    case 8:\n      return function () {\n        return hi(gh(fg(ef(de(cd(bc(ab.apply(this, arguments))))))));\n      };\n    case 9:\n      return function () {\n        return ij(hi(gh(fg(ef(de(cd(bc(ab.apply(this, arguments)))))))));\n      };\n  }\n  return;\n}\n/**\n * Type hole simulation.\n *\n * @since 2.0.0\n */\nexport const hole = /*#__PURE__*/unsafeCoerce(absurd);\n/**\n * The SK combinator, also known as the \"S-K combinator\" or \"S-combinator\", is a fundamental combinator in the\n * lambda calculus and the SKI combinator calculus.\n *\n * This function is useful for discarding the first argument passed to it and returning the second argument.\n *\n * @param _ - The first argument to be discarded.\n * @param b - The second argument to be returned.\n *\n * @example\n * import { SK } from \"effect/Function\";\n *\n * assert.deepStrictEqual(SK(0, \"hello\"), \"hello\")\n *\n * @since 2.0.0\n */\nexport const SK = (_, b) => b;\n//# sourceMappingURL=Function.js.map","/**\n * @since 2.0.0\n */\nimport * as version from \"./internal/version.js\";\nconst globalStoreId = /*#__PURE__*/Symbol.for(`effect/GlobalValue/globalStoreId/${/*#__PURE__*/version.getCurrentVersion()}`);\nif (!(globalStoreId in globalThis)) {\n  ;\n  globalThis[globalStoreId] = /*#__PURE__*/new Map();\n}\nconst globalStore = globalThis[globalStoreId];\n/**\n * @since 2.0.0\n */\nexport const globalValue = (id, compute) => {\n  if (!globalStore.has(id)) {\n    globalStore.set(id, compute());\n  }\n  return globalStore.get(id);\n};\n//# sourceMappingURL=GlobalValue.js.map","/**\n * @since 2.0.0\n */\nimport { pipe } from \"./Function.js\";\nimport { globalValue } from \"./GlobalValue.js\";\nimport { hasProperty } from \"./Predicate.js\";\nimport { structuralRegionState } from \"./Utils.js\";\n/** @internal */\nconst randomHashCache = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Hash/randomHashCache\"), () => new WeakMap());\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const symbol = /*#__PURE__*/Symbol.for(\"effect/Hash\");\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const hash = self => {\n  if (structuralRegionState.enabled === true) {\n    return 0;\n  }\n  switch (typeof self) {\n    case \"number\":\n      return number(self);\n    case \"bigint\":\n      return string(self.toString(10));\n    case \"boolean\":\n      return string(String(self));\n    case \"symbol\":\n      return string(String(self));\n    case \"string\":\n      return string(self);\n    case \"undefined\":\n      return string(\"undefined\");\n    case \"function\":\n    case \"object\":\n      {\n        if (self === null) {\n          return string(\"null\");\n        } else if (self instanceof Date) {\n          return hash(self.toISOString());\n        } else if (isHash(self)) {\n          return self[symbol]();\n        } else {\n          return random(self);\n        }\n      }\n    default:\n      throw new Error(`BUG: unhandled typeof ${typeof self} - please report an issue at https://github.com/Effect-TS/effect/issues`);\n  }\n};\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const random = self => {\n  if (!randomHashCache.has(self)) {\n    randomHashCache.set(self, number(Math.floor(Math.random() * Number.MAX_SAFE_INTEGER)));\n  }\n  return randomHashCache.get(self);\n};\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const combine = b => self => self * 53 ^ b;\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const optimize = n => n & 0xbfffffff | n >>> 1 & 0x40000000;\n/**\n * @since 2.0.0\n * @category guards\n */\nexport const isHash = u => hasProperty(u, symbol);\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const number = n => {\n  if (n !== n || n === Infinity) {\n    return 0;\n  }\n  let h = n | 0;\n  if (h !== n) {\n    h ^= n * 0xffffffff;\n  }\n  while (n > 0xffffffff) {\n    h ^= n /= 0xffffffff;\n  }\n  return optimize(n);\n};\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const string = str => {\n  let h = 5381,\n    i = str.length;\n  while (i) {\n    h = h * 33 ^ str.charCodeAt(--i);\n  }\n  return optimize(h);\n};\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const structureKeys = (o, keys) => {\n  let h = 12289;\n  for (let i = 0; i < keys.length; i++) {\n    h ^= pipe(string(keys[i]), combine(hash(o[keys[i]])));\n  }\n  return optimize(h);\n};\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const structure = o => structureKeys(o, Object.keys(o));\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const array = arr => {\n  let h = 6151;\n  for (let i = 0; i < arr.length; i++) {\n    h = pipe(h, combine(hash(arr[i])));\n  }\n  return optimize(h);\n};\n/**\n * @since 2.0.0\n * @category hashing\n */\nexport const cached = function () {\n  if (arguments.length === 1) {\n    const self = arguments[0];\n    return function (hash) {\n      Object.defineProperty(self, symbol, {\n        value() {\n          return hash;\n        },\n        enumerable: false\n      });\n      return hash;\n    };\n  }\n  const self = arguments[0];\n  const hash = arguments[1];\n  Object.defineProperty(self, symbol, {\n    value() {\n      return hash;\n    },\n    enumerable: false\n  });\n  return hash;\n};\n//# sourceMappingURL=Hash.js.map","/**\n * @since 2.0.0\n */\nimport * as HM from \"./internal/hashMap.js\";\nimport * as _keySet from \"./internal/hashMap/keySet.js\";\nconst TypeId = HM.HashMapTypeId;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isHashMap = HM.isHashMap;\n/**\n * Creates a new `HashMap`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = HM.empty;\n/**\n * Constructs a new `HashMap` from an array of key/value pairs.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = HM.make;\n/**\n * Creates a new `HashMap` from an iterable collection of key/value pairs.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = HM.fromIterable;\n/**\n * Checks if the `HashMap` contains any entries.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const isEmpty = HM.isEmpty;\n/**\n * Safely lookup the value for the specified key in the `HashMap` using the\n * internal hashing function.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const get = HM.get;\n/**\n * Lookup the value for the specified key in the `HashMap` using a custom hash.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const getHash = HM.getHash;\n/**\n * Unsafely lookup the value for the specified key in the `HashMap` using the\n * internal hashing function.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeGet = HM.unsafeGet;\n/**\n * Checks if the specified key has an entry in the `HashMap`.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const has = HM.has;\n/**\n * Checks if the specified key has an entry in the `HashMap` using a custom\n * hash.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const hasHash = HM.hasHash;\n/**\n * Sets the specified key to the specified value using the internal hashing\n * function.\n *\n * @since 2.0.0\n */\nexport const set = HM.set;\n/**\n * Returns an `IterableIterator` of the keys within the `HashMap`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const keys = HM.keys;\n/**\n * Returns a `HashSet` of keys within the `HashMap`.\n *\n * @since 2.0.0\n * @category getter\n */\nexport const keySet = _keySet.keySet;\n/**\n * Returns an `IterableIterator` of the values within the `HashMap`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const values = HM.values;\n/**\n * Returns an `IterableIterator` of the entries within the `HashMap`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const entries = HM.entries;\n/**\n * Returns an `Array<[K, V]>` of the entries within the `HashMap`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const toEntries = self => Array.from(entries(self));\n/**\n * Returns the number of entries within the `HashMap`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const size = HM.size;\n/**\n * Marks the `HashMap` as mutable.\n *\n * @since 2.0.0\n */\nexport const beginMutation = HM.beginMutation;\n/**\n * Marks the `HashMap` as immutable.\n *\n * @since 2.0.0\n */\nexport const endMutation = HM.endMutation;\n/**\n * Mutates the `HashMap` within the context of the provided function.\n *\n * @since 2.0.0\n */\nexport const mutate = HM.mutate;\n/**\n * Set or remove the specified key in the `HashMap` using the specified\n * update function. The value of the specified key will be computed using the\n * provided hash.\n *\n * The update function will be invoked with the current value of the key if it\n * exists, or `None` if no such value exists.\n *\n * @since 2.0.0\n */\nexport const modifyAt = HM.modifyAt;\n/**\n * Alter the value of the specified key in the `HashMap` using the specified\n * update function. The value of the specified key will be computed using the\n * provided hash.\n *\n * The update function will be invoked with the current value of the key if it\n * exists, or `None` if no such value exists.\n *\n * This function will always either update or insert a value into the `HashMap`.\n *\n * @since 2.0.0\n */\nexport const modifyHash = HM.modifyHash;\n/**\n * Updates the value of the specified key within the `HashMap` if it exists.\n *\n * @since 2.0.0\n */\nexport const modify = HM.modify;\n/**\n * Performs a union of this `HashMap` and that `HashMap`.\n *\n * @since 2.0.0\n */\nexport const union = HM.union;\n/**\n * Remove the entry for the specified key in the `HashMap` using the internal\n * hashing function.\n *\n * @since 2.0.0\n */\nexport const remove = HM.remove;\n/**\n * Removes all entries in the `HashMap` which have the specified keys.\n *\n * @since 2.0.0\n */\nexport const removeMany = HM.removeMany;\n/**\n * Maps over the entries of the `HashMap` using the specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = HM.map;\n/**\n * Chains over the entries of the `HashMap` using the specified function.\n *\n * **NOTE**: the hash and equal of both maps have to be the same.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = HM.flatMap;\n/**\n * Applies the specified function to the entries of the `HashMap`.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const forEach = HM.forEach;\n/**\n * Reduces the specified state over the entries of the `HashMap`.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduce = HM.reduce;\n/**\n * Filters entries out of a `HashMap` using the specified predicate.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filter = HM.filter;\n/**\n * Filters out `None` values from a `HashMap` of `Options`s.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const compact = HM.compact;\n/**\n * Maps over the entries of the `HashMap` using the specified partial function\n * and filters out `None` values.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filterMap = HM.filterMap;\n/**\n * Returns the first element that satisfies the specified\n * predicate, or `None` if no such element exists.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findFirst = HM.findFirst;\n//# sourceMappingURL=HashMap.js.map","/**\n * @since 2.0.0\n */\nimport * as HS from \"./internal/hashSet.js\";\nconst TypeId = HS.HashSetTypeId;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isHashSet = HS.isHashSet;\n/**\n * Creates an empty `HashSet`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = HS.empty;\n/**\n * Creates a new `HashSet` from an iterable collection of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = HS.fromIterable;\n/**\n * Construct a new `HashSet` from a variable number of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = HS.make;\n/**\n * Checks if the specified value exists in the `HashSet`.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const has = HS.has;\n/**\n * Check if a predicate holds true for some `HashSet` element.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const some = HS.some;\n/**\n * Check if a predicate holds true for every `HashSet` element.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const every = HS.every;\n/**\n * Returns `true` if and only if every element in the this `HashSet` is an\n * element of the second set,\n *\n * **NOTE**: the hash and equal of both sets must be the same.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const isSubset = HS.isSubset;\n/**\n * Returns an `IterableIterator` of the values in the `HashSet`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const values = HS.values;\n/**\n * Calculates the number of values in the `HashSet`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const size = HS.size;\n/**\n * Marks the `HashSet` as mutable.\n *\n * @since 2.0.0\n */\nexport const beginMutation = HS.beginMutation;\n/**\n * Marks the `HashSet` as immutable.\n *\n * @since 2.0.0\n */\nexport const endMutation = HS.endMutation;\n/**\n * Mutates the `HashSet` within the context of the provided function.\n *\n * @since 2.0.0\n */\nexport const mutate = HS.mutate;\n/**\n * Adds a value to the `HashSet`.\n *\n * @since 2.0.0\n */\nexport const add = HS.add;\n/**\n * Removes a value from the `HashSet`.\n *\n * @since 2.0.0\n */\nexport const remove = HS.remove;\n/**\n * Computes the set difference between this `HashSet` and the specified\n * `Iterable<A>`.\n *\n * **NOTE**: the hash and equal of the values in both the set and the iterable\n * must be the same.\n *\n * @since 2.0.0\n */\nexport const difference = HS.difference;\n/**\n * Returns a `HashSet` of values which are present in both this set and that\n * `Iterable<A>`.\n *\n * **NOTE**: the hash and equal of the values in both the set and the iterable\n * must be the same.\n *\n * @since 2.0.0\n */\nexport const intersection = HS.intersection;\n/**\n * Computes the set union `(`self` + `that`)` between this `HashSet` and the\n * specified `Iterable<A>`.\n *\n * **NOTE**: the hash and equal of the values in both the set and the iterable\n * must be the same.\n *\n * @since 2.0.0\n */\nexport const union = HS.union;\n/**\n * Checks if a value is present in the `HashSet`. If it is present, the value\n * will be removed from the `HashSet`, otherwise the value will be added to the\n * `HashSet`.\n *\n * @since 2.0.0\n */\nexport const toggle = HS.toggle;\n/**\n * Maps over the values of the `HashSet` using the specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = HS.map;\n/**\n * Chains over the values of the `HashSet` using the specified function.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = HS.flatMap;\n/**\n * Applies the specified function to the values of the `HashSet`.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const forEach = HS.forEach;\n/**\n * Reduces the specified state over the values of the `HashSet`.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduce = HS.reduce;\n/**\n * Filters values out of a `HashSet` using the specified predicate.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filter = HS.filter;\n/**\n * Partition the values of a `HashSet` using the specified predicate.\n *\n * If a value matches the predicate, it will be placed into the `HashSet` on the\n * right side of the resulting `Tuple`, otherwise the value will be placed into\n * the left side.\n *\n * @since 2.0.0\n * @category partitioning\n */\nexport const partition = HS.partition;\n//# sourceMappingURL=HashSet.js.map","/**\n * @since 2.0.0\n */\nimport { hasProperty, isFunction } from \"./Predicate.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const NodeInspectSymbol = /*#__PURE__*/Symbol.for(\"nodejs.util.inspect.custom\");\n/**\n * @since 2.0.0\n */\nexport const toJSON = x => {\n  if (hasProperty(x, \"toJSON\") && isFunction(x[\"toJSON\"]) && x[\"toJSON\"].length === 0) {\n    return x.toJSON();\n  } else if (Array.isArray(x)) {\n    return x.map(toJSON);\n  }\n  return x;\n};\n/**\n * @since 2.0.0\n */\nexport const format = x => JSON.stringify(x, null, 2);\n/**\n * @since 2.0.0\n */\nexport const BaseProto = {\n  toJSON() {\n    return toJSON(this);\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  toString() {\n    return format(this.toJSON());\n  }\n};\n/**\n * @since 2.0.0\n */\nexport class Class {\n  /**\n   * @since 2.0.0\n   */\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n  /**\n   * @since 2.0.0\n   */\n  toString() {\n    return format(this.toJSON());\n  }\n}\n/**\n * @since 2.0.0\n */\nexport const toStringUnknown = (u, whitespace = 2) => {\n  try {\n    return typeof u === \"object\" ? stringifyCircular(u, whitespace) : String(u);\n  } catch (_) {\n    return String(u);\n  }\n};\n/**\n * @since 2.0.0\n */\nexport const stringifyCircular = (obj, whitespace) => {\n  let cache = [];\n  const retVal = JSON.stringify(obj, (_key, value) => typeof value === \"object\" && value !== null ? cache.includes(value) ? undefined // circular reference\n  : cache.push(value) && value : value, whitespace);\n  cache = undefined;\n  return retVal;\n};\n//# sourceMappingURL=Inspectable.js.map","/**\n * This module provides utility functions for working with Iterables in TypeScript.\n *\n * @since 2.0.0\n */\nimport * as E from \"./Either.js\";\nimport * as Equal from \"./Equal.js\";\nimport { dual, identity } from \"./Function.js\";\nimport * as O from \"./Option.js\";\nimport { isBoolean } from \"./Predicate.js\";\nimport * as Tuple from \"./Tuple.js\";\n/**\n * Return a `Iterable` with element `i` initialized with `f(i)`.\n *\n * If the `length` is not specified, the `Iterable` will be infinite.\n *\n * **Note**. `length` is normalized to an integer >= 1.\n *\n * @example\n * import { makeBy } from \"effect/Iterable\"\n *\n * assert.deepStrictEqual(Array.from(makeBy(n => n * 2, { length: 5 })), [0, 2, 4, 6, 8])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const makeBy = (f, options) => {\n  const max = options?.length !== undefined ? Math.max(1, Math.floor(options.length)) : Infinity;\n  return {\n    [Symbol.iterator]() {\n      let i = 0;\n      return {\n        next() {\n          if (i < max) {\n            return {\n              value: f(i++),\n              done: false\n            };\n          }\n          return {\n            done: true,\n            value: undefined\n          };\n        }\n      };\n    }\n  };\n};\n/**\n * Return a `Iterable` containing a range of integers, including both endpoints.\n *\n * If `end` is omitted, the range will not have an upper bound.\n *\n * @example\n * import { range } from \"effect/Iterable\"\n *\n * assert.deepStrictEqual(Array.from(range(1, 3)), [1, 2, 3])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const range = (start, end) => {\n  if (end === undefined) {\n    return makeBy(i => start + i);\n  }\n  return makeBy(i => start + i, {\n    length: start <= end ? end - start + 1 : 1\n  });\n};\n/**\n * Return a `Iterable` containing a value repeated the specified number of times.\n *\n * **Note**. `n` is normalized to an integer >= 1.\n *\n * @example\n * import { replicate } from \"effect/Iterable\"\n *\n * assert.deepStrictEqual(Array.from(replicate(\"a\", 3)), [\"a\", \"a\", \"a\"])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const replicate = /*#__PURE__*/dual(2, (a, n) => makeBy(() => a, {\n  length: n\n}));\n/**\n * Takes a record and returns an Iterable of tuples containing its keys and values.\n *\n * @param self - The record to transform.\n *\n * @example\n * import { fromRecord } from \"effect/Iterable\"\n *\n * const x = { a: 1, b: 2, c: 3 }\n * assert.deepStrictEqual(Array.from(fromRecord(x)), [[\"a\", 1], [\"b\", 2], [\"c\", 3]])\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const fromRecord = self => ({\n  *[Symbol.iterator]() {\n    for (const key in self) {\n      if (Object.prototype.hasOwnProperty.call(self, key)) {\n        yield [key, self[key]];\n      }\n    }\n  }\n});\n/**\n * Prepend an element to the front of an `Iterable`, creating a new `Iterable`.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prepend = /*#__PURE__*/dual(2, (self, head) => prependAll(self, [head]));\n/**\n * Prepends the specified prefix iterable to the beginning of the specified iterable.\n *\n * @example\n * import { Iterable } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Array.from(Iterable.prependAll([1, 2], [\"a\", \"b\"])),\n *   [\"a\", \"b\", 1, 2]\n * )\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prependAll = /*#__PURE__*/dual(2, (self, that) => appendAll(that, self));\n/**\n * Append an element to the end of an `Iterable`, creating a new `Iterable`.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const append = /*#__PURE__*/dual(2, (self, last) => appendAll(self, [last]));\n/**\n * Concatenates two iterables, combining their elements.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const appendAll = /*#__PURE__*/dual(2, (self, that) => ({\n  [Symbol.iterator]() {\n    const iterA = self[Symbol.iterator]();\n    let doneA = false;\n    let iterB;\n    return {\n      next() {\n        if (!doneA) {\n          const r = iterA.next();\n          if (r.done) {\n            doneA = true;\n            iterB = that[Symbol.iterator]();\n            return iterB.next();\n          }\n          return r;\n        }\n        return iterB.next();\n      }\n    };\n  }\n}));\n/**\n * Reduce an `Iterable` from the left, keeping all intermediate results instead of only the final result.\n *\n * @category folding\n * @since 2.0.0\n */\nexport const scan = /*#__PURE__*/dual(3, (self, b, f) => ({\n  [Symbol.iterator]() {\n    let acc = b;\n    let iterator;\n    function next() {\n      if (iterator === undefined) {\n        iterator = self[Symbol.iterator]();\n        return {\n          done: false,\n          value: acc\n        };\n      }\n      const result = iterator.next();\n      if (result.done) {\n        return result;\n      }\n      acc = f(acc, result.value);\n      return {\n        done: false,\n        value: acc\n      };\n    }\n    return {\n      next\n    };\n  }\n}));\n/**\n * Determine if an `Iterable` is empty\n *\n * @example\n * import { isEmpty } from \"effect/Iterable\"\n *\n * assert.deepStrictEqual(isEmpty([]), true);\n * assert.deepStrictEqual(isEmpty([1, 2, 3]), false);\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isEmpty = self => {\n  const iterator = self[Symbol.iterator]();\n  return iterator.next().done === true;\n};\n/**\n * Return the number of elements in a `Iterable`.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const size = self => {\n  const iterator = self[Symbol.iterator]();\n  let count = 0;\n  while (!iterator.next().done) {\n    count++;\n  }\n  return count;\n};\n/**\n * Get the first element of a `Iterable`, or `None` if the `Iterable` is empty.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const head = self => {\n  const iterator = self[Symbol.iterator]();\n  const result = iterator.next();\n  return result.done ? O.none() : O.some(result.value);\n};\n/**\n * Get the first element of a `Iterable`, or throw an error if the `Iterable` is empty.\n *\n * @category getters\n * @since 3.3.0\n */\nexport const unsafeHead = self => {\n  const iterator = self[Symbol.iterator]();\n  const result = iterator.next();\n  if (result.done) throw new Error(\"unsafeHead: empty iterable\");\n  return result.value;\n};\n/**\n * Keep only a max number of elements from the start of an `Iterable`, creating a new `Iterable`.\n *\n * **Note**. `n` is normalized to a non negative integer.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const take = /*#__PURE__*/dual(2, (self, n) => ({\n  [Symbol.iterator]() {\n    let i = 0;\n    const iterator = self[Symbol.iterator]();\n    return {\n      next() {\n        if (i < n) {\n          i++;\n          return iterator.next();\n        }\n        return {\n          done: true,\n          value: undefined\n        };\n      }\n    };\n  }\n}));\n/**\n * Calculate the longest initial Iterable for which all element satisfy the specified predicate, creating a new `Iterable`.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const takeWhile = /*#__PURE__*/dual(2, (self, predicate) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let i = 0;\n    return {\n      next() {\n        const result = iterator.next();\n        if (result.done || !predicate(result.value, i++)) {\n          return {\n            done: true,\n            value: undefined\n          };\n        }\n        return result;\n      }\n    };\n  }\n}));\n/**\n * Drop a max number of elements from the start of an `Iterable`\n *\n * **Note**. `n` is normalized to a non negative integer.\n *\n * @category getters\n * @since 2.0.0\n */\nexport const drop = /*#__PURE__*/dual(2, (self, n) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let i = 0;\n    return {\n      next() {\n        while (i < n) {\n          const result = iterator.next();\n          if (result.done) {\n            return {\n              done: true,\n              value: undefined\n            };\n          }\n          i++;\n        }\n        return iterator.next();\n      }\n    };\n  }\n}));\n/**\n * Returns the first element that satisfies the specified\n * predicate, or `None` if no such element exists.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findFirst = /*#__PURE__*/dual(2, (self, f) => {\n  let i = 0;\n  for (const a of self) {\n    const o = f(a, i);\n    if (isBoolean(o)) {\n      if (o) {\n        return O.some(a);\n      }\n    } else {\n      if (O.isSome(o)) {\n        return o;\n      }\n    }\n    i++;\n  }\n  return O.none();\n});\n/**\n * Find the last element for which a predicate holds.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findLast = /*#__PURE__*/dual(2, (self, f) => {\n  let i = 0;\n  let last = O.none();\n  for (const a of self) {\n    const o = f(a, i);\n    if (isBoolean(o)) {\n      if (o) {\n        last = O.some(a);\n      }\n    } else {\n      if (O.isSome(o)) {\n        last = o;\n      }\n    }\n    i++;\n  }\n  return last;\n});\n/**\n * Takes two `Iterable`s and returns an `Iterable` of corresponding pairs.\n *\n * @category zipping\n * @since 2.0.0\n */\nexport const zip = /*#__PURE__*/dual(2, (self, that) => zipWith(self, that, Tuple.make));\n/**\n * Apply a function to pairs of elements at the same index in two `Iterable`s, collecting the results. If one\n * input `Iterable` is short, excess elements of the longer `Iterable` are discarded.\n *\n * @category zipping\n * @since 2.0.0\n */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => ({\n  [Symbol.iterator]() {\n    const selfIterator = self[Symbol.iterator]();\n    const thatIterator = that[Symbol.iterator]();\n    return {\n      next() {\n        const selfResult = selfIterator.next();\n        const thatResult = thatIterator.next();\n        if (selfResult.done || thatResult.done) {\n          return {\n            done: true,\n            value: undefined\n          };\n        }\n        return {\n          done: false,\n          value: f(selfResult.value, thatResult.value)\n        };\n      }\n    };\n  }\n}));\n/**\n * Places an element in between members of an `Iterable`.\n * If the input is a non-empty array, the result is also a non-empty array.\n *\n * @since 2.0.0\n */\nexport const intersperse = /*#__PURE__*/dual(2, (self, middle) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let next = iterator.next();\n    let emitted = false;\n    return {\n      next() {\n        if (next.done) {\n          return next;\n        } else if (emitted) {\n          emitted = false;\n          return {\n            done: false,\n            value: middle\n          };\n        }\n        emitted = true;\n        const result = next;\n        next = iterator.next();\n        return result;\n      }\n    };\n  }\n}));\n/**\n * Returns a function that checks if an `Iterable` contains a given value using a provided `isEquivalent` function.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const containsWith = isEquivalent => dual(2, (self, a) => {\n  for (const i of self) {\n    if (isEquivalent(a, i)) {\n      return true;\n    }\n  }\n  return false;\n});\nconst _equivalence = /*#__PURE__*/Equal.equivalence();\n/**\n * Returns a function that checks if a `Iterable` contains a given value using the default `Equivalence`.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const contains = /*#__PURE__*/containsWith(_equivalence);\n/**\n * Splits an `Iterable` into length-`n` pieces. The last piece will be shorter if `n` does not evenly divide the length of\n * the `Iterable`.\n *\n * @category splitting\n * @since 2.0.0\n */\nexport const chunksOf = /*#__PURE__*/dual(2, (self, n) => {\n  const safeN = Math.max(1, Math.floor(n));\n  return {\n    [Symbol.iterator]() {\n      let iterator = self[Symbol.iterator]();\n      return {\n        next() {\n          if (iterator === undefined) {\n            return {\n              done: true,\n              value: undefined\n            };\n          }\n          const chunk = [];\n          for (let i = 0; i < safeN; i++) {\n            const result = iterator.next();\n            if (result.done) {\n              iterator = undefined;\n              return chunk.length === 0 ? {\n                done: true,\n                value: undefined\n              } : {\n                done: false,\n                value: chunk\n              };\n            }\n            chunk.push(result.value);\n          }\n          return {\n            done: false,\n            value: chunk\n          };\n        }\n      };\n    }\n  };\n});\n/**\n * Group equal, consecutive elements of an `Iterable` into `NonEmptyArray`s using the provided `isEquivalent` function.\n *\n * @category grouping\n * @since 2.0.0\n */\nexport const groupWith = /*#__PURE__*/dual(2, (self, isEquivalent) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let nextResult;\n    return {\n      next() {\n        let result;\n        if (nextResult !== undefined) {\n          if (nextResult.done) {\n            return {\n              done: true,\n              value: undefined\n            };\n          }\n          result = nextResult;\n          nextResult = undefined;\n        } else {\n          result = iterator.next();\n          if (result.done) {\n            return {\n              done: true,\n              value: undefined\n            };\n          }\n        }\n        const chunk = [result.value];\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n          const next = iterator.next();\n          if (next.done || !isEquivalent(result.value, next.value)) {\n            nextResult = next;\n            return {\n              done: false,\n              value: chunk\n            };\n          }\n          chunk.push(next.value);\n        }\n      }\n    };\n  }\n}));\n/**\n * Group equal, consecutive elements of an `Iterable` into `NonEmptyArray`s.\n *\n * @category grouping\n * @since 2.0.0\n */\nexport const group = /*#__PURE__*/groupWith( /*#__PURE__*/Equal.equivalence());\n/**\n * Splits an `Iterable` into sub-non-empty-arrays stored in an object, based on the result of calling a `string`-returning\n * function on each element, and grouping the results according to values returned\n *\n * @category grouping\n * @since 2.0.0\n */\nexport const groupBy = /*#__PURE__*/dual(2, (self, f) => {\n  const out = {};\n  for (const a of self) {\n    const k = f(a);\n    if (Object.prototype.hasOwnProperty.call(out, k)) {\n      out[k].push(a);\n    } else {\n      out[k] = [a];\n    }\n  }\n  return out;\n});\nconst constEmpty = {\n  [Symbol.iterator]() {\n    return constEmptyIterator;\n  }\n};\nconst constEmptyIterator = {\n  next() {\n    return {\n      done: true,\n      value: undefined\n    };\n  }\n};\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const empty = () => constEmpty;\n/**\n * Constructs a new `Iterable<A>` from the specified value.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const of = a => [a];\n/**\n * @category mapping\n * @since 2.0.0\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let i = 0;\n    return {\n      next() {\n        const result = iterator.next();\n        if (result.done) {\n          return {\n            done: true,\n            value: undefined\n          };\n        }\n        return {\n          done: false,\n          value: f(result.value, i++)\n        };\n      }\n    };\n  }\n}));\n/**\n * Applies a function to each element in an Iterable and returns a new Iterable containing the concatenated mapped elements.\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => flatten(map(self, f)));\n/**\n * Flattens an Iterable of Iterables into a single Iterable\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatten = self => ({\n  [Symbol.iterator]() {\n    const outerIterator = self[Symbol.iterator]();\n    let innerIterator;\n    function next() {\n      if (innerIterator === undefined) {\n        const next = outerIterator.next();\n        if (next.done) {\n          return next;\n        }\n        innerIterator = next.value[Symbol.iterator]();\n      }\n      const result = innerIterator.next();\n      if (result.done) {\n        innerIterator = undefined;\n        return next();\n      }\n      return result;\n    }\n    return {\n      next\n    };\n  }\n});\n/**\n * @category filtering\n * @since 2.0.0\n */\nexport const filterMap = /*#__PURE__*/dual(2, (self, f) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let i = 0;\n    return {\n      next() {\n        let result = iterator.next();\n        while (!result.done) {\n          const b = f(result.value, i++);\n          if (O.isSome(b)) {\n            return {\n              done: false,\n              value: b.value\n            };\n          }\n          result = iterator.next();\n        }\n        return {\n          done: true,\n          value: undefined\n        };\n      }\n    };\n  }\n}));\n/**\n * Transforms all elements of the `Iterable` for as long as the specified function returns some value\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const filterMapWhile = /*#__PURE__*/dual(2, (self, f) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let i = 0;\n    return {\n      next() {\n        const result = iterator.next();\n        if (result.done) {\n          return {\n            done: true,\n            value: undefined\n          };\n        }\n        const b = f(result.value, i++);\n        if (O.isSome(b)) {\n          return {\n            done: false,\n            value: b.value\n          };\n        }\n        return {\n          done: true,\n          value: undefined\n        };\n      }\n    };\n  }\n}));\n/**\n * Retrieves the `Some` values from an `Iterable` of `Option`s.\n *\n * @example\n * import { Iterable, Option } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Array.from(Iterable.getSomes([Option.some(1), Option.none(), Option.some(2)])),\n *   [1, 2]\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getSomes = /*#__PURE__*/filterMap(identity);\n/**\n * Retrieves the `Left` values from an `Iterable` of `Either`s.\n *\n * @example\n * import { Iterable, Either } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Array.from(Iterable.getLefts([Either.right(1), Either.left(\"err\"), Either.right(2)])),\n *   [\"err\"]\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getLefts = self => filterMap(self, E.getLeft);\n/**\n * Retrieves the `Right` values from an `Iterable` of `Either`s.\n *\n * @example\n * import { Iterable, Either } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Array.from(Iterable.getRights([Either.right(1), Either.left(\"err\"), Either.right(2)])),\n *   [1, 2]\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getRights = self => filterMap(self, E.getRight);\n/**\n * @category filtering\n * @since 2.0.0\n */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let i = 0;\n    return {\n      next() {\n        let result = iterator.next();\n        while (!result.done) {\n          if (predicate(result.value, i++)) {\n            return {\n              done: false,\n              value: result.value\n            };\n          }\n          result = iterator.next();\n        }\n        return {\n          done: true,\n          value: undefined\n        };\n      }\n    };\n  }\n}));\n/**\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatMapNullable = /*#__PURE__*/dual(2, (self, f) => filterMap(self, a => {\n  const b = f(a);\n  return b == null ? O.none() : O.some(b);\n}));\n/**\n * Check if a predicate holds true for some `Iterable` element.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const some = /*#__PURE__*/dual(2, (self, predicate) => {\n  let i = 0;\n  for (const a of self) {\n    if (predicate(a, i++)) {\n      return true;\n    }\n  }\n  return false;\n});\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const unfold = (b, f) => ({\n  [Symbol.iterator]() {\n    let next = b;\n    return {\n      next() {\n        const o = f(next);\n        if (O.isNone(o)) {\n          return {\n            done: true,\n            value: undefined\n          };\n        }\n        const [a, b] = o.value;\n        next = b;\n        return {\n          done: false,\n          value: a\n        };\n      }\n    };\n  }\n});\n/**\n * Iterate over the `Iterable` applying `f`.\n *\n * @since 2.0.0\n */\nexport const forEach = /*#__PURE__*/dual(2, (self, f) => {\n  let i = 0;\n  for (const a of self) {\n    f(a, i++);\n  }\n});\n/**\n * @category folding\n * @since 2.0.0\n */\nexport const reduce = /*#__PURE__*/dual(3, (self, b, f) => {\n  if (Array.isArray(self)) {\n    return self.reduce(f, b);\n  }\n  let i = 0;\n  let result = b;\n  for (const n of self) {\n    result = f(result, n, i++);\n  }\n  return result;\n});\n/**\n * Deduplicates adjacent elements that are identical using the provided `isEquivalent` function.\n *\n * @since 2.0.0\n */\nexport const dedupeAdjacentWith = /*#__PURE__*/dual(2, (self, isEquivalent) => ({\n  [Symbol.iterator]() {\n    const iterator = self[Symbol.iterator]();\n    let first = true;\n    let last;\n    function next() {\n      const result = iterator.next();\n      if (result.done) {\n        return {\n          done: true,\n          value: undefined\n        };\n      }\n      if (first) {\n        first = false;\n        last = result.value;\n        return result;\n      }\n      const current = result.value;\n      if (isEquivalent(last, current)) {\n        return next();\n      }\n      last = current;\n      return result;\n    }\n    return {\n      next\n    };\n  }\n}));\n/**\n * Deduplicates adjacent elements that are identical.\n *\n * @since 2.0.0\n */\nexport const dedupeAdjacent = /*#__PURE__*/dedupeAdjacentWith( /*#__PURE__*/Equal.equivalence());\n/**\n * Zips this Iterable crosswise with the specified Iterable using the specified combiner.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const cartesianWith = /*#__PURE__*/dual(3, (self, that, f) => flatMap(self, a => map(that, b => f(a, b))));\n/**\n * Zips this Iterable crosswise with the specified Iterable.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const cartesian = /*#__PURE__*/dual(2, (self, that) => cartesianWith(self, that, (a, b) => [a, b]));\n//# sourceMappingURL=Iterable.js.map","import * as Context from \"./Context.js\";\nimport { clockTag } from \"./internal/clock.js\";\nimport * as core from \"./internal/core.js\";\nimport * as defaultServices from \"./internal/defaultServices.js\";\nimport * as fiberRuntime from \"./internal/fiberRuntime.js\";\nimport * as internal from \"./internal/layer.js\";\nimport * as circularLayer from \"./internal/layer/circular.js\";\nimport * as query from \"./internal/query.js\";\nimport * as Scheduler from \"./Scheduler.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const LayerTypeId = internal.LayerTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const MemoMapTypeId = internal.MemoMapTypeId;\n/**\n * Returns `true` if the specified value is a `Layer`, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isLayer = internal.isLayer;\n/**\n * Returns `true` if the specified `Layer` is a fresh version that will not be\n * shared, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isFresh = internal.isFresh;\n/**\n * @since 3.3.0\n * @category tracing\n */\nexport const annotateLogs = internal.annotateLogs;\n/**\n * @since 3.3.0\n * @category tracing\n */\nexport const annotateSpans = internal.annotateSpans;\n/**\n * Builds a layer into a scoped value.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const build = internal.build;\n/**\n * Builds a layer into an `Effect` value. Any resources associated with this\n * layer will be released when the specified scope is closed unless their scope\n * has been extended. This allows building layers where the lifetime of some of\n * the services output by the layer exceed the lifetime of the effect the\n * layer is provided to.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const buildWithScope = internal.buildWithScope;\n/**\n * Recovers from all errors.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAll = internal.catchAll;\n/**\n * Recovers from all errors.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAllCause = internal.catchAllCause;\n/**\n * Constructs a `Layer` that passes along the specified context as an\n * output.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const context = internal.context;\n/**\n * Constructs a layer that dies with the specified defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const die = internal.die;\n/**\n * Constructs a layer that dies with the specified defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dieSync = internal.dieSync;\n/**\n * Replaces the layer's output with `void` and includes the layer only for its\n * side-effects.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const discard = internal.discard;\n/**\n * Constructs a layer from the specified effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const effect = internal.fromEffect;\n/**\n * Constructs a layer from the specified effect discarding it's output.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const effectDiscard = internal.fromEffectDiscard;\n/**\n * Constructs a layer from the specified effect, which must return one or more\n * services.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const effectContext = internal.fromEffectContext;\n/**\n * A Layer that constructs an empty Context.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * Extends the scope of this layer, returning a new layer that when provided\n * to an effect will not immediately release its associated resources when\n * that effect completes execution but instead when the scope the resulting\n * effect depends on is closed.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const extendScope = internal.extendScope;\n/**\n * Constructs a layer that fails with the specified error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = internal.fail;\n/**\n * Constructs a layer that fails with the specified error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failSync = internal.failSync;\n/**\n * Constructs a layer that fails with the specified cause.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCause = internal.failCause;\n/**\n * Constructs a layer that fails with the specified cause.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCauseSync = internal.failCauseSync;\n/**\n * Constructs a layer dynamically based on the output of this layer.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = internal.flatMap;\n/**\n * Flattens layers nested in the context of an effect.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatten = internal.flatten;\n/**\n * Creates a fresh version of this layer that will not be shared.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const fresh = internal.fresh;\nconst fromFunction = internal.fromFunction;\nexport {\n/**\n * Constructs a layer from the context using the specified function.\n *\n * @since 2.0.0\n * @category constructors\n */\nfromFunction as function };\n/**\n * Builds this layer and uses it until it is interrupted. This is useful when\n * your entire application is a layer, such as an HTTP server.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const launch = internal.launch;\n/**\n * Returns a new layer whose output is mapped by the specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * Returns a layer with its error channel mapped using the specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapError = internal.mapError;\n/**\n * Feeds the error or output services of this layer into the input of either\n * the specified `failure` or `success` layers, resulting in a new layer with\n * the inputs of this layer, and the error or outputs of the specified layer.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const match = internal.match;\n/**\n * Feeds the error or output services of this layer into the input of either\n * the specified `failure` or `success` layers, resulting in a new layer with\n * the inputs of this layer, and the error or outputs of the specified layer.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const matchCause = internal.matchCause;\n/**\n * Returns a scoped effect that, if evaluated, will return the lazily computed\n * result of this layer.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const memoize = internal.memoize;\n/**\n * Merges this layer with the specified layer concurrently, producing a new layer with combined input and output types.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const merge = internal.merge;\n/**\n * Combines all the provided layers concurrently, creating a new layer with merged input, error, and output types.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const mergeAll = internal.mergeAll;\n/**\n * Translates effect failure into death of the fiber, making all failures\n * unchecked and not a part of the type of the layer.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orDie = internal.orDie;\n/**\n * Executes this layer and returns its output, if it succeeds, but otherwise\n * executes the specified layer.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElse = internal.orElse;\n/**\n * Returns a new layer that produces the outputs of this layer but also\n * passes through the inputs.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const passthrough = internal.passthrough;\n/**\n * Projects out part of one of the services output by this layer using the\n * specified function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const project = internal.project;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const locallyEffect = internal.locallyEffect;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const locally = internal.fiberRefLocally;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const locallyWith = internal.fiberRefLocallyWith;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const locallyScoped = internal.fiberRefLocallyScoped;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const fiberRefLocallyScopedWith = internal.fiberRefLocallyScopedWith;\n/**\n * Retries constructing this layer according to the specified schedule.\n *\n * @since 2.0.0\n * @category retrying\n */\nexport const retry = internal.retry;\n/**\n * A layer that constructs a scope and closes it when the workflow the layer\n * is provided to completes execution, whether by success, failure, or\n * interruption. This can be used to close a scope when providing a layer to a\n * workflow.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const scope = internal.scope;\n/**\n * Constructs a layer from the specified scoped effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const scoped = internal.scoped;\n/**\n * Constructs a layer from the specified scoped effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const scopedDiscard = internal.scopedDiscard;\n/**\n * Constructs a layer from the specified scoped effect, which must return one\n * or more services.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const scopedContext = internal.scopedContext;\n/**\n * Constructs a layer that accesses and returns the specified service from the\n * context.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const service = internal.service;\n/**\n * Constructs a layer from the specified value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = internal.succeed;\n/**\n * Constructs a layer from the specified value, which must return one or more\n * services.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeedContext = internal.succeedContext;\n/**\n * Lazily constructs a layer. This is useful to avoid infinite recursion when\n * creating layers that refer to themselves.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const suspend = internal.suspend;\n/**\n * Lazily constructs a layer from the specified value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sync = internal.sync;\n/**\n * Lazily constructs a layer from the specified value, which must return one or more\n * services.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const syncContext = internal.syncContext;\n/**\n * Performs the specified effect if this layer succeeds.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tap = internal.tap;\n/**\n * Performs the specified effect if this layer fails.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapError = internal.tapError;\n/**\n * Performs the specified effect if this layer fails.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapErrorCause = internal.tapErrorCause;\n/**\n * Converts a layer that requires no services into a scoped runtime, which can\n * be used to execute effects.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const toRuntime = internal.toRuntime;\n/**\n * Converts a layer that requires no services into a scoped runtime, which can\n * be used to execute effects.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const toRuntimeWithMemoMap = internal.toRuntimeWithMemoMap;\n/**\n * Feeds the output services of this builder into the input of the specified\n * builder, resulting in a new builder with the inputs of this builder as\n * well as any leftover inputs, and the outputs of the specified builder.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const provide = internal.provide;\n/**\n * Feeds the output services of this layer into the input of the specified\n * layer, resulting in a new layer with the inputs of this layer, and the\n * outputs of both layers.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const provideMerge = internal.provideMerge;\n/**\n * Combines this layer with the specified layer concurrently, creating a new layer with merged input types and\n * combined output types using the provided function.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = internal.zipWith;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const unwrapEffect = internal.unwrapEffect;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const unwrapScoped = internal.unwrapScoped;\n/**\n * @since 2.0.0\n * @category clock\n */\nexport const setClock = clock => scopedDiscard(fiberRuntime.fiberRefLocallyScopedWith(defaultServices.currentServices, Context.add(clockTag, clock)));\n/**\n * Sets the current `ConfigProvider`.\n *\n * @since 2.0.0\n * @category config\n */\nexport const setConfigProvider = circularLayer.setConfigProvider;\n/**\n * Adds the provided span to the span stack.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const parentSpan = circularLayer.parentSpan;\n/**\n * @since 2.0.0\n * @category requests & batching\n */\nexport const setRequestBatching = requestBatching => scopedDiscard(fiberRuntime.fiberRefLocallyScoped(core.currentRequestBatching, requestBatching));\n/**\n * @since 2.0.0\n * @category requests & batching\n */\nexport const setRequestCaching = requestCaching => scopedDiscard(fiberRuntime.fiberRefLocallyScoped(query.currentCacheEnabled, requestCaching));\n/**\n * @since 2.0.0\n * @category requests & batching\n */\nexport const setRequestCache = cache => scopedDiscard(core.isEffect(cache) ? core.flatMap(cache, x => fiberRuntime.fiberRefLocallyScoped(query.currentCache, x)) : fiberRuntime.fiberRefLocallyScoped(query.currentCache, cache));\n/**\n * @since 2.0.0\n * @category scheduler\n */\nexport const setScheduler = scheduler => scopedDiscard(fiberRuntime.fiberRefLocallyScoped(Scheduler.currentScheduler, scheduler));\n/**\n * Create and add a span to the current span stack.\n *\n * The span is ended when the Layer is released.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const span = circularLayer.span;\n/**\n * Create a Layer that sets the current Tracer\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const setTracer = circularLayer.setTracer;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const setTracerEnabled = enabled => scopedDiscard(fiberRuntime.fiberRefLocallyScoped(core.currentTracerEnabled, enabled));\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const setTracerTiming = enabled => scopedDiscard(fiberRuntime.fiberRefLocallyScoped(core.currentTracerTimingEnabled, enabled));\n/**\n * @since 2.0.0\n * @category logging\n */\nexport const setUnhandledErrorLogLevel = level => scopedDiscard(fiberRuntime.fiberRefLocallyScoped(core.currentUnhandledErrorLogLevel, level));\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const withSpan = internal.withSpan;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const withParentSpan = internal.withParentSpan;\n// -----------------------------------------------------------------------------\n// memo map\n// -----------------------------------------------------------------------------\n/**\n * Constructs a `MemoMap` that can be used to build additional layers.\n *\n * @since 2.0.0\n * @category memo map\n */\nexport const makeMemoMap = internal.makeMemoMap;\n/**\n * Builds a layer into an `Effect` value, using the specified `MemoMap` to memoize\n * the layer construction.\n *\n * @since 2.0.0\n * @category memo map\n */\nexport const buildWithMemoMap = internal.buildWithMemoMap;\n//# sourceMappingURL=Layer.js.map","/**\n * A data type for immutable linked lists representing ordered collections of elements of type `A`.\n *\n * This data type is optimal for last-in-first-out (LIFO), stack-like access patterns. If you need another access pattern, for example, random access or FIFO, consider using a collection more suited to this than `List`.\n *\n * **Performance**\n *\n * - Time: `List` has `O(1)` prepend and head/tail access. Most other operations are `O(n)` on the number of elements in the list. This includes the index-based lookup of elements, `length`, `append` and `reverse`.\n * - Space: `List` implements structural sharing of the tail list. This means that many operations are either zero- or constant-memory cost.\n *\n * @since 2.0.0\n */\n/**\n * This file is ported from\n *\n * Scala (https://www.scala-lang.org)\n *\n * Copyright EPFL and Lightbend, Inc.\n *\n * Licensed under Apache License 2.0\n * (http://www.apache.org/licenses/LICENSE-2.0).\n */\nimport * as Arr from \"./Array.js\";\nimport * as Chunk from \"./Chunk.js\";\nimport * as Either from \"./Either.js\";\nimport * as Equal from \"./Equal.js\";\nimport * as Equivalence from \"./Equivalence.js\";\nimport { dual, identity, unsafeCoerce } from \"./Function.js\";\nimport * as Hash from \"./Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"./Inspectable.js\";\nimport * as Option from \"./Option.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nimport { hasProperty } from \"./Predicate.js\";\n/**\n * @since 2.0.0\n * @category symbol\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/List\");\n/**\n * Converts the specified `List` to an `Array`.\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const toArray = self => Arr.fromIterable(self);\n/**\n * @category equivalence\n * @since 2.0.0\n */\nexport const getEquivalence = isEquivalent => Equivalence.mapInput(Arr.getEquivalence(isEquivalent), toArray);\nconst _equivalence = /*#__PURE__*/getEquivalence(Equal.equals);\nconst ConsProto = {\n  [TypeId]: TypeId,\n  _tag: \"Cons\",\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"List\",\n      _tag: \"Cons\",\n      values: toArray(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  [Equal.symbol](that) {\n    return isList(that) && this._tag === that._tag && _equivalence(this, that);\n  },\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.array(toArray(this)));\n  },\n  [Symbol.iterator]() {\n    let done = false;\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    let self = this;\n    return {\n      next() {\n        if (done) {\n          return this.return();\n        }\n        if (self._tag === \"Nil\") {\n          done = true;\n          return this.return();\n        }\n        const value = self.head;\n        self = self.tail;\n        return {\n          done,\n          value\n        };\n      },\n      return(value) {\n        if (!done) {\n          done = true;\n        }\n        return {\n          done: true,\n          value\n        };\n      }\n    };\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst makeCons = (head, tail) => {\n  const cons = Object.create(ConsProto);\n  cons.head = head;\n  cons.tail = tail;\n  return cons;\n};\nconst NilHash = /*#__PURE__*/Hash.string(\"Nil\");\nconst NilProto = {\n  [TypeId]: TypeId,\n  _tag: \"Nil\",\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"List\",\n      _tag: \"Nil\"\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  [Hash.symbol]() {\n    return NilHash;\n  },\n  [Equal.symbol](that) {\n    return isList(that) && this._tag === that._tag;\n  },\n  [Symbol.iterator]() {\n    return {\n      next() {\n        return {\n          done: true,\n          value: undefined\n        };\n      }\n    };\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst _Nil = /*#__PURE__*/Object.create(NilProto);\n/**\n * Returns `true` if the specified value is a `List`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isList = u => hasProperty(u, TypeId);\n/**\n * Returns `true` if the specified value is a `List.Nil<A>`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isNil = self => self._tag === \"Nil\";\n/**\n * Returns `true` if the specified value is a `List.Cons<A>`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isCons = self => self._tag === \"Cons\";\n/**\n * Returns the number of elements contained in the specified `List`\n *\n * @since 2.0.0\n * @category getters\n */\nexport const size = self => {\n  let these = self;\n  let len = 0;\n  while (!isNil(these)) {\n    len += 1;\n    these = these.tail;\n  }\n  return len;\n};\n/**\n * Constructs a new empty `List<A>`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const nil = () => _Nil;\n/**\n * Constructs a new `List.Cons<A>` from the specified `head` and `tail` values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const cons = (head, tail) => makeCons(head, tail);\n/**\n * Constructs a new empty `List<A>`.\n *\n * Alias of {@link nil}.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = nil;\n/**\n * Constructs a new `List<A>` from the specified value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const of = value => makeCons(value, _Nil);\n/**\n * Creates a new `List` from an iterable collection of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = prefix => {\n  const iterator = prefix[Symbol.iterator]();\n  let next;\n  if ((next = iterator.next()) && !next.done) {\n    const result = makeCons(next.value, _Nil);\n    let curr = result;\n    while ((next = iterator.next()) && !next.done) {\n      const temp = makeCons(next.value, _Nil);\n      curr.tail = temp;\n      curr = temp;\n    }\n    return result;\n  } else {\n    return _Nil;\n  }\n};\n/**\n * Constructs a new `List<A>` from the specified values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = (...elements) => fromIterable(elements);\n/**\n * Appends the specified element to the end of the `List`, creating a new `Cons`.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const append = /*#__PURE__*/dual(2, (self, element) => appendAll(self, of(element)));\n/**\n * Concatenates two lists, combining their elements.\n * If either list is non-empty, the result is also a non-empty list.\n *\n * @example\n * import { List } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   List.make(1, 2).pipe(List.appendAll(List.make(\"a\", \"b\")), List.toArray),\n *   [1, 2, \"a\", \"b\"]\n * )\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const appendAll = /*#__PURE__*/dual(2, (self, that) => prependAll(that, self));\n/**\n * Prepends the specified element to the beginning of the list.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prepend = /*#__PURE__*/dual(2, (self, element) => cons(element, self));\n/**\n * Prepends the specified prefix list to the beginning of the specified list.\n * If either list is non-empty, the result is also a non-empty list.\n *\n * @example\n * import { List } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   List.make(1, 2).pipe(List.prependAll(List.make(\"a\", \"b\")), List.toArray),\n *   [\"a\", \"b\", 1, 2]\n * )\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prependAll = /*#__PURE__*/dual(2, (self, prefix) => {\n  if (isNil(self)) {\n    return prefix;\n  } else if (isNil(prefix)) {\n    return self;\n  } else {\n    const result = makeCons(prefix.head, self);\n    let curr = result;\n    let that = prefix.tail;\n    while (!isNil(that)) {\n      const temp = makeCons(that.head, self);\n      curr.tail = temp;\n      curr = temp;\n      that = that.tail;\n    }\n    return result;\n  }\n});\n/**\n * Prepends the specified prefix list (in reverse order) to the beginning of the\n * specified list.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prependAllReversed = /*#__PURE__*/dual(2, (self, prefix) => {\n  let out = self;\n  let pres = prefix;\n  while (isCons(pres)) {\n    out = makeCons(pres.head, out);\n    pres = pres.tail;\n  }\n  return out;\n});\n/**\n * Drops the first `n` elements from the specified list.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const drop = /*#__PURE__*/dual(2, (self, n) => {\n  if (n <= 0) {\n    return self;\n  }\n  if (n >= size(self)) {\n    return _Nil;\n  }\n  let these = self;\n  let i = 0;\n  while (!isNil(these) && i < n) {\n    these = these.tail;\n    i += 1;\n  }\n  return these;\n});\n/**\n * Check if a predicate holds true for every `List` element.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const every = /*#__PURE__*/dual(2, (self, refinement) => {\n  for (const a of self) {\n    if (!refinement(a)) {\n      return false;\n    }\n  }\n  return true;\n});\n/**\n * Check if a predicate holds true for some `List` element.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const some = /*#__PURE__*/dual(2, (self, predicate) => {\n  let these = self;\n  while (!isNil(these)) {\n    if (predicate(these.head)) {\n      return true;\n    }\n    these = these.tail;\n  }\n  return false;\n});\n/**\n * Filters a list using the specified predicate.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => noneIn(self, predicate, false));\n// everything seen so far is not included\nconst noneIn = (self, predicate, isFlipped) => {\n  /* eslint-disable no-constant-condition */\n  while (true) {\n    if (isNil(self)) {\n      return _Nil;\n    } else {\n      if (predicate(self.head) !== isFlipped) {\n        return allIn(self, self.tail, predicate, isFlipped);\n      } else {\n        self = self.tail;\n      }\n    }\n  }\n};\n// everything from 'start' is included, if everything from this point is in we can return the origin\n// start otherwise if we discover an element that is out we must create a new partial list.\nconst allIn = (start, remaining, predicate, isFlipped) => {\n  /* eslint-disable no-constant-condition */\n  while (true) {\n    if (isNil(remaining)) {\n      return start;\n    } else {\n      if (predicate(remaining.head) !== isFlipped) {\n        remaining = remaining.tail;\n      } else {\n        return partialFill(start, remaining, predicate, isFlipped);\n      }\n    }\n  }\n};\n// we have seen elements that should be included then one that should be excluded, start building\nconst partialFill = (origStart, firstMiss, predicate, isFlipped) => {\n  const newHead = makeCons(unsafeHead(origStart), _Nil);\n  let toProcess = unsafeTail(origStart);\n  let currentLast = newHead;\n  // we know that all elements are :: until at least firstMiss.tail\n  while (!(toProcess === firstMiss)) {\n    const newElem = makeCons(unsafeHead(toProcess), _Nil);\n    currentLast.tail = newElem;\n    currentLast = unsafeCoerce(newElem);\n    toProcess = unsafeCoerce(toProcess.tail);\n  }\n  // at this point newHead points to a list which is a duplicate of all the 'in' elements up to the first miss.\n  // currentLast is the last element in that list.\n  // now we are going to try and share as much of the tail as we can, only moving elements across when we have to.\n  let next = firstMiss.tail;\n  let nextToCopy = unsafeCoerce(next); // the next element we would need to copy to our list if we cant share.\n  while (!isNil(next)) {\n    // generally recommended is next.isNonEmpty but this incurs an extra method call.\n    const head = unsafeHead(next);\n    if (predicate(head) !== isFlipped) {\n      next = next.tail;\n    } else {\n      // its not a match - do we have outstanding elements?\n      while (!(nextToCopy === next)) {\n        const newElem = makeCons(unsafeHead(nextToCopy), _Nil);\n        currentLast.tail = newElem;\n        currentLast = newElem;\n        nextToCopy = unsafeCoerce(nextToCopy.tail);\n      }\n      nextToCopy = unsafeCoerce(next.tail);\n      next = next.tail;\n    }\n  }\n  // we have remaining elements - they are unchanged attach them to the end\n  if (!isNil(nextToCopy)) {\n    currentLast.tail = nextToCopy;\n  }\n  return newHead;\n};\n/**\n * Filters and maps a list using the specified partial function. The resulting\n * list may be smaller than the input list due to the possibility of the partial\n * function not being defined for some elements.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const filterMap = /*#__PURE__*/dual(2, (self, f) => {\n  const bs = [];\n  for (const a of self) {\n    const oa = f(a);\n    if (Option.isSome(oa)) {\n      bs.push(oa.value);\n    }\n  }\n  return fromIterable(bs);\n});\n/**\n * Removes all `None` values from the specified list.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const compact = self => filterMap(self, identity);\n/**\n * Returns the first element that satisfies the specified\n * predicate, or `None` if no such element exists.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findFirst = /*#__PURE__*/dual(2, (self, predicate) => {\n  let these = self;\n  while (!isNil(these)) {\n    if (predicate(these.head)) {\n      return Option.some(these.head);\n    }\n    these = these.tail;\n  }\n  return Option.none();\n});\n/**\n * Applies a function to each element in a list and returns a new list containing the concatenated mapped elements.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => {\n  let rest = self;\n  let head = undefined;\n  let tail = undefined;\n  while (!isNil(rest)) {\n    let bs = f(rest.head);\n    while (!isNil(bs)) {\n      const next = makeCons(bs.head, _Nil);\n      if (tail === undefined) {\n        head = next;\n      } else {\n        tail.tail = next;\n      }\n      tail = next;\n      bs = bs.tail;\n    }\n    rest = rest.tail;\n  }\n  if (head === undefined) {\n    return _Nil;\n  }\n  return head;\n});\n/**\n * Applies the specified function to each element of the `List`.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const forEach = /*#__PURE__*/dual(2, (self, f) => {\n  let these = self;\n  while (!isNil(these)) {\n    f(these.head);\n    these = these.tail;\n  }\n});\n/**\n * Returns the first element of the specified list, or `None` if the list is\n * empty.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const head = self => isNil(self) ? Option.none() : Option.some(self.head);\n/**\n * Returns the last element of the specified list, or `None` if the list is\n * empty.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const last = self => isNil(self) ? Option.none() : Option.some(unsafeLast(self));\n/**\n * Applies the specified mapping function to each element of the list.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => {\n  if (isNil(self)) {\n    return self;\n  } else {\n    let i = 0;\n    const head = makeCons(f(self.head, i++), _Nil);\n    let nextHead = head;\n    let rest = self.tail;\n    while (!isNil(rest)) {\n      const next = makeCons(f(rest.head, i++), _Nil);\n      nextHead.tail = next;\n      nextHead = next;\n      rest = rest.tail;\n    }\n    return head;\n  }\n});\n/**\n * Partition a list into two lists, where the first list contains all elements\n * that did not satisfy the specified predicate, and the second list contains\n * all elements that did satisfy the specified predicate.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const partition = /*#__PURE__*/dual(2, (self, predicate) => {\n  const left = [];\n  const right = [];\n  for (const a of self) {\n    if (predicate(a)) {\n      right.push(a);\n    } else {\n      left.push(a);\n    }\n  }\n  return [fromIterable(left), fromIterable(right)];\n});\n/**\n * Partition a list into two lists, where the first list contains all elements\n * for which the specified function returned a `Left`, and the second list\n * contains all elements for which the specified function returned a `Right`.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const partitionMap = /*#__PURE__*/dual(2, (self, f) => {\n  const left = [];\n  const right = [];\n  for (const a of self) {\n    const e = f(a);\n    if (Either.isLeft(e)) {\n      left.push(e.left);\n    } else {\n      right.push(e.right);\n    }\n  }\n  return [fromIterable(left), fromIterable(right)];\n});\n/**\n * Folds over the elements of the list using the specified function, using the\n * specified initial value.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduce = /*#__PURE__*/dual(3, (self, zero, f) => {\n  let acc = zero;\n  let these = self;\n  while (!isNil(these)) {\n    acc = f(acc, these.head);\n    these = these.tail;\n  }\n  return acc;\n});\n/**\n * Folds over the elements of the list using the specified function, beginning\n * with the last element of the list, using the specified initial value.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduceRight = /*#__PURE__*/dual(3, (self, zero, f) => {\n  let acc = zero;\n  let these = reverse(self);\n  while (!isNil(these)) {\n    acc = f(acc, these.head);\n    these = these.tail;\n  }\n  return acc;\n});\n/**\n * Returns a new list with the elements of the specified list in reverse order.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const reverse = self => {\n  let result = empty();\n  let these = self;\n  while (!isNil(these)) {\n    result = prepend(result, these.head);\n    these = these.tail;\n  }\n  return result;\n};\n/**\n * Splits the specified list into two lists at the specified index.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const splitAt = /*#__PURE__*/dual(2, (self, n) => [take(self, n), drop(self, n)]);\n/**\n * Returns the tail of the specified list, or `None` if the list is empty.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const tail = self => isNil(self) ? Option.none() : Option.some(self.tail);\n/**\n * Takes the specified number of elements from the beginning of the specified\n * list.\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const take = /*#__PURE__*/dual(2, (self, n) => {\n  if (n <= 0) {\n    return _Nil;\n  }\n  if (n >= size(self)) {\n    return self;\n  }\n  let these = make(unsafeHead(self));\n  let current = unsafeTail(self);\n  for (let i = 1; i < n; i++) {\n    these = makeCons(unsafeHead(current), these);\n    current = unsafeTail(current);\n  }\n  return reverse(these);\n});\n/**\n * Converts the specified `List` to a `Chunk`.\n *\n * @since 2.0.0\n * @category conversions\n */\nexport const toChunk = self => Chunk.fromIterable(self);\nconst getExpectedListToBeNonEmptyErrorMessage = \"Expected List to be non-empty\";\n/**\n * Unsafely returns the first element of the specified `List`.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeHead = self => {\n  if (isNil(self)) {\n    throw new Error(getExpectedListToBeNonEmptyErrorMessage);\n  }\n  return self.head;\n};\n/**\n * Unsafely returns the last element of the specified `List`.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeLast = self => {\n  if (isNil(self)) {\n    throw new Error(getExpectedListToBeNonEmptyErrorMessage);\n  }\n  let these = self;\n  let scout = self.tail;\n  while (!isNil(scout)) {\n    these = scout;\n    scout = scout.tail;\n  }\n  return these.head;\n};\n/**\n * Unsafely returns the tail of the specified `List`.\n *\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeTail = self => {\n  if (isNil(self)) {\n    throw new Error(getExpectedListToBeNonEmptyErrorMessage);\n  }\n  return self.tail;\n};\n//# sourceMappingURL=List.js.map","import { dual, pipe } from \"./Function.js\";\nimport * as core from \"./internal/core.js\";\nimport * as number from \"./Number.js\";\nimport * as order from \"./Order.js\";\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const All = core.logLevelAll;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Fatal = core.logLevelFatal;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Error = core.logLevelError;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Warning = core.logLevelWarning;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Info = core.logLevelInfo;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Debug = core.logLevelDebug;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Trace = core.logLevelTrace;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const None = core.logLevelNone;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const allLevels = core.allLogLevels;\n/**\n * Locally applies the specified `LogLevel` to an `Effect` workflow, reverting\n * to the previous `LogLevel` after the `Effect` workflow completes.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const locally = /*#__PURE__*/dual(2, (use, self) => core.fiberRefLocally(use, core.currentLogLevel, self));\n/**\n * @since 2.0.0\n * @category instances\n */\nexport const Order = /*#__PURE__*/pipe(number.Order, /*#__PURE__*/order.mapInput(level => level.ordinal));\n/**\n * @since 2.0.0\n * @category ordering\n */\nexport const lessThan = /*#__PURE__*/order.lessThan(Order);\n/**\n * @since 2.0.0\n * @category ordering\n */\nexport const lessThanEqual = /*#__PURE__*/order.lessThanOrEqualTo(Order);\n/**\n * @since 2.0.0\n * @category ordering\n */\nexport const greaterThan = /*#__PURE__*/order.greaterThan(Order);\n/**\n * @since 2.0.0\n * @category ordering\n */\nexport const greaterThanEqual = /*#__PURE__*/order.greaterThanOrEqualTo(Order);\n/**\n * @since 2.0.0\n * @category conversions\n */\nexport const fromLiteral = literal => {\n  switch (literal) {\n    case \"All\":\n      return All;\n    case \"Debug\":\n      return Debug;\n    case \"Error\":\n      return Error;\n    case \"Fatal\":\n      return Fatal;\n    case \"Info\":\n      return Info;\n    case \"Trace\":\n      return Trace;\n    case \"None\":\n      return None;\n    case \"Warning\":\n      return Warning;\n  }\n};\n//# sourceMappingURL=LogLevel.js.map","/**\n * @since 2.0.0\n */\nimport * as internal from \"./internal/logSpan.js\";\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * @since 2.0.0\n * @category destructors\n */\nexport const render = internal.render;\n//# sourceMappingURL=LogSpan.js.map","import * as fiberRuntime from \"./internal/fiberRuntime.js\";\nimport * as circular from \"./internal/layer/circular.js\";\nimport * as internalCircular from \"./internal/logger-circular.js\";\nimport * as internal from \"./internal/logger.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const LoggerTypeId = internal.LoggerTypeId;\n/**\n * Creates a custom logger that formats log messages according to the provided\n * function.\n *\n * @example\n * import { Effect, Logger, LogLevel } from \"effect\"\n *\n * const logger = Logger.make(({ logLevel, message }) => {\n *   globalThis.console.log(`[${logLevel.label}] ${message}`)\n * })\n *\n * const task1 = Effect.logDebug(\"task1 done\")\n * const task2 = Effect.logDebug(\"task2 done\")\n *\n * const program = Effect.gen(function*() {\n *   yield* Effect.log(\"start\")\n *   yield* task1\n *   yield* task2\n *   yield* Effect.log(\"done\")\n * }).pipe(\n *   Logger.withMinimumLogLevel(LogLevel.Debug),\n *   Effect.provide(Logger.replace(Logger.defaultLogger, logger))\n * )\n *\n * // Effect.runFork(program)\n * // [INFO] start\n * // [DEBUG] task1 done\n * // [DEBUG] task2 done\n * // [INFO] done\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const make = internal.makeLogger;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const add = circular.addLogger;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const addEffect = circular.addLoggerEffect;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const addScoped = circular.addLoggerScoped;\n/**\n * @since 2.0.0\n * @category mapping\n */\nexport const mapInput = internal.mapInput;\n/**\n * @since 2.0.0\n * @category mapping\n */\nexport const mapInputOptions = internal.mapInputOptions;\n/**\n * Returns a version of this logger that only logs messages when the log level\n * satisfies the specified predicate.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filterLogLevel = internal.filterLogLevel;\n/**\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * Creates a batched logger that groups log messages together and processes them\n * in intervals.\n *\n * @param window - The time window in which to batch log messages.\n *\n * @example\n * import { Console, Effect, Logger } from \"effect\"\n *\n * const LoggerLive = Logger.replaceScoped(\n *   Logger.defaultLogger,\n *   Logger.logfmtLogger.pipe(\n *     Logger.batched(\"500 millis\", (messages) => Console.log(\"BATCH\", `[\\n${messages.join(\"\\n\")}\\n]`))\n *   )\n * )\n *\n * const program = Effect.gen(function*() {\n *   yield* Effect.log(\"one\")\n *   yield* Effect.log(\"two\")\n *   yield* Effect.log(\"three\")\n * }).pipe(Effect.provide(LoggerLive))\n *\n * // Effect.runFork(program)\n * // BATCH [\n * // timestamp=... level=INFO fiber=#0 message=one\n * // timestamp=... level=INFO fiber=#0 message=two\n * // timestamp=... level=INFO fiber=#0 message=three\n * // ]\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const batched = fiberRuntime.batchedLogger;\n/**\n * @since 2.0.0\n * @category console\n */\nexport const withConsoleLog = fiberRuntime.loggerWithConsoleLog;\n/**\n * @since 2.0.0\n * @category console\n */\nexport const withConsoleError = fiberRuntime.loggerWithConsoleError;\n/**\n * A logger that does nothing in response to logging events.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const none = internal.none;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const remove = circular.removeLogger;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const replace = circular.replaceLogger;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const replaceEffect = circular.replaceLoggerEffect;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const replaceScoped = circular.replaceLoggerScoped;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const simple = internal.simple;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = internal.succeed;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const sync = internal.sync;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const test = internalCircular.test;\n/**\n * Sets the minimum log level for subsequent logging operations, allowing\n * control over which log messages are displayed based on their severity.\n *\n * @example\n * import { Effect, Logger, LogLevel } from \"effect\"\n *\n * const program = Effect.logDebug(\"message1\").pipe(Logger.withMinimumLogLevel(LogLevel.Debug))\n *\n * // Effect.runFork(program)\n * // timestamp=... level=DEBUG fiber=#0 message=message1\n *\n * @since 2.0.0\n * @category context\n */\nexport const withMinimumLogLevel = circular.withMinimumLogLevel;\n/**\n * @since 2.0.0\n * @category tracing\n */\nexport const withSpanAnnotations = fiberRuntime.loggerWithSpanAnnotations;\n/**\n * Combines this logger with the specified logger to produce a new logger that\n * logs to both this logger and that logger.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = internal.zip;\n/**\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = internal.zipLeft;\n/**\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = internal.zipRight;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const defaultLogger = fiberRuntime.defaultLogger;\n/**\n * The `jsonLogger` logger formats log entries as JSON objects, making them easy to\n * integrate with logging systems that consume JSON data.\n *\n * @example\n * import { Effect, Logger } from \"effect\"\n *\n * const program = Effect.log(\"message1\", \"message2\").pipe(\n *   Effect.annotateLogs({ key1: \"value1\", key2: \"value2\" }),\n *   Effect.withLogSpan(\"myspan\")\n * )\n *\n * // Effect.runFork(program.pipe(Effect.provide(Logger.json)))\n * // {\"message\":[\"message1\",\"message2\"],\"logLevel\":\"INFO\",\"timestamp\":\"...\",\"annotations\":{\"key2\":\"value2\",\"key1\":\"value1\"},\"spans\":{\"myspan\":0},\"fiberId\":\"#0\"}\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const jsonLogger = internal.jsonLogger;\n/**\n * This logger outputs logs in a human-readable format that is easy to read\n * during development or in a production console.\n *\n * @example\n * import { Effect, Logger } from \"effect\"\n *\n * const program = Effect.log(\"message1\", \"message2\").pipe(\n *   Effect.annotateLogs({ key1: \"value1\", key2: \"value2\" }),\n *   Effect.withLogSpan(\"myspan\")\n * )\n *\n * // Effect.runFork(program.pipe(Effect.provide(Logger.logFmt)))\n * // timestamp=... level=INFO fiber=#0 message=message1 message=message2 myspan=0ms key2=value2 key1=value1\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const logfmtLogger = internal.logfmtLogger;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const stringLogger = internal.stringLogger;\n/**\n * The pretty logger utilizes the capabilities of the console API to generate\n * visually engaging and color-enhanced log outputs. This feature is\n * particularly useful for improving the readability of log messages during\n * development and debugging processes.\n *\n * @example\n * import { Effect, Logger } from \"effect\"\n *\n * const program = Effect.log(\"message1\", \"message2\").pipe(\n *   Effect.annotateLogs({ key1: \"value1\", key2: \"value2\" }),\n *   Effect.withLogSpan(\"myspan\")\n * )\n *\n * // Effect.runFork(program.pipe(Effect.provide(Logger.pretty)))\n * //         green --v                      v-- bold and cyan\n * // [07:51:54.434] INFO (#0) myspan=1ms: message1\n * //   message2\n * //    v-- bold\n * //   key2: value2\n * //   key1: value1\n *\n * @since 3.5.0\n * @category constructors\n */\nexport const prettyLogger = internal.prettyLogger;\n/**\n * The structured logger provides detailed log outputs, structured in a way that\n * retains comprehensive traceability of the events, suitable for deeper\n * analysis and troubleshooting.\n *\n * @example\n * import { Effect, Logger } from \"effect\"\n *\n * const program = Effect.log(\"message1\", \"message2\").pipe(\n *   Effect.annotateLogs({ key1: \"value1\", key2: \"value2\" }),\n *   Effect.withLogSpan(\"myspan\")\n * )\n *\n * // Effect.runFork(program.pipe(Effect.provide(Logger.structured)))\n * // {\n * //   message: [ 'message1', 'message2' ],\n * //   logLevel: 'INFO',\n * //   timestamp: '2024-07-09T14:05:41.623Z',\n * //   cause: undefined,\n * //   annotations: { key2: 'value2', key1: 'value1' },\n * //   spans: { myspan: 0 },\n * //   fiberId: '#0'\n * // }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const structuredLogger = internal.structuredLogger;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const tracerLogger = fiberRuntime.tracerLogger;\n/**\n * The `json` logger formats log entries as JSON objects, making them easy to\n * integrate with logging systems that consume JSON data.\n *\n * @example\n * import { Effect, Logger } from \"effect\"\n *\n * const program = Effect.log(\"message1\", \"message2\").pipe(\n *   Effect.annotateLogs({ key1: \"value1\", key2: \"value2\" }),\n *   Effect.withLogSpan(\"myspan\")\n * )\n *\n * // Effect.runFork(program.pipe(Effect.provide(Logger.json)))\n * // {\"message\":[\"message1\",\"message2\"],\"logLevel\":\"INFO\",\"timestamp\":\"...\",\"annotations\":{\"key2\":\"value2\",\"key1\":\"value1\"},\"spans\":{\"myspan\":0},\"fiberId\":\"#0\"}\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const json = /*#__PURE__*/replace(fiberRuntime.defaultLogger, fiberRuntime.jsonLogger);\n/**\n * This logger outputs logs in a human-readable format that is easy to read\n * during development or in a production console.\n *\n * @example\n * import { Effect, Logger } from \"effect\"\n *\n * const program = Effect.log(\"message1\", \"message2\").pipe(\n *   Effect.annotateLogs({ key1: \"value1\", key2: \"value2\" }),\n *   Effect.withLogSpan(\"myspan\")\n * )\n *\n * // Effect.runFork(program.pipe(Effect.provide(Logger.logFmt)))\n * // timestamp=... level=INFO fiber=#0 message=message1 message=message2 myspan=0ms key2=value2 key1=value1\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const logFmt = /*#__PURE__*/replace(fiberRuntime.defaultLogger, fiberRuntime.logFmtLogger);\n/**\n * The pretty logger utilizes the capabilities of the console API to generate\n * visually engaging and color-enhanced log outputs. This feature is\n * particularly useful for improving the readability of log messages during\n * development and debugging processes.\n *\n * @example\n * import { Effect, Logger } from \"effect\"\n *\n * const program = Effect.log(\"message1\", \"message2\").pipe(\n *   Effect.annotateLogs({ key1: \"value1\", key2: \"value2\" }),\n *   Effect.withLogSpan(\"myspan\")\n * )\n *\n * // Effect.runFork(program.pipe(Effect.provide(Logger.pretty)))\n * //         green --v                      v-- bold and cyan\n * // [07:51:54.434] INFO (#0) myspan=1ms: message1\n * //   message2\n * //    v-- bold\n * //   key2: value2\n * //   key1: value1\n *\n * @since 3.5.0\n * @category constructors\n */\nexport const pretty = /*#__PURE__*/replace(fiberRuntime.defaultLogger, fiberRuntime.prettyLogger);\n/**\n * The structured logger provides detailed log outputs, structured in a way that\n * retains comprehensive traceability of the events, suitable for deeper\n * analysis and troubleshooting.\n *\n * @example\n * import { Effect, Logger } from \"effect\"\n *\n * const program = Effect.log(\"message1\", \"message2\").pipe(\n *   Effect.annotateLogs({ key1: \"value1\", key2: \"value2\" }),\n *   Effect.withLogSpan(\"myspan\")\n * )\n *\n * // Effect.runFork(program.pipe(Effect.provide(Logger.structured)))\n * // {\n * //   message: [ 'message1', 'message2' ],\n * //   logLevel: 'INFO',\n * //   timestamp: '2024-07-09T14:05:41.623Z',\n * //   cause: undefined,\n * //   annotations: { key2: 'value2', key1: 'value1' },\n * //   spans: { myspan: 0 },\n * //   fiberId: '#0'\n * // }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const structured = /*#__PURE__*/replace(fiberRuntime.defaultLogger, fiberRuntime.structuredLogger);\n/**\n * Sets the minimum log level for logging operations, allowing control over\n * which log messages are displayed based on their severity.\n *\n * @example\n * import { Effect, Logger, LogLevel } from \"effect\"\n *\n * const program = Effect.gen(function*() {\n *   yield* Effect.log(\"Executing task...\")\n *   yield* Effect.sleep(\"100 millis\")\n *   console.log(\"task done\")\n * })\n *\n * // Logging disabled using a layer\n * // Effect.runFork(program.pipe(Effect.provide(Logger.minimumLogLevel(LogLevel.None))))\n * // task done\n *\n * @since 2.0.0\n * @category context\n */\nexport const minimumLogLevel = circular.minimumLogLevel;\n/**\n * Returns `true` if the specified value is a `Logger`, otherwise returns `false`.\n *\n * @since 1.0.0\n * @category guards\n */\nexport const isLogger = internal.isLogger;\n//# sourceMappingURL=Logger.js.map","import * as internal from \"./internal/managedRuntime.js\";\n/**\n * Convert a Layer into an ManagedRuntime, that can be used to run Effect's using\n * your services.\n *\n * @since 2.0.0\n * @category runtime class\n * @example\n * import { Console, Effect, Layer, ManagedRuntime } from \"effect\"\n *\n * class Notifications extends Effect.Tag(\"Notifications\")<\n *   Notifications,\n *   { readonly notify: (message: string) => Effect.Effect<void> }\n * >() {\n *   static Live = Layer.succeed(this, { notify: (message) => Console.log(message) })\n * }\n *\n * async function main() {\n *   const runtime = ManagedRuntime.make(Notifications.Live)\n *   await runtime.runPromise(Notifications.notify(\"Hello, world!\"))\n *   await runtime.dispose()\n * }\n *\n * main()\n */\nexport const make = internal.make;\n//# sourceMappingURL=ManagedRuntime.js.map","import * as internal from \"./internal/matcher.js\";\nimport * as Predicate from \"./Predicate.js\";\n/**\n * @category type ids\n * @since 1.0.0\n */\nexport const MatcherTypeId = internal.TypeId;\n/**\n * @category constructors\n * @since 1.0.0\n */\nexport const type = internal.type;\n/**\n * @category constructors\n * @since 1.0.0\n */\nexport const value = internal.value;\n/**\n * @category constructors\n * @since 1.0.0\n */\nexport const valueTags = internal.valueTags;\n/**\n * @category constructors\n * @since 1.0.0\n */\nexport const typeTags = internal.typeTags;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const withReturnType = internal.withReturnType;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const when = internal.when;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const whenOr = internal.whenOr;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const whenAnd = internal.whenAnd;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const discriminator = internal.discriminator;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const discriminatorStartsWith = internal.discriminatorStartsWith;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const discriminators = internal.discriminators;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const discriminatorsExhaustive = internal.discriminatorsExhaustive;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const tag = internal.tag;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const tagStartsWith = internal.tagStartsWith;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const tags = internal.tags;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const tagsExhaustive = internal.tagsExhaustive;\n/**\n * @category combinators\n * @since 1.0.0\n */\nexport const not = internal.not;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const nonEmptyString = internal.nonEmptyString;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const is = internal.is;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const string = Predicate.isString;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const number = Predicate.isNumber;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const any = internal.any;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const defined = internal.defined;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const boolean = Predicate.isBoolean;\nconst _undefined = Predicate.isUndefined;\nexport {\n/**\n * @category predicates\n * @since 1.0.0\n */\n_undefined as undefined };\nconst _null = Predicate.isNull;\nexport {\n/**\n * @category predicates\n * @since 1.0.0\n */\n_null as null };\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const bigint = Predicate.isBigInt;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const symbol = Predicate.isSymbol;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const date = Predicate.isDate;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const record = Predicate.isRecord;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const instanceOf = internal.instanceOf;\n/**\n * @category predicates\n * @since 1.0.0\n */\nexport const instanceOfUnsafe = internal.instanceOf;\n/**\n * @category conversions\n * @since 1.0.0\n */\nexport const orElse = internal.orElse;\n/**\n * @category conversions\n * @since 1.0.0\n */\nexport const orElseAbsurd = internal.orElseAbsurd;\n/**\n * @category conversions\n * @since 1.0.0\n */\nexport const either = internal.either;\n/**\n * @category conversions\n * @since 1.0.0\n */\nexport const option = internal.option;\n/**\n * @category conversions\n * @since 1.0.0\n */\nexport const exhaustive = internal.exhaustive;\n/**\n * @since 1.0.0\n * @category type ids\n */\nexport const SafeRefinementId = /*#__PURE__*/Symbol.for(\"effect/SafeRefinement\");\nconst Fail = /*#__PURE__*/Symbol.for(\"effect/Fail\");\n//# sourceMappingURL=Match.js.map","import * as internal from \"./internal/channel/mergeDecision.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const MergeDecisionTypeId = internal.MergeDecisionTypeId;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Done = internal.Done;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Await = internal.Await;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const AwaitConst = internal.AwaitConst;\n/**\n * Returns `true` if the specified value is a `MergeDecision`, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isMergeDecision = internal.isMergeDecision;\n/**\n * @since 2.0.0\n * @category folding\n */\nexport const match = internal.match;\n//# sourceMappingURL=MergeDecision.js.map","import * as Context from \"./Context.js\";\nimport * as Effectable from \"./Effectable.js\";\nimport * as Either from \"./Either.js\";\nimport { constTrue, constVoid, dual, identity } from \"./Function.js\";\nimport { globalValue } from \"./GlobalValue.js\";\nimport { NodeInspectSymbol, toStringUnknown } from \"./Inspectable.js\";\nimport * as doNotation from \"./internal/doNotation.js\";\nimport { StructuralPrototype } from \"./internal/effectable.js\";\nimport { SingleShotGen } from \"./internal/singleShotGen.js\";\nimport * as Option from \"./Option.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nimport { isIterable, isTagged } from \"./Predicate.js\";\nimport { YieldWrap, yieldWrapGet } from \"./Utils.js\";\n/**\n * @since 3.4.0\n * @experimental\n * @category type ids\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/Micro\");\n/**\n * @since 3.4.0\n * @experimental\n * @category symbols\n */\nexport const runSymbol = /*#__PURE__*/Symbol.for(\"effect/Micro/runSymbol\");\n/**\n * @since 3.4.0\n * @experimental\n * @category guards\n */\nexport const isMicro = u => typeof u === \"object\" && u !== null && TypeId in u;\n// ----------------------------------------------------------------------------\n// MicroCause\n// ----------------------------------------------------------------------------\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const MicroCauseTypeId = /*#__PURE__*/Symbol.for(\"effect/Micro/MicroCause\");\nconst microCauseVariance = {\n  _E: identity\n};\nclass MicroCauseImpl extends globalThis.Error {\n  _tag;\n  traces;\n  [MicroCauseTypeId];\n  constructor(_tag, originalError, traces) {\n    const causeName = `MicroCause.${_tag}`;\n    let name;\n    let message;\n    let stack;\n    if (originalError instanceof globalThis.Error) {\n      name = `(${causeName}) ${originalError.name}`;\n      message = originalError.message;\n      const messageLines = message.split(\"\\n\").length;\n      stack = originalError.stack ? `(${causeName}) ${originalError.stack.split(\"\\n\").slice(0, messageLines + 3).join(\"\\n\")}` : `${name}: ${message}`;\n    } else {\n      name = causeName;\n      message = toStringUnknown(originalError, 0);\n      stack = `${name}: ${message}`;\n    }\n    if (traces.length > 0) {\n      stack += `\\n    ${traces.join(\"\\n    \")}`;\n    }\n    super(message);\n    this._tag = _tag;\n    this.traces = traces;\n    this[MicroCauseTypeId] = microCauseVariance;\n    this.name = name;\n    this.stack = stack;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  toString() {\n    return this.stack;\n  }\n  [NodeInspectSymbol]() {\n    return this.stack;\n  }\n}\nclass FailImpl extends MicroCauseImpl {\n  error;\n  constructor(error, traces = []) {\n    super(\"Fail\", error, traces);\n    this.error = error;\n  }\n}\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const causeFail = (error, traces = []) => new FailImpl(error, traces);\nclass DieImpl extends MicroCauseImpl {\n  defect;\n  constructor(defect, traces = []) {\n    super(\"Die\", defect, traces);\n    this.defect = defect;\n  }\n}\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const causeDie = (defect, traces = []) => new DieImpl(defect, traces);\nclass InterruptImpl extends MicroCauseImpl {\n  constructor(traces = []) {\n    super(\"Interrupt\", \"interrupted\", traces);\n  }\n}\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const causeInterrupt = (traces = []) => new InterruptImpl(traces);\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const causeIsFail = self => self._tag === \"Fail\";\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const causeIsDie = self => self._tag === \"Die\";\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const causeIsInterrupt = self => self._tag === \"Interrupt\";\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const causeSquash = self => self._tag === \"Fail\" ? self.error : self._tag === \"Die\" ? self.defect : self;\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroCause\n */\nexport const causeWithTrace = /*#__PURE__*/dual(2, (self, trace) => {\n  const traces = [...self.traces, trace];\n  switch (self._tag) {\n    case \"Die\":\n      return causeDie(self.defect, traces);\n    case \"Interrupt\":\n      return causeInterrupt(traces);\n    case \"Fail\":\n      return causeFail(self.error, traces);\n  }\n});\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitInterrupt = /*#__PURE__*/Either.left( /*#__PURE__*/causeInterrupt());\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitSucceed = Either.right;\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitFail = e => Either.left(causeFail(e));\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitDie = defect => Either.left(causeDie(defect));\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitFailCause = Either.left;\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitIsSuccess = Either.isRight;\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitIsFailure = Either.isLeft;\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitIsInterrupt = self => exitIsFailure(self) && self.left._tag === \"Interrupt\";\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitIsFail = self => exitIsFailure(self) && self.left._tag === \"Fail\";\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitIsDie = self => exitIsFailure(self) && self.left._tag === \"Die\";\n/**\n * @since 3.4.6\n * @experimental\n * @category MicroExit\n */\nexport const exitVoid = /*#__PURE__*/exitSucceed(void 0);\n// ----------------------------------------------------------------------------\n// env\n// ----------------------------------------------------------------------------\n/**\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const EnvTypeId = /*#__PURE__*/Symbol.for(\"effect/Micro/Env\");\n/**\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const EnvRefTypeId = /*#__PURE__*/Symbol.for(\"effect/Micro/EnvRef\");\nconst EnvProto = {\n  [EnvTypeId]: {\n    _R: identity\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/**\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const envMake = refs => {\n  const self = Object.create(EnvProto);\n  self.refs = refs;\n  return self;\n};\n/**\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const envUnsafeMakeEmpty = () => {\n  const controller = new AbortController();\n  const refs = Object.create(null);\n  refs[currentAbortController.key] = controller;\n  refs[currentAbortSignal.key] = controller.signal;\n  return envMake(refs);\n};\n/**\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const envGet = /*#__PURE__*/dual(2, (self, ref) => ref.key in self.refs ? self.refs[ref.key] : ref.initial);\n/**\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const envSet = /*#__PURE__*/dual(3, (self, ref, value) => {\n  const refs = Object.assign(Object.create(null), self.refs);\n  refs[ref.key] = value;\n  return envMake(refs);\n});\n/**\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const envMutate = /*#__PURE__*/dual(2, (self, f) => envMake(f(Object.assign(Object.create(null), self.refs))));\n/**\n * Access the given `Context.Tag` from the environment.\n *\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const service = tag => make(function (env, onExit) {\n  onExit(exitSucceed(Context.get(envGet(env, currentContext), tag)));\n});\n/**\n * Access the given `Context.Tag` from the environment, without tracking the\n * dependency at the type level.\n *\n * It will return an `Option` of the service, depending on whether it is\n * available in the environment or not.\n *\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const serviceOption = tag => make(function (env, onExit) {\n  onExit(exitSucceed(Context.getOption(envGet(env, currentContext), tag)));\n});\n/**\n * Retrieve the current value of the given `EnvRef`.\n *\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const getEnvRef = envRef => make((env, onExit) => onExit(Either.right(envGet(env, envRef))));\n/**\n * Set the value of the given `EnvRef` for the duration of the effect.\n *\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const locally = /*#__PURE__*/dual(3, (self, fiberRef, value) => make((env, onExit) => self[runSymbol](envSet(env, fiberRef, value), onExit)));\n/**\n * Access the current `Context` from the environment.\n *\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const context = () => getEnvRef(currentContext);\n/**\n * Merge the given `Context` with the current context.\n *\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const provideContext = /*#__PURE__*/dual(2, (self, provided) => make(function (env, onExit) {\n  const context = envGet(env, currentContext);\n  const nextEnv = envSet(env, currentContext, Context.merge(context, provided));\n  self[runSymbol](nextEnv, onExit);\n}));\n/**\n * Add the provided service to the current context.\n *\n * @since 3.4.0\n * @experimental\n * @category environment\n */\nexport const provideService = /*#__PURE__*/dual(3, (self, tag, service) => make(function (env, onExit) {\n  const context = envGet(env, currentContext);\n  const nextEnv = envSet(env, currentContext, Context.add(context, tag, service));\n  self[runSymbol](nextEnv, onExit);\n}));\n/**\n * Create a service using the provided `Micro` effect, and add it to the\n * current context.\n *\n * @since 3.4.6\n * @experimental\n * @category environment\n */\nexport const provideServiceEffect = /*#__PURE__*/dual(3, (self, tag, acquire) => flatMap(acquire, service => provideService(self, tag, service)));\n// ========================================================================\n// Env refs\n// ========================================================================\nconst EnvRefProto = {\n  [EnvRefTypeId]: EnvRefTypeId\n};\n/**\n * @since 3.4.0\n * @experimental\n * @category environment refs\n */\nexport const envRefMake = (key, initial) => globalValue(key, () => {\n  const self = Object.create(EnvRefProto);\n  self.key = key;\n  self.initial = initial();\n  return self;\n});\n/**\n * @since 3.4.0\n * @experimental\n * @category environment refs\n */\nexport const currentAbortController = /*#__PURE__*/envRefMake(\"effect/Micro/currentAbortController\", () => undefined);\n/**\n * @since 3.4.0\n * @experimental\n * @category environment refs\n */\nexport const currentAbortSignal = /*#__PURE__*/envRefMake(\"effect/Micro/currentAbortSignal\", () => undefined);\n/**\n * @since 3.4.0\n * @experimental\n * @category environment refs\n */\nexport const currentContext = /*#__PURE__*/envRefMake(\"effect/Micro/currentContext\", () => Context.empty());\n/**\n * @since 3.4.0\n * @experimental\n * @category environment refs\n */\nexport const currentConcurrency = /*#__PURE__*/envRefMake(\"effect/Micro/currentConcurrency\", () => \"unbounded\");\n/**\n * @since 3.4.0\n * @experimental\n * @category environment refs\n */\nexport const currentMaxDepthBeforeYield = /*#__PURE__*/envRefMake(\"effect/Micro/currentMaxDepthBeforeYield\", () => 2048);\nconst currentInterruptible = /*#__PURE__*/envRefMake(\"effect/Micro/currentInterruptible\", () => true);\n/**\n * If you have a `Micro` that uses `concurrency: \"inherit\"`, you can use this\n * api to control the concurrency of that `Micro` when it is run.\n *\n * @since 3.4.0\n * @experimental\n * @category environment refs\n * @example\n * import * as Micro from \"effect/Micro\"\n *\n * Micro.forEach([1, 2, 3], (n) => Micro.succeed(n), {\n *   concurrency: \"inherit\"\n * }).pipe(\n *   Micro.withConcurrency(2) // use a concurrency of 2\n * )\n */\nexport const withConcurrency = /*#__PURE__*/dual(2, (self, concurrency) => locally(self, currentConcurrency, concurrency));\n// ----------------------------------------------------------------------------\n// constructors\n// ----------------------------------------------------------------------------\nconst MicroProto = {\n  ...Effectable.EffectPrototype,\n  _op: \"Micro\",\n  [TypeId]: {\n    _A: identity,\n    _E: identity,\n    _R: identity\n  },\n  [Symbol.iterator]() {\n    return new SingleShotGen(new YieldWrap(this));\n  }\n};\nconst microDepthState = /*#__PURE__*/globalValue(\"effect/Micro/microDepthState\", () => ({\n  depth: 0,\n  maxDepthBeforeYield: currentMaxDepthBeforeYield.initial\n}));\nconst unsafeMake = run => {\n  const self = Object.create(MicroProto);\n  self[runSymbol] = run;\n  return self;\n};\nconst unsafeMakeOptions = (run, checkAbort) => unsafeMake(function execute(env, onExit) {\n  if (checkAbort && env.refs[currentInterruptible.key] !== false && env.refs[currentAbortSignal.key].aborted) {\n    return onExit(exitInterrupt);\n  }\n  microDepthState.depth++;\n  if (microDepthState.depth === 1) {\n    microDepthState.maxDepthBeforeYield = envGet(env, currentMaxDepthBeforeYield);\n  }\n  if (microDepthState.depth >= microDepthState.maxDepthBeforeYield) {\n    yieldAdd(() => execute(env, onExit));\n  } else {\n    try {\n      run(env, onExit);\n    } catch (err) {\n      onExit(exitDie(err));\n    }\n  }\n  microDepthState.depth--;\n});\n/**\n * A low-level constructor for creating a `Micro` effect. It takes a function\n * that receives an environment and a callback which should be called with the\n * result of the effect.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const make = run => unsafeMakeOptions(run, true);\n/**\n * Converts a `MicroExit` into a `Micro` effect.\n *\n * @since 3.4.6\n * @experimental\n * @category constructors\n */\nexport const fromExit = self => make(function (_env, onExit) {\n  onExit(self);\n});\n/**\n * Converts a lazy `MicroExit` into a `Micro` effect.\n *\n * @since 3.4.6\n * @experimental\n * @category constructors\n */\nexport const fromExitSync = self => make(function (_env, onExit) {\n  onExit(self());\n});\n/**\n * Creates a `Micro` effect that will succeed with the specified constant value.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const succeed = a => fromExit(exitSucceed(a));\n/**\n * Creates a `Micro` effect that will succeed with `Option.Some` of the value.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const succeedSome = a => succeed(Option.some(a));\n/**\n * Creates a `Micro` effect that will succeed with `Option.None`.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const succeedNone = /*#__PURE__*/succeed( /*#__PURE__*/Option.none());\n/**\n * Creates a `Micro` effect that will fail with the specified error.\n *\n * This will result in a `CauseFail`, where the error is tracked at the\n * type level.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const fail = e => fromExit(exitFail(e));\n/**\n * Creates a `Micro` effect that will fail with the lazily evaluated error.\n *\n * This will result in a `CauseFail`, where the error is tracked at the\n * type level.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const failSync = e => make(function (_env, onExit) {\n  onExit(exitFail(e()));\n});\n/**\n * Creates a `Micro` effect that will die with the specified error.\n *\n * This will result in a `CauseDie`, where the error is not tracked at\n * the type level.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const die = defect => fromExit(exitDie(defect));\n/**\n * Creates a `Micro` effect that will fail with the specified `MicroCause`.\n *\n * @since 3.4.6\n * @experimental\n * @category constructors\n */\nexport const failCause = cause => fromExit(exitFailCause(cause));\n/**\n * Creates a `Micro` effect that will fail with the lazily evaluated `MicroCause`.\n *\n * @since 3.4.6\n * @experimental\n * @category constructors\n */\nexport const failCauseSync = cause => fromExitSync(() => exitFailCause(cause()));\n/**\n * Creates a `Micro` effect that will succeed with the lazily evaluated value.\n *\n * If the evaluation of the value throws an error, the effect will fail with\n * `CauseDie`.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const sync = evaluate => make(function (_env, onExit) {\n  onExit(exitSucceed(evaluate()));\n});\n/**\n * Converts an `Option` into a `Micro` effect, that will fail with\n * `NoSuchElementException` if the option is `None`. Otherwise, it will succeed with the\n * value of the option.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const fromOption = option => make(function (_env, onExit) {\n  onExit(option._tag === \"Some\" ? exitSucceed(option.value) : exitFail(new NoSuchElementException({})));\n});\n/**\n * Converts an `Either` into a `Micro` effect, that will fail with the left side\n * of the either if it is a `Left`. Otherwise, it will succeed with the right\n * side of the either.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const fromEither = either => make(function (_env, onExit) {\n  onExit(either._tag === \"Right\" ? either : exitFail(either.left));\n});\n/**\n * Lazily creates a `Micro` effect from the given side-effect.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const suspend = evaluate => make(function (env, onExit) {\n  evaluate()[runSymbol](env, onExit);\n});\nconst void_ = /*#__PURE__*/succeed(void 0);\nexport {\n/**\n * A `Micro` effect that will succeed with `void` (`undefined`).\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nvoid_ as void };\n/**\n * Create a `Micro` effect from an asynchronous computation.\n *\n * You can return a cleanup effect that will be run when the effect is aborted.\n * It is also passed an `AbortSignal` that is triggered when the effect is\n * aborted.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const async = register => make(function (env, onExit) {\n  let resumed = false;\n  const controller = register.length > 1 ? new AbortController() : undefined;\n  const signal = envGet(env, currentAbortSignal);\n  let cleanup = undefined;\n  function onAbort() {\n    if (cleanup) {\n      resume(uninterruptible(andThen(cleanup, fromExit(exitInterrupt))));\n    } else {\n      resume(fromExit(exitInterrupt));\n    }\n    if (controller !== undefined) {\n      controller.abort();\n    }\n  }\n  function resume(effect) {\n    if (resumed) {\n      return;\n    }\n    resumed = true;\n    signal.removeEventListener(\"abort\", onAbort);\n    effect[runSymbol](env, onExit);\n  }\n  cleanup = controller === undefined ? register(resume) : register(resume, controller.signal);\n  if (resumed) return;\n  signal.addEventListener(\"abort\", onAbort);\n});\nconst try_ = options => make(function (_env, onExit) {\n  try {\n    onExit(exitSucceed(options.try()));\n  } catch (err) {\n    onExit(exitFail(options.catch(err)));\n  }\n});\nexport {\n/**\n * The `Micro` equivalent of a try / catch block, which allows you to map\n * thrown errors to a specific error type.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n * @example\n * import { Micro } from \"effect\"\n *\n * Micro.try({\n *   try: () => throw new Error(\"boom\"),\n *   catch: (cause) => new Error(\"caught\", { cause })\n * })\n */\ntry_ as try };\n/**\n * Wrap a `Promise` into a `Micro` effect. Any errors will result in a\n * `CauseDie`.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const promise = evaluate => async(function (resume, signal) {\n  evaluate(signal).then(a => resume(succeed(a)), e => resume(die(e)));\n});\n/**\n * Wrap a `Promise` into a `Micro` effect. Any errors will be caught and\n * converted into a specific error type.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n * @example\n * import { Micro } from \"effect\"\n *\n * Micro.tryPromise({\n *   try: () => Promise.resolve(\"success\"),\n *   catch: (cause) => new Error(\"caught\", { cause })\n * })\n */\nexport const tryPromise = options => async(function (resume, signal) {\n  try {\n    options.try(signal).then(a => resume(succeed(a)), e => resume(fail(options.catch(e))));\n  } catch (err) {\n    resume(fail(options.catch(err)));\n  }\n});\nconst yieldState = /*#__PURE__*/globalValue(\"effect/Micro/yieldState\", () => ({\n  tasks: [],\n  working: false\n}));\nconst yieldRunTasks = () => {\n  const tasks = yieldState.tasks;\n  yieldState.tasks = [];\n  for (let i = 0, len = tasks.length; i < len; i++) {\n    tasks[i]();\n  }\n};\nconst setImmediate = \"setImmediate\" in globalThis ? globalThis.setImmediate : f => setTimeout(f, 0);\nconst yieldAdd = task => {\n  yieldState.tasks.push(task);\n  if (!yieldState.working) {\n    yieldState.working = true;\n    setImmediate(() => {\n      yieldState.working = false;\n      yieldRunTasks();\n    });\n  }\n};\n/**\n * Pause the execution of the current `Micro` effect, and resume it on the next\n * iteration of the event loop.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const yieldNow = /*#__PURE__*/make(function (_env, onExit) {\n  yieldAdd(() => onExit(exitVoid));\n});\n/**\n * Flush any yielded effects that are waiting to be executed.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const yieldFlush = /*#__PURE__*/sync(function () {\n  while (yieldState.tasks.length > 0) {\n    yieldRunTasks();\n  }\n});\n/**\n * A `Micro` that will never succeed or fail. It wraps `setInterval` to prevent\n * the Javascript runtime from exiting.\n *\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const never = /*#__PURE__*/async(function () {\n  const interval = setInterval(constVoid, 2147483646);\n  return sync(() => clearInterval(interval));\n});\n/**\n * @since 3.4.0\n * @experimental\n * @category constructors\n */\nexport const gen = (...args) => make(function (env, onExit) {\n  const iterator = args.length === 1 ? args[0]() : args[1].call(args[0]);\n  let running = false;\n  let value = undefined;\n  function run() {\n    running = true;\n    try {\n      let shouldContinue = true;\n      while (shouldContinue) {\n        const result = iterator.next(value);\n        if (result.done) {\n          return onExit(exitSucceed(result.value));\n        }\n        shouldContinue = false;\n        yieldWrapGet(result.value)[runSymbol](env, function (exit) {\n          if (exit._tag === \"Left\") {\n            onExit(exit);\n          } else {\n            shouldContinue = true;\n            value = exit.right;\n            if (!running) run();\n          }\n        });\n      }\n    } catch (err) {\n      onExit(exitDie(err));\n    }\n    running = false;\n  }\n  run();\n});\n// ----------------------------------------------------------------------------\n// mapping & sequencing\n// ----------------------------------------------------------------------------\n/**\n * Flattens any nested `Micro` effects, merging the error and requirement types.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const flatten = self => make(function (env, onExit) {\n  self[runSymbol](env, exit => exit._tag === \"Left\" ? onExit(exit) : exit.right[runSymbol](env, onExit));\n});\n/**\n * Transforms the success value of the `Micro` effect with the specified\n * function.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => make(function (env, onExit) {\n  self[runSymbol](env, function (exit) {\n    onExit(exit._tag === \"Left\" ? exit : exitSucceed(f(exit.right)));\n  });\n}));\n/**\n * Create a `Micro` effect that will replace the success value of the given\n * effect.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const as = /*#__PURE__*/dual(2, (self, value) => map(self, _ => value));\n/**\n * Wrap the success value of this `Micro` effect in an `Option.Some`.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const asSome = self => map(self, Option.some);\n/**\n * Map the success value of this `Micro` effect to another `Micro` effect, then\n * flatten the result.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => make(function (env, onExit) {\n  self[runSymbol](env, function (exit) {\n    if (exit._tag === \"Left\") {\n      return onExit(exit);\n    }\n    f(exit.right)[runSymbol](env, onExit);\n  });\n}));\n/**\n * Swap the error and success types of the `Micro` effect.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const flip = self => matchEffect(self, {\n  onFailure: succeed,\n  onSuccess: fail\n});\n/**\n * A more flexible version of `flatMap`, that combines `map` and `flatMap` into\n * a single api.\n *\n * It also allows you to pass in a `Micro` effect directly, which will be\n * executed after the current effect.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const andThen = /*#__PURE__*/dual(2, (self, f) => make(function (env, onExit) {\n  self[runSymbol](env, function (exit) {\n    if (exit._tag === \"Left\") {\n      return onExit(exit);\n    } else if (envGet(env, currentAbortSignal).aborted) {\n      return onExit(exitInterrupt);\n    }\n    const value = isMicro(f) ? f : typeof f === \"function\" ? f(exit.right) : f;\n    if (isMicro(value)) {\n      value[runSymbol](env, onExit);\n    } else {\n      onExit(exitSucceed(value));\n    }\n  });\n}));\n/**\n * Execute a side effect from the success value of the `Micro` effect.\n *\n * It is similar to the `andThen` api, but the success value is ignored.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const tap = /*#__PURE__*/dual(2, (self, f) => make(function (env, onExit) {\n  self[runSymbol](env, function (selfExit) {\n    if (selfExit._tag === \"Left\") {\n      return onExit(selfExit);\n    } else if (envGet(env, currentAbortSignal).aborted) {\n      return onExit(exitInterrupt);\n    }\n    const value = isMicro(f) ? f : typeof f === \"function\" ? f(selfExit.right) : f;\n    if (isMicro(value)) {\n      value[runSymbol](env, function (tapExit) {\n        if (tapExit._tag === \"Left\") {\n          return onExit(tapExit);\n        }\n        onExit(selfExit);\n      });\n    } else {\n      onExit(selfExit);\n    }\n  });\n}));\n/**\n * Replace the success value of the `Micro` effect with `void`.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const asVoid = self => map(self, _ => void 0);\n/**\n * Access the `MicroExit` of the given `Micro` effect.\n *\n * @since 3.4.6\n * @experimental\n * @category mapping & sequencing\n */\nexport const exit = self => make(function (env, onExit) {\n  self[runSymbol](env, function (exit) {\n    onExit(exitSucceed(exit));\n  });\n});\n/**\n * Replace the error type of the given `Micro` with the full `MicroCause` object.\n *\n * @since 3.4.0\n * @experimental\n * @category mapping & sequencing\n */\nexport const sandbox = self => catchAllCause(self, cause => fail(cause));\nfunction forkSignal(env) {\n  const controller = new AbortController();\n  const parentSignal = envGet(env, currentAbortSignal);\n  function onAbort() {\n    controller.abort();\n    parentSignal.removeEventListener(\"abort\", onAbort);\n  }\n  parentSignal.addEventListener(\"abort\", onAbort);\n  const envWithSignal = envMutate(env, function (refs) {\n    refs[currentAbortController.key] = controller;\n    refs[currentAbortSignal.key] = controller.signal;\n    return refs;\n  });\n  return [envWithSignal, onAbort];\n}\n/**\n * Returns an effect that races all the specified effects,\n * yielding the value of the first effect to succeed with a value. Losers of\n * the race will be interrupted immediately\n *\n * @since 3.4.0\n * @experimental\n * @category sequencing\n */\nexport const raceAll = all => make(function (env, onExit) {\n  const [envWithSignal, onAbort] = forkSignal(env);\n  const effects = Array.from(all);\n  let len = effects.length;\n  let index = 0;\n  let done = 0;\n  let exit = undefined;\n  const causes = [];\n  function onDone(exit_) {\n    done++;\n    if (exit_._tag === \"Right\" && exit === undefined) {\n      len = index;\n      exit = exit_;\n      onAbort();\n    } else if (exit_._tag === \"Left\") {\n      causes.push(exit_.left);\n    }\n    if (done >= len) {\n      onExit(exit ?? Either.left(causes[0]));\n    }\n  }\n  for (; index < len; index++) {\n    effects[index][runSymbol](envWithSignal, onDone);\n  }\n});\n/**\n * Returns an effect that races all the specified effects,\n * yielding the value of the first effect to succeed or fail. Losers of\n * the race will be interrupted immediately\n *\n * @since 3.4.0\n * @experimental\n * @category sequencing\n */\nexport const raceAllFirst = all => make(function (env, onExit) {\n  const [envWithSignal, onAbort] = forkSignal(env);\n  const effects = Array.from(all);\n  let len = effects.length;\n  let index = 0;\n  let done = 0;\n  let exit = undefined;\n  const causes = [];\n  function onDone(exit_) {\n    done++;\n    if (exit === undefined) {\n      len = index;\n      exit = exit_;\n      onAbort();\n    }\n    if (done >= len) {\n      onExit(exit ?? Either.left(causes[0]));\n    }\n  }\n  for (; index < len; index++) {\n    effects[index][runSymbol](envWithSignal, onDone);\n  }\n});\n/**\n * Returns an effect that races two effects, yielding the value of the first\n * effect to succeed. Losers of the race will be interrupted immediately\n *\n * @since 3.4.0\n * @experimental\n * @category sequencing\n */\nexport const race = /*#__PURE__*/dual(2, (self, that) => raceAll([self, that]));\n/**\n * Returns an effect that races two effects, yielding the value of the first\n * effect to succeed *or* fail. Losers of the race will be interrupted immediately\n *\n * @since 3.4.0\n * @experimental\n * @category sequencing\n */\nexport const raceFirst = /*#__PURE__*/dual(2, (self, that) => raceAllFirst([self, that]));\n// ----------------------------------------------------------------------------\n// zipping\n// ----------------------------------------------------------------------------\n/**\n * Combine two `Micro` effects into a single effect that produces a tuple of\n * their results.\n *\n * @since 3.4.0\n * @experimental\n * @category zipping\n */\nexport const zip = /*#__PURE__*/dual(args => isMicro(args[1]), (self, that, options) => zipWith(self, that, (a, a2) => [a, a2], options));\n/**\n * The `Micro.zipWith` function combines two `Micro` effects and allows you to\n * apply a function to the results of the combined effects, transforming them\n * into a single value.\n *\n * @since 3.4.3\n * @experimental\n * @category zipping\n */\nexport const zipWith = /*#__PURE__*/dual(args => isMicro(args[1]), (self, that, f, options) => {\n  if (options?.concurrent) {\n    // Use `all` exclusively for concurrent cases, as it introduces additional overhead due to the management of concurrency\n    return map(all([self, that], {\n      concurrency: \"unbounded\"\n    }), ([a, a2]) => f(a, a2));\n  }\n  return flatMap(self, a => map(that, a2 => f(a, a2)));\n});\n// ----------------------------------------------------------------------------\n// filtering & conditionals\n// ----------------------------------------------------------------------------\n/**\n * Filter the specified effect with the provided function, failing with specified\n * `MicroCause` if the predicate fails.\n *\n * In addition to the filtering capabilities discussed earlier, you have the option to further\n * refine and narrow down the type of the success channel by providing a\n *\n * @since 3.4.0\n * @experimental\n * @category filtering & conditionals\n */\nexport const filterOrFailCause = /*#__PURE__*/dual(args => isMicro(args[0]), (self, refinement, orFailWith) => flatMap(self, a => refinement(a) ? succeed(a) : failCause(orFailWith(a))));\n/**\n * Filter the specified effect with the provided function, failing with specified\n * error if the predicate fails.\n *\n * In addition to the filtering capabilities discussed earlier, you have the option to further\n * refine and narrow down the type of the success channel by providing a\n *\n * @since 3.4.0\n * @experimental\n * @category filtering & conditionals\n */\nexport const filterOrFail = /*#__PURE__*/dual(args => isMicro(args[0]), (self, refinement, orFailWith) => flatMap(self, a => refinement(a) ? succeed(a) : fail(orFailWith(a))));\n/**\n * The moral equivalent of `if (p) exp`.\n *\n * @since 3.4.0\n * @experimental\n * @category filtering & conditionals\n */\nexport const when = /*#__PURE__*/dual(2, (self, condition) => flatMap(isMicro(condition) ? condition : sync(condition), pass => pass ? asSome(self) : succeed(Option.none())));\n// ----------------------------------------------------------------------------\n// repetition\n// ----------------------------------------------------------------------------\n/**\n * Repeat the given `Micro` using the provided options.\n *\n * The `while` predicate will be checked after each iteration, and can use the\n * fall `MicroExit` of the effect to determine if the repetition should continue.\n *\n * @since 3.4.6\n * @experimental\n * @category repetition\n */\nexport const repeatExit = /*#__PURE__*/dual(2, (self, options) => make(function (env, onExit) {\n  const startedAt = options.schedule ? Date.now() : 0;\n  let attempt = 0;\n  self[runSymbol](env, function loop(exit) {\n    if (options.while !== undefined && !options.while(exit)) {\n      return onExit(exit);\n    } else if (options.times !== undefined && attempt >= options.times) {\n      return onExit(exit);\n    }\n    attempt++;\n    let delayEffect = yieldNow;\n    if (options.schedule !== undefined) {\n      const elapsed = Date.now() - startedAt;\n      const duration = options.schedule(attempt, elapsed);\n      if (Option.isNone(duration)) {\n        return onExit(exit);\n      }\n      delayEffect = sleep(duration.value);\n    }\n    delayEffect[runSymbol](env, function (exit) {\n      if (exit._tag === \"Left\") {\n        return onExit(exit);\n      }\n      self[runSymbol](env, loop);\n    });\n  });\n}));\n/**\n * Repeat the given `Micro` effect using the provided options. Only successful\n * results will be repeated.\n *\n * @since 3.4.0\n * @experimental\n * @category repetition\n */\nexport const repeat = /*#__PURE__*/dual(args => isMicro(args[0]), (self, options) => repeatExit(self, {\n  ...options,\n  while: exit => exit._tag === \"Right\" && (options?.while === undefined || options.while(exit.right))\n}));\n/**\n * Repeat the given `Micro` effect forever, only stopping if the effect fails.\n *\n * @since 3.4.0\n * @experimental\n * @category repetition\n */\nexport const forever = self => repeat(self);\n/**\n * Create a `MicroSchedule` that will stop repeating after the specified number\n * of attempts.\n *\n * @since 3.4.6\n * @experimental\n * @category scheduling\n */\nexport const scheduleRecurs = n => attempt => attempt <= n ? Option.some(0) : Option.none();\n/**\n * Create a `MicroSchedule` that will generate a constant delay.\n *\n * @since 3.4.6\n * @experimental\n * @category scheduling\n */\nexport const scheduleSpaced = millis => () => Option.some(millis);\n/**\n * Create a `MicroSchedule` that will generate a delay with an exponential backoff.\n *\n * @since 3.4.6\n * @experimental\n * @category scheduling\n */\nexport const scheduleExponential = (baseMillis, factor = 2) => attempt => Option.some(Math.pow(factor, attempt) * baseMillis);\n/**\n * Returns a new `MicroSchedule` with an added calculated delay to each delay\n * returned by this schedule.\n *\n * @since 3.4.6\n * @experimental\n * @category scheduling\n */\nexport const scheduleAddDelay = /*#__PURE__*/dual(2, (self, f) => (attempt, elapsed) => Option.map(self(attempt, elapsed), duration => duration + f()));\n/**\n * Transform a `MicroSchedule` to one that will have a delay that will never exceed\n * the specified maximum.\n *\n * @since 3.4.6\n * @experimental\n * @category scheduling\n */\nexport const scheduleWithMaxDelay = /*#__PURE__*/dual(2, (self, max) => (attempt, elapsed) => Option.map(self(attempt, elapsed), duration => Math.min(duration, max)));\n/**\n * Transform a `MicroSchedule` to one that will stop repeating after the specified\n * amount of time.\n *\n * @since 3.4.6\n * @experimental\n * @category scheduling\n */\nexport const scheduleWithMaxElapsed = /*#__PURE__*/dual(2, (self, max) => (attempt, elapsed) => elapsed < max ? self(attempt, elapsed) : Option.none());\n/**\n * Combines two `MicroSchedule`s, by recurring if either schedule wants to\n * recur, using the minimum of the two durations between recurrences.\n *\n * @since 3.4.6\n * @experimental\n * @category scheduling\n */\nexport const scheduleUnion = /*#__PURE__*/dual(2, (self, that) => (attempt, elapsed) => Option.zipWith(self(attempt, elapsed), that(attempt, elapsed), (d1, d2) => Math.min(d1, d2)));\n/**\n * Combines two `MicroSchedule`s, by recurring only if both schedules want to\n * recur, using the maximum of the two durations between recurrences.\n *\n * @since 3.4.6\n * @experimental\n * @category scheduling\n */\nexport const scheduleIntersect = /*#__PURE__*/dual(2, (self, that) => (attempt, elapsed) => Option.zipWith(self(attempt, elapsed), that(attempt, elapsed), (d1, d2) => Math.max(d1, d2)));\n// ----------------------------------------------------------------------------\n// error handling\n// ----------------------------------------------------------------------------\n/**\n * Catch the full `MicroCause` object of the given `Micro` effect, allowing you to\n * recover from any kind of cause.\n *\n * @since 3.4.6\n * @experimental\n * @category error handling\n */\nexport const catchAllCause = /*#__PURE__*/dual(2, (self, f) => catchCauseIf(self, constTrue, f));\n/**\n * Selectively catch a `MicroCause` object of the given `Micro` effect,\n * using the provided predicate to determine if the failure should be caught.\n *\n * @since 3.4.6\n * @experimental\n * @category error handling\n */\nexport const catchCauseIf = /*#__PURE__*/dual(3, (self, predicate, f) => make(function (env, onExit) {\n  self[runSymbol](env, function (exit) {\n    if (exit._tag === \"Right\" || !predicate(exit.left)) {\n      onExit(exit);\n    } else {\n      f(exit.left)[runSymbol](env, onExit);\n    }\n  });\n}));\n/**\n * Catch the error of the given `Micro` effect, allowing you to recover from it.\n *\n * It only catches expected (`MicroCause.Fail`) errors.\n *\n * @since 3.4.6\n * @experimental\n * @category error handling\n */\nexport const catchAll = /*#__PURE__*/dual(2, (self, f) => catchAllCause(self, cause => causeIsFail(cause) ? f(cause.error) : failCause(cause)));\n/**\n * Catch any unexpected errors of the given `Micro` effect, allowing you to recover from them.\n *\n * @since 3.4.6\n * @experimental\n * @category error handling\n */\nexport const catchAllDefect = /*#__PURE__*/dual(2, (self, f) => catchCauseIf(self, causeIsDie, die => f(die.defect)));\n/**\n * Perform a side effect using the full `MicroCause` object of the given `Micro`.\n *\n * @since 3.4.6\n * @experimental\n * @category error handling\n */\nexport const tapErrorCause = /*#__PURE__*/dual(2, (self, f) => tapErrorCauseIf(self, constTrue, f));\n/**\n * Perform a side effect using if a `MicroCause` object matches the specified\n * predicate.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const tapErrorCauseIf = /*#__PURE__*/dual(3, (self, refinement, f) => catchCauseIf(self, refinement, cause => andThen(f(cause), failCause(cause))));\n/**\n * Perform a side effect from expected errors of the given `Micro`.\n *\n * @since 3.4.6\n * @experimental\n * @category error handling\n */\nexport const tapError = /*#__PURE__*/dual(2, (self, f) => tapErrorCauseIf(self, causeIsFail, fail => f(fail.error)));\n/**\n * Perform a side effect from unexpected errors of the given `Micro`.\n *\n * @since 3.4.6\n * @experimental\n * @category error handling\n */\nexport const tapDefect = /*#__PURE__*/dual(2, (self, f) => tapErrorCauseIf(self, causeIsDie, die => f(die.defect)));\n/**\n * Catch any expected errors that match the specified predicate.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const catchIf = /*#__PURE__*/dual(3, (self, predicate, f) => catchCauseIf(self, f => causeIsFail(f) && predicate(f.error), fail => f(fail.error)));\n/**\n * Recovers from the specified tagged error.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const catchTag = /*#__PURE__*/dual(3, (self, k, f) => catchIf(self, isTagged(k), f));\n/**\n * Transform the full `MicroCause` object of the given `Micro` effect.\n *\n * @since 3.4.6\n * @experimental\n * @category error handling\n */\nexport const mapErrorCause = /*#__PURE__*/dual(2, (self, f) => catchAllCause(self, cause => failCause(f(cause))));\n/**\n * Transform any expected errors of the given `Micro` effect.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const mapError = /*#__PURE__*/dual(2, (self, f) => catchAll(self, error => fail(f(error))));\n/**\n * Elevate any expected errors of the given `Micro` effect to unexpected errors,\n * resulting in an error type of `never`.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const orDie = self => catchAll(self, die);\n/**\n * Recover from all errors by succeeding with the given value.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const orElseSucceed = /*#__PURE__*/dual(2, (self, f) => catchAll(self, _ => sync(f)));\n/**\n * Ignore any expected errors of the given `Micro` effect, returning `void`.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const ignore = self => matchEffect(self, {\n  onFailure: _ => void_,\n  onSuccess: _ => void_\n});\n/**\n * Ignore any expected errors of the given `Micro` effect, returning `void`.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const ignoreLogged = self => matchEffect(self, {\n  onFailure: error => sync(() => console.error(error)),\n  onSuccess: _ => void_\n});\n/**\n * Replace the success value of the given `Micro` effect with an `Option`,\n * wrapping the success value in `Some` and returning `None` if the effect fails\n * with an expected error.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const option = self => match(self, {\n  onFailure: _ => Option.none(),\n  onSuccess: Option.some\n});\n/**\n * Replace the success value of the given `Micro` effect with an `Either`,\n * wrapping the success value in `Right` and wrapping any expected errors with\n * a `Left`.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const either = self => match(self, {\n  onFailure: Either.left,\n  onSuccess: Either.right\n});\n/**\n * Retry the given `Micro` effect using the provided options.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const retry = /*#__PURE__*/dual(args => isMicro(args[0]), (self, options) => repeatExit(self, {\n  ...options,\n  while: exit => exit._tag === \"Left\" && exit.left._tag === \"Fail\" && (options?.while === undefined || options.while(exit.left.error))\n}));\n/**\n * Add a stack trace to any failures that occur in the effect. The trace will be\n * added to the `traces` field of the `MicroCause` object.\n *\n * @since 3.4.0\n * @experimental\n * @category error handling\n */\nexport const withTrace = function () {\n  const prevLimit = globalThis.Error.stackTraceLimit;\n  globalThis.Error.stackTraceLimit = 2;\n  const error = new globalThis.Error();\n  globalThis.Error.stackTraceLimit = prevLimit;\n  function generate(name, cause) {\n    const stack = error.stack;\n    if (!stack) {\n      return cause;\n    }\n    const line = stack.split(\"\\n\")[2]?.trim().replace(/^at /, \"\");\n    if (!line) {\n      return cause;\n    }\n    const lineMatch = line.match(/\\((.*)\\)$/);\n    return causeWithTrace(cause, `at ${name} (${lineMatch ? lineMatch[1] : line})`);\n  }\n  const f = name => self => unsafeMakeOptions(function (env, onExit) {\n    self[runSymbol](env, function (exit) {\n      onExit(exit._tag === \"Left\" ? Either.left(generate(name, exit.left)) : exit);\n    });\n  }, false);\n  if (arguments.length === 2) {\n    return f(arguments[1])(arguments[0]);\n  }\n  return f(arguments[0]);\n};\n// ----------------------------------------------------------------------------\n// pattern matching\n// ----------------------------------------------------------------------------\n/**\n * @since 3.4.6\n * @experimental\n * @category pattern matching\n */\nexport const matchCauseEffect = /*#__PURE__*/dual(2, (self, options) => make(function (env, onExit) {\n  self[runSymbol](env, function (exit) {\n    try {\n      const next = exit._tag === \"Left\" ? options.onFailure(exit.left) : options.onSuccess(exit.right);\n      next[runSymbol](env, onExit);\n    } catch (err) {\n      onExit(exitDie(err));\n    }\n  });\n}));\n/**\n * @since 3.4.6\n * @experimental\n * @category pattern matching\n */\nexport const matchCause = /*#__PURE__*/dual(2, (self, options) => matchCauseEffect(self, {\n  onFailure: cause => sync(() => options.onFailure(cause)),\n  onSuccess: value => sync(() => options.onSuccess(value))\n}));\n/**\n * @since 3.4.6\n * @experimental\n * @category pattern matching\n */\nexport const matchEffect = /*#__PURE__*/dual(2, (self, options) => matchCauseEffect(self, {\n  onFailure: cause => cause._tag === \"Fail\" ? options.onFailure(cause.error) : failCause(cause),\n  onSuccess: options.onSuccess\n}));\n/**\n * @since 3.4.0\n * @experimental\n * @category pattern matching\n */\nexport const match = /*#__PURE__*/dual(2, (self, options) => matchEffect(self, {\n  onFailure: error => sync(() => options.onFailure(error)),\n  onSuccess: value => sync(() => options.onSuccess(value))\n}));\n// ----------------------------------------------------------------------------\n// delays & timeouts\n// ----------------------------------------------------------------------------\n/**\n * Create a `Micro` effect that will sleep for the specified duration.\n *\n * @since 3.4.0\n * @experimental\n * @category delays & timeouts\n */\nexport const sleep = millis => async(function (resume) {\n  const timeout = setTimeout(function () {\n    resume(void_);\n  }, millis);\n  return sync(() => {\n    return clearTimeout(timeout);\n  });\n});\n/**\n * Returns an effect that will delay the execution of this effect by the\n * specified duration.\n *\n * @since 3.4.0\n * @experimental\n * @category delays & timeouts\n */\nexport const delay = /*#__PURE__*/dual(2, (self, millis) => andThen(sleep(millis), self));\n/**\n * Returns an effect that will timeout this effect, that will execute the\n * fallback effect if the timeout elapses before the effect has produced a value.\n *\n * If the timeout elapses, the running effect will be safely interrupted.\n *\n * @since 3.4.0\n * @experimental\n * @category delays & timeouts\n */\nexport const timeoutOrElse = /*#__PURE__*/dual(2, (self, options) => raceFirst(self, andThen(interruptible(sleep(options.duration)), options.onTimeout)));\n/**\n * Returns an effect that will timeout this effect, that will fail with a\n * `TimeoutException` if the timeout elapses before the effect has produced a\n * value.\n *\n * If the timeout elapses, the running effect will be safely interrupted.\n *\n * @since 3.4.0\n * @experimental\n * @category delays & timeouts\n */\nexport const timeout = /*#__PURE__*/dual(2, (self, millis) => timeoutOrElse(self, {\n  duration: millis,\n  onTimeout: () => fail(new TimeoutException())\n}));\n/**\n * Returns an effect that will timeout this effect, succeeding with a `None`\n * if the timeout elapses before the effect has produced a value; and `Some` of\n * the produced value otherwise.\n *\n * If the timeout elapses, the running effect will be safely interrupted.\n *\n * @since 3.4.0\n * @experimental\n * @category delays & timeouts\n */\nexport const timeoutOption = /*#__PURE__*/dual(2, (self, millis) => raceFirst(asSome(self), as(interruptible(sleep(millis)), Option.none())));\n// ----------------------------------------------------------------------------\n// resources & finalization\n// ----------------------------------------------------------------------------\n/**\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const MicroScopeTypeId = /*#__PURE__*/Symbol.for(\"effect/Micro/MicroScope\");\n/**\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const MicroScope = /*#__PURE__*/Context.GenericTag(\"effect/Micro/MicroScope\");\nclass MicroScopeImpl {\n  [MicroScopeTypeId];\n  state = {\n    _tag: \"Open\",\n    finalizers: /*#__PURE__*/new Set()\n  };\n  constructor() {\n    this[MicroScopeTypeId] = MicroScopeTypeId;\n  }\n  unsafeAddFinalizer(finalizer) {\n    if (this.state._tag === \"Open\") {\n      this.state.finalizers.add(finalizer);\n    }\n  }\n  addFinalizer(finalizer) {\n    return suspend(() => {\n      if (this.state._tag === \"Open\") {\n        this.state.finalizers.add(finalizer);\n        return void_;\n      }\n      return finalizer(this.state.exit);\n    });\n  }\n  unsafeRemoveFinalizer(finalizer) {\n    if (this.state._tag === \"Open\") {\n      this.state.finalizers.delete(finalizer);\n    }\n  }\n  close(microExit) {\n    return suspend(() => {\n      if (this.state._tag === \"Open\") {\n        const finalizers = Array.from(this.state.finalizers).reverse();\n        this.state = {\n          _tag: \"Closed\",\n          exit: microExit\n        };\n        return flatMap(forEach(finalizers, finalizer => exit(finalizer(microExit))), exits => asVoid(fromExit(Either.all(exits))));\n      }\n      return void_;\n    });\n  }\n  get fork() {\n    return sync(() => {\n      const newScope = new MicroScopeImpl();\n      if (this.state._tag === \"Closed\") {\n        newScope.state = this.state;\n        return newScope;\n      }\n      function fin(exit) {\n        return newScope.close(exit);\n      }\n      this.state.finalizers.add(fin);\n      newScope.unsafeAddFinalizer(_ => sync(() => this.unsafeRemoveFinalizer(fin)));\n      return newScope;\n    });\n  }\n}\n/**\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const scopeMake = /*#__PURE__*/sync(() => new MicroScopeImpl());\n/**\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const scopeUnsafeMake = () => new MicroScopeImpl();\n/**\n * Access the current `MicroScope`.\n *\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const scope = /*#__PURE__*/service(MicroScope);\n/**\n * Provide a `MicroScope` to an effect.\n *\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const provideScope = /*#__PURE__*/dual(2, (self, scope) => provideService(self, MicroScope, scope));\n/**\n * Provide a `MicroScope` to the given effect, closing it after the effect has\n * finished executing.\n *\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const scoped = self => suspend(function () {\n  const scope = new MicroScopeImpl();\n  return onExit(provideService(self, MicroScope, scope), exit => scope.close(exit));\n});\n/**\n * Create a resource with a cleanup `Micro` effect, ensuring the cleanup is\n * executed when the `MicroScope` is closed.\n *\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const acquireRelease = (acquire, release) => uninterruptible(flatMap(scope, scope => tap(acquire, a => scope.addFinalizer(exit => release(a, exit)))));\n/**\n * Add a finalizer to the current `MicroScope`.\n *\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const addFinalizer = finalizer => flatMap(scope, scope => scope.addFinalizer(finalizer));\n/**\n * When the `Micro` effect is completed, run the given finalizer effect with the\n * `MicroExit` of the executed effect.\n *\n * @since 3.4.6\n * @experimental\n * @category resources & finalization\n */\nexport const onExit = /*#__PURE__*/dual(2, (self, f) => onExitIf(self, constTrue, f));\n/**\n * When the `Micro` effect is completed, run the given finalizer effect if it\n * matches the specified predicate.\n *\n * @since 3.4.6\n * @experimental\n * @category resources & finalization\n */\nexport const onExitIf = /*#__PURE__*/dual(3, (self, refinement, f) => uninterruptibleMask(restore => make(function (env, onExit) {\n  restore(self)[runSymbol](env, function (exit) {\n    if (!refinement(exit)) {\n      return onExit(exit);\n    }\n    f(exit)[runSymbol](env, function (finalizerExit) {\n      if (finalizerExit._tag === \"Left\") {\n        return onExit(finalizerExit);\n      }\n      onExit(exit);\n    });\n  });\n})));\n/**\n * Regardless of the result of the this `Micro` effect, run the finalizer effect.\n *\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const ensuring = /*#__PURE__*/dual(2, (self, finalizer) => onExit(self, _ => finalizer));\n/**\n * When the `Micro` effect fails, run the given finalizer effect with the\n * `MicroCause` of the executed effect.\n *\n * @since 3.4.6\n * @experimental\n * @category resources & finalization\n */\nexport const onError = /*#__PURE__*/dual(2, (self, f) => onExitIf(self, exitIsFailure, exit => f(exit.left)));\n/**\n * If this `Micro` effect is aborted, run the finalizer effect.\n *\n * @since 3.4.6\n * @experimental\n * @category resources & finalization\n */\nexport const onInterrupt = /*#__PURE__*/dual(2, (self, finalizer) => onExitIf(self, exitIsInterrupt, _ => finalizer));\n/**\n * Acquire a resource, use it, and then release the resource when the `use`\n * effect has completed.\n *\n * @since 3.4.0\n * @experimental\n * @category resources & finalization\n */\nexport const acquireUseRelease = (acquire, use, release) => uninterruptibleMask(restore => flatMap(acquire, a => flatMap(exit(restore(use(a))), exit => andThen(release(a, exit), fromExit(exit)))));\n// ----------------------------------------------------------------------------\n// interruption\n// ----------------------------------------------------------------------------\n/**\n * Abort the current `Micro` effect.\n *\n * @since 3.4.6\n * @experimental\n * @category interruption\n */\nexport const interrupt = /*#__PURE__*/make(function (env, onExit) {\n  const controller = envGet(env, currentAbortController);\n  controller.abort();\n  onExit(exitInterrupt);\n});\n/**\n * Wrap the given `Micro` effect in an uninterruptible region, preventing the\n * effect from being aborted.\n *\n * @since 3.4.0\n * @experimental\n * @category interruption\n */\nexport const uninterruptible = self => unsafeMakeOptions(function (env, onExit) {\n  const nextEnv = envMutate(env, function (env) {\n    env[currentInterruptible.key] = false;\n    env[currentAbortSignal.key] = new AbortController().signal;\n    return env;\n  });\n  self[runSymbol](nextEnv, onExit);\n}, false);\n/**\n * Wrap the given `Micro` effect in an uninterruptible region, preventing the\n * effect from being aborted.\n *\n * You can use the `restore` function to restore a `Micro` effect to the\n * interruptibility state before the `uninterruptibleMask` was applied.\n *\n * @since 3.4.0\n * @experimental\n * @category interruption\n * @example\n * import * as Micro from \"effect/Micro\"\n *\n * Micro.uninterruptibleMask((restore) =>\n *   Micro.sleep(1000).pipe( // uninterruptible\n *     Micro.andThen(restore(Micro.sleep(1000))) // interruptible\n *   )\n * )\n */\nexport const uninterruptibleMask = f => unsafeMakeOptions((env, onExit) => {\n  const isInterruptible = envGet(env, currentInterruptible);\n  const effect = isInterruptible ? f(interruptible) : f(identity);\n  const nextEnv = isInterruptible ? envMutate(env, function (env) {\n    env[currentInterruptible.key] = false;\n    env[currentAbortSignal.key] = new AbortController().signal;\n    return env;\n  }) : env;\n  effect[runSymbol](nextEnv, onExit);\n}, false);\n/**\n * Wrap the given `Micro` effect in an interruptible region, allowing the effect\n * to be aborted.\n *\n * @since 3.4.0\n * @experimental\n * @category interruption\n */\nexport const interruptible = self => make((env, onExit) => {\n  const isInterruptible = envGet(env, currentInterruptible);\n  let newEnv = env;\n  if (!isInterruptible) {\n    const controller = envGet(env, currentAbortController);\n    newEnv = envMutate(env, function (env) {\n      env[currentInterruptible.key] = true;\n      env[currentAbortSignal.key] = controller.signal;\n      return env;\n    });\n  }\n  self[runSymbol](newEnv, onExit);\n});\n/**\n * Runs all the provided effects in sequence respecting the structure provided in input.\n *\n * Supports multiple arguments, a single argument tuple / array or record / struct.\n *\n * @since 3.4.0\n * @experimental\n * @category collecting & elements\n */\nexport const all = (arg, options) => {\n  if (Array.isArray(arg) || isIterable(arg)) {\n    return forEach(arg, identity, options);\n  } else if (options?.discard) {\n    return forEach(Object.values(arg), identity, options);\n  }\n  return suspend(() => {\n    const out = {};\n    return as(forEach(Object.entries(arg), ([key, effect]) => map(effect, value => {\n      out[key] = value;\n    }), {\n      discard: true,\n      concurrency: options?.concurrency\n    }), out);\n  });\n};\n/**\n * For each element of the provided iterable, run the effect and collect the results.\n *\n * If the `discard` option is set to `true`, the results will be discarded and\n * the effect will return `void`.\n *\n * The `concurrency` option can be set to control how many effects are run in\n * parallel. By default, the effects are run sequentially.\n *\n * @since 3.4.0\n * @experimental\n * @category collecting & elements\n */\nexport const forEach = (iterable, f, options) => make(function (env, onExit) {\n  const concurrencyOption = options?.concurrency === \"inherit\" ? envGet(env, currentConcurrency) : options?.concurrency ?? 1;\n  const concurrency = concurrencyOption === \"unbounded\" ? Number.POSITIVE_INFINITY : Math.max(1, concurrencyOption);\n  // abort\n  const [envWithSignal, onAbort] = forkSignal(env);\n  // iterate\n  let result = undefined;\n  const items = Array.from(iterable);\n  let length = items.length;\n  const out = options?.discard ? undefined : new Array(length);\n  let index = 0;\n  let inProgress = 0;\n  let doneCount = 0;\n  let pumping = false;\n  function pump() {\n    pumping = true;\n    while (inProgress < concurrency && index < length) {\n      const currentIndex = index;\n      const item = items[currentIndex];\n      index++;\n      inProgress++;\n      try {\n        f(item, currentIndex)[runSymbol](envWithSignal, function (exit) {\n          if (exit._tag === \"Left\") {\n            if (result === undefined) {\n              result = exit;\n              length = index;\n              onAbort();\n            }\n          } else if (out !== undefined) {\n            out[currentIndex] = exit.right;\n          }\n          doneCount++;\n          inProgress--;\n          if (doneCount === length) {\n            onExit(result ?? Either.right(out));\n          } else if (!pumping && inProgress < concurrency) {\n            pump();\n          }\n        });\n      } catch (err) {\n        result = exitDie(err);\n        length = index;\n        onAbort();\n      }\n    }\n    pumping = false;\n  }\n  pump();\n});\n/**\n * Effectfully filter the elements of the provided iterable.\n *\n * Use the `concurrency` option to control how many elements are processed in parallel.\n *\n * @since 3.4.0\n * @experimental\n * @category collecting & elements\n */\nexport const filter = (iterable, f, options) => filterMap(iterable, a => map(f(a), pass => {\n  pass = options?.negate ? !pass : pass;\n  return pass ? Option.some(a) : Option.none();\n}), options);\n/**\n * Effectfully filter the elements of the provided iterable.\n *\n * Use the `concurrency` option to control how many elements are processed in parallel.\n *\n * @since 3.4.0\n * @experimental\n * @category collecting & elements\n */\nexport const filterMap = (iterable, f, options) => suspend(() => {\n  const out = [];\n  return as(forEach(iterable, a => map(f(a), o => {\n    if (o._tag === \"Some\") {\n      out.push(o.value);\n    }\n  }), {\n    discard: true,\n    concurrency: options?.concurrency\n  }), out);\n});\n// ----------------------------------------------------------------------------\n// do notation\n// ----------------------------------------------------------------------------\n/**\n * Start a do notation block.\n *\n * @since 3.4.0\n * @experimental\n * @category do notation\n */\nexport const Do = /*#__PURE__*/succeed({});\n/**\n * Bind the success value of this `Micro` effect to the provided name.\n *\n * @since 3.4.0\n * @experimental\n * @category do notation\n */\nexport const bindTo = /*#__PURE__*/doNotation.bindTo(map);\n/**\n * Bind the success value of this `Micro` effect to the provided name.\n *\n * @since 3.4.0\n * @experimental\n * @category do notation\n */\nexport const bind = /*#__PURE__*/doNotation.bind(map, flatMap);\nconst let_ = /*#__PURE__*/doNotation.let_(map);\nexport {\n/**\n * Bind the result of a synchronous computation to the given name.\n *\n * @since 3.4.0\n * @experimental\n * @category do notation\n */\nlet_ as let };\n// ----------------------------------------------------------------------------\n// handle & forking\n// ----------------------------------------------------------------------------\n/**\n * @since 3.4.0\n * @experimental\n * @category handle & forking\n */\nexport const HandleTypeId = /*#__PURE__*/Symbol.for(\"effect/Micro/Handle\");\n/**\n * @since 3.4.0\n * @experimental\n * @category handle & forking\n */\nexport const isHandle = u => typeof u === \"object\" && u !== null && HandleTypeId in u;\nclass HandleImpl {\n  parentSignal;\n  [HandleTypeId];\n  observers = /*#__PURE__*/new Set();\n  _exit = undefined;\n  _controller;\n  isRoot;\n  constructor(parentSignal, controller) {\n    this.parentSignal = parentSignal;\n    this[HandleTypeId] = HandleTypeId;\n    this.isRoot = controller !== undefined;\n    this._controller = controller ?? new AbortController();\n    if (!this.isRoot) {\n      parentSignal.addEventListener(\"abort\", this.unsafeInterrupt);\n    }\n  }\n  unsafePoll() {\n    return this._exit ?? null;\n  }\n  unsafeInterrupt = () => {\n    this._controller.abort();\n  };\n  emit(exit) {\n    if (this._exit) {\n      return;\n    }\n    this._exit = exit;\n    if (!this.isRoot) {\n      this.parentSignal.removeEventListener(\"abort\", this.unsafeInterrupt);\n    }\n    this.observers.forEach(observer => observer(exit));\n    this.observers.clear();\n  }\n  addObserver(observer) {\n    if (this._exit) {\n      return observer(this._exit);\n    }\n    this.observers.add(observer);\n  }\n  removeObserver(observer) {\n    this.observers.delete(observer);\n  }\n  get await() {\n    return suspend(() => {\n      if (this._exit) {\n        return succeed(this._exit);\n      }\n      return async(resume => {\n        function observer(exit) {\n          resume(succeed(exit));\n        }\n        this.addObserver(observer);\n        return sync(() => {\n          this.removeObserver(observer);\n        });\n      });\n    });\n  }\n  get join() {\n    return flatMap(this.await, fromExit);\n  }\n  get interrupt() {\n    return suspend(() => {\n      this.unsafeInterrupt();\n      return this.await;\n    });\n  }\n}\n/**\n * Run the `Micro` effect in a new `Handle` that can be awaited, joined, or\n * aborted.\n *\n * When the parent `Micro` finishes, this `Micro` will be aborted.\n *\n * @since 3.4.0\n * @experimental\n * @category handle & forking\n */\nexport const fork = self => make(function (env, onExit) {\n  const signal = envGet(env, currentAbortSignal);\n  const handle = new HandleImpl(signal);\n  const nextEnv = envMutate(env, map => {\n    map[currentAbortController.key] = handle._controller;\n    map[currentAbortSignal.key] = handle._controller.signal;\n    return map;\n  });\n  yieldAdd(() => {\n    self[runSymbol](nextEnv, exit => {\n      handle.emit(exit);\n    });\n  });\n  onExit(Either.right(handle));\n});\n/**\n * Run the `Micro` effect in a new `Handle` that can be awaited, joined, or\n * aborted.\n *\n * It will not be aborted when the parent `Micro` finishes.\n *\n * @since 3.4.0\n * @experimental\n * @category handle & forking\n */\nexport const forkDaemon = self => make(function (env, onExit) {\n  const controller = new AbortController();\n  const handle = new HandleImpl(controller.signal, controller);\n  const nextEnv = envMutate(env, map => {\n    map[currentAbortController.key] = controller;\n    map[currentAbortSignal.key] = controller.signal;\n    return map;\n  });\n  yieldAdd(() => {\n    self[runSymbol](nextEnv, exit => {\n      handle.emit(exit);\n    });\n  });\n  onExit(Either.right(handle));\n});\n/**\n * Run the `Micro` effect in a new `Handle` that can be awaited, joined, or\n * aborted.\n *\n * The lifetime of the handle will be attached to the provided `MicroScope`.\n *\n * @since 3.4.0\n * @experimental\n * @category handle & forking\n */\nexport const forkIn = /*#__PURE__*/dual(2, (self, scope) => uninterruptibleMask(restore => flatMap(scope.fork, scope => tap(restore(forkDaemon(onExit(self, exit => scope.close(exit)))), fiber => scope.addFinalizer(_ => asVoid(fiber.interrupt))))));\n/**\n * Run the `Micro` effect in a new `Handle` that can be awaited, joined, or\n * aborted.\n *\n * The lifetime of the handle will be attached to the current `MicroScope`.\n *\n * @since 3.4.0\n * @experimental\n * @category handle & forking\n */\nexport const forkScoped = self => flatMap(scope, scope => forkIn(self, scope));\n// ----------------------------------------------------------------------------\n// execution\n// ----------------------------------------------------------------------------\n/**\n * Execute the `Micro` effect and return a `Handle` that can be awaited, joined,\n * or aborted.\n *\n * You can listen for the result by adding an observer using the handle's\n * `addObserver` method.\n *\n * @since 3.4.0\n * @experimental\n * @category execution\n * @example\n * import * as Micro from \"effect/Micro\"\n *\n * const handle = Micro.succeed(42).pipe(\n *   Micro.delay(1000),\n *   Micro.runFork\n * )\n *\n * handle.addObserver((exit) => {\n *   console.log(exit)\n * })\n */\nexport const runFork = (effect, options) => {\n  const controller = new AbortController();\n  const refs = Object.create(null);\n  refs[currentAbortController.key] = controller;\n  refs[currentAbortSignal.key] = controller.signal;\n  const env = envMake(refs);\n  const handle = new HandleImpl(controller.signal, controller);\n  effect[runSymbol](envSet(env, currentAbortSignal, handle._controller.signal), exit => {\n    handle.emit(exit);\n    if (options?.signal) {\n      options.signal.removeEventListener(\"abort\", handle.unsafeInterrupt);\n    }\n  });\n  if (options?.signal) {\n    if (options.signal.aborted) {\n      handle.unsafeInterrupt();\n    } else {\n      options.signal.addEventListener(\"abort\", handle.unsafeInterrupt, {\n        once: true\n      });\n    }\n  }\n  return handle;\n};\n/**\n * Execute the `Micro` effect and return a `Promise` that resolves with the\n * `MicroExit` of the computation.\n *\n * @since 3.4.6\n * @experimental\n * @category execution\n */\nexport const runPromiseExit = (effect, options) => new Promise((resolve, _reject) => {\n  const handle = runFork(effect, options);\n  handle.addObserver(resolve);\n});\n/**\n * Execute the `Micro` effect and return a `Promise` that resolves with the\n * successful value of the computation.\n *\n * @since 3.4.0\n * @experimental\n * @category execution\n */\nexport const runPromise = (effect, options) => runPromiseExit(effect, options).then(exit => {\n  if (exit._tag === \"Left\") {\n    throw exit.left;\n  }\n  return exit.right;\n});\n/**\n * Attempt to execute the `Micro` effect synchronously and return the `MicroExit`.\n *\n * If any asynchronous effects are encountered, the function will return a\n * `CauseDie` containing the `Handle`.\n *\n * @since 3.4.6\n * @experimental\n * @category execution\n */\nexport const runSyncExit = effect => {\n  const handle = runFork(effect);\n  while (yieldState.tasks.length > 0) {\n    yieldRunTasks();\n  }\n  const exit = handle.unsafePoll();\n  if (exit === null) {\n    return exitDie(handle);\n  }\n  return exit;\n};\n/**\n * Attempt to execute the `Micro` effect synchronously and return the success\n * value.\n *\n * @since 3.4.0\n * @experimental\n * @category execution\n */\nexport const runSync = effect => {\n  const exit = runSyncExit(effect);\n  if (exit._tag === \"Left\") {\n    throw exit.left;\n  }\n  return exit.right;\n};\nconst YieldableError = /*#__PURE__*/function () {\n  class YieldableError extends globalThis.Error {\n    [runSymbol](_env, onExit) {\n      onExit(exitFail(this));\n    }\n    toString() {\n      return this.message ? `${this.name}: ${this.message}` : this.name;\n    }\n    toJSON() {\n      return {\n        ...this\n      };\n    }\n    [NodeInspectSymbol]() {\n      const stack = this.stack;\n      if (stack) {\n        return `${this.toString()}\\n${stack.split(\"\\n\").slice(1).join(\"\\n\")}`;\n      }\n      return this.toString();\n    }\n  }\n  Object.assign(YieldableError.prototype, MicroProto, StructuralPrototype);\n  return YieldableError;\n}();\n/**\n * @since 3.4.0\n * @experimental\n * @category errors\n */\nexport const Error = /*#__PURE__*/function () {\n  return class extends YieldableError {\n    constructor(args) {\n      super();\n      if (args) {\n        Object.assign(this, args);\n      }\n    }\n  };\n}();\n/**\n * @since 3.4.0\n * @experimental\n * @category errors\n */\nexport const TaggedError = tag => {\n  class Base extends Error {\n    _tag = tag;\n  }\n  ;\n  Base.prototype.name = tag;\n  return Base;\n};\n/**\n * Represents a checked exception which occurs when an expected element was\n * unable to be found.\n *\n * @since 3.4.4\n * @experimental\n * @category errors\n */\nexport class NoSuchElementException extends /*#__PURE__*/TaggedError(\"NoSuchElementException\") {}\n/**\n * Represents a checked exception which occurs when a timeout occurs.\n *\n * @since 3.4.4\n * @experimental\n * @category errors\n */\nexport class TimeoutException extends /*#__PURE__*/TaggedError(\"TimeoutException\") {}\n//# sourceMappingURL=Micro.js.map","import * as Equal from \"./Equal.js\";\nimport { dual } from \"./Function.js\";\nimport * as Hash from \"./Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"./Inspectable.js\";\nimport * as Option from \"./Option.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nconst TypeId = /*#__PURE__*/Symbol.for(\"effect/MutableHashMap\");\nconst MutableHashMapProto = {\n  [TypeId]: TypeId,\n  [Symbol.iterator]() {\n    return new MutableHashMapIterator(this);\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"MutableHashMap\",\n      values: Array.from(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nclass MutableHashMapIterator {\n  self;\n  referentialIterator;\n  bucketIterator;\n  constructor(self) {\n    this.self = self;\n    this.referentialIterator = self.referential[Symbol.iterator]();\n  }\n  next() {\n    if (this.bucketIterator !== undefined) {\n      return this.bucketIterator.next();\n    }\n    const result = this.referentialIterator.next();\n    if (result.done) {\n      this.bucketIterator = new BucketIterator(this.self.buckets.values());\n      return this.next();\n    }\n    return result;\n  }\n  [Symbol.iterator]() {\n    return new MutableHashMapIterator(this.self);\n  }\n}\nclass BucketIterator {\n  backing;\n  constructor(backing) {\n    this.backing = backing;\n  }\n  currentBucket;\n  next() {\n    if (this.currentBucket === undefined) {\n      const result = this.backing.next();\n      if (result.done) {\n        return result;\n      }\n      this.currentBucket = result.value[Symbol.iterator]();\n    }\n    const result = this.currentBucket.next();\n    if (result.done) {\n      this.currentBucket = undefined;\n      return this.next();\n    }\n    return result;\n  }\n}\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = () => {\n  const self = Object.create(MutableHashMapProto);\n  self.referential = new Map();\n  self.buckets = new Map();\n  self.bucketsSize = 0;\n  return self;\n};\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = (...entries) => fromIterable(entries);\n/**\n * Creates a new `MutableHashMap` from an iterable collection of key/value pairs.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = entries => {\n  const self = empty();\n  for (const [key, value] of entries) {\n    set(self, key, value);\n  }\n  return self;\n};\n/**\n * @since 2.0.0\n * @category elements\n */\nexport const get = /*#__PURE__*/dual(2, (self, key) => {\n  if (Equal.isEqual(key) === false) {\n    return self.referential.has(key) ? Option.some(self.referential.get(key)) : Option.none();\n  }\n  const hash = key[Hash.symbol]();\n  const bucket = self.buckets.get(hash);\n  if (bucket === undefined) {\n    return Option.none();\n  }\n  return getFromBucket(self, bucket, key);\n});\nconst getFromBucket = (self, bucket, key, remove = false) => {\n  for (let i = 0, len = bucket.length; i < len; i++) {\n    if (key[Equal.symbol](bucket[i][0])) {\n      const value = bucket[i][1];\n      if (remove) {\n        bucket.splice(i, 1);\n        self.bucketsSize--;\n      }\n      return Option.some(value);\n    }\n  }\n  return Option.none();\n};\n/**\n * @since 2.0.0\n * @category elements\n */\nexport const has = /*#__PURE__*/dual(2, (self, key) => Option.isSome(get(self, key)));\n/**\n * @since 2.0.0\n */\nexport const set = /*#__PURE__*/dual(3, (self, key, value) => {\n  if (Equal.isEqual(key) === false) {\n    self.referential.set(key, value);\n    return self;\n  }\n  const hash = key[Hash.symbol]();\n  const bucket = self.buckets.get(hash);\n  if (bucket === undefined) {\n    self.buckets.set(hash, [[key, value]]);\n    self.bucketsSize++;\n    return self;\n  }\n  removeFromBucket(self, bucket, key);\n  bucket.push([key, value]);\n  self.bucketsSize++;\n  return self;\n});\nconst removeFromBucket = (self, bucket, key) => {\n  for (let i = 0, len = bucket.length; i < len; i++) {\n    if (key[Equal.symbol](bucket[i][0])) {\n      bucket.splice(i, 1);\n      self.bucketsSize--;\n      return;\n    }\n  }\n};\n/**\n * Updates the value of the specified key within the `MutableHashMap` if it exists.\n *\n * @since 2.0.0\n */\nexport const modify = /*#__PURE__*/dual(3, (self, key, f) => {\n  if (Equal.isEqual(key) === false) {\n    if (self.referential.has(key)) {\n      self.referential.set(key, f(self.referential.get(key)));\n    }\n    return self;\n  }\n  const hash = key[Hash.symbol]();\n  const bucket = self.buckets.get(hash);\n  if (bucket === undefined) {\n    return self;\n  }\n  const value = getFromBucket(self, bucket, key, true);\n  if (Option.isNone(value)) {\n    return self;\n  }\n  bucket.push([key, f(value.value)]);\n  self.bucketsSize++;\n  return self;\n});\n/**\n * Set or remove the specified key in the `MutableHashMap` using the specified\n * update function.\n *\n * @since 2.0.0\n */\nexport const modifyAt = /*#__PURE__*/dual(3, (self, key, f) => {\n  if (Equal.isEqual(key) === false) {\n    const result = f(get(self, key));\n    if (Option.isSome(result)) {\n      set(self, key, result.value);\n    } else {\n      remove(self, key);\n    }\n    return self;\n  }\n  const hash = key[Hash.symbol]();\n  const bucket = self.buckets.get(hash);\n  if (bucket === undefined) {\n    const result = f(Option.none());\n    return Option.isSome(result) ? set(self, key, result.value) : self;\n  }\n  const result = f(getFromBucket(self, bucket, key, true));\n  if (Option.isNone(result)) {\n    if (bucket.length === 0) {\n      self.buckets.delete(hash);\n    }\n    return self;\n  }\n  bucket.push([key, result.value]);\n  self.bucketsSize++;\n  return self;\n});\n/**\n * @since 2.0.0\n */\nexport const remove = /*#__PURE__*/dual(2, (self, key) => {\n  if (Equal.isEqual(key) === false) {\n    self.referential.delete(key);\n    return self;\n  }\n  const hash = key[Hash.symbol]();\n  const bucket = self.buckets.get(hash);\n  if (bucket === undefined) {\n    return self;\n  }\n  removeFromBucket(self, bucket, key);\n  if (bucket.length === 0) {\n    self.buckets.delete(hash);\n  }\n  return self;\n});\n/**\n * @since 2.0.0\n */\nexport const clear = self => {\n  self.referential.clear();\n  self.buckets.clear();\n  self.bucketsSize = 0;\n  return self;\n};\n/**\n * @since 2.0.0\n * @category elements\n */\nexport const size = self => {\n  return self.referential.size + self.bucketsSize;\n};\n//# sourceMappingURL=MutableHashMap.js.map","/**\n * @since 2.0.0\n */\nimport * as Dual from \"./Function.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"./Inspectable.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nconst TypeId = /*#__PURE__*/Symbol.for(\"effect/MutableList\");\nconst MutableListProto = {\n  [TypeId]: TypeId,\n  [Symbol.iterator]() {\n    let done = false;\n    let head = this.head;\n    return {\n      next() {\n        if (done) {\n          return this.return();\n        }\n        if (head == null) {\n          done = true;\n          return this.return();\n        }\n        const value = head.value;\n        head = head.next;\n        return {\n          done,\n          value\n        };\n      },\n      return(value) {\n        if (!done) {\n          done = true;\n        }\n        return {\n          done: true,\n          value\n        };\n      }\n    };\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"MutableList\",\n      values: Array.from(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nconst makeNode = value => ({\n  value,\n  removed: false,\n  prev: undefined,\n  next: undefined\n});\n/**\n * Creates an empty `MutableList`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = () => {\n  const list = Object.create(MutableListProto);\n  list.head = undefined;\n  list.tail = undefined;\n  list._length = 0;\n  return list;\n};\n/**\n * Creates a new `MutableList` from an iterable collection of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = iterable => {\n  const list = empty();\n  for (const element of iterable) {\n    append(list, element);\n  }\n  return list;\n};\n/**\n * Creates a new `MutableList` from the specified elements.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = (...elements) => fromIterable(elements);\n/**\n * Returns `true` if the list contains zero elements, `false`, otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isEmpty = self => length(self) === 0;\n/**\n * Returns the length of the list.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const length = self => self._length;\n/**\n * Returns the last element of the list, if it exists.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const tail = self => self.tail === undefined ? undefined : self.tail.value;\n/**\n * Returns the first element of the list, if it exists.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const head = self => self.head === undefined ? undefined : self.head.value;\n/**\n * Executes the specified function `f` for each element in the list.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const forEach = /*#__PURE__*/Dual.dual(2, (self, f) => {\n  let current = self.head;\n  while (current !== undefined) {\n    f(current.value);\n    current = current.next;\n  }\n});\n/**\n * Removes all elements from the doubly-linked list.\n *\n * @since 2.0.0\n */\nexport const reset = self => {\n  ;\n  self._length = 0;\n  self.head = undefined;\n  self.tail = undefined;\n  return self;\n};\n/**\n * Appends the specified element to the end of the `MutableList`.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const append = /*#__PURE__*/Dual.dual(2, (self, value) => {\n  const node = makeNode(value);\n  if (self.head === undefined) {\n    self.head = node;\n  }\n  if (self.tail === undefined) {\n    self.tail = node;\n  } else {\n    self.tail.next = node;\n    node.prev = self.tail;\n    self.tail = node;\n  }\n  ;\n  self._length += 1;\n  return self;\n});\n/**\n * Removes the first value from the list and returns it, if it exists.\n *\n * @since 0.0.1\n */\nexport const shift = self => {\n  const head = self.head;\n  if (head !== undefined) {\n    remove(self, head);\n    return head.value;\n  }\n  return undefined;\n};\n/**\n * Removes the last value from the list and returns it, if it exists.\n *\n * @since 0.0.1\n */\nexport const pop = self => {\n  const tail = self.tail;\n  if (tail !== undefined) {\n    remove(self, tail);\n    return tail.value;\n  }\n  return undefined;\n};\n/**\n * Prepends the specified value to the beginning of the list.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const prepend = /*#__PURE__*/Dual.dual(2, (self, value) => {\n  const node = makeNode(value);\n  node.next = self.head;\n  if (self.head !== undefined) {\n    self.head.prev = node;\n  }\n  self.head = node;\n  if (self.tail === undefined) {\n    self.tail = node;\n  }\n  ;\n  self._length += 1;\n  return self;\n});\nconst remove = (self, node) => {\n  if (node.removed) {\n    return;\n  }\n  node.removed = true;\n  if (node.prev !== undefined && node.next !== undefined) {\n    node.prev.next = node.next;\n    node.next.prev = node.prev;\n  } else if (node.prev !== undefined) {\n    self.tail = node.prev;\n    node.prev.next = undefined;\n  } else if (node.next !== undefined) {\n    self.head = node.next;\n    node.next.prev = undefined;\n  } else {\n    self.tail = undefined;\n    self.head = undefined;\n  }\n  if (self._length > 0) {\n    ;\n    self._length -= 1;\n  }\n};\n//# sourceMappingURL=MutableList.js.map","/**\n * @since 2.0.0\n */\nimport * as Chunk from \"./Chunk.js\";\nimport * as Dual from \"./Function.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"./Inspectable.js\";\nimport * as MutableList from \"./MutableList.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nconst TypeId = /*#__PURE__*/Symbol.for(\"effect/MutableQueue\");\n/**\n * @since 2.0.0\n * @category symbol\n */\nexport const EmptyMutableQueue = /*#__PURE__*/Symbol.for(\"effect/mutable/MutableQueue/Empty\");\nconst MutableQueueProto = {\n  [TypeId]: TypeId,\n  [Symbol.iterator]() {\n    return Array.from(this.queue)[Symbol.iterator]();\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"MutableQueue\",\n      values: Array.from(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst make = capacity => {\n  const queue = Object.create(MutableQueueProto);\n  queue.queue = MutableList.empty();\n  queue.capacity = capacity;\n  return queue;\n};\n/**\n * Creates a new bounded `MutableQueue`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const bounded = capacity => make(capacity);\n/**\n * Creates a new unbounded `MutableQueue`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unbounded = () => make(undefined);\n/**\n * Returns the current number of elements in the queue.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const length = self => MutableList.length(self.queue);\n/**\n * Returns `true` if the queue is empty, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isEmpty = self => MutableList.isEmpty(self.queue);\n/**\n * Returns `true` if the queue is full, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isFull = self => self.capacity === undefined ? false : MutableList.length(self.queue) === self.capacity;\n/**\n * The **maximum** number of elements that a queue can hold.\n *\n * **Note**: unbounded queues can still implement this interface with\n * `capacity = Infinity`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const capacity = self => self.capacity === undefined ? Infinity : self.capacity;\n/**\n * Offers an element to the queue.\n *\n * Returns whether the enqueue was successful or not.\n *\n * @since 2.0.0\n */\nexport const offer = /*#__PURE__*/Dual.dual(2, (self, value) => {\n  const queueLength = MutableList.length(self.queue);\n  if (self.capacity !== undefined && queueLength === self.capacity) {\n    return false;\n  }\n  MutableList.append(value)(self.queue);\n  return true;\n});\n/**\n * Enqueues a collection of values into the queue.\n *\n * Returns a `Chunk` of the values that were **not** able to be enqueued.\n *\n * @since 2.0.0\n */\nexport const offerAll = /*#__PURE__*/Dual.dual(2, (self, values) => {\n  const iterator = values[Symbol.iterator]();\n  let next;\n  let remainder = Chunk.empty();\n  let offering = true;\n  while (offering && (next = iterator.next()) && !next.done) {\n    offering = offer(next.value)(self);\n  }\n  while (next != null && !next.done) {\n    remainder = Chunk.prepend(next.value)(remainder);\n    next = iterator.next();\n  }\n  return Chunk.reverse(remainder);\n});\n/**\n * Dequeues an element from the queue.\n *\n * Returns either an element from the queue, or the `def` param.\n *\n * **Note**: if there is no meaningful default for your type, you can always\n * use `poll(MutableQueue.EmptyMutableQueue)`.\n *\n * @since 2.0.0\n */\nexport const poll = /*#__PURE__*/Dual.dual(2, (self, def) => {\n  if (MutableList.isEmpty(self.queue)) {\n    return def;\n  }\n  return MutableList.shift(self.queue);\n});\n/**\n * Dequeues up to `n` elements from the queue.\n *\n * Returns a `List` of up to `n` elements.\n *\n * @since 2.0.0\n */\nexport const pollUpTo = /*#__PURE__*/Dual.dual(2, (self, n) => {\n  let result = Chunk.empty();\n  let count = 0;\n  while (count < n) {\n    const element = poll(EmptyMutableQueue)(self);\n    if (element === EmptyMutableQueue) {\n      break;\n    }\n    result = Chunk.prepend(element)(result);\n    count += 1;\n  }\n  return Chunk.reverse(result);\n});\n//# sourceMappingURL=MutableQueue.js.map","/**\n * @since 2.0.0\n */\nimport * as Equal from \"./Equal.js\";\nimport * as Dual from \"./Function.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"./Inspectable.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nconst TypeId = /*#__PURE__*/Symbol.for(\"effect/MutableRef\");\nconst MutableRefProto = {\n  [TypeId]: TypeId,\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"MutableRef\",\n      current: toJSON(this.current)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = value => {\n  const ref = Object.create(MutableRefProto);\n  ref.current = value;\n  return ref;\n};\n/**\n * @since 2.0.0\n * @category general\n */\nexport const compareAndSet = /*#__PURE__*/Dual.dual(3, (self, oldValue, newValue) => {\n  if (Equal.equals(oldValue, self.current)) {\n    self.current = newValue;\n    return true;\n  }\n  return false;\n});\n/**\n * @since 2.0.0\n * @category numeric\n */\nexport const decrement = self => update(self, n => n - 1);\n/**\n * @since 2.0.0\n * @category numeric\n */\nexport const decrementAndGet = self => updateAndGet(self, n => n - 1);\n/**\n * @since 2.0.0\n * @category general\n */\nexport const get = self => self.current;\n/**\n * @since 2.0.0\n * @category numeric\n */\nexport const getAndDecrement = self => getAndUpdate(self, n => n - 1);\n/**\n * @since 2.0.0\n * @category numeric\n */\nexport const getAndIncrement = self => getAndUpdate(self, n => n + 1);\n/**\n * @since 2.0.0\n * @category general\n */\nexport const getAndSet = /*#__PURE__*/Dual.dual(2, (self, value) => {\n  const ret = self.current;\n  self.current = value;\n  return ret;\n});\n/**\n * @since 2.0.0\n * @category general\n */\nexport const getAndUpdate = /*#__PURE__*/Dual.dual(2, (self, f) => getAndSet(self, f(get(self))));\n/**\n * @since 2.0.0\n * @category numeric\n */\nexport const increment = self => update(self, n => n + 1);\n/**\n * @since 2.0.0\n * @category numeric\n */\nexport const incrementAndGet = self => updateAndGet(self, n => n + 1);\n/**\n * @since 2.0.0\n * @category general\n */\nexport const set = /*#__PURE__*/Dual.dual(2, (self, value) => {\n  self.current = value;\n  return self;\n});\n/**\n * @since 2.0.0\n * @category general\n */\nexport const setAndGet = /*#__PURE__*/Dual.dual(2, (self, value) => {\n  self.current = value;\n  return self.current;\n});\n/**\n * @since 2.0.0\n * @category general\n */\nexport const update = /*#__PURE__*/Dual.dual(2, (self, f) => set(self, f(get(self))));\n/**\n * @since 2.0.0\n * @category general\n */\nexport const updateAndGet = /*#__PURE__*/Dual.dual(2, (self, f) => setAndGet(self, f(get(self))));\n/**\n * @since 2.0.0\n * @category boolean\n */\nexport const toggle = self => update(self, _ => !_);\n//# sourceMappingURL=MutableRef.js.map","/**\n * This module provides utility functions and type class instances for working with the `number` type in TypeScript.\n * It includes functions for basic arithmetic operations, as well as type class instances for\n * `Equivalence` and `Order`.\n *\n * @since 2.0.0\n */\nimport * as equivalence from \"./Equivalence.js\";\nimport { dual } from \"./Function.js\";\nimport * as option from \"./internal/option.js\";\nimport * as order from \"./Order.js\";\nimport * as predicate from \"./Predicate.js\";\n/**\n * Tests if a value is a `number`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isNumber } from \"effect/Number\"\n *\n * assert.deepStrictEqual(isNumber(2), true)\n * assert.deepStrictEqual(isNumber(\"2\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNumber = predicate.isNumber;\n/**\n * Provides an addition operation on `number`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { sum } from \"effect/Number\"\n *\n * assert.deepStrictEqual(sum(2, 3), 5)\n *\n * @category math\n * @since 2.0.0\n */\nexport const sum = /*#__PURE__*/dual(2, (self, that) => self + that);\n/**\n * Provides a multiplication operation on `number`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { multiply } from \"effect/Number\"\n *\n * assert.deepStrictEqual(multiply(2, 3), 6)\n *\n * @category math\n * @since 2.0.0\n */\nexport const multiply = /*#__PURE__*/dual(2, (self, that) => self * that);\n/**\n * Provides a subtraction operation on `number`s.\n *\n * @param self - The first operand.\n * @param that - The second operand.\n *\n * @example\n * import { subtract } from \"effect/Number\"\n *\n * assert.deepStrictEqual(subtract(2, 3), -1)\n *\n * @category math\n * @since 2.0.0\n */\nexport const subtract = /*#__PURE__*/dual(2, (self, that) => self - that);\n/**\n * Provides a division operation on `number`s.\n *\n * @param self - The dividend operand.\n * @param that - The divisor operand.\n *\n * @example\n * import { Number, Option } from \"effect\"\n *\n * assert.deepStrictEqual(Number.divide(6, 3), Option.some(2))\n * assert.deepStrictEqual(Number.divide(6, 0), Option.none())\n *\n * @category math\n * @since 2.0.0\n */\nexport const divide = /*#__PURE__*/dual(2, (self, that) => that === 0 ? option.none : option.some(self / that));\n/**\n * Provides a division operation on `number`s.\n *\n * Throws a `RangeError` if the divisor is `0`.\n *\n * @param self - The dividend operand.\n * @param that - The divisor operand.\n *\n * @example\n * import { unsafeDivide } from \"effect/Number\"\n *\n * assert.deepStrictEqual(unsafeDivide(6, 3), 2)\n *\n * @category math\n * @since 2.0.0\n */\nexport const unsafeDivide = /*#__PURE__*/dual(2, (self, that) => self / that);\n/**\n * Returns the result of adding `1` to a given number.\n *\n * @param n - A `number` to be incremented.\n *\n * @example\n * import { increment } from \"effect/Number\"\n *\n * assert.deepStrictEqual(increment(2), 3)\n *\n * @category math\n * @since 2.0.0\n */\nexport const increment = n => n + 1;\n/**\n * Decrements a number by `1`.\n *\n * @param n - A `number` to be decremented.\n *\n * @example\n * import { decrement } from \"effect/Number\"\n *\n * assert.deepStrictEqual(decrement(3), 2)\n *\n * @category math\n * @since 2.0.0\n */\nexport const decrement = n => n - 1;\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Equivalence = equivalence.number;\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Order = order.number;\n/**\n * Returns `true` if the first argument is less than the second, otherwise `false`.\n *\n * @param self - The first argument.\n * @param that - The second argument.\n *\n * @example\n * import { lessThan } from \"effect/Number\"\n *\n * assert.deepStrictEqual(lessThan(2, 3), true)\n * assert.deepStrictEqual(lessThan(3, 3), false)\n * assert.deepStrictEqual(lessThan(4, 3), false)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const lessThan = /*#__PURE__*/order.lessThan(Order);\n/**\n * Returns a function that checks if a given `number` is less than or equal to the provided one.\n *\n * @param self - The first `number` to compare with.\n * @param that - The second `number` to compare with.\n *\n * @example\n * import { lessThanOrEqualTo } from \"effect/Number\"\n *\n * assert.deepStrictEqual(lessThanOrEqualTo(2, 3), true)\n * assert.deepStrictEqual(lessThanOrEqualTo(3, 3), true)\n * assert.deepStrictEqual(lessThanOrEqualTo(4, 3), false)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const lessThanOrEqualTo = /*#__PURE__*/order.lessThanOrEqualTo(Order);\n/**\n * Returns `true` if the first argument is greater than the second, otherwise `false`.\n *\n * @param self - The first argument.\n * @param that - The second argument.\n *\n * @example\n * import { greaterThan } from \"effect/Number\"\n *\n * assert.deepStrictEqual(greaterThan(2, 3), false)\n * assert.deepStrictEqual(greaterThan(3, 3), false)\n * assert.deepStrictEqual(greaterThan(4, 3), true)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const greaterThan = /*#__PURE__*/order.greaterThan(Order);\n/**\n * Returns a function that checks if a given `number` is greater than or equal to the provided one.\n *\n * @param self - The first `number` to compare with.\n * @param that - The second `number` to compare with.\n *\n * @example\n * import { greaterThanOrEqualTo } from \"effect/Number\"\n *\n * assert.deepStrictEqual(greaterThanOrEqualTo(2, 3), false)\n * assert.deepStrictEqual(greaterThanOrEqualTo(3, 3), true)\n * assert.deepStrictEqual(greaterThanOrEqualTo(4, 3), true)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const greaterThanOrEqualTo = /*#__PURE__*/order.greaterThanOrEqualTo(Order);\n/**\n * Checks if a `number` is between a `minimum` and `maximum` value (inclusive).\n *\n * @param self - The `number` to check.\n * @param minimum - The `minimum` value to check.\n * @param maximum - The `maximum` value to check.\n *\n * @example\n * import { Number } from \"effect\"\n *\n * const between = Number.between({ minimum: 0, maximum: 5 })\n *\n * assert.deepStrictEqual(between(3), true)\n * assert.deepStrictEqual(between(-1), false)\n * assert.deepStrictEqual(between(6), false)\n *\n * @category predicates\n * @since 2.0.0\n */\nexport const between = /*#__PURE__*/order.between(Order);\n/**\n * Restricts the given `number` to be within the range specified by the `minimum` and `maximum` values.\n *\n * - If the `number` is less than the `minimum` value, the function returns the `minimum` value.\n * - If the `number` is greater than the `maximum` value, the function returns the `maximum` value.\n * - Otherwise, it returns the original `number`.\n *\n * @param self - The `number` to be clamped.\n * @param minimum - The lower end of the range.\n * @param maximum - The upper end of the range.\n *\n * @example\n * import { Number } from \"effect\"\n *\n * const clamp = Number.clamp({ minimum: 1, maximum: 5 })\n *\n * assert.equal(clamp(3), 3)\n * assert.equal(clamp(0), 1)\n * assert.equal(clamp(6), 5)\n *\n * @since 2.0.0\n */\nexport const clamp = /*#__PURE__*/order.clamp(Order);\n/**\n * Returns the minimum between two `number`s.\n *\n * @param self - The first `number`.\n * @param that - The second `number`.\n *\n * @example\n * import { min } from \"effect/Number\"\n *\n * assert.deepStrictEqual(min(2, 3), 2)\n *\n * @since 2.0.0\n */\nexport const min = /*#__PURE__*/order.min(Order);\n/**\n * Returns the maximum between two `number`s.\n *\n * @param self - The first `number`.\n * @param that - The second `number`.\n *\n * @example\n * import { max } from \"effect/Number\"\n *\n * assert.deepStrictEqual(max(2, 3), 3)\n *\n * @since 2.0.0\n */\nexport const max = /*#__PURE__*/order.max(Order);\n/**\n * Determines the sign of a given `number`.\n *\n * @param n - The `number` to determine the sign of.\n *\n * @example\n * import { sign } from \"effect/Number\"\n *\n * assert.deepStrictEqual(sign(-5), -1)\n * assert.deepStrictEqual(sign(0), 0)\n * assert.deepStrictEqual(sign(5), 1)\n *\n * @category math\n * @since 2.0.0\n */\nexport const sign = n => Order(n, 0);\n/**\n * Takes an `Iterable` of `number`s and returns their sum as a single `number`.\n *\n * @param collection - The collection of `number`s to sum.\n *\n * @example\n * import { sumAll } from \"effect/Number\"\n *\n * assert.deepStrictEqual(sumAll([2, 3, 4]), 9)\n *\n * @category math\n * @since 2.0.0\n */\nexport const sumAll = collection => {\n  let out = 0;\n  for (const n of collection) {\n    out += n;\n  }\n  return out;\n};\n/**\n * Takes an `Iterable` of `number`s and returns their multiplication as a single `number`.\n *\n * @param collection - The collection of `number`s to multiply.\n *\n * @example\n * import { multiplyAll } from \"effect/Number\"\n *\n * assert.deepStrictEqual(multiplyAll([2, 3, 4]), 24)\n *\n * @category math\n * @since 2.0.0\n */\nexport const multiplyAll = collection => {\n  let out = 1;\n  for (const n of collection) {\n    if (n === 0) {\n      return 0;\n    }\n    out *= n;\n  }\n  return out;\n};\n/**\n * Returns the remainder left over when one operand is divided by a second operand.\n *\n * It always takes the sign of the dividend.\n *\n * @param self - The dividend.\n * @param divisor - The divisor.\n *\n * @example\n * import { remainder } from \"effect/Number\"\n *\n * assert.deepStrictEqual(remainder(2, 2), 0)\n * assert.deepStrictEqual(remainder(3, 2), 1)\n * assert.deepStrictEqual(remainder(-4, 2), -0)\n *\n * @category math\n * @since 2.0.0\n */\nexport const remainder = /*#__PURE__*/dual(2, (self, divisor) => {\n  // https://stackoverflow.com/questions/3966484/why-does-modulus-operator-return-fractional-number-in-javascript/31711034#31711034\n  const selfDecCount = (self.toString().split(\".\")[1] || \"\").length;\n  const divisorDecCount = (divisor.toString().split(\".\")[1] || \"\").length;\n  const decCount = selfDecCount > divisorDecCount ? selfDecCount : divisorDecCount;\n  const selfInt = parseInt(self.toFixed(decCount).replace(\".\", \"\"));\n  const divisorInt = parseInt(divisor.toFixed(decCount).replace(\".\", \"\"));\n  return selfInt % divisorInt / Math.pow(10, decCount);\n});\n/**\n * Returns the next power of 2 from the given number.\n *\n * @param self - The number to find the next power of 2 from.\n *\n * @example\n * import { nextPow2 } from \"effect/Number\"\n *\n * assert.deepStrictEqual(nextPow2(5), 8)\n * assert.deepStrictEqual(nextPow2(17), 32)\n *\n * @category math\n * @since 2.0.0\n */\nexport const nextPow2 = n => {\n  const nextPow = Math.ceil(Math.log(n) / Math.log(2));\n  return Math.max(Math.pow(2, nextPow), 2);\n};\n/**\n * Tries to parse a `number` from a `string` using the `Number()` function.\n * The following special string values are supported: \"NaN\", \"Infinity\", \"-Infinity\".\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const parse = s => {\n  if (s === \"NaN\") {\n    return option.some(NaN);\n  }\n  if (s === \"Infinity\") {\n    return option.some(Infinity);\n  }\n  if (s === \"-Infinity\") {\n    return option.some(-Infinity);\n  }\n  if (s.trim() === \"\") {\n    return option.none;\n  }\n  const n = Number(s);\n  return Number.isNaN(n) ? option.none : option.some(n);\n};\n//# sourceMappingURL=Number.js.map","import * as Equal from \"./Equal.js\";\nimport * as Equivalence from \"./Equivalence.js\";\nimport { constNull, constUndefined, dual, identity, isFunction } from \"./Function.js\";\nimport * as doNotation from \"./internal/doNotation.js\";\nimport * as either from \"./internal/either.js\";\nimport * as option from \"./internal/option.js\";\nimport * as order from \"./Order.js\";\nimport * as Gen from \"./Utils.js\";\n/**\n * @category symbols\n * @since 2.0.0\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/Option\");\n/**\n * Creates a new `Option` that represents the absence of a value.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const none = () => option.none;\n/**\n * Creates a new `Option` that wraps the given value.\n *\n * @param value - The value to wrap.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const some = option.some;\n/**\n * Tests if a value is a `Option`.\n *\n * @param input - The value to check.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.isOption(Option.some(1)), true)\n * assert.deepStrictEqual(Option.isOption(Option.none()), true)\n * assert.deepStrictEqual(Option.isOption({}), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isOption = option.isOption;\n/**\n * Determine if a `Option` is a `None`.\n *\n * @param self - The `Option` to check.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.isNone(Option.some(1)), false)\n * assert.deepStrictEqual(Option.isNone(Option.none()), true)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNone = option.isNone;\n/**\n * Determine if a `Option` is a `Some`.\n *\n * @param self - The `Option` to check.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.isSome(Option.some(1)), true)\n * assert.deepStrictEqual(Option.isSome(Option.none()), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isSome = option.isSome;\n/**\n * Matches the given `Option` and returns either the provided `onNone` value or the result of the provided `onSome`\n * function when passed the `Option`'s value.\n *\n * @param self - The `Option` to match\n * @param onNone - The value to be returned if the `Option` is `None`\n * @param onSome - The function to be called if the `Option` is `Some`, it will be passed the `Option`'s value and its result will be returned\n *\n * @example\n * import { pipe, Option } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   pipe(Option.some(1), Option.match({ onNone: () => 'a none', onSome: (a) => `a some containing ${a}` })),\n *   'a some containing 1'\n * )\n *\n * assert.deepStrictEqual(\n *   pipe(Option.none(), Option.match({ onNone: () => 'a none', onSome: (a) => `a some containing ${a}` })),\n *   'a none'\n * )\n *\n * @category pattern matching\n * @since 2.0.0\n */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onNone,\n  onSome\n}) => isNone(self) ? onNone() : onSome(self.value));\n/**\n * Returns a type guard from a `Option` returning function.\n * This function ensures that a type guard definition is type-safe.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * const parsePositive = (n: number): Option.Option<number> =>\n *   n > 0 ? Option.some(n) : Option.none()\n *\n * const isPositive = Option.toRefinement(parsePositive)\n *\n * assert.deepStrictEqual(isPositive(1), true)\n * assert.deepStrictEqual(isPositive(-1), false)\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const toRefinement = f => a => isSome(f(a));\n/**\n * Converts an `Iterable` of values into an `Option`. Returns the first value of the `Iterable` wrapped in a `Some`\n * if the `Iterable` is not empty, otherwise returns `None`.\n *\n * @param collection - The `Iterable` to be converted to an `Option`.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.fromIterable([1, 2, 3]), Option.some(1))\n * assert.deepStrictEqual(Option.fromIterable([]), Option.none())\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const fromIterable = collection => {\n  for (const a of collection) {\n    return some(a);\n  }\n  return none();\n};\n/**\n * Converts a `Either` to an `Option` discarding the error.\n *\n * Alias of {@link fromEither}.\n *\n * @example\n * import { Option, Either } from \"effect\"\n *\n * assert.deepStrictEqual(Option.getRight(Either.right('ok')), Option.some('ok'))\n * assert.deepStrictEqual(Option.getRight(Either.left('err')), Option.none())\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const getRight = either.getRight;\n/**\n * Converts a `Either` to an `Option` discarding the value.\n *\n * @example\n * import { Option, Either } from \"effect\"\n *\n * assert.deepStrictEqual(Option.getLeft(Either.right(\"ok\")), Option.none())\n * assert.deepStrictEqual(Option.getLeft(Either.left(\"a\")), Option.some(\"a\"))\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const getLeft = either.getLeft;\n/**\n * Returns the value of the `Option` if it is `Some`, otherwise returns `onNone`\n *\n * @param self - The `Option` to get the value of.\n * @param onNone - Function that returns the default value to return if the `Option` is `None`.\n *\n * @example\n * import { pipe, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(Option.some(1), Option.getOrElse(() => 0)), 1)\n * assert.deepStrictEqual(pipe(Option.none(), Option.getOrElse(() => 0)), 0)\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getOrElse = /*#__PURE__*/dual(2, (self, onNone) => isNone(self) ? onNone() : self.value);\n/**\n * Returns the provided `Option` `that` if `self` is `None`, otherwise returns `self`.\n *\n * @param self - The first `Option` to be checked.\n * @param that - The `Option` to return if `self` is `None`.\n *\n * @example\n * import { pipe, Option } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   pipe(\n *     Option.none(),\n *     Option.orElse(() => Option.none())\n *   ),\n *   Option.none()\n * )\n * assert.deepStrictEqual(\n *   pipe(\n *     Option.some('a'),\n *     Option.orElse(() => Option.none())\n *   ),\n *   Option.some('a')\n * )\n * assert.deepStrictEqual(\n *   pipe(\n *     Option.none(),\n *     Option.orElse(() => Option.some('b'))\n *   ),\n *   Option.some('b')\n * )\n * assert.deepStrictEqual(\n *   pipe(\n *     Option.some('a'),\n *     Option.orElse(() => Option.some('b'))\n *   ),\n *   Option.some('a')\n * )\n *\n * @category error handling\n * @since 2.0.0\n */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => isNone(self) ? that() : self);\n/**\n * Returns the provided default value as `Some` if `self` is `None`, otherwise returns `self`.\n *\n * @param self - The first `Option` to be checked.\n * @param onNone - Function that returns the default value to return if the `Option` is `None`.\n *\n * @example\n * import { pipe, Option } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   pipe(\n *     Option.none(),\n *     Option.orElseSome(() => 'b')\n *   ),\n *   Option.some('b')\n * )\n * assert.deepStrictEqual(\n *   pipe(\n *     Option.some('a'),\n *     Option.orElseSome(() => 'b')\n *   ),\n *   Option.some('a')\n * )\n *\n * @category error handling\n * @since 2.0.0\n */\nexport const orElseSome = /*#__PURE__*/dual(2, (self, onNone) => isNone(self) ? some(onNone()) : self);\n/**\n * Similar to `orElse`, but instead of returning a simple union, it returns an `Either` object,\n * which contains information about which of the two `Option`s has been chosen.\n *\n * This is useful when it's important to know whether the value was retrieved from the first `Option` or the second option.\n *\n * @param self - The first `Option` to be checked.\n * @param that - The second `Option` to be considered if the first `Option` is `None`.\n *\n * @category error handling\n * @since 2.0.0\n */\nexport const orElseEither = /*#__PURE__*/dual(2, (self, that) => isNone(self) ? map(that(), either.right) : map(self, either.left));\n/**\n * Given an `Iterable` collection of `Option`s, returns the first `Some` found in the collection.\n *\n * @param collection - An iterable collection of `Option` to be searched.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.firstSomeOf([Option.none(), Option.some(1), Option.some(2)]), Option.some(1))\n *\n * @category error handling\n * @since 2.0.0\n */\nexport const firstSomeOf = collection => {\n  let out = none();\n  for (out of collection) {\n    if (isSome(out)) {\n      return out;\n    }\n  }\n  return out;\n};\n/**\n * Constructs a new `Option` from a nullable type. If the value is `null` or `undefined`, returns `None`, otherwise\n * returns the value wrapped in a `Some`.\n *\n * @param nullableValue - The nullable value to be converted to an `Option`.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.fromNullable(undefined), Option.none())\n * assert.deepStrictEqual(Option.fromNullable(null), Option.none())\n * assert.deepStrictEqual(Option.fromNullable(1), Option.some(1))\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const fromNullable = nullableValue => nullableValue == null ? none() : some(nullableValue);\n/**\n * This API is useful for lifting a function that returns `null` or `undefined` into the `Option` context.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * const parse = (s: string): number | undefined => {\n *   const n = parseFloat(s)\n *   return isNaN(n) ? undefined : n\n * }\n *\n * const parseOption = Option.liftNullable(parse)\n *\n * assert.deepStrictEqual(parseOption('1'), Option.some(1))\n * assert.deepStrictEqual(parseOption('not a number'), Option.none())\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const liftNullable = f => (...a) => fromNullable(f(...a));\n/**\n * Returns the value of the `Option` if it is a `Some`, otherwise returns `null`.\n *\n * @param self - The `Option` to extract the value from.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.getOrNull(Option.some(1)), 1)\n * assert.deepStrictEqual(Option.getOrNull(Option.none()), null)\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getOrNull = /*#__PURE__*/getOrElse(constNull);\n/**\n * Returns the value of the `Option` if it is a `Some`, otherwise returns `undefined`.\n *\n * @param self - The `Option` to extract the value from.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.getOrUndefined(Option.some(1)), 1)\n * assert.deepStrictEqual(Option.getOrUndefined(Option.none()), undefined)\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getOrUndefined = /*#__PURE__*/getOrElse(constUndefined);\n/**\n * A utility function that lifts a function that throws exceptions into a function that returns an `Option`.\n *\n * This function is useful for any function that might throw an exception, allowing the developer to handle\n * the exception in a more functional way.\n *\n * @param f - the function that can throw exceptions.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * const parse = Option.liftThrowable(JSON.parse)\n *\n * assert.deepStrictEqual(parse(\"1\"), Option.some(1))\n * assert.deepStrictEqual(parse(\"\"), Option.none())\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const liftThrowable = f => (...a) => {\n  try {\n    return some(f(...a));\n  } catch (e) {\n    return none();\n  }\n};\n/**\n * Extracts the value of an `Option` or throws if the `Option` is `None`.\n *\n * If a default error is sufficient for your use case and you don't need to configure the thrown error, see {@link getOrThrow}.\n *\n * @param self - The `Option` to extract the value from.\n * @param onNone - A function that will be called if the `Option` is `None`. It returns the error to be thrown.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Option.getOrThrowWith(Option.some(1), () => new Error('Unexpected None')),\n *   1\n * )\n * assert.throws(() => Option.getOrThrowWith(Option.none(), () => new Error('Unexpected None')))\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const getOrThrowWith = /*#__PURE__*/dual(2, (self, onNone) => {\n  if (isSome(self)) {\n    return self.value;\n  }\n  throw onNone();\n});\n/**\n * Extracts the value of an `Option` or throws if the `Option` is `None`.\n *\n * The thrown error is a default error. To configure the error thrown, see  {@link getOrThrowWith}.\n *\n * @param self - The `Option` to extract the value from.\n * @throws `Error(\"getOrThrow called on a None\")`\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.getOrThrow(Option.some(1)), 1)\n * assert.throws(() => Option.getOrThrow(Option.none()))\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const getOrThrow = /*#__PURE__*/getOrThrowWith(() => new Error(\"getOrThrow called on a None\"));\n/**\n * Maps the `Some` side of an `Option` value to a new `Option` value.\n *\n * @param self - An `Option` to map\n * @param f - The function to map over the value of the `Option`\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => isNone(self) ? none() : some(f(self.value)));\n/**\n * Maps the `Some` value of this `Option` to the specified constant value.\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const as = /*#__PURE__*/dual(2, (self, b) => map(self, () => b));\n/**\n * Maps the `Some` value of this `Option` to the `void` constant value.\n *\n * This is useful when the value of the `Option` is not needed, but the presence or absence of the value is important.\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const asVoid = /*#__PURE__*/as(undefined);\nconst void_ = /*#__PURE__*/some(undefined);\nexport {\n/**\n * @since 2.0.0\n */\nvoid_ as void };\n/**\n * Applies a function to the value of an `Option` and flattens the result, if the input is `Some`.\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => isNone(self) ? none() : f(self.value));\n/**\n * Executes a sequence of two `Option`s. The second `Option` can be dependent on the result of the first `Option`.\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const andThen = /*#__PURE__*/dual(2, (self, f) => flatMap(self, a => {\n  const b = isFunction(f) ? f(a) : f;\n  return isOption(b) ? b : some(b);\n}));\n/**\n * This is `flatMap` + `fromNullable`, useful when working with optional values.\n *\n * @example\n * import { pipe, Option } from \"effect\"\n *\n * interface Employee {\n *   company?: {\n *     address?: {\n *       street?: {\n *         name?: string\n *       }\n *     }\n *   }\n * }\n *\n * const employee1: Employee = { company: { address: { street: { name: 'high street' } } } }\n *\n * assert.deepStrictEqual(\n *   pipe(\n *     Option.some(employee1),\n *     Option.flatMapNullable(employee => employee.company?.address?.street?.name),\n *   ),\n *   Option.some('high street')\n * )\n *\n * const employee2: Employee = { company: { address: { street: {} } } }\n *\n * assert.deepStrictEqual(\n *   pipe(\n *     Option.some(employee2),\n *     Option.flatMapNullable(employee => employee.company?.address?.street?.name),\n *   ),\n *   Option.none()\n * )\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatMapNullable = /*#__PURE__*/dual(2, (self, f) => isNone(self) ? none() : fromNullable(f(self.value)));\n/**\n * @category sequencing\n * @since 2.0.0\n */\nexport const flatten = /*#__PURE__*/flatMap(identity);\n/**\n * @category zipping\n * @since 2.0.0\n */\nexport const zipRight = /*#__PURE__*/dual(2, (self, that) => flatMap(self, () => that));\n/**\n * @category sequencing\n * @since 2.0.0\n */\nexport const composeK = /*#__PURE__*/dual(2, (afb, bfc) => a => flatMap(afb(a), bfc));\n/**\n * Sequences the specified `that` `Option` but ignores its value.\n *\n * It is useful when we want to chain multiple operations, but only care about the result of `self`.\n *\n * @param that - The `Option` that will be ignored in the chain and discarded\n * @param self - The `Option` we care about\n *\n * @category zipping\n * @since 2.0.0\n */\nexport const zipLeft = /*#__PURE__*/dual(2, (self, that) => tap(self, () => that));\n/**\n * Applies the provided function `f` to the value of the `Option` if it is `Some` and returns the original `Option`\n * unless `f` returns `None`, in which case it returns `None`.\n *\n * This function is useful for performing additional computations on the value of the input `Option` without affecting its value.\n *\n * @param f - Function to apply to the value of the `Option` if it is `Some`\n * @param self - The `Option` to apply the function to\n *\n * @example\n * import { Option } from \"effect\"\n *\n * const getInteger = (n: number) => Number.isInteger(n) ? Option.some(n) : Option.none()\n *\n * assert.deepStrictEqual(Option.tap(Option.none(), getInteger), Option.none())\n * assert.deepStrictEqual(Option.tap(Option.some(1), getInteger), Option.some(1))\n * assert.deepStrictEqual(Option.tap(Option.some(1.14), getInteger), Option.none())\n *\n * @category sequencing\n * @since 2.0.0\n */\nexport const tap = /*#__PURE__*/dual(2, (self, f) => flatMap(self, a => map(f(a), () => a)));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const product = (self, that) => isSome(self) && isSome(that) ? some([self.value, that.value]) : none();\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const productMany = (self, collection) => {\n  if (isNone(self)) {\n    return none();\n  }\n  const out = [self.value];\n  for (const o of collection) {\n    if (isNone(o)) {\n      return none();\n    }\n    out.push(o.value);\n  }\n  return some(out);\n};\n/**\n * Takes a structure of `Option`s and returns an `Option` of values with the same structure.\n *\n * - If a tuple is supplied, then the returned `Option` will contain a tuple with the same length.\n * - If a struct is supplied, then the returned `Option` will contain a struct with the same keys.\n * - If an iterable is supplied, then the returned `Option` will contain an array.\n *\n * @param fields - the struct of `Option`s to be sequenced.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.all([Option.some(1), Option.some(2)]), Option.some([1, 2]))\n * assert.deepStrictEqual(Option.all({ a: Option.some(1), b: Option.some(\"hello\") }), Option.some({ a: 1, b: \"hello\" }))\n * assert.deepStrictEqual(Option.all({ a: Option.some(1), b: Option.none() }), Option.none())\n *\n * @category combining\n * @since 2.0.0\n */\n// @ts-expect-error\nexport const all = input => {\n  if (Symbol.iterator in input) {\n    const out = [];\n    for (const o of input) {\n      if (isNone(o)) {\n        return none();\n      }\n      out.push(o.value);\n    }\n    return some(out);\n  }\n  const out = {};\n  for (const key of Object.keys(input)) {\n    const o = input[key];\n    if (isNone(o)) {\n      return none();\n    }\n    out[key] = o.value;\n  }\n  return some(out);\n};\n/**\n * Zips two `Option` values together using a provided function, returning a new `Option` of the result.\n *\n * @param self - The left-hand side of the zip operation\n * @param that - The right-hand side of the zip operation\n * @param f - The function used to combine the values of the two `Option`s\n *\n * @example\n * import { Option } from \"effect\"\n *\n * type Complex = [real: number, imaginary: number]\n *\n * const complex = (real: number, imaginary: number): Complex => [real, imaginary]\n *\n * assert.deepStrictEqual(Option.zipWith(Option.none(), Option.none(), complex), Option.none())\n * assert.deepStrictEqual(Option.zipWith(Option.some(1), Option.none(), complex), Option.none())\n * assert.deepStrictEqual(Option.zipWith(Option.none(), Option.some(1), complex), Option.none())\n * assert.deepStrictEqual(Option.zipWith(Option.some(1), Option.some(2), complex), Option.some([1, 2]))\n *\n * assert.deepStrictEqual(Option.zipWith(Option.some(1), complex)(Option.some(2)), Option.some([2, 1]))\n *\n * @category zipping\n * @since 2.0.0\n */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => map(product(self, that), ([a, b]) => f(a, b)));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const ap = /*#__PURE__*/dual(2, (self, that) => zipWith(self, that, (f, a) => f(a)));\n/**\n * Reduces an `Iterable` of `Option<A>` to a single value of type `B`, elements that are `None` are ignored.\n *\n * @param self - The Iterable of `Option<A>` to be reduced.\n * @param b - The initial value of the accumulator.\n * @param f - The reducing function that takes the current accumulator value and the unwrapped value of an `Option<A>`.\n *\n * @example\n * import { pipe, Option } from \"effect\"\n *\n * const iterable = [Option.some(1), Option.none(), Option.some(2), Option.none()]\n * assert.deepStrictEqual(pipe(iterable, Option.reduceCompact(0, (b, a) => b + a)), 3)\n *\n * @category folding\n * @since 2.0.0\n */\nexport const reduceCompact = /*#__PURE__*/dual(3, (self, b, f) => {\n  let out = b;\n  for (const oa of self) {\n    if (isSome(oa)) {\n      out = f(out, oa.value);\n    }\n  }\n  return out;\n});\n/**\n * Transforms an `Option` into an `Array`.\n * If the input is `None`, an empty array is returned.\n * If the input is `Some`, the value is wrapped in an array.\n *\n * @param self - The `Option` to convert to an array.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * assert.deepStrictEqual(Option.toArray(Option.some(1)), [1])\n * assert.deepStrictEqual(Option.toArray(Option.none()), [])\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const toArray = self => isNone(self) ? [] : [self.value];\n/**\n * @category filtering\n * @since 2.0.0\n */\nexport const partitionMap = /*#__PURE__*/dual(2, (self, f) => {\n  if (isNone(self)) {\n    return [none(), none()];\n  }\n  const e = f(self.value);\n  return either.isLeft(e) ? [some(e.left), none()] : [none(), some(e.right)];\n});\n/**\n * Maps over the value of an `Option` and filters out `None`s.\n *\n * Useful when in addition to filtering you also want to change the type of the `Option`.\n *\n * @param self - The `Option` to map over.\n * @param f - A function to apply to the value of the `Option`.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * const evenNumber = (n: number) => n % 2 === 0 ? Option.some(n) : Option.none()\n *\n * assert.deepStrictEqual(Option.filterMap(Option.none(), evenNumber), Option.none())\n * assert.deepStrictEqual(Option.filterMap(Option.some(3), evenNumber), Option.none())\n * assert.deepStrictEqual(Option.filterMap(Option.some(2), evenNumber), Option.some(2))\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const filterMap = /*#__PURE__*/dual(2, (self, f) => isNone(self) ? none() : f(self.value));\n/**\n * Filters an `Option` using a predicate. If the predicate is not satisfied or the `Option` is `None` returns `None`.\n *\n * If you need to change the type of the `Option` in addition to filtering, see `filterMap`.\n *\n * @param predicate - A predicate function to apply to the `Option` value.\n * @param fb - The `Option` to filter.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * // predicate\n * const isEven = (n: number) => n % 2 === 0\n *\n * assert.deepStrictEqual(Option.filter(Option.none(), isEven), Option.none())\n * assert.deepStrictEqual(Option.filter(Option.some(3), isEven), Option.none())\n * assert.deepStrictEqual(Option.filter(Option.some(2), isEven), Option.some(2))\n *\n * // refinement\n * const isNumber = (v: unknown): v is number => typeof v === \"number\"\n *\n * assert.deepStrictEqual(Option.filter(Option.none(), isNumber), Option.none())\n * assert.deepStrictEqual(Option.filter(Option.some('hello'), isNumber), Option.none())\n * assert.deepStrictEqual(Option.filter(Option.some(2), isNumber), Option.some(2))\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => filterMap(self, b => predicate(b) ? option.some(b) : option.none));\n/**\n * @example\n * import { Option, Number } from \"effect\"\n *\n * const isEquivalent = Option.getEquivalence(Number.Equivalence)\n * assert.deepStrictEqual(isEquivalent(Option.none(), Option.none()), true)\n * assert.deepStrictEqual(isEquivalent(Option.none(), Option.some(1)), false)\n * assert.deepStrictEqual(isEquivalent(Option.some(1), Option.none()), false)\n * assert.deepStrictEqual(isEquivalent(Option.some(1), Option.some(2)), false)\n * assert.deepStrictEqual(isEquivalent(Option.some(1), Option.some(1)), true)\n *\n * @category equivalence\n * @since 2.0.0\n */\nexport const getEquivalence = isEquivalent => Equivalence.make((x, y) => isNone(x) ? isNone(y) : isNone(y) ? false : isEquivalent(x.value, y.value));\n/**\n * The `Order` instance allows `Option` values to be compared with\n * `compare`, whenever there is an `Order` instance for\n * the type the `Option` contains.\n *\n * `None` is considered to be less than any `Some` value.\n *\n * @example\n * import { pipe, Option, Number } from \"effect\"\n *\n * const O = Option.getOrder(Number.Order)\n * assert.deepStrictEqual(O(Option.none(), Option.none()), 0)\n * assert.deepStrictEqual(O(Option.none(), Option.some(1)), -1)\n * assert.deepStrictEqual(O(Option.some(1), Option.none()), 1)\n * assert.deepStrictEqual(O(Option.some(1), Option.some(2)), -1)\n * assert.deepStrictEqual(O(Option.some(1), Option.some(1)), 0)\n *\n * @category sorting\n * @since 2.0.0\n */\nexport const getOrder = O => order.make((self, that) => isSome(self) ? isSome(that) ? O(self.value, that.value) : 1 : -1);\n/**\n * Lifts a binary function into `Option`.\n *\n * @param f - The function to lift.\n *\n * @category lifting\n * @since 2.0.0\n */\nexport const lift2 = f => dual(2, (self, that) => zipWith(self, that, f));\n/**\n * Transforms a `Predicate` function into a `Some` of the input value if the predicate returns `true` or `None`\n * if the predicate returns `false`.\n *\n * @param predicate - A `Predicate` function that takes in a value of type `A` and returns a boolean.\n *\n * @example\n * import { Option } from \"effect\"\n *\n * const getOption = Option.liftPredicate((n: number) => n >= 0)\n *\n * assert.deepStrictEqual(getOption(-1), Option.none())\n * assert.deepStrictEqual(getOption(1), Option.some(1))\n *\n * @category lifting\n * @since 2.0.0\n */\nexport const liftPredicate = /*#__PURE__*/dual(2, (b, predicate) => predicate(b) ? some(b) : none());\n/**\n * Returns a function that checks if a `Option` contains a given value using a provided `isEquivalent` function.\n *\n * @param equivalent - An `Equivalence` instance to compare values of the `Option`.\n * @param self - The `Option` to apply the comparison to.\n * @param a - The value to compare against the `Option`.\n *\n * @example\n * import { pipe, Option, Number } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(Option.some(2), Option.containsWith(Number.Equivalence)(2)), true)\n * assert.deepStrictEqual(pipe(Option.some(1), Option.containsWith(Number.Equivalence)(2)), false)\n * assert.deepStrictEqual(pipe(Option.none(), Option.containsWith(Number.Equivalence)(2)), false)\n *\n * @category elements\n * @since 2.0.0\n */\nexport const containsWith = isEquivalent => dual(2, (self, a) => isNone(self) ? false : isEquivalent(self.value, a));\nconst _equivalence = /*#__PURE__*/Equal.equivalence();\n/**\n * Returns a function that checks if an `Option` contains a given value using the default `Equivalence`.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const contains = /*#__PURE__*/containsWith(_equivalence);\n/**\n * Check if a value in an `Option` type meets a certain predicate.\n *\n * @param self - The `Option` to check.\n * @param predicate - The condition to check.\n *\n * @example\n * import { pipe, Option } from \"effect\"\n *\n * const isEven = (n: number) => n % 2 === 0\n *\n * assert.deepStrictEqual(pipe(Option.some(2), Option.exists(isEven)), true)\n * assert.deepStrictEqual(pipe(Option.some(1), Option.exists(isEven)), false)\n * assert.deepStrictEqual(pipe(Option.none(), Option.exists(isEven)), false)\n *\n * @since 2.0.0\n */\nexport const exists = /*#__PURE__*/dual(2, (self, refinement) => isNone(self) ? false : refinement(self.value));\n// -------------------------------------------------------------------------------------\n// do notation\n// -------------------------------------------------------------------------------------\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Option` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n * 5. Regular `Option` functions like `map` and `filter` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope\n *\n * @see {@link Do}\n * @see {@link bind}\n * @see {@link let_ let}\n *\n * @example\n * import { Option, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Option.Do,\n *   Option.bind(\"x\", () => Option.some(2)),\n *   Option.bind(\"y\", () => Option.some(3)),\n *   Option.let(\"sum\", ({ x, y }) => x + y),\n *   Option.filter(({ x, y }) => x * y > 5)\n * )\n * assert.deepStrictEqual(result, Option.some({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bindTo = /*#__PURE__*/doNotation.bindTo(map);\nconst let_ = /*#__PURE__*/doNotation.let_(map);\nexport {\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Option` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n * 5. Regular `Option` functions like `map` and `filter` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope\n *\n * @see {@link Do}\n * @see {@link bind}\n * @see {@link bindTo}\n *\n * @example\n * import { Option, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Option.Do,\n *   Option.bind(\"x\", () => Option.some(2)),\n *   Option.bind(\"y\", () => Option.some(3)),\n *   Option.let(\"sum\", ({ x, y }) => x + y),\n *   Option.filter(({ x, y }) => x * y > 5)\n * )\n * assert.deepStrictEqual(result, Option.some({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nlet_ as let };\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Option` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n * 5. Regular `Option` functions like `map` and `filter` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link let_ let}\n *\n * @example\n * import { Option, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Option.Do,\n *   Option.bind(\"x\", () => Option.some(2)),\n *   Option.bind(\"y\", () => Option.some(3)),\n *   Option.let(\"sum\", ({ x, y }) => x + y),\n *   Option.filter(({ x, y }) => x * y > 5)\n * )\n * assert.deepStrictEqual(result, Option.some({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bind = /*#__PURE__*/doNotation.bind(map, flatMap);\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Option` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n * 5. Regular `Option` functions like `map` and `filter` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope\n *\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link let_ let}\n *\n * @example\n * import { Option, pipe } from \"effect\"\n *\n * const result = pipe(\n *   Option.Do,\n *   Option.bind(\"x\", () => Option.some(2)),\n *   Option.bind(\"y\", () => Option.some(3)),\n *   Option.let(\"sum\", ({ x, y }) => x + y),\n *   Option.filter(({ x, y }) => x * y > 5)\n * )\n * assert.deepStrictEqual(result, Option.some({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const Do = /*#__PURE__*/some({});\nconst adapter = /*#__PURE__*/Gen.adapter();\n/**\n * @category generators\n * @since 2.0.0\n */\nexport const gen = (...args) => {\n  let f;\n  if (args.length === 1) {\n    f = args[0];\n  } else {\n    f = args[1].bind(args[0]);\n  }\n  const iterator = f(adapter);\n  let state = iterator.next();\n  if (state.done) {\n    return some(state.value);\n  } else {\n    let current = state.value;\n    if (Gen.isGenKind(current)) {\n      current = current.value;\n    } else {\n      current = Gen.yieldWrapGet(current);\n    }\n    if (isNone(current)) {\n      return current;\n    }\n    while (!state.done) {\n      state = iterator.next(current.value);\n      if (!state.done) {\n        current = state.value;\n        if (Gen.isGenKind(current)) {\n          current = current.value;\n        } else {\n          current = Gen.yieldWrapGet(current);\n        }\n        if (isNone(current)) {\n          return current;\n        }\n      }\n    }\n    return some(state.value);\n  }\n};\n//# sourceMappingURL=Option.js.map","/**\n * This module provides an implementation of the `Order` type class which is used to define a total ordering on some type `A`.\n * An order is defined by a relation `<=`, which obeys the following laws:\n *\n * - either `x <= y` or `y <= x` (totality)\n * - if `x <= y` and `y <= x`, then `x == y` (antisymmetry)\n * - if `x <= y` and `y <= z`, then `x <= z` (transitivity)\n *\n * The truth table for compare is defined as follows:\n *\n * | `x <= y` | `x >= y` | Ordering |                       |\n * | -------- | -------- | -------- | --------------------- |\n * | `true`   | `true`   | `0`      | corresponds to x == y |\n * | `true`   | `false`  | `< 0`    | corresponds to x < y  |\n * | `false`  | `true`   | `> 0`    | corresponds to x > y  |\n *\n * @since 2.0.0\n */\nimport { dual } from \"./Function.js\";\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const make = compare => (self, that) => self === that ? 0 : compare(self, that);\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const string = /*#__PURE__*/make((self, that) => self < that ? -1 : 1);\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const number = /*#__PURE__*/make((self, that) => self < that ? -1 : 1);\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const boolean = /*#__PURE__*/make((self, that) => self < that ? -1 : 1);\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const bigint = /*#__PURE__*/make((self, that) => self < that ? -1 : 1);\n/**\n * @since 2.0.0\n */\nexport const reverse = O => make((self, that) => O(that, self));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const combine = /*#__PURE__*/dual(2, (self, that) => make((a1, a2) => {\n  const out = self(a1, a2);\n  if (out !== 0) {\n    return out;\n  }\n  return that(a1, a2);\n}));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const combineMany = /*#__PURE__*/dual(2, (self, collection) => make((a1, a2) => {\n  let out = self(a1, a2);\n  if (out !== 0) {\n    return out;\n  }\n  for (const O of collection) {\n    out = O(a1, a2);\n    if (out !== 0) {\n      return out;\n    }\n  }\n  return out;\n}));\n/**\n * @since 2.0.0\n */\nexport const empty = () => make(() => 0);\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const combineAll = collection => combineMany(empty(), collection);\n/**\n * @category mapping\n * @since 2.0.0\n */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => make((b1, b2) => self(f(b1), f(b2))));\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Date = /*#__PURE__*/mapInput(number, date => date.getTime());\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const product = /*#__PURE__*/dual(2, (self, that) => make(([xa, xb], [ya, yb]) => {\n  const o = self(xa, ya);\n  return o !== 0 ? o : that(xb, yb);\n}));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const all = collection => {\n  return make((x, y) => {\n    const len = Math.min(x.length, y.length);\n    let collectionLength = 0;\n    for (const O of collection) {\n      if (collectionLength >= len) {\n        break;\n      }\n      const o = O(x[collectionLength], y[collectionLength]);\n      if (o !== 0) {\n        return o;\n      }\n      collectionLength++;\n    }\n    return 0;\n  });\n};\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const productMany = /*#__PURE__*/dual(2, (self, collection) => {\n  const O = all(collection);\n  return make((x, y) => {\n    const o = self(x[0], y[0]);\n    return o !== 0 ? o : O(x.slice(1), y.slice(1));\n  });\n});\n/**\n * Similar to `Promise.all` but operates on `Order`s.\n *\n * ```\n * [Order<A>, Order<B>, ...] -> Order<[A, B, ...]>\n * ```\n *\n * This function creates and returns a new `Order` for a tuple of values based on the given `Order`s for each element in the tuple.\n * The returned `Order` compares two tuples of the same type by applying the corresponding `Order` to each element in the tuple.\n * It is useful when you need to compare two tuples of the same type and you have a specific way of comparing each element\n * of the tuple.\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const tuple = (...elements) => all(elements);\n/**\n * This function creates and returns a new `Order` for an array of values based on a given `Order` for the elements of the array.\n * The returned `Order` compares two arrays by applying the given `Order` to each element in the arrays.\n * If all elements are equal, the arrays are then compared based on their length.\n * It is useful when you need to compare two arrays of the same type and you have a specific way of comparing each element of the array.\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const array = O => make((self, that) => {\n  const aLen = self.length;\n  const bLen = that.length;\n  const len = Math.min(aLen, bLen);\n  for (let i = 0; i < len; i++) {\n    const o = O(self[i], that[i]);\n    if (o !== 0) {\n      return o;\n    }\n  }\n  return number(aLen, bLen);\n});\n/**\n * This function creates and returns a new `Order` for a struct of values based on the given `Order`s\n * for each property in the struct.\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const struct = fields => {\n  const keys = Object.keys(fields);\n  return make((self, that) => {\n    for (const key of keys) {\n      const o = fields[key](self[key], that[key]);\n      if (o !== 0) {\n        return o;\n      }\n    }\n    return 0;\n  });\n};\n/**\n * Test whether one value is _strictly less than_ another.\n *\n * @since 2.0.0\n */\nexport const lessThan = O => dual(2, (self, that) => O(self, that) === -1);\n/**\n * Test whether one value is _strictly greater than_ another.\n *\n * @since 2.0.0\n */\nexport const greaterThan = O => dual(2, (self, that) => O(self, that) === 1);\n/**\n * Test whether one value is _non-strictly less than_ another.\n *\n * @since 2.0.0\n */\nexport const lessThanOrEqualTo = O => dual(2, (self, that) => O(self, that) !== 1);\n/**\n * Test whether one value is _non-strictly greater than_ another.\n *\n * @since 2.0.0\n */\nexport const greaterThanOrEqualTo = O => dual(2, (self, that) => O(self, that) !== -1);\n/**\n * Take the minimum of two values. If they are considered equal, the first argument is chosen.\n *\n * @since 2.0.0\n */\nexport const min = O => dual(2, (self, that) => self === that || O(self, that) < 1 ? self : that);\n/**\n * Take the maximum of two values. If they are considered equal, the first argument is chosen.\n *\n * @since 2.0.0\n */\nexport const max = O => dual(2, (self, that) => self === that || O(self, that) > -1 ? self : that);\n/**\n * Clamp a value between a minimum and a maximum.\n *\n * @example\n * import { Order, Number } from \"effect\"\n *\n * const clamp = Order.clamp(Number.Order)({ minimum: 1, maximum: 5 })\n *\n * assert.equal(clamp(3), 3)\n * assert.equal(clamp(0), 1)\n * assert.equal(clamp(6), 5)\n *\n * @since 2.0.0\n */\nexport const clamp = O => dual(2, (self, options) => min(O)(options.maximum, max(O)(options.minimum, self)));\n/**\n * Test whether a value is between a minimum and a maximum (inclusive).\n *\n * @since 2.0.0\n */\nexport const between = O => dual(2, (self, options) => !lessThan(O)(self, options.minimum) && !greaterThan(O)(self, options.maximum));\n//# sourceMappingURL=Order.js.map","/**\n * @since 2.0.0\n */\n/**\n * @since 2.0.0\n */\nexport const pipeArguments = (self, args) => {\n  switch (args.length) {\n    case 1:\n      return args[0](self);\n    case 2:\n      return args[1](args[0](self));\n    case 3:\n      return args[2](args[1](args[0](self)));\n    case 4:\n      return args[3](args[2](args[1](args[0](self))));\n    case 5:\n      return args[4](args[3](args[2](args[1](args[0](self)))));\n    case 6:\n      return args[5](args[4](args[3](args[2](args[1](args[0](self))))));\n    case 7:\n      return args[6](args[5](args[4](args[3](args[2](args[1](args[0](self)))))));\n    case 8:\n      return args[7](args[6](args[5](args[4](args[3](args[2](args[1](args[0](self))))))));\n    case 9:\n      return args[8](args[7](args[6](args[5](args[4](args[3](args[2](args[1](args[0](self)))))))));\n    default:\n      {\n        let ret = self;\n        for (let i = 0, len = args.length; i < len; i++) {\n          ret = args[i](ret);\n        }\n        return ret;\n      }\n  }\n};\n//# sourceMappingURL=Pipeable.js.map","/**\n * @since 2.0.0\n */\nimport { dual, isFunction as isFunction_ } from \"./Function.js\";\n/**\n * Given a `Predicate<A>` returns a `Predicate<B>`\n *\n * @param self - the `Predicate<A>` to be transformed to `Predicate<B>`.\n * @param f - a function to transform `B` to `A`.\n *\n * @example\n * import { Predicate, Number } from \"effect\"\n *\n * const minLength3 = Predicate.mapInput(Number.greaterThan(2), (s: string) => s.length)\n *\n * assert.deepStrictEqual(minLength3(\"a\"), false)\n * assert.deepStrictEqual(minLength3(\"aa\"), false)\n * assert.deepStrictEqual(minLength3(\"aaa\"), true)\n * assert.deepStrictEqual(minLength3(\"aaaa\"), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => b => self(f(b)));\n/**\n * Determine if an `Array` is a tuple with exactly `N` elements, narrowing down the type to `TupleOf`.\n *\n * An `Array` is considered to be a `TupleOf` if its length is exactly `N`.\n *\n * @param self - The `Array` to check.\n * @param n - The exact number of elements that the `Array` should have to be considered a `TupleOf`.\n *\n * @example\n * import { isTupleOf } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isTupleOf([1, 2, 3], 3), true);\n * assert.deepStrictEqual(isTupleOf([1, 2, 3], 2), false);\n * assert.deepStrictEqual(isTupleOf([1, 2, 3], 4), false);\n *\n * const arr: number[] = [1, 2, 3];\n * if (isTupleOf(arr, 3)) {\n *   console.log(arr);\n *   // ^? [number, number, number]\n * }\n *\n * @category guards\n * @since 3.3.0\n */\nexport const isTupleOf = /*#__PURE__*/dual(2, (self, n) => self.length === n);\n/**\n * Determine if an `Array` is a tuple with at least `N` elements, narrowing down the type to `TupleOfAtLeast`.\n *\n * An `Array` is considered to be a `TupleOfAtLeast` if its length is at least `N`.\n *\n * @param self - The `Array` to check.\n * @param n - The minimum number of elements that the `Array` should have to be considered a `TupleOfAtLeast`.\n *\n * @example\n * import { isTupleOfAtLeast } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isTupleOfAtLeast([1, 2, 3], 3), true);\n * assert.deepStrictEqual(isTupleOfAtLeast([1, 2, 3], 2), true);\n * assert.deepStrictEqual(isTupleOfAtLeast([1, 2, 3], 4), false);\n *\n * const arr: number[] = [1, 2, 3, 4];\n * if (isTupleOfAtLeast(arr, 3)) {\n *   console.log(arr);\n *   // ^? [number, number, number, ...number[]]\n * }\n *\n * @category guards\n * @since 3.3.0\n */\nexport const isTupleOfAtLeast = /*#__PURE__*/dual(2, (self, n) => self.length >= n);\n/**\n * Tests if a value is `truthy`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isTruthy } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isTruthy(1), true)\n * assert.deepStrictEqual(isTruthy(0), false)\n * assert.deepStrictEqual(isTruthy(\"\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isTruthy = input => !!input;\n/**\n * Tests if a value is a `Set`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isSet } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isSet(new Set([1, 2])), true)\n * assert.deepStrictEqual(isSet(new Set()), true)\n * assert.deepStrictEqual(isSet({}), false)\n * assert.deepStrictEqual(isSet(null), false)\n * assert.deepStrictEqual(isSet(undefined), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isSet = input => input instanceof Set;\n/**\n * Tests if a value is a `Map`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isMap } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isMap(new Map()), true)\n * assert.deepStrictEqual(isMap({}), false)\n * assert.deepStrictEqual(isMap(null), false)\n * assert.deepStrictEqual(isMap(undefined), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isMap = input => input instanceof Map;\n/**\n * Tests if a value is a `string`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isString } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isString(\"a\"), true)\n *\n * assert.deepStrictEqual(isString(1), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isString = input => typeof input === \"string\";\n/**\n * Tests if a value is a `number`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isNumber } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isNumber(2), true)\n *\n * assert.deepStrictEqual(isNumber(\"2\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNumber = input => typeof input === \"number\";\n/**\n * Tests if a value is a `boolean`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isBoolean } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isBoolean(true), true)\n *\n * assert.deepStrictEqual(isBoolean(\"true\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isBoolean = input => typeof input === \"boolean\";\n/**\n * Tests if a value is a `bigint`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isBigInt } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isBigInt(1n), true)\n *\n * assert.deepStrictEqual(isBigInt(1), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isBigInt = input => typeof input === \"bigint\";\n/**\n * Tests if a value is a `symbol`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isSymbol } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isSymbol(Symbol.for(\"a\")), true)\n *\n * assert.deepStrictEqual(isSymbol(\"a\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isSymbol = input => typeof input === \"symbol\";\n/**\n * Tests if a value is a `function`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isFunction } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isFunction(isFunction), true)\n *\n * assert.deepStrictEqual(isFunction(\"function\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isFunction = isFunction_;\n/**\n * Tests if a value is `undefined`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isUndefined } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isUndefined(undefined), true)\n *\n * assert.deepStrictEqual(isUndefined(null), false)\n * assert.deepStrictEqual(isUndefined(\"undefined\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isUndefined = input => input === undefined;\n/**\n * Tests if a value is not `undefined`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isNotUndefined } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isNotUndefined(null), true)\n * assert.deepStrictEqual(isNotUndefined(\"undefined\"), true)\n *\n * assert.deepStrictEqual(isNotUndefined(undefined), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNotUndefined = input => input !== undefined;\n/**\n * Tests if a value is `null`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isNull } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isNull(null), true)\n *\n * assert.deepStrictEqual(isNull(undefined), false)\n * assert.deepStrictEqual(isNull(\"null\"), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNull = input => input === null;\n/**\n * Tests if a value is not `null`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isNotNull } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isNotNull(undefined), true)\n * assert.deepStrictEqual(isNotNull(\"null\"), true)\n *\n * assert.deepStrictEqual(isNotNull(null), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNotNull = input => input !== null;\n/**\n * A guard that always fails.\n *\n * @param _ - The value to test.\n *\n * @example\n * import { isNever } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isNever(null), false)\n * assert.deepStrictEqual(isNever(undefined), false)\n * assert.deepStrictEqual(isNever({}), false)\n * assert.deepStrictEqual(isNever([]), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNever = _ => false;\n/**\n * A guard that always succeeds.\n *\n * @param _ - The value to test.\n *\n * @example\n * import { isUnknown } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isUnknown(null), true)\n * assert.deepStrictEqual(isUnknown(undefined), true)\n *\n * assert.deepStrictEqual(isUnknown({}), true)\n * assert.deepStrictEqual(isUnknown([]), true)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isUnknown = _ => true;\nconst isRecordOrArray = input => typeof input === \"object\" && input !== null;\n/**\n * Tests if a value is an `object`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isObject } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isObject({}), true)\n * assert.deepStrictEqual(isObject([]), true)\n *\n * assert.deepStrictEqual(isObject(null), false)\n * assert.deepStrictEqual(isObject(undefined), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isObject = input => isRecordOrArray(input) || isFunction(input);\n/**\n * Checks whether a value is an `object` containing a specified property key.\n *\n * @param property - The field to check within the object.\n * @param self - The value to examine.\n *\n * @category guards\n * @since 2.0.0\n */\nexport const hasProperty = /*#__PURE__*/dual(2, (self, property) => isObject(self) && property in self);\n/**\n * Tests if a value is an `object` with a property `_tag` that matches the given tag.\n *\n * @param input - The value to test.\n * @param tag - The tag to test for.\n *\n * @example\n * import { isTagged } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isTagged(1, \"a\"), false)\n * assert.deepStrictEqual(isTagged(null, \"a\"), false)\n * assert.deepStrictEqual(isTagged({}, \"a\"), false)\n * assert.deepStrictEqual(isTagged({ a: \"a\" }, \"a\"), false)\n * assert.deepStrictEqual(isTagged({ _tag: \"a\" }, \"a\"), true)\n * assert.deepStrictEqual(isTagged(\"a\")({ _tag: \"a\" }), true)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isTagged = /*#__PURE__*/dual(2, (self, tag) => hasProperty(self, \"_tag\") && self[\"_tag\"] === tag);\n/**\n * A guard that succeeds when the input is `null` or `undefined`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isNullable } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isNullable(null), true)\n * assert.deepStrictEqual(isNullable(undefined), true)\n *\n * assert.deepStrictEqual(isNullable({}), false)\n * assert.deepStrictEqual(isNullable([]), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNullable = input => input === null || input === undefined;\n/**\n * A guard that succeeds when the input is not `null` or `undefined`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isNotNullable } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isNotNullable({}), true)\n * assert.deepStrictEqual(isNotNullable([]), true)\n *\n * assert.deepStrictEqual(isNotNullable(null), false)\n * assert.deepStrictEqual(isNotNullable(undefined), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isNotNullable = input => input !== null && input !== undefined;\n/**\n * A guard that succeeds when the input is an `Error`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isError } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isError(new Error()), true)\n *\n * assert.deepStrictEqual(isError(null), false)\n * assert.deepStrictEqual(isError({}), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isError = input => input instanceof Error;\n/**\n * A guard that succeeds when the input is a `Uint8Array`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isUint8Array } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isUint8Array(new Uint8Array()), true)\n *\n * assert.deepStrictEqual(isUint8Array(null), false)\n * assert.deepStrictEqual(isUint8Array({}), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isUint8Array = input => input instanceof Uint8Array;\n/**\n * A guard that succeeds when the input is a `Date`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isDate } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isDate(new Date()), true)\n *\n * assert.deepStrictEqual(isDate(null), false)\n * assert.deepStrictEqual(isDate({}), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isDate = input => input instanceof Date;\n/**\n * A guard that succeeds when the input is an `Iterable`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isIterable } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isIterable([]), true)\n * assert.deepStrictEqual(isIterable(new Set()), true)\n *\n * assert.deepStrictEqual(isIterable(null), false)\n * assert.deepStrictEqual(isIterable({}), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isIterable = input => hasProperty(input, Symbol.iterator);\n/**\n * A guard that succeeds when the input is a record.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isRecord } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isRecord({}), true)\n * assert.deepStrictEqual(isRecord({ a: 1 }), true)\n *\n * assert.deepStrictEqual(isRecord([]), false)\n * assert.deepStrictEqual(isRecord([1, 2, 3]), false)\n * assert.deepStrictEqual(isRecord(null), false)\n * assert.deepStrictEqual(isRecord(undefined), false)\n * assert.deepStrictEqual(isRecord(() => null), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isRecord = input => isRecordOrArray(input) && !Array.isArray(input);\n/**\n * A guard that succeeds when the input is a readonly record.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isReadonlyRecord } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isReadonlyRecord({}), true)\n * assert.deepStrictEqual(isReadonlyRecord({ a: 1 }), true)\n *\n * assert.deepStrictEqual(isReadonlyRecord([]), false)\n * assert.deepStrictEqual(isReadonlyRecord([1, 2, 3]), false)\n * assert.deepStrictEqual(isReadonlyRecord(null), false)\n * assert.deepStrictEqual(isReadonlyRecord(undefined), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isReadonlyRecord = isRecord;\n/**\n * A guard that succeeds when the input is a Promise.\n *\n * @param input - The value to test.\n *\n * @example\n * import { isPromise } from \"effect/Predicate\"\n *\n * assert.deepStrictEqual(isPromise({}), false)\n * assert.deepStrictEqual(isPromise(Promise.resolve(\"hello\")), true)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isPromise = input => hasProperty(input, \"then\") && \"catch\" in input && isFunction(input.then) && isFunction(input.catch);\n/**\n * @category guards\n * @since 2.0.0\n */\nexport const isPromiseLike = input => hasProperty(input, \"then\") && isFunction(input.then);\n/**\n * @since 2.0.0\n */\nexport const compose = /*#__PURE__*/dual(2, (ab, bc) => a => ab(a) && bc(a));\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const product = (self, that) => ([a, b]) => self(a) && that(b);\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const all = collection => {\n  return as => {\n    let collectionIndex = 0;\n    for (const p of collection) {\n      if (collectionIndex >= as.length) {\n        break;\n      }\n      if (p(as[collectionIndex]) === false) {\n        return false;\n      }\n      collectionIndex++;\n    }\n    return true;\n  };\n};\n/**\n * @category combining\n * @since 2.0.0\n */\nexport const productMany = (self, collection) => {\n  const rest = all(collection);\n  return ([head, ...tail]) => self(head) === false ? false : rest(tail);\n};\n/**\n * Similar to `Promise.all` but operates on `Predicate`s.\n *\n * ```\n * [Predicate<A>, Predicate<B>, ...] -> Predicate<[A, B, ...]>\n * ```\n *\n * @since 2.0.0\n */\nexport const tuple = (...elements) => all(elements);\n/**\n * @since 2.0.0\n */\nexport const struct = fields => {\n  const keys = Object.keys(fields);\n  return a => {\n    for (const key of keys) {\n      if (!fields[key](a[key])) {\n        return false;\n      }\n    }\n    return true;\n  };\n};\n/**\n * Negates the result of a given predicate.\n *\n * @param self - A predicate.\n *\n * @example\n * import { Predicate, Number } from \"effect\"\n *\n * const isPositive = Predicate.not(Number.lessThan(0))\n *\n * assert.deepStrictEqual(isPositive(-1), false)\n * assert.deepStrictEqual(isPositive(0), true)\n * assert.deepStrictEqual(isPositive(1), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const not = self => a => !self(a);\n/**\n * Combines two predicates into a new predicate that returns `true` if at least one of the predicates returns `true`.\n *\n * @param self - A predicate.\n * @param that - A predicate.\n *\n * @example\n * import { Predicate, Number } from \"effect\"\n *\n * const nonZero = Predicate.or(Number.lessThan(0), Number.greaterThan(0))\n *\n * assert.deepStrictEqual(nonZero(-1), true)\n * assert.deepStrictEqual(nonZero(0), false)\n * assert.deepStrictEqual(nonZero(1), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const or = /*#__PURE__*/dual(2, (self, that) => a => self(a) || that(a));\n/**\n * Combines two predicates into a new predicate that returns `true` if both of the predicates returns `true`.\n *\n * @param self - A predicate.\n * @param that - A predicate.\n *\n * @example\n * import { Predicate } from \"effect\"\n *\n * const minLength = (n: number) => (s: string) => s.length >= n\n * const maxLength = (n: number) => (s: string) => s.length <= n\n *\n * const length = (n: number) => Predicate.and(minLength(n), maxLength(n))\n *\n * assert.deepStrictEqual(length(2)(\"aa\"), true)\n * assert.deepStrictEqual(length(2)(\"a\"), false)\n * assert.deepStrictEqual(length(2)(\"aaa\"), false)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const and = /*#__PURE__*/dual(2, (self, that) => a => self(a) && that(a));\n/**\n * @category combinators\n * @since 2.0.0\n */\nexport const xor = /*#__PURE__*/dual(2, (self, that) => a => self(a) !== that(a));\n/**\n * @category combinators\n * @since 2.0.0\n */\nexport const eqv = /*#__PURE__*/dual(2, (self, that) => a => self(a) === that(a));\n/**\n * Represents the logical implication combinator for predicates. In formal\n * logic, the implication operator `->` denotes that if the first proposition\n * (antecedent) is true, then the second proposition (consequent) must also be\n * true. In simpler terms, `p implies q` can be interpreted as \"if p then q\". If\n * the first predicate holds, then the second predicate must hold\n * for the given context.\n *\n * In practical terms within TypeScript, `p implies q` is equivalent to `!p || (p && q)`.\n *\n * Note that if the antecedent is `false`, the result is `true` by default\n * because the outcome of the consequent cannot be determined.\n *\n * This function is useful in situations where you need to enforce rules or\n * constraints that are contingent on certain conditions.\n * It proves especially helpful in defining property tests.\n *\n * The example below illustrates the transitive property of order using the\n * `implies` function. In simple terms, if `a <= b` and `b <= c`, then `a <= c`\n * must be true.\n *\n * @example\n * import { Predicate } from \"effect\"\n *\n * type Triple = {\n *   readonly a: number\n *   readonly b: number\n *   readonly c: number\n * }\n *\n * const transitivity = Predicate.implies(\n *   // antecedent\n *   (input: Triple) => input.a <= input.b && input.b <= input.c,\n *   // consequent\n *   (input: Triple) => input.a <= input.c\n * )\n *\n * assert.equal(transitivity({ a: 1, b: 2, c: 3 }), true)\n * // antecedent is `false`, so the result is `true`\n * assert.equal(transitivity({ a: 1, b: 0, c: 0 }), true)\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const implies = /*#__PURE__*/dual(2, (antecedent, consequent) => a => antecedent(a) ? consequent(a) : true);\n/**\n * @category combinators\n * @since 2.0.0\n */\nexport const nor = /*#__PURE__*/dual(2, (self, that) => a => !(self(a) || that(a)));\n/**\n * @category combinators\n * @since 2.0.0\n */\nexport const nand = /*#__PURE__*/dual(2, (self, that) => a => !(self(a) && that(a)));\n/**\n * @category elements\n * @since 2.0.0\n */\nexport const every = collection => a => {\n  for (const p of collection) {\n    if (!p(a)) {\n      return false;\n    }\n  }\n  return true;\n};\n/**\n * @category elements\n * @since 2.0.0\n */\nexport const some = collection => a => {\n  for (const p of collection) {\n    if (p(a)) {\n      return true;\n    }\n  }\n  return false;\n};\n//# sourceMappingURL=Predicate.js.map","import * as internal from \"./internal/pubsub.js\";\n/**\n * Creates a bounded `PubSub` with the back pressure strategy. The `PubSub` will retain\n * messages until they have been taken by all subscribers, applying back\n * pressure to publishers if the `PubSub` is at capacity.\n *\n * For best performance use capacities that are powers of two.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const bounded = internal.bounded;\n/**\n * Creates a bounded `PubSub` with the dropping strategy. The `PubSub` will drop new\n * messages if the `PubSub` is at capacity.\n *\n * For best performance use capacities that are powers of two.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dropping = internal.dropping;\n/**\n * Creates a bounded `PubSub` with the sliding strategy. The `PubSub` will add new\n * messages and drop old messages if the `PubSub` is at capacity.\n *\n * For best performance use capacities that are powers of two.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sliding = internal.sliding;\n/**\n * Creates an unbounded `PubSub`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unbounded = internal.unbounded;\n/**\n *  Returns the number of elements the queue can hold.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const capacity = internal.capacity;\n/**\n * Retrieves the size of the queue, which is equal to the number of elements\n * in the queue. This may be negative if fibers are suspended waiting for\n * elements to be added to the queue.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const size = internal.size;\n/**\n * Returns `true` if the `Queue` contains at least one element, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isFull = internal.isFull;\n/**\n * Returns `true` if the `Queue` contains zero elements, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isEmpty = internal.isEmpty;\n/**\n * Interrupts any fibers that are suspended on `offer` or `take`. Future calls\n * to `offer*` and `take*` will be interrupted immediately.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const shutdown = internal.shutdown;\n/**\n * Returns `true` if `shutdown` has been called, otherwise returns `false`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isShutdown = internal.isShutdown;\n/**\n * Waits until the queue is shutdown. The `Effect` returned by this method will\n * not resume until the queue has been shutdown. If the queue is already\n * shutdown, the `Effect` will resume right away.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const awaitShutdown = internal.awaitShutdown;\n/**\n * Publishes a message to the `PubSub`, returning whether the message was published\n * to the `PubSub`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const publish = internal.publish;\n/**\n * Publishes all of the specified messages to the `PubSub`, returning whether they\n * were published to the `PubSub`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const publishAll = internal.publishAll;\n/**\n * Subscribes to receive messages from the `PubSub`. The resulting subscription can\n * be evaluated multiple times within the scope to take a message from the `PubSub`\n * each time.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const subscribe = internal.subscribe;\n//# sourceMappingURL=PubSub.js.map","import * as internal from \"./internal/queue.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const EnqueueTypeId = internal.EnqueueTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const DequeueTypeId = internal.DequeueTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const QueueStrategyTypeId = internal.QueueStrategyTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const BackingQueueTypeId = internal.BackingQueueTypeId;\n/**\n * Returns `true` if the specified value is a `Queue`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isQueue = internal.isQueue;\n/**\n * Returns `true` if the specified value is a `Dequeue`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isDequeue = internal.isDequeue;\n/**\n * Returns `true` if the specified value is a `Enqueue`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isEnqueue = internal.isEnqueue;\n/**\n * @since 2.0.0\n * @category strategies\n */\nexport const backPressureStrategy = internal.backPressureStrategy;\n/**\n * @since 2.0.0\n * @category strategies\n */\nexport const droppingStrategy = internal.droppingStrategy;\n/**\n * @since 2.0.0\n * @category strategies\n */\nexport const slidingStrategy = internal.slidingStrategy;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * Makes a new bounded `Queue`. When the capacity of the queue is reached, any\n * additional calls to `offer` will be suspended until there is more room in\n * the queue.\n *\n * **Note**: When possible use only power of 2 capacities; this will provide\n * better performance by utilising an optimised version of the underlying\n * `RingBuffer`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const bounded = internal.bounded;\n/**\n * Makes a new bounded `Queue` with the dropping strategy.\n *\n * When the capacity of the queue is reached, new elements will be dropped and the\n * old elements will remain.\n *\n * **Note**: When possible use only power of 2 capacities; this will provide\n * better performance by utilising an optimised version of the underlying\n * `RingBuffer`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dropping = internal.dropping;\n/**\n * Makes a new bounded `Queue` with the sliding strategy.\n *\n * When the capacity of the queue is reached, new elements will be added and the\n * old elements will be dropped.\n *\n * **Note**: When possible use only power of 2 capacities; this will provide\n * better performance by utilising an optimised version of the underlying\n * `RingBuffer`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sliding = internal.sliding;\n/**\n * Creates a new unbounded `Queue`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unbounded = internal.unbounded;\n/**\n * Returns the number of elements the queue can hold.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const capacity = internal.capacity;\n/**\n * Retrieves the size of the queue, which is equal to the number of elements\n * in the queue. This may be negative if fibers are suspended waiting for\n * elements to be added to the queue.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const size = internal.size;\n/**\n * Returns `true` if the `Queue` contains zero elements, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isEmpty = internal.isEmpty;\n/**\n * Returns `true` if the `Queue` contains at least one element, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isFull = internal.isFull;\n/**\n * Returns `true` if `shutdown` has been called, otherwise returns `false`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isShutdown = internal.isShutdown;\n/**\n * Waits until the queue is shutdown. The `Effect` returned by this method will\n * not resume until the queue has been shutdown. If the queue is already\n * shutdown, the `Effect` will resume right away.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const awaitShutdown = internal.awaitShutdown;\n/**\n * Interrupts any fibers that are suspended on `offer` or `take`. Future calls\n * to `offer*` and `take*` will be interrupted immediately.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const shutdown = internal.shutdown;\n/**\n * Places one value in the queue.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const offer = internal.offer;\n/**\n * Places one value in the queue.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const unsafeOffer = internal.unsafeOffer;\n/**\n * For Bounded Queue: uses the `BackPressure` Strategy, places the values in\n * the queue and always returns true. If the queue has reached capacity, then\n * the fiber performing the `offerAll` will be suspended until there is room\n * in the queue.\n *\n * For Unbounded Queue: Places all values in the queue and returns true.\n *\n * For Sliding Queue: uses `Sliding` Strategy If there is room in the queue,\n * it places the values otherwise it removes the old elements and enqueues the\n * new ones. Always returns true.\n *\n * For Dropping Queue: uses `Dropping` Strategy, It places the values in the\n * queue but if there is no room it will not enqueue them and return false.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const offerAll = internal.offerAll;\n/**\n * Returns the first value in the `Queue` as a `Some<A>`, or `None` if the queue\n * is empty.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const poll = internal.poll;\n/**\n * Takes the oldest value in the queue. If the queue is empty, this will return\n * a computation that resumes when an item has been added to the queue.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const take = internal.take;\n/**\n * Takes all the values in the queue and returns the values. If the queue is\n * empty returns an empty collection.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeAll = internal.takeAll;\n/**\n * Takes up to max number of values from the queue.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeUpTo = internal.takeUpTo;\n/**\n * Takes a number of elements from the queue between the specified minimum and\n * maximum. If there are fewer than the minimum number of elements available,\n * suspends until at least the minimum number of elements have been collected.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeBetween = internal.takeBetween;\n/**\n * Takes the specified number of elements from the queue. If there are fewer\n * than the specified number of elements available, it suspends until they\n * become available.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeN = internal.takeN;\n//# sourceMappingURL=Queue.js.map","import * as defaultServices from \"./internal/defaultServices.js\";\nimport * as internal from \"./internal/random.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const RandomTypeId = internal.RandomTypeId;\n/**\n * Returns the next numeric value from the pseudo-random number generator.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const next = defaultServices.next;\n/**\n * Returns the next integer value from the pseudo-random number generator.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const nextInt = defaultServices.nextInt;\n/**\n * Returns the next boolean value from the pseudo-random number generator.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const nextBoolean = defaultServices.nextBoolean;\n/**\n * Returns the next numeric value in the specified range from the\n * pseudo-random number generator.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const nextRange = defaultServices.nextRange;\n/**\n * Returns the next integer value in the specified range from the\n * pseudo-random number generator.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const nextIntBetween = defaultServices.nextIntBetween;\n/**\n * Uses the pseudo-random number generator to shuffle the specified iterable.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const shuffle = defaultServices.shuffle;\n/**\n * Retreives the `Random` service from the context and uses it to run the\n * specified workflow.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const randomWith = defaultServices.randomWith;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const Random = internal.randomTag;\n/**\n * Constructs the `Random` service, seeding the pseudo-random number generator\n * with an hash of the specified seed.\n * This constructor is useful for generating predictable sequences of random values for specific use cases.\n *\n * Example uses:\n * - Generating random UI data for visual tests.\n * - Creating data that needs to change daily but remain the same throughout a single day, such as using a date as the seed.\n *\n * @param seed - The seed value used to initialize the generator.\n *\n * @example\n * import { Effect, Random } from \"effect\"\n *\n * const random1 = Random.make(\"myseed\")\n * const random2 = Random.make(\"myseed\")\n *\n * assert.equal(Effect.runSync(random1.next), Effect.runSync(random2.next))\n *\n * @since 3.5.0\n * @category constructors\n */\nexport const make = internal.make;\n//# sourceMappingURL=Random.js.map","import { dual } from \"./Function.js\";\nimport * as core from \"./internal/core.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nimport { hasProperty } from \"./Predicate.js\";\n/**\n * @since 2.0.0\n * @category type ids\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/Readable\");\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isReadable = u => hasProperty(u, TypeId);\nconst Proto = {\n  [TypeId]: TypeId,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = get => {\n  const self = Object.create(Proto);\n  self.get = get;\n  return self;\n};\n/**\n * @since 2.0.0\n * @category combinators\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => make(core.map(self.get, f)));\n/**\n * @since 2.0.0\n * @category combinators\n */\nexport const mapEffect = /*#__PURE__*/dual(2, (self, f) => make(core.flatMap(self.get, f)));\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrap = effect => make(core.flatMap(effect, s => s.get));\n//# sourceMappingURL=Readable.js.map","/**\n * This module provides utility functions for working with records in TypeScript.\n *\n * @since 2.0.0\n */\nimport * as E from \"./Either.js\";\nimport * as Equal from \"./Equal.js\";\nimport { dual, identity } from \"./Function.js\";\nimport * as Option from \"./Option.js\";\n/**\n * Creates a new, empty record.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const empty = () => ({});\n/**\n * Determine if a record is empty.\n *\n * @param self - record to test for emptiness.\n *\n * @example\n * import { isEmptyRecord } from \"effect/Record\"\n *\n * assert.deepStrictEqual(isEmptyRecord({}), true);\n * assert.deepStrictEqual(isEmptyRecord({ a: 3 }), false);\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isEmptyRecord = self => keys(self).length === 0;\n/**\n * Determine if a record is empty.\n *\n * @param self - record to test for emptiness.\n *\n * @example\n * import { isEmptyReadonlyRecord } from \"effect/Record\"\n *\n * assert.deepStrictEqual(isEmptyReadonlyRecord({}), true);\n * assert.deepStrictEqual(isEmptyReadonlyRecord({ a: 3 }), false);\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isEmptyReadonlyRecord = isEmptyRecord;\n/**\n * Takes an iterable and a projection function and returns a record.\n * The projection function maps each value of the iterable to a tuple of a key and a value, which is then added to the resulting record.\n *\n * @param self - An iterable of values to be mapped to a record.\n * @param f - A projection function that maps values of the iterable to a tuple of a key and a value.\n *\n * @example\n * import { fromIterableWith } from \"effect/Record\"\n *\n * const input = [1, 2, 3, 4]\n *\n * assert.deepStrictEqual(\n *   fromIterableWith(input, a => [String(a), a * 2]),\n *   { '1': 2, '2': 4, '3': 6, '4': 8 }\n * )\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const fromIterableWith = /*#__PURE__*/dual(2, (self, f) => {\n  const out = empty();\n  for (const a of self) {\n    const [k, b] = f(a);\n    out[k] = b;\n  }\n  return out;\n});\n/**\n * Creates a new record from an iterable, utilizing the provided function to determine the key for each element.\n *\n * @param items - An iterable containing elements.\n * @param f - A function that extracts the key for each element.\n *\n * @example\n * import { fromIterableBy } from \"effect/Record\"\n *\n * const users = [\n *   { id: \"2\", name: \"name2\" },\n *   { id: \"1\", name: \"name1\" }\n * ]\n *\n * assert.deepStrictEqual(\n *   fromIterableBy(users, user => user.id),\n *   {\n *     \"2\": { id: \"2\", name: \"name2\" },\n *     \"1\": { id: \"1\", name: \"name1\" }\n *   }\n * )\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const fromIterableBy = (items, f) => fromIterableWith(items, a => [f(a), a]);\n/**\n * Builds a record from an iterable of key-value pairs.\n *\n * If there are conflicting keys when using `fromEntries`, the last occurrence of the key/value pair will overwrite the\n * previous ones. So the resulting record will only have the value of the last occurrence of each key.\n *\n * @param self - The iterable of key-value pairs.\n *\n * @example\n * import { fromEntries } from \"effect/Record\"\n *\n * const input: Array<[string, number]> = [[\"a\", 1], [\"b\", 2]]\n *\n * assert.deepStrictEqual(fromEntries(input), { a: 1, b: 2 })\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromEntries = Object.fromEntries;\n/**\n * Transforms the values of a record into an `Array` with a custom mapping function.\n *\n * @param self - The record to transform.\n * @param f - The custom mapping function to apply to each key/value of the record.\n *\n * @example\n * import { collect } from \"effect/Record\"\n *\n * const x = { a: 1, b: 2, c: 3 }\n * assert.deepStrictEqual(collect(x, (key, n) => [key, n]), [[\"a\", 1], [\"b\", 2], [\"c\", 3]])\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const collect = /*#__PURE__*/dual(2, (self, f) => {\n  const out = [];\n  for (const key of keys(self)) {\n    out.push(f(key, self[key]));\n  }\n  return out;\n});\n/**\n * Takes a record and returns an array of tuples containing its keys and values.\n *\n * @param self - The record to transform.\n *\n * @example\n * import { toEntries } from \"effect/Record\"\n *\n * const x = { a: 1, b: 2, c: 3 }\n * assert.deepStrictEqual(toEntries(x), [[\"a\", 1], [\"b\", 2], [\"c\", 3]])\n *\n * @category conversions\n * @since 2.0.0\n */\nexport const toEntries = /*#__PURE__*/collect((key, value) => [key, value]);\n/**\n * Returns the number of key/value pairs in a record.\n *\n * @param self - A record to calculate the number of key/value pairs in.\n *\n * @example\n * import { size } from \"effect/Record\";\n *\n * assert.deepStrictEqual(size({ a: \"a\", b: 1, c: true }), 3);\n *\n * @since 2.0.0\n */\nexport const size = self => keys(self).length;\n/**\n * Check if a given `key` exists in a record.\n *\n * @param self - the record to look in.\n * @param key - the key to look for in the record.\n *\n * @example\n * import { empty, has } from \"effect/Record\"\n *\n * assert.deepStrictEqual(has({ a: 1, b: 2 }, \"a\"), true);\n * assert.deepStrictEqual(has(empty<string>(), \"c\"), false);\n *\n * @since 2.0.0\n */\nexport const has = /*#__PURE__*/dual(2, (self, key) => Object.prototype.hasOwnProperty.call(self, key));\n/**\n * Retrieve a value at a particular key from a record, returning it wrapped in an `Option`.\n *\n * @param self - The record to retrieve value from.\n * @param key - Key to retrieve from record.\n *\n * @example\n * import { Record as R, Option } from \"effect\"\n *\n * const person: Record<string, unknown> = { name: \"John Doe\", age: 35 }\n *\n * assert.deepStrictEqual(R.get(person, \"name\"), Option.some(\"John Doe\"))\n * assert.deepStrictEqual(R.get(person, \"email\"), Option.none())\n *\n * @since 2.0.0\n */\nexport const get = /*#__PURE__*/dual(2, (self, key) => has(self, key) ? Option.some(self[key]) : Option.none());\n/**\n * Apply a function to the element at the specified key, creating a new record.\n * If the key does not exist, the record is returned unchanged.\n *\n * @param self - The record to be updated.\n * @param key - The key of the element to modify.\n * @param f - The function to apply to the element.\n *\n * @example\n * import { Record as R } from \"effect\"\n *\n * const f = (x: number) => x * 2\n *\n * assert.deepStrictEqual(\n *  R.modify({ a: 3 }, 'a', f),\n *  { a: 6 }\n * )\n * assert.deepStrictEqual(\n *  R.modify({ a: 3 } as Record<string, number>, 'b', f),\n *  { a: 3 }\n * )\n *\n * @since 2.0.0\n */\nexport const modify = /*#__PURE__*/dual(3, (self, key, f) => {\n  if (!has(self, key)) {\n    return {\n      ...self\n    };\n  }\n  return {\n    ...self,\n    [key]: f(self[key])\n  };\n});\n/**\n * Apply a function to the element at the specified key, creating a new record,\n * or return `None` if the key doesn't exist.\n *\n * @param self - The record to be updated.\n * @param key - The key of the element to modify.\n * @param f - The function to apply to the element.\n *\n * @example\n * import { Record as R, Option } from \"effect\"\n *\n * const f = (x: number) => x * 2\n *\n * assert.deepStrictEqual(\n *  R.modifyOption({ a: 3 }, 'a', f),\n *  Option.some({ a: 6 })\n * )\n * assert.deepStrictEqual(\n *  R.modifyOption({ a: 3 } as Record<string, number>, 'b', f),\n *  Option.none()\n * )\n *\n * @since 2.0.0\n */\nexport const modifyOption = /*#__PURE__*/dual(3, (self, key, f) => {\n  if (!has(self, key)) {\n    return Option.none();\n  }\n  return Option.some({\n    ...self,\n    [key]: f(self[key])\n  });\n});\n/**\n * Replaces a value in the record with the new value passed as parameter.\n *\n * @param self - The record to be updated.\n * @param key - The key to search for in the record.\n * @param b - The new value to replace the existing value with.\n *\n * @example\n * import { Record, Option } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Record.replaceOption({ a: 1, b: 2, c: 3 }, 'a', 10),\n *   Option.some({ a: 10, b: 2, c: 3 })\n * )\n * assert.deepStrictEqual(Record.replaceOption(Record.empty<string>(), 'a', 10), Option.none())\n *\n * @since 2.0.0\n */\nexport const replaceOption = /*#__PURE__*/dual(3, (self, key, b) => modifyOption(self, key, () => b));\n/**\n * If the given key exists in the record, returns a new record with the key removed,\n * otherwise returns a copy of the original record.\n *\n * @param self - the record to remove the key from.\n * @param key - the key to remove from the record.\n *\n * @example\n * import { remove } from \"effect/Record\"\n *\n * assert.deepStrictEqual(remove({ a: 1, b: 2 }, \"a\"), { b: 2 })\n *\n * @since 2.0.0\n */\nexport const remove = /*#__PURE__*/dual(2, (self, key) => {\n  if (!has(self, key)) {\n    return {\n      ...self\n    };\n  }\n  const out = {\n    ...self\n  };\n  delete out[key];\n  return out;\n});\n/**\n * Retrieves the value of the property with the given `key` from a record and returns an `Option`\n * of a tuple with the value and the record with the removed property.\n * If the key is not present, returns `O.none`.\n *\n * @param self - The input record.\n * @param key - The key of the property to retrieve.\n *\n * @example\n * import { Record as R, Option } from \"effect\"\n *\n * assert.deepStrictEqual(R.pop({ a: 1, b: 2 }, \"a\"), Option.some([1, { b: 2 }]))\n * assert.deepStrictEqual(R.pop({ a: 1, b: 2 } as Record<string, number>, \"c\"), Option.none())\n *\n * @category record\n * @since 2.0.0\n */\nexport const pop = /*#__PURE__*/dual(2, (self, key) => has(self, key) ? Option.some([self[key], remove(self, key)]) : Option.none());\n/**\n * Maps a record into another record by applying a transformation function to each of its values.\n *\n * @param self - The record to be mapped.\n * @param f - A transformation function that will be applied to each of the values in the record.\n *\n * @example\n * import { map } from \"effect/Record\"\n *\n * const f = (n: number) => `-${n}`\n *\n * assert.deepStrictEqual(map({ a: 3, b: 5 }, f), { a: \"-3\", b: \"-5\" })\n *\n * const g = (n: number, key: string) => `${key.toUpperCase()}-${n}`\n *\n * assert.deepStrictEqual(map({ a: 3, b: 5 }, g), { a: \"A-3\", b: \"B-5\" })\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const map = /*#__PURE__*/dual(2, (self, f) => {\n  const out = {\n    ...self\n  };\n  for (const key of keys(self)) {\n    out[key] = f(self[key], key);\n  }\n  return out;\n});\n/**\n * Maps the keys of a `ReadonlyRecord` while preserving the corresponding values.\n *\n * @example\n * import { mapKeys } from \"effect/Record\"\n *\n * assert.deepStrictEqual(mapKeys({ a: 3, b: 5 }, (key) => key.toUpperCase()), { A: 3, B: 5 })\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const mapKeys = /*#__PURE__*/dual(2, (self, f) => {\n  const out = {};\n  for (const key of keys(self)) {\n    const a = self[key];\n    out[f(key, a)] = a;\n  }\n  return out;\n});\n/**\n * Maps entries of a `ReadonlyRecord` using the provided function, allowing modification of both keys and corresponding values.\n *\n * @example\n * import { mapEntries } from \"effect/Record\"\n *\n * assert.deepStrictEqual(mapEntries({ a: 3, b: 5 }, (a, key) => [key.toUpperCase(), a + 1]), { A: 4, B: 6 })\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const mapEntries = /*#__PURE__*/dual(2, (self, f) => {\n  const out = {};\n  for (const key of keys(self)) {\n    const [k, b] = f(self[key], key);\n    out[k] = b;\n  }\n  return out;\n});\n/**\n * Transforms a record into a record by applying the function `f` to each key and value in the original record.\n * If the function returns `Some`, the key-value pair is included in the output record.\n *\n * @param self - The input record.\n * @param f - The transformation function.\n *\n * @example\n * import { Record, Option } from \"effect\"\n *\n * const x = { a: 1, b: 2, c: 3 }\n * const f = (a: number, key: string) => a > 2 ? Option.some(a * 2) : Option.none()\n * assert.deepStrictEqual(Record.filterMap(x, f), { c: 6 })\n *\n * @since 2.0.0\n */\nexport const filterMap = /*#__PURE__*/dual(2, (self, f) => {\n  const out = empty();\n  for (const key of keys(self)) {\n    const o = f(self[key], key);\n    if (Option.isSome(o)) {\n      out[key] = o.value;\n    }\n  }\n  return out;\n});\n/**\n * Selects properties from a record whose values match the given predicate.\n *\n * @param self - The record to filter.\n * @param predicate - A function that returns a `boolean` value to determine if the entry should be included in the new record.\n *\n * @example\n * import { filter } from \"effect/Record\"\n *\n * const x = { a: 1, b: 2, c: 3, d: 4 }\n * assert.deepStrictEqual(filter(x, (n) => n > 2), { c: 3, d: 4 })\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => {\n  const out = empty();\n  for (const key of keys(self)) {\n    if (predicate(self[key], key)) {\n      out[key] = self[key];\n    }\n  }\n  return out;\n});\n/**\n * Given a record with `Option` values, returns a new record containing only the `Some` values, preserving the original keys.\n *\n * @param self - A record with `Option` values.\n *\n * @example\n * import { Record, Option } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Record.getSomes({ a: Option.some(1), b: Option.none(), c: Option.some(2) }),\n *   { a: 1, c: 2 }\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getSomes = /*#__PURE__*/filterMap(identity);\n/**\n * Given a record with `Either` values, returns a new record containing only the `Left` values, preserving the original keys.\n *\n * @example\n * import { Record, Either } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Record.getLefts({ a: Either.right(1), b: Either.left(\"err\"), c: Either.right(2) }),\n *   { b: \"err\" }\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getLefts = self => {\n  const out = empty();\n  for (const key of keys(self)) {\n    const value = self[key];\n    if (E.isLeft(value)) {\n      out[key] = value.left;\n    }\n  }\n  return out;\n};\n/**\n * Given a record with `Either` values, returns a new record containing only the `Right` values, preserving the original keys.\n *\n * @example\n * import { Record, Either } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Record.getRights({ a: Either.right(1), b: Either.left(\"err\"), c: Either.right(2) }),\n *   { a: 1, c: 2 }\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const getRights = self => {\n  const out = empty();\n  for (const key of keys(self)) {\n    const value = self[key];\n    if (E.isRight(value)) {\n      out[key] = value.right;\n    }\n  }\n  return out;\n};\n/**\n * Partitions the elements of a record into two groups: those that match a predicate, and those that don't.\n *\n * @param self - The record to partition.\n * @param f - The predicate function to apply to each element.\n *\n * @example\n * import { Record, Either } from \"effect\"\n *\n * const x = { a: 1, b: 2, c: 3 }\n * const f = (n: number) => (n % 2 === 0 ? Either.right(n) : Either.left(n))\n * assert.deepStrictEqual(Record.partitionMap(x, f), [{ a: 1, c: 3 }, { b: 2}])\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const partitionMap = /*#__PURE__*/dual(2, (self, f) => {\n  const left = empty();\n  const right = empty();\n  for (const key of keys(self)) {\n    const e = f(self[key], key);\n    if (E.isLeft(e)) {\n      left[key] = e.left;\n    } else {\n      right[key] = e.right;\n    }\n  }\n  return [left, right];\n});\n/**\n * Partitions a record of `Either` values into two separate records,\n * one with the `Left` values and one with the `Right` values.\n *\n * @param self - the record to partition.\n *\n * @example\n * import { Record, Either } from \"effect\"\n *\n * assert.deepStrictEqual(\n *   Record.separate({ a: Either.left(\"e\"), b: Either.right(1) }),\n *   [{ a: \"e\" }, { b: 1 }]\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const separate = /*#__PURE__*/partitionMap(identity);\n/**\n * Partitions a record into two separate records based on the result of a predicate function.\n *\n * @param self - The input record to partition.\n * @param predicate - The partitioning function to determine the partitioning of each value of the record.\n *\n * @example\n * import { partition } from \"effect/Record\"\n *\n * assert.deepStrictEqual(\n *   partition({ a: 1, b: 3 }, (n) => n > 2),\n *   [{ a: 1 }, { b: 3 }]\n * )\n *\n * @category filtering\n * @since 2.0.0\n */\nexport const partition = /*#__PURE__*/dual(2, (self, predicate) => {\n  const left = empty();\n  const right = empty();\n  for (const key of keys(self)) {\n    if (predicate(self[key], key)) {\n      right[key] = self[key];\n    } else {\n      left[key] = self[key];\n    }\n  }\n  return [left, right];\n});\n/**\n * Retrieve the keys of a given record as an array.\n *\n * @param self - The object for which you want to get the keys.\n *\n * @since 2.0.0\n */\nexport const keys = self => Object.keys(self);\n/**\n * Retrieve the values of a given record as an array.\n *\n * @param self - The object for which you want to get the values.\n *\n * @since 2.0.0\n */\nexport const values = self => collect(self, (_, a) => a);\n/**\n * Add a new key-value pair or update an existing key's value in a record.\n *\n * @param self - The record to which you want to add or update a key-value pair.\n * @param key - The key you want to add or update.\n * @param values - The value you want to associate with the key.\n *\n * @example\n * import { set } from \"effect/Record\"\n *\n * assert.deepStrictEqual(set(\"a\", 5)({ a: 1, b: 2 }), { a: 5, b: 2 });\n * assert.deepStrictEqual(set(\"c\", 5)({ a: 1, b: 2 }), { a: 1, b: 2, c: 5 });\n *\n * @since 2.0.0\n */\nexport const set = /*#__PURE__*/dual(3, (self, key, value) => {\n  return {\n    ...self,\n    [key]: value\n  };\n});\n/**\n * Replace a key's value in a record and return the updated record.\n * If the key does not exist in the record, a copy of the original record is returned.\n *\n * @param self - The original record.\n * @param key - The key to replace.\n * @param value - The new value to associate with the key.\n *\n * @example\n * import { Record } from \"effect\"\n *\n * assert.deepStrictEqual(Record.replace(\"a\", 3)({ a: 1, b: 2 }), { a: 3, b: 2 });\n * assert.deepStrictEqual(Record.replace(\"c\", 3)({ a: 1, b: 2 }), { a: 1, b: 2 });\n *\n * @since 2.0.0\n */\nexport const replace = /*#__PURE__*/dual(3, (self, key, value) => {\n  if (has(self, key)) {\n    return {\n      ...self,\n      [key]: value\n    };\n  }\n  return {\n    ...self\n  };\n});\n/**\n * Check if all the keys and values in one record are also found in another record.\n *\n * @param self - The first record to check.\n * @param that - The second record to compare against.\n * @param equivalence - A function to compare values.\n *\n * @since 2.0.0\n */\nexport const isSubrecordBy = equivalence => dual(2, (self, that) => {\n  for (const key of keys(self)) {\n    if (!has(that, key) || !equivalence(self[key], that[key])) {\n      return false;\n    }\n  }\n  return true;\n});\n/**\n * Check if one record is a subrecord of another, meaning it contains all the keys and values found in the second record.\n * This comparison uses default equality checks (`Equal.equivalence()`).\n *\n * @param self - The first record to check.\n * @param that - The second record to compare against.\n *\n * @since 2.0.0\n */\nexport const isSubrecord = /*#__PURE__*/isSubrecordBy( /*#__PURE__*/Equal.equivalence());\n/**\n * Reduce a record to a single value by combining its entries with a specified function.\n *\n * @param self - The record to reduce.\n * @param zero - The initial value of the accumulator.\n * @param f - The function to combine entries (accumulator, value, key).\n *\n * @category folding\n * @since 2.0.0\n */\nexport const reduce = /*#__PURE__*/dual(3, (self, zero, f) => {\n  let out = zero;\n  for (const key of keys(self)) {\n    out = f(out, self[key], key);\n  }\n  return out;\n});\n/**\n * Check if all entries in a record meet a specific condition.\n *\n * @param self - The record to check.\n * @param predicate - The condition to test entries (value, key).\n *\n * @since 2.0.0\n */\nexport const every = /*#__PURE__*/dual(2, (self, refinement) => {\n  for (const key of keys(self)) {\n    if (!refinement(self[key], key)) {\n      return false;\n    }\n  }\n  return true;\n});\n/**\n * Check if any entry in a record meets a specific condition.\n *\n * @param self - The record to check.\n * @param predicate - The condition to test entries (value, key).\n *\n * @since 2.0.0\n */\nexport const some = /*#__PURE__*/dual(2, (self, predicate) => {\n  for (const key of keys(self)) {\n    if (predicate(self[key], key)) {\n      return true;\n    }\n  }\n  return false;\n});\n/**\n * Merge two records, preserving entries that exist in either of the records.\n *\n * @param self - The first record.\n * @param that - The second record to combine with the first.\n * @param combine - A function to specify how to merge entries with the same key.\n *\n * @since 2.0.0\n */\nexport const union = /*#__PURE__*/dual(3, (self, that, combine) => {\n  if (isEmptyRecord(self)) {\n    return {\n      ...that\n    };\n  }\n  if (isEmptyRecord(that)) {\n    return {\n      ...self\n    };\n  }\n  const out = empty();\n  for (const key of keys(self)) {\n    if (has(that, key)) {\n      out[key] = combine(self[key], that[key]);\n    } else {\n      out[key] = self[key];\n    }\n  }\n  for (const key of keys(that)) {\n    if (!has(out, key)) {\n      out[key] = that[key];\n    }\n  }\n  return out;\n});\n/**\n * Merge two records, retaining only the entries that exist in both records.\n *\n * @param self - The first record.\n * @param that - The second record to merge with the first.\n * @param combine - A function to specify how to merge entries with the same key.\n *\n * @since 2.0.0\n */\nexport const intersection = /*#__PURE__*/dual(3, (self, that, combine) => {\n  const out = empty();\n  if (isEmptyRecord(self) || isEmptyRecord(that)) {\n    return out;\n  }\n  for (const key of keys(self)) {\n    if (has(that, key)) {\n      out[key] = combine(self[key], that[key]);\n    }\n  }\n  return out;\n});\n/**\n * Merge two records, preserving only the entries that are unique to each record.\n *\n * @param self - The first record.\n * @param that - The second record to compare with the first.\n *\n * @since 2.0.0\n */\nexport const difference = /*#__PURE__*/dual(2, (self, that) => {\n  if (isEmptyRecord(self)) {\n    return {\n      ...that\n    };\n  }\n  if (isEmptyRecord(that)) {\n    return {\n      ...self\n    };\n  }\n  const out = {};\n  for (const key of keys(self)) {\n    if (!has(that, key)) {\n      out[key] = self[key];\n    }\n  }\n  for (const key of keys(that)) {\n    if (!has(self, key)) {\n      out[key] = that[key];\n    }\n  }\n  return out;\n});\n/**\n * Create an `Equivalence` for records using the provided `Equivalence` for values.\n *\n * @param equivalence - An `Equivalence` for the values contained in the records.\n *\n * @category instances\n * @since 2.0.0\n */\nexport const getEquivalence = equivalence => {\n  const is = isSubrecordBy(equivalence);\n  return (self, that) => is(self, that) && is(that, self);\n};\n/**\n * Create a non-empty record from a single element.\n *\n * @param key - The key for the element.\n * @param value - The value associated with the key.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const singleton = (key, value) => ({\n  [key]: value\n});\n//# sourceMappingURL=Record.js.map","import * as RBT from \"./internal/redBlackTree.js\";\nimport * as RBTI from \"./internal/redBlackTree/iterator.js\";\nconst TypeId = RBT.RedBlackTreeTypeId;\n/**\n * @since 2.0.0\n * @category constants\n */\nexport const Direction = RBTI.Direction;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isRedBlackTree = RBT.isRedBlackTree;\n/**\n * Creates an empty `RedBlackTree`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = RBT.empty;\n/**\n * Creates a new `RedBlackTree` from an iterable collection of key/value pairs.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = RBT.fromIterable;\n/**\n * Constructs a new `RedBlackTree` from the specified entries.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = RBT.make;\n/**\n * Returns an iterator that points to the element at the specified index of the\n * tree.\n *\n * **Note**: The iterator will run through elements in order.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const at = RBT.atForwards;\n/**\n * Returns an iterator that points to the element at the specified index of the\n * tree.\n *\n * **Note**: The iterator will run through elements in reverse order.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const atReversed = RBT.atBackwards;\n/**\n * Finds all values in the tree associated with the specified key.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const findAll = RBT.findAll;\n/**\n * Finds the first value in the tree associated with the specified key, if it exists.\n *\n * @category elements\n * @since 2.0.0\n */\nexport const findFirst = RBT.findFirst;\n/**\n * Returns the first entry in the tree, if it exists.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const first = RBT.first;\n/**\n * Returns the element at the specified index within the tree or `None` if the\n * specified index does not exist.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const getAt = RBT.getAt;\n/**\n * Gets the `Order<K>` that the `RedBlackTree<K, V>` is using.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const getOrder = RBT.getOrder;\n/**\n * Returns an iterator that traverse entries in order with keys greater than the\n * specified key.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const greaterThan = RBT.greaterThanForwards;\n/**\n * Returns an iterator that traverse entries in reverse order with keys greater\n * than the specified key.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const greaterThanReversed = RBT.greaterThanBackwards;\n/**\n * Returns an iterator that traverse entries in order with keys greater than or\n * equal to the specified key.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const greaterThanEqual = RBT.greaterThanEqualForwards;\n/**\n * Returns an iterator that traverse entries in reverse order with keys greater\n * than or equal to the specified key.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const greaterThanEqualReversed = RBT.greaterThanEqualBackwards;\n/**\n * Finds the item with key, if it exists.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const has = RBT.has;\n/**\n * Insert a new item into the tree.\n *\n * @since 2.0.0\n */\nexport const insert = RBT.insert;\n/**\n * Get all the keys present in the tree in order.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const keys = RBT.keysForward;\n/**\n * Get all the keys present in the tree in reverse order.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const keysReversed = RBT.keysBackward;\n/**\n * Returns the last entry in the tree, if it exists.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const last = RBT.last;\n/**\n * Returns an iterator that traverse entries in order with keys less than the\n * specified key.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const lessThan = RBT.lessThanForwards;\n/**\n * Returns an iterator that traverse entries in reverse order with keys less\n * than the specified key.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const lessThanReversed = RBT.lessThanBackwards;\n/**\n * Returns an iterator that traverse entries in order with keys less than or\n * equal to the specified key.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const lessThanEqual = RBT.lessThanEqualForwards;\n/**\n * Returns an iterator that traverse entries in reverse order with keys less\n * than or equal to the specified key.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const lessThanEqualReversed = RBT.lessThanEqualBackwards;\n/**\n * Execute the specified function for each node of the tree, in order.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const forEach = RBT.forEach;\n/**\n * Visit each node of the tree in order with key greater then or equal to max.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const forEachGreaterThanEqual = RBT.forEachGreaterThanEqual;\n/**\n * Visit each node of the tree in order with key lower then max.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const forEachLessThan = RBT.forEachLessThan;\n/**\n * Visit each node of the tree in order with key lower than max and greater\n * than or equal to min.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const forEachBetween = RBT.forEachBetween;\n/**\n * Reduce a state over the entries of the tree.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduce = RBT.reduce;\n/**\n * Removes the entry with the specified key, if it exists.\n *\n * @since 2.0.0\n */\nexport const removeFirst = RBT.removeFirst;\n/**\n * Traverse the tree in reverse order.\n *\n * @since 2.0.0\n * @category traversing\n */\nexport const reversed = RBT.reversed;\n/**\n * Returns the size of the tree.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const size = RBT.size;\n/**\n * Get all values present in the tree in order.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const values = RBT.valuesForward;\n/**\n * Get all values present in the tree in reverse order.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const valuesReversed = RBT.valuesBackward;\n//# sourceMappingURL=RedBlackTree.js.map","import * as Equivalence from \"./Equivalence.js\";\nimport * as redacted_ from \"./internal/redacted.js\";\n/**\n * @since 3.3.0\n * @category symbols\n */\nexport const RedactedTypeId = redacted_.RedactedTypeId;\n/**\n * @since 3.3.0\n * @category refinements\n */\nexport const isRedacted = redacted_.isRedacted;\n/**\n * This function creates a `Redacted<A>` instance from a given value `A`,\n * securely hiding its content.\n *\n * @example\n * import { Redacted } from \"effect\"\n *\n * const API_KEY = Redacted.make(\"1234567890\")\n *\n * @since 3.3.0\n * @category constructors\n */\nexport const make = redacted_.make;\n/**\n * Retrieves the original value from a `Redacted` instance. Use this function\n * with caution, as it exposes the sensitive data.\n *\n * @example\n * import { Redacted } from \"effect\"\n *\n * const API_KEY = Redacted.make(\"1234567890\")\n *\n * assert.equal(Redacted.value(API_KEY), \"1234567890\")\n *\n * @since 3.3.0\n * @category getters\n */\nexport const value = redacted_.value;\n/**\n * Erases the underlying value of a `Redacted` instance, rendering it unusable.\n * This function is intended to ensure that sensitive data does not remain in\n * memory longer than necessary.\n *\n * @example\n * import { Redacted } from \"effect\"\n *\n * const API_KEY = Redacted.make(\"1234567890\")\n *\n * assert.equal(Redacted.value(API_KEY), \"1234567890\")\n *\n * Redacted.unsafeWipe(API_KEY)\n *\n * assert.throws(() => Redacted.value(API_KEY), new Error(\"Unable to get redacted value\"))\n *\n * @since 3.3.0\n * @category unsafe\n */\nexport const unsafeWipe = redacted_.unsafeWipe;\n/**\n * Generates an equivalence relation for `Redacted<A>` values based on an\n * equivalence relation for the underlying values `A`. This function is useful\n * for comparing `Redacted` instances without exposing their contents.\n *\n * @example\n * import { Redacted, Equivalence } from \"effect\"\n *\n * const API_KEY1 = Redacted.make(\"1234567890\")\n * const API_KEY2 = Redacted.make(\"1-34567890\")\n * const API_KEY3 = Redacted.make(\"1234567890\")\n *\n * const equivalence = Redacted.getEquivalence(Equivalence.string)\n *\n * assert.equal(equivalence(API_KEY1, API_KEY2), false)\n * assert.equal(equivalence(API_KEY1, API_KEY3), true)\n *\n * @category equivalence\n * @since 3.3.0\n */\nexport const getEquivalence = isEquivalent => Equivalence.make((x, y) => isEquivalent(value(x), value(y)));\n//# sourceMappingURL=Redacted.js.map","import * as internal from \"./internal/ref.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const RefTypeId = internal.RefTypeId;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * @since 2.0.0\n * @category getters\n */\nexport const get = internal.get;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const getAndSet = internal.getAndSet;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const getAndUpdate = internal.getAndUpdate;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const getAndUpdateSome = internal.getAndUpdateSome;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const modify = internal.modify;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const modifySome = internal.modifySome;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const set = internal.set;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const setAndGet = internal.setAndGet;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const update = internal.update;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const updateAndGet = internal.updateAndGet;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const updateSome = internal.updateSome;\n/**\n * @since 2.0.0\n * @category utils\n */\nexport const updateSomeAndGet = internal.updateSomeAndGet;\n/**\n * @since 2.0.0\n * @category unsafe\n */\nexport const unsafeMake = internal.unsafeMake;\n//# sourceMappingURL=Ref.js.map","/**\n * This module provides utility functions for working with RegExp in TypeScript.\n *\n * @since 2.0.0\n */\n/**\n * Escapes special characters in a regular expression pattern.\n *\n * @example\n * import { RegExp } from \"effect\"\n *\n * assert.deepStrictEqual(RegExp.escape(\"a*b\"), \"a\\\\*b\")\n *\n * @since 2.0.0\n */\nexport const escape = string => string.replace(/[/\\\\^$*+?.()|[\\]{}]/g, \"\\\\$&\");\n//# sourceMappingURL=RegExp.js.map","import * as _RequestBlock from \"./internal/blockedRequests.js\";\nimport * as cache from \"./internal/cache.js\";\nimport * as core from \"./internal/core.js\";\nimport * as fiberRuntime from \"./internal/fiberRuntime.js\";\nimport * as internal from \"./internal/request.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const RequestTypeId = internal.RequestTypeId;\n/**\n * Returns `true` if the specified value is a `Request`, `false` otherwise.\n *\n * @since 2.0.0\n * @category refinements\n */\nexport const isRequest = internal.isRequest;\n/**\n * Constructs a new `Request`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const of = internal.of;\n/**\n * Constructs a new `Request`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const tagged = internal.tagged;\n/**\n * Provides a constructor for a Request Class.\n *\n * @example\n * import { Request } from \"effect\"\n *\n * type Success = string\n * type Error = never\n *\n * class MyRequest extends Request.Class<Success, Error, {\n *   readonly id: string\n * }> {}\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const Class = internal.Class;\n/**\n * Provides a Tagged constructor for a Request Class.\n *\n * @example\n * import { Request } from \"effect\"\n *\n * type Success = string\n * type Error = never\n *\n * class MyRequest extends Request.TaggedClass(\"MyRequest\")<Success, Error, {\n *   readonly name: string\n * }> {}\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const TaggedClass = internal.TaggedClass;\n/**\n * Complete a `Request` with the specified result.\n *\n * @since 2.0.0\n * @category request completion\n */\nexport const complete = internal.complete;\n/**\n * Interrupts the child effect when requests are no longer needed\n *\n * @since 2.0.0\n * @category request completion\n */\nexport const interruptWhenPossible = fiberRuntime.interruptWhenPossible;\n/**\n * Complete a `Request` with the specified effectful computation, failing the\n * request with the error from the effect workflow if it fails, and completing\n * the request with the value of the effect workflow if it succeeds.\n *\n * @since 2.0.0\n * @category request completion\n */\nexport const completeEffect = internal.completeEffect;\n/**\n * Complete a `Request` with the specified error.\n *\n * @since 2.0.0\n * @category request completion\n */\nexport const fail = internal.fail;\n/**\n * Complete a `Request` with the specified cause.\n *\n * @since 2.0.0\n * @category request completion\n */\nexport const failCause = internal.failCause;\n/**\n * Complete a `Request` with the specified value.\n *\n * @since 2.0.0\n * @category request completion\n */\nexport const succeed = internal.succeed;\n/**\n * @since 2.0.0\n * @category models\n */\nexport const makeCache = options => cache.make({\n  ...options,\n  lookup: () => core.map(core.deferredMake(), handle => ({\n    listeners: new internal.Listeners(),\n    handle\n  }))\n});\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const EntryTypeId = /*#__PURE__*/Symbol.for(\"effect/RequestBlock.Entry\");\n/**\n * @since 2.0.0\n * @category guards\n */\nexport const isEntry = _RequestBlock.isEntry;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const makeEntry = _RequestBlock.makeEntry;\n//# sourceMappingURL=Request.js.map","import * as internal from \"./internal/runtime.js\";\n/**\n * Executes the effect using the provided Scheduler or using the global\n * Scheduler if not provided\n *\n * @since 2.0.0\n * @category execution\n */\nexport const runFork = internal.unsafeFork;\n/**\n * Executes the effect synchronously returning the exit.\n *\n * This method is effectful and should only be invoked at the edges of your\n * program.\n *\n * @since 2.0.0\n * @category execution\n */\nexport const runSyncExit = internal.unsafeRunSyncExit;\n/**\n * Executes the effect synchronously throwing in case of errors or async boundaries.\n *\n * This method is effectful and should only be invoked at the edges of your\n * program.\n *\n * @since 2.0.0\n * @category execution\n */\nexport const runSync = internal.unsafeRunSync;\n/**\n * Executes the effect asynchronously, eventually passing the exit value to\n * the specified callback.\n *\n * This method is effectful and should only be invoked at the edges of your\n * program.\n *\n * @since 2.0.0\n * @category execution\n */\nexport const runCallback = internal.unsafeRunCallback;\n/**\n * Runs the `Effect`, returning a JavaScript `Promise` that will be resolved\n * with the value of the effect once the effect has been executed, or will be\n * rejected with the first error or exception throw by the effect.\n *\n * This method is effectful and should only be used at the edges of your\n * program.\n *\n * @since 2.0.0\n * @category execution\n */\nexport const runPromise = internal.unsafeRunPromise;\n/**\n * Runs the `Effect`, returning a JavaScript `Promise` that will be resolved\n * with the `Exit` state of the effect once the effect has been executed.\n *\n * This method is effectful and should only be used at the edges of your\n * program.\n *\n * @since 2.0.0\n * @category execution\n */\nexport const runPromiseExit = internal.unsafeRunPromiseExit;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const defaultRuntime = internal.defaultRuntime;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const defaultRuntimeFlags = internal.defaultRuntimeFlags;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const FiberFailureId = /*#__PURE__*/Symbol.for(\"effect/Runtime/FiberFailure\");\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const FiberFailureCauseId = internal.FiberFailureCauseId;\n/**\n * @since 2.0.0\n * @category guards\n */\nexport const isAsyncFiberException = internal.isAsyncFiberException;\n/**\n * @since 2.0.0\n * @category guards\n */\nexport const isFiberFailure = internal.isFiberFailure;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const makeFiberFailure = internal.fiberFailure;\n/**\n * @since 2.0.0\n * @category runtime flags\n */\nexport const updateRuntimeFlags = internal.updateRuntimeFlags;\n/**\n * @since 2.0.0\n * @category runtime flags\n */\nexport const enableRuntimeFlag = internal.enableRuntimeFlag;\n/**\n * @since 2.0.0\n * @category runtime flags\n */\nexport const disableRuntimeFlag = internal.disableRuntimeFlag;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const updateContext = internal.updateContext;\n/**\n * @since 2.0.0\n * @category context\n * @example\n * import { Context, Runtime } from \"effect\"\n *\n * class Name extends Context.Tag(\"Name\")<Name, string>() {}\n *\n * const runtime: Runtime.Runtime<Name> = Runtime.defaultRuntime.pipe(\n *   Runtime.provideService(Name, \"John\")\n * )\n */\nexport const provideService = internal.provideService;\n/**\n * @since 2.0.0\n * @category fiber refs\n */\nexport const updateFiberRefs = internal.updateFiberRefs;\n/**\n * @since 2.0.0\n * @category fiber refs\n * @example\n * import { Effect, FiberRef, Runtime } from \"effect\"\n *\n * const ref = FiberRef.unsafeMake(0)\n *\n * const updatedRuntime = Runtime.defaultRuntime.pipe(\n *   Runtime.setFiberRef(ref, 1)\n * )\n *\n * // returns 1\n * const result = Runtime.runSync(updatedRuntime)(FiberRef.get(ref))\n */\nexport const setFiberRef = internal.setFiberRef;\n/**\n * @since 2.0.0\n * @category fiber refs\n * @example\n * import { Effect, FiberRef, Runtime } from \"effect\"\n *\n * const ref = FiberRef.unsafeMake(0)\n *\n * const updatedRuntime = Runtime.defaultRuntime.pipe(\n *   Runtime.setFiberRef(ref, 1),\n *   Runtime.deleteFiberRef(ref)\n * )\n *\n * // returns 0\n * const result = Runtime.runSync(updatedRuntime)(FiberRef.get(ref))\n */\nexport const deleteFiberRef = internal.deleteFiberRef;\n//# sourceMappingURL=Runtime.js.map","/**\n * @since 2.0.0\n */\nimport * as runtimeFlags from \"./internal/runtimeFlags.js\";\nimport * as internal from \"./internal/runtimeFlagsPatch.js\";\n/**\n * The empty `RuntimeFlagsPatch`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * Creates a `RuntimeFlagsPatch` describing enabling the provided `RuntimeFlag`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const enable = internal.enable;\n/**\n * Creates a `RuntimeFlagsPatch` describing disabling the provided `RuntimeFlag`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const disable = internal.disable;\n/**\n * Returns `true` if the specified `RuntimeFlagsPatch` is empty.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isEmpty = internal.isEmpty;\n/**\n * Returns `true` if the `RuntimeFlagsPatch` describes the specified\n * `RuntimeFlag` as active.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const isActive = internal.isActive;\n/**\n * Returns `true` if the `RuntimeFlagsPatch` describes the specified\n * `RuntimeFlag` as enabled.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const isEnabled = internal.isEnabled;\n/**\n * Returns `true` if the `RuntimeFlagsPatch` describes the specified\n * `RuntimeFlag` as disabled.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const isDisabled = internal.isDisabled;\n/**\n * Returns `true` if the `RuntimeFlagsPatch` includes the specified\n * `RuntimeFlag`, `false` otherwise.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const includes = internal.isActive;\n/**\n * Creates a `RuntimeFlagsPatch` describing the application of the `self` patch,\n * followed by `that` patch.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const andThen = internal.andThen;\n/**\n * Creates a `RuntimeFlagsPatch` describing application of both the `self` patch\n * and `that` patch.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const both = internal.both;\n/**\n * Creates a `RuntimeFlagsPatch` describing application of either the `self`\n * patch or `that` patch.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const either = internal.either;\n/**\n * Creates a `RuntimeFlagsPatch` which describes exclusion of the specified\n * `RuntimeFlag` from the set of `RuntimeFlags`.\n *\n * @category utils\n * @since 2.0.0\n */\nexport const exclude = internal.exclude;\n/**\n * Creates a `RuntimeFlagsPatch` which describes the inverse of the patch\n * specified by the provided `RuntimeFlagsPatch`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const inverse = internal.inverse;\n/**\n * Returns a `ReadonlySet<number>` containing the `RuntimeFlags` described as\n * enabled by the specified `RuntimeFlagsPatch`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const enabledSet = runtimeFlags.enabledSet;\n/**\n * Returns a `ReadonlySet<number>` containing the `RuntimeFlags` described as\n * disabled by the specified `RuntimeFlagsPatch`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const disabledSet = runtimeFlags.disabledSet;\n/**\n * Renders the provided `RuntimeFlagsPatch` to a string.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const render = runtimeFlags.renderPatch;\n//# sourceMappingURL=RuntimeFlagsPatch.js.map","import * as internal from \"./internal/schedule.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const ScheduleTypeId = internal.ScheduleTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const ScheduleDriverTypeId = internal.ScheduleDriverTypeId;\n/**\n * Constructs a new `Schedule` with the specified `initial` state and the\n * specified `step` function.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const makeWithState = internal.makeWithState;\n/**\n * Returns a new schedule with the given delay added to every interval defined\n * by this schedule.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const addDelay = internal.addDelay;\n/**\n * Returns a new schedule with the given effectfully computed delay added to\n * every interval defined by this schedule.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const addDelayEffect = internal.addDelayEffect;\n/**\n * The same as `andThenEither`, but merges the output.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const andThen = internal.andThen;\n/**\n * Returns a new schedule that first executes this schedule to completion, and\n * then executes the specified schedule to completion.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const andThenEither = internal.andThenEither;\n/**\n * Returns a new schedule that maps this schedule to a constant output.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const as = internal.as;\n/**\n * Returns a new schedule that maps the output of this schedule to unit.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const asVoid = internal.asVoid;\n/**\n * Returns a new schedule that has both the inputs and outputs of this and the\n * specified schedule.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const bothInOut = internal.bothInOut;\n/**\n * Returns a new schedule that passes each input and output of this schedule\n * to the specified function, and then determines whether or not to continue\n * based on the return value of the function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const check = internal.check;\n/**\n * Returns a new schedule that passes each input and output of this schedule\n * to the specified function, and then determines whether or not to continue\n * based on the return value of the function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const checkEffect = internal.checkEffect;\n/**\n * A schedule that recurs anywhere, collecting all inputs into a `Chunk`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllInputs = internal.collectAllInputs;\n/**\n * Returns a new schedule that collects the outputs of this one into a chunk.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const collectAllOutputs = internal.collectAllOutputs;\n/**\n * A schedule that recurs until the condition f fails, collecting all inputs\n * into a list.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const collectUntil = internal.collectUntil;\n/**\n * A schedule that recurs until the effectful condition f fails, collecting\n * all inputs into a list.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const collectUntilEffect = internal.collectUntilEffect;\n/**\n * A schedule that recurs as long as the condition f holds, collecting all\n * inputs into a list.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const collectWhile = internal.collectWhile;\n/**\n * A schedule that recurs as long as the effectful condition holds, collecting\n * all inputs into a list.\n *\n * @category utils\n * @since 2.0.0\n */\nexport const collectWhileEffect = internal.collectWhileEffect;\n/**\n * Returns the composition of this schedule and the specified schedule, by\n * piping the output of this one into the input of the other. Effects\n * described by this schedule will always be executed before the effects\n * described by the second schedule.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const compose = internal.compose;\n/**\n * Returns a new schedule that deals with a narrower class of inputs than this\n * schedule.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapInput = internal.mapInput;\n/**\n * Transforms the context being provided to this schedule with the\n * specified function.\n *\n * @since 2.0.0\n * @category context\n */\nexport const mapInputContext = internal.mapInputContext;\n/**\n * Returns a new schedule that deals with a narrower class of inputs than this\n * schedule.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapInputEffect = internal.mapInputEffect;\n/**\n * A schedule that always recurs, which counts the number of recurrences.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const count = internal.count;\n/**\n * Cron schedule that recurs every `minute` that matches the schedule.\n *\n * It triggers at zero second of the minute. Producing the timestamps of the cron window.\n *\n * NOTE: `expression` parameter is validated lazily. Must be a valid cron expression.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const cron = internal.cron;\n/**\n * Cron-like schedule that recurs every specified `day` of month. Won't recur\n * on months containing less days than specified in `day` param.\n *\n * It triggers at zero hour of the day. Producing a count of repeats: 0, 1, 2.\n *\n * NOTE: `day` parameter is validated lazily. Must be in range 1...31.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dayOfMonth = internal.dayOfMonth;\n/**\n * Cron-like schedule that recurs every specified `day` of each week. It\n * triggers at zero hour of the week. Producing a count of repeats: 0, 1, 2.\n *\n * NOTE: `day` parameter is validated lazily. Must be in range 1 (Monday)...7\n * (Sunday).\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dayOfWeek = internal.dayOfWeek;\n/**\n * Returns a new schedule with the specified effectfully computed delay added\n * before the start of each interval produced by this schedule.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const delayed = internal.delayed;\n/**\n * Returns a new schedule with the specified effectfully computed delay added\n * before the start of each interval produced by this schedule.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const delayedEffect = internal.delayedEffect;\n/**\n * Takes a schedule that produces a delay, and returns a new schedule that\n * uses this delay to further delay intervals in the resulting schedule.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const delayedSchedule = internal.delayedSchedule;\n/**\n * Returns a new schedule that outputs the delay between each occurence.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const delays = internal.delays;\n/**\n * Returns a new schedule that maps both the input and output.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapBoth = internal.mapBoth;\n/**\n * Returns a new schedule that maps both the input and output.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapBothEffect = internal.mapBothEffect;\n/**\n * Returns a driver that can be used to step the schedule, appropriately\n * handling sleeping.\n *\n * @since 2.0.0\n * @category getter\n */\nexport const driver = internal.driver;\n/**\n * A schedule that can recur one time, the specified amount of time into the\n * future.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const duration = internal.duration;\n/**\n * Returns a new schedule that performs a geometric union on the intervals\n * defined by both schedules.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const either = internal.either;\n/**\n * The same as `either` followed by `map`.\n *\n * @since 2.0.0\n * @category alternatives\n */\nexport const eitherWith = internal.eitherWith;\n/**\n * A schedule that occurs everywhere, which returns the total elapsed duration\n * since the first step.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const elapsed = internal.elapsed;\n/**\n * Returns a new schedule that will run the specified finalizer as soon as the\n * schedule is complete. Note that unlike `Effect.ensuring`, this method does not\n * guarantee the finalizer will be run. The `Schedule` may not initialize or\n * the driver of the schedule may not run to completion. However, if the\n * `Schedule` ever decides not to continue, then the finalizer will be run.\n *\n * @since 2.0.0\n * @category finalization\n */\nexport const ensuring = internal.ensuring;\n/**\n * A schedule that always recurs, but will wait a certain amount between\n * repetitions, given by `base * factor.pow(n)`, where `n` is the number of\n * repetitions so far. Returns the current duration between recurrences.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const exponential = internal.exponential;\n/**\n * A schedule that always recurs, increasing delays by summing the preceding\n * two delays (similar to the fibonacci sequence). Returns the current\n * duration between recurrences.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fibonacci = internal.fibonacci;\n/**\n * A schedule that recurs on a fixed interval. Returns the number of\n * repetitions of the schedule so far.\n *\n * If the action run between updates takes longer than the interval, then the\n * action will be run immediately, but re-runs will not \"pile up\".\n *\n * ```\n * |-----interval-----|-----interval-----|-----interval-----|\n * |---------action--------||action|-----|action|-----------|\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fixed = internal.fixed;\n/**\n * A schedule that always recurs, producing a count of repeats: 0, 1, 2.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const forever = internal.forever;\n/**\n * A schedule that recurs once with the specified delay.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromDelay = internal.fromDelay;\n/**\n * A schedule that recurs once for each of the specified durations, delaying\n * each time for the length of the specified duration. Returns the length of\n * the current duration between recurrences.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromDelays = internal.fromDelays;\n/**\n * A schedule that always recurs, mapping input values through the specified\n * function.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromFunction = internal.fromFunction;\n/**\n * Cron-like schedule that recurs every specified `hour` of each day. It\n * triggers at zero minute of the hour. Producing a count of repeats: 0, 1, 2.\n *\n * NOTE: `hour` parameter is validated lazily. Must be in range 0...23.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const hourOfDay = internal.hourOfDay;\n/**\n * A schedule that always recurs, which returns inputs as outputs.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const identity = internal.identity;\n/**\n * Returns a new schedule that performs a geometric intersection on the\n * intervals defined by both schedules.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const intersect = internal.intersect;\n/**\n * Returns a new schedule that combines this schedule with the specified\n * schedule, continuing as long as both schedules want to continue and merging\n * the next intervals according to the specified merge function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const intersectWith = internal.intersectWith;\n/**\n * Returns a new schedule that randomly modifies the size of the intervals of\n * this schedule.\n *\n * Defaults `min` to `0.8` and `max` to `1.2`.\n *\n * The new interval size is between `min * old interval size` and `max * old\n * interval size`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const jittered = internal.jittered;\n/**\n * Returns a new schedule that randomly modifies the size of the intervals of\n * this schedule.\n *\n * The new interval size is between `min * old interval size` and `max * old\n * interval size`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const jitteredWith = internal.jitteredWith;\n/**\n * A schedule that always recurs, but will repeat on a linear time interval,\n * given by `base * n` where `n` is the number of repetitions so far. Returns\n * the current duration between recurrences.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const linear = internal.linear;\n/**\n * Returns a new schedule that maps the output of this schedule through the\n * specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * Returns a new schedule that maps the output of this schedule through the\n * specified effectful function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapEffect = internal.mapEffect;\n/**\n * Cron-like schedule that recurs every specified `minute` of each hour. It\n * triggers at zero second of the minute. Producing a count of repeats: 0, 1,\n * 2.\n *\n * NOTE: `minute` parameter is validated lazily. Must be in range 0...59.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const minuteOfHour = internal.minuteOfHour;\n/**\n * Returns a new schedule that modifies the delay using the specified\n * function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const modifyDelay = internal.modifyDelay;\n/**\n * Returns a new schedule that modifies the delay using the specified\n * effectual function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const modifyDelayEffect = internal.modifyDelayEffect;\n/**\n * Returns a new schedule that applies the current one but runs the specified\n * effect for every decision of this schedule. This can be used to create\n * schedules that log failures, decisions, or computed values.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const onDecision = internal.onDecision;\n/**\n * A schedule that recurs one time.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const once = internal.once;\n/**\n * Returns a new schedule that passes through the inputs of this schedule.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const passthrough = internal.passthrough;\n/**\n * Returns a new schedule with its context provided to it, so the\n * resulting schedule does not require any context.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideContext = internal.provideContext;\n/**\n * Returns a new schedule with the single service it requires provided to it.\n * If the schedule requires multiple services use `provideContext`\n * instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideService = internal.provideService;\n/**\n * A schedule that recurs for until the predicate evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const recurUntil = internal.recurUntil;\n/**\n * A schedule that recurs for until the predicate evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const recurUntilEffect = internal.recurUntilEffect;\n/**\n * A schedule that recurs for until the input value becomes applicable to\n * partial function and then map that value with given function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const recurUntilOption = internal.recurUntilOption;\n/**\n * A schedule that recurs during the given duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const recurUpTo = internal.recurUpTo;\n/**\n * A schedule that recurs for as long as the predicate evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const recurWhile = internal.recurWhile;\n/**\n * A schedule that recurs for as long as the effectful predicate evaluates to\n * true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const recurWhileEffect = internal.recurWhileEffect;\n/**\n * A schedule spanning all time, which can be stepped only the specified\n * number of times before it terminates.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const recurs = internal.recurs;\n/**\n * Returns a new schedule that folds over the outputs of this one.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduce = internal.reduce;\n/**\n * Returns a new schedule that effectfully folds over the outputs of this one.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const reduceEffect = internal.reduceEffect;\n/**\n * Returns a new schedule that loops this one continuously, resetting the\n * state when this schedule is done.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatForever = internal.forever;\n/**\n * Returns a new schedule that outputs the number of repetitions of this one.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repetitions = internal.repetitions;\n/**\n * Return a new schedule that automatically resets the schedule to its initial\n * state after some time of inactivity defined by `duration`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const resetAfter = internal.resetAfter;\n/**\n * Resets the schedule when the specified predicate on the schedule output\n * evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const resetWhen = internal.resetWhen;\n/**\n * Runs a schedule using the provided inputs, and collects all outputs.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const run = internal.run;\n/**\n * Cron-like schedule that recurs every specified `second` of each minute. It\n * triggers at zero nanosecond of the second. Producing a count of repeats: 0,\n * 1, 2.\n *\n * NOTE: `second` parameter is validated lazily. Must be in range 0...59.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const secondOfMinute = internal.secondOfMinute;\n/**\n * Returns a schedule that recurs continuously, each repetition spaced the\n * specified duration from the last run.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const spaced = internal.spaced;\n/**\n * A schedule that does not recur, it just stops.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const stop = internal.stop;\n/**\n * Returns a schedule that repeats one time, producing the specified constant\n * value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = internal.succeed;\n/**\n * Returns a schedule that repeats one time, producing the specified constant\n * value.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const sync = internal.sync;\n/**\n * Returns a new schedule that effectfully processes every input to this\n * schedule.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapInput = internal.tapInput;\n/**\n * Returns a new schedule that effectfully processes every output from this\n * schedule.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapOutput = internal.tapOutput;\n/**\n * Unfolds a schedule that repeats one time from the specified state and\n * iterator.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfold = internal.unfold;\n/**\n * Returns a new schedule that performs a geometric union on the intervals\n * defined by both schedules.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const union = internal.union;\n/**\n * Returns a new schedule that combines this schedule with the specified\n * schedule, continuing as long as either schedule wants to continue and\n * merging the next intervals according to the specified merge function.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const unionWith = internal.unionWith;\n/**\n * Returns a new schedule that continues until the specified predicate on the\n * input evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const untilInput = internal.untilInput;\n/**\n * Returns a new schedule that continues until the specified effectful\n * predicate on the input evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const untilInputEffect = internal.untilInputEffect;\n/**\n * Returns a new schedule that continues until the specified predicate on the\n * output evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const untilOutput = internal.untilOutput;\n/**\n * Returns a new schedule that continues until the specified effectful\n * predicate on the output evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const untilOutputEffect = internal.untilOutputEffect;\n/**\n * A schedule that recurs during the given duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const upTo = internal.upTo;\n/**\n * Returns a new schedule that continues for as long as the specified predicate\n * on the input evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const whileInput = internal.whileInput;\n/**\n * Returns a new schedule that continues for as long as the specified effectful\n * predicate on the input evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const whileInputEffect = internal.whileInputEffect;\n/**\n * Returns a new schedule that continues for as long the specified predicate\n * on the output evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const whileOutput = internal.whileOutput;\n/**\n * Returns a new schedule that continues for as long the specified effectful\n * predicate on the output evaluates to true.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const whileOutputEffect = internal.whileOutputEffect;\n/**\n * A schedule that divides the timeline to `interval`-long windows, and sleeps\n * until the nearest window boundary every time it recurs.\n *\n * For example, `windowed(Duration.seconds(10))` would produce a schedule as\n * follows:\n *\n * ```\n *      10s        10s        10s       10s\n * |----------|----------|----------|----------|\n * |action------|sleep---|act|-sleep|action----|\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const windowed = internal.windowed;\n/**\n * The same as `intersect` but ignores the right output.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = internal.zipLeft;\n/**\n * The same as `intersect` but ignores the left output.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = internal.zipRight;\n/**\n * Equivalent to `intersect` followed by `map`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = internal.zipWith;\n//# sourceMappingURL=Schedule.js.map","/**\n * @since 2.0.0\n */\nimport * as internal from \"./internal/schedule/decision.js\";\nconst _continue = internal._continue;\nexport {\n/**\n * @since 2.0.0\n * @category constructors\n */\n_continue as continue };\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const continueWith = internal.continueWith;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const done = internal.done;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isContinue = internal.isContinue;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isDone = internal.isDone;\n//# sourceMappingURL=ScheduleDecision.js.map","import * as internal from \"./internal/schedule/interval.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const IntervalTypeId = internal.IntervalTypeId;\n/**\n * Constructs a new interval from the two specified endpoints. If the start\n * endpoint greater than the end endpoint, then a zero size interval will be\n * returned.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * An `Interval` of zero-width.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * Returns `true` if this `Interval` is less than `that` interval, `false`\n * otherwise.\n *\n * @since 2.0.0\n * @category ordering\n */\nexport const lessThan = internal.lessThan;\n/**\n * Returns the minimum of two `Interval`s.\n *\n * @since 2.0.0\n * @category ordering\n */\nexport const min = internal.min;\n/**\n * Returns the maximum of two `Interval`s.\n *\n * @since 2.0.0\n * @category ordering\n */\nexport const max = internal.max;\n/**\n * Returns `true` if the specified `Interval` is empty, `false` otherwise.\n *\n * @since 2.0.0\n * @category ordering\n */\nexport const isEmpty = internal.isEmpty;\n/**\n * Returns `true` if the specified `Interval` is non-empty, `false` otherwise.\n *\n * @since 2.0.0\n * @category ordering\n */\nexport const isNonEmpty = internal.isNonEmpty;\n/**\n * Computes a new `Interval` which is the intersection of this `Interval` and\n * that `Interval`.\n *\n * @since 2.0.0\n * @category ordering\n */\nexport const intersect = internal.intersect;\n/**\n * Calculates the size of the `Interval` as the `Duration` from the start of the\n * interval to the end of the interval.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const size = internal.size;\n/**\n * Computes a new `Interval` which is the union of this `Interval` and that\n * `Interval` as a `Some`, otherwise returns `None` if the two intervals cannot\n * form a union.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const union = internal.union;\n/**\n * Construct an `Interval` that includes all time equal to and after the\n * specified start time.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const after = internal.after;\n/**\n * Construct an `Interval` that includes all time equal to and before the\n * specified end time.\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const before = internal.before;\n//# sourceMappingURL=ScheduleInterval.js.map","import * as internal from \"./internal/schedule/intervals.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const IntervalsTypeId = internal.IntervalsTypeId;\n/**\n * Creates a new `Intervals` from a `List` of `Interval`s.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * Constructs an empty list of `Interval`s.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * Creates `Intervals` from the specified `Iterable<Interval>`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = internal.fromIterable;\n/**\n * Computes the union of this `Intervals` and  that `Intervals`\n *\n * @since 2.0.0\n * @category utils\n */\nexport const union = internal.union;\n/**\n * Produces the intersection of this `Intervals` and that `Intervals`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const intersect = internal.intersect;\n/**\n * The start of the earliest interval in the specified `Intervals`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const start = internal.start;\n/**\n * The end of the latest interval in the specified `Intervals`.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const end = internal.end;\n/**\n * Returns `true` if the start of this `Intervals` is before the start of that\n * `Intervals`, `false` otherwise.\n *\n * @since 2.0.0\n * @category ordering\n */\nexport const lessThan = internal.lessThan;\n/**\n * Returns `true` if this `Intervals` is non-empty, `false` otherwise.\n *\n * @since 2.0.0\n * @category getters\n */\nexport const isNonEmpty = internal.isNonEmpty;\n/**\n * Returns the maximum of the two `Intervals` (i.e. which has the latest start).\n *\n * @since 2.0.0\n * @category ordering\n */\nexport const max = internal.max;\n//# sourceMappingURL=ScheduleIntervals.js.map","/**\n * @since 2.0.0\n */\nimport { dual } from \"./Function.js\";\nimport { globalValue } from \"./GlobalValue.js\";\nimport * as core from \"./internal/core.js\";\n/**\n * @since 2.0.0\n * @category utils\n */\nexport class PriorityBuckets {\n  /**\n   * @since 2.0.0\n   */\n  buckets = [];\n  /**\n   * @since 2.0.0\n   */\n  scheduleTask(task, priority) {\n    let bucket = undefined;\n    let index;\n    for (index = 0; index < this.buckets.length; index++) {\n      if (this.buckets[index][0] <= priority) {\n        bucket = this.buckets[index];\n      } else {\n        break;\n      }\n    }\n    if (bucket) {\n      bucket[1].push(task);\n    } else {\n      const newBuckets = [];\n      for (let i = 0; i < index; i++) {\n        newBuckets.push(this.buckets[i]);\n      }\n      newBuckets.push([priority, [task]]);\n      for (let i = index; i < this.buckets.length; i++) {\n        newBuckets.push(this.buckets[i]);\n      }\n      this.buckets = newBuckets;\n    }\n  }\n}\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport class MixedScheduler {\n  maxNextTickBeforeTimer;\n  /**\n   * @since 2.0.0\n   */\n  running = false;\n  /**\n   * @since 2.0.0\n   */\n  tasks = /*#__PURE__*/new PriorityBuckets();\n  constructor(\n  /**\n   * @since 2.0.0\n   */\n  maxNextTickBeforeTimer) {\n    this.maxNextTickBeforeTimer = maxNextTickBeforeTimer;\n  }\n  /**\n   * @since 2.0.0\n   */\n  starveInternal(depth) {\n    const tasks = this.tasks.buckets;\n    this.tasks.buckets = [];\n    for (const [_, toRun] of tasks) {\n      for (let i = 0; i < toRun.length; i++) {\n        toRun[i]();\n      }\n    }\n    if (this.tasks.buckets.length === 0) {\n      this.running = false;\n    } else {\n      this.starve(depth);\n    }\n  }\n  /**\n   * @since 2.0.0\n   */\n  starve(depth = 0) {\n    if (depth >= this.maxNextTickBeforeTimer) {\n      setTimeout(() => this.starveInternal(0), 0);\n    } else {\n      Promise.resolve(void 0).then(() => this.starveInternal(depth + 1));\n    }\n  }\n  /**\n   * @since 2.0.0\n   */\n  shouldYield(fiber) {\n    return fiber.currentOpCount > fiber.getFiberRef(core.currentMaxOpsBeforeYield) ? fiber.getFiberRef(core.currentSchedulingPriority) : false;\n  }\n  /**\n   * @since 2.0.0\n   */\n  scheduleTask(task, priority) {\n    this.tasks.scheduleTask(task, priority);\n    if (!this.running) {\n      this.running = true;\n      this.starve();\n    }\n  }\n}\n/**\n * @since 2.0.0\n * @category schedulers\n */\nexport const defaultScheduler = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Scheduler/defaultScheduler\"), () => new MixedScheduler(2048));\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport class SyncScheduler {\n  /**\n   * @since 2.0.0\n   */\n  tasks = /*#__PURE__*/new PriorityBuckets();\n  /**\n   * @since 2.0.0\n   */\n  deferred = false;\n  /**\n   * @since 2.0.0\n   */\n  scheduleTask(task, priority) {\n    if (this.deferred) {\n      defaultScheduler.scheduleTask(task, priority);\n    } else {\n      this.tasks.scheduleTask(task, priority);\n    }\n  }\n  /**\n   * @since 2.0.0\n   */\n  shouldYield(fiber) {\n    return fiber.currentOpCount > fiber.getFiberRef(core.currentMaxOpsBeforeYield) ? fiber.getFiberRef(core.currentSchedulingPriority) : false;\n  }\n  /**\n   * @since 2.0.0\n   */\n  flush() {\n    while (this.tasks.buckets.length > 0) {\n      const tasks = this.tasks.buckets;\n      this.tasks.buckets = [];\n      for (const [_, toRun] of tasks) {\n        for (let i = 0; i < toRun.length; i++) {\n          toRun[i]();\n        }\n      }\n    }\n    this.deferred = true;\n  }\n}\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport class ControlledScheduler {\n  /**\n   * @since 2.0.0\n   */\n  tasks = /*#__PURE__*/new PriorityBuckets();\n  /**\n   * @since 2.0.0\n   */\n  deferred = false;\n  /**\n   * @since 2.0.0\n   */\n  scheduleTask(task, priority) {\n    if (this.deferred) {\n      defaultScheduler.scheduleTask(task, priority);\n    } else {\n      this.tasks.scheduleTask(task, priority);\n    }\n  }\n  /**\n   * @since 2.0.0\n   */\n  shouldYield(fiber) {\n    return fiber.currentOpCount > fiber.getFiberRef(core.currentMaxOpsBeforeYield) ? fiber.getFiberRef(core.currentSchedulingPriority) : false;\n  }\n  /**\n   * @since 2.0.0\n   */\n  step() {\n    const tasks = this.tasks.buckets;\n    this.tasks.buckets = [];\n    for (const [_, toRun] of tasks) {\n      for (let i = 0; i < toRun.length; i++) {\n        toRun[i]();\n      }\n    }\n  }\n}\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const makeMatrix = (...record) => {\n  const index = record.sort(([p0], [p1]) => p0 < p1 ? -1 : p0 > p1 ? 1 : 0);\n  return {\n    shouldYield(fiber) {\n      for (const scheduler of record) {\n        const priority = scheduler[1].shouldYield(fiber);\n        if (priority !== false) {\n          return priority;\n        }\n      }\n      return false;\n    },\n    scheduleTask(task, priority) {\n      let scheduler = undefined;\n      for (const i of index) {\n        if (priority >= i[0]) {\n          scheduler = i[1];\n        } else {\n          return (scheduler ?? defaultScheduler).scheduleTask(task, priority);\n        }\n      }\n      return (scheduler ?? defaultScheduler).scheduleTask(task, priority);\n    }\n  };\n};\n/**\n * @since 2.0.0\n * @category utilities\n */\nexport const defaultShouldYield = fiber => {\n  return fiber.currentOpCount > fiber.getFiberRef(core.currentMaxOpsBeforeYield) ? fiber.getFiberRef(core.currentSchedulingPriority) : false;\n};\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = (scheduleTask, shouldYield = defaultShouldYield) => ({\n  scheduleTask,\n  shouldYield\n});\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const makeBatched = (callback, shouldYield = defaultShouldYield) => {\n  let running = false;\n  const tasks = new PriorityBuckets();\n  const starveInternal = () => {\n    const tasksToRun = tasks.buckets;\n    tasks.buckets = [];\n    for (const [_, toRun] of tasksToRun) {\n      for (let i = 0; i < toRun.length; i++) {\n        toRun[i]();\n      }\n    }\n    if (tasks.buckets.length === 0) {\n      running = false;\n    } else {\n      starve();\n    }\n  };\n  const starve = () => callback(starveInternal);\n  return make((task, priority) => {\n    tasks.scheduleTask(task, priority);\n    if (!running) {\n      running = true;\n      starve();\n    }\n  }, shouldYield);\n};\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const timer = (ms, shouldYield = defaultShouldYield) => make(task => setTimeout(task, ms), shouldYield);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const timerBatched = (ms, shouldYield = defaultShouldYield) => makeBatched(task => setTimeout(task, ms), shouldYield);\n/** @internal */\nexport const currentScheduler = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentScheduler\"), () => core.fiberRefUnsafeMake(defaultScheduler));\n/** @internal */\nexport const withScheduler = /*#__PURE__*/dual(2, (self, scheduler) => core.fiberRefLocally(self, currentScheduler, scheduler));\n//# sourceMappingURL=Scheduler.js.map","/**\n * @since 2.0.0\n */\nimport * as core from \"./internal/core.js\";\nimport * as fiberRuntime from \"./internal/fiberRuntime.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const ScopeTypeId = core.ScopeTypeId;\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const CloseableScopeTypeId = core.CloseableScopeTypeId;\n/**\n * @since 2.0.0\n * @category context\n */\nexport const Scope = fiberRuntime.scopeTag;\n/**\n * Adds a finalizer to this scope. The finalizer is guaranteed to be run when\n * the scope is closed.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const addFinalizer = core.scopeAddFinalizer;\n/**\n * A simplified version of `addFinalizerWith` when the `finalizer` does not\n * depend on the `Exit` value that the scope is closed with.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const addFinalizerExit = core.scopeAddFinalizerExit;\n/**\n * Closes a scope with the specified exit value, running all finalizers that\n * have been added to the scope.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const close = core.scopeClose;\n/**\n * Extends the scope of an `Effect` workflow that needs a scope into this\n * scope by providing it to the workflow but not closing the scope when the\n * workflow completes execution. This allows extending a scoped value into a\n * larger scope.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const extend = fiberRuntime.scopeExtend;\n/**\n * Forks a new scope that is a child of this scope. The child scope will\n * automatically be closed when this scope is closed.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const fork = core.scopeFork;\n/**\n * Uses the scope by providing it to an `Effect` workflow that needs a scope,\n * guaranteeing that the scope is closed with the result of that workflow as\n * soon as the workflow completes execution, whether by success, failure, or\n * interruption.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const use = fiberRuntime.scopeUse;\n/**\n * Creates a Scope where Finalizers will run according to the `ExecutionStrategy`.\n *\n * If an ExecutionStrategy is not provided `sequential` will be used.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = fiberRuntime.scopeMake;\n//# sourceMappingURL=Scope.js.map","import * as internal from \"./internal/sink.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const SinkTypeId = internal.SinkTypeId;\n/**\n * Replaces this sink's result with the provided value.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const as = internal.as;\n/**\n * A sink that collects all elements into a `Chunk`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAll = internal.collectAll;\n/**\n * A sink that collects first `n` elements into a chunk.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllN = internal.collectAllN;\n/**\n * Repeatedly runs the sink and accumulates its results into a `Chunk`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const collectAllFrom = internal.collectAllFrom;\n/**\n * A sink that collects all of its inputs into a map. The keys are extracted\n * from inputs using the keying function `key`; if multiple inputs use the\n * same key, they are merged using the `merge` function.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllToMap = internal.collectAllToMap;\n/**\n * A sink that collects first `n` keys into a map. The keys are calculated\n * from inputs using the keying function `key`; if multiple inputs use the the\n * same key, they are merged using the `merge` function.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllToMapN = internal.collectAllToMapN;\n/**\n * A sink that collects all of its inputs into a set.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllToSet = internal.collectAllToSet;\n/**\n * A sink that collects first `n` distinct inputs into a set.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllToSetN = internal.collectAllToSetN;\n/**\n * Accumulates incoming elements into a chunk until predicate `p` is\n * satisfied.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllUntil = internal.collectAllUntil;\n/**\n * Accumulates incoming elements into a chunk until effectful predicate `p` is\n * satisfied.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllUntilEffect = internal.collectAllUntilEffect;\n/**\n * Accumulates incoming elements into a chunk as long as they verify predicate\n * `p`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllWhile = internal.collectAllWhile;\n/**\n * Accumulates incoming elements into a chunk as long as they verify effectful\n * predicate `p`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const collectAllWhileEffect = internal.collectAllWhileEffect;\n/**\n * Repeatedly runs the sink for as long as its results satisfy the predicate\n * `p`. The sink's results will be accumulated using the stepping function `f`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const collectAllWhileWith = internal.collectAllWhileWith;\n/**\n * Collects the leftovers from the stream when the sink succeeds and returns\n * them as part of the sink's result.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const collectLeftover = internal.collectLeftover;\n/**\n * Transforms this sink's input elements.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapInput = internal.mapInput;\n/**\n * Effectfully transforms this sink's input elements.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapInputEffect = internal.mapInputEffect;\n/**\n * Transforms this sink's input chunks. `f` must preserve chunking-invariance.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapInputChunks = internal.mapInputChunks;\n/**\n * Effectfully transforms this sink's input chunks. `f` must preserve\n * chunking-invariance.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapInputChunksEffect = internal.mapInputChunksEffect;\n/**\n * A sink that counts the number of elements fed to it.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const count = internal.count;\n/**\n * Creates a sink halting with the specified defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const die = internal.die;\n/**\n * Creates a sink halting with the specified message, wrapped in a\n * `RuntimeException`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dieMessage = internal.dieMessage;\n/**\n * Creates a sink halting with the specified defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dieSync = internal.dieSync;\n/**\n * Transforms both inputs and result of this sink using the provided\n * functions.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const dimap = internal.dimap;\n/**\n * Effectfully transforms both inputs and result of this sink using the\n * provided functions.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const dimapEffect = internal.dimapEffect;\n/**\n * Transforms both input chunks and result of this sink using the provided\n * functions.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const dimapChunks = internal.dimapChunks;\n/**\n * Effectfully transforms both input chunks and result of this sink using the\n * provided functions. `f` and `g` must preserve chunking-invariance.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const dimapChunksEffect = internal.dimapChunksEffect;\n/**\n * A sink that ignores its inputs.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const drain = internal.drain;\n/**\n * Creates a sink that drops `n` elements.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const drop = internal.drop;\n/**\n * Drops incoming elements until the predicate is satisfied.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dropUntil = internal.dropUntil;\n/**\n * Drops incoming elements until the effectful predicate is satisfied.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dropUntilEffect = internal.dropUntilEffect;\n/**\n * Drops incoming elements as long as the predicate is satisfied.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dropWhile = internal.dropWhile;\n/**\n * Drops incoming elements as long as the effectful predicate is satisfied.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dropWhileEffect = internal.dropWhileEffect;\n/**\n * Returns a new sink with an attached finalizer. The finalizer is guaranteed\n * to be executed so long as the sink begins execution (and regardless of\n * whether or not it completes).\n *\n * @since 2.0.0\n * @category finalization\n */\nexport const ensuring = internal.ensuring;\n/**\n * Returns a new sink with an attached finalizer. The finalizer is guaranteed\n * to be executed so long as the sink begins execution (and regardless of\n * whether or not it completes).\n *\n * @since 2.0.0\n * @category finalization\n */\nexport const ensuringWith = internal.ensuringWith;\n/**\n * Accesses the whole context of the sink.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const context = internal.context;\n/**\n * Accesses the context of the sink.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const contextWith = internal.contextWith;\n/**\n * Accesses the context of the sink in the context of an effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const contextWithEffect = internal.contextWithEffect;\n/**\n * Accesses the context of the sink in the context of a sink.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const contextWithSink = internal.contextWithSink;\n/**\n * A sink that returns whether all elements satisfy the specified predicate.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const every = internal.every;\n/**\n * A sink that always fails with the specified error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = internal.fail;\n/**\n * A sink that always fails with the specified lazily evaluated error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failSync = internal.failSync;\n/**\n * Creates a sink halting with a specified `Cause`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCause = internal.failCause;\n/**\n * Creates a sink halting with a specified lazily evaluated `Cause`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCauseSync = internal.failCauseSync;\n/**\n * Filters the sink's input with the given predicate.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filterInput = internal.filterInput;\n/**\n * Effectfully filter the input of this sink using the specified predicate.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filterInputEffect = internal.filterInputEffect;\n/**\n * Creates a sink that produces values until one verifies the predicate `f`.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const findEffect = internal.findEffect;\n/**\n * A sink that folds its inputs with the provided function, termination\n * predicate and initial state.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const fold = internal.fold;\n/**\n * Folds over the result of the sink\n *\n * @since 2.0.0\n * @category folding\n */\nexport const foldSink = internal.foldSink;\n/**\n * A sink that folds its input chunks with the provided function, termination\n * predicate and initial state. `contFn` condition is checked only for the\n * initial value and at the end of processing of each chunk. `f` and `contFn`\n * must preserve chunking-invariance.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldChunks = internal.foldChunks;\n/**\n * A sink that effectfully folds its input chunks with the provided function,\n * termination predicate and initial state. `contFn` condition is checked only\n * for the initial value and at the end of processing of each chunk. `f` and\n * `contFn` must preserve chunking-invariance.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldChunksEffect = internal.foldChunksEffect;\n/**\n * A sink that effectfully folds its inputs with the provided function,\n * termination predicate and initial state.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldEffect = internal.foldEffect;\n/**\n * A sink that folds its inputs with the provided function and initial state.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldLeft = internal.foldLeft;\n/**\n * A sink that folds its input chunks with the provided function and initial\n * state. `f` must preserve chunking-invariance.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldLeftChunks = internal.foldLeftChunks;\n/**\n * A sink that effectfully folds its input chunks with the provided function\n * and initial state. `f` must preserve chunking-invariance.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldLeftChunksEffect = internal.foldLeftChunksEffect;\n/**\n * A sink that effectfully folds its inputs with the provided function and\n * initial state.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldLeftEffect = internal.foldLeftEffect;\n/**\n * Creates a sink that folds elements of type `In` into a structure of type\n * `S` until `max` elements have been folded.\n *\n * Like `Sink.foldWeighted`, but with a constant cost function of `1`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldUntil = internal.foldUntil;\n/**\n * Creates a sink that effectfully folds elements of type `In` into a\n * structure of type `S` until `max` elements have been folded.\n *\n * Like `Sink.foldWeightedEffect` but with a constant cost function of `1`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldUntilEffect = internal.foldUntilEffect;\n/**\n * Creates a sink that folds elements of type `In` into a structure of type\n * `S`, until `max` worth of elements (determined by the `costFn`) have been\n * folded.\n *\n * @note\n *   Elements that have an individual cost larger than `max` will force the\n *   sink to cross the `max` cost. See `Sink.foldWeightedDecompose` for a\n *   variant that can handle these cases.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldWeighted = internal.foldWeighted;\n/**\n * Creates a sink that folds elements of type `In` into a structure of type\n * `S`, until `max` worth of elements (determined by the `costFn`) have been\n * folded.\n *\n * The `decompose` function will be used for decomposing elements that cause\n * an `S` aggregate to cross `max` into smaller elements. For example:\n *\n * ```ts\n * pipe(\n *   Stream.make(1, 5, 1),\n *   Stream.transduce(\n *     Sink.foldWeightedDecompose(\n *       Chunk.empty<number>(),\n *       4,\n *       (n: number) => n,\n *       (n: number) => Chunk.make(n - 1, 1),\n *       (acc, el) => pipe(acc, Chunk.append(el))\n *     )\n *   ),\n *   Stream.runCollect\n * )\n * ```\n *\n * The stream would emit the elements `Chunk(1), Chunk(4), Chunk(1, 1)`.\n *\n * Be vigilant with this function, it has to generate \"simpler\" values or the\n * fold may never end. A value is considered indivisible if `decompose` yields\n * the empty chunk or a single-valued chunk. In these cases, there is no other\n * choice than to yield a value that will cross the threshold.\n *\n * `Sink.foldWeightedDecomposeEffect` allows the decompose function to return an\n * effect value, and consequently it allows the sink to fail.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldWeightedDecompose = internal.foldWeightedDecompose;\n/**\n * Creates a sink that effectfully folds elements of type `In` into a\n * structure of type `S`, until `max` worth of elements (determined by the\n * `costFn`) have been folded.\n *\n * The `decompose` function will be used for decomposing elements that cause\n * an `S` aggregate to cross `max` into smaller elements. Be vigilant with\n * this function, it has to generate \"simpler\" values or the fold may never\n * end. A value is considered indivisible if `decompose` yields the empty\n * chunk or a single-valued chunk. In these cases, there is no other choice\n * than to yield a value that will cross the threshold.\n *\n * See `Sink.foldWeightedDecompose` for an example.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldWeightedDecomposeEffect = internal.foldWeightedDecomposeEffect;\n/**\n * Creates a sink that effectfully folds elements of type `In` into a\n * structure of type `S`, until `max` worth of elements (determined by the\n * `costFn`) have been folded.\n *\n * @note\n *   Elements that have an individual cost larger than `max` will force the\n *   sink to cross the `max` cost. See `Sink.foldWeightedDecomposeEffect` for\n *   a variant that can handle these cases.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const foldWeightedEffect = internal.foldWeightedEffect;\n/**\n * A sink that executes the provided effectful function for every element fed\n * to it.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const forEach = internal.forEach;\n/**\n * A sink that executes the provided effectful function for every chunk fed to\n * it.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const forEachChunk = internal.forEachChunk;\n/**\n * A sink that executes the provided effectful function for every chunk fed to\n * it until `f` evaluates to `false`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const forEachChunkWhile = internal.forEachChunkWhile;\n/**\n * A sink that executes the provided effectful function for every element fed\n * to it until `f` evaluates to `false`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const forEachWhile = internal.forEachWhile;\n/**\n * Runs this sink until it yields a result, then uses that result to create\n * another sink from the provided function which will continue to run until it\n * yields a result.\n *\n * This function essentially runs sinks in sequence.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = internal.flatMap;\n/**\n * Creates a sink from a `Channel`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChannel = internal.fromChannel;\n/**\n * Creates a `Channel` from a Sink.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const toChannel = internal.toChannel;\n/**\n * Creates a single-value sink produced from an effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromEffect = internal.fromEffect;\n/**\n * Create a sink which publishes each element to the specified `PubSub`.\n *\n * @param shutdown If `true`, the `PubSub` will be shutdown after the sink is evaluated (defaults to `false`)\n * @since 2.0.0\n * @category constructors\n */\nexport const fromPubSub = internal.fromPubSub;\n/**\n * Creates a sink from a chunk processing function.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromPush = internal.fromPush;\n/**\n * Create a sink which enqueues each element into the specified queue.\n *\n * @param shutdown If `true`, the queue will be shutdown after the sink is evaluated (defaults to `false`)\n * @since 2.0.0\n * @category constructors\n */\nexport const fromQueue = internal.fromQueue;\n/**\n * Creates a sink containing the first value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const head = internal.head;\n/**\n * Drains the remaining elements from the stream after the sink finishes\n *\n * @since 2.0.0\n * @category utils\n */\nexport const ignoreLeftover = internal.ignoreLeftover;\n/**\n * Creates a sink containing the last value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const last = internal.last;\n/**\n * Creates a sink that does not consume any input but provides the given chunk\n * as its leftovers\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const leftover = internal.leftover;\n/**\n * Transforms this sink's result.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * Effectfully transforms this sink's result.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapEffect = internal.mapEffect;\n/**\n * Transforms the errors emitted by this sink using `f`.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapError = internal.mapError;\n/**\n * Transforms the leftovers emitted by this sink using `f`.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapLeftover = internal.mapLeftover;\n/**\n * Creates a sink which transforms it's inputs into a string.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const mkString = internal.mkString;\n/**\n * Creates a sink which never terminates.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const never = internal.never;\n/**\n * Switch to another sink in case of failure\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElse = internal.orElse;\n/**\n * Provides the sink with its required context, which eliminates its\n * dependency on `R`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideContext = internal.provideContext;\n/**\n * Runs both sinks in parallel on the input, , returning the result or the\n * error from the one that finishes first.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const race = internal.race;\n/**\n * Runs both sinks in parallel on the input, returning the result or the error\n * from the one that finishes first.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const raceBoth = internal.raceBoth;\n/**\n * Runs both sinks in parallel on the input, using the specified merge\n * function as soon as one result or the other has been computed.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const raceWith = internal.raceWith;\n/**\n * @since 2.0.0\n * @category error handling\n */\nexport const refineOrDie = internal.refineOrDie;\n/**\n * @since 2.0.0\n * @category error handling\n */\nexport const refineOrDieWith = internal.refineOrDieWith;\n/**\n * A sink that returns whether an element satisfies the specified predicate.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const some = internal.some;\n/**\n * Splits the sink on the specified predicate, returning a new sink that\n * consumes elements until an element after the first satisfies the specified\n * predicate.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const splitWhere = internal.splitWhere;\n/**\n * A sink that immediately ends with the specified value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = internal.succeed;\n/**\n * A sink that sums incoming numeric values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sum = internal.sum;\n/**\n * Summarize a sink by running an effect when the sink starts and again when\n * it completes.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const summarized = internal.summarized;\n/**\n * Returns a lazily constructed sink that may require effects for its\n * creation.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const suspend = internal.suspend;\n/**\n * A sink that immediately ends with the specified lazy value.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sync = internal.sync;\n/**\n * A sink that takes the specified number of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const take = internal.take;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const timed = internal.timed;\n/**\n * Creates a sink produced from an effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrap = internal.unwrap;\n/**\n * Creates a sink produced from a scoped effect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrapScoped = internal.unwrapScoped;\n/**\n * Returns the sink that executes this one and times its execution.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const withDuration = internal.withDuration;\n/**\n * Feeds inputs to this sink until it yields a result, then switches over to\n * the provided sink until it yields a result, finally combining the two\n * results into a tuple.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = internal.zip;\n/**\n * Like `Sink.zip` but keeps only the result from this sink.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = internal.zipLeft;\n/**\n * Like `Sink.zip` but keeps only the result from `that` sink.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = internal.zipRight;\n/**\n * Feeds inputs to this sink until it yields a result, then switches over to\n * the provided sink until it yields a result, finally combining the two\n * results with `f`.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = internal.zipWith;\n//# sourceMappingURL=Sink.js.map","/**\n * @since 2.0.0\n */\nimport * as Equal from \"./Equal.js\";\nimport * as Dual from \"./Function.js\";\nimport { pipe } from \"./Function.js\";\nimport * as Hash from \"./Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"./Inspectable.js\";\nimport { pipeArguments } from \"./Pipeable.js\";\nimport { hasProperty } from \"./Predicate.js\";\nimport * as RBT from \"./RedBlackTree.js\";\nconst TypeId = /*#__PURE__*/Symbol.for(\"effect/SortedSet\");\nconst SortedSetProto = {\n  [TypeId]: {\n    _A: _ => _\n  },\n  [Hash.symbol]() {\n    return pipe(Hash.hash(this.keyTree), Hash.combine(Hash.hash(TypeId)), Hash.cached(this));\n  },\n  [Equal.symbol](that) {\n    return isSortedSet(that) && Equal.equals(this.keyTree, that.keyTree);\n  },\n  [Symbol.iterator]() {\n    return RBT.keys(this.keyTree);\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"SortedSet\",\n      values: Array.from(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst fromTree = keyTree => {\n  const a = Object.create(SortedSetProto);\n  a.keyTree = keyTree;\n  return a;\n};\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isSortedSet = u => hasProperty(u, TypeId);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = O => fromTree(RBT.empty(O));\n/**\n * Creates a new `SortedSet` from an iterable collection of values.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = /*#__PURE__*/Dual.dual(2, (iterable, ord) => fromTree(RBT.fromIterable(Array.from(iterable).map(k => [k, true]), ord)));\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = ord => (...entries) => fromIterable(entries, ord);\n/**\n * @since 2.0.0\n * @category elements\n */\nexport const add = /*#__PURE__*/Dual.dual(2, (self, value) => RBT.has(self.keyTree, value) ? self : fromTree(RBT.insert(self.keyTree, value, true)));\n/**\n * @since 2.0.0\n */\nexport const difference = /*#__PURE__*/Dual.dual(2, (self, that) => {\n  let out = self;\n  for (const value of that) {\n    out = remove(out, value);\n  }\n  return out;\n});\n/**\n * Check if a predicate holds true for every `SortedSet` element.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const every = /*#__PURE__*/Dual.dual(2, (self, predicate) => {\n  for (const value of self) {\n    if (!predicate(value)) {\n      return false;\n    }\n  }\n  return true;\n});\n/**\n * @since 2.0.0\n * @category filtering\n */\nexport const filter = /*#__PURE__*/Dual.dual(2, (self, predicate) => {\n  const ord = RBT.getOrder(self.keyTree);\n  let out = empty(ord);\n  for (const value of self) {\n    if (predicate(value)) {\n      out = add(out, value);\n    }\n  }\n  return out;\n});\n/**\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = /*#__PURE__*/Dual.dual(3, (self, O, f) => {\n  let out = empty(O);\n  forEach(self, a => {\n    for (const b of f(a)) {\n      out = add(out, b);\n    }\n  });\n  return out;\n});\n/**\n * @since 2.0.0\n * @category traversing\n */\nexport const forEach = /*#__PURE__*/Dual.dual(2, (self, f) => RBT.forEach(self.keyTree, f));\n/**\n * @since 2.0.0\n * @category elements\n */\nexport const has = /*#__PURE__*/Dual.dual(2, (self, value) => RBT.has(self.keyTree, value));\n/**\n * @since 2.0.0\n */\nexport const intersection = /*#__PURE__*/Dual.dual(2, (self, that) => {\n  const ord = RBT.getOrder(self.keyTree);\n  let out = empty(ord);\n  for (const value of that) {\n    if (has(self, value)) {\n      out = add(out, value);\n    }\n  }\n  return out;\n});\n/**\n * @since 2.0.0\n * @category elements\n */\nexport const isSubset = /*#__PURE__*/Dual.dual(2, (self, that) => every(self, a => has(that, a)));\n/**\n * @since 2.0.0\n * @category mapping\n */\nexport const map = /*#__PURE__*/Dual.dual(3, (self, O, f) => {\n  let out = empty(O);\n  forEach(self, a => {\n    const b = f(a);\n    if (!has(out, b)) {\n      out = add(out, b);\n    }\n  });\n  return out;\n});\n/**\n * @since 2.0.0\n * @category filtering\n */\nexport const partition = /*#__PURE__*/Dual.dual(2, (self, predicate) => {\n  const ord = RBT.getOrder(self.keyTree);\n  let right = empty(ord);\n  let left = empty(ord);\n  for (const value of self) {\n    if (predicate(value)) {\n      right = add(right, value);\n    } else {\n      left = add(left, value);\n    }\n  }\n  return [left, right];\n});\n/**\n * @since 2.0.0\n * @category elements\n */\nexport const remove = /*#__PURE__*/Dual.dual(2, (self, value) => fromTree(RBT.removeFirst(self.keyTree, value)));\n/**\n * @since 2.0.0\n * @category getters\n */\nexport const size = self => RBT.size(self.keyTree);\n/**\n * Check if a predicate holds true for some `SortedSet` element.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const some = /*#__PURE__*/Dual.dual(2, (self, predicate) => {\n  for (const value of self) {\n    if (predicate(value)) {\n      return true;\n    }\n  }\n  return false;\n});\n/**\n * @since 2.0.0\n * @category elements\n */\nexport const toggle = /*#__PURE__*/Dual.dual(2, (self, value) => has(self, value) ? remove(self, value) : add(self, value));\n/**\n * @since 2.0.0\n */\nexport const union = /*#__PURE__*/Dual.dual(2, (self, that) => {\n  const ord = RBT.getOrder(self.keyTree);\n  let out = empty(ord);\n  for (const value of self) {\n    out = add(value)(out);\n  }\n  for (const value of that) {\n    out = add(value)(out);\n  }\n  return out;\n});\n/**\n * @since 2.0.0\n * @category getters\n */\nexport const values = self => RBT.keys(self.keyTree);\n/**\n * @since 2.0.0\n * @category equivalence\n */\nexport const getEquivalence = () => (a, b) => isSubset(a, b) && isSubset(b, a);\n//# sourceMappingURL=SortedSet.js.map","import * as _groupBy from \"./internal/groupBy.js\";\nimport * as internal from \"./internal/stream.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const StreamTypeId = internal.StreamTypeId;\n/**\n * The default chunk size used by the various combinators and constructors of\n * `Stream`.\n *\n * @since 2.0.0\n * @category constants\n */\nexport const DefaultChunkSize = internal.DefaultChunkSize;\n/**\n * Collects each underlying Chunk of the stream into a new chunk, and emits it\n * on each pull.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const accumulate = internal.accumulate;\n/**\n * Re-chunks the elements of the stream by accumulating each underlying chunk.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const accumulateChunks = internal.accumulateChunks;\n/**\n * Creates a stream from a single value that will get cleaned up after the\n * stream is consumed.\n *\n * @example\n * import { Console, Effect, Stream } from \"effect\"\n *\n * // Simulating File operations\n * const open = (filename: string) =>\n *   Effect.gen(function*() {\n *     yield* Console.log(`Opening ${filename}`)\n *     return {\n *       getLines: Effect.succeed([\"Line 1\", \"Line 2\", \"Line 3\"]),\n *       close: Console.log(`Closing ${filename}`)\n *     }\n *   })\n *\n * const stream = Stream.acquireRelease(\n *   open(\"file.txt\"),\n *   (file) => file.close\n * ).pipe(Stream.flatMap((file) => file.getLines))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Opening file.txt\n * // Closing file.txt\n * // { _id: 'Chunk', values: [ [ 'Line 1', 'Line 2', 'Line 3' ] ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const acquireRelease = internal.acquireRelease;\n/**\n * Aggregates elements of this stream using the provided sink for as long as\n * the downstream operators on the stream are busy.\n *\n * This operator divides the stream into two asynchronous \"islands\". Operators\n * upstream of this operator run on one fiber, while downstream operators run\n * on another. Whenever the downstream fiber is busy processing elements, the\n * upstream fiber will feed elements into the sink until it signals\n * completion.\n *\n * Any sink can be used here, but see `Sink.foldWeightedEffect` and\n * `Sink.foldUntilEffect` for sinks that cover the common usecases.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const aggregate = internal.aggregate;\n/**\n * Like `aggregateWithinEither`, but only returns the `Right` results.\n *\n * @param sink A `Sink` used to perform the aggregation.\n * @param schedule A `Schedule` used to signal when to stop the aggregation.\n * @since 2.0.0\n * @category utils\n */\nexport const aggregateWithin = internal.aggregateWithin;\n/**\n * Aggregates elements using the provided sink until it completes, or until\n * the delay signalled by the schedule has passed.\n *\n * This operator divides the stream into two asynchronous islands. Operators\n * upstream of this operator run on one fiber, while downstream operators run\n * on another. Elements will be aggregated by the sink until the downstream\n * fiber pulls the aggregated value, or until the schedule's delay has passed.\n *\n * Aggregated elements will be fed into the schedule to determine the delays\n * between pulls.\n *\n * @param sink A `Sink` used to perform the aggregation.\n * @param schedule A `Schedule` used to signal when to stop the aggregation.\n * @since 2.0.0\n * @category utils\n */\nexport const aggregateWithinEither = internal.aggregateWithinEither;\n/**\n * Maps the success values of this stream to the specified constant value.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.range(1, 5).pipe(Stream.as(null))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ null, null, null, null, null ] }\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const as = internal.as;\nconst _async = internal._async;\nexport {\n/**\n * Creates a stream from an asynchronous callback that can be called multiple\n * times. The optionality of the error type `E` in `Emit` can be used to\n * signal the end of the stream by setting it to `None`.\n *\n * The registration function can optionally return an `Effect`, which will be\n * executed if the `Fiber` executing this Effect is interrupted.\n *\n * @example\n * import type { StreamEmit } from \"effect\"\n * import { Chunk, Effect, Option, Stream } from \"effect\"\n *\n * const events = [1, 2, 3, 4]\n *\n * const stream = Stream.async(\n *   (emit: StreamEmit.Emit<never, never, number, void>) => {\n *     events.forEach((n) => {\n *       setTimeout(() => {\n *         if (n === 3) {\n *           emit(Effect.fail(Option.none())) // Terminate the stream\n *         } else {\n *           emit(Effect.succeed(Chunk.of(n))) // Add the current item to the stream\n *         }\n *       }, 100 * n)\n *     })\n *   }\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\n_async as async };\n/**\n * Creates a stream from an asynchronous callback that can be called multiple\n * times The registration of the callback itself returns an effect. The\n * optionality of the error type `E` can be used to signal the end of the\n * stream, by setting it to `None`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const asyncEffect = internal.asyncEffect;\n/**\n * Creates a stream from an asynchronous callback that can be called multiple\n * times. The registration of the callback itself returns an a scoped\n * resource. The optionality of the error type `E` can be used to signal the\n * end of the stream, by setting it to `None`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const asyncScoped = internal.asyncScoped;\n/**\n * Returns a `Stream` that first collects `n` elements from the input `Stream`,\n * and then creates a new `Stream` using the specified function, and sends all\n * the following elements through that.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const branchAfter = internal.branchAfter;\n/**\n * Fan out the stream, producing a list of streams that have the same elements\n * as this stream. The driver stream will only ever advance the `maximumLag`\n * chunks before the slowest downstream stream.\n *\n * @example\n * import { Console, Effect, Fiber, Schedule, Stream } from \"effect\"\n *\n * const numbers = Effect.scoped(\n *   Stream.range(1, 20).pipe(\n *     Stream.tap((n) => Console.log(`Emit ${n} element before broadcasting`)),\n *     Stream.broadcast(2, 5),\n *     Stream.flatMap(([first, second]) =>\n *       Effect.gen(function*() {\n *         const fiber1 = yield* Stream.runFold(first, 0, (acc, e) => Math.max(acc, e)).pipe(\n *           Effect.andThen((max) => Console.log(`Maximum: ${max}`)),\n *           Effect.fork\n *         )\n *         const fiber2 = yield* second.pipe(\n *           Stream.schedule(Schedule.spaced(\"1 second\")),\n *           Stream.runForEach((n) => Console.log(`Logging to the Console: ${n}`)),\n *           Effect.fork\n *         )\n *         yield* Fiber.join(fiber1).pipe(\n *           Effect.zip(Fiber.join(fiber2), { concurrent: true })\n *         )\n *       })\n *     ),\n *     Stream.runCollect\n *   )\n * )\n *\n * // Effect.runPromise(numbers).then(console.log)\n * // Emit 1 element before broadcasting\n * // Emit 2 element before broadcasting\n * // Emit 3 element before broadcasting\n * // Emit 4 element before broadcasting\n * // Emit 5 element before broadcasting\n * // Emit 6 element before broadcasting\n * // Emit 7 element before broadcasting\n * // Emit 8 element before broadcasting\n * // Emit 9 element before broadcasting\n * // Emit 10 element before broadcasting\n * // Emit 11 element before broadcasting\n * // Logging to the Console: 1\n * // Logging to the Console: 2\n * // Logging to the Console: 3\n * // Logging to the Console: 4\n * // Logging to the Console: 5\n * // Emit 12 element before broadcasting\n * // Emit 13 element before broadcasting\n * // Emit 14 element before broadcasting\n * // Emit 15 element before broadcasting\n * // Emit 16 element before broadcasting\n * // Logging to the Console: 6\n * // Logging to the Console: 7\n * // Logging to the Console: 8\n * // Logging to the Console: 9\n * // Logging to the Console: 10\n * // Emit 17 element before broadcasting\n * // Emit 18 element before broadcasting\n * // Emit 19 element before broadcasting\n * // Emit 20 element before broadcasting\n * // Logging to the Console: 11\n * // Logging to the Console: 12\n * // Logging to the Console: 13\n * // Logging to the Console: 14\n * // Logging to the Console: 15\n * // Maximum: 20\n * // Logging to the Console: 16\n * // Logging to the Console: 17\n * // Logging to the Console: 18\n * // Logging to the Console: 19\n * // Logging to the Console: 20\n * // { _id: 'Chunk', values: [ undefined ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const broadcast = internal.broadcast;\n/**\n * Fan out the stream, producing a dynamic number of streams that have the\n * same elements as this stream. The driver stream will only ever advance the\n * `maximumLag` chunks before the slowest downstream stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const broadcastDynamic = internal.broadcastDynamic;\n/**\n * Converts the stream to a scoped list of queues. Every value will be\n * replicated to every queue with the slowest queue being allowed to buffer\n * `maximumLag` chunks before the driver is back pressured.\n *\n * Queues can unsubscribe from upstream by shutting down.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const broadcastedQueues = internal.broadcastedQueues;\n/**\n * Converts the stream to a scoped dynamic amount of queues. Every chunk will\n * be replicated to every queue with the slowest queue being allowed to buffer\n * `maximumLag` chunks before the driver is back pressured.\n *\n * Queues can unsubscribe from upstream by shutting down.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const broadcastedQueuesDynamic = internal.broadcastedQueuesDynamic;\n/**\n * Allows a faster producer to progress independently of a slower consumer by\n * buffering up to `capacity` elements in a queue.\n *\n * Note: This combinator destroys the chunking structure. It's recommended to\n *       use rechunk afterwards. Additionally, prefer capacities that are powers\n *       of 2 for better performance.\n *\n * @example\n * import { Console, Effect, Schedule, Stream } from \"effect\"\n *\n * const stream = Stream.range(1, 10).pipe(\n *   Stream.tap((n) => Console.log(`before buffering: ${n}`)),\n *   Stream.buffer({ capacity: 4 }),\n *   Stream.tap((n) => Console.log(`after buffering: ${n}`)),\n *   Stream.schedule(Schedule.spaced(\"5 seconds\"))\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // before buffering: 1\n * // before buffering: 2\n * // before buffering: 3\n * // before buffering: 4\n * // before buffering: 5\n * // before buffering: 6\n * // after buffering: 1\n * // after buffering: 2\n * // before buffering: 7\n * // after buffering: 3\n * // before buffering: 8\n * // after buffering: 4\n * // before buffering: 9\n * // after buffering: 5\n * // before buffering: 10\n * // ...\n *\n * @since 2.0.0\n * @category utils\n */\nexport const buffer = internal.buffer;\n/**\n * Allows a faster producer to progress independently of a slower consumer by\n * buffering up to `capacity` chunks in a queue.\n *\n * @note Prefer capacities that are powers of 2 for better performance.\n * @since 2.0.0\n * @category utils\n */\nexport const bufferChunks = internal.bufferChunks;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails with a typed error.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAll = internal.catchAll;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails. Allows recovery from all causes of failure, including\n * interruption if the stream is uninterruptible.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAllCause = internal.catchAllCause;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails with some typed error.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchSome = internal.catchSome;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails with an error matching the given `_tag`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchTag = internal.catchTag;\n/**\n * Switches over to the stream produced by one of the provided functions, in\n * case this one fails with an error matching one of the given `_tag`'s.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchTags = internal.catchTags;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails with some errors. Allows recovery from all causes of failure,\n * including interruption if the stream is uninterruptible.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchSomeCause = internal.catchSomeCause;\n/**\n * Returns a new stream that only emits elements that are not equal to the\n * previous element emitted, using natural equality to determine whether two\n * elements are equal.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 1, 1, 2, 2, 3, 4).pipe(Stream.changes)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const changes = internal.changes;\n/**\n * Returns a new stream that only emits elements that are not equal to the\n * previous element emitted, using the specified function to determine whether\n * two elements are equal.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const changesWith = internal.changesWith;\n/**\n * Returns a new stream that only emits elements that are not equal to the\n * previous element emitted, using the specified effectual function to\n * determine whether two elements are equal.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const changesWithEffect = internal.changesWithEffect;\n/**\n * Exposes the underlying chunks of the stream as a stream of chunks of\n * elements.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const chunks = internal.chunks;\n/**\n * Performs the specified stream transformation with the chunk structure of\n * the stream exposed.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const chunksWith = internal.chunksWith;\n/**\n * Combines the elements from this stream and the specified stream by\n * repeatedly applying the function `f` to extract an element using both sides\n * and conceptually \"offer\" it to the destination stream. `f` can maintain\n * some internal state to control the combining process, with the initial\n * state being specified by `s`.\n *\n * Where possible, prefer `Stream.combineChunks` for a more efficient\n * implementation.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const combine = internal.combine;\n/**\n * Combines the chunks from this stream and the specified stream by repeatedly\n * applying the function `f` to extract a chunk using both sides and\n * conceptually \"offer\" it to the destination stream. `f` can maintain some\n * internal state to control the combining process, with the initial state\n * being specified by `s`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const combineChunks = internal.combineChunks;\n/**\n * Concatenates the specified stream with this stream, resulting in a stream\n * that emits the elements from this stream and then the elements from the\n * specified stream.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3)\n * const s2 = Stream.make(4, 5)\n *\n * const stream = Stream.concat(s1, s2)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const concat = internal.concat;\n/**\n * Concatenates all of the streams in the chunk to one stream.\n *\n * @example\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3)\n * const s2 = Stream.make(4, 5)\n * const s3 = Stream.make(6, 7, 8)\n *\n * const stream = Stream.concatAll(Chunk.make(s1, s2, s3))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     1, 2, 3, 4,\n * //     5, 6, 7, 8\n * //   ]\n * // }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const concatAll = internal.concatAll;\n/**\n * Composes this stream with the specified stream to create a cartesian\n * product of elements. The `that` stream would be run multiple times, for\n * every element in the `this` stream.\n *\n * See also `Stream.zip` for the more common point-wise variant.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3)\n * const s2 = Stream.make(\"a\", \"b\")\n *\n * const product = Stream.cross(s1, s2)\n *\n * // Effect.runPromise(Stream.runCollect(product)).then(console.log)\n * // {\n * //   _id: \"Chunk\",\n * //   values: [\n * //     [ 1, \"a\" ], [ 1, \"b\" ], [ 2, \"a\" ], [ 2, \"b\" ], [ 3, \"a\" ], [ 3, \"b\" ]\n * //   ]\n * // }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const cross = internal.cross;\n/**\n * Composes this stream with the specified stream to create a cartesian\n * product of elements, but keeps only elements from this stream. The `that`\n * stream would be run multiple times, for every element in the `this` stream.\n *\n * See also `Stream.zipLeft` for the more common point-wise variant.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const crossLeft = internal.crossLeft;\n/**\n * Composes this stream with the specified stream to create a cartesian\n * product of elements, but keeps only elements from the other stream. The\n * `that` stream would be run multiple times, for every element in the `this`\n * stream.\n *\n * See also `Stream.zipRight` for the more common point-wise variant.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const crossRight = internal.crossRight;\n/**\n * Composes this stream with the specified stream to create a cartesian\n * product of elements with a specified function. The `that` stream would be\n * run multiple times, for every element in the `this` stream.\n *\n * See also `Stream.zipWith` for the more common point-wise variant.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const crossWith = internal.crossWith;\n/**\n * Delays the emission of values by holding new values for a set duration. If\n * no new values arrive during that time the value is emitted, however if a\n * new value is received during the holding period the previous value is\n * discarded and the process is repeated with the new value.\n *\n * This operator is useful if you have a stream of \"bursty\" events which\n * eventually settle down and you only need the final event of the burst. For\n * example, a search engine may only want to initiate a search after a user\n * has paused typing so as to not prematurely recommend results.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * let last = Date.now()\n * const log = (message: string) =>\n *   Effect.sync(() => {\n *     const end = Date.now()\n *     console.log(`${message} after ${end - last}ms`)\n *     last = end\n *   })\n *\n * const stream = Stream.make(1, 2, 3).pipe(\n *   Stream.concat(\n *     Stream.fromEffect(Effect.sleep(\"200 millis\").pipe(Effect.as(4))) // Emit 4 after 200 ms\n *   ),\n *   Stream.concat(Stream.make(5, 6)), // Continue with more rapid values\n *   Stream.concat(\n *     Stream.fromEffect(Effect.sleep(\"150 millis\").pipe(Effect.as(7))) // Emit 7 after 150 ms\n *   ),\n *   Stream.concat(Stream.make(8)),\n *   Stream.tap((n) => log(`Received ${n}`)),\n *   Stream.debounce(\"100 millis\"), // Only emit values after a pause of at least 100 milliseconds,\n *   Stream.tap((n) => log(`> Emitted ${n}`))\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Received 1 after 5ms\n * // Received 2 after 2ms\n * // Received 3 after 0ms\n * // > Emitted 3 after 104ms\n * // Received 4 after 99ms\n * // Received 5 after 1ms\n * // Received 6 after 0ms\n * // > Emitted 6 after 101ms\n * // Received 7 after 50ms\n * // Received 8 after 1ms\n * // > Emitted 8 after 101ms\n * // { _id: 'Chunk', values: [ 3, 6, 8 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const debounce = internal.debounce;\n/**\n * The stream that dies with the specified defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const die = internal.die;\n/**\n * The stream that dies with the specified lazily evaluated defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dieSync = internal.dieSync;\n/**\n * The stream that dies with an exception described by `message`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dieMessage = internal.dieMessage;\n/**\n * More powerful version of `Stream.broadcast`. Allows to provide a function\n * that determines what queues should receive which elements. The decide\n * function will receive the indices of the queues in the resulting list.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const distributedWith = internal.distributedWith;\n/**\n * More powerful version of `Stream.distributedWith`. This returns a function\n * that will produce new queues and corresponding indices. You can also\n * provide a function that will be executed after the final events are\n * enqueued in all queues. Shutdown of the queues is handled by the driver.\n * Downstream users can also shutdown queues manually. In this case the driver\n * will continue but no longer backpressure on them.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const distributedWithDynamic = internal.distributedWithDynamic;\n/**\n * Converts this stream to a stream that executes its effects but emits no\n * elements. Useful for sequencing effects using streams:\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * // We create a stream and immediately drain it.\n * const stream = Stream.range(1, 6).pipe(Stream.drain)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const drain = internal.drain;\n/**\n * Drains the provided stream in the background for as long as this stream is\n * running. If this stream ends before `other`, `other` will be interrupted.\n * If `other` fails, this stream will fail with that error.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const drainFork = internal.drainFork;\n/**\n * Drops the specified number of elements from this stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const drop = internal.drop;\n/**\n * Drops the last specified number of elements from this stream.\n *\n * @note This combinator keeps `n` elements in memory. Be careful with big\n *       numbers.\n * @since 2.0.0\n * @category utils\n */\nexport const dropRight = internal.dropRight;\n/**\n * Drops all elements of the stream until the specified predicate evaluates to\n * `true`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dropUntil = internal.dropUntil;\n/**\n * Drops all elements of the stream until the specified effectful predicate\n * evaluates to `true`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dropUntilEffect = internal.dropUntilEffect;\n/**\n * Drops all elements of the stream for as long as the specified predicate\n * evaluates to `true`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dropWhile = internal.dropWhile;\n/**\n * Drops all elements of the stream for as long as the specified predicate\n * produces an effect that evalutates to `true`\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dropWhileEffect = internal.dropWhileEffect;\n/**\n * Returns a stream whose failures and successes have been lifted into an\n * `Either`. The resulting stream cannot fail, because the failures have been\n * exposed as part of the `Either` success case.\n *\n * @note The stream will end as soon as the first error occurs.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const either = internal.either;\n/**\n * The empty stream.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.empty\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * Executes the provided finalizer after this stream's finalizers run.\n *\n * @example\n * import { Console, Effect, Stream } from \"effect\"\n *\n * const program = Stream.fromEffect(Console.log(\"Application Logic.\")).pipe(\n *   Stream.concat(Stream.finalizer(Console.log(\"Finalizing the stream\"))),\n *   Stream.ensuring(\n *     Console.log(\"Doing some other works after stream's finalization\")\n *   )\n * )\n *\n * // Effect.runPromise(Stream.runCollect(program)).then(console.log)\n * // Application Logic.\n * // Finalizing the stream\n * // Doing some other works after stream's finalization\n * // { _id: 'Chunk', values: [ undefined, undefined ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const ensuring = internal.ensuring;\n/**\n * Executes the provided finalizer after this stream's finalizers run.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const ensuringWith = internal.ensuringWith;\n/**\n * Accesses the whole context of the stream.\n *\n * @since 2.0.0\n * @category context\n */\nexport const context = internal.context;\n/**\n * Accesses the context of the stream.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWith = internal.contextWith;\n/**\n * Accesses the context of the stream in the context of an effect.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWithEffect = internal.contextWithEffect;\n/**\n * Accesses the context of the stream in the context of a stream.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWithStream = internal.contextWithStream;\n/**\n * Creates a stream that executes the specified effect but emits no elements.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const execute = internal.execute;\n/**\n * Terminates with the specified error.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.fail(\"Uh oh!\")\n *\n * Effect.runPromiseExit(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Exit',\n * //   _tag: 'Failure',\n * //   cause: { _id: 'Cause', _tag: 'Fail', failure: 'Uh oh!' }\n * // }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = internal.fail;\n/**\n * Terminates with the specified lazily evaluated error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failSync = internal.failSync;\n/**\n * The stream that always fails with the specified `Cause`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCause = internal.failCause;\n/**\n * The stream that always fails with the specified lazily evaluated `Cause`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCauseSync = internal.failCauseSync;\n/**\n * Filters the elements emitted by this stream using the provided function.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.range(1, 11).pipe(Stream.filter((n) => n % 2 === 0))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 2, 4, 6, 8, 10 ] }\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filter = internal.filter;\n/**\n * Effectfully filters the elements emitted by this stream.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filterEffect = internal.filterEffect;\n/**\n * Performs a filter and map in a single step.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const filterMap = internal.filterMap;\n/**\n * Performs an effectful filter and map in a single step.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const filterMapEffect = internal.filterMapEffect;\n/**\n * Transforms all elements of the stream for as long as the specified partial\n * function is defined.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const filterMapWhile = internal.filterMapWhile;\n/**\n * Effectfully transforms all elements of the stream for as long as the\n * specified partial function is defined.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const filterMapWhileEffect = internal.filterMapWhileEffect;\n/**\n * Creates a one-element stream that never fails and executes the finalizer\n * when it ends.\n *\n * @example\n * import { Console, Effect, Stream } from \"effect\"\n *\n * const application = Stream.fromEffect(Console.log(\"Application Logic.\"))\n *\n * const deleteDir = (dir: string) => Console.log(`Deleting dir: ${dir}`)\n *\n * const program = application.pipe(\n *   Stream.concat(\n *     Stream.finalizer(\n *       deleteDir(\"tmp\").pipe(\n *         Effect.andThen(Console.log(\"Temporary directory was deleted.\"))\n *       )\n *     )\n *   )\n * )\n *\n * // Effect.runPromise(Stream.runCollect(program)).then(console.log)\n * // Application Logic.\n * // Deleting dir: tmp\n * // Temporary directory was deleted.\n * // { _id: 'Chunk', values: [ undefined, undefined ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const finalizer = internal.finalizer;\n/**\n * Finds the first element emitted by this stream that satisfies the provided\n * predicate.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const find = internal.find;\n/**\n * Finds the first element emitted by this stream that satisfies the provided\n * effectful predicate.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const findEffect = internal.findEffect;\n/**\n * Returns a stream made of the concatenation in strict order of all the\n * streams produced by passing each element of this stream to `f0`\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = internal.flatMap;\n/**\n * Flattens this stream-of-streams into a stream made of the concatenation in\n * strict order of all the streams.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatten = internal.flatten;\n/**\n * Submerges the chunks carried by this stream into the stream's structure,\n * while still preserving them.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenChunks = internal.flattenChunks;\n/**\n * Flattens `Effect` values into the stream's structure, preserving all\n * information about the effect.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenEffect = internal.flattenEffect;\n/**\n * Unwraps `Exit` values that also signify end-of-stream by failing with `None`.\n *\n * For `Exit` values that do not signal end-of-stream, prefer:\n *\n * ```ts\n * stream.mapZIO(ZIO.done(_))\n * ```\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenExitOption = internal.flattenExitOption;\n/**\n * Submerges the iterables carried by this stream into the stream's structure,\n * while still preserving them.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenIterables = internal.flattenIterables;\n/**\n * Unwraps `Exit` values and flatten chunks that also signify end-of-stream\n * by failing with `None`.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenTake = internal.flattenTake;\n/**\n * Repeats this stream forever.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const forever = internal.forever;\n/**\n * Creates a stream from an `AsyncIterable`.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const myAsyncIterable = async function*() {\n *   yield 1\n *   yield 2\n * }\n *\n * const stream = Stream.fromAsyncIterable(\n *   myAsyncIterable(),\n *   (e) => new Error(String(e)) // Error Handling\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromAsyncIterable = internal.fromAsyncIterable;\n/**\n * Creates a stream from a `Channel`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChannel = internal.fromChannel;\n/**\n * Creates a channel from a `Stream`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const toChannel = internal.toChannel;\n/**\n * Creates a stream from a `Chunk` of values.\n *\n * @example\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * // Creating a stream with values from a single Chunk\n * const stream = Stream.fromChunk(Chunk.make(1, 2, 3))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChunk = internal.fromChunk;\n/**\n * Creates a stream from a subscription to a `PubSub`.\n *\n * @param shutdown If `true`, the `PubSub` will be shutdown after the stream is evaluated (defaults to `false`)\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChunkPubSub = internal.fromChunkPubSub;\n/**\n * Creates a stream from a `Queue` of values.\n *\n * @param shutdown If `true`, the queue will be shutdown after the stream is evaluated (defaults to `false`)\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChunkQueue = internal.fromChunkQueue;\n/**\n * Creates a stream from an arbitrary number of chunks.\n *\n * @example\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * // Creating a stream with values from multiple Chunks\n * const stream = Stream.fromChunks(Chunk.make(1, 2, 3), Chunk.make(4, 5, 6))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5, 6 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChunks = internal.fromChunks;\n/**\n * Either emits the success value of this effect or terminates the stream\n * with the failure value of this effect.\n *\n * @example\n * import { Effect, Random, Stream } from \"effect\"\n *\n * const stream = Stream.fromEffect(Random.nextInt)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Example Output: { _id: 'Chunk', values: [ 922694024 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromEffect = internal.fromEffect;\n/**\n * Creates a stream from an effect producing a value of type `A` or an empty\n * `Stream`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromEffectOption = internal.fromEffectOption;\n/**\n * Creates a stream from a subscription to a `PubSub`.\n *\n * @param shutdown If `true`, the `PubSub` will be shutdown after the stream is evaluated (defaults to `false`)\n * @since 2.0.0\n * @category constructors\n */\nexport const fromPubSub = internal.fromPubSub;\n/**\n * Creates a new `Stream` from an iterable collection of values.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n *\n * const stream = Stream.fromIterable(numbers)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = internal.fromIterable;\n/**\n * Creates a stream from an effect producing a value of type `Iterable<A>`.\n *\n * @example\n * import { Context, Effect, Stream } from \"effect\"\n *\n * class Database extends Context.Tag(\"Database\")<\n *   Database,\n *   { readonly getUsers: Effect.Effect<Array<string>> }\n * >() {}\n *\n * const getUsers = Database.pipe(Effect.andThen((_) => _.getUsers))\n *\n * const stream = Stream.fromIterableEffect(getUsers)\n *\n * // Effect.runPromise(\n * //   Stream.runCollect(stream.pipe(Stream.provideService(Database, { getUsers: Effect.succeed([\"user1\", \"user2\"]) })))\n * // ).then(console.log)\n * // { _id: 'Chunk', values: [ 'user1', 'user2' ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterableEffect = internal.fromIterableEffect;\n/**\n * Creates a stream from an iterator\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIteratorSucceed = internal.fromIteratorSucceed;\n/**\n * Creates a stream from an effect that pulls elements from another stream.\n *\n * See `Stream.toPull` for reference.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromPull = internal.fromPull;\n/**\n * Creates a stream from a queue of values\n *\n * @param maxChunkSize The maximum number of queued elements to put in one chunk in the stream\n * @param shutdown If `true`, the queue will be shutdown after the stream is evaluated (defaults to `false`)\n * @since 2.0.0\n * @category constructors\n */\nexport const fromQueue = internal.fromQueue;\n/**\n * Creates a stream from a `ReadableStream`.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromReadableStream = internal.fromReadableStream;\n/**\n * Creates a stream from a `ReadableStreamBYOBReader`.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStreamBYOBReader.\n *\n * @param allocSize Controls the size of the underlying `ArrayBuffer` (defaults to `4096`).\n * @since 2.0.0\n * @category constructors\n */\nexport const fromReadableStreamByob = internal.fromReadableStreamByob;\n/**\n * Creates a stream from a `Schedule` that does not require any further\n * input. The stream will emit an element for each value output from the\n * schedule, continuing for as long as the schedule continues.\n *\n * @example\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * // Emits values every 1 second for a total of 5 emissions\n * const schedule = Schedule.spaced(\"1 second\").pipe(\n *   Schedule.compose(Schedule.recurs(5))\n * )\n *\n * const stream = Stream.fromSchedule(schedule)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromSchedule = internal.fromSchedule;\n/**\n * Creates a pipeline that groups on adjacent keys, calculated by the\n * specified function.\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const groupAdjacentBy = internal.groupAdjacentBy;\n/**\n * More powerful version of `Stream.groupByKey`.\n *\n * @example\n * import { Chunk, Effect, GroupBy, Stream } from \"effect\"\n *\n * const groupByKeyResult = Stream.fromIterable([\n *   \"Mary\",\n *   \"James\",\n *   \"Robert\",\n *   \"Patricia\",\n *   \"John\",\n *   \"Jennifer\",\n *   \"Rebecca\",\n *   \"Peter\"\n * ]).pipe(\n *   Stream.groupBy((name) => Effect.succeed([name.substring(0, 1), name]))\n * )\n *\n * const stream = GroupBy.evaluate(groupByKeyResult, (key, stream) =>\n *   Stream.fromEffect(\n *     Stream.runCollect(stream).pipe(\n *       Effect.andThen((chunk) => [key, Chunk.size(chunk)] as const)\n *     )\n *   ))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [ [ 'M', 1 ], [ 'J', 3 ], [ 'R', 2 ], [ 'P', 2 ] ]\n * // }\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const groupBy = _groupBy.groupBy;\n/**\n * Partition a stream using a function and process each stream individually.\n * This returns a data structure that can be used to further filter down which\n * groups shall be processed.\n *\n * After calling apply on the GroupBy object, the remaining groups will be\n * processed in parallel and the resulting streams merged in a\n * nondeterministic fashion.\n *\n * Up to `buffer` elements may be buffered in any group stream before the\n * producer is backpressured. Take care to consume from all streams in order\n * to prevent deadlocks.\n *\n * For example, to collect the first 2 words for every starting letter from a\n * stream of words:\n *\n * ```ts\n * import * as GroupBy from \"./GroupBy\"\n * import * as Stream from \"./Stream\"\n * import { pipe } from \"./Function\"\n *\n * pipe(\n *   Stream.fromIterable([\"hello\", \"world\", \"hi\", \"holla\"]),\n *   Stream.groupByKey((word) => word[0]),\n *   GroupBy.evaluate((key, stream) =>\n *     pipe(\n *       stream,\n *       Stream.take(2),\n *       Stream.map((words) => [key, words] as const)\n *     )\n *   )\n * )\n * ```\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const groupByKey = _groupBy.groupByKey;\n/**\n * Partitions the stream with specified `chunkSize`.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.range(0, 8).pipe(Stream.grouped(3))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then((chunks) => console.log(\"%o\", chunks))\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     { _id: 'Chunk', values: [ 0, 1, 2, [length]: 3 ] },\n * //     { _id: 'Chunk', values: [ 3, 4, 5, [length]: 3 ] },\n * //     { _id: 'Chunk', values: [ 6, 7, 8, [length]: 3 ] },\n * //     [length]: 3\n * //   ]\n * // }\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const grouped = internal.grouped;\n/**\n * Partitions the stream with the specified `chunkSize` or until the specified\n * `duration` has passed, whichever is satisfied first.\n *\n * @example\n * import { Chunk, Effect, Schedule, Stream } from \"effect\"\n *\n * const stream = Stream.range(0, 9).pipe(\n *   Stream.repeat(Schedule.spaced(\"1 second\")),\n *   Stream.groupedWithin(18, \"1.5 seconds\"),\n *   Stream.take(3)\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then((chunks) => console.log(Chunk.toArray(chunks)))\n * // [\n * //   {\n * //     _id: 'Chunk',\n * //     values: [\n * //       0, 1, 2, 3, 4, 5, 6,\n * //       7, 8, 9, 0, 1, 2, 3,\n * //       4, 5, 6, 7\n * //     ]\n * //   },\n * //   {\n * //     _id: 'Chunk',\n * //     values: [\n * //       8, 9, 0, 1, 2,\n * //       3, 4, 5, 6, 7,\n * //       8, 9\n * //     ]\n * //   },\n * //   {\n * //     _id: 'Chunk',\n * //     values: [\n * //       0, 1, 2, 3, 4, 5, 6,\n * //       7, 8, 9, 0, 1, 2, 3,\n * //       4, 5, 6, 7\n * //     ]\n * //   }\n * // ]\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const groupedWithin = internal.groupedWithin;\n/**\n * Specialized version of haltWhen which halts the evaluation of this stream\n * after the given duration.\n *\n * An element in the process of being pulled will not be interrupted when the\n * given duration completes. See `interruptAfter` for this behavior.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const haltAfter = internal.haltAfter;\n/**\n * Halts the evaluation of this stream when the provided effect completes. The\n * given effect will be forked as part of the returned stream, and its success\n * will be discarded.\n *\n * An element in the process of being pulled will not be interrupted when the\n * effect completes. See `interruptWhen` for this behavior.\n *\n * If the effect completes with a failure, the stream will emit that failure.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const haltWhen = internal.haltWhen;\n/**\n * Halts the evaluation of this stream when the provided promise resolves.\n *\n * If the promise completes with a failure, the stream will emit that failure.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const haltWhenDeferred = internal.haltWhenDeferred;\n/**\n * The identity pipeline, which does not modify streams in any way.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const identity = internal.identityStream;\n/**\n * Interleaves this stream and the specified stream deterministically by\n * alternating pulling values from this stream and the specified stream. When\n * one stream is exhausted all remaining values in the other stream will be\n * pulled.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3)\n * const s2 = Stream.make(4, 5, 6)\n *\n * const stream = Stream.interleave(s1, s2)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 4, 2, 5, 3, 6 ] }\n * @since 2.0.0\n * @category utils\n */\nexport const interleave = internal.interleave;\n/**\n * Combines this stream and the specified stream deterministically using the\n * stream of boolean values `pull` to control which stream to pull from next.\n * A value of `true` indicates to pull from this stream and a value of `false`\n * indicates to pull from the specified stream. Only consumes as many elements\n * as requested by the `pull` stream. If either this stream or the specified\n * stream are exhausted further requests for values from that stream will be\n * ignored.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 3, 5, 7, 9)\n * const s2 = Stream.make(2, 4, 6, 8, 10)\n *\n * const booleanStream = Stream.make(true, false, false).pipe(Stream.forever)\n *\n * const stream = Stream.interleaveWith(s1, s2, booleanStream)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     1, 2,  4, 3, 6,\n * //     8, 5, 10, 7, 9\n * //   ]\n * // }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interleaveWith = internal.interleaveWith;\n/**\n * Intersperse stream with provided `element`.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3, 4, 5).pipe(Stream.intersperse(0))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     1, 0, 2, 0, 3,\n * //     0, 4, 0, 5\n * //   ]\n * // }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const intersperse = internal.intersperse;\n/**\n * Intersperse the specified element, also adding a prefix and a suffix.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3, 4, 5).pipe(\n *   Stream.intersperseAffixes({\n *     start: \"[\",\n *     middle: \"-\",\n *     end: \"]\"\n *   })\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     '[', 1,   '-', 2,   '-',\n * //     3,   '-', 4,   '-', 5,\n * //     ']'\n * //   ]\n * // }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const intersperseAffixes = internal.intersperseAffixes;\n/**\n * Specialized version of `Stream.interruptWhen` which interrupts the\n * evaluation of this stream after the given `Duration`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptAfter = internal.interruptAfter;\n/**\n * Interrupts the evaluation of this stream when the provided effect\n * completes. The given effect will be forked as part of this stream, and its\n * success will be discarded. This combinator will also interrupt any\n * in-progress element being pulled from upstream.\n *\n * If the effect completes with a failure before the stream completes, the\n * returned stream will emit that failure.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptWhen = internal.interruptWhen;\n/**\n * Interrupts the evaluation of this stream when the provided promise\n * resolves. This combinator will also interrupt any in-progress element being\n * pulled from upstream.\n *\n * If the promise completes with a failure, the stream will emit that failure.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptWhenDeferred = internal.interruptWhenDeferred;\n/**\n * The infinite stream of iterative function application: a, f(a), f(f(a)),\n * f(f(f(a))), ...\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * // An infinite Stream of numbers starting from 1 and incrementing\n * const stream = Stream.iterate(1, (n) => n + 1)\n *\n * // Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(10)))).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const iterate = internal.iterate;\n/**\n * Creates a stream from an sequence of values.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * Transforms the elements of this stream using the supplied function.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3).pipe(Stream.map((n) => n + 1))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 2, 3, 4 ] }\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * Statefully maps over the elements of this stream to produce new elements.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const runningTotal = (stream: Stream.Stream<number>): Stream.Stream<number> =>\n *   stream.pipe(Stream.mapAccum(0, (s, a) => [s + a, s + a]))\n *\n * // input:  0, 1, 2, 3, 4, 5, 6\n * // Effect.runPromise(Stream.runCollect(runningTotal(Stream.range(0, 6)))).then(\n * //   console.log\n * // )\n * // { _id: \"Chunk\", values: [ 0, 1, 3, 6, 10, 15, 21 ] }\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapAccum = internal.mapAccum;\n/**\n * Statefully and effectfully maps over the elements of this stream to produce\n * new elements.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapAccumEffect = internal.mapAccumEffect;\n/**\n * Returns a stream whose failure and success channels have been mapped by the\n * specified `onFailure` and `onSuccess` functions.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapBoth = internal.mapBoth;\n/**\n * Transforms the chunks emitted by this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapChunks = internal.mapChunks;\n/**\n * Effectfully transforms the chunks emitted by this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapChunksEffect = internal.mapChunksEffect;\n/**\n * Maps each element to an iterable, and flattens the iterables into the\n * output of this stream.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const numbers = Stream.make(\"1-2-3\", \"4-5\", \"6\").pipe(\n *   Stream.mapConcat((s) => s.split(\"-\")),\n *   Stream.map((s) => parseInt(s))\n * )\n *\n * // Effect.runPromise(Stream.runCollect(numbers)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5, 6 ] }\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapConcat = internal.mapConcat;\n/**\n * Maps each element to a chunk, and flattens the chunks into the output of\n * this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapConcatChunk = internal.mapConcatChunk;\n/**\n * Effectfully maps each element to a chunk, and flattens the chunks into the\n * output of this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapConcatChunkEffect = internal.mapConcatChunkEffect;\n/**\n * Effectfully maps each element to an iterable, and flattens the iterables\n * into the output of this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapConcatEffect = internal.mapConcatEffect;\n/**\n * Maps over elements of the stream with the specified effectful function.\n *\n * @example\n * import { Effect, Random, Stream } from \"effect\"\n *\n * const stream = Stream.make(10, 20, 30).pipe(\n *   Stream.mapEffect((n) => Random.nextIntBetween(0, n))\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Example Output: { _id: 'Chunk', values: [ 7, 19, 8 ] }\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapEffect = _groupBy.mapEffectOptions;\n/**\n * Transforms the errors emitted by this stream using `f`.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapError = internal.mapError;\n/**\n * Transforms the full causes of failures emitted by this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapErrorCause = internal.mapErrorCause;\n/**\n * Merges this stream and the specified stream together.\n *\n * New produced stream will terminate when both specified stream terminate if\n * no termination strategy is specified.\n *\n * @example\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3).pipe(\n *   Stream.schedule(Schedule.spaced(\"100 millis\"))\n * )\n * const s2 = Stream.make(4, 5, 6).pipe(\n *   Stream.schedule(Schedule.spaced(\"200 millis\"))\n * )\n *\n * const stream = Stream.merge(s1, s2)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 4, 2, 3, 5, 6 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const merge = internal.merge;\n/**\n * Merges a variable list of streams in a non-deterministic fashion. Up to `n`\n * streams may be consumed in parallel and up to `outputBuffer` chunks may be\n * buffered by this operator.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeAll = internal.mergeAll;\n/**\n * Merges this stream and the specified stream together to a common element\n * type with the specified mapping functions.\n *\n * New produced stream will terminate when both specified stream terminate if\n * no termination strategy is specified.\n *\n * @example\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * const s1 = Stream.make(\"1\", \"2\", \"3\").pipe(\n *   Stream.schedule(Schedule.spaced(\"100 millis\"))\n * )\n * const s2 = Stream.make(4.1, 5.3, 6.2).pipe(\n *   Stream.schedule(Schedule.spaced(\"200 millis\"))\n * )\n *\n * const stream = Stream.mergeWith(s1, s2, {\n *   onSelf: (s) => parseInt(s),\n *   onOther: (n) => Math.floor(n)\n * })\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 4, 2, 3, 5, 6 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeWith = internal.mergeWith;\n/**\n * Merges this stream and the specified stream together to produce a stream of\n * eithers.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeEither = internal.mergeEither;\n/**\n * Merges this stream and the specified stream together, discarding the values\n * from the right stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeLeft = internal.mergeLeft;\n/**\n * Merges this stream and the specified stream together, discarding the values\n * from the left stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeRight = internal.mergeRight;\n/**\n * Returns a combined string resulting from concatenating each of the values\n * from the stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mkString = internal.mkString;\n/**\n * The stream that never produces any value or fails with any error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const never = internal.never;\n/**\n * Runs the specified effect if this stream fails, providing the error to the\n * effect if it exists.\n *\n * Note: Unlike `Effect.onError` there is no guarantee that the provided\n * effect will not be interrupted.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const onError = internal.onError;\n/**\n * Runs the specified effect if this stream ends.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const onDone = internal.onDone;\n/**\n * Translates any failure into a stream termination, making the stream\n * infallible and all failures unchecked.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orDie = internal.orDie;\n/**\n * Keeps none of the errors, and terminates the stream with them, using the\n * specified function to convert the `E` into a defect.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orDieWith = internal.orDieWith;\n/**\n * Switches to the provided stream in case this one fails with a typed error.\n *\n * See also `Stream.catchAll`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElse = internal.orElse;\n/**\n * Switches to the provided stream in case this one fails with a typed error.\n *\n * See also `Stream.catchAll`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseEither = internal.orElseEither;\n/**\n * Fails with given error in case this one fails with a typed error.\n *\n * See also `Stream.catchAll`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseFail = internal.orElseFail;\n/**\n * Produces the specified element if this stream is empty.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseIfEmpty = internal.orElseIfEmpty;\n/**\n * Produces the specified chunk if this stream is empty.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseIfEmptyChunk = internal.orElseIfEmptyChunk;\n/**\n * Switches to the provided stream in case this one is empty.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseIfEmptyStream = internal.orElseIfEmptyStream;\n/**\n * Succeeds with the specified value if this one fails with a typed error.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseSucceed = internal.orElseSucceed;\n/**\n * Like `Stream.unfold`, but allows the emission of values to end one step further\n * than the unfolding of the state. This is useful for embedding paginated\n * APIs, hence the name.\n *\n * @example\n * import { Effect, Option, Stream } from \"effect\"\n *\n * const stream = Stream.paginate(0, (n) => [\n *   n,\n *   n < 3 ? Option.some(n + 1) : Option.none()\n * ])\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const paginate = internal.paginate;\n/**\n * Like `Stream.unfoldChunk`, but allows the emission of values to end one step\n * further than the unfolding of the state. This is useful for embedding\n * paginated APIs, hence the name.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const paginateChunk = internal.paginateChunk;\n/**\n * Like `Stream.unfoldChunkEffect`, but allows the emission of values to end one step\n * further than the unfolding of the state. This is useful for embedding\n * paginated APIs, hence the name.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const paginateChunkEffect = internal.paginateChunkEffect;\n/**\n * Like `Stream.unfoldEffect` but allows the emission of values to end one step\n * further than the unfolding of the state. This is useful for embedding\n * paginated APIs, hence the name.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const paginateEffect = internal.paginateEffect;\n/**\n * Partition a stream using a predicate. The first stream will contain all\n * element evaluated to true and the second one will contain all element\n * evaluated to false. The faster stream may advance by up to buffer elements\n * further than the slower one.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const partition = Stream.range(1, 10).pipe(\n *   Stream.partition((n) => n % 2 === 0, { bufferSize: 5 })\n * )\n *\n * const program = Effect.scoped(\n *   Effect.gen(function*() {\n *     const [evens, odds] = yield* partition\n *     console.log(yield* Stream.runCollect(evens))\n *     console.log(yield* Stream.runCollect(odds))\n *   })\n * )\n *\n * // Effect.runPromise(program)\n * // { _id: 'Chunk', values: [ 2, 4, 6, 8, 10 ] }\n * // { _id: 'Chunk', values: [ 1, 3, 5, 7, 9 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const partition = internal.partition;\n/**\n * Split a stream by an effectful predicate. The faster stream may advance by\n * up to buffer elements further than the slower one.\n *\n * @example\n * import { Effect, Either, Stream } from \"effect\"\n *\n * const partition = Stream.range(1, 9).pipe(\n *   Stream.partitionEither(\n *     (n) => Effect.succeed(n % 2 === 0 ? Either.left(n) : Either.right(n)),\n *     { bufferSize: 5 }\n *   )\n * )\n *\n * const program = Effect.scoped(\n *   Effect.gen(function*() {\n *     const [evens, odds] = yield* partition\n *     console.log(yield* Stream.runCollect(evens))\n *     console.log(yield* Stream.runCollect(odds))\n *   })\n * )\n *\n * // Effect.runPromise(program)\n * // { _id: 'Chunk', values: [ 2, 4, 6, 8 ] }\n * // { _id: 'Chunk', values: [ 1, 3, 5, 7, 9 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const partitionEither = internal.partitionEither;\n/**\n * Peels off enough material from the stream to construct a `Z` using the\n * provided `Sink` and then returns both the `Z` and the rest of the\n * `Stream` in a scope. Like all scoped values, the provided stream is\n * valid only within the scope.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const peel = internal.peel;\n/**\n * Pipes all of the values from this stream through the provided sink.\n *\n * See also `Stream.transduce`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const pipeThrough = internal.pipeThrough;\n/**\n * Pipes all the values from this stream through the provided channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const pipeThroughChannel = internal.pipeThroughChannel;\n/**\n * Pipes all values from this stream through the provided channel, passing\n * through any error emitted by this stream unchanged.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const pipeThroughChannelOrFail = internal.pipeThroughChannelOrFail;\n/**\n * Emits the provided chunk before emitting any other value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const prepend = internal.prepend;\n/**\n * Provides the stream with its required context, which eliminates its\n * dependency on `R`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideContext = internal.provideContext;\n/**\n * Provides a `Layer` to the stream, which translates it to another level.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideLayer = internal.provideLayer;\n/**\n * Provides the stream with the single service it requires. If the stream\n * requires more than one service use `Stream.provideContext` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideService = internal.provideService;\n/**\n * Provides the stream with the single service it requires. If the stream\n * requires more than one service use `Stream.provideContext` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideServiceEffect = internal.provideServiceEffect;\n/**\n * Provides the stream with the single service it requires. If the stream\n * requires more than one service use `Stream.provideContext` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideServiceStream = internal.provideServiceStream;\n/**\n * Transforms the context being provided to the stream with the specified\n * function.\n *\n * @since 2.0.0\n * @category context\n */\nexport const mapInputContext = internal.mapInputContext;\n/**\n * Splits the context into two parts, providing one part using the\n * specified layer and leaving the remainder `R0`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideSomeLayer = internal.provideSomeLayer;\n/**\n * Returns a stream that mirrors the first upstream to emit an item.\n * As soon as one of the upstream emits a first value, all the others are interrupted.\n * The resulting stream will forward all items from the \"winning\" source stream.\n * Any upstream failures will cause the returned stream to fail.\n *\n * @example\n * import { Stream, Schedule, Console, Effect } from \"effect\"\n *\n * const stream = Stream.raceAll(\n *   Stream.fromSchedule(Schedule.spaced('1 millis')),\n *   Stream.fromSchedule(Schedule.spaced('2 millis')),\n *   Stream.fromSchedule(Schedule.spaced('4 millis')),\n * ).pipe(Stream.take(6), Stream.tap(Console.log))\n *\n * Effect.runPromise(Stream.runDrain(stream))\n * // Output each millisecond from the first stream, the rest streams are interrupted\n * // 0\n * // 1\n * // 2\n * // 3\n * // 4\n * // 5\n * @since 3.5.0\n * @category racing\n */\nexport const raceAll = internal.raceAll;\n/**\n * Constructs a stream from a range of integers, including both endpoints.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * // A Stream with a range of numbers from 1 to 5\n * const stream = Stream.range(1, 5)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const range = internal.range;\n/**\n * Re-chunks the elements of the stream into chunks of `n` elements each. The\n * last chunk might contain less than `n` elements.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const rechunk = internal.rechunk;\n/**\n * Keeps some of the errors, and terminates the fiber with the rest\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const refineOrDie = internal.refineOrDie;\n/**\n * Keeps some of the errors, and terminates the fiber with the rest, using the\n * specified function to convert the `E` into a defect.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const refineOrDieWith = internal.refineOrDieWith;\n/**\n * Repeats the entire stream using the specified schedule. The stream will\n * execute normally, and then repeat again according to the provided schedule.\n *\n * @example\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * const stream = Stream.repeat(Stream.succeed(1), Schedule.forever)\n *\n * // Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 1, 1, 1, 1 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeat = internal.repeat;\n/**\n * Creates a stream from an effect producing a value of type `A` which repeats\n * forever.\n *\n * @example\n * import { Effect, Random, Stream } from \"effect\"\n *\n * const stream = Stream.repeatEffect(Random.nextInt)\n *\n * // Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // Example Output: { _id: 'Chunk', values: [ 3891571149, 4239494205, 2352981603, 2339111046, 1488052210 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffect = internal.repeatEffect;\n/**\n * Creates a stream from an effect producing chunks of `A` values which\n * repeats forever.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffectChunk = internal.repeatEffectChunk;\n/**\n * Creates a stream from an effect producing chunks of `A` values until it\n * fails with `None`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffectChunkOption = internal.repeatEffectChunkOption;\n/**\n * Creates a stream from an effect producing values of type `A` until it fails\n * with `None`.\n *\n * @example\n * // In this example, we're draining an Iterator to create a stream from it\n * import { Stream, Effect, Option } from \"effect\"\n *\n * const drainIterator = <A>(it: Iterator<A>): Stream.Stream<A> =>\n *   Stream.repeatEffectOption(\n *     Effect.sync(() => it.next()).pipe(\n *       Effect.andThen((res) => {\n *         if (res.done) {\n *           return Effect.fail(Option.none())\n *         }\n *         return Effect.succeed(res.value)\n *       })\n *     )\n *   )\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffectOption = internal.repeatEffectOption;\n/**\n * Creates a stream from an effect producing a value of type `A`, which is\n * repeated using the specified schedule.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffectWithSchedule = internal.repeatEffectWithSchedule;\n/**\n * Repeats the entire stream using the specified schedule. The stream will\n * execute normally, and then repeat again according to the provided schedule.\n * The schedule output will be emitted at the end of each repetition.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeatEither = internal.repeatEither;\n/**\n * Repeats each element of the stream using the provided schedule. Repetitions\n * are done in addition to the first execution, which means using\n * `Schedule.recurs(1)` actually results in the original effect, plus an\n * additional recurrence, for a total of two repetitions of each value in the\n * stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeatElements = internal.repeatElements;\n/**\n * Repeats each element of the stream using the provided schedule. When the\n * schedule is finished, then the output of the schedule will be emitted into\n * the stream. Repetitions are done in addition to the first execution, which\n * means using `Schedule.recurs(1)` actually results in the original effect,\n * plus an additional recurrence, for a total of two repetitions of each value\n * in the stream.\n *\n * This function accepts two conversion functions, which allow the output of\n * this stream and the output of the provided schedule to be unified into a\n * single type. For example, `Either` or similar data type.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeatElementsWith = internal.repeatElementsWith;\n/**\n * Repeats the provided value infinitely.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.repeatValue(0)\n *\n * // Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 0, 0, 0, 0 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatValue = internal.repeatValue;\n/**\n * Repeats the entire stream using the specified schedule. The stream will\n * execute normally, and then repeat again according to the provided schedule.\n * The schedule output will be emitted at the end of each repetition and can\n * be unified with the stream elements using the provided functions.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeatWith = internal.repeatWith;\n/**\n * When the stream fails, retry it according to the given schedule\n *\n * This retries the entire stream, so will re-execute all of the stream's\n * acquire operations.\n *\n * The schedule is reset as soon as the first element passes through the\n * stream again.\n *\n * @param schedule A `Schedule` receiving as input the errors of the stream.\n * @since 2.0.0\n * @category utils\n */\nexport const retry = internal.retry;\n/**\n * Runs the sink on the stream to produce either the sink's result or an error.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const run = internal.run;\n/**\n * Runs the stream and collects all of its elements to a chunk.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runCollect = internal.runCollect;\n/**\n * Runs the stream and emits the number of elements processed\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runCount = internal.runCount;\n/**\n * Runs the stream only for its effects. The emitted elements are discarded.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runDrain = internal.runDrain;\n/**\n * Executes a pure fold over the stream of values - reduces all elements in\n * the stream to a value of type `S`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFold = internal.runFold;\n/**\n * Executes an effectful fold over the stream of values.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldEffect = internal.runFoldEffect;\n/**\n * Executes a pure fold over the stream of values. Returns a scoped value that\n * represents the scope of the stream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldScoped = internal.runFoldScoped;\n/**\n * Executes an effectful fold over the stream of values. Returns a scoped\n * value that represents the scope of the stream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldScopedEffect = internal.runFoldScopedEffect;\n/**\n * Reduces the elements in the stream to a value of type `S`. Stops the fold\n * early when the condition is not fulfilled. Example:\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldWhile = internal.runFoldWhile;\n/**\n * Executes an effectful fold over the stream of values. Stops the fold early\n * when the condition is not fulfilled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldWhileEffect = internal.runFoldWhileEffect;\n/**\n * Executes a pure fold over the stream of values. Returns a scoped value that\n * represents the scope of the stream. Stops the fold early when the condition\n * is not fulfilled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldWhileScoped = internal.runFoldWhileScoped;\n/**\n * Executes an effectful fold over the stream of values. Returns a scoped\n * value that represents the scope of the stream. Stops the fold early when\n * the condition is not fulfilled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldWhileScopedEffect = internal.runFoldWhileScopedEffect;\n/**\n * Consumes all elements of the stream, passing them to the specified\n * callback.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEach = internal.runForEach;\n/**\n * Consumes all elements of the stream, passing them to the specified\n * callback.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachChunk = internal.runForEachChunk;\n/**\n * Like `Stream.runForEachChunk`, but returns a scoped effect so the\n * finalization order can be controlled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachChunkScoped = internal.runForEachChunkScoped;\n/**\n * Like `Stream.forEach`, but returns a scoped effect so the finalization\n * order can be controlled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachScoped = internal.runForEachScoped;\n/**\n * Consumes elements of the stream, passing them to the specified callback,\n * and terminating consumption when the callback returns `false`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachWhile = internal.runForEachWhile;\n/**\n * Like `Stream.runForEachWhile`, but returns a scoped effect so the\n * finalization order can be controlled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachWhileScoped = internal.runForEachWhileScoped;\n/**\n * Runs the stream to completion and yields the first value emitted by it,\n * discarding the rest of the elements.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runHead = internal.runHead;\n/**\n * Publishes elements of this stream to a `PubSub`. Stream failure and ending will\n * also be signalled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoPubSub = internal.runIntoPubSub;\n/**\n * Like `Stream.runIntoPubSub`, but provides the result as a scoped effect to\n * allow for scope composition.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoPubSubScoped = internal.runIntoPubSubScoped;\n/**\n * Enqueues elements of this stream into a queue. Stream failure and ending\n * will also be signalled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoQueue = internal.runIntoQueue;\n/**\n * Like `Stream.runIntoQueue`, but provides the result as a scoped [[ZIO]]\n * to allow for scope composition.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoQueueElementsScoped = internal.runIntoQueueElementsScoped;\n/**\n * Like `Stream.runIntoQueue`, but provides the result as a scoped effect\n * to allow for scope composition.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoQueueScoped = internal.runIntoQueueScoped;\n/**\n * Runs the stream to completion and yields the last value emitted by it,\n * discarding the rest of the elements.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runLast = internal.runLast;\n/**\n * @since 2.0.0\n * @category destructors\n */\nexport const runScoped = internal.runScoped;\n/**\n * Runs the stream to a sink which sums elements, provided they are Numeric.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runSum = internal.runSum;\n/**\n * Statefully maps over the elements of this stream to produce all\n * intermediate results of type `S` given an initial S.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.range(1, 6).pipe(Stream.scan(0, (a, b) => a + b))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0,  1,  3, 6, 10, 15, 21 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scan = internal.scan;\n/**\n * Statefully and effectfully maps over the elements of this stream to produce\n * all intermediate results of type `S` given an initial S.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scanEffect = internal.scanEffect;\n/**\n * Statefully maps over the elements of this stream to produce all\n * intermediate results.\n *\n * See also `Stream.scan`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scanReduce = internal.scanReduce;\n/**\n * Statefully and effectfully maps over the elements of this stream to produce\n * all intermediate results.\n *\n * See also `Stream.scanEffect`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scanReduceEffect = internal.scanReduceEffect;\n/**\n * Schedules the output of the stream using the provided `schedule`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const schedule = internal.schedule;\n/**\n * Schedules the output of the stream using the provided `schedule` and emits\n * its output at the end (if `schedule` is finite). Uses the provided function\n * to align the stream and schedule outputs on the same type.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scheduleWith = internal.scheduleWith;\n/**\n * Creates a single-valued stream from a scoped resource.\n *\n * @example\n * import { Console, Effect, Stream } from \"effect\"\n *\n * // Creating a single-valued stream from a scoped resource\n * const stream = Stream.scoped(\n *   Effect.acquireUseRelease(\n *     Console.log(\"acquire\"),\n *     () => Console.log(\"use\"),\n *     () => Console.log(\"release\")\n *   )\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // acquire\n * // use\n * // release\n * // { _id: 'Chunk', values: [ undefined ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const scoped = internal.scoped;\n/**\n * Emits a sliding window of `n` elements.\n *\n * ```ts\n * import * as Stream from \"./Stream\"\n * import { pipe } from \"./Function\"\n *\n * pipe(\n *   Stream.make(1, 2, 3, 4),\n *   Stream.sliding(2),\n *   Stream.runCollect\n * )\n * // => Chunk(Chunk(1, 2), Chunk(2, 3), Chunk(3, 4))\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const sliding = internal.sliding;\n/**\n * Like `sliding`, but with a configurable `stepSize` parameter.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const slidingSize = internal.slidingSize;\n/**\n * Converts an option on values into an option on errors.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const some = internal.some;\n/**\n * Extracts the optional value, or returns the given 'default'.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const someOrElse = internal.someOrElse;\n/**\n * Extracts the optional value, or fails with the given error 'e'.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const someOrFail = internal.someOrFail;\n/**\n * Splits elements based on a predicate.\n *\n * ```ts\n * import * as Stream from \"./Stream\"\n * import { pipe } from \"./Function\"\n *\n * pipe(\n *   Stream.range(1, 10),\n *   Stream.split((n) => n % 4 === 0),\n *   Stream.runCollect\n * )\n * // => Chunk(Chunk(1, 2, 3), Chunk(5, 6, 7), Chunk(9))\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const split = internal.split;\n/**\n * Splits elements on a delimiter and transforms the splits into desired output.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const splitOnChunk = internal.splitOnChunk;\n/**\n * Splits strings on newlines. Handles both Windows newlines (`\\r\\n`) and UNIX\n * newlines (`\\n`).\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const splitLines = internal.splitLines;\n/**\n * Creates a single-valued pure stream.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * // A Stream with a single number\n * const stream = Stream.succeed(3)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 3 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = internal.succeed;\n/**\n * Creates a single-valued pure stream.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sync = internal.sync;\n/**\n * Returns a lazily constructed stream.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const suspend = internal.suspend;\n/**\n * Takes the specified number of elements from this stream.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.take(Stream.iterate(0, (n) => n + 1), 5)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const take = internal.take;\n/**\n * Takes the last specified number of elements from this stream.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.takeRight(Stream.make(1, 2, 3, 4, 5, 6), 3)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 4, 5, 6 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeRight = internal.takeRight;\n/**\n * Takes all elements of the stream until the specified predicate evaluates to\n * `true`.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.takeUntil(Stream.iterate(0, (n) => n + 1), (n) => n === 4)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeUntil = internal.takeUntil;\n/**\n * Takes all elements of the stream until the specified effectual predicate\n * evaluates to `true`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeUntilEffect = internal.takeUntilEffect;\n/**\n * Takes all elements of the stream for as long as the specified predicate\n * evaluates to `true`.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.takeWhile(Stream.iterate(0, (n) => n + 1), (n) => n < 5)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeWhile = internal.takeWhile;\n/**\n * Adds an effect to consumption of every element of the stream.\n *\n * @example\n * import { Console, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3).pipe(\n *   Stream.tap((n) => Console.log(`before mapping: ${n}`)),\n *   Stream.map((n) => n * 2),\n *   Stream.tap((n) => Console.log(`after mapping: ${n}`))\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // before mapping: 1\n * // after mapping: 2\n * // before mapping: 2\n * // after mapping: 4\n * // before mapping: 3\n * // after mapping: 6\n * // { _id: 'Chunk', values: [ 2, 4, 6 ] }\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tap = internal.tap;\n/**\n * Returns a stream that effectfully \"peeks\" at the failure or success of\n * the stream.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapBoth = internal.tapBoth;\n/**\n * Returns a stream that effectfully \"peeks\" at the failure of the stream.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapError = internal.tapError;\n/**\n * Returns a stream that effectfully \"peeks\" at the cause of failure of the\n * stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const tapErrorCause = internal.tapErrorCause;\n/**\n * Sends all elements emitted by this stream to the specified sink in addition\n * to emitting them.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapSink = internal.tapSink;\n/**\n * Delays the chunks of this stream according to the given bandwidth\n * parameters using the token bucket algorithm. Allows for burst in the\n * processing of elements by allowing the token bucket to accumulate tokens up\n * to a `units + burst` threshold. The weight of each chunk is determined by\n * the `cost` function.\n *\n * If using the \"enforce\" strategy, chunks that do not meet the bandwidth\n * constraints are dropped. If using the \"shape\" strategy, chunks are delayed\n * until they can be emitted without exceeding the bandwidth constraints.\n *\n * Defaults to the \"shape\" strategy.\n *\n * @example\n * import { Chunk, Effect, Schedule, Stream } from \"effect\"\n *\n * let last = Date.now()\n * const log = (message: string) =>\n *   Effect.sync(() => {\n *     const end = Date.now()\n *     console.log(`${message} after ${end - last}ms`)\n *     last = end\n *   })\n *\n * const stream = Stream.fromSchedule(Schedule.spaced(\"50 millis\")).pipe(\n *   Stream.take(6),\n *   Stream.tap((n) => log(`Received ${n}`)),\n *   Stream.throttle({\n *     cost: Chunk.size,\n *     duration: \"100 millis\",\n *     units: 1\n *   }),\n *   Stream.tap((n) => log(`> Emitted ${n}`))\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Received 0 after 56ms\n * // > Emitted 0 after 0ms\n * // Received 1 after 52ms\n * // > Emitted 1 after 48ms\n * // Received 2 after 52ms\n * // > Emitted 2 after 49ms\n * // Received 3 after 52ms\n * // > Emitted 3 after 48ms\n * // Received 4 after 52ms\n * // > Emitted 4 after 47ms\n * // Received 5 after 52ms\n * // > Emitted 5 after 49ms\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4, 5 ] }\n *\n * @since 2.0.0\n * @category utils\n */\nexport const throttle = internal.throttle;\n/**\n * Delays the chunks of this stream according to the given bandwidth\n * parameters using the token bucket algorithm. Allows for burst in the\n * processing of elements by allowing the token bucket to accumulate tokens up\n * to a `units + burst` threshold. The weight of each chunk is determined by\n * the effectful `costFn` function.\n *\n * If using the \"enforce\" strategy, chunks that do not meet the bandwidth\n * constraints are dropped. If using the \"shape\" strategy, chunks are delayed\n * until they can be emitted without exceeding the bandwidth constraints.\n *\n * Defaults to the \"shape\" strategy.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const throttleEffect = internal.throttleEffect;\n/**\n * A stream that emits void values spaced by the specified duration.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * let last = Date.now()\n * const log = (message: string) =>\n *   Effect.sync(() => {\n *     const end = Date.now()\n *     console.log(`${message} after ${end - last}ms`)\n *     last = end\n *   })\n *\n * const stream = Stream.tick(\"1 seconds\").pipe(Stream.tap(() => log(\"tick\")))\n *\n * // Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // tick after 4ms\n * // tick after 1003ms\n * // tick after 1001ms\n * // tick after 1002ms\n * // tick after 1002ms\n * // { _id: 'Chunk', values: [ undefined, undefined, undefined, undefined, undefined ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const tick = internal.tick;\n/**\n * Ends the stream if it does not produce a value after the specified duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const timeout = internal.timeout;\n/**\n * Fails the stream with given error if it does not produce a value after d\n * duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const timeoutFail = internal.timeoutFail;\n/**\n * Fails the stream with given cause if it does not produce a value after d\n * duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const timeoutFailCause = internal.timeoutFailCause;\n/**\n * Switches the stream if it does not produce a value after the specified\n * duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const timeoutTo = internal.timeoutTo;\n/**\n * Converts the stream to a scoped `PubSub` of chunks. After the scope is closed,\n * the `PubSub` will never again produce values and should be discarded.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toPubSub = internal.toPubSub;\n/**\n * Returns in a scope a ZIO effect that can be used to repeatedly pull chunks\n * from the stream. The pull effect fails with None when the stream is\n * finished, or with Some error if it fails, otherwise it returns a chunk of\n * the stream's output.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * // Simulate a chunked stream\n * const stream = Stream.fromIterable([1, 2, 3, 4, 5]).pipe(Stream.rechunk(2))\n *\n * const program = Effect.gen(function*() {\n *   // Create an effect to get data chunks from the stream\n *   const getChunk = yield* Stream.toPull(stream)\n *\n *   // Continuously fetch and process chunks\n *   while (true) {\n *     const chunk = yield* getChunk\n *     console.log(chunk)\n *   }\n * })\n *\n * // Effect.runPromise(Effect.scoped(program)).then(console.log, console.error)\n * // { _id: 'Chunk', values: [ 1, 2 ] }\n * // { _id: 'Chunk', values: [ 3, 4 ] }\n * // { _id: 'Chunk', values: [ 5 ] }\n * // (FiberFailure) Error: {\n * //   \"_id\": \"Option\",\n * //   \"_tag\": \"None\"\n * // }\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toPull = internal.toPull;\n/**\n * Converts the stream to a scoped queue of chunks. After the scope is closed,\n * the queue will never again produce values and should be discarded.\n *\n * Defaults to the \"suspend\" back pressure strategy with a capacity of 2.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toQueue = internal.toQueue;\n/**\n * Converts the stream to a scoped queue of elements. After the scope is\n * closed, the queue will never again produce values and should be discarded.\n *\n * Defaults to a capacity of 2.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toQueueOfElements = internal.toQueueOfElements;\n/**\n * Converts the stream to a `ReadableStream`.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toReadableStream = internal.toReadableStream;\n/**\n * Converts the stream to a `Effect<ReadableStream>`.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toReadableStreamEffect = internal.toReadableStreamEffect;\n/**\n * Converts the stream to a `ReadableStream` using the provided runtime.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toReadableStreamRuntime = internal.toReadableStreamRuntime;\n/**\n * Applies the transducer to the stream and emits its outputs.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const transduce = internal.transduce;\n/**\n * Creates a stream by peeling off the \"layers\" of a value of type `S`.\n *\n * @example\n * import { Effect, Option, Stream } from \"effect\"\n *\n * const stream = Stream.unfold(1, (n) => Option.some([n, n + 1]))\n *\n * // Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfold = internal.unfold;\n/**\n * Creates a stream by peeling off the \"layers\" of a value of type `S`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfoldChunk = internal.unfoldChunk;\n/**\n * Creates a stream by effectfully peeling off the \"layers\" of a value of type\n * `S`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfoldChunkEffect = internal.unfoldChunkEffect;\n/**\n * Creates a stream by effectfully peeling off the \"layers\" of a value of type\n * `S`.\n *\n * @example\n * import { Effect, Option, Random, Stream } from \"effect\"\n *\n * const stream = Stream.unfoldEffect(1, (n) =>\n *   Random.nextBoolean.pipe(\n *     Effect.map((b) => (b ? Option.some([n, -n]) : Option.some([n, n])))\n *   ))\n *\n * // Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // { _id: 'Chunk', values: [ 1, -1, -1, -1, -1 ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfoldEffect = internal.unfoldEffect;\nconst void_ = internal.void;\nexport {\n/**\n * A stream that contains a single `void` value.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.void\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ undefined ] }\n *\n * @since 2.0.0\n * @category constructors\n */\nvoid_ as void };\n/**\n * Creates a stream produced from an `Effect`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrap = internal.unwrap;\n/**\n * Creates a stream produced from a scoped `Effect`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrapScoped = internal.unwrapScoped;\n/**\n * Updates the specified service within the context of the `Stream`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const updateService = internal.updateService;\n/**\n * Returns the specified stream if the given condition is satisfied, otherwise\n * returns an empty stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const when = internal.when;\n/**\n * Returns the resulting stream when the given `PartialFunction` is defined\n * for the given value, otherwise returns an empty stream.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const whenCase = internal.whenCase;\n/**\n * Returns the stream when the given partial function is defined for the given\n * effectful value, otherwise returns an empty stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const whenCaseEffect = internal.whenCaseEffect;\n/**\n * Returns the stream if the given effectful condition is satisfied, otherwise\n * returns an empty stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const whenEffect = internal.whenEffect;\n/**\n * Wraps the stream with a new span for tracing.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const withSpan = internal.withSpan;\n/**\n * Zips this stream with another point-wise and emits tuples of elements from\n * both streams.\n *\n * The new stream will end when one of the sides ends.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * // We create two streams and zip them together.\n * const stream = Stream.zip(\n *   Stream.make(1, 2, 3, 4, 5, 6),\n *   Stream.make(\"a\", \"b\", \"c\")\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ [ 1, 'a' ], [ 2, 'b' ], [ 3, 'c' ] ] }\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = internal.zip;\n/**\n * Zips this stream with another point-wise and emits tuples of elements from\n * both streams.\n *\n * The new stream will end when one of the sides ends.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipFlatten = internal.zipFlatten;\n/**\n * Zips this stream with another point-wise, creating a new stream of pairs of\n * elements from both sides.\n *\n * The defaults `defaultLeft` and `defaultRight` will be used if the streams\n * have different lengths and one of the streams has ended before the other.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipAll(Stream.make(1, 2, 3, 4, 5, 6), {\n *   other: Stream.make(\"a\", \"b\", \"c\"),\n *   defaultSelf: 0,\n *   defaultOther: \"x\"\n * })\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: \"Chunk\", values: [ [ 1, \"a\" ], [ 2, \"b\" ], [ 3, \"c\" ], [ 4, \"x\" ], [ 5, \"x\" ], [ 6, \"x\" ] ] }\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAll = internal.zipAll;\n/**\n * Zips this stream with another point-wise, and keeps only elements from this\n * stream.\n *\n * The provided default value will be used if the other stream ends before\n * this one.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllLeft = internal.zipAllLeft;\n/**\n * Zips this stream with another point-wise, and keeps only elements from the\n * other stream.\n *\n * The provided default value will be used if this stream ends before the\n * other one.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllRight = internal.zipAllRight;\n/**\n * Zips this stream that is sorted by distinct keys and the specified stream\n * that is sorted by distinct keys to produce a new stream that is sorted by\n * distinct keys. Combines values associated with each key into a tuple,\n * using the specified values `defaultLeft` and `defaultRight` to fill in\n * missing values.\n *\n * This allows zipping potentially unbounded streams of data by key in\n * constant space but the caller is responsible for ensuring that the\n * streams are sorted by distinct keys.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllSortedByKey = internal.zipAllSortedByKey;\n/**\n * Zips this stream that is sorted by distinct keys and the specified stream\n * that is sorted by distinct keys to produce a new stream that is sorted by\n * distinct keys. Keeps only values from this stream, using the specified\n * value `default` to fill in missing values.\n *\n * This allows zipping potentially unbounded streams of data by key in\n * constant space but the caller is responsible for ensuring that the\n * streams are sorted by distinct keys.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllSortedByKeyLeft = internal.zipAllSortedByKeyLeft;\n/**\n * Zips this stream that is sorted by distinct keys and the specified stream\n * that is sorted by distinct keys to produce a new stream that is sorted by\n * distinct keys. Keeps only values from that stream, using the specified\n * value `default` to fill in missing values.\n *\n * This allows zipping potentially unbounded streams of data by key in\n * constant space but the caller is responsible for ensuring that the\n * streams are sorted by distinct keys.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllSortedByKeyRight = internal.zipAllSortedByKeyRight;\n/**\n * Zips this stream that is sorted by distinct keys and the specified stream\n * that is sorted by distinct keys to produce a new stream that is sorted by\n * distinct keys. Uses the functions `left`, `right`, and `both` to handle\n * the cases where a key and value exist in this stream, that stream, or\n * both streams.\n *\n * This allows zipping potentially unbounded streams of data by key in\n * constant space but the caller is responsible for ensuring that the\n * streams are sorted by distinct keys.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllSortedByKeyWith = internal.zipAllSortedByKeyWith;\n/**\n * Zips this stream with another point-wise. The provided functions will be\n * used to create elements for the composed stream.\n *\n * The functions `left` and `right` will be used if the streams have different\n * lengths and one of the streams has ended before the other.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipAllWith(Stream.make(1, 2, 3, 4, 5, 6), {\n *   other: Stream.make(\"a\", \"b\", \"c\"),\n *   onSelf: (n) => [n, \"x\"],\n *   onOther: (s) => [0, s],\n *   onBoth: (n, s) => [n - s.length, s]\n * })\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: \"Chunk\", values: [ [ 0, \"a\" ], [ 1, \"b\" ], [ 2, \"c\" ], [ 4, \"x\" ], [ 5, \"x\" ], [ 6, \"x\" ] ] }\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllWith = internal.zipAllWith;\n/**\n * Zips the two streams so that when a value is emitted by either of the two\n * streams, it is combined with the latest value from the other stream to\n * produce a result.\n *\n * Note: tracking the latest value is done on a per-chunk basis. That means\n * that emitted elements that are not the last value in chunks will never be\n * used for zipping.\n *\n * @example\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3).pipe(\n *   Stream.schedule(Schedule.spaced(\"1 second\"))\n * )\n *\n * const s2 = Stream.make(\"a\", \"b\", \"c\", \"d\").pipe(\n *   Stream.schedule(Schedule.spaced(\"500 millis\"))\n * )\n *\n * const stream = Stream.zipLatest(s1, s2)\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: \"Chunk\", values: [ [ 1, \"a\" ], [ 1, \"b\" ], [ 2, \"b\" ], [ 2, \"c\" ], [ 2, \"d\" ], [ 3, \"d\" ] ] }\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLatest = internal.zipLatest;\n/**\n * Zips multiple streams so that when a value is emitted by any of the streams,\n * it is combined with the latest values from the other streams to produce a result.\n *\n * Note: tracking the latest value is done on a per-chunk basis. That means\n * that emitted elements that are not the last value in chunks will never be\n * used for zipping.\n *\n * @example\n * import { Stream, Schedule, Console, Effect } from \"effect\"\n *\n * const stream = Stream.zipLatestAll(\n *     Stream.fromSchedule(Schedule.spaced('1 millis')),\n *     Stream.fromSchedule(Schedule.spaced('2 millis')),\n *     Stream.fromSchedule(Schedule.spaced('4 millis')),\n * ).pipe(Stream.take(6), Stream.tap(Console.log))\n *\n * // Effect.runPromise(Stream.runDrain(stream))\n * // Output:\n * // [ 0, 0, 0 ]\n * // [ 1, 0, 0 ]\n * // [ 1, 1, 0 ]\n * // [ 2, 1, 0 ]\n * // [ 3, 1, 0 ]\n * // [ 3, 1, 1 ]\n * // .....\n *\n * @since 3.3.0\n * @category zipping\n */\nexport const zipLatestAll = internal.zipLatestAll;\n/**\n * Zips the two streams so that when a value is emitted by either of the two\n * streams, it is combined with the latest value from the other stream to\n * produce a result.\n *\n * Note: tracking the latest value is done on a per-chunk basis. That means\n * that emitted elements that are not the last value in chunks will never be\n * used for zipping.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLatestWith = internal.zipLatestWith;\n/**\n * Zips this stream with another point-wise, but keeps only the outputs of\n * this stream.\n *\n * The new stream will end when one of the sides ends.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = internal.zipLeft;\n/**\n * Zips this stream with another point-wise, but keeps only the outputs of the\n * other stream.\n *\n * The new stream will end when one of the sides ends.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = internal.zipRight;\n/**\n * Zips this stream with another point-wise and applies the function to the\n * paired elements.\n *\n * The new stream will end when one of the sides ends.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * // We create two streams and zip them with custom logic.\n * const stream = Stream.zipWith(\n *   Stream.make(1, 2, 3, 4, 5, 6),\n *   Stream.make(\"a\", \"b\", \"c\"),\n *   (n, s) => [n - s.length, s]\n * )\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ [ 0, 'a' ], [ 1, 'b' ], [ 2, 'c' ] ] }\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = internal.zipWith;\n/**\n * Zips this stream with another point-wise and applies the function to the\n * paired elements.\n *\n * The new stream will end when one of the sides ends.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithChunks = internal.zipWithChunks;\n/**\n * Zips each element with the next element if present.\n *\n * @example\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipWithNext(Stream.make(1, 2, 3, 4))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then((chunk) => console.log(Chunk.toArray(chunk)))\n * // [\n * //   [ 1, { _id: 'Option', _tag: 'Some', value: 2 } ],\n * //   [ 2, { _id: 'Option', _tag: 'Some', value: 3 } ],\n * //   [ 3, { _id: 'Option', _tag: 'Some', value: 4 } ],\n * //   [ 4, { _id: 'Option', _tag: 'None' } ]\n * // ]\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithNext = internal.zipWithNext;\n/**\n * Zips each element with the previous element. Initially accompanied by\n * `None`.\n *\n * @example\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipWithPrevious(Stream.make(1, 2, 3, 4))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then((chunk) => console.log(Chunk.toArray(chunk)))\n * // [\n * //   [ { _id: 'Option', _tag: 'None' }, 1 ],\n * //   [ { _id: 'Option', _tag: 'Some', value: 1 }, 2 ],\n * //   [ { _id: 'Option', _tag: 'Some', value: 2 }, 3 ],\n * //   [ { _id: 'Option', _tag: 'Some', value: 3 }, 4 ]\n * // ]\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithPrevious = internal.zipWithPrevious;\n/**\n * Zips each element with both the previous and next element.\n *\n * @example\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipWithPreviousAndNext(Stream.make(1, 2, 3, 4))\n *\n * // Effect.runPromise(Stream.runCollect(stream)).then((chunk) => console.log(Chunk.toArray(chunk)))\n * // [\n * //   [\n * //     { _id: 'Option', _tag: 'None' },\n * //     1,\n * //     { _id: 'Option', _tag: 'Some', value: 2 }\n * //   ],\n * //   [\n * //     { _id: 'Option', _tag: 'Some', value: 1 },\n * //     2,\n * //     { _id: 'Option', _tag: 'Some', value: 3 }\n * //   ],\n * //   [\n * //     { _id: 'Option', _tag: 'Some', value: 2 },\n * //     3,\n * //     { _id: 'Option', _tag: 'Some', value: 4 }\n * //   ],\n * //   [\n * //     { _id: 'Option', _tag: 'Some', value: 3 },\n * //     4,\n * //     { _id: 'Option', _tag: 'None' }\n * //   ]\n * // ]\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithPreviousAndNext = internal.zipWithPreviousAndNext;\n/**\n * Zips this stream together with the index of elements.\n *\n * @example\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(\"Mary\", \"James\", \"Robert\", \"Patricia\")\n *\n * const indexedStream = Stream.zipWithIndex(stream)\n *\n * // Effect.runPromise(Stream.runCollect(indexedStream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [ [ 'Mary', 0 ], [ 'James', 1 ], [ 'Robert', 2 ], [ 'Patricia', 3 ] ]\n * // }\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithIndex = internal.zipWithIndex;\n// -------------------------------------------------------------------------------------\n// Do notation\n// -------------------------------------------------------------------------------------\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Stream` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link bindEffect}\n * @see {@link let_ let}\n *\n * @example\n * import { Chunk, Effect, pipe, Stream } from \"effect\"\n *\n * const result = pipe(\n *   Stream.Do,\n *   Stream.bind(\"x\", () => Stream.succeed(2)),\n *   Stream.bind(\"y\", () => Stream.succeed(3)),\n *   Stream.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(Stream.runCollect(result)), Chunk.of({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const Do = internal.Do;\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Stream` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link bindEffect}\n * @see {@link let_ let}\n *\n * @example\n * import { Chunk, Effect, pipe, Stream } from \"effect\"\n *\n * const result = pipe(\n *   Stream.Do,\n *   Stream.bind(\"x\", () => Stream.succeed(2)),\n *   Stream.bind(\"y\", () => Stream.succeed(3)),\n *   Stream.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(Stream.runCollect(result)), Chunk.of({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bind = internal.bind;\n/**\n * Binds an effectful value in a `do` scope\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link let_ let}\n *\n * @since 2.0.0\n * @category do notation\n */\nexport const bindEffect = _groupBy.bindEffect;\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Stream` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bind}\n * @see {@link bindEffect}\n * @see {@link let_ let}\n *\n * @example\n * import { Chunk, Effect, pipe, Stream } from \"effect\"\n *\n * const result = pipe(\n *   Stream.Do,\n *   Stream.bind(\"x\", () => Stream.succeed(2)),\n *   Stream.bind(\"y\", () => Stream.succeed(3)),\n *   Stream.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(Stream.runCollect(result)), Chunk.of({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bindTo = internal.bindTo;\nconst let_ = internal.let_;\nexport {\n/**\n * The \"do simulation\" in allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Stream` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link bindEffect}\n *\n * @example\n * import { Chunk, Effect, pipe, Stream } from \"effect\"\n *\n * const result = pipe(\n *   Stream.Do,\n *   Stream.bind(\"x\", () => Stream.succeed(2)),\n *   Stream.bind(\"y\", () => Stream.succeed(3)),\n *   Stream.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(Stream.runCollect(result)), Chunk.of({ x: 2, y: 3, sum: 5 }))\n *\n * @category do notation\n * @since 2.0.0\n */\nlet_ as let };\n// -------------------------------------------------------------------------------------\n// encoding\n// -------------------------------------------------------------------------------------\n/**\n * Decode Uint8Array chunks into a stream of strings using the specified encoding.\n *\n * @since 2.0.0\n * @category encoding\n */\nexport const decodeText = internal.decodeText;\n/**\n * Encode a stream of strings into a stream of Uint8Array chunks using the specified encoding.\n *\n * @since 2.0.0\n * @category encoding\n */\nexport const encodeText = internal.encodeText;\n/**\n * Creates a `Stream` using addEventListener.\n * @since 3.1.0\n */\nexport const fromEventListener = internal.fromEventListener;\n//# sourceMappingURL=Stream.js.map","/**\n * @since 2.0.0\n */\nimport * as internal from \"./internal/stream/haltStrategy.js\";\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Left = internal.Left;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Right = internal.Right;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Both = internal.Both;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const Either = internal.Either;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const fromInput = internal.fromInput;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isLeft = internal.isLeft;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isRight = internal.isRight;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isBoth = internal.isBoth;\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isEither = internal.isEither;\n/**\n * Folds over the specified `HaltStrategy` using the provided case functions.\n *\n * @since 2.0.0\n * @category folding\n */\nexport const match = internal.match;\n//# sourceMappingURL=StreamHaltStrategy.js.map","/**\n * This module provides utility functions and type class instances for working with the `string` type in TypeScript.\n * It includes functions for basic string manipulation, as well as type class instances for\n * `Equivalence` and `Order`.\n *\n * @since 2.0.0\n */\nimport * as equivalence from \"./Equivalence.js\";\nimport { dual } from \"./Function.js\";\nimport * as readonlyArray from \"./internal/array.js\";\nimport * as number from \"./Number.js\";\nimport * as Option from \"./Option.js\";\nimport * as order from \"./Order.js\";\nimport * as predicate from \"./Predicate.js\";\n/**\n * Tests if a value is a `string`.\n *\n * @param input - The value to test.\n *\n * @example\n * import { String } from \"effect\"\n *\n * assert.deepStrictEqual(String.isString(\"a\"), true)\n * assert.deepStrictEqual(String.isString(1), false)\n *\n * @category guards\n * @since 2.0.0\n */\nexport const isString = predicate.isString;\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Equivalence = equivalence.string;\n/**\n * @category instances\n * @since 2.0.0\n */\nexport const Order = order.string;\n/**\n * The empty string `\"\"`.\n *\n * @since 2.0.0\n */\nexport const empty = \"\";\n/**\n * Concatenates two strings at runtime.\n *\n * @since 2.0.0\n */\nexport const concat = /*#__PURE__*/dual(2, (self, that) => self + that);\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe('a', String.toUpperCase), 'A')\n *\n * @since 2.0.0\n */\nexport const toUpperCase = self => self.toUpperCase();\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe('A', String.toLowerCase), 'a')\n *\n * @since 2.0.0\n */\nexport const toLowerCase = self => self.toLowerCase();\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe('abc', String.capitalize), 'Abc')\n *\n * @since 2.0.0\n */\nexport const capitalize = self => {\n  if (self.length === 0) return self;\n  return toUpperCase(self[0]) + self.slice(1);\n};\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe('ABC', String.uncapitalize), 'aBC')\n *\n * @since 2.0.0\n */\nexport const uncapitalize = self => {\n  if (self.length === 0) return self;\n  return toLowerCase(self[0]) + self.slice(1);\n};\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe('abc', String.replace('b', 'd')), 'adc')\n *\n * @since 2.0.0\n */\nexport const replace = (searchValue, replaceValue) => self => self.replace(searchValue, replaceValue);\n/**\n * @example\n * import { String } from \"effect\"\n *\n * assert.deepStrictEqual(String.trim(' a '), 'a')\n *\n * @since 2.0.0\n */\nexport const trim = self => self.trim();\n/**\n * @example\n * import { String } from \"effect\"\n *\n * assert.deepStrictEqual(String.trimStart(' a '), 'a ')\n *\n * @since 2.0.0\n */\nexport const trimStart = self => self.trimStart();\n/**\n * @example\n * import { String } from \"effect\"\n *\n * assert.deepStrictEqual(String.trimEnd(' a '), ' a')\n *\n * @since 2.0.0\n */\nexport const trimEnd = self => self.trimEnd();\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe('abcd', String.slice(1, 3)), 'bc')\n *\n * @since 2.0.0\n */\nexport const slice = (start, end) => self => self.slice(start, end);\n/**\n * Test whether a `string` is empty.\n *\n * @example\n * import { String } from \"effect\"\n *\n * assert.deepStrictEqual(String.isEmpty(''), true)\n * assert.deepStrictEqual(String.isEmpty('a'), false)\n *\n * @since 2.0.0\n */\nexport const isEmpty = self => self.length === 0;\n/**\n * Test whether a `string` is non empty.\n *\n * @since 2.0.0\n */\nexport const isNonEmpty = self => self.length > 0;\n/**\n * Calculate the number of characters in a `string`.\n *\n * @example\n * import { String } from \"effect\"\n *\n * assert.deepStrictEqual(String.length('abc'), 3)\n *\n * @since 2.0.0\n */\nexport const length = self => self.length;\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe('abc', String.split('')), ['a', 'b', 'c'])\n * assert.deepStrictEqual(pipe('', String.split('')), [''])\n *\n * @since 2.0.0\n */\nexport const split = /*#__PURE__*/dual(2, (self, separator) => {\n  const out = self.split(separator);\n  return readonlyArray.isNonEmptyArray(out) ? out : [self];\n});\n/**\n * Returns `true` if `searchString` appears as a substring of `self`, at one or more positions that are\n * greater than or equal to `position`; otherwise, returns `false`.\n *\n * @since 2.0.0\n */\nexport const includes = (searchString, position) => self => self.includes(searchString, position);\n/**\n * @since 2.0.0\n */\nexport const startsWith = (searchString, position) => self => self.startsWith(searchString, position);\n/**\n * @since 2.0.0\n */\nexport const endsWith = (searchString, position) => self => self.endsWith(searchString, position);\n/**\n * @example\n * import { pipe, String, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"abc\", String.charCodeAt(1)), Option.some(98))\n * assert.deepStrictEqual(pipe(\"abc\", String.charCodeAt(4)), Option.none())\n *\n * @since 2.0.0\n */\nexport const charCodeAt = /*#__PURE__*/dual(2, (self, index) => Option.filter(Option.some(self.charCodeAt(index)), charCode => !isNaN(charCode)));\n/**\n * @example\n * import { pipe, String, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"abcd\", String.substring(1)), \"bcd\")\n * assert.deepStrictEqual(pipe(\"abcd\", String.substring(1, 3)), \"bc\")\n *\n * @since 2.0.0\n */\nexport const substring = (start, end) => self => self.substring(start, end);\n/**\n * @example\n * import { pipe, String, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"abc\", String.at(1)), Option.some(\"b\"))\n * assert.deepStrictEqual(pipe(\"abc\", String.at(4)), Option.none())\n *\n * @since 2.0.0\n */\nexport const at = /*#__PURE__*/dual(2, (self, index) => Option.fromNullable(self.at(index)));\n/**\n * @example\n * import { pipe, String, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"abc\", String.charAt(1)), Option.some(\"b\"))\n * assert.deepStrictEqual(pipe(\"abc\", String.charAt(4)), Option.none())\n *\n * @since 2.0.0\n */\nexport const charAt = /*#__PURE__*/dual(2, (self, index) => Option.filter(Option.some(self.charAt(index)), isNonEmpty));\n/**\n * @example\n * import { pipe, String, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"abc\", String.codePointAt(1)), Option.some(98))\n *\n * @since 2.0.0\n */\nexport const codePointAt = /*#__PURE__*/dual(2, (self, index) => Option.fromNullable(self.codePointAt(index)));\n/**\n * @example\n * import { pipe, String, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"abbbc\", String.indexOf(\"b\")), Option.some(1))\n *\n * @since 2.0.0\n */\nexport const indexOf = searchString => self => Option.filter(Option.some(self.indexOf(searchString)), number.greaterThanOrEqualTo(0));\n/**\n * @example\n * import { pipe, String, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"abbbc\", String.lastIndexOf(\"b\")), Option.some(3))\n * assert.deepStrictEqual(pipe(\"abbbc\", String.lastIndexOf(\"d\")), Option.none())\n *\n * @since 2.0.0\n */\nexport const lastIndexOf = searchString => self => Option.filter(Option.some(self.lastIndexOf(searchString)), number.greaterThanOrEqualTo(0));\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"a\", String.localeCompare(\"b\")), -1)\n * assert.deepStrictEqual(pipe(\"b\", String.localeCompare(\"a\")), 1)\n * assert.deepStrictEqual(pipe(\"a\", String.localeCompare(\"a\")), 0)\n *\n * @since 2.0.0\n */\nexport const localeCompare = (that, locales, options) => self => number.sign(self.localeCompare(that, locales, options));\n/**\n * It is the `pipe`-able version of the native `match` method.\n *\n * @since 2.0.0\n */\nexport const match = regexp => self => Option.fromNullable(self.match(regexp));\n/**\n * It is the `pipe`-able version of the native `matchAll` method.\n *\n * @since 2.0.0\n */\nexport const matchAll = regexp => self => self.matchAll(regexp);\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * const str = \"\\u1E9B\\u0323\";\n * assert.deepStrictEqual(pipe(str, String.normalize()), \"\\u1E9B\\u0323\")\n * assert.deepStrictEqual(pipe(str, String.normalize(\"NFC\")), \"\\u1E9B\\u0323\")\n * assert.deepStrictEqual(pipe(str, String.normalize(\"NFD\")), \"\\u017F\\u0323\\u0307\")\n * assert.deepStrictEqual(pipe(str, String.normalize(\"NFKC\")), \"\\u1E69\")\n * assert.deepStrictEqual(pipe(str, String.normalize(\"NFKD\")), \"\\u0073\\u0323\\u0307\")\n *\n * @since 2.0.0\n */\nexport const normalize = form => self => self.normalize(form);\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"a\", String.padEnd(5)), \"a    \")\n * assert.deepStrictEqual(pipe(\"a\", String.padEnd(5, \"_\")), \"a____\")\n *\n * @since 2.0.0\n */\nexport const padEnd = (maxLength, fillString) => self => self.padEnd(maxLength, fillString);\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"a\", String.padStart(5)), \"    a\")\n * assert.deepStrictEqual(pipe(\"a\", String.padStart(5, \"_\")), \"____a\")\n *\n * @since 2.0.0\n */\nexport const padStart = (maxLength, fillString) => self => self.padStart(maxLength, fillString);\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"a\", String.repeat(5)), \"aaaaa\")\n *\n * @since 2.0.0\n */\nexport const repeat = count => self => self.repeat(count);\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"ababb\", String.replaceAll(\"b\", \"c\")), \"acacc\")\n * assert.deepStrictEqual(pipe(\"ababb\", String.replaceAll(/ba/g, \"cc\")), \"accbb\")\n *\n * @since 2.0.0\n */\nexport const replaceAll = (searchValue, replaceValue) => self => self.replaceAll(searchValue, replaceValue);\n/**\n * @example\n * import { pipe, String, Option } from \"effect\"\n *\n * assert.deepStrictEqual(pipe(\"ababb\", String.search(\"b\")), Option.some(1))\n * assert.deepStrictEqual(pipe(\"ababb\", String.search(/abb/)), Option.some(2))\n * assert.deepStrictEqual(pipe(\"ababb\", String.search(\"d\")), Option.none())\n *\n * @since 2.0.0\n */\nexport const search = /*#__PURE__*/dual(2, (self, regexp) => Option.filter(Option.some(self.search(regexp)), number.greaterThanOrEqualTo(0)));\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * const str = \"\\u0130\"\n * assert.deepStrictEqual(pipe(str, String.toLocaleLowerCase(\"tr\")), \"i\")\n *\n * @since 2.0.0\n */\nexport const toLocaleLowerCase = locale => self => self.toLocaleLowerCase(locale);\n/**\n * @example\n * import { pipe, String } from \"effect\"\n *\n * const str = \"i\\u0307\"\n * assert.deepStrictEqual(pipe(str, String.toLocaleUpperCase(\"lt-LT\")), \"I\")\n *\n * @since 2.0.0\n */\nexport const toLocaleUpperCase = locale => self => self.toLocaleUpperCase(locale);\n/**\n * Keep the specified number of characters from the start of a string.\n *\n * If `n` is larger than the available number of characters, the string will\n * be returned whole.\n *\n * If `n` is not a positive number, an empty string will be returned.\n *\n * If `n` is a float, it will be rounded down to the nearest integer.\n *\n * @example\n * import { String } from \"effect\"\n *\n * assert.deepStrictEqual(String.takeLeft(\"Hello World\", 5), \"Hello\")\n *\n * @since 2.0.0\n */\nexport const takeLeft = /*#__PURE__*/dual(2, (self, n) => self.slice(0, Math.max(n, 0)));\n/**\n * Keep the specified number of characters from the end of a string.\n *\n * If `n` is larger than the available number of characters, the string will\n * be returned whole.\n *\n * If `n` is not a positive number, an empty string will be returned.\n *\n * If `n` is a float, it will be rounded down to the nearest integer.\n *\n * @example\n * import { String } from \"effect\"\n *\n * assert.deepStrictEqual(String.takeRight(\"Hello World\", 5), \"World\")\n *\n * @since 2.0.0\n */\nexport const takeRight = /*#__PURE__*/dual(2, (self, n) => self.slice(Math.max(0, self.length - Math.floor(n)), Infinity));\nconst CR = 0x0d;\nconst LF = 0x0a;\n/**\n * Returns an `IterableIterator` which yields each line contained within the\n * string, trimming off the trailing newline character.\n *\n * @since 2.0.0\n */\nexport const linesIterator = self => linesSeparated(self, true);\n/**\n * Returns an `IterableIterator` which yields each line contained within the\n * string as well as the trailing newline character.\n *\n * @since 2.0.0\n */\nexport const linesWithSeparators = s => linesSeparated(s, false);\n/**\n * For every line in this string, strip a leading prefix consisting of blanks\n * or control characters followed by the character specified by `marginChar`\n * from the line.\n *\n * @since 2.0.0\n */\nexport const stripMarginWith = /*#__PURE__*/dual(2, (self, marginChar) => {\n  let out = \"\";\n  for (const line of linesWithSeparators(self)) {\n    let index = 0;\n    while (index < line.length && line.charAt(index) <= \" \") {\n      index = index + 1;\n    }\n    const stripped = index < line.length && line.charAt(index) === marginChar ? line.substring(index + 1) : line;\n    out = out + stripped;\n  }\n  return out;\n});\n/**\n * For every line in this string, strip a leading prefix consisting of blanks\n * or control characters followed by the `\"|\"` character from the line.\n *\n * @since 2.0.0\n */\nexport const stripMargin = self => stripMarginWith(self, \"|\");\n/**\n * @since 2.0.0\n */\nexport const snakeToCamel = self => {\n  let str = self[0];\n  for (let i = 1; i < self.length; i++) {\n    str += self[i] === \"_\" ? self[++i].toUpperCase() : self[i];\n  }\n  return str;\n};\n/**\n * @since 2.0.0\n */\nexport const snakeToPascal = self => {\n  let str = self[0].toUpperCase();\n  for (let i = 1; i < self.length; i++) {\n    str += self[i] === \"_\" ? self[++i].toUpperCase() : self[i];\n  }\n  return str;\n};\n/**\n * @since 2.0.0\n */\nexport const snakeToKebab = self => self.replace(/_/g, \"-\");\n/**\n * @since 2.0.0\n */\nexport const camelToSnake = self => self.replace(/([A-Z])/g, \"_$1\").toLowerCase();\n/**\n * @since 2.0.0\n */\nexport const pascalToSnake = self => (self.slice(0, 1) + self.slice(1).replace(/([A-Z])/g, \"_$1\")).toLowerCase();\n/**\n * @since 2.0.0\n */\nexport const kebabToSnake = self => self.replace(/-/g, \"_\");\nclass LinesIterator {\n  s;\n  stripped;\n  index;\n  length;\n  constructor(s, stripped = false) {\n    this.s = s;\n    this.stripped = stripped;\n    this.index = 0;\n    this.length = s.length;\n  }\n  next() {\n    if (this.done) {\n      return {\n        done: true,\n        value: undefined\n      };\n    }\n    const start = this.index;\n    while (!this.done && !isLineBreak(this.s[this.index])) {\n      this.index = this.index + 1;\n    }\n    let end = this.index;\n    if (!this.done) {\n      const char = this.s[this.index];\n      this.index = this.index + 1;\n      if (!this.done && isLineBreak2(char, this.s[this.index])) {\n        this.index = this.index + 1;\n      }\n      if (!this.stripped) {\n        end = this.index;\n      }\n    }\n    return {\n      done: false,\n      value: this.s.substring(start, end)\n    };\n  }\n  [Symbol.iterator]() {\n    return new LinesIterator(this.s, this.stripped);\n  }\n  get done() {\n    return this.index >= this.length;\n  }\n}\n/**\n * Test if the provided character is a line break character (i.e. either `\"\\r\"`\n * or `\"\\n\"`).\n */\nconst isLineBreak = char => {\n  const code = char.charCodeAt(0);\n  return code === CR || code === LF;\n};\n/**\n * Test if the provided characters combine to form a carriage return/line-feed\n * (i.e. `\"\\r\\n\"`).\n */\nconst isLineBreak2 = (char0, char1) => char0.charCodeAt(0) === CR && char1.charCodeAt(0) === LF;\nconst linesSeparated = (self, stripped) => new LinesIterator(self, stripped);\n//# sourceMappingURL=String.js.map","import * as defaultServices from \"./internal/defaultServices.js\";\nimport * as internal from \"./internal/tracer.js\";\n/**\n * @since 2.0.0\n */\nexport const TracerTypeId = internal.TracerTypeId;\n/**\n * @since 2.0.0\n * @category tags\n */\nexport const ParentSpan = internal.spanTag;\n/**\n * @since 2.0.0\n * @category tags\n */\nexport const Tracer = internal.tracerTag;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const externalSpan = internal.externalSpan;\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const tracerWith = defaultServices.tracerWith;\n//# sourceMappingURL=Tracer.js.map","/**\n * This module provides utility functions for working with tuples in TypeScript.\n *\n * @since 2.0.0\n */\nimport * as Equivalence from \"./Equivalence.js\";\nimport { dual } from \"./Function.js\";\nimport * as order from \"./Order.js\";\n/**\n * Constructs a new tuple from the provided values.\n *\n * @param elements - The list of elements to create the tuple from.\n *\n * @example\n * import { make } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(make(1, 'hello', true), [1, 'hello', true])\n *\n * @category constructors\n * @since 2.0.0\n */\nexport const make = (...elements) => elements;\n/**\n * Return the first element of a tuple.\n *\n * @param self - A tuple of length `2`.\n *\n * @example\n * import { getFirst } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(getFirst([\"hello\", 42]), \"hello\")\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getFirst = self => self[0];\n/**\n * Return the second element of a tuple.\n *\n * @param self - A tuple of length `2`.\n *\n * @example\n * import { getSecond } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(getSecond([\"hello\", 42]), 42)\n *\n * @category getters\n * @since 2.0.0\n */\nexport const getSecond = self => self[1];\n/**\n * Transforms both elements of a tuple using the given functions.\n *\n * @param self - A tuple of length `2`.\n * @param f - The function to transform the first element of the tuple.\n * @param g - The function to transform the second element of the tuple.\n *\n * @example\n * import { mapBoth } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(\n *   mapBoth([\"hello\", 42], { onFirst: s => s.toUpperCase(), onSecond: n => n.toString() }),\n *   [\"HELLO\", \"42\"]\n * )\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const mapBoth = /*#__PURE__*/dual(2, (self, {\n  onFirst,\n  onSecond\n}) => [onFirst(self[0]), onSecond(self[1])]);\n/**\n * Transforms the first component of a tuple using a given function.\n *\n * @param self - A tuple of length `2`.\n * @param f - The function to transform the first element of the tuple.\n *\n * @example\n * import { mapFirst } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(\n *   mapFirst([\"hello\", 42], s => s.toUpperCase()),\n *   [\"HELLO\", 42]\n * )\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const mapFirst = /*#__PURE__*/dual(2, (self, f) => [f(self[0]), self[1]]);\n/**\n * Transforms the second component of a tuple using a given function.\n *\n * @param self - A tuple of length `2`.\n * @param f - The function to transform the second element of the tuple.\n *\n * @example\n * import { mapSecond } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(\n *   mapSecond([\"hello\", 42], n => n.toString()),\n *   [\"hello\", \"42\"]\n * )\n *\n * @category mapping\n * @since 2.0.0\n */\nexport const mapSecond = /*#__PURE__*/dual(2, (self, f) => [self[0], f(self[1])]);\n/**\n * Swaps the two elements of a tuple.\n *\n * @param self - A tuple of length `2`.\n *\n * @example\n * import { swap } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(swap([\"hello\", 42]), [42, \"hello\"])\n *\n * @since 2.0.0\n */\nexport const swap = self => [self[1], self[0]];\n/**\n * Given a tuple of `Equivalence`s returns a new `Equivalence` that compares values of a tuple\n * by applying each `Equivalence` to the corresponding element of the tuple.\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const getEquivalence = Equivalence.tuple;\n/**\n * This function creates and returns a new `Order` for a tuple of values based on the given `Order`s for each element in the tuple.\n * The returned `Order` compares two tuples of the same type by applying the corresponding `Order` to each element in the tuple.\n * It is useful when you need to compare two tuples of the same type and you have a specific way of comparing each element\n * of the tuple.\n *\n * @category combinators\n * @since 2.0.0\n */\nexport const getOrder = order.tuple;\n/**\n * Appends an element to the end of a tuple.\n *\n * @category concatenating\n * @since 2.0.0\n */\nexport const appendElement = /*#__PURE__*/dual(2, (self, that) => [...self, that]);\n/**\n * Retrieves the element at a specified index from a tuple.\n *\n * @param self - A tuple from which to retrieve the element.\n * @param index - The index of the element to retrieve.\n *\n * @example\n * import { Tuple } from \"effect\"\n *\n * assert.deepStrictEqual(Tuple.at([1, 'hello', true], 1), 'hello')\n *\n * @category getters\n * @since 3.4.0\n */\nexport const at = /*#__PURE__*/dual(2, (self, index) => self[index]);\nexport {\n/**\n * Determine if an `Array` is a tuple with exactly `N` elements, narrowing down the type to `TupleOf`.\n *\n * An `Array` is considered to be a `TupleOf` if its length is exactly `N`.\n *\n * @param self - The `Array` to check.\n * @param n - The exact number of elements that the `Array` should have to be considered a `TupleOf`.\n *\n * @example\n * import { isTupleOf } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(isTupleOf([1, 2, 3], 3), true);\n * assert.deepStrictEqual(isTupleOf([1, 2, 3], 2), false);\n * assert.deepStrictEqual(isTupleOf([1, 2, 3], 4), false);\n *\n * const arr: number[] = [1, 2, 3];\n * if (isTupleOf(arr, 3)) {\n *   console.log(arr);\n *   // ^? [number, number, number]\n * }\n *\n * @category guards\n * @since 3.3.0\n */\nisTupleOf,\n/**\n * Determine if an `Array` is a tuple with at least `N` elements, narrowing down the type to `TupleOfAtLeast`.\n *\n * An `Array` is considered to be a `TupleOfAtLeast` if its length is at least `N`.\n *\n * @param self - The `Array` to check.\n * @param n - The minimum number of elements that the `Array` should have to be considered a `TupleOfAtLeast`.\n *\n * @example\n * import { isTupleOfAtLeast } from \"effect/Tuple\"\n *\n * assert.deepStrictEqual(isTupleOfAtLeast([1, 2, 3], 3), true);\n * assert.deepStrictEqual(isTupleOfAtLeast([1, 2, 3], 2), true);\n * assert.deepStrictEqual(isTupleOfAtLeast([1, 2, 3], 4), false);\n *\n * const arr: number[] = [1, 2, 3, 4];\n * if (isTupleOfAtLeast(arr, 3)) {\n *   console.log(arr);\n *   // ^? [number, number, number, ...number[]]\n * }\n *\n * @category guards\n * @since 3.3.0\n */\nisTupleOfAtLeast } from \"./Predicate.js\";\n//# sourceMappingURL=Tuple.js.map","/**\n * @since 2.0.0\n */\nimport { identity } from \"./Function.js\";\nimport { globalValue } from \"./GlobalValue.js\";\nimport { getBugErrorMessage } from \"./internal/errors.js\";\nimport { isNullable, isObject } from \"./Predicate.js\";\n/*\n * Copyright 2014 Thom Chiovoloni, released under the MIT license.\n *\n * A random number generator based on the basic implementation of the PCG algorithm,\n * as described here: http://www.pcg-random.org/\n *\n * Adapted for TypeScript from Thom's original code at https://github.com/thomcc/pcg-random\n *\n * forked from https://github.com/frptools\n *\n * @since 2.0.0\n */\n/**\n * @category symbols\n * @since 2.0.0\n */\nexport const GenKindTypeId = /*#__PURE__*/Symbol.for(\"effect/Gen/GenKind\");\n/**\n * @category predicates\n * @since 3.0.6\n */\nexport const isGenKind = u => isObject(u) && GenKindTypeId in u;\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport class GenKindImpl {\n  value;\n  constructor(\n  /**\n   * @since 2.0.0\n   */\n  value) {\n    this.value = value;\n  }\n  /**\n   * @since 2.0.0\n   */\n  get _F() {\n    return identity;\n  }\n  /**\n   * @since 2.0.0\n   */\n  get _R() {\n    return _ => _;\n  }\n  /**\n   * @since 2.0.0\n   */\n  get _O() {\n    return _ => _;\n  }\n  /**\n   * @since 2.0.0\n   */\n  get _E() {\n    return _ => _;\n  }\n  /**\n   * @since 2.0.0\n   */\n  [GenKindTypeId] = GenKindTypeId;\n  /**\n   * @since 2.0.0\n   */\n  [Symbol.iterator]() {\n    return new SingleShotGen(this);\n  }\n}\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport class SingleShotGen {\n  self;\n  called = false;\n  constructor(self) {\n    this.self = self;\n  }\n  /**\n   * @since 2.0.0\n   */\n  next(a) {\n    return this.called ? {\n      value: a,\n      done: true\n    } : (this.called = true, {\n      value: this.self,\n      done: false\n    });\n  }\n  /**\n   * @since 2.0.0\n   */\n  return(a) {\n    return {\n      value: a,\n      done: true\n    };\n  }\n  /**\n   * @since 2.0.0\n   */\n  throw(e) {\n    throw e;\n  }\n  /**\n   * @since 2.0.0\n   */\n  [Symbol.iterator]() {\n    return new SingleShotGen(this.self);\n  }\n}\n/**\n * @category constructors\n * @since 2.0.0\n */\nexport const makeGenKind = kind => new GenKindImpl(kind);\n/**\n * @category adapters\n * @since 2.0.0\n */\nexport const adapter = () => function () {\n  let x = arguments[0];\n  for (let i = 1; i < arguments.length; i++) {\n    x = arguments[i](x);\n  }\n  return new GenKindImpl(x);\n};\nconst defaultIncHi = 0x14057b7e;\nconst defaultIncLo = 0xf767814f;\nconst MUL_HI = 0x5851f42d >>> 0;\nconst MUL_LO = 0x4c957f2d >>> 0;\nconst BIT_53 = 9007199254740992.0;\nconst BIT_27 = 134217728.0;\n/**\n * PCG is a family of simple fast space-efficient statistically good algorithms\n * for random number generation. Unlike many general-purpose RNGs, they are also\n * hard to predict.\n *\n * @category model\n * @since 2.0.0\n */\nexport class PCGRandom {\n  _state;\n  constructor(seedHi, seedLo, incHi, incLo) {\n    if (isNullable(seedLo) && isNullable(seedHi)) {\n      seedLo = Math.random() * 0xffffffff >>> 0;\n      seedHi = 0;\n    } else if (isNullable(seedLo)) {\n      seedLo = seedHi;\n      seedHi = 0;\n    }\n    if (isNullable(incLo) && isNullable(incHi)) {\n      incLo = this._state ? this._state[3] : defaultIncLo;\n      incHi = this._state ? this._state[2] : defaultIncHi;\n    } else if (isNullable(incLo)) {\n      incLo = incHi;\n      incHi = 0;\n    }\n    this._state = new Int32Array([0, 0, incHi >>> 0, ((incLo || 0) | 1) >>> 0]);\n    this._next();\n    add64(this._state, this._state[0], this._state[1], seedHi >>> 0, seedLo >>> 0);\n    this._next();\n    return this;\n  }\n  /**\n   * Returns a copy of the internal state of this random number generator as a\n   * JavaScript Array.\n   *\n   * @category getters\n   * @since 2.0.0\n   */\n  getState() {\n    return [this._state[0], this._state[1], this._state[2], this._state[3]];\n  }\n  /**\n   * Restore state previously retrieved using `getState()`.\n   *\n   * @since 2.0.0\n   */\n  setState(state) {\n    this._state[0] = state[0];\n    this._state[1] = state[1];\n    this._state[2] = state[2];\n    this._state[3] = state[3] | 1;\n  }\n  /**\n   * Get a uniformly distributed 32 bit integer between [0, max).\n   *\n   * @category getter\n   * @since 2.0.0\n   */\n  integer(max) {\n    if (!max) {\n      return this._next();\n    }\n    max = max >>> 0;\n    if ((max & max - 1) === 0) {\n      return this._next() & max - 1; // fast path for power of 2\n    }\n    let num = 0;\n    const skew = (-max >>> 0) % max >>> 0;\n    for (num = this._next(); num < skew; num = this._next()) {\n      // this loop will rarely execute more than twice,\n      // and is intentionally empty\n    }\n    return num % max;\n  }\n  /**\n   * Get a uniformly distributed IEEE-754 double between 0.0 and 1.0, with\n   * 53 bits of precision (every bit of the mantissa is randomized).\n   *\n   * @category getters\n   * @since 2.0.0\n   */\n  number() {\n    const hi = (this._next() & 0x03ffffff) * 1.0;\n    const lo = (this._next() & 0x07ffffff) * 1.0;\n    return (hi * BIT_27 + lo) / BIT_53;\n  }\n  /** @internal */\n  _next() {\n    // save current state (what we'll use for this number)\n    const oldHi = this._state[0] >>> 0;\n    const oldLo = this._state[1] >>> 0;\n    // churn LCG.\n    mul64(this._state, oldHi, oldLo, MUL_HI, MUL_LO);\n    add64(this._state, this._state[0], this._state[1], this._state[2], this._state[3]);\n    // get least sig. 32 bits of ((oldstate >> 18) ^ oldstate) >> 27\n    let xsHi = oldHi >>> 18;\n    let xsLo = (oldLo >>> 18 | oldHi << 14) >>> 0;\n    xsHi = (xsHi ^ oldHi) >>> 0;\n    xsLo = (xsLo ^ oldLo) >>> 0;\n    const xorshifted = (xsLo >>> 27 | xsHi << 5) >>> 0;\n    // rotate xorshifted right a random amount, based on the most sig. 5 bits\n    // bits of the old state.\n    const rot = oldHi >>> 27;\n    const rot2 = (-rot >>> 0 & 31) >>> 0;\n    return (xorshifted >>> rot | xorshifted << rot2) >>> 0;\n  }\n}\nfunction mul64(out, aHi, aLo, bHi, bLo) {\n  let c1 = (aLo >>> 16) * (bLo & 0xffff) >>> 0;\n  let c0 = (aLo & 0xffff) * (bLo >>> 16) >>> 0;\n  let lo = (aLo & 0xffff) * (bLo & 0xffff) >>> 0;\n  let hi = (aLo >>> 16) * (bLo >>> 16) + ((c0 >>> 16) + (c1 >>> 16)) >>> 0;\n  c0 = c0 << 16 >>> 0;\n  lo = lo + c0 >>> 0;\n  if (lo >>> 0 < c0 >>> 0) {\n    hi = hi + 1 >>> 0;\n  }\n  c1 = c1 << 16 >>> 0;\n  lo = lo + c1 >>> 0;\n  if (lo >>> 0 < c1 >>> 0) {\n    hi = hi + 1 >>> 0;\n  }\n  hi = hi + Math.imul(aLo, bHi) >>> 0;\n  hi = hi + Math.imul(aHi, bLo) >>> 0;\n  out[0] = hi;\n  out[1] = lo;\n}\n// add two 64 bit numbers (given in parts), and store the result in `out`.\nfunction add64(out, aHi, aLo, bHi, bLo) {\n  let hi = aHi + bHi >>> 0;\n  const lo = aLo + bLo >>> 0;\n  if (lo >>> 0 < aLo >>> 0) {\n    hi = hi + 1 | 0;\n  }\n  out[0] = hi;\n  out[1] = lo;\n}\n/**\n * @since 3.0.6\n */\nexport const YieldWrapTypeId = /*#__PURE__*/Symbol.for(\"effect/Utils/YieldWrap\");\n/**\n * @since 3.0.6\n */\nexport class YieldWrap {\n  /**\n   * @since 3.0.6\n   */\n  #value;\n  constructor(value) {\n    this.#value = value;\n  }\n  /**\n   * @since 3.0.6\n   */\n  [YieldWrapTypeId]() {\n    return this.#value;\n  }\n}\n/**\n * @since 3.0.6\n */\nexport function yieldWrapGet(self) {\n  if (typeof self === \"object\" && self !== null && YieldWrapTypeId in self) {\n    return self[YieldWrapTypeId]();\n  }\n  throw new Error(getBugErrorMessage(\"yieldWrapGet\"));\n}\n/**\n * Note: this is an experimental feature made available to allow custom matchers in tests, not to be directly used yet in user code\n *\n * @since 3.1.1\n * @status experimental\n * @category modifiers\n */\nexport const structuralRegionState = /*#__PURE__*/globalValue(\"effect/Utils/isStructuralRegion\", () => ({\n  enabled: false,\n  tester: undefined\n}));\n/**\n * Note: this is an experimental feature made available to allow custom matchers in tests, not to be directly used yet in user code\n *\n * @since 3.1.1\n * @status experimental\n * @category modifiers\n */\nexport const structuralRegion = (body, tester) => {\n  const current = structuralRegionState.enabled;\n  const currentTester = structuralRegionState.tester;\n  structuralRegionState.enabled = true;\n  if (tester) {\n    structuralRegionState.tester = tester;\n  }\n  try {\n    return body();\n  } finally {\n    structuralRegionState.enabled = current;\n    structuralRegionState.tester = currentTester;\n  }\n};\nconst tracingFunction = name => {\n  const wrap = {\n    [name](body) {\n      return body();\n    }\n  };\n  return function (fn) {\n    return wrap[name](fn);\n  };\n};\n/**\n * @since 3.2.2\n * @status experimental\n * @category tracing\n */\nexport const internalCall = /*#__PURE__*/tracingFunction(\"effect_internal_function\");\n//# sourceMappingURL=Utils.js.map","/**\n * @since 2.0.0\n */\n/** @internal */\nexport const isNonEmptyArray = self => self.length > 0;\n//# sourceMappingURL=array.js.map","import * as Chunk from \"../Chunk.js\";\nimport * as Either from \"../Either.js\";\nimport * as Equal from \"../Equal.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport * as List from \"../List.js\";\nimport * as Option from \"../Option.js\";\nimport { hasProperty } from \"../Predicate.js\";\n/** @internal */\nexport const empty = {\n  _tag: \"Empty\"\n};\n/**\n * Combines this collection of blocked requests with the specified collection\n * of blocked requests, in parallel.\n *\n * @internal\n */\nexport const par = (self, that) => ({\n  _tag: \"Par\",\n  left: self,\n  right: that\n});\n/**\n * Combines this collection of blocked requests with the specified collection\n * of blocked requests, in sequence.\n *\n * @internal\n */\nexport const seq = (self, that) => ({\n  _tag: \"Seq\",\n  left: self,\n  right: that\n});\n/**\n * Constructs a collection of blocked requests from the specified blocked\n * request and data source.\n *\n * @internal\n */\nexport const single = (dataSource, blockedRequest) => ({\n  _tag: \"Single\",\n  dataSource: dataSource,\n  blockedRequest\n});\n/** @internal */\nexport const MapRequestResolversReducer = f => ({\n  emptyCase: () => empty,\n  parCase: (left, right) => par(left, right),\n  seqCase: (left, right) => seq(left, right),\n  singleCase: (dataSource, blockedRequest) => single(f(dataSource), blockedRequest)\n});\n/**\n * Transforms all data sources with the specified data source aspect, which\n * can change the environment type of data sources but must preserve the\n * request type of each data source.\n *\n * @internal\n */\nexport const mapRequestResolvers = (self, f) => reduce(self, MapRequestResolversReducer(f));\n/**\n * Folds over the cases of this collection of blocked requests with the\n * specified functions.\n *\n * @internal\n */\nexport const reduce = (self, reducer) => {\n  let input = List.of(self);\n  let output = List.empty();\n  while (List.isCons(input)) {\n    const current = input.head;\n    switch (current._tag) {\n      case \"Empty\":\n        {\n          output = List.cons(Either.right(reducer.emptyCase()), output);\n          input = input.tail;\n          break;\n        }\n      case \"Par\":\n        {\n          output = List.cons(Either.left({\n            _tag: \"ParCase\"\n          }), output);\n          input = List.cons(current.left, List.cons(current.right, input.tail));\n          break;\n        }\n      case \"Seq\":\n        {\n          output = List.cons(Either.left({\n            _tag: \"SeqCase\"\n          }), output);\n          input = List.cons(current.left, List.cons(current.right, input.tail));\n          break;\n        }\n      case \"Single\":\n        {\n          const result = reducer.singleCase(current.dataSource, current.blockedRequest);\n          output = List.cons(Either.right(result), output);\n          input = input.tail;\n          break;\n        }\n    }\n  }\n  const result = List.reduce(output, List.empty(), (acc, current) => {\n    switch (current._tag) {\n      case \"Left\":\n        {\n          const left = List.unsafeHead(acc);\n          const right = List.unsafeHead(List.unsafeTail(acc));\n          const tail = List.unsafeTail(List.unsafeTail(acc));\n          switch (current.left._tag) {\n            case \"ParCase\":\n              {\n                return List.cons(reducer.parCase(left, right), tail);\n              }\n            case \"SeqCase\":\n              {\n                return List.cons(reducer.seqCase(left, right), tail);\n              }\n          }\n        }\n      case \"Right\":\n        {\n          return List.cons(current.right, acc);\n        }\n    }\n  });\n  if (List.isNil(result)) {\n    throw new Error(\"BUG: BlockedRequests.reduce - please report an issue at https://github.com/Effect-TS/effect/issues\");\n  }\n  return result.head;\n};\n/**\n * Flattens a collection of blocked requests into a collection of pipelined\n * and batched requests that can be submitted for execution.\n *\n * @internal\n */\nexport const flatten = self => {\n  let current = List.of(self);\n  let updated = List.empty();\n  // eslint-disable-next-line no-constant-condition\n  while (1) {\n    const [parallel, sequential] = List.reduce(current, [parallelCollectionEmpty(), List.empty()], ([parallel, sequential], blockedRequest) => {\n      const [par, seq] = step(blockedRequest);\n      return [parallelCollectionCombine(parallel, par), List.appendAll(sequential, seq)];\n    });\n    updated = merge(updated, parallel);\n    if (List.isNil(sequential)) {\n      return List.reverse(updated);\n    }\n    current = sequential;\n  }\n  throw new Error(\"BUG: BlockedRequests.flatten - please report an issue at https://github.com/Effect-TS/effect/issues\");\n};\n/**\n * Takes one step in evaluating a collection of blocked requests, returning a\n * collection of blocked requests that can be performed in parallel and a list\n * of blocked requests that must be performed sequentially after those\n * requests.\n */\nconst step = requests => {\n  let current = requests;\n  let parallel = parallelCollectionEmpty();\n  let stack = List.empty();\n  let sequential = List.empty();\n  // eslint-disable-next-line no-constant-condition\n  while (1) {\n    switch (current._tag) {\n      case \"Empty\":\n        {\n          if (List.isNil(stack)) {\n            return [parallel, sequential];\n          }\n          current = stack.head;\n          stack = stack.tail;\n          break;\n        }\n      case \"Par\":\n        {\n          stack = List.cons(current.right, stack);\n          current = current.left;\n          break;\n        }\n      case \"Seq\":\n        {\n          const left = current.left;\n          const right = current.right;\n          switch (left._tag) {\n            case \"Empty\":\n              {\n                current = right;\n                break;\n              }\n            case \"Par\":\n              {\n                const l = left.left;\n                const r = left.right;\n                current = par(seq(l, right), seq(r, right));\n                break;\n              }\n            case \"Seq\":\n              {\n                const l = left.left;\n                const r = left.right;\n                current = seq(l, seq(r, right));\n                break;\n              }\n            case \"Single\":\n              {\n                current = left;\n                sequential = List.cons(right, sequential);\n                break;\n              }\n          }\n          break;\n        }\n      case \"Single\":\n        {\n          parallel = parallelCollectionAdd(parallel, current);\n          if (List.isNil(stack)) {\n            return [parallel, sequential];\n          }\n          current = stack.head;\n          stack = stack.tail;\n          break;\n        }\n    }\n  }\n  throw new Error(\"BUG: BlockedRequests.step - please report an issue at https://github.com/Effect-TS/effect/issues\");\n};\n/**\n * Merges a collection of requests that must be executed sequentially with a\n * collection of requests that can be executed in parallel. If the collections\n * are both from the same single data source then the requests can be\n * pipelined while preserving ordering guarantees.\n */\nconst merge = (sequential, parallel) => {\n  if (List.isNil(sequential)) {\n    return List.of(parallelCollectionToSequentialCollection(parallel));\n  }\n  if (parallelCollectionIsEmpty(parallel)) {\n    return sequential;\n  }\n  const seqHeadKeys = sequentialCollectionKeys(sequential.head);\n  const parKeys = parallelCollectionKeys(parallel);\n  if (seqHeadKeys.length === 1 && parKeys.length === 1 && Equal.equals(seqHeadKeys[0], parKeys[0])) {\n    return List.cons(sequentialCollectionCombine(sequential.head, parallelCollectionToSequentialCollection(parallel)), sequential.tail);\n  }\n  return List.cons(parallelCollectionToSequentialCollection(parallel), sequential);\n};\n//\n// circular\n//\n/** @internal */\nexport const EntryTypeId = /*#__PURE__*/Symbol.for(\"effect/RequestBlock/Entry\");\n/** @internal */\nclass EntryImpl {\n  request;\n  result;\n  listeners;\n  ownerId;\n  state;\n  [EntryTypeId] = blockedRequestVariance;\n  constructor(request, result, listeners, ownerId, state) {\n    this.request = request;\n    this.result = result;\n    this.listeners = listeners;\n    this.ownerId = ownerId;\n    this.state = state;\n  }\n}\nconst blockedRequestVariance = {\n  /* c8 ignore next */\n  _R: _ => _\n};\n/** @internal */\nexport const isEntry = u => hasProperty(u, EntryTypeId);\n/** @internal */\nexport const makeEntry = options => new EntryImpl(options.request, options.result, options.listeners, options.ownerId, options.state);\n/** @internal */\nexport const RequestBlockParallelTypeId = /*#__PURE__*/Symbol.for(\"effect/RequestBlock/RequestBlockParallel\");\nconst parallelVariance = {\n  /* c8 ignore next */\n  _R: _ => _\n};\nclass ParallelImpl {\n  map;\n  [RequestBlockParallelTypeId] = parallelVariance;\n  constructor(map) {\n    this.map = map;\n  }\n}\n/** @internal */\nexport const parallelCollectionEmpty = () => new ParallelImpl(HashMap.empty());\n/** @internal */\nexport const parallelCollectionMake = (dataSource, blockedRequest) => new ParallelImpl(HashMap.make([dataSource, Chunk.of(blockedRequest)]));\n/** @internal */\nexport const parallelCollectionAdd = (self, blockedRequest) => new ParallelImpl(HashMap.modifyAt(self.map, blockedRequest.dataSource, _ => Option.orElseSome(Option.map(_, Chunk.append(blockedRequest.blockedRequest)), () => Chunk.of(blockedRequest.blockedRequest))));\n/** @internal */\nexport const parallelCollectionCombine = (self, that) => new ParallelImpl(HashMap.reduce(self.map, that.map, (map, value, key) => HashMap.set(map, key, Option.match(HashMap.get(map, key), {\n  onNone: () => value,\n  onSome: other => Chunk.appendAll(value, other)\n}))));\n/** @internal */\nexport const parallelCollectionIsEmpty = self => HashMap.isEmpty(self.map);\n/** @internal */\nexport const parallelCollectionKeys = self => Array.from(HashMap.keys(self.map));\n/** @internal */\nexport const parallelCollectionToSequentialCollection = self => sequentialCollectionMake(HashMap.map(self.map, x => Chunk.of(x)));\n// TODO\n// /** @internal */\n// export const parallelCollectionToChunk = <R>(\n//   self: ParallelCollection<R>\n// ): Array<[RequestResolver.RequestResolver<unknown, R>, Array<Request.Entry<unknown>>]> => Array.from(self.map) as any\n/** @internal */\nexport const SequentialCollectionTypeId = /*#__PURE__*/Symbol.for(\"effect/RequestBlock/RequestBlockSequential\");\nconst sequentialVariance = {\n  /* c8 ignore next */\n  _R: _ => _\n};\nclass SequentialImpl {\n  map;\n  [SequentialCollectionTypeId] = sequentialVariance;\n  constructor(map) {\n    this.map = map;\n  }\n}\n/** @internal */\nexport const sequentialCollectionMake = map => new SequentialImpl(map);\n/** @internal */\nexport const sequentialCollectionCombine = (self, that) => new SequentialImpl(HashMap.reduce(that.map, self.map, (map, value, key) => HashMap.set(map, key, Option.match(HashMap.get(map, key), {\n  onNone: () => Chunk.empty(),\n  onSome: a => Chunk.appendAll(a, value)\n}))));\n/** @internal */\nexport const sequentialCollectionIsEmpty = self => HashMap.isEmpty(self.map);\n/** @internal */\nexport const sequentialCollectionKeys = self => Array.from(HashMap.keys(self.map));\n/** @internal */\nexport const sequentialCollectionToChunk = self => Array.from(self.map);\n//# sourceMappingURL=blockedRequests.js.map","import * as Context from \"../Context.js\";\nimport * as Deferred from \"../Deferred.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as Either from \"../Either.js\";\nimport * as Equal from \"../Equal.js\";\nimport * as Exit from \"../Exit.js\";\nimport { pipe } from \"../Function.js\";\nimport * as Hash from \"../Hash.js\";\nimport * as MutableHashMap from \"../MutableHashMap.js\";\nimport * as MutableQueue from \"../MutableQueue.js\";\nimport * as MutableRef from \"../MutableRef.js\";\nimport * as Option from \"../Option.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as effect from \"./core-effect.js\";\nimport * as core from \"./core.js\";\nimport * as Data from \"./data.js\";\nimport { none } from \"./fiberId.js\";\nimport * as fiberRuntime from \"./fiberRuntime.js\";\n/** @internal */\nexport const complete = (key, exit, entryStats, timeToLiveMillis) => Data.struct({\n  _tag: \"Complete\",\n  key,\n  exit,\n  entryStats,\n  timeToLiveMillis\n});\n/** @internal */\nexport const pending = (key, deferred) => Data.struct({\n  _tag: \"Pending\",\n  key,\n  deferred\n});\n/** @internal */\nexport const refreshing = (deferred, complete) => Data.struct({\n  _tag: \"Refreshing\",\n  deferred,\n  complete\n});\n/** @internal */\nexport const MapKeyTypeId = /*#__PURE__*/Symbol.for(\"effect/Cache/MapKey\");\nclass MapKeyImpl {\n  current;\n  [MapKeyTypeId] = MapKeyTypeId;\n  previous = undefined;\n  next = undefined;\n  constructor(current) {\n    this.current = current;\n  }\n  [Hash.symbol]() {\n    return pipe(Hash.hash(this.current), Hash.combine(Hash.hash(this.previous)), Hash.combine(Hash.hash(this.next)), Hash.cached(this));\n  }\n  [Equal.symbol](that) {\n    if (this === that) {\n      return true;\n    }\n    return isMapKey(that) && Equal.equals(this.current, that.current) && Equal.equals(this.previous, that.previous) && Equal.equals(this.next, that.next);\n  }\n}\n/** @internal */\nexport const makeMapKey = current => new MapKeyImpl(current);\n/** @internal */\nexport const isMapKey = u => hasProperty(u, MapKeyTypeId);\nclass KeySetImpl {\n  head = undefined;\n  tail = undefined;\n  add(key) {\n    if (key !== this.tail) {\n      if (this.tail === undefined) {\n        this.head = key;\n        this.tail = key;\n      } else {\n        const previous = key.previous;\n        const next = key.next;\n        if (next !== undefined) {\n          key.next = undefined;\n          if (previous !== undefined) {\n            previous.next = next;\n            next.previous = previous;\n          } else {\n            this.head = next;\n            this.head.previous = undefined;\n          }\n        }\n        this.tail.next = key;\n        key.previous = this.tail;\n        this.tail = key;\n      }\n    }\n  }\n  remove() {\n    const key = this.head;\n    if (key !== undefined) {\n      const next = key.next;\n      if (next !== undefined) {\n        key.next = undefined;\n        this.head = next;\n        this.head.previous = undefined;\n      } else {\n        this.head = undefined;\n        this.tail = undefined;\n      }\n    }\n    return key;\n  }\n}\n/** @internal */\nexport const makeKeySet = () => new KeySetImpl();\n/**\n * Constructs a new `CacheState` from the specified values.\n *\n * @internal\n */\nexport const makeCacheState = (map, keys, accesses, updating, hits, misses) => ({\n  map,\n  keys,\n  accesses,\n  updating,\n  hits,\n  misses\n});\n/**\n * Constructs an initial cache state.\n *\n * @internal\n */\nexport const initialCacheState = () => makeCacheState(MutableHashMap.empty(), makeKeySet(), MutableQueue.unbounded(), MutableRef.make(false), 0, 0);\n/** @internal */\nconst CacheSymbolKey = \"effect/Cache\";\n/** @internal */\nexport const CacheTypeId = /*#__PURE__*/Symbol.for(CacheSymbolKey);\nconst cacheVariance = {\n  /* c8 ignore next */\n  _Key: _ => _,\n  /* c8 ignore next */\n  _Error: _ => _,\n  /* c8 ignore next */\n  _Value: _ => _\n};\n/** @internal */\nexport const makeCacheStats = options => options;\n/** @internal */\nexport const makeEntryStats = loadedMillis => ({\n  loadedMillis\n});\nclass CacheImpl {\n  capacity;\n  context;\n  fiberId;\n  lookup;\n  timeToLive;\n  [CacheTypeId] = cacheVariance;\n  cacheState;\n  constructor(capacity, context, fiberId, lookup, timeToLive) {\n    this.capacity = capacity;\n    this.context = context;\n    this.fiberId = fiberId;\n    this.lookup = lookup;\n    this.timeToLive = timeToLive;\n    this.cacheState = initialCacheState();\n  }\n  get(key) {\n    return core.map(this.getEither(key), Either.merge);\n  }\n  get cacheStats() {\n    return core.sync(() => makeCacheStats({\n      hits: this.cacheState.hits,\n      misses: this.cacheState.misses,\n      size: MutableHashMap.size(this.cacheState.map)\n    }));\n  }\n  getOption(key) {\n    return core.suspend(() => Option.match(MutableHashMap.get(this.cacheState.map, key), {\n      onNone: () => {\n        const mapKey = makeMapKey(key);\n        this.trackAccess(mapKey);\n        this.trackMiss();\n        return core.succeed(Option.none());\n      },\n      onSome: value => this.resolveMapValue(value)\n    }));\n  }\n  getOptionComplete(key) {\n    return core.suspend(() => Option.match(MutableHashMap.get(this.cacheState.map, key), {\n      onNone: () => {\n        const mapKey = makeMapKey(key);\n        this.trackAccess(mapKey);\n        this.trackMiss();\n        return core.succeed(Option.none());\n      },\n      onSome: value => this.resolveMapValue(value, true)\n    }));\n  }\n  contains(key) {\n    return core.sync(() => MutableHashMap.has(this.cacheState.map, key));\n  }\n  entryStats(key) {\n    return core.sync(() => {\n      const option = MutableHashMap.get(this.cacheState.map, key);\n      if (Option.isSome(option)) {\n        switch (option.value._tag) {\n          case \"Complete\":\n            {\n              const loaded = option.value.entryStats.loadedMillis;\n              return Option.some(makeEntryStats(loaded));\n            }\n          case \"Pending\":\n            {\n              return Option.none();\n            }\n          case \"Refreshing\":\n            {\n              const loaded = option.value.complete.entryStats.loadedMillis;\n              return Option.some(makeEntryStats(loaded));\n            }\n        }\n      }\n      return Option.none();\n    });\n  }\n  getEither(key) {\n    return core.suspend(() => {\n      const k = key;\n      let mapKey = undefined;\n      let deferred = undefined;\n      let value = Option.getOrUndefined(MutableHashMap.get(this.cacheState.map, k));\n      if (value === undefined) {\n        deferred = Deferred.unsafeMake(this.fiberId);\n        mapKey = makeMapKey(k);\n        if (MutableHashMap.has(this.cacheState.map, k)) {\n          value = Option.getOrUndefined(MutableHashMap.get(this.cacheState.map, k));\n        } else {\n          MutableHashMap.set(this.cacheState.map, k, pending(mapKey, deferred));\n        }\n      }\n      if (value === undefined) {\n        this.trackAccess(mapKey);\n        this.trackMiss();\n        return core.map(this.lookupValueOf(key, deferred), Either.right);\n      } else {\n        return core.flatMap(this.resolveMapValue(value), Option.match({\n          onNone: () => this.getEither(key),\n          onSome: value => core.succeed(Either.left(value))\n        }));\n      }\n    });\n  }\n  invalidate(key) {\n    return core.sync(() => {\n      MutableHashMap.remove(this.cacheState.map, key);\n    });\n  }\n  invalidateWhen(key, when) {\n    return core.sync(() => {\n      const value = MutableHashMap.get(this.cacheState.map, key);\n      if (Option.isSome(value) && value.value._tag === \"Complete\") {\n        if (value.value.exit._tag === \"Success\") {\n          if (when(value.value.exit.value)) {\n            MutableHashMap.remove(this.cacheState.map, key);\n          }\n        }\n      }\n    });\n  }\n  get invalidateAll() {\n    return core.sync(() => {\n      this.cacheState.map = MutableHashMap.empty();\n    });\n  }\n  refresh(key) {\n    return effect.clockWith(clock => core.suspend(() => {\n      const k = key;\n      const deferred = Deferred.unsafeMake(this.fiberId);\n      let value = Option.getOrUndefined(MutableHashMap.get(this.cacheState.map, k));\n      if (value === undefined) {\n        if (MutableHashMap.has(this.cacheState.map, k)) {\n          value = Option.getOrUndefined(MutableHashMap.get(this.cacheState.map, k));\n        } else {\n          MutableHashMap.set(this.cacheState.map, k, pending(makeMapKey(k), deferred));\n        }\n      }\n      if (value === undefined) {\n        return core.asVoid(this.lookupValueOf(key, deferred));\n      } else {\n        switch (value._tag) {\n          case \"Complete\":\n            {\n              if (this.hasExpired(clock, value.timeToLiveMillis)) {\n                const found = Option.getOrUndefined(MutableHashMap.get(this.cacheState.map, k));\n                if (Equal.equals(found, value)) {\n                  MutableHashMap.remove(this.cacheState.map, k);\n                }\n                return core.asVoid(this.get(key));\n              }\n              // Only trigger the lookup if we're still the current value, `completedResult`\n              return pipe(this.lookupValueOf(key, deferred), effect.when(() => {\n                const current = Option.getOrUndefined(MutableHashMap.get(this.cacheState.map, k));\n                if (Equal.equals(current, value)) {\n                  const mapValue = refreshing(deferred, value);\n                  MutableHashMap.set(this.cacheState.map, k, mapValue);\n                  return true;\n                }\n                return false;\n              }), core.asVoid);\n            }\n          case \"Pending\":\n            {\n              return Deferred.await(value.deferred);\n            }\n          case \"Refreshing\":\n            {\n              return Deferred.await(value.deferred);\n            }\n        }\n      }\n    }));\n  }\n  set(key, value) {\n    return effect.clockWith(clock => core.sync(() => {\n      const now = clock.unsafeCurrentTimeMillis();\n      const k = key;\n      const lookupResult = Exit.succeed(value);\n      const mapValue = complete(makeMapKey(k), lookupResult, makeEntryStats(now), now + Duration.toMillis(Duration.decode(this.timeToLive(lookupResult))));\n      MutableHashMap.set(this.cacheState.map, k, mapValue);\n    }));\n  }\n  get size() {\n    return core.sync(() => {\n      return MutableHashMap.size(this.cacheState.map);\n    });\n  }\n  get values() {\n    return core.sync(() => {\n      const values = [];\n      for (const entry of this.cacheState.map) {\n        if (entry[1]._tag === \"Complete\" && entry[1].exit._tag === \"Success\") {\n          values.push(entry[1].exit.value);\n        }\n      }\n      return values;\n    });\n  }\n  get entries() {\n    return core.sync(() => {\n      const values = [];\n      for (const entry of this.cacheState.map) {\n        if (entry[1]._tag === \"Complete\" && entry[1].exit._tag === \"Success\") {\n          values.push([entry[0], entry[1].exit.value]);\n        }\n      }\n      return values;\n    });\n  }\n  get keys() {\n    return core.sync(() => {\n      const keys = [];\n      for (const entry of this.cacheState.map) {\n        if (entry[1]._tag === \"Complete\" && entry[1].exit._tag === \"Success\") {\n          keys.push(entry[0]);\n        }\n      }\n      return keys;\n    });\n  }\n  resolveMapValue(value, ignorePending = false) {\n    return effect.clockWith(clock => {\n      switch (value._tag) {\n        case \"Complete\":\n          {\n            this.trackAccess(value.key);\n            if (this.hasExpired(clock, value.timeToLiveMillis)) {\n              MutableHashMap.remove(this.cacheState.map, value.key.current);\n              return core.succeed(Option.none());\n            }\n            this.trackHit();\n            return core.map(value.exit, Option.some);\n          }\n        case \"Pending\":\n          {\n            this.trackAccess(value.key);\n            this.trackHit();\n            if (ignorePending) {\n              return core.succeed(Option.none());\n            }\n            return core.map(Deferred.await(value.deferred), Option.some);\n          }\n        case \"Refreshing\":\n          {\n            this.trackAccess(value.complete.key);\n            this.trackHit();\n            if (this.hasExpired(clock, value.complete.timeToLiveMillis)) {\n              if (ignorePending) {\n                return core.succeed(Option.none());\n              }\n              return core.map(Deferred.await(value.deferred), Option.some);\n            }\n            return core.map(value.complete.exit, Option.some);\n          }\n      }\n    });\n  }\n  trackHit() {\n    this.cacheState.hits = this.cacheState.hits + 1;\n  }\n  trackMiss() {\n    this.cacheState.misses = this.cacheState.misses + 1;\n  }\n  trackAccess(key) {\n    MutableQueue.offer(this.cacheState.accesses, key);\n    if (MutableRef.compareAndSet(this.cacheState.updating, false, true)) {\n      let loop = true;\n      while (loop) {\n        const key = MutableQueue.poll(this.cacheState.accesses, MutableQueue.EmptyMutableQueue);\n        if (key === MutableQueue.EmptyMutableQueue) {\n          loop = false;\n        } else {\n          this.cacheState.keys.add(key);\n        }\n      }\n      let size = MutableHashMap.size(this.cacheState.map);\n      loop = size > this.capacity;\n      while (loop) {\n        const key = this.cacheState.keys.remove();\n        if (key !== undefined) {\n          if (MutableHashMap.has(this.cacheState.map, key.current)) {\n            MutableHashMap.remove(this.cacheState.map, key.current);\n            size = size - 1;\n            loop = size > this.capacity;\n          }\n        } else {\n          loop = false;\n        }\n      }\n      MutableRef.set(this.cacheState.updating, false);\n    }\n  }\n  hasExpired(clock, timeToLiveMillis) {\n    return clock.unsafeCurrentTimeMillis() > timeToLiveMillis;\n  }\n  lookupValueOf(input, deferred) {\n    return effect.clockWith(clock => core.suspend(() => {\n      const key = input;\n      return pipe(this.lookup(input), core.provideContext(this.context), core.exit, core.flatMap(exit => {\n        const now = clock.unsafeCurrentTimeMillis();\n        const stats = makeEntryStats(now);\n        const value = complete(makeMapKey(key), exit, stats, now + Duration.toMillis(Duration.decode(this.timeToLive(exit))));\n        MutableHashMap.set(this.cacheState.map, key, value);\n        return core.zipRight(Deferred.done(deferred, exit), exit);\n      }), core.onInterrupt(() => core.zipRight(Deferred.interrupt(deferred), core.sync(() => {\n        MutableHashMap.remove(this.cacheState.map, key);\n      }))));\n    }));\n  }\n}\n/** @internal */\nexport const make = options => {\n  const timeToLive = Duration.decode(options.timeToLive);\n  return makeWith({\n    capacity: options.capacity,\n    lookup: options.lookup,\n    timeToLive: () => timeToLive\n  });\n};\n/** @internal */\nexport const makeWith = options => core.map(fiberRuntime.all([core.context(), core.fiberId]), ([context, fiberId]) => new CacheImpl(options.capacity, context, fiberId, options.lookup, exit => Duration.decode(options.timeToLive(exit))));\n/** @internal */\nexport const unsafeMakeWith = (capacity, lookup, timeToLive) => new CacheImpl(capacity, Context.empty(), none, lookup, exit => Duration.decode(timeToLive(exit)));\n//# sourceMappingURL=cache.js.map","import * as Arr from \"../Array.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Either from \"../Either.js\";\nimport * as Equal from \"../Equal.js\";\nimport { constFalse, constTrue, dual, identity, pipe } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as Hash from \"../Hash.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport { NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty, isFunction } from \"../Predicate.js\";\nimport { getBugErrorMessage } from \"./errors.js\";\nimport * as OpCodes from \"./opCodes/cause.js\";\n// -----------------------------------------------------------------------------\n// Models\n// -----------------------------------------------------------------------------\n/** @internal */\nconst CauseSymbolKey = \"effect/Cause\";\n/** @internal */\nexport const CauseTypeId = /*#__PURE__*/Symbol.for(CauseSymbolKey);\nconst variance = {\n  /* c8 ignore next */\n  _E: _ => _\n};\n/** @internal */\nconst proto = {\n  [CauseTypeId]: variance,\n  [Hash.symbol]() {\n    return pipe(Hash.hash(CauseSymbolKey), Hash.combine(Hash.hash(flattenCause(this))), Hash.cached(this));\n  },\n  [Equal.symbol](that) {\n    return isCause(that) && causeEquals(this, that);\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  },\n  toJSON() {\n    switch (this._tag) {\n      case \"Empty\":\n        return {\n          _id: \"Cause\",\n          _tag: this._tag\n        };\n      case \"Die\":\n        return {\n          _id: \"Cause\",\n          _tag: this._tag,\n          defect: toJSON(this.defect)\n        };\n      case \"Interrupt\":\n        return {\n          _id: \"Cause\",\n          _tag: this._tag,\n          fiberId: this.fiberId.toJSON()\n        };\n      case \"Fail\":\n        return {\n          _id: \"Cause\",\n          _tag: this._tag,\n          failure: toJSON(this.error)\n        };\n      case \"Sequential\":\n      case \"Parallel\":\n        return {\n          _id: \"Cause\",\n          _tag: this._tag,\n          left: toJSON(this.left),\n          right: toJSON(this.right)\n        };\n    }\n  },\n  toString() {\n    return pretty(this);\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n};\n// -----------------------------------------------------------------------------\n// Constructors\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const empty = /*#__PURE__*/(() => {\n  const o = /*#__PURE__*/Object.create(proto);\n  o._tag = OpCodes.OP_EMPTY;\n  return o;\n})();\n/** @internal */\nexport const fail = error => {\n  const o = Object.create(proto);\n  o._tag = OpCodes.OP_FAIL;\n  o.error = error;\n  return o;\n};\n/** @internal */\nexport const die = defect => {\n  const o = Object.create(proto);\n  o._tag = OpCodes.OP_DIE;\n  o.defect = defect;\n  return o;\n};\n/** @internal */\nexport const interrupt = fiberId => {\n  const o = Object.create(proto);\n  o._tag = OpCodes.OP_INTERRUPT;\n  o.fiberId = fiberId;\n  return o;\n};\n/** @internal */\nexport const parallel = (left, right) => {\n  const o = Object.create(proto);\n  o._tag = OpCodes.OP_PARALLEL;\n  o.left = left;\n  o.right = right;\n  return o;\n};\n/** @internal */\nexport const sequential = (left, right) => {\n  const o = Object.create(proto);\n  o._tag = OpCodes.OP_SEQUENTIAL;\n  o.left = left;\n  o.right = right;\n  return o;\n};\n// -----------------------------------------------------------------------------\n// Refinements\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const isCause = u => hasProperty(u, CauseTypeId);\n/** @internal */\nexport const isEmptyType = self => self._tag === OpCodes.OP_EMPTY;\n/** @internal */\nexport const isFailType = self => self._tag === OpCodes.OP_FAIL;\n/** @internal */\nexport const isDieType = self => self._tag === OpCodes.OP_DIE;\n/** @internal */\nexport const isInterruptType = self => self._tag === OpCodes.OP_INTERRUPT;\n/** @internal */\nexport const isSequentialType = self => self._tag === OpCodes.OP_SEQUENTIAL;\n/** @internal */\nexport const isParallelType = self => self._tag === OpCodes.OP_PARALLEL;\n// -----------------------------------------------------------------------------\n// Getters\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const size = self => reduceWithContext(self, void 0, SizeCauseReducer);\n/** @internal */\nexport const isEmpty = self => {\n  if (self._tag === OpCodes.OP_EMPTY) {\n    return true;\n  }\n  return reduce(self, true, (acc, cause) => {\n    switch (cause._tag) {\n      case OpCodes.OP_EMPTY:\n        {\n          return Option.some(acc);\n        }\n      case OpCodes.OP_DIE:\n      case OpCodes.OP_FAIL:\n      case OpCodes.OP_INTERRUPT:\n        {\n          return Option.some(false);\n        }\n      default:\n        {\n          return Option.none();\n        }\n    }\n  });\n};\n/** @internal */\nexport const isFailure = self => Option.isSome(failureOption(self));\n/** @internal */\nexport const isDie = self => Option.isSome(dieOption(self));\n/** @internal */\nexport const isInterrupted = self => Option.isSome(interruptOption(self));\n/** @internal */\nexport const isInterruptedOnly = self => reduceWithContext(undefined, IsInterruptedOnlyCauseReducer)(self);\n/** @internal */\nexport const failures = self => Chunk.reverse(reduce(self, Chunk.empty(), (list, cause) => cause._tag === OpCodes.OP_FAIL ? Option.some(pipe(list, Chunk.prepend(cause.error))) : Option.none()));\n/** @internal */\nexport const defects = self => Chunk.reverse(reduce(self, Chunk.empty(), (list, cause) => cause._tag === OpCodes.OP_DIE ? Option.some(pipe(list, Chunk.prepend(cause.defect))) : Option.none()));\n/** @internal */\nexport const interruptors = self => reduce(self, HashSet.empty(), (set, cause) => cause._tag === OpCodes.OP_INTERRUPT ? Option.some(pipe(set, HashSet.add(cause.fiberId))) : Option.none());\n/** @internal */\nexport const failureOption = self => find(self, cause => cause._tag === OpCodes.OP_FAIL ? Option.some(cause.error) : Option.none());\n/** @internal */\nexport const failureOrCause = self => {\n  const option = failureOption(self);\n  switch (option._tag) {\n    case \"None\":\n      {\n        // no `E` inside this `Cause`, so it can be safely cast to `never`\n        return Either.right(self);\n      }\n    case \"Some\":\n      {\n        return Either.left(option.value);\n      }\n  }\n};\n/** @internal */\nexport const dieOption = self => find(self, cause => cause._tag === OpCodes.OP_DIE ? Option.some(cause.defect) : Option.none());\n/** @internal */\nexport const flipCauseOption = self => match(self, {\n  onEmpty: Option.some(empty),\n  onFail: failureOption => pipe(failureOption, Option.map(fail)),\n  onDie: defect => Option.some(die(defect)),\n  onInterrupt: fiberId => Option.some(interrupt(fiberId)),\n  onSequential: (left, right) => {\n    if (Option.isSome(left) && Option.isSome(right)) {\n      return Option.some(sequential(left.value, right.value));\n    }\n    if (Option.isNone(left) && Option.isSome(right)) {\n      return Option.some(right.value);\n    }\n    if (Option.isSome(left) && Option.isNone(right)) {\n      return Option.some(left.value);\n    }\n    return Option.none();\n  },\n  onParallel: (left, right) => {\n    if (Option.isSome(left) && Option.isSome(right)) {\n      return Option.some(parallel(left.value, right.value));\n    }\n    if (Option.isNone(left) && Option.isSome(right)) {\n      return Option.some(right.value);\n    }\n    if (Option.isSome(left) && Option.isNone(right)) {\n      return Option.some(left.value);\n    }\n    return Option.none();\n  }\n});\n/** @internal */\nexport const interruptOption = self => find(self, cause => cause._tag === OpCodes.OP_INTERRUPT ? Option.some(cause.fiberId) : Option.none());\n/** @internal */\nexport const keepDefects = self => match(self, {\n  onEmpty: Option.none(),\n  onFail: () => Option.none(),\n  onDie: defect => Option.some(die(defect)),\n  onInterrupt: () => Option.none(),\n  onSequential: (left, right) => {\n    if (Option.isSome(left) && Option.isSome(right)) {\n      return Option.some(sequential(left.value, right.value));\n    }\n    if (Option.isSome(left) && Option.isNone(right)) {\n      return Option.some(left.value);\n    }\n    if (Option.isNone(left) && Option.isSome(right)) {\n      return Option.some(right.value);\n    }\n    return Option.none();\n  },\n  onParallel: (left, right) => {\n    if (Option.isSome(left) && Option.isSome(right)) {\n      return Option.some(parallel(left.value, right.value));\n    }\n    if (Option.isSome(left) && Option.isNone(right)) {\n      return Option.some(left.value);\n    }\n    if (Option.isNone(left) && Option.isSome(right)) {\n      return Option.some(right.value);\n    }\n    return Option.none();\n  }\n});\n/** @internal */\nexport const keepDefectsAndElectFailures = self => match(self, {\n  onEmpty: Option.none(),\n  onFail: failure => Option.some(die(failure)),\n  onDie: defect => Option.some(die(defect)),\n  onInterrupt: () => Option.none(),\n  onSequential: (left, right) => {\n    if (Option.isSome(left) && Option.isSome(right)) {\n      return Option.some(sequential(left.value, right.value));\n    }\n    if (Option.isSome(left) && Option.isNone(right)) {\n      return Option.some(left.value);\n    }\n    if (Option.isNone(left) && Option.isSome(right)) {\n      return Option.some(right.value);\n    }\n    return Option.none();\n  },\n  onParallel: (left, right) => {\n    if (Option.isSome(left) && Option.isSome(right)) {\n      return Option.some(parallel(left.value, right.value));\n    }\n    if (Option.isSome(left) && Option.isNone(right)) {\n      return Option.some(left.value);\n    }\n    if (Option.isNone(left) && Option.isSome(right)) {\n      return Option.some(right.value);\n    }\n    return Option.none();\n  }\n});\n/** @internal */\nexport const linearize = self => match(self, {\n  onEmpty: HashSet.empty(),\n  onFail: error => HashSet.make(fail(error)),\n  onDie: defect => HashSet.make(die(defect)),\n  onInterrupt: fiberId => HashSet.make(interrupt(fiberId)),\n  onSequential: (leftSet, rightSet) => pipe(leftSet, HashSet.flatMap(leftCause => pipe(rightSet, HashSet.map(rightCause => sequential(leftCause, rightCause))))),\n  onParallel: (leftSet, rightSet) => pipe(leftSet, HashSet.flatMap(leftCause => pipe(rightSet, HashSet.map(rightCause => parallel(leftCause, rightCause)))))\n});\n/** @internal */\nexport const stripFailures = self => match(self, {\n  onEmpty: empty,\n  onFail: () => empty,\n  onDie: defect => die(defect),\n  onInterrupt: fiberId => interrupt(fiberId),\n  onSequential: sequential,\n  onParallel: parallel\n});\n/** @internal */\nexport const electFailures = self => match(self, {\n  onEmpty: empty,\n  onFail: failure => die(failure),\n  onDie: defect => die(defect),\n  onInterrupt: fiberId => interrupt(fiberId),\n  onSequential: (left, right) => sequential(left, right),\n  onParallel: (left, right) => parallel(left, right)\n});\n/** @internal */\nexport const stripSomeDefects = /*#__PURE__*/dual(2, (self, pf) => match(self, {\n  onEmpty: Option.some(empty),\n  onFail: error => Option.some(fail(error)),\n  onDie: defect => {\n    const option = pf(defect);\n    return Option.isSome(option) ? Option.none() : Option.some(die(defect));\n  },\n  onInterrupt: fiberId => Option.some(interrupt(fiberId)),\n  onSequential: (left, right) => {\n    if (Option.isSome(left) && Option.isSome(right)) {\n      return Option.some(sequential(left.value, right.value));\n    }\n    if (Option.isSome(left) && Option.isNone(right)) {\n      return Option.some(left.value);\n    }\n    if (Option.isNone(left) && Option.isSome(right)) {\n      return Option.some(right.value);\n    }\n    return Option.none();\n  },\n  onParallel: (left, right) => {\n    if (Option.isSome(left) && Option.isSome(right)) {\n      return Option.some(parallel(left.value, right.value));\n    }\n    if (Option.isSome(left) && Option.isNone(right)) {\n      return Option.some(left.value);\n    }\n    if (Option.isNone(left) && Option.isSome(right)) {\n      return Option.some(right.value);\n    }\n    return Option.none();\n  }\n}));\n// -----------------------------------------------------------------------------\n// Mapping\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const as = /*#__PURE__*/dual(2, (self, error) => map(self, () => error));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => flatMap(self, e => fail(f(e))));\n// -----------------------------------------------------------------------------\n// Sequencing\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => match(self, {\n  onEmpty: empty,\n  onFail: error => f(error),\n  onDie: defect => die(defect),\n  onInterrupt: fiberId => interrupt(fiberId),\n  onSequential: (left, right) => sequential(left, right),\n  onParallel: (left, right) => parallel(left, right)\n}));\n/** @internal */\nexport const flatten = self => flatMap(self, identity);\n/** @internal */\nexport const andThen = /*#__PURE__*/dual(2, (self, f) => isFunction(f) ? flatMap(self, f) : flatMap(self, () => f));\n// -----------------------------------------------------------------------------\n// Equality\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const contains = /*#__PURE__*/dual(2, (self, that) => {\n  if (that._tag === OpCodes.OP_EMPTY || self === that) {\n    return true;\n  }\n  return reduce(self, false, (accumulator, cause) => {\n    return Option.some(accumulator || causeEquals(cause, that));\n  });\n});\n/** @internal */\nconst causeEquals = (left, right) => {\n  let leftStack = Chunk.of(left);\n  let rightStack = Chunk.of(right);\n  while (Chunk.isNonEmpty(leftStack) && Chunk.isNonEmpty(rightStack)) {\n    const [leftParallel, leftSequential] = pipe(Chunk.headNonEmpty(leftStack), reduce([HashSet.empty(), Chunk.empty()], ([parallel, sequential], cause) => {\n      const [par, seq] = evaluateCause(cause);\n      return Option.some([pipe(parallel, HashSet.union(par)), pipe(sequential, Chunk.appendAll(seq))]);\n    }));\n    const [rightParallel, rightSequential] = pipe(Chunk.headNonEmpty(rightStack), reduce([HashSet.empty(), Chunk.empty()], ([parallel, sequential], cause) => {\n      const [par, seq] = evaluateCause(cause);\n      return Option.some([pipe(parallel, HashSet.union(par)), pipe(sequential, Chunk.appendAll(seq))]);\n    }));\n    if (!Equal.equals(leftParallel, rightParallel)) {\n      return false;\n    }\n    leftStack = leftSequential;\n    rightStack = rightSequential;\n  }\n  return true;\n};\n// -----------------------------------------------------------------------------\n// Flattening\n// -----------------------------------------------------------------------------\n/**\n * Flattens a cause to a sequence of sets of causes, where each set represents\n * causes that fail in parallel and sequential sets represent causes that fail\n * after each other.\n *\n * @internal\n */\nconst flattenCause = cause => {\n  return flattenCauseLoop(Chunk.of(cause), Chunk.empty());\n};\n/** @internal */\nconst flattenCauseLoop = (causes, flattened) => {\n  // eslint-disable-next-line no-constant-condition\n  while (1) {\n    const [parallel, sequential] = pipe(causes, Arr.reduce([HashSet.empty(), Chunk.empty()], ([parallel, sequential], cause) => {\n      const [par, seq] = evaluateCause(cause);\n      return [pipe(parallel, HashSet.union(par)), pipe(sequential, Chunk.appendAll(seq))];\n    }));\n    const updated = HashSet.size(parallel) > 0 ? pipe(flattened, Chunk.prepend(parallel)) : flattened;\n    if (Chunk.isEmpty(sequential)) {\n      return Chunk.reverse(updated);\n    }\n    causes = sequential;\n    flattened = updated;\n  }\n  throw new Error(getBugErrorMessage(\"Cause.flattenCauseLoop\"));\n};\n// -----------------------------------------------------------------------------\n// Finding\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const find = /*#__PURE__*/dual(2, (self, pf) => {\n  const stack = [self];\n  while (stack.length > 0) {\n    const item = stack.pop();\n    const option = pf(item);\n    switch (option._tag) {\n      case \"None\":\n        {\n          switch (item._tag) {\n            case OpCodes.OP_SEQUENTIAL:\n            case OpCodes.OP_PARALLEL:\n              {\n                stack.push(item.right);\n                stack.push(item.left);\n                break;\n              }\n          }\n          break;\n        }\n      case \"Some\":\n        {\n          return option;\n        }\n    }\n  }\n  return Option.none();\n});\n// -----------------------------------------------------------------------------\n// Filtering\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => reduceWithContext(self, void 0, FilterCauseReducer(predicate)));\n// -----------------------------------------------------------------------------\n// Evaluation\n// -----------------------------------------------------------------------------\n/**\n * Takes one step in evaluating a cause, returning a set of causes that fail\n * in parallel and a list of causes that fail sequentially after those causes.\n *\n * @internal\n */\nconst evaluateCause = self => {\n  let cause = self;\n  const stack = [];\n  let _parallel = HashSet.empty();\n  let _sequential = Chunk.empty();\n  while (cause !== undefined) {\n    switch (cause._tag) {\n      case OpCodes.OP_EMPTY:\n        {\n          if (stack.length === 0) {\n            return [_parallel, _sequential];\n          }\n          cause = stack.pop();\n          break;\n        }\n      case OpCodes.OP_FAIL:\n        {\n          _parallel = HashSet.add(_parallel, Chunk.make(cause._tag, cause.error));\n          if (stack.length === 0) {\n            return [_parallel, _sequential];\n          }\n          cause = stack.pop();\n          break;\n        }\n      case OpCodes.OP_DIE:\n        {\n          _parallel = HashSet.add(_parallel, Chunk.make(cause._tag, cause.defect));\n          if (stack.length === 0) {\n            return [_parallel, _sequential];\n          }\n          cause = stack.pop();\n          break;\n        }\n      case OpCodes.OP_INTERRUPT:\n        {\n          _parallel = HashSet.add(_parallel, Chunk.make(cause._tag, cause.fiberId));\n          if (stack.length === 0) {\n            return [_parallel, _sequential];\n          }\n          cause = stack.pop();\n          break;\n        }\n      case OpCodes.OP_SEQUENTIAL:\n        {\n          switch (cause.left._tag) {\n            case OpCodes.OP_EMPTY:\n              {\n                cause = cause.right;\n                break;\n              }\n            case OpCodes.OP_SEQUENTIAL:\n              {\n                cause = sequential(cause.left.left, sequential(cause.left.right, cause.right));\n                break;\n              }\n            case OpCodes.OP_PARALLEL:\n              {\n                cause = parallel(sequential(cause.left.left, cause.right), sequential(cause.left.right, cause.right));\n                break;\n              }\n            default:\n              {\n                _sequential = Chunk.prepend(_sequential, cause.right);\n                cause = cause.left;\n                break;\n              }\n          }\n          break;\n        }\n      case OpCodes.OP_PARALLEL:\n        {\n          stack.push(cause.right);\n          cause = cause.left;\n          break;\n        }\n    }\n  }\n  throw new Error(getBugErrorMessage(\"Cause.evaluateCauseLoop\"));\n};\n// -----------------------------------------------------------------------------\n// Reducing\n// -----------------------------------------------------------------------------\n/** @internal */\nconst SizeCauseReducer = {\n  emptyCase: () => 0,\n  failCase: () => 1,\n  dieCase: () => 1,\n  interruptCase: () => 1,\n  sequentialCase: (_, left, right) => left + right,\n  parallelCase: (_, left, right) => left + right\n};\n/** @internal */\nconst IsInterruptedOnlyCauseReducer = {\n  emptyCase: constTrue,\n  failCase: constFalse,\n  dieCase: constFalse,\n  interruptCase: constTrue,\n  sequentialCase: (_, left, right) => left && right,\n  parallelCase: (_, left, right) => left && right\n};\n/** @internal */\nconst FilterCauseReducer = predicate => ({\n  emptyCase: () => empty,\n  failCase: (_, error) => fail(error),\n  dieCase: (_, defect) => die(defect),\n  interruptCase: (_, fiberId) => interrupt(fiberId),\n  sequentialCase: (_, left, right) => {\n    if (predicate(left)) {\n      if (predicate(right)) {\n        return sequential(left, right);\n      }\n      return left;\n    }\n    if (predicate(right)) {\n      return right;\n    }\n    return empty;\n  },\n  parallelCase: (_, left, right) => {\n    if (predicate(left)) {\n      if (predicate(right)) {\n        return parallel(left, right);\n      }\n      return left;\n    }\n    if (predicate(right)) {\n      return right;\n    }\n    return empty;\n  }\n});\nconst OP_SEQUENTIAL_CASE = \"SequentialCase\";\nconst OP_PARALLEL_CASE = \"ParallelCase\";\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onDie,\n  onEmpty,\n  onFail,\n  onInterrupt,\n  onParallel,\n  onSequential\n}) => {\n  return reduceWithContext(self, void 0, {\n    emptyCase: () => onEmpty,\n    failCase: (_, error) => onFail(error),\n    dieCase: (_, defect) => onDie(defect),\n    interruptCase: (_, fiberId) => onInterrupt(fiberId),\n    sequentialCase: (_, left, right) => onSequential(left, right),\n    parallelCase: (_, left, right) => onParallel(left, right)\n  });\n});\n/** @internal */\nexport const reduce = /*#__PURE__*/dual(3, (self, zero, pf) => {\n  let accumulator = zero;\n  let cause = self;\n  const causes = [];\n  while (cause !== undefined) {\n    const option = pf(accumulator, cause);\n    accumulator = Option.isSome(option) ? option.value : accumulator;\n    switch (cause._tag) {\n      case OpCodes.OP_SEQUENTIAL:\n        {\n          causes.push(cause.right);\n          cause = cause.left;\n          break;\n        }\n      case OpCodes.OP_PARALLEL:\n        {\n          causes.push(cause.right);\n          cause = cause.left;\n          break;\n        }\n      default:\n        {\n          cause = undefined;\n          break;\n        }\n    }\n    if (cause === undefined && causes.length > 0) {\n      cause = causes.pop();\n    }\n  }\n  return accumulator;\n});\n/** @internal */\nexport const reduceWithContext = /*#__PURE__*/dual(3, (self, context, reducer) => {\n  const input = [self];\n  const output = [];\n  while (input.length > 0) {\n    const cause = input.pop();\n    switch (cause._tag) {\n      case OpCodes.OP_EMPTY:\n        {\n          output.push(Either.right(reducer.emptyCase(context)));\n          break;\n        }\n      case OpCodes.OP_FAIL:\n        {\n          output.push(Either.right(reducer.failCase(context, cause.error)));\n          break;\n        }\n      case OpCodes.OP_DIE:\n        {\n          output.push(Either.right(reducer.dieCase(context, cause.defect)));\n          break;\n        }\n      case OpCodes.OP_INTERRUPT:\n        {\n          output.push(Either.right(reducer.interruptCase(context, cause.fiberId)));\n          break;\n        }\n      case OpCodes.OP_SEQUENTIAL:\n        {\n          input.push(cause.right);\n          input.push(cause.left);\n          output.push(Either.left({\n            _tag: OP_SEQUENTIAL_CASE\n          }));\n          break;\n        }\n      case OpCodes.OP_PARALLEL:\n        {\n          input.push(cause.right);\n          input.push(cause.left);\n          output.push(Either.left({\n            _tag: OP_PARALLEL_CASE\n          }));\n          break;\n        }\n    }\n  }\n  const accumulator = [];\n  while (output.length > 0) {\n    const either = output.pop();\n    switch (either._tag) {\n      case \"Left\":\n        {\n          switch (either.left._tag) {\n            case OP_SEQUENTIAL_CASE:\n              {\n                const left = accumulator.pop();\n                const right = accumulator.pop();\n                const value = reducer.sequentialCase(context, left, right);\n                accumulator.push(value);\n                break;\n              }\n            case OP_PARALLEL_CASE:\n              {\n                const left = accumulator.pop();\n                const right = accumulator.pop();\n                const value = reducer.parallelCase(context, left, right);\n                accumulator.push(value);\n                break;\n              }\n          }\n          break;\n        }\n      case \"Right\":\n        {\n          accumulator.push(either.right);\n          break;\n        }\n    }\n  }\n  if (accumulator.length === 0) {\n    throw new Error(\"BUG: Cause.reduceWithContext - please report an issue at https://github.com/Effect-TS/effect/issues\");\n  }\n  return accumulator.pop();\n});\n// -----------------------------------------------------------------------------\n// Pretty Printing\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const pretty = (cause, options) => {\n  if (isInterruptedOnly(cause)) {\n    return \"All fibers interrupted without errors.\";\n  }\n  return prettyErrors(cause).map(function (e) {\n    if (options?.renderErrorCause !== true || e.cause === undefined) {\n      return e.stack;\n    }\n    return `${e.stack} {\\n${renderErrorCause(e.cause, \"  \")}\\n}`;\n  }).join(\"\\n\");\n};\nconst renderErrorCause = (cause, prefix) => {\n  const lines = cause.stack.split(\"\\n\");\n  let stack = `${prefix}[cause]: ${lines[0]}`;\n  for (let i = 1, len = lines.length; i < len; i++) {\n    stack += `\\n${prefix}${lines[i]}`;\n  }\n  if (cause.cause) {\n    stack += ` {\\n${renderErrorCause(cause.cause, `${prefix}  `)}\\n${prefix}}`;\n  }\n  return stack;\n};\nclass PrettyError extends globalThis.Error {\n  span = undefined;\n  constructor(originalError) {\n    const originalErrorIsObject = typeof originalError === \"object\" && originalError !== null;\n    const prevLimit = Error.stackTraceLimit;\n    Error.stackTraceLimit = 1;\n    super(prettyErrorMessage(originalError), originalErrorIsObject && \"cause\" in originalError && typeof originalError.cause !== \"undefined\" ? {\n      cause: new PrettyError(originalError.cause)\n    } : undefined);\n    if (this.message === \"\") {\n      this.message = \"An error has occurred\";\n    }\n    Error.stackTraceLimit = prevLimit;\n    this.name = originalError instanceof Error ? originalError.name : \"Error\";\n    if (originalErrorIsObject) {\n      if (spanSymbol in originalError) {\n        this.span = originalError[spanSymbol];\n      }\n      Object.keys(originalError).forEach(key => {\n        if (!(key in this)) {\n          // @ts-expect-error\n          this[key] = originalError[key];\n        }\n      });\n    }\n    this.stack = prettyErrorStack(`${this.name}: ${this.message}`, originalError instanceof Error && originalError.stack ? originalError.stack : \"\", this.span);\n  }\n}\n/**\n * A utility function for generating human-readable error messages from a generic error of type `unknown`.\n *\n * Rules:\n *\n * 1) If the input `u` is already a string, it's considered a message.\n * 2) If `u` is an Error instance with a message defined, it uses the message.\n * 3) If `u` has a user-defined `toString()` method, it uses that method.\n * 4) Otherwise, it uses `JSON.stringify` to produce a string representation and uses it as the error message,\n *   with \"Error\" added as a prefix.\n *\n * @internal\n */\nexport const prettyErrorMessage = u => {\n  // 1)\n  if (typeof u === \"string\") {\n    return u;\n  }\n  // 2)\n  if (typeof u === \"object\" && u !== null && u instanceof Error) {\n    return u.message;\n  }\n  // 3)\n  try {\n    if (hasProperty(u, \"toString\") && isFunction(u[\"toString\"]) && u[\"toString\"] !== Object.prototype.toString && u[\"toString\"] !== globalThis.Array.prototype.toString) {\n      return u[\"toString\"]();\n    }\n  } catch {\n    // something's off, rollback to json\n  }\n  // 4)\n  return JSON.stringify(u);\n};\nconst locationRegex = /\\((.*)\\)/;\n/** @internal */\nexport const spanToTrace = /*#__PURE__*/globalValue(\"effect/Tracer/spanToTrace\", () => new WeakMap());\nconst prettyErrorStack = (message, stack, span) => {\n  const out = [message];\n  const lines = stack.startsWith(message) ? stack.slice(message.length).split(\"\\n\") : stack.split(\"\\n\");\n  for (let i = 1; i < lines.length; i++) {\n    if (lines[i].includes(\"Generator.next\")) {\n      break;\n    }\n    if (lines[i].includes(\"effect_internal_function\")) {\n      out.pop();\n      break;\n    }\n    out.push(lines[i].replace(/at .*effect_instruction_i.*\\((.*)\\)/, \"at $1\").replace(/EffectPrimitive\\.\\w+/, \"<anonymous>\"));\n  }\n  if (span) {\n    let current = span;\n    let i = 0;\n    while (current && current._tag === \"Span\" && i < 10) {\n      const stackFn = spanToTrace.get(current);\n      if (typeof stackFn === \"function\") {\n        const stack = stackFn();\n        if (typeof stack === \"string\") {\n          const locationMatch = stack.match(locationRegex);\n          const location = locationMatch ? locationMatch[1] : stack.replace(/^at /, \"\");\n          out.push(`    at ${current.name} (${location})`);\n        } else {\n          out.push(`    at ${current.name}`);\n        }\n      } else {\n        out.push(`    at ${current.name}`);\n      }\n      current = Option.getOrUndefined(current.parent);\n      i++;\n    }\n  }\n  return out.join(\"\\n\");\n};\nconst spanSymbol = /*#__PURE__*/Symbol.for(\"effect/SpanAnnotation\");\n/** @internal */\nexport const prettyErrors = cause => reduceWithContext(cause, void 0, {\n  emptyCase: () => [],\n  dieCase: (_, unknownError) => {\n    return [new PrettyError(unknownError)];\n  },\n  failCase: (_, error) => {\n    return [new PrettyError(error)];\n  },\n  interruptCase: () => [],\n  parallelCase: (_, l, r) => [...l, ...r],\n  sequentialCase: (_, l, r) => [...l, ...r]\n});\n//# sourceMappingURL=cause.js.map","import * as Cause from \"../Cause.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Context from \"../Context.js\";\nimport * as Deferred from \"../Deferred.js\";\nimport * as Effect from \"../Effect.js\";\nimport * as Either from \"../Either.js\";\nimport * as Equal from \"../Equal.js\";\nimport * as Exit from \"../Exit.js\";\nimport * as Fiber from \"../Fiber.js\";\nimport * as FiberRef from \"../FiberRef.js\";\nimport { constVoid, dual, identity, pipe } from \"../Function.js\";\nimport * as Layer from \"../Layer.js\";\nimport * as Option from \"../Option.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as PubSub from \"../PubSub.js\";\nimport * as Queue from \"../Queue.js\";\nimport * as Ref from \"../Ref.js\";\nimport * as Scope from \"../Scope.js\";\nimport * as executor from \"./channel/channelExecutor.js\";\nimport * as mergeDecision from \"./channel/mergeDecision.js\";\nimport * as mergeState from \"./channel/mergeState.js\";\nimport * as _mergeStrategy from \"./channel/mergeStrategy.js\";\nimport * as singleProducerAsyncInput from \"./channel/singleProducerAsyncInput.js\";\nimport * as coreEffect from \"./core-effect.js\";\nimport * as core from \"./core-stream.js\";\nimport * as MergeDecisionOpCodes from \"./opCodes/channelMergeDecision.js\";\nimport * as MergeStateOpCodes from \"./opCodes/channelMergeState.js\";\nimport * as ChannelStateOpCodes from \"./opCodes/channelState.js\";\nimport * as tracer from \"./tracer.js\";\n/** @internal */\nexport const acquireUseRelease = (acquire, use, release) => core.flatMap(core.fromEffect(Ref.make(() => Effect.void)), ref => pipe(core.fromEffect(Effect.uninterruptible(Effect.tap(acquire, a => Ref.set(ref, exit => release(a, exit))))), core.flatMap(use), core.ensuringWith(exit => Effect.flatMap(Ref.get(ref), f => f(exit)))));\n/** @internal */\nexport const as = /*#__PURE__*/dual(2, (self, value) => map(self, () => value));\n/** @internal */\nexport const asVoid = self => map(self, constVoid);\n/** @internal */\nexport const buffer = options => core.suspend(() => {\n  const doBuffer = (empty, isEmpty, ref) => unwrap(Ref.modify(ref, inElem => isEmpty(inElem) ? [core.readWith({\n    onInput: input => core.flatMap(core.write(input), () => doBuffer(empty, isEmpty, ref)),\n    onFailure: error => core.fail(error),\n    onDone: done => core.succeedNow(done)\n  }), inElem] : [core.flatMap(core.write(inElem), () => doBuffer(empty, isEmpty, ref)), empty]));\n  return doBuffer(options.empty, options.isEmpty, options.ref);\n});\n/** @internal */\nexport const bufferChunk = ref => buffer({\n  empty: Chunk.empty(),\n  isEmpty: Chunk.isEmpty,\n  ref\n});\n/** @internal */\nexport const catchAll = /*#__PURE__*/dual(2, (self, f) => core.catchAllCause(self, cause => Either.match(Cause.failureOrCause(cause), {\n  onLeft: f,\n  onRight: core.failCause\n})));\n/** @internal */\nexport const concatMap = /*#__PURE__*/dual(2, (self, f) => core.concatMapWith(self, f, () => void 0, () => void 0));\n/** @internal */\nexport const collect = /*#__PURE__*/dual(2, (self, pf) => {\n  const collector = core.readWith({\n    onInput: out => Option.match(pf(out), {\n      onNone: () => collector,\n      onSome: out2 => core.flatMap(core.write(out2), () => collector)\n    }),\n    onFailure: core.fail,\n    onDone: core.succeedNow\n  });\n  return core.pipeTo(self, collector);\n});\n/** @internal */\nexport const concatOut = self => core.concatAll(self);\n/** @internal */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => {\n  const reader = core.readWith({\n    onInput: inElem => core.flatMap(core.write(inElem), () => reader),\n    onFailure: core.fail,\n    onDone: done => core.succeedNow(f(done))\n  });\n  return core.pipeTo(reader, self);\n});\n/** @internal */\nexport const mapInputEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const reader = core.readWith({\n    onInput: inElem => core.flatMap(core.write(inElem), () => reader),\n    onFailure: core.fail,\n    onDone: done => core.fromEffect(f(done))\n  });\n  return core.pipeTo(reader, self);\n});\n/** @internal */\nexport const mapInputError = /*#__PURE__*/dual(2, (self, f) => {\n  const reader = core.readWith({\n    onInput: inElem => core.flatMap(core.write(inElem), () => reader),\n    onFailure: error => core.fail(f(error)),\n    onDone: core.succeedNow\n  });\n  return core.pipeTo(reader, self);\n});\n/** @internal */\nexport const mapInputErrorEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const reader = core.readWith({\n    onInput: inElem => core.flatMap(core.write(inElem), () => reader),\n    onFailure: error => core.fromEffect(f(error)),\n    onDone: core.succeedNow\n  });\n  return core.pipeTo(reader, self);\n});\n/** @internal */\nexport const mapInputIn = /*#__PURE__*/dual(2, (self, f) => {\n  const reader = core.readWith({\n    onInput: inElem => core.flatMap(core.write(f(inElem)), () => reader),\n    onFailure: core.fail,\n    onDone: core.succeedNow\n  });\n  return core.pipeTo(reader, self);\n});\n/** @internal */\nexport const mapInputInEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const reader = core.readWith({\n    onInput: inElem => core.flatMap(core.flatMap(core.fromEffect(f(inElem)), core.write), () => reader),\n    onFailure: core.fail,\n    onDone: core.succeedNow\n  });\n  return core.pipeTo(reader, self);\n});\n/** @internal */\nexport const doneCollect = self => core.suspend(() => {\n  const builder = [];\n  return pipe(core.pipeTo(self, doneCollectReader(builder)), core.flatMap(outDone => core.succeed([Chunk.unsafeFromArray(builder), outDone])));\n});\n/** @internal */\nconst doneCollectReader = builder => {\n  return core.readWith({\n    onInput: outElem => core.flatMap(core.sync(() => {\n      builder.push(outElem);\n    }), () => doneCollectReader(builder)),\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n};\n/** @internal */\nexport const drain = self => {\n  const drainer = core.readWithCause({\n    onInput: () => drainer,\n    onFailure: core.failCause,\n    onDone: core.succeed\n  });\n  return core.pipeTo(self, drainer);\n};\n/** @internal */\nexport const emitCollect = self => core.flatMap(doneCollect(self), core.write);\n/** @internal */\nexport const ensuring = /*#__PURE__*/dual(2, (self, finalizer) => core.ensuringWith(self, () => finalizer));\n/** @internal */\nexport const context = () => core.fromEffect(Effect.context());\n/** @internal */\nexport const contextWith = f => map(context(), f);\n/** @internal */\nexport const contextWithChannel = f => core.flatMap(context(), f);\n/** @internal */\nexport const contextWithEffect = f => mapEffect(context(), f);\n/** @internal */\nexport const flatten = self => core.flatMap(self, identity);\n/** @internal */\nexport const foldChannel = /*#__PURE__*/dual(2, (self, options) => core.foldCauseChannel(self, {\n  onFailure: cause => {\n    const either = Cause.failureOrCause(cause);\n    switch (either._tag) {\n      case \"Left\":\n        {\n          return options.onFailure(either.left);\n        }\n      case \"Right\":\n        {\n          return core.failCause(either.right);\n        }\n    }\n  },\n  onSuccess: options.onSuccess\n}));\n/** @internal */\nexport const fromEither = either => core.suspend(() => Either.match(either, {\n  onLeft: core.fail,\n  onRight: core.succeed\n}));\n/** @internal */\nexport const fromInput = input => unwrap(input.takeWith(core.failCause, elem => core.flatMap(core.write(elem), () => fromInput(input)), core.succeed));\n/** @internal */\nexport const fromPubSub = pubsub => unwrapScoped(Effect.map(PubSub.subscribe(pubsub), fromQueue));\n/** @internal */\nexport const fromPubSubScoped = pubsub => Effect.map(PubSub.subscribe(pubsub), fromQueue);\n/** @internal */\nexport const fromOption = option => core.suspend(() => Option.match(option, {\n  onNone: () => core.fail(Option.none()),\n  onSome: core.succeed\n}));\n/** @internal */\nexport const fromQueue = queue => core.suspend(() => fromQueueInternal(queue));\n/** @internal */\nconst fromQueueInternal = queue => pipe(core.fromEffect(Queue.take(queue)), core.flatMap(Either.match({\n  onLeft: Exit.match({\n    onFailure: core.failCause,\n    onSuccess: core.succeedNow\n  }),\n  onRight: elem => core.flatMap(core.write(elem), () => fromQueueInternal(queue))\n})));\n/** @internal */\nexport const identityChannel = () => core.readWith({\n  onInput: input => core.flatMap(core.write(input), () => identityChannel()),\n  onFailure: core.fail,\n  onDone: core.succeedNow\n});\n/** @internal */\nexport const interruptWhen = /*#__PURE__*/dual(2, (self, effect) => mergeWith(self, {\n  other: core.fromEffect(effect),\n  onSelfDone: selfDone => mergeDecision.Done(Effect.suspend(() => selfDone)),\n  onOtherDone: effectDone => mergeDecision.Done(Effect.suspend(() => effectDone))\n}));\n/** @internal */\nexport const interruptWhenDeferred = /*#__PURE__*/dual(2, (self, deferred) => interruptWhen(self, Deferred.await(deferred)));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => core.flatMap(self, a => core.sync(() => f(a))));\n/** @internal */\nexport const mapEffect = /*#__PURE__*/dual(2, (self, f) => core.flatMap(self, z => core.fromEffect(f(z))));\n/** @internal */\nexport const mapError = /*#__PURE__*/dual(2, (self, f) => mapErrorCause(self, Cause.map(f)));\n/** @internal */\nexport const mapErrorCause = /*#__PURE__*/dual(2, (self, f) => core.catchAllCause(self, cause => core.failCause(f(cause))));\n/** @internal */\nexport const mapOut = /*#__PURE__*/dual(2, (self, f) => {\n  const reader = core.readWith({\n    onInput: outElem => core.flatMap(core.write(f(outElem)), () => reader),\n    onFailure: core.fail,\n    onDone: core.succeedNow\n  });\n  return core.pipeTo(self, reader);\n});\n/** @internal */\nexport const mapOutEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const reader = core.readWithCause({\n    onInput: outElem => pipe(core.fromEffect(f(outElem)), core.flatMap(core.write), core.flatMap(() => reader)),\n    onFailure: core.failCause,\n    onDone: core.succeedNow\n  });\n  return core.pipeTo(self, reader);\n});\n/** @internal */\nexport const mapOutEffectPar = /*#__PURE__*/dual(3, (self, f, n) => pipe(Effect.gen(function* ($) {\n  const queue = yield* $(Effect.acquireRelease(Queue.bounded(n), queue => Queue.shutdown(queue)));\n  const errorSignal = yield* $(Deferred.make());\n  const withPermits = n === Number.POSITIVE_INFINITY ? _ => identity : (yield* $(Effect.makeSemaphore(n))).withPermits;\n  const pull = yield* $(toPull(self));\n  yield* $(Effect.matchCauseEffect(pull, {\n    onFailure: cause => Queue.offer(queue, Effect.failCause(cause)),\n    onSuccess: either => Either.match(either, {\n      onLeft: outDone => {\n        const lock = withPermits(n);\n        return Effect.zipRight(Effect.interruptible(lock(Effect.void)), Effect.asVoid(Queue.offer(queue, Effect.succeed(Either.left(outDone)))));\n      },\n      onRight: outElem => Effect.gen(function* ($) {\n        const deferred = yield* $(Deferred.make());\n        const latch = yield* $(Deferred.make());\n        yield* $(Effect.asVoid(Queue.offer(queue, Effect.map(Deferred.await(deferred), Either.right))));\n        yield* $(Deferred.succeed(latch, void 0), Effect.zipRight(pipe(Effect.uninterruptibleMask(restore => pipe(Effect.exit(restore(Deferred.await(errorSignal))), Effect.raceFirst(Effect.exit(restore(f(outElem)))),\n        // TODO: remove\n        Effect.flatMap(exit => Effect.suspend(() => exit)))), Effect.tapErrorCause(cause => Deferred.failCause(errorSignal, cause)), Effect.intoDeferred(deferred))), withPermits(1), Effect.forkScoped);\n        yield* $(Deferred.await(latch));\n      })\n    })\n  }), Effect.forever, Effect.interruptible, Effect.forkScoped);\n  return queue;\n}), Effect.map(queue => {\n  const consumer = unwrap(Effect.matchCause(Effect.flatten(Queue.take(queue)), {\n    onFailure: core.failCause,\n    onSuccess: Either.match({\n      onLeft: core.succeedNow,\n      onRight: outElem => core.flatMap(core.write(outElem), () => consumer)\n    })\n  }));\n  return consumer;\n}), unwrapScoped));\n/** @internal */\nexport const mergeAll = options => {\n  return channels => mergeAllWith(options)(channels, constVoid);\n};\n/** @internal */\nexport const mergeAllUnbounded = channels => mergeAllWith({\n  concurrency: \"unbounded\"\n})(channels, constVoid);\n/** @internal */\nexport const mergeAllUnboundedWith = (channels, f) => mergeAllWith({\n  concurrency: \"unbounded\"\n})(channels, f);\n/** @internal */\nexport const mergeAllWith = ({\n  bufferSize = 16,\n  concurrency,\n  mergeStrategy = _mergeStrategy.BackPressure()\n}) => (channels, f) => pipe(Effect.gen(function* ($) {\n  const concurrencyN = concurrency === \"unbounded\" ? Number.MAX_SAFE_INTEGER : concurrency;\n  const input = yield* $(singleProducerAsyncInput.make());\n  const queueReader = fromInput(input);\n  const queue = yield* $(Effect.acquireRelease(Queue.bounded(bufferSize), queue => Queue.shutdown(queue)));\n  const cancelers = yield* $(Effect.acquireRelease(Queue.unbounded(), queue => Queue.shutdown(queue)));\n  const lastDone = yield* $(Ref.make(Option.none()));\n  const errorSignal = yield* $(Deferred.make());\n  const withPermits = (yield* $(Effect.makeSemaphore(concurrencyN))).withPermits;\n  const pull = yield* $(toPull(channels));\n  const evaluatePull = pull => pipe(Effect.flatMap(pull, Either.match({\n    onLeft: done => Effect.succeed(Option.some(done)),\n    onRight: outElem => Effect.as(Queue.offer(queue, Effect.succeed(Either.right(outElem))), Option.none())\n  })), Effect.repeat({\n    until: _ => Option.isSome(_)\n  }), Effect.flatMap(outDone => Ref.update(lastDone, Option.match({\n    onNone: () => Option.some(outDone.value),\n    onSome: lastDone => Option.some(f(lastDone, outDone.value))\n  }))), Effect.catchAllCause(cause => Cause.isInterrupted(cause) ? Effect.failCause(cause) : pipe(Queue.offer(queue, Effect.failCause(cause)), Effect.zipRight(Deferred.succeed(errorSignal, void 0)), Effect.asVoid)));\n  yield* $(Effect.matchCauseEffect(pull, {\n    onFailure: cause => pipe(Queue.offer(queue, Effect.failCause(cause)), Effect.zipRight(Effect.succeed(false))),\n    onSuccess: Either.match({\n      onLeft: outDone => Effect.raceWith(Effect.interruptible(Deferred.await(errorSignal)), Effect.interruptible(withPermits(concurrencyN)(Effect.void)), {\n        onSelfDone: (_, permitAcquisition) => Effect.as(Fiber.interrupt(permitAcquisition), false),\n        onOtherDone: (_, failureAwait) => Effect.zipRight(Fiber.interrupt(failureAwait), pipe(Ref.get(lastDone), Effect.flatMap(Option.match({\n          onNone: () => Queue.offer(queue, Effect.succeed(Either.left(outDone))),\n          onSome: lastDone => Queue.offer(queue, Effect.succeed(Either.left(f(lastDone, outDone))))\n        })), Effect.as(false)))\n      }),\n      onRight: channel => _mergeStrategy.match(mergeStrategy, {\n        onBackPressure: () => Effect.gen(function* ($) {\n          const latch = yield* $(Deferred.make());\n          const raceEffects = pipe(queueReader, core.pipeTo(channel), toPull, Effect.flatMap(pull => Effect.race(evaluatePull(pull), Effect.interruptible(Deferred.await(errorSignal)))), Effect.scoped);\n          yield* $(Deferred.succeed(latch, void 0), Effect.zipRight(raceEffects), withPermits(1), Effect.forkScoped);\n          yield* $(Deferred.await(latch));\n          const errored = yield* $(Deferred.isDone(errorSignal));\n          return !errored;\n        }),\n        onBufferSliding: () => Effect.gen(function* ($) {\n          const canceler = yield* $(Deferred.make());\n          const latch = yield* $(Deferred.make());\n          const size = yield* $(Queue.size(cancelers));\n          yield* $(Queue.take(cancelers), Effect.flatMap(_ => Deferred.succeed(_, void 0)), Effect.when(() => size >= concurrencyN));\n          yield* $(Queue.offer(cancelers, canceler));\n          const raceEffects = pipe(queueReader, core.pipeTo(channel), toPull, Effect.flatMap(pull => pipe(evaluatePull(pull), Effect.race(Effect.interruptible(Deferred.await(errorSignal))), Effect.race(Effect.interruptible(Deferred.await(canceler))))), Effect.scoped);\n          yield* $(Deferred.succeed(latch, void 0), Effect.zipRight(raceEffects), withPermits(1), Effect.forkScoped);\n          yield* $(Deferred.await(latch));\n          const errored = yield* $(Deferred.isDone(errorSignal));\n          return !errored;\n        })\n      })\n    })\n  }), Effect.repeat({\n    while: _ => _\n  }), Effect.forkScoped);\n  return [queue, input];\n}), Effect.map(([queue, input]) => {\n  const consumer = pipe(Queue.take(queue), Effect.flatten, Effect.matchCause({\n    onFailure: core.failCause,\n    onSuccess: Either.match({\n      onLeft: core.succeedNow,\n      onRight: outElem => core.flatMap(core.write(outElem), () => consumer)\n    })\n  }), unwrap);\n  return core.embedInput(consumer, input);\n}), unwrapScoped);\n/** @internal */\nexport const mergeMap = /*#__PURE__*/dual(3, (self, f, options) => mergeAll(options)(mapOut(self, f)));\n/** @internal */\nexport const mergeOut = /*#__PURE__*/dual(2, (self, n) => mergeAll({\n  concurrency: n\n})(mapOut(self, identity)));\n/** @internal */\nexport const mergeOutWith = /*#__PURE__*/dual(3, (self, n, f) => mergeAllWith({\n  concurrency: n\n})(mapOut(self, identity), f));\n/** @internal */\nexport const mergeWith = /*#__PURE__*/dual(2, (self, options) => unwrapScoped(Effect.flatMap(singleProducerAsyncInput.make(), input => {\n  const queueReader = fromInput(input);\n  return Effect.map(Effect.all([toPull(core.pipeTo(queueReader, self)), toPull(core.pipeTo(queueReader, options.other)), Effect.scope]), ([pullL, pullR, scope]) => {\n    const handleSide = (exit, fiber, pull) => (done, both, single) => {\n      const onDecision = decision => {\n        const op = decision;\n        if (op._tag === MergeDecisionOpCodes.OP_DONE) {\n          return Effect.succeed(core.fromEffect(Effect.zipRight(Fiber.interrupt(fiber), op.effect)));\n        }\n        return Effect.map(Fiber.await(fiber), Exit.match({\n          onFailure: cause => core.fromEffect(op.f(Exit.failCause(cause))),\n          onSuccess: Either.match({\n            onLeft: done => core.fromEffect(op.f(Exit.succeed(done))),\n            onRight: elem => zipRight(core.write(elem), go(single(op.f)))\n          })\n        }));\n      };\n      return Exit.match(exit, {\n        onFailure: cause => onDecision(done(Exit.failCause(cause))),\n        onSuccess: Either.match({\n          onLeft: z => onDecision(done(Exit.succeed(z))),\n          onRight: elem => Effect.succeed(core.flatMap(core.write(elem), () => core.flatMap(core.fromEffect(Effect.forkDaemon(pull)), leftFiber => go(both(leftFiber, fiber)))))\n        })\n      });\n    };\n    const go = state => {\n      switch (state._tag) {\n        case MergeStateOpCodes.OP_BOTH_RUNNING:\n          {\n            const leftJoin = Effect.interruptible(Fiber.join(state.left));\n            const rightJoin = Effect.interruptible(Fiber.join(state.right));\n            return unwrap(Effect.raceWith(leftJoin, rightJoin, {\n              onSelfDone: (leftExit, rf) => Effect.zipRight(Fiber.interrupt(rf), handleSide(leftExit, state.right, pullL)(options.onSelfDone, mergeState.BothRunning, f => mergeState.LeftDone(f))),\n              onOtherDone: (rightExit, lf) => Effect.zipRight(Fiber.interrupt(lf), handleSide(rightExit, state.left, pullR)(options.onOtherDone, (left, right) => mergeState.BothRunning(right, left), f => mergeState.RightDone(f)))\n            }));\n          }\n        case MergeStateOpCodes.OP_LEFT_DONE:\n          {\n            return unwrap(Effect.map(Effect.exit(pullR), Exit.match({\n              onFailure: cause => core.fromEffect(state.f(Exit.failCause(cause))),\n              onSuccess: Either.match({\n                onLeft: done => core.fromEffect(state.f(Exit.succeed(done))),\n                onRight: elem => core.flatMap(core.write(elem), () => go(mergeState.LeftDone(state.f)))\n              })\n            })));\n          }\n        case MergeStateOpCodes.OP_RIGHT_DONE:\n          {\n            return unwrap(Effect.map(Effect.exit(pullL), Exit.match({\n              onFailure: cause => core.fromEffect(state.f(Exit.failCause(cause))),\n              onSuccess: Either.match({\n                onLeft: done => core.fromEffect(state.f(Exit.succeed(done))),\n                onRight: elem => core.flatMap(core.write(elem), () => go(mergeState.RightDone(state.f)))\n              })\n            })));\n          }\n      }\n    };\n    return pipe(core.fromEffect(Effect.zipWith(Effect.forkIn(pullL, scope), Effect.forkIn(pullR, scope), (left, right) => mergeState.BothRunning(left, right))), core.flatMap(go), core.embedInput(input));\n  });\n})));\n/** @internal */\nexport const never = /*#__PURE__*/core.fromEffect(Effect.never);\n/** @internal */\nexport const orDie = /*#__PURE__*/dual(2, (self, error) => orDieWith(self, error));\n/** @internal */\nexport const orDieWith = /*#__PURE__*/dual(2, (self, f) => catchAll(self, e => {\n  throw f(e);\n}));\n/** @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => catchAll(self, that));\n/** @internal */\nexport const pipeToOrFail = /*#__PURE__*/dual(2, (self, that) => core.suspend(() => {\n  let channelException = undefined;\n  const reader = core.readWith({\n    onInput: outElem => core.flatMap(core.write(outElem), () => reader),\n    onFailure: outErr => {\n      channelException = ChannelException(outErr);\n      return core.failCause(Cause.die(channelException));\n    },\n    onDone: core.succeedNow\n  });\n  const writer = core.readWithCause({\n    onInput: outElem => pipe(core.write(outElem), core.flatMap(() => writer)),\n    onFailure: cause => Cause.isDieType(cause) && isChannelException(cause.defect) && Equal.equals(cause.defect, channelException) ? core.fail(cause.defect.error) : core.failCause(cause),\n    onDone: core.succeedNow\n  });\n  return core.pipeTo(core.pipeTo(core.pipeTo(self, reader), that), writer);\n}));\n/** @internal */\nexport const provideService = /*#__PURE__*/dual(3, (self, tag, service) => {\n  return core.flatMap(context(), context => core.provideContext(self, Context.add(context, tag, service)));\n});\n/** @internal */\nexport const provideLayer = /*#__PURE__*/dual(2, (self, layer) => unwrapScoped(Effect.map(Layer.build(layer), env => core.provideContext(self, env))));\n/** @internal */\nexport const mapInputContext = /*#__PURE__*/dual(2, (self, f) => contextWithChannel(context => core.provideContext(self, f(context))));\n/** @internal */\nexport const provideSomeLayer = /*#__PURE__*/dual(2, (self, layer) =>\n// @ts-expect-error\nprovideLayer(self, Layer.merge(Layer.context(), layer)));\n/** @internal */\nexport const read = () => core.readOrFail(Option.none());\n/** @internal */\nexport const repeated = self => core.flatMap(self, () => repeated(self));\n/** @internal */\nexport const run = self => Effect.scoped(executor.runScoped(self));\n/** @internal */\nexport const runCollect = self => executor.run(core.collectElements(self));\n/** @internal */\nexport const runDrain = self => executor.run(drain(self));\n/** @internal */\nexport const scoped = effect => unwrap(Effect.uninterruptibleMask(restore => Effect.map(Scope.make(), scope => core.acquireReleaseOut(Effect.tapErrorCause(restore(Scope.extend(effect, scope)), cause => Scope.close(scope, Exit.failCause(cause))), (_, exit) => Scope.close(scope, exit)))));\n/** @internal */\nexport const service = tag => core.fromEffect(tag);\n/** @internal */\nexport const serviceWith = tag => f => map(service(tag), f);\n/** @internal */\nexport const serviceWithChannel = tag => f => core.flatMap(service(tag), f);\n/** @internal */\nexport const serviceWithEffect = tag => f => mapEffect(service(tag), f);\n/** @internal */\nexport const splitLines = () => core.suspend(() => {\n  let stringBuilder = \"\";\n  let midCRLF = false;\n  const splitLinesChunk = chunk => {\n    const chunkBuilder = [];\n    Chunk.map(chunk, str => {\n      if (str.length !== 0) {\n        let from = 0;\n        let indexOfCR = str.indexOf(\"\\r\");\n        let indexOfLF = str.indexOf(\"\\n\");\n        if (midCRLF) {\n          if (indexOfLF === 0) {\n            chunkBuilder.push(stringBuilder);\n            stringBuilder = \"\";\n            from = 1;\n            indexOfLF = str.indexOf(\"\\n\", from);\n          } else {\n            stringBuilder = stringBuilder + \"\\r\";\n          }\n          midCRLF = false;\n        }\n        while (indexOfCR !== -1 || indexOfLF !== -1) {\n          if (indexOfCR === -1 || indexOfLF !== -1 && indexOfLF < indexOfCR) {\n            if (stringBuilder.length === 0) {\n              chunkBuilder.push(str.substring(from, indexOfLF));\n            } else {\n              chunkBuilder.push(stringBuilder + str.substring(from, indexOfLF));\n              stringBuilder = \"\";\n            }\n            from = indexOfLF + 1;\n            indexOfLF = str.indexOf(\"\\n\", from);\n          } else {\n            if (str.length === indexOfCR + 1) {\n              midCRLF = true;\n              indexOfCR = -1;\n            } else {\n              if (indexOfLF === indexOfCR + 1) {\n                if (stringBuilder.length === 0) {\n                  chunkBuilder.push(str.substring(from, indexOfCR));\n                } else {\n                  stringBuilder = stringBuilder + str.substring(from, indexOfCR);\n                  chunkBuilder.push(stringBuilder);\n                  stringBuilder = \"\";\n                }\n                from = indexOfCR + 2;\n                indexOfCR = str.indexOf(\"\\r\", from);\n                indexOfLF = str.indexOf(\"\\n\", from);\n              } else {\n                indexOfCR = str.indexOf(\"\\r\", indexOfCR + 1);\n              }\n            }\n          }\n        }\n        if (midCRLF) {\n          stringBuilder = stringBuilder + str.substring(from, str.length - 1);\n        } else {\n          stringBuilder = stringBuilder + str.substring(from, str.length);\n        }\n      }\n    });\n    return Chunk.unsafeFromArray(chunkBuilder);\n  };\n  const loop = core.readWithCause({\n    onInput: input => {\n      const out = splitLinesChunk(input);\n      return Chunk.isEmpty(out) ? loop : core.flatMap(core.write(out), () => loop);\n    },\n    onFailure: cause => stringBuilder.length === 0 ? core.failCause(cause) : core.flatMap(core.write(Chunk.of(stringBuilder)), () => core.failCause(cause)),\n    onDone: done => stringBuilder.length === 0 ? core.succeed(done) : core.flatMap(core.write(Chunk.of(stringBuilder)), () => core.succeed(done))\n  });\n  return loop;\n});\n/** @internal */\nexport const toPubSub = pubsub => toQueue(pubsub);\n/** @internal */\nexport const toPull = self => Effect.map(Effect.acquireRelease(Effect.sync(() => new executor.ChannelExecutor(self, void 0, identity)), (exec, exit) => {\n  const finalize = exec.close(exit);\n  return finalize === undefined ? Effect.void : finalize;\n}), exec => Effect.suspend(() => interpretToPull(exec.run(), exec)));\n/** @internal */\nconst interpretToPull = (channelState, exec) => {\n  const state = channelState;\n  switch (state._tag) {\n    case ChannelStateOpCodes.OP_DONE:\n      {\n        return Exit.match(exec.getDone(), {\n          onFailure: Effect.failCause,\n          onSuccess: done => Effect.succeed(Either.left(done))\n        });\n      }\n    case ChannelStateOpCodes.OP_EMIT:\n      {\n        return Effect.succeed(Either.right(exec.getEmit()));\n      }\n    case ChannelStateOpCodes.OP_FROM_EFFECT:\n      {\n        return pipe(state.effect, Effect.flatMap(() => interpretToPull(exec.run(), exec)));\n      }\n    case ChannelStateOpCodes.OP_READ:\n      {\n        return executor.readUpstream(state, () => interpretToPull(exec.run(), exec), cause => Effect.failCause(cause));\n      }\n  }\n};\n/** @internal */\nexport const toQueue = queue => core.suspend(() => toQueueInternal(queue));\n/** @internal */\nconst toQueueInternal = queue => {\n  return core.readWithCause({\n    onInput: elem => core.flatMap(core.fromEffect(Queue.offer(queue, Either.right(elem))), () => toQueueInternal(queue)),\n    onFailure: cause => core.fromEffect(pipe(Queue.offer(queue, Either.left(Exit.failCause(cause))))),\n    onDone: done => core.fromEffect(pipe(Queue.offer(queue, Either.left(Exit.succeed(done)))))\n  });\n};\n/** @internal */\nexport const unwrap = channel => flatten(core.fromEffect(channel));\n/** @internal */\nexport const unwrapScoped = self => core.concatAllWith(scoped(self), (d, _) => d, (d, _) => d);\n/** @internal */\nexport const updateService = /*#__PURE__*/dual(3, (self, tag, f) => mapInputContext(self, context => Context.merge(context, Context.make(tag, f(Context.unsafeGet(context, tag))))));\n/** @internal */\nexport const withSpan = function () {\n  const dataFirst = typeof arguments[0] !== \"string\";\n  const name = dataFirst ? arguments[1] : arguments[0];\n  const options = tracer.addSpanStackTrace(dataFirst ? arguments[2] : arguments[1]);\n  const acquire = Effect.all([Effect.makeSpan(name, options), Effect.context(), Effect.clock, FiberRef.get(FiberRef.currentTracerTimingEnabled)]);\n  if (dataFirst) {\n    const self = arguments[0];\n    return acquireUseRelease(acquire, ([span, context]) => core.provideContext(self, Context.add(context, tracer.spanTag, span)), ([span,, clock, timingEnabled], exit) => coreEffect.endSpan(span, exit, clock, timingEnabled));\n  }\n  return self => acquireUseRelease(acquire, ([span, context]) => core.provideContext(self, Context.add(context, tracer.spanTag, span)), ([span,, clock, timingEnabled], exit) => coreEffect.endSpan(span, exit, clock, timingEnabled));\n};\n/** @internal */\nexport const writeAll = (...outs) => writeChunk(Chunk.fromIterable(outs));\n/** @internal */\nexport const writeChunk = outs => writeChunkWriter(0, outs.length, outs);\n/** @internal */\nconst writeChunkWriter = (idx, len, chunk) => {\n  return idx === len ? core.void : pipe(core.write(pipe(chunk, Chunk.unsafeGet(idx))), core.flatMap(() => writeChunkWriter(idx + 1, len, chunk)));\n};\n/** @internal */\nexport const zip = /*#__PURE__*/dual(args => core.isChannel(args[1]), (self, that, options) => options?.concurrent ? mergeWith(self, {\n  other: that,\n  onSelfDone: exit1 => mergeDecision.Await(exit2 => Effect.suspend(() => Exit.zip(exit1, exit2))),\n  onOtherDone: exit2 => mergeDecision.Await(exit1 => Effect.suspend(() => Exit.zip(exit1, exit2)))\n}) : core.flatMap(self, a => map(that, b => [a, b])));\n/** @internal */\nexport const zipLeft = /*#__PURE__*/dual(args => core.isChannel(args[1]), (self, that, options) => options?.concurrent ? map(zip(self, that, {\n  concurrent: true\n}), tuple => tuple[0]) : core.flatMap(self, z => as(that, z)));\n/** @internal */\nexport const zipRight = /*#__PURE__*/dual(args => core.isChannel(args[1]), (self, that, options) => options?.concurrent ? map(zip(self, that, {\n  concurrent: true\n}), tuple => tuple[1]) : core.flatMap(self, () => that));\n/** @internal */\nexport const ChannelExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Channel/ChannelException\");\n/** @internal */\nexport const ChannelException = error => ({\n  _tag: \"ChannelException\",\n  [ChannelExceptionTypeId]: ChannelExceptionTypeId,\n  error\n});\n/** @internal */\nexport const isChannelException = u => hasProperty(u, ChannelExceptionTypeId);\n//# sourceMappingURL=channel.js.map","import * as Cause from \"../../Cause.js\";\nimport * as Deferred from \"../../Deferred.js\";\nimport * as Effect from \"../../Effect.js\";\nimport * as ExecutionStrategy from \"../../ExecutionStrategy.js\";\nimport * as Exit from \"../../Exit.js\";\nimport * as Fiber from \"../../Fiber.js\";\nimport { identity, pipe } from \"../../Function.js\";\nimport * as Option from \"../../Option.js\";\nimport * as Scope from \"../../Scope.js\";\nimport * as core from \"../core-stream.js\";\nimport * as ChannelOpCodes from \"../opCodes/channel.js\";\nimport * as ChildExecutorDecisionOpCodes from \"../opCodes/channelChildExecutorDecision.js\";\nimport * as ChannelStateOpCodes from \"../opCodes/channelState.js\";\nimport * as UpstreamPullStrategyOpCodes from \"../opCodes/channelUpstreamPullStrategy.js\";\nimport * as ContinuationOpCodes from \"../opCodes/continuation.js\";\nimport * as ChannelState from \"./channelState.js\";\nimport * as Continuation from \"./continuation.js\";\nimport * as Subexecutor from \"./subexecutor.js\";\nimport * as upstreamPullRequest from \"./upstreamPullRequest.js\";\n/** @internal */\nexport class ChannelExecutor {\n  _activeSubexecutor = undefined;\n  _cancelled = undefined;\n  _closeLastSubstream = undefined;\n  _currentChannel;\n  _done = undefined;\n  _doneStack = [];\n  _emitted = undefined;\n  _executeCloseLastSubstream;\n  _input = undefined;\n  _inProgressFinalizer = undefined;\n  _providedEnv;\n  constructor(initialChannel, providedEnv, executeCloseLastSubstream) {\n    this._currentChannel = initialChannel;\n    this._executeCloseLastSubstream = executeCloseLastSubstream;\n    this._providedEnv = providedEnv;\n  }\n  run() {\n    let result = undefined;\n    while (result === undefined) {\n      if (this._cancelled !== undefined) {\n        result = this.processCancellation();\n      } else if (this._activeSubexecutor !== undefined) {\n        result = this.runSubexecutor();\n      } else {\n        try {\n          if (this._currentChannel === undefined) {\n            result = ChannelState.Done();\n          } else {\n            if (Effect.isEffect(this._currentChannel)) {\n              this._currentChannel = core.fromEffect(this._currentChannel);\n            } else {\n              switch (this._currentChannel._tag) {\n                case ChannelOpCodes.OP_BRACKET_OUT:\n                  {\n                    result = this.runBracketOut(this._currentChannel);\n                    break;\n                  }\n                case ChannelOpCodes.OP_BRIDGE:\n                  {\n                    const bridgeInput = this._currentChannel.input;\n                    // PipeTo(left, Bridge(queue, channel))\n                    // In a fiber: repeatedly run left and push its outputs to the queue\n                    // Add a finalizer to interrupt the fiber and close the executor\n                    this._currentChannel = this._currentChannel.channel;\n                    if (this._input !== undefined) {\n                      const inputExecutor = this._input;\n                      this._input = undefined;\n                      const drainer = () => Effect.flatMap(bridgeInput.awaitRead(), () => Effect.suspend(() => {\n                        const state = inputExecutor.run();\n                        switch (state._tag) {\n                          case ChannelStateOpCodes.OP_DONE:\n                            {\n                              return Exit.match(inputExecutor.getDone(), {\n                                onFailure: cause => bridgeInput.error(cause),\n                                onSuccess: value => bridgeInput.done(value)\n                              });\n                            }\n                          case ChannelStateOpCodes.OP_EMIT:\n                            {\n                              return Effect.flatMap(bridgeInput.emit(inputExecutor.getEmit()), () => drainer());\n                            }\n                          case ChannelStateOpCodes.OP_FROM_EFFECT:\n                            {\n                              return Effect.matchCauseEffect(state.effect, {\n                                onFailure: cause => bridgeInput.error(cause),\n                                onSuccess: () => drainer()\n                              });\n                            }\n                          case ChannelStateOpCodes.OP_READ:\n                            {\n                              return readUpstream(state, () => drainer(), cause => bridgeInput.error(cause));\n                            }\n                        }\n                      }));\n                      result = ChannelState.fromEffect(Effect.flatMap(Effect.forkDaemon(drainer()), fiber => Effect.sync(() => this.addFinalizer(exit => Effect.flatMap(Fiber.interrupt(fiber), () => Effect.suspend(() => {\n                        const effect = this.restorePipe(exit, inputExecutor);\n                        return effect !== undefined ? effect : Effect.void;\n                      }))))));\n                    }\n                    break;\n                  }\n                case ChannelOpCodes.OP_CONCAT_ALL:\n                  {\n                    const executor = new ChannelExecutor(this._currentChannel.value(), this._providedEnv, effect => Effect.sync(() => {\n                      const prevLastClose = this._closeLastSubstream === undefined ? Effect.void : this._closeLastSubstream;\n                      this._closeLastSubstream = pipe(prevLastClose, Effect.zipRight(effect));\n                    }));\n                    executor._input = this._input;\n                    const channel = this._currentChannel;\n                    this._activeSubexecutor = new Subexecutor.PullFromUpstream(executor, value => channel.k(value), undefined, [], (x, y) => channel.combineInners(x, y), (x, y) => channel.combineAll(x, y), request => channel.onPull(request), value => channel.onEmit(value));\n                    this._closeLastSubstream = undefined;\n                    this._currentChannel = undefined;\n                    break;\n                  }\n                case ChannelOpCodes.OP_EMIT:\n                  {\n                    this._emitted = this._currentChannel.out;\n                    this._currentChannel = this._activeSubexecutor !== undefined ? undefined : core.void;\n                    result = ChannelState.Emit();\n                    break;\n                  }\n                case ChannelOpCodes.OP_ENSURING:\n                  {\n                    this.runEnsuring(this._currentChannel);\n                    break;\n                  }\n                case ChannelOpCodes.OP_FAIL:\n                  {\n                    result = this.doneHalt(this._currentChannel.error());\n                    break;\n                  }\n                case ChannelOpCodes.OP_FOLD:\n                  {\n                    this._doneStack.push(this._currentChannel.k);\n                    this._currentChannel = this._currentChannel.channel;\n                    break;\n                  }\n                case ChannelOpCodes.OP_FROM_EFFECT:\n                  {\n                    const effect = this._providedEnv === undefined ? this._currentChannel.effect() : pipe(this._currentChannel.effect(), Effect.provide(this._providedEnv));\n                    result = ChannelState.fromEffect(Effect.matchCauseEffect(effect, {\n                      onFailure: cause => {\n                        const state = this.doneHalt(cause);\n                        return state !== undefined && ChannelState.isFromEffect(state) ? state.effect : Effect.void;\n                      },\n                      onSuccess: value => {\n                        const state = this.doneSucceed(value);\n                        return state !== undefined && ChannelState.isFromEffect(state) ? state.effect : Effect.void;\n                      }\n                    }));\n                    break;\n                  }\n                case ChannelOpCodes.OP_PIPE_TO:\n                  {\n                    const previousInput = this._input;\n                    const leftExec = new ChannelExecutor(this._currentChannel.left(), this._providedEnv, effect => this._executeCloseLastSubstream(effect));\n                    leftExec._input = previousInput;\n                    this._input = leftExec;\n                    this.addFinalizer(exit => {\n                      const effect = this.restorePipe(exit, previousInput);\n                      return effect !== undefined ? effect : Effect.void;\n                    });\n                    this._currentChannel = this._currentChannel.right();\n                    break;\n                  }\n                case ChannelOpCodes.OP_PROVIDE:\n                  {\n                    const previousEnv = this._providedEnv;\n                    this._providedEnv = this._currentChannel.context();\n                    this._currentChannel = this._currentChannel.inner;\n                    this.addFinalizer(() => Effect.sync(() => {\n                      this._providedEnv = previousEnv;\n                    }));\n                    break;\n                  }\n                case ChannelOpCodes.OP_READ:\n                  {\n                    const read = this._currentChannel;\n                    result = ChannelState.Read(this._input, identity, emitted => {\n                      try {\n                        this._currentChannel = read.more(emitted);\n                      } catch (error) {\n                        this._currentChannel = read.done.onExit(Exit.die(error));\n                      }\n                      return undefined;\n                    }, exit => {\n                      const onExit = exit => {\n                        return read.done.onExit(exit);\n                      };\n                      this._currentChannel = onExit(exit);\n                      return undefined;\n                    });\n                    break;\n                  }\n                case ChannelOpCodes.OP_SUCCEED:\n                  {\n                    result = this.doneSucceed(this._currentChannel.evaluate());\n                    break;\n                  }\n                case ChannelOpCodes.OP_SUCCEED_NOW:\n                  {\n                    result = this.doneSucceed(this._currentChannel.terminal);\n                    break;\n                  }\n                case ChannelOpCodes.OP_SUSPEND:\n                  {\n                    this._currentChannel = this._currentChannel.channel();\n                    break;\n                  }\n                default:\n                  {\n                    // @ts-expect-error\n                    this._currentChannel._tag;\n                  }\n              }\n            }\n          }\n        } catch (error) {\n          this._currentChannel = core.failCause(Cause.die(error));\n        }\n      }\n    }\n    return result;\n  }\n  getDone() {\n    return this._done;\n  }\n  getEmit() {\n    return this._emitted;\n  }\n  cancelWith(exit) {\n    this._cancelled = exit;\n  }\n  clearInProgressFinalizer() {\n    this._inProgressFinalizer = undefined;\n  }\n  storeInProgressFinalizer(finalizer) {\n    this._inProgressFinalizer = finalizer;\n  }\n  popAllFinalizers(exit) {\n    const finalizers = [];\n    let next = this._doneStack.pop();\n    while (next) {\n      if (next._tag === \"ContinuationFinalizer\") {\n        finalizers.push(next.finalizer);\n      }\n      next = this._doneStack.pop();\n    }\n    const effect = finalizers.length === 0 ? Effect.void : runFinalizers(finalizers, exit);\n    this.storeInProgressFinalizer(effect);\n    return effect;\n  }\n  popNextFinalizers() {\n    const builder = [];\n    while (this._doneStack.length !== 0) {\n      const cont = this._doneStack[this._doneStack.length - 1];\n      if (cont._tag === ContinuationOpCodes.OP_CONTINUATION_K) {\n        return builder;\n      }\n      builder.push(cont);\n      this._doneStack.pop();\n    }\n    return builder;\n  }\n  restorePipe(exit, prev) {\n    const currInput = this._input;\n    this._input = prev;\n    if (currInput !== undefined) {\n      const effect = currInput.close(exit);\n      return effect;\n    }\n    return Effect.void;\n  }\n  close(exit) {\n    let runInProgressFinalizers = undefined;\n    const finalizer = this._inProgressFinalizer;\n    if (finalizer !== undefined) {\n      runInProgressFinalizers = pipe(finalizer, Effect.ensuring(Effect.sync(() => this.clearInProgressFinalizer())));\n    }\n    let closeSelf = undefined;\n    const selfFinalizers = this.popAllFinalizers(exit);\n    if (selfFinalizers !== undefined) {\n      closeSelf = pipe(selfFinalizers, Effect.ensuring(Effect.sync(() => this.clearInProgressFinalizer())));\n    }\n    const closeSubexecutors = this._activeSubexecutor === undefined ? undefined : this._activeSubexecutor.close(exit);\n    if (closeSubexecutors === undefined && runInProgressFinalizers === undefined && closeSelf === undefined) {\n      return undefined;\n    }\n    return pipe(Effect.exit(ifNotNull(closeSubexecutors)), Effect.zip(Effect.exit(ifNotNull(runInProgressFinalizers))), Effect.zip(Effect.exit(ifNotNull(closeSelf))), Effect.map(([[exit1, exit2], exit3]) => pipe(exit1, Exit.zipRight(exit2), Exit.zipRight(exit3))), Effect.uninterruptible,\n    // TODO: remove\n    Effect.flatMap(exit => Effect.suspend(() => exit)));\n  }\n  doneSucceed(value) {\n    if (this._doneStack.length === 0) {\n      this._done = Exit.succeed(value);\n      this._currentChannel = undefined;\n      return ChannelState.Done();\n    }\n    const head = this._doneStack[this._doneStack.length - 1];\n    if (head._tag === ContinuationOpCodes.OP_CONTINUATION_K) {\n      this._doneStack.pop();\n      this._currentChannel = head.onSuccess(value);\n      return undefined;\n    }\n    const finalizers = this.popNextFinalizers();\n    if (this._doneStack.length === 0) {\n      this._doneStack = finalizers.reverse();\n      this._done = Exit.succeed(value);\n      this._currentChannel = undefined;\n      return ChannelState.Done();\n    }\n    const finalizerEffect = runFinalizers(finalizers.map(f => f.finalizer), Exit.succeed(value));\n    this.storeInProgressFinalizer(finalizerEffect);\n    const effect = pipe(finalizerEffect, Effect.ensuring(Effect.sync(() => this.clearInProgressFinalizer())), Effect.uninterruptible, Effect.flatMap(() => Effect.sync(() => this.doneSucceed(value))));\n    return ChannelState.fromEffect(effect);\n  }\n  doneHalt(cause) {\n    if (this._doneStack.length === 0) {\n      this._done = Exit.failCause(cause);\n      this._currentChannel = undefined;\n      return ChannelState.Done();\n    }\n    const head = this._doneStack[this._doneStack.length - 1];\n    if (head._tag === ContinuationOpCodes.OP_CONTINUATION_K) {\n      this._doneStack.pop();\n      this._currentChannel = head.onHalt(cause);\n      return undefined;\n    }\n    const finalizers = this.popNextFinalizers();\n    if (this._doneStack.length === 0) {\n      this._doneStack = finalizers.reverse();\n      this._done = Exit.failCause(cause);\n      this._currentChannel = undefined;\n      return ChannelState.Done();\n    }\n    const finalizerEffect = runFinalizers(finalizers.map(f => f.finalizer), Exit.failCause(cause));\n    this.storeInProgressFinalizer(finalizerEffect);\n    const effect = pipe(finalizerEffect, Effect.ensuring(Effect.sync(() => this.clearInProgressFinalizer())), Effect.uninterruptible, Effect.flatMap(() => Effect.sync(() => this.doneHalt(cause))));\n    return ChannelState.fromEffect(effect);\n  }\n  processCancellation() {\n    this._currentChannel = undefined;\n    this._done = this._cancelled;\n    this._cancelled = undefined;\n    return ChannelState.Done();\n  }\n  runBracketOut(bracketOut) {\n    const effect = Effect.uninterruptible(Effect.matchCauseEffect(this.provide(bracketOut.acquire()), {\n      onFailure: cause => Effect.sync(() => {\n        this._currentChannel = core.failCause(cause);\n      }),\n      onSuccess: out => Effect.sync(() => {\n        this.addFinalizer(exit => this.provide(bracketOut.finalizer(out, exit)));\n        this._currentChannel = core.write(out);\n      })\n    }));\n    return ChannelState.fromEffect(effect);\n  }\n  provide(effect) {\n    if (this._providedEnv === undefined) {\n      return effect;\n    }\n    return pipe(effect, Effect.provide(this._providedEnv));\n  }\n  runEnsuring(ensuring) {\n    this.addFinalizer(ensuring.finalizer);\n    this._currentChannel = ensuring.channel;\n  }\n  addFinalizer(f) {\n    this._doneStack.push(new Continuation.ContinuationFinalizerImpl(f));\n  }\n  runSubexecutor() {\n    const subexecutor = this._activeSubexecutor;\n    switch (subexecutor._tag) {\n      case Subexecutor.OP_PULL_FROM_CHILD:\n        {\n          return this.pullFromChild(subexecutor.childExecutor, subexecutor.parentSubexecutor, subexecutor.onEmit, subexecutor);\n        }\n      case Subexecutor.OP_PULL_FROM_UPSTREAM:\n        {\n          return this.pullFromUpstream(subexecutor);\n        }\n      case Subexecutor.OP_DRAIN_CHILD_EXECUTORS:\n        {\n          return this.drainChildExecutors(subexecutor);\n        }\n      case Subexecutor.OP_EMIT:\n        {\n          this._emitted = subexecutor.value;\n          this._activeSubexecutor = subexecutor.next;\n          return ChannelState.Emit();\n        }\n    }\n  }\n  replaceSubexecutor(nextSubExec) {\n    this._currentChannel = undefined;\n    this._activeSubexecutor = nextSubExec;\n  }\n  finishWithExit(exit) {\n    const state = Exit.match(exit, {\n      onFailure: cause => this.doneHalt(cause),\n      onSuccess: value => this.doneSucceed(value)\n    });\n    this._activeSubexecutor = undefined;\n    return state === undefined ? Effect.void : ChannelState.effect(state);\n  }\n  finishSubexecutorWithCloseEffect(subexecutorDone, ...closeFuncs) {\n    this.addFinalizer(() => pipe(closeFuncs, Effect.forEach(closeFunc => pipe(Effect.sync(() => closeFunc(subexecutorDone)), Effect.flatMap(closeEffect => closeEffect !== undefined ? closeEffect : Effect.void)), {\n      discard: true\n    })));\n    const state = pipe(subexecutorDone, Exit.match({\n      onFailure: cause => this.doneHalt(cause),\n      onSuccess: value => this.doneSucceed(value)\n    }));\n    this._activeSubexecutor = undefined;\n    return state;\n  }\n  applyUpstreamPullStrategy(upstreamFinished, queue, strategy) {\n    switch (strategy._tag) {\n      case UpstreamPullStrategyOpCodes.OP_PULL_AFTER_NEXT:\n        {\n          const shouldPrepend = !upstreamFinished || queue.some(subexecutor => subexecutor !== undefined);\n          return [strategy.emitSeparator, shouldPrepend ? [undefined, ...queue] : queue];\n        }\n      case UpstreamPullStrategyOpCodes.OP_PULL_AFTER_ALL_ENQUEUED:\n        {\n          const shouldEnqueue = !upstreamFinished || queue.some(subexecutor => subexecutor !== undefined);\n          return [strategy.emitSeparator, shouldEnqueue ? [...queue, undefined] : queue];\n        }\n    }\n  }\n  pullFromChild(childExecutor, parentSubexecutor, onEmitted, subexecutor) {\n    return ChannelState.Read(childExecutor, identity, emitted => {\n      const childExecutorDecision = onEmitted(emitted);\n      switch (childExecutorDecision._tag) {\n        case ChildExecutorDecisionOpCodes.OP_CONTINUE:\n          {\n            break;\n          }\n        case ChildExecutorDecisionOpCodes.OP_CLOSE:\n          {\n            this.finishWithDoneValue(childExecutor, parentSubexecutor, childExecutorDecision.value);\n            break;\n          }\n        case ChildExecutorDecisionOpCodes.OP_YIELD:\n          {\n            const modifiedParent = parentSubexecutor.enqueuePullFromChild(subexecutor);\n            this.replaceSubexecutor(modifiedParent);\n            break;\n          }\n      }\n      this._activeSubexecutor = new Subexecutor.Emit(emitted, this._activeSubexecutor);\n      return undefined;\n    }, Exit.match({\n      onFailure: cause => {\n        const state = this.handleSubexecutorFailure(childExecutor, parentSubexecutor, cause);\n        return state === undefined ? undefined : ChannelState.effectOrUndefinedIgnored(state);\n      },\n      onSuccess: doneValue => {\n        this.finishWithDoneValue(childExecutor, parentSubexecutor, doneValue);\n        return undefined;\n      }\n    }));\n  }\n  finishWithDoneValue(childExecutor, parentSubexecutor, doneValue) {\n    const subexecutor = parentSubexecutor;\n    switch (subexecutor._tag) {\n      case Subexecutor.OP_PULL_FROM_UPSTREAM:\n        {\n          const modifiedParent = new Subexecutor.PullFromUpstream(subexecutor.upstreamExecutor, subexecutor.createChild, subexecutor.lastDone !== undefined ? subexecutor.combineChildResults(subexecutor.lastDone, doneValue) : doneValue, subexecutor.activeChildExecutors, subexecutor.combineChildResults, subexecutor.combineWithChildResult, subexecutor.onPull, subexecutor.onEmit);\n          this._closeLastSubstream = childExecutor.close(Exit.succeed(doneValue));\n          this.replaceSubexecutor(modifiedParent);\n          break;\n        }\n      case Subexecutor.OP_DRAIN_CHILD_EXECUTORS:\n        {\n          const modifiedParent = new Subexecutor.DrainChildExecutors(subexecutor.upstreamExecutor, subexecutor.lastDone !== undefined ? subexecutor.combineChildResults(subexecutor.lastDone, doneValue) : doneValue, subexecutor.activeChildExecutors, subexecutor.upstreamDone, subexecutor.combineChildResults, subexecutor.combineWithChildResult, subexecutor.onPull);\n          this._closeLastSubstream = childExecutor.close(Exit.succeed(doneValue));\n          this.replaceSubexecutor(modifiedParent);\n          break;\n        }\n      default:\n        {\n          break;\n        }\n    }\n  }\n  handleSubexecutorFailure(childExecutor, parentSubexecutor, cause) {\n    return this.finishSubexecutorWithCloseEffect(Exit.failCause(cause), exit => parentSubexecutor.close(exit), exit => childExecutor.close(exit));\n  }\n  pullFromUpstream(subexecutor) {\n    if (subexecutor.activeChildExecutors.length === 0) {\n      return this.performPullFromUpstream(subexecutor);\n    }\n    const activeChild = subexecutor.activeChildExecutors[0];\n    const parentSubexecutor = new Subexecutor.PullFromUpstream(subexecutor.upstreamExecutor, subexecutor.createChild, subexecutor.lastDone, subexecutor.activeChildExecutors.slice(1), subexecutor.combineChildResults, subexecutor.combineWithChildResult, subexecutor.onPull, subexecutor.onEmit);\n    if (activeChild === undefined) {\n      return this.performPullFromUpstream(parentSubexecutor);\n    }\n    this.replaceSubexecutor(new Subexecutor.PullFromChild(activeChild.childExecutor, parentSubexecutor, activeChild.onEmit));\n    return undefined;\n  }\n  performPullFromUpstream(subexecutor) {\n    return ChannelState.Read(subexecutor.upstreamExecutor, effect => {\n      const closeLastSubstream = this._closeLastSubstream === undefined ? Effect.void : this._closeLastSubstream;\n      this._closeLastSubstream = undefined;\n      return pipe(this._executeCloseLastSubstream(closeLastSubstream), Effect.zipRight(effect));\n    }, emitted => {\n      if (this._closeLastSubstream !== undefined) {\n        const closeLastSubstream = this._closeLastSubstream;\n        this._closeLastSubstream = undefined;\n        return pipe(this._executeCloseLastSubstream(closeLastSubstream), Effect.map(() => {\n          const childExecutor = new ChannelExecutor(subexecutor.createChild(emitted), this._providedEnv, this._executeCloseLastSubstream);\n          childExecutor._input = this._input;\n          const [emitSeparator, updatedChildExecutors] = this.applyUpstreamPullStrategy(false, subexecutor.activeChildExecutors, subexecutor.onPull(upstreamPullRequest.Pulled(emitted)));\n          this._activeSubexecutor = new Subexecutor.PullFromChild(childExecutor, new Subexecutor.PullFromUpstream(subexecutor.upstreamExecutor, subexecutor.createChild, subexecutor.lastDone, updatedChildExecutors, subexecutor.combineChildResults, subexecutor.combineWithChildResult, subexecutor.onPull, subexecutor.onEmit), subexecutor.onEmit);\n          if (Option.isSome(emitSeparator)) {\n            this._activeSubexecutor = new Subexecutor.Emit(emitSeparator.value, this._activeSubexecutor);\n          }\n          return undefined;\n        }));\n      }\n      const childExecutor = new ChannelExecutor(subexecutor.createChild(emitted), this._providedEnv, this._executeCloseLastSubstream);\n      childExecutor._input = this._input;\n      const [emitSeparator, updatedChildExecutors] = this.applyUpstreamPullStrategy(false, subexecutor.activeChildExecutors, subexecutor.onPull(upstreamPullRequest.Pulled(emitted)));\n      this._activeSubexecutor = new Subexecutor.PullFromChild(childExecutor, new Subexecutor.PullFromUpstream(subexecutor.upstreamExecutor, subexecutor.createChild, subexecutor.lastDone, updatedChildExecutors, subexecutor.combineChildResults, subexecutor.combineWithChildResult, subexecutor.onPull, subexecutor.onEmit), subexecutor.onEmit);\n      if (Option.isSome(emitSeparator)) {\n        this._activeSubexecutor = new Subexecutor.Emit(emitSeparator.value, this._activeSubexecutor);\n      }\n      return undefined;\n    }, exit => {\n      if (subexecutor.activeChildExecutors.some(subexecutor => subexecutor !== undefined)) {\n        const drain = new Subexecutor.DrainChildExecutors(subexecutor.upstreamExecutor, subexecutor.lastDone, [undefined, ...subexecutor.activeChildExecutors], subexecutor.upstreamExecutor.getDone(), subexecutor.combineChildResults, subexecutor.combineWithChildResult, subexecutor.onPull);\n        if (this._closeLastSubstream !== undefined) {\n          const closeLastSubstream = this._closeLastSubstream;\n          this._closeLastSubstream = undefined;\n          return pipe(this._executeCloseLastSubstream(closeLastSubstream), Effect.map(() => this.replaceSubexecutor(drain)));\n        }\n        this.replaceSubexecutor(drain);\n        return undefined;\n      }\n      const closeLastSubstream = this._closeLastSubstream;\n      const state = this.finishSubexecutorWithCloseEffect(pipe(exit, Exit.map(a => subexecutor.combineWithChildResult(subexecutor.lastDone, a))), () => closeLastSubstream, exit => subexecutor.upstreamExecutor.close(exit));\n      return state === undefined ? undefined :\n      // NOTE: assuming finalizers cannot fail\n      ChannelState.effectOrUndefinedIgnored(state);\n    });\n  }\n  drainChildExecutors(subexecutor) {\n    if (subexecutor.activeChildExecutors.length === 0) {\n      const lastClose = this._closeLastSubstream;\n      if (lastClose !== undefined) {\n        this.addFinalizer(() => Effect.succeed(lastClose));\n      }\n      return this.finishSubexecutorWithCloseEffect(subexecutor.upstreamDone, () => lastClose, exit => subexecutor.upstreamExecutor.close(exit));\n    }\n    const activeChild = subexecutor.activeChildExecutors[0];\n    const rest = subexecutor.activeChildExecutors.slice(1);\n    if (activeChild === undefined) {\n      const [emitSeparator, remainingExecutors] = this.applyUpstreamPullStrategy(true, rest, subexecutor.onPull(upstreamPullRequest.NoUpstream(rest.reduce((n, curr) => curr !== undefined ? n + 1 : n, 0))));\n      this.replaceSubexecutor(new Subexecutor.DrainChildExecutors(subexecutor.upstreamExecutor, subexecutor.lastDone, remainingExecutors, subexecutor.upstreamDone, subexecutor.combineChildResults, subexecutor.combineWithChildResult, subexecutor.onPull));\n      if (Option.isSome(emitSeparator)) {\n        this._emitted = emitSeparator.value;\n        return ChannelState.Emit();\n      }\n      return undefined;\n    }\n    const parentSubexecutor = new Subexecutor.DrainChildExecutors(subexecutor.upstreamExecutor, subexecutor.lastDone, rest, subexecutor.upstreamDone, subexecutor.combineChildResults, subexecutor.combineWithChildResult, subexecutor.onPull);\n    this.replaceSubexecutor(new Subexecutor.PullFromChild(activeChild.childExecutor, parentSubexecutor, activeChild.onEmit));\n    return undefined;\n  }\n}\nconst ifNotNull = effect => effect !== undefined ? effect : Effect.void;\nconst runFinalizers = (finalizers, exit) => {\n  return pipe(Effect.forEach(finalizers, fin => Effect.exit(fin(exit))), Effect.map(exits => pipe(Exit.all(exits), Option.getOrElse(() => Exit.void))), Effect.flatMap(exit => Effect.suspend(() => exit)));\n};\n/**\n * @internal\n */\nexport const readUpstream = (r, onSuccess, onFailure) => {\n  const readStack = [r];\n  const read = () => {\n    const current = readStack.pop();\n    if (current === undefined || current.upstream === undefined) {\n      return Effect.dieMessage(\"Unexpected end of input for channel execution\");\n    }\n    const state = current.upstream.run();\n    switch (state._tag) {\n      case ChannelStateOpCodes.OP_EMIT:\n        {\n          const emitEffect = current.onEmit(current.upstream.getEmit());\n          if (readStack.length === 0) {\n            if (emitEffect === undefined) {\n              return Effect.suspend(onSuccess);\n            }\n            return pipe(emitEffect, Effect.matchCauseEffect({\n              onFailure,\n              onSuccess\n            }));\n          }\n          if (emitEffect === undefined) {\n            return Effect.suspend(() => read());\n          }\n          return pipe(emitEffect, Effect.matchCauseEffect({\n            onFailure,\n            onSuccess: () => read()\n          }));\n        }\n      case ChannelStateOpCodes.OP_DONE:\n        {\n          const doneEffect = current.onDone(current.upstream.getDone());\n          if (readStack.length === 0) {\n            if (doneEffect === undefined) {\n              return Effect.suspend(onSuccess);\n            }\n            return pipe(doneEffect, Effect.matchCauseEffect({\n              onFailure,\n              onSuccess\n            }));\n          }\n          if (doneEffect === undefined) {\n            return Effect.suspend(() => read());\n          }\n          return pipe(doneEffect, Effect.matchCauseEffect({\n            onFailure,\n            onSuccess: () => read()\n          }));\n        }\n      case ChannelStateOpCodes.OP_FROM_EFFECT:\n        {\n          readStack.push(current);\n          return pipe(current.onEffect(state.effect), Effect.catchAllCause(cause => Effect.suspend(() => {\n            const doneEffect = current.onDone(Exit.failCause(cause));\n            return doneEffect === undefined ? Effect.void : doneEffect;\n          })), Effect.matchCauseEffect({\n            onFailure,\n            onSuccess: () => read()\n          }));\n        }\n      case ChannelStateOpCodes.OP_READ:\n        {\n          readStack.push(current);\n          readStack.push(state);\n          return Effect.suspend(() => read());\n        }\n    }\n  };\n  return read();\n};\n/** @internal */\nexport const run = self => pipe(runScoped(self), Effect.scoped);\n/** @internal */\nexport const runScoped = self => {\n  const run = (channelDeferred, scopeDeferred, scope) => Effect.acquireUseRelease(Effect.sync(() => new ChannelExecutor(self, void 0, identity)), exec => Effect.suspend(() => pipe(runScopedInterpret(exec.run(), exec), Effect.intoDeferred(channelDeferred), Effect.zipRight(Deferred.await(channelDeferred)), Effect.zipLeft(Deferred.await(scopeDeferred)))), (exec, exit) => {\n    const finalize = exec.close(exit);\n    if (finalize === undefined) {\n      return Effect.void;\n    }\n    return Effect.tapErrorCause(finalize, cause => Scope.addFinalizer(scope, Effect.failCause(cause)));\n  });\n  return Effect.uninterruptibleMask(restore => Effect.flatMap(Effect.scope, parent => pipe(Effect.all([Scope.fork(parent, ExecutionStrategy.sequential), Deferred.make(), Deferred.make()]), Effect.flatMap(([child, channelDeferred, scopeDeferred]) => pipe(Effect.forkScoped(restore(run(channelDeferred, scopeDeferred, child))), Effect.flatMap(fiber => pipe(Scope.addFinalizer(parent, Deferred.succeed(scopeDeferred, void 0).pipe(Effect.zipRight(Effect.yieldNow()))), Effect.zipRight(restore(Deferred.await(channelDeferred))), Effect.zipLeft(Fiber.inheritAll(fiber)))))))));\n};\n/** @internal */\nconst runScopedInterpret = (channelState, exec) => {\n  const op = channelState;\n  switch (op._tag) {\n    case ChannelStateOpCodes.OP_FROM_EFFECT:\n      {\n        return pipe(op.effect, Effect.flatMap(() => runScopedInterpret(exec.run(), exec)));\n      }\n    case ChannelStateOpCodes.OP_EMIT:\n      {\n        // Can't really happen because Out <:< Nothing. So just skip ahead.\n        return runScopedInterpret(exec.run(), exec);\n      }\n    case ChannelStateOpCodes.OP_DONE:\n      {\n        return Effect.suspend(() => exec.getDone());\n      }\n    case ChannelStateOpCodes.OP_READ:\n      {\n        return readUpstream(op, () => runScopedInterpret(exec.run(), exec), Effect.failCause);\n      }\n  }\n};\n//# sourceMappingURL=channelExecutor.js.map","import * as Effect from \"../../Effect.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as OpCodes from \"../opCodes/channelState.js\";\n/** @internal */\nexport const ChannelStateTypeId = /*#__PURE__*/Symbol.for(\"effect/ChannelState\");\nconst channelStateVariance = {\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _R: _ => _\n};\n/** @internal */\nconst proto = {\n  [ChannelStateTypeId]: channelStateVariance\n};\n/** @internal */\nexport const Done = () => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_DONE;\n  return op;\n};\n/** @internal */\nexport const Emit = () => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_EMIT;\n  return op;\n};\n/** @internal */\nexport const fromEffect = effect => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_FROM_EFFECT;\n  op.effect = effect;\n  return op;\n};\n/** @internal */\nexport const Read = (upstream, onEffect, onEmit, onDone) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_READ;\n  op.upstream = upstream;\n  op.onEffect = onEffect;\n  op.onEmit = onEmit;\n  op.onDone = onDone;\n  return op;\n};\n/** @internal */\nexport const isChannelState = u => hasProperty(u, ChannelStateTypeId);\n/** @internal */\nexport const isDone = self => self._tag === OpCodes.OP_DONE;\n/** @internal */\nexport const isEmit = self => self._tag === OpCodes.OP_EMIT;\n/** @internal */\nexport const isFromEffect = self => self._tag === OpCodes.OP_FROM_EFFECT;\n/** @internal */\nexport const isRead = self => self._tag === OpCodes.OP_READ;\n/** @internal */\nexport const effect = self => isFromEffect(self) ? self.effect : Effect.void;\n/** @internal */\nexport const effectOrUndefinedIgnored = self => isFromEffect(self) ? Effect.ignore(self.effect) : undefined;\n//# sourceMappingURL=channelState.js.map","import { dual } from \"../../Function.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as OpCodes from \"../opCodes/channelChildExecutorDecision.js\";\n/** @internal */\nconst ChildExecutorDecisionSymbolKey = \"effect/ChannelChildExecutorDecision\";\n/** @internal */\nexport const ChildExecutorDecisionTypeId = /*#__PURE__*/Symbol.for(ChildExecutorDecisionSymbolKey);\n/** @internal */\nconst proto = {\n  [ChildExecutorDecisionTypeId]: ChildExecutorDecisionTypeId\n};\n/** @internal */\nexport const Continue = _ => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_CONTINUE;\n  return op;\n};\n/** @internal */\nexport const Close = value => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_CLOSE;\n  op.value = value;\n  return op;\n};\n/** @internal */\nexport const Yield = _ => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_YIELD;\n  return op;\n};\n/** @internal */\nexport const isChildExecutorDecision = u => hasProperty(u, ChildExecutorDecisionTypeId);\n/** @internal */\nexport const isContinue = self => self._tag === OpCodes.OP_CONTINUE;\n/** @internal */\nexport const isClose = self => self._tag === OpCodes.OP_CLOSE;\n/** @internal */\nexport const isYield = self => self._tag === OpCodes.OP_YIELD;\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onClose,\n  onContinue,\n  onYield\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_CONTINUE:\n      {\n        return onContinue();\n      }\n    case OpCodes.OP_CLOSE:\n      {\n        return onClose(self.value);\n      }\n    case OpCodes.OP_YIELD:\n      {\n        return onYield();\n      }\n  }\n});\n//# sourceMappingURL=childExecutorDecision.js.map","import * as Exit from \"../../Exit.js\";\nimport * as OpCodes from \"../opCodes/continuation.js\";\n/** @internal */\nexport const ContinuationTypeId = /*#__PURE__*/Symbol.for(\"effect/ChannelContinuation\");\nconst continuationVariance = {\n  /* c8 ignore next */\n  _Env: _ => _,\n  /* c8 ignore next */\n  _InErr: _ => _,\n  /* c8 ignore next */\n  _InElem: _ => _,\n  /* c8 ignore next */\n  _InDone: _ => _,\n  /* c8 ignore next */\n  _OutErr: _ => _,\n  /* c8 ignore next */\n  _OutDone: _ => _,\n  /* c8 ignore next */\n  _OutErr2: _ => _,\n  /* c8 ignore next */\n  _OutElem: _ => _,\n  /* c8 ignore next */\n  _OutDone2: _ => _\n};\n/** @internal */\nexport class ContinuationKImpl {\n  onSuccess;\n  onHalt;\n  _tag = OpCodes.OP_CONTINUATION_K;\n  [ContinuationTypeId] = continuationVariance;\n  constructor(onSuccess, onHalt) {\n    this.onSuccess = onSuccess;\n    this.onHalt = onHalt;\n  }\n  onExit(exit) {\n    return Exit.isFailure(exit) ? this.onHalt(exit.cause) : this.onSuccess(exit.value);\n  }\n}\n/** @internal */\nexport class ContinuationFinalizerImpl {\n  finalizer;\n  _tag = OpCodes.OP_CONTINUATION_FINALIZER;\n  [ContinuationTypeId] = continuationVariance;\n  constructor(finalizer) {\n    this.finalizer = finalizer;\n  }\n}\n//# sourceMappingURL=continuation.js.map","import { dual } from \"../../Function.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as OpCodes from \"../opCodes/channelMergeDecision.js\";\n/** @internal */\nconst MergeDecisionSymbolKey = \"effect/ChannelMergeDecision\";\n/** @internal */\nexport const MergeDecisionTypeId = /*#__PURE__*/Symbol.for(MergeDecisionSymbolKey);\n/** @internal */\nconst proto = {\n  [MergeDecisionTypeId]: {\n    _R: _ => _,\n    _E0: _ => _,\n    _Z0: _ => _,\n    _E: _ => _,\n    _Z: _ => _\n  }\n};\n/** @internal */\nexport const Done = effect => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_DONE;\n  op.effect = effect;\n  return op;\n};\n/** @internal */\nexport const Await = f => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_AWAIT;\n  op.f = f;\n  return op;\n};\n/** @internal */\nexport const AwaitConst = effect => Await(() => effect);\n/** @internal */\nexport const isMergeDecision = u => hasProperty(u, MergeDecisionTypeId);\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onAwait,\n  onDone\n}) => {\n  const op = self;\n  switch (op._tag) {\n    case OpCodes.OP_DONE:\n      return onDone(op.effect);\n    case OpCodes.OP_AWAIT:\n      return onAwait(op.f);\n  }\n});\n//# sourceMappingURL=mergeDecision.js.map","import { dual } from \"../../Function.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as OpCodes from \"../opCodes/channelMergeState.js\";\n/** @internal */\nconst MergeStateSymbolKey = \"effect/ChannelMergeState\";\n/** @internal */\nexport const MergeStateTypeId = /*#__PURE__*/Symbol.for(MergeStateSymbolKey);\n/** @internal */\nconst proto = {\n  [MergeStateTypeId]: MergeStateTypeId\n};\n/** @internal */\nexport const BothRunning = (left, right) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_BOTH_RUNNING;\n  op.left = left;\n  op.right = right;\n  return op;\n};\n/** @internal */\nexport const LeftDone = f => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_LEFT_DONE;\n  op.f = f;\n  return op;\n};\n/** @internal */\nexport const RightDone = f => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_RIGHT_DONE;\n  op.f = f;\n  return op;\n};\n/** @internal */\nexport const isMergeState = u => hasProperty(u, MergeStateTypeId);\n/** @internal */\nexport const isBothRunning = self => {\n  return self._tag === OpCodes.OP_BOTH_RUNNING;\n};\n/** @internal */\nexport const isLeftDone = self => {\n  return self._tag === OpCodes.OP_LEFT_DONE;\n};\n/** @internal */\nexport const isRightDone = self => {\n  return self._tag === OpCodes.OP_RIGHT_DONE;\n};\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onBothRunning,\n  onLeftDone,\n  onRightDone\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_BOTH_RUNNING:\n      {\n        return onBothRunning(self.left, self.right);\n      }\n    case OpCodes.OP_LEFT_DONE:\n      {\n        return onLeftDone(self.f);\n      }\n    case OpCodes.OP_RIGHT_DONE:\n      {\n        return onRightDone(self.f);\n      }\n  }\n});\n//# sourceMappingURL=mergeState.js.map","import { dual } from \"../../Function.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as OpCodes from \"../opCodes/channelMergeStrategy.js\";\n/** @internal */\nconst MergeStrategySymbolKey = \"effect/ChannelMergeStrategy\";\n/** @internal */\nexport const MergeStrategyTypeId = /*#__PURE__*/Symbol.for(MergeStrategySymbolKey);\n/** @internal */\nconst proto = {\n  [MergeStrategyTypeId]: MergeStrategyTypeId\n};\n/** @internal */\nexport const BackPressure = _ => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_BACK_PRESSURE;\n  return op;\n};\n/** @internal */\nexport const BufferSliding = _ => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_BUFFER_SLIDING;\n  return op;\n};\n/** @internal */\nexport const isMergeStrategy = u => hasProperty(u, MergeStrategyTypeId);\n/** @internal */\nexport const isBackPressure = self => self._tag === OpCodes.OP_BACK_PRESSURE;\n/** @internal */\nexport const isBufferSliding = self => self._tag === OpCodes.OP_BUFFER_SLIDING;\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onBackPressure,\n  onBufferSliding\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_BACK_PRESSURE:\n      {\n        return onBackPressure();\n      }\n    case OpCodes.OP_BUFFER_SLIDING:\n      {\n        return onBufferSliding();\n      }\n  }\n});\n//# sourceMappingURL=mergeStrategy.js.map","import * as Cause from \"../../Cause.js\";\nimport * as Deferred from \"../../Deferred.js\";\nimport * as Effect from \"../../Effect.js\";\nimport * as Either from \"../../Either.js\";\nimport * as Exit from \"../../Exit.js\";\nimport { pipe } from \"../../Function.js\";\nimport * as Ref from \"../../Ref.js\";\n/** @internal */\nconst OP_STATE_EMPTY = \"Empty\";\n/** @internal */\nconst OP_STATE_EMIT = \"Emit\";\n/** @internal */\nconst OP_STATE_ERROR = \"Error\";\n/** @internal */\nconst OP_STATE_DONE = \"Done\";\n/** @internal */\nconst stateEmpty = notifyProducer => ({\n  _tag: OP_STATE_EMPTY,\n  notifyProducer\n});\n/** @internal */\nconst stateEmit = notifyConsumers => ({\n  _tag: OP_STATE_EMIT,\n  notifyConsumers\n});\n/** @internal */\nconst stateError = cause => ({\n  _tag: OP_STATE_ERROR,\n  cause\n});\n/** @internal */\nconst stateDone = done => ({\n  _tag: OP_STATE_DONE,\n  done\n});\n/** @internal */\nclass SingleProducerAsyncInputImpl {\n  ref;\n  constructor(ref) {\n    this.ref = ref;\n  }\n  awaitRead() {\n    return Effect.flatten(Ref.modify(this.ref, state => state._tag === OP_STATE_EMPTY ? [Deferred.await(state.notifyProducer), state] : [Effect.void, state]));\n  }\n  get close() {\n    return Effect.fiberIdWith(fiberId => this.error(Cause.interrupt(fiberId)));\n  }\n  done(value) {\n    return Effect.flatten(Ref.modify(this.ref, state => {\n      switch (state._tag) {\n        case OP_STATE_EMPTY:\n          {\n            return [Deferred.await(state.notifyProducer), state];\n          }\n        case OP_STATE_EMIT:\n          {\n            return [Effect.forEach(state.notifyConsumers, deferred => Deferred.succeed(deferred, Either.left(value)), {\n              discard: true\n            }), stateDone(value)];\n          }\n        case OP_STATE_ERROR:\n          {\n            return [Effect.interrupt, state];\n          }\n        case OP_STATE_DONE:\n          {\n            return [Effect.interrupt, state];\n          }\n      }\n    }));\n  }\n  emit(element) {\n    return Effect.flatMap(Deferred.make(), deferred => Effect.flatten(Ref.modify(this.ref, state => {\n      switch (state._tag) {\n        case OP_STATE_EMPTY:\n          {\n            return [Deferred.await(state.notifyProducer), state];\n          }\n        case OP_STATE_EMIT:\n          {\n            const notifyConsumer = state.notifyConsumers[0];\n            const notifyConsumers = state.notifyConsumers.slice(1);\n            if (notifyConsumer !== undefined) {\n              return [Deferred.succeed(notifyConsumer, Either.right(element)), notifyConsumers.length === 0 ? stateEmpty(deferred) : stateEmit(notifyConsumers)];\n            }\n            throw new Error(\"Bug: Channel.SingleProducerAsyncInput.emit - Queue was empty! please report an issue at https://github.com/Effect-TS/effect/issues\");\n          }\n        case OP_STATE_ERROR:\n          {\n            return [Effect.interrupt, state];\n          }\n        case OP_STATE_DONE:\n          {\n            return [Effect.interrupt, state];\n          }\n      }\n    })));\n  }\n  error(cause) {\n    return Effect.flatten(Ref.modify(this.ref, state => {\n      switch (state._tag) {\n        case OP_STATE_EMPTY:\n          {\n            return [Deferred.await(state.notifyProducer), state];\n          }\n        case OP_STATE_EMIT:\n          {\n            return [Effect.forEach(state.notifyConsumers, deferred => Deferred.failCause(deferred, cause), {\n              discard: true\n            }), stateError(cause)];\n          }\n        case OP_STATE_ERROR:\n          {\n            return [Effect.interrupt, state];\n          }\n        case OP_STATE_DONE:\n          {\n            return [Effect.interrupt, state];\n          }\n      }\n    }));\n  }\n  get take() {\n    return this.takeWith(cause => Exit.failCause(Cause.map(cause, Either.left)), elem => Exit.succeed(elem), done => Exit.fail(Either.right(done)));\n  }\n  takeWith(onError, onElement, onDone) {\n    return Effect.flatMap(Deferred.make(), deferred => Effect.flatten(Ref.modify(this.ref, state => {\n      switch (state._tag) {\n        case OP_STATE_EMPTY:\n          {\n            return [Effect.zipRight(Deferred.succeed(state.notifyProducer, void 0), Effect.matchCause(Deferred.await(deferred), {\n              onFailure: onError,\n              onSuccess: Either.match({\n                onLeft: onDone,\n                onRight: onElement\n              })\n            })), stateEmit([deferred])];\n          }\n        case OP_STATE_EMIT:\n          {\n            return [Effect.matchCause(Deferred.await(deferred), {\n              onFailure: onError,\n              onSuccess: Either.match({\n                onLeft: onDone,\n                onRight: onElement\n              })\n            }), stateEmit([...state.notifyConsumers, deferred])];\n          }\n        case OP_STATE_ERROR:\n          {\n            return [Effect.succeed(onError(state.cause)), state];\n          }\n        case OP_STATE_DONE:\n          {\n            return [Effect.succeed(onDone(state.done)), state];\n          }\n      }\n    })));\n  }\n}\n/** @internal */\nexport const make = () => pipe(Deferred.make(), Effect.flatMap(deferred => Ref.make(stateEmpty(deferred))), Effect.map(ref => new SingleProducerAsyncInputImpl(ref)));\n//# sourceMappingURL=singleProducerAsyncInput.js.map","import * as Effect from \"../../Effect.js\";\nimport * as Exit from \"../../Exit.js\";\nimport { pipe } from \"../../Function.js\";\n/** @internal */\nexport const OP_PULL_FROM_CHILD = \"PullFromChild\";\n/** @internal */\nexport const OP_PULL_FROM_UPSTREAM = \"PullFromUpstream\";\n/** @internal */\nexport const OP_DRAIN_CHILD_EXECUTORS = \"DrainChildExecutors\";\n/** @internal */\nexport const OP_EMIT = \"Emit\";\n/**\n * Execute the `childExecutor` and on each emitted value, decide what to do by\n * `onEmit`.\n *\n * @internal\n */\nexport class PullFromChild {\n  childExecutor;\n  parentSubexecutor;\n  onEmit;\n  _tag = OP_PULL_FROM_CHILD;\n  constructor(childExecutor, parentSubexecutor, onEmit) {\n    this.childExecutor = childExecutor;\n    this.parentSubexecutor = parentSubexecutor;\n    this.onEmit = onEmit;\n  }\n  close(exit) {\n    const fin1 = this.childExecutor.close(exit);\n    const fin2 = this.parentSubexecutor.close(exit);\n    if (fin1 !== undefined && fin2 !== undefined) {\n      return Effect.zipWith(Effect.exit(fin1), Effect.exit(fin2), (exit1, exit2) => pipe(exit1, Exit.zipRight(exit2)));\n    } else if (fin1 !== undefined) {\n      return fin1;\n    } else if (fin2 !== undefined) {\n      return fin2;\n    } else {\n      return undefined;\n    }\n  }\n  enqueuePullFromChild(_child) {\n    return this;\n  }\n}\n/**\n * Execute `upstreamExecutor` and for each emitted element, spawn a child\n * channel and continue with processing it by `PullFromChild`.\n *\n * @internal\n */\nexport class PullFromUpstream {\n  upstreamExecutor;\n  createChild;\n  lastDone;\n  activeChildExecutors;\n  combineChildResults;\n  combineWithChildResult;\n  onPull;\n  onEmit;\n  _tag = OP_PULL_FROM_UPSTREAM;\n  constructor(upstreamExecutor, createChild, lastDone, activeChildExecutors, combineChildResults, combineWithChildResult, onPull, onEmit) {\n    this.upstreamExecutor = upstreamExecutor;\n    this.createChild = createChild;\n    this.lastDone = lastDone;\n    this.activeChildExecutors = activeChildExecutors;\n    this.combineChildResults = combineChildResults;\n    this.combineWithChildResult = combineWithChildResult;\n    this.onPull = onPull;\n    this.onEmit = onEmit;\n  }\n  close(exit) {\n    const fin1 = this.upstreamExecutor.close(exit);\n    const fins = [...this.activeChildExecutors.map(child => child !== undefined ? child.childExecutor.close(exit) : undefined), fin1];\n    const result = fins.reduce((acc, next) => {\n      if (acc !== undefined && next !== undefined) {\n        return Effect.zipWith(acc, Effect.exit(next), (exit1, exit2) => Exit.zipRight(exit1, exit2));\n      } else if (acc !== undefined) {\n        return acc;\n      } else if (next !== undefined) {\n        return Effect.exit(next);\n      } else {\n        return undefined;\n      }\n    }, undefined);\n    return result === undefined ? result : result;\n  }\n  enqueuePullFromChild(child) {\n    return new PullFromUpstream(this.upstreamExecutor, this.createChild, this.lastDone, [...this.activeChildExecutors, child], this.combineChildResults, this.combineWithChildResult, this.onPull, this.onEmit);\n  }\n}\n/**\n * Transformed from `PullFromUpstream` when upstream has finished but there\n * are still active child executors.\n *\n * @internal\n */\nexport class DrainChildExecutors {\n  upstreamExecutor;\n  lastDone;\n  activeChildExecutors;\n  upstreamDone;\n  combineChildResults;\n  combineWithChildResult;\n  onPull;\n  _tag = OP_DRAIN_CHILD_EXECUTORS;\n  constructor(upstreamExecutor, lastDone, activeChildExecutors, upstreamDone, combineChildResults, combineWithChildResult, onPull) {\n    this.upstreamExecutor = upstreamExecutor;\n    this.lastDone = lastDone;\n    this.activeChildExecutors = activeChildExecutors;\n    this.upstreamDone = upstreamDone;\n    this.combineChildResults = combineChildResults;\n    this.combineWithChildResult = combineWithChildResult;\n    this.onPull = onPull;\n  }\n  close(exit) {\n    const fin1 = this.upstreamExecutor.close(exit);\n    const fins = [...this.activeChildExecutors.map(child => child !== undefined ? child.childExecutor.close(exit) : undefined), fin1];\n    const result = fins.reduce((acc, next) => {\n      if (acc !== undefined && next !== undefined) {\n        return Effect.zipWith(acc, Effect.exit(next), (exit1, exit2) => Exit.zipRight(exit1, exit2));\n      } else if (acc !== undefined) {\n        return acc;\n      } else if (next !== undefined) {\n        return Effect.exit(next);\n      } else {\n        return undefined;\n      }\n    }, undefined);\n    return result === undefined ? result : result;\n  }\n  enqueuePullFromChild(child) {\n    return new DrainChildExecutors(this.upstreamExecutor, this.lastDone, [...this.activeChildExecutors, child], this.upstreamDone, this.combineChildResults, this.combineWithChildResult, this.onPull);\n  }\n}\n/** @internal */\nexport class Emit {\n  value;\n  next;\n  _tag = OP_EMIT;\n  constructor(value, next) {\n    this.value = value;\n    this.next = next;\n  }\n  close(exit) {\n    const result = this.next.close(exit);\n    return result === undefined ? result : result;\n  }\n  enqueuePullFromChild(_child) {\n    return this;\n  }\n}\n//# sourceMappingURL=subexecutor.js.map","import { dual } from \"../../Function.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as OpCodes from \"../opCodes/channelUpstreamPullRequest.js\";\n/** @internal */\nconst UpstreamPullRequestSymbolKey = \"effect/ChannelUpstreamPullRequest\";\n/** @internal */\nexport const UpstreamPullRequestTypeId = /*#__PURE__*/Symbol.for(UpstreamPullRequestSymbolKey);\nconst upstreamPullRequestVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\n/** @internal */\nconst proto = {\n  [UpstreamPullRequestTypeId]: upstreamPullRequestVariance\n};\n/** @internal */\nexport const Pulled = value => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_PULLED;\n  op.value = value;\n  return op;\n};\n/** @internal */\nexport const NoUpstream = activeDownstreamCount => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_NO_UPSTREAM;\n  op.activeDownstreamCount = activeDownstreamCount;\n  return op;\n};\n/** @internal */\nexport const isUpstreamPullRequest = u => hasProperty(u, UpstreamPullRequestTypeId);\n/** @internal */\nexport const isPulled = self => self._tag === OpCodes.OP_PULLED;\n/** @internal */\nexport const isNoUpstream = self => self._tag === OpCodes.OP_NO_UPSTREAM;\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onNoUpstream,\n  onPulled\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_PULLED:\n      {\n        return onPulled(self.value);\n      }\n    case OpCodes.OP_NO_UPSTREAM:\n      {\n        return onNoUpstream(self.activeDownstreamCount);\n      }\n  }\n});\n//# sourceMappingURL=upstreamPullRequest.js.map","import { dual } from \"../../Function.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as OpCodes from \"../opCodes/channelUpstreamPullStrategy.js\";\n/** @internal */\nconst UpstreamPullStrategySymbolKey = \"effect/ChannelUpstreamPullStrategy\";\n/** @internal */\nexport const UpstreamPullStrategyTypeId = /*#__PURE__*/Symbol.for(UpstreamPullStrategySymbolKey);\nconst upstreamPullStrategyVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\n/** @internal */\nconst proto = {\n  [UpstreamPullStrategyTypeId]: upstreamPullStrategyVariance\n};\n/** @internal */\nexport const PullAfterNext = emitSeparator => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_PULL_AFTER_NEXT;\n  op.emitSeparator = emitSeparator;\n  return op;\n};\n/** @internal */\nexport const PullAfterAllEnqueued = emitSeparator => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_PULL_AFTER_ALL_ENQUEUED;\n  op.emitSeparator = emitSeparator;\n  return op;\n};\n/** @internal */\nexport const isUpstreamPullStrategy = u => hasProperty(u, UpstreamPullStrategyTypeId);\n/** @internal */\nexport const isPullAfterNext = self => self._tag === OpCodes.OP_PULL_AFTER_NEXT;\n/** @internal */\nexport const isPullAfterAllEnqueued = self => self._tag === OpCodes.OP_PULL_AFTER_ALL_ENQUEUED;\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onAllEnqueued,\n  onNext\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_PULL_AFTER_NEXT:\n      {\n        return onNext(self.emitSeparator);\n      }\n    case OpCodes.OP_PULL_AFTER_ALL_ENQUEUED:\n      {\n        return onAllEnqueued(self.emitSeparator);\n      }\n  }\n});\n//# sourceMappingURL=upstreamPullStrategy.js.map","import * as Context from \"../Context.js\";\nimport * as Duration from \"../Duration.js\";\nimport { constFalse } from \"../Function.js\";\nimport * as core from \"./core.js\";\n/** @internal */\nconst ClockSymbolKey = \"effect/Clock\";\n/** @internal */\nexport const ClockTypeId = /*#__PURE__*/Symbol.for(ClockSymbolKey);\n/** @internal */\nexport const clockTag = /*#__PURE__*/Context.GenericTag(\"effect/Clock\");\n/** @internal */\nexport const MAX_TIMER_MILLIS = 2 ** 31 - 1;\n/** @internal */\nexport const globalClockScheduler = {\n  unsafeSchedule(task, duration) {\n    const millis = Duration.toMillis(duration);\n    // If the duration is greater than the value allowable by the JS timer\n    // functions, treat the value as an infinite duration\n    if (millis > MAX_TIMER_MILLIS) {\n      return constFalse;\n    }\n    let completed = false;\n    const handle = setTimeout(() => {\n      completed = true;\n      task();\n    }, millis);\n    return () => {\n      clearTimeout(handle);\n      return !completed;\n    };\n  }\n};\nconst performanceNowNanos = /*#__PURE__*/function () {\n  const bigint1e6 = /*#__PURE__*/BigInt(1_000_000);\n  if (typeof performance === \"undefined\") {\n    return () => BigInt(Date.now()) * bigint1e6;\n  } else if (typeof performance.timeOrigin === \"number\" && performance.timeOrigin === 0) {\n    return () => BigInt(Math.round(performance.now() * 1_000_000));\n  }\n  const origin = /*#__PURE__*/BigInt( /*#__PURE__*/Date.now()) * bigint1e6 - /*#__PURE__*/BigInt( /*#__PURE__*/Math.round( /*#__PURE__*/performance.now() * 1_000_000));\n  return () => origin + BigInt(Math.round(performance.now() * 1_000_000));\n}();\nconst processOrPerformanceNow = /*#__PURE__*/function () {\n  const processHrtime = typeof process === \"object\" && \"hrtime\" in process && typeof process.hrtime.bigint === \"function\" ? process.hrtime : undefined;\n  if (!processHrtime) {\n    return performanceNowNanos;\n  }\n  const origin = /*#__PURE__*/performanceNowNanos() - /*#__PURE__*/processHrtime.bigint();\n  return () => origin + processHrtime.bigint();\n}();\n/** @internal */\nclass ClockImpl {\n  [ClockTypeId] = ClockTypeId;\n  unsafeCurrentTimeMillis() {\n    return Date.now();\n  }\n  unsafeCurrentTimeNanos() {\n    return processOrPerformanceNow();\n  }\n  currentTimeMillis = /*#__PURE__*/core.sync(() => this.unsafeCurrentTimeMillis());\n  currentTimeNanos = /*#__PURE__*/core.sync(() => this.unsafeCurrentTimeNanos());\n  scheduler() {\n    return core.succeed(globalClockScheduler);\n  }\n  sleep(duration) {\n    return core.async(resume => {\n      const canceler = globalClockScheduler.unsafeSchedule(() => resume(core.void), duration);\n      return core.asVoid(core.sync(canceler));\n    });\n  }\n}\n/** @internal */\nexport const make = () => new ClockImpl();\n//# sourceMappingURL=clock.js.map","import { globalValue } from \"../GlobalValue.js\";\nimport { fiberRefUnsafeMake } from \"./core.js\";\n/** @internal */\nexport const currentRequestMap = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentRequestMap\"), () => fiberRefUnsafeMake(new Map()));\n//# sourceMappingURL=completedRequestMap.js.map","import * as core from \"./core.js\";\n/** @internal */\nexport const match = (concurrency, sequential, unbounded, bounded) => {\n  switch (concurrency) {\n    case undefined:\n      return sequential();\n    case \"unbounded\":\n      return unbounded();\n    case \"inherit\":\n      return core.fiberRefGetWith(core.currentConcurrency, concurrency => concurrency === \"unbounded\" ? unbounded() : concurrency > 1 ? bounded(concurrency) : sequential());\n    default:\n      return concurrency > 1 ? bounded(concurrency) : sequential();\n  }\n};\n/** @internal */\nexport const matchSimple = (concurrency, sequential, concurrent) => {\n  switch (concurrency) {\n    case undefined:\n      return sequential();\n    case \"unbounded\":\n      return concurrent();\n    case \"inherit\":\n      return core.fiberRefGetWith(core.currentConcurrency, concurrency => concurrency === \"unbounded\" || concurrency > 1 ? concurrent() : sequential());\n    default:\n      return concurrency > 1 ? concurrent() : sequential();\n  }\n};\n//# sourceMappingURL=concurrency.js.map","import * as Chunk from \"../Chunk.js\";\nimport * as ConfigError from \"../ConfigError.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as Either from \"../Either.js\";\nimport { constTrue, dual, pipe } from \"../Function.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport * as Option from \"../Option.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as configError from \"./configError.js\";\nimport * as core from \"./core.js\";\nimport * as defaultServices from \"./defaultServices.js\";\nimport * as effectable from \"./effectable.js\";\nimport * as OpCodes from \"./opCodes/config.js\";\nimport * as redacted_ from \"./redacted.js\";\nimport * as InternalSecret from \"./secret.js\";\nconst ConfigSymbolKey = \"effect/Config\";\n/** @internal */\nexport const ConfigTypeId = /*#__PURE__*/Symbol.for(ConfigSymbolKey);\nconst configVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\nconst proto = {\n  ...effectable.CommitPrototype,\n  [ConfigTypeId]: configVariance,\n  commit() {\n    return defaultServices.config(this);\n  }\n};\n/** @internal */\nexport const boolean = name => {\n  const config = primitive(\"a boolean property\", text => {\n    switch (text) {\n      case \"true\":\n      case \"yes\":\n      case \"on\":\n      case \"1\":\n        {\n          return Either.right(true);\n        }\n      case \"false\":\n      case \"no\":\n      case \"off\":\n      case \"0\":\n        {\n          return Either.right(false);\n        }\n      default:\n        {\n          const error = configError.InvalidData([], `Expected a boolean value but received ${text}`);\n          return Either.left(error);\n        }\n    }\n  });\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const array = (config, name) => {\n  return pipe(chunk(config, name), map(Chunk.toArray));\n};\n/** @internal */\nexport const chunk = (config, name) => {\n  return map(name === undefined ? repeat(config) : nested(repeat(config), name), Chunk.unsafeFromArray);\n};\n/** @internal */\nexport const date = name => {\n  const config = primitive(\"a date property\", text => {\n    const result = Date.parse(text);\n    if (Number.isNaN(result)) {\n      return Either.left(configError.InvalidData([], `Expected a Date value but received ${text}`));\n    }\n    return Either.right(new Date(result));\n  });\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const fail = message => {\n  const fail = Object.create(proto);\n  fail._tag = OpCodes.OP_FAIL;\n  fail.message = message;\n  fail.parse = () => Either.left(configError.Unsupported([], message));\n  return fail;\n};\n/** @internal */\nexport const number = name => {\n  const config = primitive(\"a number property\", text => {\n    const result = Number.parseFloat(text);\n    if (Number.isNaN(result)) {\n      return Either.left(configError.InvalidData([], `Expected a number value but received ${text}`));\n    }\n    return Either.right(result);\n  });\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const integer = name => {\n  const config = primitive(\"an integer property\", text => {\n    const result = Number.parseInt(text, 10);\n    if (Number.isNaN(result)) {\n      return Either.left(configError.InvalidData([], `Expected an integer value but received ${text}`));\n    }\n    return Either.right(result);\n  });\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const literal = (...literals) => name => {\n  const valuesString = literals.map(String).join(\", \");\n  const config = primitive(`one of (${valuesString})`, text => {\n    const found = literals.find(value => String(value) === text);\n    if (found === undefined) {\n      return Either.left(configError.InvalidData([], `Expected one of (${valuesString}) but received ${text}`));\n    }\n    return Either.right(found);\n  });\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const logLevel = name => {\n  const config = mapOrFail(string(), value => {\n    const label = value.toUpperCase();\n    const level = core.allLogLevels.find(level => level.label === label);\n    return level === undefined ? Either.left(configError.InvalidData([], `Expected a log level but received ${value}`)) : Either.right(level);\n  });\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const duration = name => {\n  const config = mapOrFail(string(), value => {\n    const duration = Duration.decodeUnknown(value);\n    return Either.fromOption(duration, () => configError.InvalidData([], `Expected a duration but received ${value}`));\n  });\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => mapOrFail(self, a => Either.right(f(a))));\n/** @internal */\nexport const mapAttempt = /*#__PURE__*/dual(2, (self, f) => mapOrFail(self, a => {\n  try {\n    return Either.right(f(a));\n  } catch (error) {\n    return Either.left(configError.InvalidData([], error instanceof Error ? error.message : `${error}`));\n  }\n}));\n/** @internal */\nexport const mapOrFail = /*#__PURE__*/dual(2, (self, f) => {\n  const mapOrFail = Object.create(proto);\n  mapOrFail._tag = OpCodes.OP_MAP_OR_FAIL;\n  mapOrFail.original = self;\n  mapOrFail.mapOrFail = f;\n  return mapOrFail;\n});\n/** @internal */\nexport const nested = /*#__PURE__*/dual(2, (self, name) => {\n  const nested = Object.create(proto);\n  nested._tag = OpCodes.OP_NESTED;\n  nested.name = name;\n  nested.config = self;\n  return nested;\n});\n/** @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => {\n  const fallback = Object.create(proto);\n  fallback._tag = OpCodes.OP_FALLBACK;\n  fallback.first = self;\n  fallback.second = suspend(that);\n  fallback.condition = constTrue;\n  return fallback;\n});\n/** @internal */\nexport const orElseIf = /*#__PURE__*/dual(2, (self, options) => {\n  const fallback = Object.create(proto);\n  fallback._tag = OpCodes.OP_FALLBACK;\n  fallback.first = self;\n  fallback.second = suspend(options.orElse);\n  fallback.condition = options.if;\n  return fallback;\n});\n/** @internal */\nexport const option = self => {\n  return pipe(self, map(Option.some), orElseIf({\n    orElse: () => succeed(Option.none()),\n    if: ConfigError.isMissingDataOnly\n  }));\n};\n/** @internal */\nexport const primitive = (description, parse) => {\n  const primitive = Object.create(proto);\n  primitive._tag = OpCodes.OP_PRIMITIVE;\n  primitive.description = description;\n  primitive.parse = parse;\n  return primitive;\n};\n/** @internal */\nexport const repeat = self => {\n  const repeat = Object.create(proto);\n  repeat._tag = OpCodes.OP_SEQUENCE;\n  repeat.config = self;\n  return repeat;\n};\n/** @internal */\nexport const secret = name => {\n  const config = primitive(\"a secret property\", text => Either.right(InternalSecret.fromString(text)));\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const redacted = name => {\n  const config = primitive(\"a redacted property\", text => Either.right(redacted_.make(text)));\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const hashSet = (config, name) => {\n  const newConfig = map(chunk(config), HashSet.fromIterable);\n  return name === undefined ? newConfig : nested(newConfig, name);\n};\n/** @internal */\nexport const string = name => {\n  const config = primitive(\"a text property\", Either.right);\n  return name === undefined ? config : nested(config, name);\n};\n/** @internal */\nexport const all = arg => {\n  if (Array.isArray(arg)) {\n    return tuple(arg);\n  } else if (Symbol.iterator in arg) {\n    return tuple([...arg]);\n  }\n  return struct(arg);\n};\nconst struct = r => {\n  const entries = Object.entries(r);\n  let result = pipe(entries[0][1], map(value => ({\n    [entries[0][0]]: value\n  })));\n  if (entries.length === 1) {\n    return result;\n  }\n  const rest = entries.slice(1);\n  for (const [key, config] of rest) {\n    result = pipe(result, zipWith(config, (record, value) => ({\n      ...record,\n      [key]: value\n    })));\n  }\n  return result;\n};\n/** @internal */\nexport const succeed = value => {\n  const constant = Object.create(proto);\n  constant._tag = OpCodes.OP_CONSTANT;\n  constant.value = value;\n  constant.parse = () => Either.right(value);\n  return constant;\n};\n/** @internal */\nexport const suspend = config => {\n  const lazy = Object.create(proto);\n  lazy._tag = OpCodes.OP_LAZY;\n  lazy.config = config;\n  return lazy;\n};\n/** @internal */\nexport const sync = value => {\n  return suspend(() => succeed(value()));\n};\n/** @internal */\nexport const hashMap = (config, name) => {\n  const table = Object.create(proto);\n  table._tag = OpCodes.OP_HASHMAP;\n  table.valueConfig = config;\n  return name === undefined ? table : nested(table, name);\n};\n/** @internal */\nexport const isConfig = u => hasProperty(u, ConfigTypeId);\n/** @internal */\nconst tuple = tuple => {\n  if (tuple.length === 0) {\n    return succeed([]);\n  }\n  if (tuple.length === 1) {\n    return map(tuple[0], x => [x]);\n  }\n  let result = map(tuple[0], x => [x]);\n  for (let i = 1; i < tuple.length; i++) {\n    const config = tuple[i];\n    result = pipe(result, zipWith(config, (tuple, value) => [...tuple, value]));\n  }\n  return result;\n};\n/**\n * @internal\n */\nexport const unwrap = wrapped => {\n  if (isConfig(wrapped)) {\n    return wrapped;\n  }\n  return struct(Object.fromEntries(Object.entries(wrapped).map(([k, a]) => [k, unwrap(a)])));\n};\n/** @internal */\nexport const validate = /*#__PURE__*/dual(2, (self, {\n  message,\n  validation\n}) => mapOrFail(self, a => {\n  if (validation(a)) {\n    return Either.right(a);\n  }\n  return Either.left(configError.InvalidData([], message));\n}));\n/** @internal */\nexport const withDefault = /*#__PURE__*/dual(2, (self, def) => orElseIf(self, {\n  orElse: () => succeed(def),\n  if: ConfigError.isMissingDataOnly\n}));\n/** @internal */\nexport const withDescription = /*#__PURE__*/dual(2, (self, description) => {\n  const described = Object.create(proto);\n  described._tag = OpCodes.OP_DESCRIBED;\n  described.config = self;\n  described.description = description;\n  return described;\n});\n/** @internal */\nexport const zip = /*#__PURE__*/dual(2, (self, that) => zipWith(self, that, (a, b) => [a, b]));\n/** @internal */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => {\n  const zipWith = Object.create(proto);\n  zipWith._tag = OpCodes.OP_ZIP_WITH;\n  zipWith.left = self;\n  zipWith.right = that;\n  zipWith.zip = f;\n  return zipWith;\n});\n//# sourceMappingURL=config.js.map","import * as RA from \"../Array.js\";\nimport * as Either from \"../Either.js\";\nimport { constFalse, constTrue, dual, pipe } from \"../Function.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as OpCodes from \"./opCodes/configError.js\";\n/** @internal */\nconst ConfigErrorSymbolKey = \"effect/ConfigError\";\n/** @internal */\nexport const ConfigErrorTypeId = /*#__PURE__*/Symbol.for(ConfigErrorSymbolKey);\n/** @internal */\nexport const proto = {\n  _tag: \"ConfigError\",\n  [ConfigErrorTypeId]: ConfigErrorTypeId\n};\n/** @internal */\nexport const And = (self, that) => {\n  const error = Object.create(proto);\n  error._op = OpCodes.OP_AND;\n  error.left = self;\n  error.right = that;\n  Object.defineProperty(error, \"toString\", {\n    enumerable: false,\n    value() {\n      return `${this.left} and ${this.right}`;\n    }\n  });\n  return error;\n};\n/** @internal */\nexport const Or = (self, that) => {\n  const error = Object.create(proto);\n  error._op = OpCodes.OP_OR;\n  error.left = self;\n  error.right = that;\n  Object.defineProperty(error, \"toString\", {\n    enumerable: false,\n    value() {\n      return `${this.left} or ${this.right}`;\n    }\n  });\n  return error;\n};\n/** @internal */\nexport const InvalidData = (path, message, options = {\n  pathDelim: \".\"\n}) => {\n  const error = Object.create(proto);\n  error._op = OpCodes.OP_INVALID_DATA;\n  error.path = path;\n  error.message = message;\n  Object.defineProperty(error, \"toString\", {\n    enumerable: false,\n    value() {\n      const path = pipe(this.path, RA.join(options.pathDelim));\n      return `(Invalid data at ${path}: \"${this.message}\")`;\n    }\n  });\n  return error;\n};\n/** @internal */\nexport const MissingData = (path, message, options = {\n  pathDelim: \".\"\n}) => {\n  const error = Object.create(proto);\n  error._op = OpCodes.OP_MISSING_DATA;\n  error.path = path;\n  error.message = message;\n  Object.defineProperty(error, \"toString\", {\n    enumerable: false,\n    value() {\n      const path = pipe(this.path, RA.join(options.pathDelim));\n      return `(Missing data at ${path}: \"${this.message}\")`;\n    }\n  });\n  return error;\n};\n/** @internal */\nexport const SourceUnavailable = (path, message, cause, options = {\n  pathDelim: \".\"\n}) => {\n  const error = Object.create(proto);\n  error._op = OpCodes.OP_SOURCE_UNAVAILABLE;\n  error.path = path;\n  error.message = message;\n  error.cause = cause;\n  Object.defineProperty(error, \"toString\", {\n    enumerable: false,\n    value() {\n      const path = pipe(this.path, RA.join(options.pathDelim));\n      return `(Source unavailable at ${path}: \"${this.message}\")`;\n    }\n  });\n  return error;\n};\n/** @internal */\nexport const Unsupported = (path, message, options = {\n  pathDelim: \".\"\n}) => {\n  const error = Object.create(proto);\n  error._op = OpCodes.OP_UNSUPPORTED;\n  error.path = path;\n  error.message = message;\n  Object.defineProperty(error, \"toString\", {\n    enumerable: false,\n    value() {\n      const path = pipe(this.path, RA.join(options.pathDelim));\n      return `(Unsupported operation at ${path}: \"${this.message}\")`;\n    }\n  });\n  return error;\n};\n/** @internal */\nexport const isConfigError = u => hasProperty(u, ConfigErrorTypeId);\n/** @internal */\nexport const isAnd = self => self._op === OpCodes.OP_AND;\n/** @internal */\nexport const isOr = self => self._op === OpCodes.OP_OR;\n/** @internal */\nexport const isInvalidData = self => self._op === OpCodes.OP_INVALID_DATA;\n/** @internal */\nexport const isMissingData = self => self._op === OpCodes.OP_MISSING_DATA;\n/** @internal */\nexport const isSourceUnavailable = self => self._op === OpCodes.OP_SOURCE_UNAVAILABLE;\n/** @internal */\nexport const isUnsupported = self => self._op === OpCodes.OP_UNSUPPORTED;\n/** @internal */\nexport const prefixed = /*#__PURE__*/dual(2, (self, prefix) => {\n  switch (self._op) {\n    case OpCodes.OP_AND:\n      {\n        return And(prefixed(self.left, prefix), prefixed(self.right, prefix));\n      }\n    case OpCodes.OP_OR:\n      {\n        return Or(prefixed(self.left, prefix), prefixed(self.right, prefix));\n      }\n    case OpCodes.OP_INVALID_DATA:\n      {\n        return InvalidData([...prefix, ...self.path], self.message);\n      }\n    case OpCodes.OP_MISSING_DATA:\n      {\n        return MissingData([...prefix, ...self.path], self.message);\n      }\n    case OpCodes.OP_SOURCE_UNAVAILABLE:\n      {\n        return SourceUnavailable([...prefix, ...self.path], self.message, self.cause);\n      }\n    case OpCodes.OP_UNSUPPORTED:\n      {\n        return Unsupported([...prefix, ...self.path], self.message);\n      }\n  }\n});\n/** @internal */\nconst IsMissingDataOnlyReducer = {\n  andCase: (_, left, right) => left && right,\n  orCase: (_, left, right) => left && right,\n  invalidDataCase: constFalse,\n  missingDataCase: constTrue,\n  sourceUnavailableCase: constFalse,\n  unsupportedCase: constFalse\n};\n/** @internal */\nexport const reduceWithContext = /*#__PURE__*/dual(3, (self, context, reducer) => {\n  const input = [self];\n  const output = [];\n  while (input.length > 0) {\n    const error = input.pop();\n    switch (error._op) {\n      case OpCodes.OP_AND:\n        {\n          input.push(error.right);\n          input.push(error.left);\n          output.push(Either.left({\n            _op: \"AndCase\"\n          }));\n          break;\n        }\n      case OpCodes.OP_OR:\n        {\n          input.push(error.right);\n          input.push(error.left);\n          output.push(Either.left({\n            _op: \"OrCase\"\n          }));\n          break;\n        }\n      case OpCodes.OP_INVALID_DATA:\n        {\n          output.push(Either.right(reducer.invalidDataCase(context, error.path, error.message)));\n          break;\n        }\n      case OpCodes.OP_MISSING_DATA:\n        {\n          output.push(Either.right(reducer.missingDataCase(context, error.path, error.message)));\n          break;\n        }\n      case OpCodes.OP_SOURCE_UNAVAILABLE:\n        {\n          output.push(Either.right(reducer.sourceUnavailableCase(context, error.path, error.message, error.cause)));\n          break;\n        }\n      case OpCodes.OP_UNSUPPORTED:\n        {\n          output.push(Either.right(reducer.unsupportedCase(context, error.path, error.message)));\n          break;\n        }\n    }\n  }\n  const accumulator = [];\n  while (output.length > 0) {\n    const either = output.pop();\n    switch (either._op) {\n      case \"Left\":\n        {\n          switch (either.left._op) {\n            case \"AndCase\":\n              {\n                const left = accumulator.pop();\n                const right = accumulator.pop();\n                const value = reducer.andCase(context, left, right);\n                accumulator.push(value);\n                break;\n              }\n            case \"OrCase\":\n              {\n                const left = accumulator.pop();\n                const right = accumulator.pop();\n                const value = reducer.orCase(context, left, right);\n                accumulator.push(value);\n                break;\n              }\n          }\n          break;\n        }\n      case \"Right\":\n        {\n          accumulator.push(either.right);\n          break;\n        }\n    }\n  }\n  if (accumulator.length === 0) {\n    throw new Error(\"BUG: ConfigError.reduceWithContext - please report an issue at https://github.com/Effect-TS/effect/issues\");\n  }\n  return accumulator.pop();\n});\n/** @internal */\nexport const isMissingDataOnly = self => reduceWithContext(self, void 0, IsMissingDataOnlyReducer);\n//# sourceMappingURL=configError.js.map","import * as Arr from \"../Array.js\";\nimport * as Context from \"../Context.js\";\nimport * as Either from \"../Either.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport * as number from \"../Number.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport * as regexp from \"../RegExp.js\";\nimport * as configError from \"./configError.js\";\nimport * as pathPatch from \"./configProvider/pathPatch.js\";\nimport * as core from \"./core.js\";\nimport * as OpCodes from \"./opCodes/config.js\";\nimport * as StringUtils from \"./string-utils.js\";\nconst concat = (l, r) => [...l, ...r];\n/** @internal */\nconst ConfigProviderSymbolKey = \"effect/ConfigProvider\";\n/** @internal */\nexport const ConfigProviderTypeId = /*#__PURE__*/Symbol.for(ConfigProviderSymbolKey);\n/** @internal */\nexport const configProviderTag = /*#__PURE__*/Context.GenericTag(\"effect/ConfigProvider\");\n/** @internal */\nconst FlatConfigProviderSymbolKey = \"effect/ConfigProviderFlat\";\n/** @internal */\nexport const FlatConfigProviderTypeId = /*#__PURE__*/Symbol.for(FlatConfigProviderSymbolKey);\n/** @internal */\nexport const make = options => ({\n  [ConfigProviderTypeId]: ConfigProviderTypeId,\n  pipe() {\n    return pipeArguments(this, arguments);\n  },\n  ...options\n});\n/** @internal */\nexport const makeFlat = options => ({\n  [FlatConfigProviderTypeId]: FlatConfigProviderTypeId,\n  patch: options.patch,\n  load: (path, config, split = true) => options.load(path, config, split),\n  enumerateChildren: options.enumerateChildren\n});\n/** @internal */\nexport const fromFlat = flat => make({\n  load: config => core.flatMap(fromFlatLoop(flat, Arr.empty(), config, false), chunk => Option.match(Arr.head(chunk), {\n    onNone: () => core.fail(configError.MissingData(Arr.empty(), `Expected a single value having structure: ${config}`)),\n    onSome: core.succeed\n  })),\n  flattened: flat\n});\n/** @internal */\nexport const fromEnv = config => {\n  const {\n    pathDelim,\n    seqDelim\n  } = Object.assign({}, {\n    pathDelim: \"_\",\n    seqDelim: \",\"\n  }, config);\n  const makePathString = path => pipe(path, Arr.join(pathDelim));\n  const unmakePathString = pathString => pathString.split(pathDelim);\n  const getEnv = () => typeof process !== \"undefined\" && \"env\" in process && typeof process.env === \"object\" ? process.env : {};\n  const load = (path, primitive, split = true) => {\n    const pathString = makePathString(path);\n    const current = getEnv();\n    const valueOpt = pathString in current ? Option.some(current[pathString]) : Option.none();\n    return pipe(valueOpt, core.mapError(() => configError.MissingData(path, `Expected ${pathString} to exist in the process context`)), core.flatMap(value => parsePrimitive(value, path, primitive, seqDelim, split)));\n  };\n  const enumerateChildren = path => core.sync(() => {\n    const current = getEnv();\n    const keys = Object.keys(current);\n    const keyPaths = keys.map(value => unmakePathString(value.toUpperCase()));\n    const filteredKeyPaths = keyPaths.filter(keyPath => {\n      for (let i = 0; i < path.length; i++) {\n        const pathComponent = pipe(path, Arr.unsafeGet(i));\n        const currentElement = keyPath[i];\n        if (currentElement === undefined || pathComponent !== currentElement) {\n          return false;\n        }\n      }\n      return true;\n    }).flatMap(keyPath => keyPath.slice(path.length, path.length + 1));\n    return HashSet.fromIterable(filteredKeyPaths);\n  });\n  return fromFlat(makeFlat({\n    load,\n    enumerateChildren,\n    patch: pathPatch.empty\n  }));\n};\n/** @internal */\nexport const fromMap = (map, config) => {\n  const {\n    pathDelim,\n    seqDelim\n  } = Object.assign({\n    seqDelim: \",\",\n    pathDelim: \".\"\n  }, config);\n  const makePathString = path => pipe(path, Arr.join(pathDelim));\n  const unmakePathString = pathString => pathString.split(pathDelim);\n  const mapWithIndexSplit = splitIndexInKeys(map, str => unmakePathString(str), makePathString);\n  const load = (path, primitive, split = true) => {\n    const pathString = makePathString(path);\n    const valueOpt = mapWithIndexSplit.has(pathString) ? Option.some(mapWithIndexSplit.get(pathString)) : Option.none();\n    return pipe(valueOpt, core.mapError(() => configError.MissingData(path, `Expected ${pathString} to exist in the provided map`)), core.flatMap(value => parsePrimitive(value, path, primitive, seqDelim, split)));\n  };\n  const enumerateChildren = path => core.sync(() => {\n    const keyPaths = Arr.fromIterable(mapWithIndexSplit.keys()).map(unmakePathString);\n    const filteredKeyPaths = keyPaths.filter(keyPath => {\n      for (let i = 0; i < path.length; i++) {\n        const pathComponent = pipe(path, Arr.unsafeGet(i));\n        const currentElement = keyPath[i];\n        if (currentElement === undefined || pathComponent !== currentElement) {\n          return false;\n        }\n      }\n      return true;\n    }).flatMap(keyPath => keyPath.slice(path.length, path.length + 1));\n    return HashSet.fromIterable(filteredKeyPaths);\n  });\n  return fromFlat(makeFlat({\n    load,\n    enumerateChildren,\n    patch: pathPatch.empty\n  }));\n};\nconst extend = (leftDef, rightDef, left, right) => {\n  const leftPad = Arr.unfold(left.length, index => index >= right.length ? Option.none() : Option.some([leftDef(index), index + 1]));\n  const rightPad = Arr.unfold(right.length, index => index >= left.length ? Option.none() : Option.some([rightDef(index), index + 1]));\n  const leftExtension = concat(left, leftPad);\n  const rightExtension = concat(right, rightPad);\n  return [leftExtension, rightExtension];\n};\nconst appendConfigPath = (path, config) => {\n  let op = config;\n  if (op._tag === \"Nested\") {\n    const out = path.slice();\n    while (op._tag === \"Nested\") {\n      out.push(op.name);\n      op = op.config;\n    }\n    return out;\n  }\n  return path;\n};\nconst fromFlatLoop = (flat, prefix, config, split) => {\n  const op = config;\n  switch (op._tag) {\n    case OpCodes.OP_CONSTANT:\n      {\n        return core.succeed(Arr.of(op.value));\n      }\n    case OpCodes.OP_DESCRIBED:\n      {\n        return core.suspend(() => fromFlatLoop(flat, prefix, op.config, split));\n      }\n    case OpCodes.OP_FAIL:\n      {\n        return core.fail(configError.MissingData(prefix, op.message));\n      }\n    case OpCodes.OP_FALLBACK:\n      {\n        return pipe(core.suspend(() => fromFlatLoop(flat, prefix, op.first, split)), core.catchAll(error1 => {\n          if (op.condition(error1)) {\n            return pipe(fromFlatLoop(flat, prefix, op.second, split), core.catchAll(error2 => core.fail(configError.Or(error1, error2))));\n          }\n          return core.fail(error1);\n        }));\n      }\n    case OpCodes.OP_LAZY:\n      {\n        return core.suspend(() => fromFlatLoop(flat, prefix, op.config(), split));\n      }\n    case OpCodes.OP_MAP_OR_FAIL:\n      {\n        return core.suspend(() => pipe(fromFlatLoop(flat, prefix, op.original, split), core.flatMap(core.forEachSequential(a => pipe(op.mapOrFail(a), core.mapError(configError.prefixed(appendConfigPath(prefix, op.original))))))));\n      }\n    case OpCodes.OP_NESTED:\n      {\n        return core.suspend(() => fromFlatLoop(flat, concat(prefix, Arr.of(op.name)), op.config, split));\n      }\n    case OpCodes.OP_PRIMITIVE:\n      {\n        return pipe(pathPatch.patch(prefix, flat.patch), core.flatMap(prefix => pipe(flat.load(prefix, op, split), core.flatMap(values => {\n          if (values.length === 0) {\n            const name = pipe(Arr.last(prefix), Option.getOrElse(() => \"<n/a>\"));\n            return core.fail(configError.MissingData([], `Expected ${op.description} with name ${name}`));\n          }\n          return core.succeed(values);\n        }))));\n      }\n    case OpCodes.OP_SEQUENCE:\n      {\n        return pipe(pathPatch.patch(prefix, flat.patch), core.flatMap(patchedPrefix => pipe(flat.enumerateChildren(patchedPrefix), core.flatMap(indicesFrom), core.flatMap(indices => {\n          if (indices.length === 0) {\n            return core.suspend(() => core.map(fromFlatLoop(flat, patchedPrefix, op.config, true), Arr.of));\n          }\n          return pipe(core.forEachSequential(indices, index => fromFlatLoop(flat, Arr.append(prefix, `[${index}]`), op.config, true)), core.map(chunkChunk => {\n            const flattened = Arr.flatten(chunkChunk);\n            if (flattened.length === 0) {\n              return Arr.of(Arr.empty());\n            }\n            return Arr.of(flattened);\n          }));\n        }))));\n      }\n    case OpCodes.OP_HASHMAP:\n      {\n        return core.suspend(() => pipe(pathPatch.patch(prefix, flat.patch), core.flatMap(prefix => pipe(flat.enumerateChildren(prefix), core.flatMap(keys => {\n          return pipe(keys, core.forEachSequential(key => fromFlatLoop(flat, concat(prefix, Arr.of(key)), op.valueConfig, split)), core.map(matrix => {\n            if (matrix.length === 0) {\n              return Arr.of(HashMap.empty());\n            }\n            return pipe(transpose(matrix), Arr.map(values => HashMap.fromIterable(Arr.zip(Arr.fromIterable(keys), values))));\n          }));\n        })))));\n      }\n    case OpCodes.OP_ZIP_WITH:\n      {\n        return core.suspend(() => pipe(fromFlatLoop(flat, prefix, op.left, split), core.either, core.flatMap(left => pipe(fromFlatLoop(flat, prefix, op.right, split), core.either, core.flatMap(right => {\n          if (Either.isLeft(left) && Either.isLeft(right)) {\n            return core.fail(configError.And(left.left, right.left));\n          }\n          if (Either.isLeft(left) && Either.isRight(right)) {\n            return core.fail(left.left);\n          }\n          if (Either.isRight(left) && Either.isLeft(right)) {\n            return core.fail(right.left);\n          }\n          if (Either.isRight(left) && Either.isRight(right)) {\n            const path = pipe(prefix, Arr.join(\".\"));\n            const fail = fromFlatLoopFail(prefix, path);\n            const [lefts, rights] = extend(fail, fail, pipe(left.right, Arr.map(Either.right)), pipe(right.right, Arr.map(Either.right)));\n            return pipe(lefts, Arr.zip(rights), core.forEachSequential(([left, right]) => pipe(core.zip(left, right), core.map(([left, right]) => op.zip(left, right)))));\n          }\n          throw new Error(\"BUG: ConfigProvider.fromFlatLoop - please report an issue at https://github.com/Effect-TS/effect/issues\");\n        })))));\n      }\n  }\n};\nconst fromFlatLoopFail = (prefix, path) => index => Either.left(configError.MissingData(prefix, `The element at index ${index} in a sequence at path \"${path}\" was missing`));\n/** @internal */\nexport const mapInputPath = /*#__PURE__*/dual(2, (self, f) => fromFlat(mapInputPathFlat(self.flattened, f)));\nconst mapInputPathFlat = (self, f) => makeFlat({\n  load: (path, config, split = true) => self.load(path, config, split),\n  enumerateChildren: path => self.enumerateChildren(path),\n  patch: pathPatch.mapName(self.patch, f)\n});\n/** @internal */\nexport const nested = /*#__PURE__*/dual(2, (self, name) => fromFlat(makeFlat({\n  load: (path, config) => self.flattened.load(path, config, true),\n  enumerateChildren: path => self.flattened.enumerateChildren(path),\n  patch: pathPatch.nested(self.flattened.patch, name)\n})));\n/** @internal */\nexport const unnested = /*#__PURE__*/dual(2, (self, name) => fromFlat(makeFlat({\n  load: (path, config) => self.flattened.load(path, config, true),\n  enumerateChildren: path => self.flattened.enumerateChildren(path),\n  patch: pathPatch.unnested(self.flattened.patch, name)\n})));\n/** @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => fromFlat(orElseFlat(self.flattened, () => that().flattened)));\nconst orElseFlat = (self, that) => makeFlat({\n  load: (path, config, split) => pipe(pathPatch.patch(path, self.patch), core.flatMap(patch => self.load(patch, config, split)), core.catchAll(error1 => pipe(core.sync(that), core.flatMap(that => pipe(pathPatch.patch(path, that.patch), core.flatMap(patch => that.load(patch, config, split)), core.catchAll(error2 => core.fail(configError.Or(error1, error2)))))))),\n  enumerateChildren: path => pipe(pathPatch.patch(path, self.patch), core.flatMap(patch => self.enumerateChildren(patch)), core.either, core.flatMap(left => pipe(core.sync(that), core.flatMap(that => pipe(pathPatch.patch(path, that.patch), core.flatMap(patch => that.enumerateChildren(patch)), core.either, core.flatMap(right => {\n    if (Either.isLeft(left) && Either.isLeft(right)) {\n      return core.fail(configError.And(left.left, right.left));\n    }\n    if (Either.isLeft(left) && Either.isRight(right)) {\n      return core.succeed(right.right);\n    }\n    if (Either.isRight(left) && Either.isLeft(right)) {\n      return core.succeed(left.right);\n    }\n    if (Either.isRight(left) && Either.isRight(right)) {\n      return core.succeed(pipe(left.right, HashSet.union(right.right)));\n    }\n    throw new Error(\"BUG: ConfigProvider.orElseFlat - please report an issue at https://github.com/Effect-TS/effect/issues\");\n  })))))),\n  patch: pathPatch.empty\n});\n/** @internal */\nexport const constantCase = self => mapInputPath(self, StringUtils.constantCase);\n/** @internal */\nexport const kebabCase = self => mapInputPath(self, StringUtils.kebabCase);\n/** @internal */\nexport const lowerCase = self => mapInputPath(self, StringUtils.lowerCase);\n/** @internal */\nexport const snakeCase = self => mapInputPath(self, StringUtils.snakeCase);\n/** @internal */\nexport const upperCase = self => mapInputPath(self, StringUtils.upperCase);\n/** @internal */\nexport const within = /*#__PURE__*/dual(3, (self, path, f) => {\n  const unnest = Arr.reduce(path, self, (provider, name) => unnested(provider, name));\n  const nest = Arr.reduceRight(path, f(unnest), (provider, name) => nested(provider, name));\n  return orElse(nest, () => self);\n});\nconst splitPathString = (text, delim) => {\n  const split = text.split(new RegExp(`\\\\s*${regexp.escape(delim)}\\\\s*`));\n  return split;\n};\nconst parsePrimitive = (text, path, primitive, delimiter, split) => {\n  if (!split) {\n    return pipe(primitive.parse(text), core.mapBoth({\n      onFailure: configError.prefixed(path),\n      onSuccess: Arr.of\n    }));\n  }\n  return pipe(splitPathString(text, delimiter), core.forEachSequential(char => primitive.parse(char.trim())), core.mapError(configError.prefixed(path)));\n};\nconst transpose = array => {\n  return Object.keys(array[0]).map(column => array.map(row => row[column]));\n};\nconst indicesFrom = quotedIndices => pipe(core.forEachSequential(quotedIndices, parseQuotedIndex), core.mapBoth({\n  onFailure: () => Arr.empty(),\n  onSuccess: Arr.sort(number.Order)\n}), core.either, core.map(Either.merge));\nconst STR_INDEX_REGEX = /(^.+)(\\[(\\d+)\\])$/;\nconst QUOTED_INDEX_REGEX = /^(\\[(\\d+)\\])$/;\nconst parseQuotedIndex = str => {\n  const match = str.match(QUOTED_INDEX_REGEX);\n  if (match !== null) {\n    const matchedIndex = match[2];\n    return pipe(matchedIndex !== undefined && matchedIndex.length > 0 ? Option.some(matchedIndex) : Option.none(), Option.flatMap(parseInteger));\n  }\n  return Option.none();\n};\nconst splitIndexInKeys = (map, unmakePathString, makePathString) => {\n  const newMap = new Map();\n  for (const [pathString, value] of map) {\n    const keyWithIndex = pipe(unmakePathString(pathString), Arr.flatMap(key => Option.match(splitIndexFrom(key), {\n      onNone: () => Arr.of(key),\n      onSome: ([key, index]) => Arr.make(key, `[${index}]`)\n    })));\n    newMap.set(makePathString(keyWithIndex), value);\n  }\n  return newMap;\n};\nconst splitIndexFrom = key => {\n  const match = key.match(STR_INDEX_REGEX);\n  if (match !== null) {\n    const matchedString = match[1];\n    const matchedIndex = match[3];\n    const optionalString = matchedString !== undefined && matchedString.length > 0 ? Option.some(matchedString) : Option.none();\n    const optionalIndex = pipe(matchedIndex !== undefined && matchedIndex.length > 0 ? Option.some(matchedIndex) : Option.none(), Option.flatMap(parseInteger));\n    return Option.all([optionalString, optionalIndex]);\n  }\n  return Option.none();\n};\nconst parseInteger = str => {\n  const parsedIndex = Number.parseInt(str);\n  return Number.isNaN(parsedIndex) ? Option.none() : Option.some(parsedIndex);\n};\nconst keyName = name => ({\n  _tag: \"KeyName\",\n  name\n});\nconst keyIndex = index => ({\n  _tag: \"KeyIndex\",\n  index\n});\n/** @internal */\nexport const fromJson = json => {\n  const hiddenDelimiter = \"\\ufeff\";\n  const indexedEntries = Arr.map(getIndexedEntries(json), ([key, value]) => [configPathToString(key).join(hiddenDelimiter), value]);\n  return fromMap(new Map(indexedEntries), {\n    pathDelim: hiddenDelimiter,\n    seqDelim: hiddenDelimiter\n  });\n};\nconst configPathToString = path => {\n  const output = [];\n  let i = 0;\n  while (i < path.length) {\n    const component = path[i];\n    if (component._tag === \"KeyName\") {\n      if (i + 1 < path.length) {\n        const nextComponent = path[i + 1];\n        if (nextComponent._tag === \"KeyIndex\") {\n          output.push(`${component.name}[${nextComponent.index}]`);\n          i += 2;\n        } else {\n          output.push(component.name);\n          i += 1;\n        }\n      } else {\n        output.push(component.name);\n        i += 1;\n      }\n    }\n  }\n  return output;\n};\nconst getIndexedEntries = config => {\n  const loopAny = (path, value) => {\n    if (typeof value === \"string\") {\n      return Arr.make([path, value]);\n    }\n    if (typeof value === \"number\" || typeof value === \"boolean\") {\n      return Arr.make([path, String(value)]);\n    }\n    if (Arr.isArray(value)) {\n      return loopArray(path, value);\n    }\n    if (typeof value === \"object\" && value !== null) {\n      return loopObject(path, value);\n    }\n    return Arr.empty();\n  };\n  const loopArray = (path, values) => Arr.match(values, {\n    onEmpty: () => Arr.make([path, \"<nil>\"]),\n    onNonEmpty: Arr.flatMap((value, index) => loopAny(Arr.append(path, keyIndex(index)), value))\n  });\n  const loopObject = (path, value) => Object.entries(value).flatMap(([key, value]) => {\n    const newPath = Arr.append(path, keyName(key));\n    const result = loopAny(newPath, value);\n    if (Arr.isEmptyReadonlyArray(result)) {\n      return Arr.make([newPath, \"\"]);\n    }\n    return result;\n  });\n  return loopObject(Arr.empty(), config);\n};\n//# sourceMappingURL=configProvider.js.map","import * as RA from \"../../Array.js\";\nimport * as Either from \"../../Either.js\";\nimport { dual, pipe } from \"../../Function.js\";\nimport * as List from \"../../List.js\";\nimport * as Option from \"../../Option.js\";\nimport * as configError from \"../configError.js\";\n/** @internal */\nexport const empty = {\n  _tag: \"Empty\"\n};\n/** @internal */\nexport const andThen = /*#__PURE__*/dual(2, (self, that) => ({\n  _tag: \"AndThen\",\n  first: self,\n  second: that\n}));\n/** @internal */\nexport const mapName = /*#__PURE__*/dual(2, (self, f) => andThen(self, {\n  _tag: \"MapName\",\n  f\n}));\n/** @internal */\nexport const nested = /*#__PURE__*/dual(2, (self, name) => andThen(self, {\n  _tag: \"Nested\",\n  name\n}));\n/** @internal */\nexport const unnested = /*#__PURE__*/dual(2, (self, name) => andThen(self, {\n  _tag: \"Unnested\",\n  name\n}));\n/** @internal */\nexport const patch = /*#__PURE__*/dual(2, (path, patch) => {\n  let input = List.of(patch);\n  let output = path;\n  while (List.isCons(input)) {\n    const patch = input.head;\n    switch (patch._tag) {\n      case \"Empty\":\n        {\n          input = input.tail;\n          break;\n        }\n      case \"AndThen\":\n        {\n          input = List.cons(patch.first, List.cons(patch.second, input.tail));\n          break;\n        }\n      case \"MapName\":\n        {\n          output = RA.map(output, patch.f);\n          input = input.tail;\n          break;\n        }\n      case \"Nested\":\n        {\n          output = RA.prepend(output, patch.name);\n          input = input.tail;\n          break;\n        }\n      case \"Unnested\":\n        {\n          const containsName = pipe(RA.head(output), Option.contains(patch.name));\n          if (containsName) {\n            output = RA.tailNonEmpty(output);\n            input = input.tail;\n          } else {\n            return Either.left(configError.MissingData(output, `Expected ${patch.name} to be in path in ConfigProvider#unnested`));\n          }\n          break;\n        }\n    }\n  }\n  return Either.right(output);\n});\n//# sourceMappingURL=pathPatch.js.map","import * as Context from \"../Context.js\";\nimport { dual } from \"../Function.js\";\nimport * as core from \"./core.js\";\nimport * as defaultServices from \"./defaultServices.js\";\nimport * as defaultConsole from \"./defaultServices/console.js\";\nimport * as fiberRuntime from \"./fiberRuntime.js\";\nimport * as layer from \"./layer.js\";\n/** @internal */\nexport const console = /*#__PURE__*/core.map( /*#__PURE__*/core.fiberRefGet(defaultServices.currentServices), /*#__PURE__*/Context.get(defaultConsole.consoleTag));\n/** @internal */\nexport const consoleWith = f => core.fiberRefGetWith(defaultServices.currentServices, services => f(Context.get(services, defaultConsole.consoleTag)));\n/** @internal */\nexport const withConsole = /*#__PURE__*/dual(2, (effect, value) => core.fiberRefLocallyWith(effect, defaultServices.currentServices, Context.add(defaultConsole.consoleTag, value)));\n/** @internal */\nexport const withConsoleScoped = console => fiberRuntime.fiberRefLocallyScopedWith(defaultServices.currentServices, Context.add(defaultConsole.consoleTag, console));\n/** @internal */\nexport const setConsole = console => layer.scopedDiscard(fiberRuntime.fiberRefLocallyScopedWith(defaultServices.currentServices, Context.add(defaultConsole.consoleTag, console)));\n/** @internal */\nexport const assert = (condition, ...args) => consoleWith(_ => _.assert(condition, ...args));\n/** @internal */\nexport const clear = /*#__PURE__*/consoleWith(_ => _.clear);\n/** @internal */\nexport const count = label => consoleWith(_ => _.count(label));\n/** @internal */\nexport const countReset = label => consoleWith(_ => _.countReset(label));\n/** @internal */\nexport const debug = (...args) => consoleWith(_ => _.debug(...args));\n/** @internal */\nexport const dir = (item, options) => consoleWith(_ => _.dir(item, options));\n/** @internal */\nexport const dirxml = (...args) => consoleWith(_ => _.dirxml(...args));\n/** @internal */\nexport const error = (...args) => consoleWith(_ => _.error(...args));\n/** @internal */\nexport const group = options => consoleWith(_ => fiberRuntime.acquireRelease(_.group(options), () => _.groupEnd));\n/** @internal */\nexport const info = (...args) => consoleWith(_ => _.info(...args));\n/** @internal */\nexport const log = (...args) => consoleWith(_ => _.log(...args));\n/** @internal */\nexport const table = (tabularData, properties) => consoleWith(_ => _.table(tabularData, properties));\n/** @internal */\nexport const time = label => consoleWith(_ => fiberRuntime.acquireRelease(_.time(label), () => _.timeEnd(label)));\n/** @internal */\nexport const timeLog = (label, ...args) => consoleWith(_ => _.timeLog(label, ...args));\n/** @internal */\nexport const trace = (...args) => consoleWith(_ => _.trace(...args));\n/** @internal */\nexport const warn = (...args) => consoleWith(_ => _.warn(...args));\n/** @internal */\nexport const withGroup = /*#__PURE__*/dual(args => core.isEffect(args[0]), (self, options) => consoleWith(_ => core.acquireUseRelease(_.group(options), () => self, () => _.groupEnd)));\n/** @internal */\nexport const withTime = /*#__PURE__*/dual(args => core.isEffect(args[0]), (self, label) => consoleWith(_ => core.acquireUseRelease(_.time(label), () => self, () => _.timeEnd(label))));\n//# sourceMappingURL=console.js.map","import * as Equal from \"../Equal.js\";\nimport { dual } from \"../Function.js\";\nimport * as Hash from \"../Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport { EffectPrototype, effectVariance } from \"./effectable.js\";\nimport * as option from \"./option.js\";\n/** @internal */\nexport const TagTypeId = /*#__PURE__*/Symbol.for(\"effect/Context/Tag\");\n/** @internal */\nconst STMSymbolKey = \"effect/STM\";\n/** @internal */\nexport const STMTypeId = /*#__PURE__*/Symbol.for(STMSymbolKey);\n/** @internal */\nexport const TagProto = {\n  ...EffectPrototype,\n  _tag: \"Tag\",\n  _op: \"Tag\",\n  [STMTypeId]: effectVariance,\n  [TagTypeId]: {\n    _Service: _ => _,\n    _Identifier: _ => _\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"Tag\",\n      key: this.key,\n      stack: this.stack\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  of(self) {\n    return self;\n  },\n  context(self) {\n    return make(this, self);\n  }\n};\n/** @internal */\nexport const makeGenericTag = key => {\n  const limit = Error.stackTraceLimit;\n  Error.stackTraceLimit = 2;\n  const creationError = new Error();\n  Error.stackTraceLimit = limit;\n  const tag = Object.create(TagProto);\n  Object.defineProperty(tag, \"stack\", {\n    get() {\n      return creationError.stack;\n    }\n  });\n  tag.key = key;\n  return tag;\n};\n/** @internal */\nexport const Tag = id => () => {\n  const limit = Error.stackTraceLimit;\n  Error.stackTraceLimit = 2;\n  const creationError = new Error();\n  Error.stackTraceLimit = limit;\n  function TagClass() {}\n  Object.setPrototypeOf(TagClass, TagProto);\n  TagClass.key = id;\n  Object.defineProperty(TagClass, \"stack\", {\n    get() {\n      return creationError.stack;\n    }\n  });\n  return TagClass;\n};\n/** @internal */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/Context\");\n/** @internal */\nexport const ContextProto = {\n  [TypeId]: {\n    _Services: _ => _\n  },\n  [Equal.symbol](that) {\n    if (isContext(that)) {\n      if (this.unsafeMap.size === that.unsafeMap.size) {\n        for (const k of this.unsafeMap.keys()) {\n          if (!that.unsafeMap.has(k) || !Equal.equals(this.unsafeMap.get(k), that.unsafeMap.get(k))) {\n            return false;\n          }\n        }\n        return true;\n      }\n    }\n    return false;\n  },\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.number(this.unsafeMap.size));\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"Context\",\n      services: Array.from(this.unsafeMap).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n};\n/** @internal */\nexport const makeContext = unsafeMap => {\n  const context = Object.create(ContextProto);\n  context.unsafeMap = unsafeMap;\n  return context;\n};\nconst serviceNotFoundError = tag => {\n  const error = new Error(`Service not found${tag.key ? `: ${String(tag.key)}` : \"\"}`);\n  if (tag.stack) {\n    const lines = tag.stack.split(\"\\n\");\n    if (lines.length > 2) {\n      const afterAt = lines[2].match(/at (.*)/);\n      if (afterAt) {\n        error.message = error.message + ` (defined at ${afterAt[1]})`;\n      }\n    }\n  }\n  if (error.stack) {\n    const lines = error.stack.split(\"\\n\");\n    lines.splice(1, 3);\n    error.stack = lines.join(\"\\n\");\n  }\n  return error;\n};\n/** @internal */\nexport const isContext = u => hasProperty(u, TypeId);\n/** @internal */\nexport const isTag = u => hasProperty(u, TagTypeId);\nconst _empty = /*#__PURE__*/makeContext( /*#__PURE__*/new Map());\n/** @internal */\nexport const empty = () => _empty;\n/** @internal */\nexport const make = (tag, service) => makeContext(new Map([[tag.key, service]]));\n/** @internal */\nexport const add = /*#__PURE__*/dual(3, (self, tag, service) => {\n  const map = new Map(self.unsafeMap);\n  map.set(tag.key, service);\n  return makeContext(map);\n});\n/** @internal */\nexport const unsafeGet = /*#__PURE__*/dual(2, (self, tag) => {\n  if (!self.unsafeMap.has(tag.key)) {\n    throw serviceNotFoundError(tag);\n  }\n  return self.unsafeMap.get(tag.key);\n});\n/** @internal */\nexport const get = unsafeGet;\n/** @internal */\nexport const getOption = /*#__PURE__*/dual(2, (self, tag) => {\n  if (!self.unsafeMap.has(tag.key)) {\n    return option.none;\n  }\n  return option.some(self.unsafeMap.get(tag.key));\n});\n/** @internal */\nexport const merge = /*#__PURE__*/dual(2, (self, that) => {\n  const map = new Map(self.unsafeMap);\n  for (const [tag, s] of that.unsafeMap) {\n    map.set(tag, s);\n  }\n  return makeContext(map);\n});\n/** @internal */\nexport const pick = (...tags) => self => {\n  const tagSet = new Set(tags.map(_ => _.key));\n  const newEnv = new Map();\n  for (const [tag, s] of self.unsafeMap.entries()) {\n    if (tagSet.has(tag)) {\n      newEnv.set(tag, s);\n    }\n  }\n  return makeContext(newEnv);\n};\n/** @internal */\nexport const omit = (...tags) => self => {\n  const newEnv = new Map(self.unsafeMap);\n  for (const tag of tags) {\n    newEnv.delete(tag.key);\n  }\n  return makeContext(newEnv);\n};\n//# sourceMappingURL=context.js.map","import { internalCall } from \"effect/Utils\";\nimport * as Arr from \"../Array.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Clock from \"../Clock.js\";\nimport * as Context from \"../Context.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as FiberRefs from \"../FiberRefs.js\";\nimport { constFalse, constTrue, constVoid, dual, identity, pipe } from \"../Function.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport * as List from \"../List.js\";\nimport * as LogLevel from \"../LogLevel.js\";\nimport * as LogSpan from \"../LogSpan.js\";\nimport * as Option from \"../Option.js\";\nimport * as Predicate from \"../Predicate.js\";\nimport * as Ref from \"../Ref.js\";\nimport * as Tracer from \"../Tracer.js\";\nimport { yieldWrapGet } from \"../Utils.js\";\nimport * as internalCause from \"./cause.js\";\nimport { clockTag } from \"./clock.js\";\nimport * as core from \"./core.js\";\nimport * as defaultServices from \"./defaultServices.js\";\nimport * as doNotation from \"./doNotation.js\";\nimport * as fiberRefsPatch from \"./fiberRefs/patch.js\";\nimport * as metricLabel from \"./metric/label.js\";\nimport * as runtimeFlags from \"./runtimeFlags.js\";\nimport * as internalTracer from \"./tracer.js\";\n/* @internal */\nexport const annotateLogs = /*#__PURE__*/dual(args => core.isEffect(args[0]), function () {\n  const args = arguments;\n  return core.fiberRefLocallyWith(args[0], core.currentLogAnnotations, typeof args[1] === \"string\" ? HashMap.set(args[1], args[2]) : annotations => Object.entries(args[1]).reduce((acc, [key, value]) => HashMap.set(acc, key, value), annotations));\n});\n/* @internal */\nexport const asSome = self => core.map(self, Option.some);\n/* @internal */\nexport const asSomeError = self => core.mapError(self, Option.some);\n/* @internal */\nexport const try_ = arg => {\n  let evaluate;\n  let onFailure = undefined;\n  if (typeof arg === \"function\") {\n    evaluate = arg;\n  } else {\n    evaluate = arg.try;\n    onFailure = arg.catch;\n  }\n  return core.sync(() => {\n    try {\n      return evaluate();\n    } catch (error) {\n      throw core.makeEffectError(internalCause.fail(onFailure ? onFailure(error) : new core.UnknownException(error)));\n    }\n  });\n};\n/* @internal */\nexport const _catch = /*#__PURE__*/dual(3, (self, tag, options) => core.catchAll(self, e => {\n  if (Predicate.hasProperty(e, tag) && e[tag] === options.failure) {\n    return options.onFailure(e);\n  }\n  return core.fail(e);\n}));\n/* @internal */\nexport const catchAllDefect = /*#__PURE__*/dual(2, (self, f) => core.catchAllCause(self, cause => {\n  const option = internalCause.find(cause, _ => internalCause.isDieType(_) ? Option.some(_) : Option.none());\n  switch (option._tag) {\n    case \"None\":\n      {\n        return core.failCause(cause);\n      }\n    case \"Some\":\n      {\n        return f(option.value.defect);\n      }\n  }\n}));\n/* @internal */\nexport const catchSomeCause = /*#__PURE__*/dual(2, (self, f) => core.matchCauseEffect(self, {\n  onFailure: cause => {\n    const option = f(cause);\n    switch (option._tag) {\n      case \"None\":\n        {\n          return core.failCause(cause);\n        }\n      case \"Some\":\n        {\n          return option.value;\n        }\n    }\n  },\n  onSuccess: core.succeed\n}));\n/* @internal */\nexport const catchSomeDefect = /*#__PURE__*/dual(2, (self, pf) => core.catchAllCause(self, cause => {\n  const option = internalCause.find(cause, _ => internalCause.isDieType(_) ? Option.some(_) : Option.none());\n  switch (option._tag) {\n    case \"None\":\n      {\n        return core.failCause(cause);\n      }\n    case \"Some\":\n      {\n        const optionEffect = pf(option.value.defect);\n        return optionEffect._tag === \"Some\" ? optionEffect.value : core.failCause(cause);\n      }\n  }\n}));\n/* @internal */\nexport const catchTag = /*#__PURE__*/dual(3, (self, k, f) => core.catchIf(self, Predicate.isTagged(k), f));\n/** @internal */\nexport const catchTags = /*#__PURE__*/dual(2, (self, cases) => {\n  let keys;\n  return core.catchIf(self, e => {\n    keys ??= Object.keys(cases);\n    return Predicate.hasProperty(e, \"_tag\") && Predicate.isString(e[\"_tag\"]) && keys.includes(e[\"_tag\"]);\n  }, e => cases[e[\"_tag\"]](e));\n});\n/* @internal */\nexport const cause = self => core.matchCause(self, {\n  onFailure: identity,\n  onSuccess: () => internalCause.empty\n});\n/* @internal */\nexport const clockWith = Clock.clockWith;\n/* @internal */\nexport const clock = /*#__PURE__*/clockWith(core.succeed);\n/* @internal */\nexport const delay = /*#__PURE__*/dual(2, (self, duration) => core.zipRight(Clock.sleep(duration), self));\n/* @internal */\nexport const descriptorWith = f => core.withFiberRuntime((state, status) => f({\n  id: state.id(),\n  status,\n  interruptors: internalCause.interruptors(state.getFiberRef(core.currentInterruptedCause))\n}));\n/* @internal */\nexport const allowInterrupt = /*#__PURE__*/descriptorWith(descriptor => HashSet.size(descriptor.interruptors) > 0 ? core.interrupt : core.void);\n/* @internal */\nexport const descriptor = /*#__PURE__*/descriptorWith(core.succeed);\n/* @internal */\nexport const diffFiberRefs = self => summarized(self, fiberRefs, fiberRefsPatch.diff);\n/* @internal */\nexport const diffFiberRefsAndRuntimeFlags = self => summarized(self, core.zip(fiberRefs, core.runtimeFlags), ([refs, flags], [refsNew, flagsNew]) => [fiberRefsPatch.diff(refs, refsNew), runtimeFlags.diff(flags, flagsNew)]);\n/* @internal */\nexport const Do = /*#__PURE__*/core.succeed({});\n/* @internal */\nexport const bind = /*#__PURE__*/doNotation.bind(core.map, core.flatMap);\n/* @internal */\nexport const bindTo = /*#__PURE__*/doNotation.bindTo(core.map);\n/* @internal */\nexport const let_ = /*#__PURE__*/doNotation.let_(core.map);\n/* @internal */\nexport const dropUntil = /*#__PURE__*/dual(2, (elements, predicate) => core.suspend(() => {\n  const iterator = elements[Symbol.iterator]();\n  const builder = [];\n  let next;\n  let dropping = core.succeed(false);\n  let i = 0;\n  while ((next = iterator.next()) && !next.done) {\n    const a = next.value;\n    const index = i++;\n    dropping = core.flatMap(dropping, bool => {\n      if (bool) {\n        builder.push(a);\n        return core.succeed(true);\n      }\n      return predicate(a, index);\n    });\n  }\n  return core.map(dropping, () => builder);\n}));\n/* @internal */\nexport const dropWhile = /*#__PURE__*/dual(2, (elements, predicate) => core.suspend(() => {\n  const iterator = elements[Symbol.iterator]();\n  const builder = [];\n  let next;\n  let dropping = core.succeed(true);\n  let i = 0;\n  while ((next = iterator.next()) && !next.done) {\n    const a = next.value;\n    const index = i++;\n    dropping = core.flatMap(dropping, d => core.map(d ? predicate(a, index) : core.succeed(false), b => {\n      if (!b) {\n        builder.push(a);\n      }\n      return b;\n    }));\n  }\n  return core.map(dropping, () => builder);\n}));\n/* @internal */\nexport const contextWith = f => core.map(core.context(), f);\n/* @internal */\nexport const eventually = self => core.orElse(self, () => core.flatMap(core.yieldNow(), () => eventually(self)));\n/* @internal */\nexport const filterMap = /*#__PURE__*/dual(2, (elements, pf) => core.map(core.forEachSequential(elements, identity), Arr.filterMap(pf)));\n/* @internal */\nexport const filterOrDie = /*#__PURE__*/dual(3, (self, predicate, orDieWith) => filterOrElse(self, predicate, a => core.dieSync(() => orDieWith(a))));\n/* @internal */\nexport const filterOrDieMessage = /*#__PURE__*/dual(3, (self, predicate, message) => filterOrElse(self, predicate, () => core.dieMessage(message)));\n/* @internal */\nexport const filterOrElse = /*#__PURE__*/dual(3, (self, predicate, orElse) => core.flatMap(self, a => predicate(a) ? core.succeed(a) : orElse(a)));\n/** @internal */\nexport const liftPredicate = /*#__PURE__*/dual(3, (self, predicate, orFailWith) => core.suspend(() => predicate(self) ? core.succeed(self) : core.fail(orFailWith(self))));\n/* @internal */\nexport const filterOrFail = /*#__PURE__*/dual(args => core.isEffect(args[0]), (self, predicate, orFailWith) => filterOrElse(self, predicate, a => orFailWith === undefined ? core.fail(new core.NoSuchElementException()) : core.failSync(() => orFailWith(a))));\n/* @internal */\nexport const findFirst = /*#__PURE__*/dual(2, (elements, f) => core.suspend(() => {\n  const iterator = elements[Symbol.iterator]();\n  const next = iterator.next();\n  if (!next.done) {\n    return findLoop(iterator, 0, f, next.value);\n  }\n  return core.succeed(Option.none());\n}));\nconst findLoop = (iterator, index, f, value) => core.flatMap(f(value, index), result => {\n  if (result) {\n    return core.succeed(Option.some(value));\n  }\n  const next = iterator.next();\n  if (!next.done) {\n    return findLoop(iterator, index + 1, f, next.value);\n  }\n  return core.succeed(Option.none());\n});\n/* @internal */\nexport const firstSuccessOf = effects => core.suspend(() => {\n  const list = Chunk.fromIterable(effects);\n  if (!Chunk.isNonEmpty(list)) {\n    return core.dieSync(() => new core.IllegalArgumentException(`Received an empty collection of effects`));\n  }\n  return pipe(Chunk.tailNonEmpty(list), Arr.reduce(Chunk.headNonEmpty(list), (left, right) => core.orElse(left, () => right)));\n});\n/* @internal */\nexport const flipWith = /*#__PURE__*/dual(2, (self, f) => core.flip(f(core.flip(self))));\n/* @internal */\nexport const match = /*#__PURE__*/dual(2, (self, options) => core.matchEffect(self, {\n  onFailure: e => core.succeed(options.onFailure(e)),\n  onSuccess: a => core.succeed(options.onSuccess(a))\n}));\n/* @internal */\nexport const every = /*#__PURE__*/dual(2, (elements, f) => core.suspend(() => forAllLoop(elements[Symbol.iterator](), 0, f)));\nconst forAllLoop = (iterator, index, f) => {\n  const next = iterator.next();\n  return next.done ? core.succeed(true) : core.flatMap(f(next.value, index), b => b ? forAllLoop(iterator, index + 1, f) : core.succeed(b));\n};\n/* @internal */\nexport const forever = self => {\n  const loop = core.flatMap(core.flatMap(self, () => core.yieldNow()), () => loop);\n  return loop;\n};\n/**\n * Inspired by https://github.com/tusharmath/qio/pull/22 (revised)\n  @internal */\nexport const gen = function () {\n  let f;\n  if (arguments.length === 1) {\n    f = arguments[0];\n  } else {\n    f = arguments[1].bind(arguments[0]);\n  }\n  return core.suspend(() => {\n    const iterator = f(pipe);\n    const state = internalCall(() => iterator.next());\n    const run = state => {\n      return state.done ? core.succeed(state.value) : core.flatMap(yieldWrapGet(state.value), val => run(internalCall(() => iterator.next(val))));\n    };\n    return run(state);\n  });\n};\n/* @internal */\nexport const fiberRefs = /*#__PURE__*/core.withFiberRuntime(state => core.succeed(state.getFiberRefs()));\n/* @internal */\nexport const head = self => core.flatMap(self, as => {\n  const iterator = as[Symbol.iterator]();\n  const next = iterator.next();\n  if (next.done) {\n    return core.fail(new core.NoSuchElementException());\n  }\n  return core.succeed(next.value);\n});\n/* @internal */\nexport const ignore = self => match(self, {\n  onFailure: constVoid,\n  onSuccess: constVoid\n});\n/* @internal */\nexport const ignoreLogged = self => core.matchCauseEffect(self, {\n  onFailure: cause => logDebug(cause, \"An error was silently ignored because it is not anticipated to be useful\"),\n  onSuccess: () => core.void\n});\n/* @internal */\nexport const inheritFiberRefs = childFiberRefs => updateFiberRefs((parentFiberId, parentFiberRefs) => FiberRefs.joinAs(parentFiberRefs, parentFiberId, childFiberRefs));\n/* @internal */\nexport const isFailure = self => match(self, {\n  onFailure: constTrue,\n  onSuccess: constFalse\n});\n/* @internal */\nexport const isSuccess = self => match(self, {\n  onFailure: constFalse,\n  onSuccess: constTrue\n});\n/* @internal */\nexport const iterate = (initial, options) => core.suspend(() => {\n  if (options.while(initial)) {\n    return core.flatMap(options.body(initial), z2 => iterate(z2, options));\n  }\n  return core.succeed(initial);\n});\n/** @internal */\nexport const logWithLevel = level => (...message) => {\n  const levelOption = Option.fromNullable(level);\n  let cause = undefined;\n  for (let i = 0, len = message.length; i < len; i++) {\n    const msg = message[i];\n    if (internalCause.isCause(msg)) {\n      if (cause !== undefined) {\n        cause = internalCause.sequential(cause, msg);\n      } else {\n        cause = msg;\n      }\n      message = [...message.slice(0, i), ...message.slice(i + 1)];\n      i--;\n    }\n  }\n  if (cause === undefined) {\n    cause = internalCause.empty;\n  }\n  return core.withFiberRuntime(fiberState => {\n    fiberState.log(message, cause, levelOption);\n    return core.void;\n  });\n};\n/** @internal */\nexport const log = /*#__PURE__*/logWithLevel();\n/** @internal */\nexport const logTrace = /*#__PURE__*/logWithLevel(LogLevel.Trace);\n/** @internal */\nexport const logDebug = /*#__PURE__*/logWithLevel(LogLevel.Debug);\n/** @internal */\nexport const logInfo = /*#__PURE__*/logWithLevel(LogLevel.Info);\n/** @internal */\nexport const logWarning = /*#__PURE__*/logWithLevel(LogLevel.Warning);\n/** @internal */\nexport const logError = /*#__PURE__*/logWithLevel(LogLevel.Error);\n/** @internal */\nexport const logFatal = /*#__PURE__*/logWithLevel(LogLevel.Fatal);\n/* @internal */\nexport const withLogSpan = /*#__PURE__*/dual(2, (effect, label) => core.flatMap(Clock.currentTimeMillis, now => core.fiberRefLocallyWith(effect, core.currentLogSpan, List.prepend(LogSpan.make(label, now)))));\n/* @internal */\nexport const logAnnotations = /*#__PURE__*/core.fiberRefGet(core.currentLogAnnotations);\n/* @internal */\nexport const loop = (initial, options) => options.discard ? loopDiscard(initial, options.while, options.step, options.body) : core.map(loopInternal(initial, options.while, options.step, options.body), Arr.fromIterable);\nconst loopInternal = (initial, cont, inc, body) => core.suspend(() => cont(initial) ? core.flatMap(body(initial), a => core.map(loopInternal(inc(initial), cont, inc, body), List.prepend(a))) : core.sync(() => List.empty()));\nconst loopDiscard = (initial, cont, inc, body) => core.suspend(() => cont(initial) ? core.flatMap(body(initial), () => loopDiscard(inc(initial), cont, inc, body)) : core.void);\n/* @internal */\nexport const mapAccum = /*#__PURE__*/dual(3, (elements, zero, f) => core.suspend(() => {\n  const iterator = elements[Symbol.iterator]();\n  const builder = [];\n  let result = core.succeed(zero);\n  let next;\n  let i = 0;\n  while (!(next = iterator.next()).done) {\n    const index = i++;\n    const value = next.value;\n    result = core.flatMap(result, state => core.map(f(state, value, index), ([z, b]) => {\n      builder.push(b);\n      return z;\n    }));\n  }\n  return core.map(result, z => [z, builder]);\n}));\n/* @internal */\nexport const mapErrorCause = /*#__PURE__*/dual(2, (self, f) => core.matchCauseEffect(self, {\n  onFailure: c => core.failCauseSync(() => f(c)),\n  onSuccess: core.succeed\n}));\n/* @internal */\nexport const memoize = self => pipe(core.deferredMake(), core.flatMap(deferred => pipe(diffFiberRefsAndRuntimeFlags(self), core.intoDeferred(deferred), once, core.map(complete => core.zipRight(complete, pipe(core.deferredAwait(deferred), core.flatMap(([patch, a]) => core.as(core.zip(patchFiberRefs(patch[0]), core.updateRuntimeFlags(patch[1])), a))))))));\n/* @internal */\nexport const merge = self => core.matchEffect(self, {\n  onFailure: e => core.succeed(e),\n  onSuccess: core.succeed\n});\n/* @internal */\nexport const negate = self => core.map(self, b => !b);\n/* @internal */\nexport const none = self => core.flatMap(self, option => {\n  switch (option._tag) {\n    case \"None\":\n      return core.void;\n    case \"Some\":\n      return core.fail(new core.NoSuchElementException());\n  }\n});\n/* @internal */\nexport const once = self => core.map(Ref.make(true), ref => core.asVoid(core.whenEffect(self, Ref.getAndSet(ref, false))));\n/* @internal */\nexport const option = self => core.matchEffect(self, {\n  onFailure: () => core.succeed(Option.none()),\n  onSuccess: a => core.succeed(Option.some(a))\n});\n/* @internal */\nexport const orElseFail = /*#__PURE__*/dual(2, (self, evaluate) => core.orElse(self, () => core.failSync(evaluate)));\n/* @internal */\nexport const orElseSucceed = /*#__PURE__*/dual(2, (self, evaluate) => core.orElse(self, () => core.sync(evaluate)));\n/* @internal */\nexport const parallelErrors = self => core.matchCauseEffect(self, {\n  onFailure: cause => {\n    const errors = Arr.fromIterable(internalCause.failures(cause));\n    return errors.length === 0 ? core.failCause(cause) : core.fail(errors);\n  },\n  onSuccess: core.succeed\n});\n/* @internal */\nexport const patchFiberRefs = patch => updateFiberRefs((fiberId, fiberRefs) => pipe(patch, fiberRefsPatch.patch(fiberId, fiberRefs)));\n/* @internal */\nexport const promise = evaluate => evaluate.length >= 1 ? core.async((resolve, signal) => {\n  evaluate(signal).then(a => resolve(core.exitSucceed(a)), e => resolve(core.exitDie(e)));\n}) : core.async(resolve => {\n  ;\n  evaluate().then(a => resolve(core.exitSucceed(a)), e => resolve(core.exitDie(e)));\n});\n/* @internal */\nexport const provideService = /*#__PURE__*/dual(3, (self, tag, service) => core.contextWithEffect(env => core.provideContext(self, Context.add(env, tag, service))));\n/* @internal */\nexport const provideServiceEffect = /*#__PURE__*/dual(3, (self, tag, effect) => core.contextWithEffect(env => core.flatMap(effect, service => core.provideContext(self, pipe(env, Context.add(tag, service))))));\n/* @internal */\nexport const random = /*#__PURE__*/defaultServices.randomWith(core.succeed);\n/* @internal */\nexport const reduce = /*#__PURE__*/dual(3, (elements, zero, f) => Arr.fromIterable(elements).reduce((acc, el, i) => core.flatMap(acc, a => f(a, el, i)), core.succeed(zero)));\n/* @internal */\nexport const reduceRight = /*#__PURE__*/dual(3, (elements, zero, f) => Arr.fromIterable(elements).reduceRight((acc, el, i) => core.flatMap(acc, a => f(el, a, i)), core.succeed(zero)));\n/* @internal */\nexport const reduceWhile = /*#__PURE__*/dual(3, (elements, zero, options) => core.flatMap(core.sync(() => elements[Symbol.iterator]()), iterator => reduceWhileLoop(iterator, 0, zero, options.while, options.body)));\nconst reduceWhileLoop = (iterator, index, state, predicate, f) => {\n  const next = iterator.next();\n  if (!next.done && predicate(state)) {\n    return core.flatMap(f(state, next.value, index), nextState => reduceWhileLoop(iterator, index + 1, nextState, predicate, f));\n  }\n  return core.succeed(state);\n};\n/* @internal */\nexport const repeatN = /*#__PURE__*/dual(2, (self, n) => core.suspend(() => repeatNLoop(self, n)));\n/* @internal */\nconst repeatNLoop = (self, n) => core.flatMap(self, a => n <= 0 ? core.succeed(a) : core.zipRight(core.yieldNow(), repeatNLoop(self, n - 1)));\n/* @internal */\nexport const sandbox = self => core.matchCauseEffect(self, {\n  onFailure: core.fail,\n  onSuccess: core.succeed\n});\n/* @internal */\nexport const setFiberRefs = fiberRefs => core.suspend(() => FiberRefs.setAll(fiberRefs));\n/* @internal */\nexport const sleep = Clock.sleep;\n/* @internal */\nexport const succeedNone = /*#__PURE__*/core.succeed( /*#__PURE__*/Option.none());\n/* @internal */\nexport const succeedSome = value => core.succeed(Option.some(value));\n/* @internal */\nexport const summarized = /*#__PURE__*/dual(3, (self, summary, f) => core.flatMap(summary, start => core.flatMap(self, value => core.map(summary, end => [f(start, end), value]))));\n/* @internal */\nexport const tagMetrics = /*#__PURE__*/dual(args => core.isEffect(args[0]), function () {\n  return labelMetrics(arguments[0], typeof arguments[1] === \"string\" ? [metricLabel.make(arguments[1], arguments[2])] : Object.entries(arguments[1]).map(([k, v]) => metricLabel.make(k, v)));\n});\n/* @internal */\nexport const labelMetrics = /*#__PURE__*/dual(2, (self, labels) => core.fiberRefLocallyWith(self, core.currentMetricLabels, old => Arr.union(old, labels)));\n/* @internal */\nexport const takeUntil = /*#__PURE__*/dual(2, (elements, predicate) => core.suspend(() => {\n  const iterator = elements[Symbol.iterator]();\n  const builder = [];\n  let next;\n  let effect = core.succeed(false);\n  let i = 0;\n  while ((next = iterator.next()) && !next.done) {\n    const a = next.value;\n    const index = i++;\n    effect = core.flatMap(effect, bool => {\n      if (bool) {\n        return core.succeed(true);\n      }\n      builder.push(a);\n      return predicate(a, index);\n    });\n  }\n  return core.map(effect, () => builder);\n}));\n/* @internal */\nexport const takeWhile = /*#__PURE__*/dual(2, (elements, predicate) => core.suspend(() => {\n  const iterator = elements[Symbol.iterator]();\n  const builder = [];\n  let next;\n  let taking = core.succeed(true);\n  let i = 0;\n  while ((next = iterator.next()) && !next.done) {\n    const a = next.value;\n    const index = i++;\n    taking = core.flatMap(taking, taking => pipe(taking ? predicate(a, index) : core.succeed(false), core.map(bool => {\n      if (bool) {\n        builder.push(a);\n      }\n      return bool;\n    })));\n  }\n  return core.map(taking, () => builder);\n}));\n/* @internal */\nexport const tapBoth = /*#__PURE__*/dual(2, (self, {\n  onFailure,\n  onSuccess\n}) => core.matchCauseEffect(self, {\n  onFailure: cause => {\n    const either = internalCause.failureOrCause(cause);\n    switch (either._tag) {\n      case \"Left\":\n        {\n          return core.zipRight(onFailure(either.left), core.failCause(cause));\n        }\n      case \"Right\":\n        {\n          return core.failCause(cause);\n        }\n    }\n  },\n  onSuccess: a => core.as(onSuccess(a), a)\n}));\n/* @internal */\nexport const tapDefect = /*#__PURE__*/dual(2, (self, f) => core.catchAllCause(self, cause => Option.match(internalCause.keepDefects(cause), {\n  onNone: () => core.failCause(cause),\n  onSome: a => core.zipRight(f(a), core.failCause(cause))\n})));\n/* @internal */\nexport const tapError = /*#__PURE__*/dual(2, (self, f) => core.matchCauseEffect(self, {\n  onFailure: cause => {\n    const either = internalCause.failureOrCause(cause);\n    switch (either._tag) {\n      case \"Left\":\n        return core.zipRight(f(either.left), core.failCause(cause));\n      case \"Right\":\n        return core.failCause(cause);\n    }\n  },\n  onSuccess: core.succeed\n}));\n/* @internal */\nexport const tapErrorTag = /*#__PURE__*/dual(3, (self, k, f) => tapError(self, e => {\n  if (Predicate.isTagged(e, k)) {\n    return f(e);\n  }\n  return core.void;\n}));\n/* @internal */\nexport const tapErrorCause = /*#__PURE__*/dual(2, (self, f) => core.matchCauseEffect(self, {\n  onFailure: cause => core.zipRight(f(cause), core.failCause(cause)),\n  onSuccess: core.succeed\n}));\n/* @internal */\nexport const timed = self => timedWith(self, Clock.currentTimeNanos);\n/* @internal */\nexport const timedWith = /*#__PURE__*/dual(2, (self, nanos) => summarized(self, nanos, (start, end) => Duration.nanos(end - start)));\n/* @internal */\nexport const tracerWith = Tracer.tracerWith;\n/** @internal */\nexport const tracer = /*#__PURE__*/tracerWith(core.succeed);\n/* @internal */\nexport const tryPromise = arg => {\n  let evaluate;\n  let catcher = undefined;\n  if (typeof arg === \"function\") {\n    evaluate = arg;\n  } else {\n    evaluate = arg.try;\n    catcher = arg.catch;\n  }\n  if (evaluate.length >= 1) {\n    return core.async((resolve, signal) => {\n      try {\n        evaluate(signal).then(a => resolve(core.exitSucceed(a)), e => resolve(core.fail(catcher ? catcher(e) : new core.UnknownException(e))));\n      } catch (e) {\n        resolve(core.fail(catcher ? catcher(e) : new core.UnknownException(e)));\n      }\n    });\n  }\n  return core.async(resolve => {\n    try {\n      evaluate().then(a => resolve(core.exitSucceed(a)), e => resolve(core.fail(catcher ? catcher(e) : new core.UnknownException(e))));\n    } catch (e) {\n      resolve(core.fail(catcher ? catcher(e) : new core.UnknownException(e)));\n    }\n  });\n};\n/* @internal */\nexport const tryMap = /*#__PURE__*/dual(2, (self, options) => core.flatMap(self, a => try_({\n  try: () => options.try(a),\n  catch: options.catch\n})));\n/* @internal */\nexport const tryMapPromise = /*#__PURE__*/dual(2, (self, options) => core.flatMap(self, a => tryPromise({\n  try: options.try.length >= 1 ? signal => options.try(a, signal) : () => options.try(a),\n  catch: options.catch\n})));\n/* @internal */\nexport const unless = /*#__PURE__*/dual(2, (self, condition) => core.suspend(() => condition() ? succeedNone : asSome(self)));\n/* @internal */\nexport const unlessEffect = /*#__PURE__*/dual(2, (self, condition) => core.flatMap(condition, b => b ? succeedNone : asSome(self)));\n/* @internal */\nexport const unsandbox = self => mapErrorCause(self, internalCause.flatten);\n/* @internal */\nexport const updateFiberRefs = f => core.withFiberRuntime(state => {\n  state.setFiberRefs(f(state.id(), state.getFiberRefs()));\n  return core.void;\n});\n/* @internal */\nexport const updateService = /*#__PURE__*/dual(3, (self, tag, f) => core.mapInputContext(self, context => Context.add(context, tag, f(Context.unsafeGet(context, tag)))));\n/* @internal */\nexport const when = /*#__PURE__*/dual(2, (self, condition) => core.suspend(() => condition() ? core.map(self, Option.some) : core.succeed(Option.none())));\n/* @internal */\nexport const whenFiberRef = /*#__PURE__*/dual(3, (self, fiberRef, predicate) => core.flatMap(core.fiberRefGet(fiberRef), s => predicate(s) ? core.map(self, a => [s, Option.some(a)]) : core.succeed([s, Option.none()])));\n/* @internal */\nexport const whenRef = /*#__PURE__*/dual(3, (self, ref, predicate) => core.flatMap(Ref.get(ref), s => predicate(s) ? core.map(self, a => [s, Option.some(a)]) : core.succeed([s, Option.none()])));\n/* @internal */\nexport const withMetric = /*#__PURE__*/dual(2, (self, metric) => metric(self));\n/** @internal */\nexport const serviceFunctionEffect = (getService, f) => (...args) => core.flatMap(getService, a => f(a)(...args));\n/** @internal */\nexport const serviceFunction = (getService, f) => (...args) => core.map(getService, a => f(a)(...args));\n/** @internal */\nexport const serviceFunctions = getService => new Proxy({}, {\n  get(_target, prop, _receiver) {\n    return (...args) => core.flatMap(getService, s => s[prop](...args));\n  }\n});\n/** @internal */\nexport const serviceConstants = getService => new Proxy({}, {\n  get(_target, prop, _receiver) {\n    return core.flatMap(getService, s => core.isEffect(s[prop]) ? s[prop] : core.succeed(s[prop]));\n  }\n});\n/** @internal */\nexport const serviceMembers = getService => ({\n  functions: serviceFunctions(getService),\n  constants: serviceConstants(getService)\n});\n/** @internal */\nexport const serviceOption = tag => core.map(core.context(), Context.getOption(tag));\n/** @internal */\nexport const serviceOptional = tag => core.flatMap(core.context(), Context.getOption(tag));\n// -----------------------------------------------------------------------------\n// tracing\n// -----------------------------------------------------------------------------\n/* @internal */\nexport const annotateCurrentSpan = function () {\n  const args = arguments;\n  return ignore(core.flatMap(currentSpan, span => core.sync(() => {\n    if (typeof args[0] === \"string\") {\n      span.attribute(args[0], args[1]);\n    } else {\n      for (const key in args[0]) {\n        span.attribute(key, args[0][key]);\n      }\n    }\n  })));\n};\n/* @internal */\nexport const annotateSpans = /*#__PURE__*/dual(args => core.isEffect(args[0]), function () {\n  const args = arguments;\n  return core.fiberRefLocallyWith(args[0], core.currentTracerSpanAnnotations, typeof args[1] === \"string\" ? HashMap.set(args[1], args[2]) : annotations => Object.entries(args[1]).reduce((acc, [key, value]) => HashMap.set(acc, key, value), annotations));\n});\n/** @internal */\nexport const currentParentSpan = /*#__PURE__*/serviceOptional(internalTracer.spanTag);\n/** @internal */\nexport const currentSpan = /*#__PURE__*/core.flatMap( /*#__PURE__*/core.context(), context => {\n  const span = context.unsafeMap.get(internalTracer.spanTag.key);\n  return span !== undefined && span._tag === \"Span\" ? core.succeed(span) : core.fail(new core.NoSuchElementException());\n});\n/* @internal */\nexport const linkSpans = /*#__PURE__*/dual(args => core.isEffect(args[0]), (self, span, attributes) => core.fiberRefLocallyWith(self, core.currentTracerSpanLinks, Chunk.append({\n  _tag: \"SpanLink\",\n  span,\n  attributes: attributes ?? {}\n})));\nconst bigint0 = /*#__PURE__*/BigInt(0);\n/** @internal */\nexport const unsafeMakeSpan = (fiber, name, options) => {\n  const enabled = fiber.getFiberRef(core.currentTracerEnabled);\n  if (enabled === false) {\n    return core.noopSpan(name);\n  }\n  const context = fiber.getFiberRef(core.currentContext);\n  const services = fiber.getFiberRef(defaultServices.currentServices);\n  const tracer = Context.get(services, internalTracer.tracerTag);\n  const clock = Context.get(services, Clock.Clock);\n  const timingEnabled = fiber.getFiberRef(core.currentTracerTimingEnabled);\n  const fiberRefs = fiber.getFiberRefs();\n  const annotationsFromEnv = FiberRefs.get(fiberRefs, core.currentTracerSpanAnnotations);\n  const linksFromEnv = FiberRefs.get(fiberRefs, core.currentTracerSpanLinks);\n  const parent = options.parent ? Option.some(options.parent) : options.root ? Option.none() : Context.getOption(context, internalTracer.spanTag);\n  const links = linksFromEnv._tag === \"Some\" ? options.links !== undefined ? [...Chunk.toReadonlyArray(linksFromEnv.value), ...(options.links ?? [])] : Chunk.toReadonlyArray(linksFromEnv.value) : options.links ?? Arr.empty();\n  const span = tracer.span(name, parent, options.context ?? Context.empty(), links, timingEnabled ? clock.unsafeCurrentTimeNanos() : bigint0, options.kind ?? \"internal\");\n  if (typeof options.captureStackTrace === \"function\") {\n    internalCause.spanToTrace.set(span, options.captureStackTrace);\n  }\n  if (annotationsFromEnv._tag === \"Some\") {\n    HashMap.forEach(annotationsFromEnv.value, (value, key) => span.attribute(key, value));\n  }\n  if (options.attributes !== undefined) {\n    Object.entries(options.attributes).forEach(([k, v]) => span.attribute(k, v));\n  }\n  return span;\n};\n/** @internal */\nexport const makeSpan = (name, options) => {\n  options = internalTracer.addSpanStackTrace(options);\n  return core.withFiberRuntime(fiber => core.succeed(unsafeMakeSpan(fiber, name, options)));\n};\n/* @internal */\nexport const spanAnnotations = /*#__PURE__*/core.fiberRefGet(core.currentTracerSpanAnnotations);\n/* @internal */\nexport const spanLinks = /*#__PURE__*/core.fiberRefGet(core.currentTracerSpanLinks);\n/** @internal */\nexport const endSpan = (span, exit, clock, timingEnabled) => core.sync(() => {\n  if (span.status._tag === \"Ended\") {\n    return;\n  }\n  if (core.exitIsFailure(exit) && internalCause.spanToTrace.has(span)) {\n    span.attribute(\"code.stacktrace\", internalCause.spanToTrace.get(span)());\n  }\n  span.end(timingEnabled ? clock.unsafeCurrentTimeNanos() : bigint0, exit);\n});\n/** @internal */\nexport const useSpan = (name, ...args) => {\n  const options = internalTracer.addSpanStackTrace(args.length === 1 ? undefined : args[0]);\n  const evaluate = args[args.length - 1];\n  return core.withFiberRuntime(fiber => {\n    const span = unsafeMakeSpan(fiber, name, options);\n    const timingEnabled = fiber.getFiberRef(core.currentTracerTimingEnabled);\n    const clock = Context.get(fiber.getFiberRef(defaultServices.currentServices), clockTag);\n    return core.onExit(evaluate(span), exit => endSpan(span, exit, clock, timingEnabled));\n  });\n};\n/** @internal */\nexport const withParentSpan = /*#__PURE__*/dual(2, (self, span) => provideService(self, internalTracer.spanTag, span));\n/** @internal */\nexport const withSpan = function () {\n  const dataFirst = typeof arguments[0] !== \"string\";\n  const name = dataFirst ? arguments[1] : arguments[0];\n  const options = internalTracer.addSpanStackTrace(dataFirst ? arguments[2] : arguments[1]);\n  if (dataFirst) {\n    const self = arguments[0];\n    return useSpan(name, options, span => withParentSpan(self, span));\n  }\n  return self => useSpan(name, options, span => withParentSpan(self, span));\n};\nexport const functionWithSpan = options => function () {\n  let captureStackTrace = options.captureStackTrace ?? false;\n  if (options.captureStackTrace !== false) {\n    const limit = Error.stackTraceLimit;\n    Error.stackTraceLimit = 2;\n    const error = new Error();\n    Error.stackTraceLimit = limit;\n    let cache = false;\n    captureStackTrace = () => {\n      if (cache !== false) {\n        return cache;\n      }\n      if (error.stack) {\n        const stack = error.stack.trim().split(\"\\n\");\n        cache = stack.slice(2).join(\"\\n\").trim();\n        return cache;\n      }\n    };\n  }\n  return core.suspend(() => {\n    const opts = typeof options.options === \"function\" ? options.options.apply(null, arguments) : options.options;\n    return withSpan(core.suspend(() => internalCall(() => options.body.apply(this, arguments))), opts.name, {\n      ...opts,\n      captureStackTrace\n    });\n  });\n};\n// -------------------------------------------------------------------------------------\n// optionality\n// -------------------------------------------------------------------------------------\n/* @internal */\nexport const fromNullable = value => value == null ? core.fail(new core.NoSuchElementException()) : core.succeed(value);\n/* @internal */\nexport const optionFromOptional = self => core.catchAll(core.map(self, Option.some), error => core.isNoSuchElementException(error) ? succeedNone : core.fail(error));\n//# sourceMappingURL=core-effect.js.map","import * as Cause from \"../Cause.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Effect from \"../Effect.js\";\nimport * as Either from \"../Either.js\";\nimport { constVoid, dual, identity } from \"../Function.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as childExecutorDecision from \"./channel/childExecutorDecision.js\";\nimport { ContinuationKImpl } from \"./channel/continuation.js\";\nimport * as upstreamPullStrategy from \"./channel/upstreamPullStrategy.js\";\nimport * as OpCodes from \"./opCodes/channel.js\";\n/** @internal */\nconst ChannelSymbolKey = \"effect/Channel\";\n/** @internal */\nexport const ChannelTypeId = /*#__PURE__*/Symbol.for(ChannelSymbolKey);\nconst channelVariance = {\n  /* c8 ignore next */\n  _Env: _ => _,\n  /* c8 ignore next */\n  _InErr: _ => _,\n  /* c8 ignore next */\n  _InElem: _ => _,\n  /* c8 ignore next */\n  _InDone: _ => _,\n  /* c8 ignore next */\n  _OutErr: _ => _,\n  /* c8 ignore next */\n  _OutElem: _ => _,\n  /* c8 ignore next */\n  _OutDone: _ => _\n};\n/** @internal */\nconst proto = {\n  [ChannelTypeId]: channelVariance,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const isChannel = u => hasProperty(u, ChannelTypeId) || Effect.isEffect(u);\n/** @internal */\nexport const acquireReleaseOut = /*#__PURE__*/dual(2, (self, release) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_BRACKET_OUT;\n  op.acquire = () => self;\n  op.finalizer = release;\n  return op;\n});\n/** @internal */\nexport const catchAllCause = /*#__PURE__*/dual(2, (self, f) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_FOLD;\n  op.channel = self;\n  op.k = new ContinuationKImpl(succeed, f);\n  return op;\n});\n/** @internal */\nexport const collectElements = self => {\n  return suspend(() => {\n    const builder = [];\n    return flatMap(pipeTo(self, collectElementsReader(builder)), value => sync(() => [Chunk.fromIterable(builder), value]));\n  });\n};\n/** @internal */\nconst collectElementsReader = builder => readWith({\n  onInput: outElem => flatMap(sync(() => {\n    builder.push(outElem);\n  }), () => collectElementsReader(builder)),\n  onFailure: fail,\n  onDone: succeedNow\n});\n/** @internal */\nexport const concatAll = channels => concatAllWith(channels, constVoid, constVoid);\n/** @internal */\nexport const concatAllWith = (channels, f, g) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_CONCAT_ALL;\n  op.combineInners = f;\n  op.combineAll = g;\n  op.onPull = () => upstreamPullStrategy.PullAfterNext(Option.none());\n  op.onEmit = () => childExecutorDecision.Continue;\n  op.value = () => channels;\n  op.k = identity;\n  return op;\n};\n/** @internal */\nexport const concatMapWith = /*#__PURE__*/dual(4, (self, f, g, h) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_CONCAT_ALL;\n  op.combineInners = g;\n  op.combineAll = h;\n  op.onPull = () => upstreamPullStrategy.PullAfterNext(Option.none());\n  op.onEmit = () => childExecutorDecision.Continue;\n  op.value = () => self;\n  op.k = f;\n  return op;\n});\n/** @internal */\nexport const concatMapWithCustom = /*#__PURE__*/dual(6, (self, f, g, h, onPull, onEmit) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_CONCAT_ALL;\n  op.combineInners = g;\n  op.combineAll = h;\n  op.onPull = onPull;\n  op.onEmit = onEmit;\n  op.value = () => self;\n  op.k = f;\n  return op;\n});\n/** @internal */\nexport const embedInput = /*#__PURE__*/dual(2, (self, input) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_BRIDGE;\n  op.input = input;\n  op.channel = self;\n  return op;\n});\n/** @internal */\nexport const ensuringWith = /*#__PURE__*/dual(2, (self, finalizer) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_ENSURING;\n  op.channel = self;\n  op.finalizer = finalizer;\n  return op;\n});\n/** @internal */\nexport const fail = error => failCause(Cause.fail(error));\n/** @internal */\nexport const failSync = evaluate => failCauseSync(() => Cause.fail(evaluate()));\n/** @internal */\nexport const failCause = cause => failCauseSync(() => cause);\n/** @internal */\nexport const failCauseSync = evaluate => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_FAIL;\n  op.error = evaluate;\n  return op;\n};\n/** @internal */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_FOLD;\n  op.channel = self;\n  op.k = new ContinuationKImpl(f, failCause);\n  return op;\n});\n/** @internal */\nexport const foldCauseChannel = /*#__PURE__*/dual(2, (self, options) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_FOLD;\n  op.channel = self;\n  op.k = new ContinuationKImpl(options.onSuccess, options.onFailure);\n  return op;\n});\n/** @internal */\nexport const fromEffect = effect => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_FROM_EFFECT;\n  op.effect = () => effect;\n  return op;\n};\n/** @internal */\nexport const pipeTo = /*#__PURE__*/dual(2, (self, that) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_PIPE_TO;\n  op.left = () => self;\n  op.right = () => that;\n  return op;\n});\n/** @internal */\nexport const provideContext = /*#__PURE__*/dual(2, (self, env) => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_PROVIDE;\n  op.context = () => env;\n  op.inner = self;\n  return op;\n});\n/** @internal */\nexport const readOrFail = error => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_READ;\n  op.more = succeed;\n  op.done = new ContinuationKImpl(() => fail(error), () => fail(error));\n  return op;\n};\n/** @internal */\nexport const readWith = options => readWithCause({\n  onInput: options.onInput,\n  onFailure: cause => Either.match(Cause.failureOrCause(cause), {\n    onLeft: options.onFailure,\n    onRight: failCause\n  }),\n  onDone: options.onDone\n});\n/** @internal */\nexport const readWithCause = options => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_READ;\n  op.more = options.onInput;\n  op.done = new ContinuationKImpl(options.onDone, options.onFailure);\n  return op;\n};\n/** @internal */\nexport const succeed = value => sync(() => value);\n/** @internal */\nexport const succeedNow = result => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_SUCCEED_NOW;\n  op.terminal = result;\n  return op;\n};\n/** @internal */\nexport const suspend = evaluate => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_SUSPEND;\n  op.channel = evaluate;\n  return op;\n};\nexport const sync = evaluate => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_SUCCEED;\n  op.evaluate = evaluate;\n  return op;\n};\nconst void_ = /*#__PURE__*/succeedNow(void 0);\nexport { /** @internal */\nvoid_ as void };\n/** @internal */\nexport const write = out => {\n  const op = Object.create(proto);\n  op._tag = OpCodes.OP_EMIT;\n  op.out = out;\n  return op;\n};\n//# sourceMappingURL=core-stream.js.map","import { internalCall } from \"effect/Utils\";\nimport * as Arr from \"../Array.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Context from \"../Context.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as Either from \"../Either.js\";\nimport * as Equal from \"../Equal.js\";\nimport * as FiberId from \"../FiberId.js\";\nimport { dual, identity, pipe } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as Hash from \"../Hash.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport * as List from \"../List.js\";\nimport * as MutableRef from \"../MutableRef.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty, isObject, isPromiseLike } from \"../Predicate.js\";\nimport * as RuntimeFlagsPatch from \"../RuntimeFlagsPatch.js\";\nimport { YieldWrap } from \"../Utils.js\";\nimport * as _blockedRequests from \"./blockedRequests.js\";\nimport * as internalCause from \"./cause.js\";\nimport * as deferred from \"./deferred.js\";\nimport * as internalDiffer from \"./differ.js\";\nimport { effectVariance, StructuralCommitPrototype } from \"./effectable.js\";\nimport { getBugErrorMessage } from \"./errors.js\";\nimport * as DeferredOpCodes from \"./opCodes/deferred.js\";\nimport * as OpCodes from \"./opCodes/effect.js\";\nimport * as _runtimeFlags from \"./runtimeFlags.js\";\nimport { SingleShotGen } from \"./singleShotGen.js\";\nimport * as internalTracer from \"./tracer.js\";\n// -----------------------------------------------------------------------------\n// Effect\n// -----------------------------------------------------------------------------\n/** @internal */\nconst EffectErrorSymbolKey = \"effect/EffectError\";\n/** @internal */\nexport const EffectErrorTypeId = /*#__PURE__*/Symbol.for(EffectErrorSymbolKey);\n/** @internal */\nexport const isEffectError = u => hasProperty(u, EffectErrorTypeId);\n/** @internal */\nexport const makeEffectError = cause => ({\n  [EffectErrorTypeId]: EffectErrorTypeId,\n  _tag: \"EffectError\",\n  cause\n});\n/**\n * @internal\n */\nexport const blocked = (blockedRequests, _continue) => {\n  const effect = new EffectPrimitive(\"Blocked\");\n  effect.effect_instruction_i0 = blockedRequests;\n  effect.effect_instruction_i1 = _continue;\n  return effect;\n};\n/**\n * @internal\n */\nexport const runRequestBlock = blockedRequests => {\n  const effect = new EffectPrimitive(\"RunBlocked\");\n  effect.effect_instruction_i0 = blockedRequests;\n  return effect;\n};\n/** @internal */\nexport const EffectTypeId = /*#__PURE__*/Symbol.for(\"effect/Effect\");\n/** @internal */\nexport class RevertFlags {\n  patch;\n  op;\n  _op = OpCodes.OP_REVERT_FLAGS;\n  constructor(patch, op) {\n    this.patch = patch;\n    this.op = op;\n  }\n}\nclass EffectPrimitive {\n  _op;\n  effect_instruction_i0 = undefined;\n  effect_instruction_i1 = undefined;\n  effect_instruction_i2 = undefined;\n  trace = undefined;\n  [EffectTypeId] = effectVariance;\n  constructor(_op) {\n    this._op = _op;\n  }\n  [Equal.symbol](that) {\n    return this === that;\n  }\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.random(this));\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  toJSON() {\n    return {\n      _id: \"Effect\",\n      _op: this._op,\n      effect_instruction_i0: toJSON(this.effect_instruction_i0),\n      effect_instruction_i1: toJSON(this.effect_instruction_i1),\n      effect_instruction_i2: toJSON(this.effect_instruction_i2)\n    };\n  }\n  toString() {\n    return format(this.toJSON());\n  }\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n  [Symbol.iterator]() {\n    return new SingleShotGen(new YieldWrap(this));\n  }\n}\n/** @internal */\nclass EffectPrimitiveFailure {\n  _op;\n  effect_instruction_i0 = undefined;\n  effect_instruction_i1 = undefined;\n  effect_instruction_i2 = undefined;\n  trace = undefined;\n  [EffectTypeId] = effectVariance;\n  constructor(_op) {\n    this._op = _op;\n    // @ts-expect-error\n    this._tag = _op;\n  }\n  [Equal.symbol](that) {\n    return exitIsExit(that) && that._op === \"Failure\" &&\n    // @ts-expect-error\n    Equal.equals(this.effect_instruction_i0, that.effect_instruction_i0);\n  }\n  [Hash.symbol]() {\n    return pipe(\n    // @ts-expect-error\n    Hash.string(this._tag),\n    // @ts-expect-error\n    Hash.combine(Hash.hash(this.effect_instruction_i0)), Hash.cached(this));\n  }\n  get cause() {\n    return this.effect_instruction_i0;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  toJSON() {\n    return {\n      _id: \"Exit\",\n      _tag: this._op,\n      cause: this.cause.toJSON()\n    };\n  }\n  toString() {\n    return format(this.toJSON());\n  }\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n  [Symbol.iterator]() {\n    return new SingleShotGen(new YieldWrap(this));\n  }\n}\n/** @internal */\nclass EffectPrimitiveSuccess {\n  _op;\n  effect_instruction_i0 = undefined;\n  effect_instruction_i1 = undefined;\n  effect_instruction_i2 = undefined;\n  trace = undefined;\n  [EffectTypeId] = effectVariance;\n  constructor(_op) {\n    this._op = _op;\n    // @ts-expect-error\n    this._tag = _op;\n  }\n  [Equal.symbol](that) {\n    return exitIsExit(that) && that._op === \"Success\" &&\n    // @ts-expect-error\n    Equal.equals(this.effect_instruction_i0, that.effect_instruction_i0);\n  }\n  [Hash.symbol]() {\n    return pipe(\n    // @ts-expect-error\n    Hash.string(this._tag),\n    // @ts-expect-error\n    Hash.combine(Hash.hash(this.effect_instruction_i0)), Hash.cached(this));\n  }\n  get value() {\n    return this.effect_instruction_i0;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  toJSON() {\n    return {\n      _id: \"Exit\",\n      _tag: this._op,\n      value: toJSON(this.value)\n    };\n  }\n  toString() {\n    return format(this.toJSON());\n  }\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n  [Symbol.iterator]() {\n    return new SingleShotGen(new YieldWrap(this));\n  }\n}\n/** @internal */\nexport const isEffect = u => hasProperty(u, EffectTypeId);\n/* @internal */\nexport const withFiberRuntime = withRuntime => {\n  const effect = new EffectPrimitive(OpCodes.OP_WITH_RUNTIME);\n  effect.effect_instruction_i0 = withRuntime;\n  return effect;\n};\n/* @internal */\nexport const acquireUseRelease = /*#__PURE__*/dual(3, (acquire, use, release) => uninterruptibleMask(restore => flatMap(acquire, a => flatMap(exit(suspend(() => restore(use(a)))), exit => {\n  return suspend(() => release(a, exit)).pipe(matchCauseEffect({\n    onFailure: cause => {\n      switch (exit._tag) {\n        case OpCodes.OP_FAILURE:\n          return failCause(internalCause.parallel(exit.effect_instruction_i0, cause));\n        case OpCodes.OP_SUCCESS:\n          return failCause(cause);\n      }\n    },\n    onSuccess: () => exit\n  }));\n}))));\n/* @internal */\nexport const as = /*#__PURE__*/dual(2, (self, value) => flatMap(self, () => succeed(value)));\n/* @internal */\nexport const asVoid = self => as(self, void 0);\n/* @internal */\nexport const custom = function () {\n  const wrapper = new EffectPrimitive(OpCodes.OP_COMMIT);\n  switch (arguments.length) {\n    case 2:\n      {\n        wrapper.effect_instruction_i0 = arguments[0];\n        wrapper.commit = arguments[1];\n        break;\n      }\n    case 3:\n      {\n        wrapper.effect_instruction_i0 = arguments[0];\n        wrapper.effect_instruction_i1 = arguments[1];\n        wrapper.commit = arguments[2];\n        break;\n      }\n    case 4:\n      {\n        wrapper.effect_instruction_i0 = arguments[0];\n        wrapper.effect_instruction_i1 = arguments[1];\n        wrapper.effect_instruction_i2 = arguments[2];\n        wrapper.commit = arguments[3];\n        break;\n      }\n    default:\n      {\n        throw new Error(getBugErrorMessage(\"you're not supposed to end up here\"));\n      }\n  }\n  return wrapper;\n};\n/* @internal */\nexport const unsafeAsync = (register, blockingOn = FiberId.none) => {\n  const effect = new EffectPrimitive(OpCodes.OP_ASYNC);\n  let cancelerRef = undefined;\n  effect.effect_instruction_i0 = resume => {\n    cancelerRef = register(resume);\n  };\n  effect.effect_instruction_i1 = blockingOn;\n  return cancelerRef !== undefined ? onInterrupt(effect, _ => cancelerRef) : effect;\n};\n/* @internal */\nexport const async = (register, blockingOn = FiberId.none) => {\n  return custom(register, function () {\n    let backingResume = undefined;\n    let pendingEffect = undefined;\n    function proxyResume(effect) {\n      if (backingResume) {\n        backingResume(effect);\n      } else if (pendingEffect === undefined) {\n        pendingEffect = effect;\n      }\n    }\n    const effect = new EffectPrimitive(OpCodes.OP_ASYNC);\n    effect.effect_instruction_i0 = resume => {\n      backingResume = resume;\n      if (pendingEffect) {\n        resume(pendingEffect);\n      }\n    };\n    effect.effect_instruction_i1 = blockingOn;\n    let cancelerRef = undefined;\n    let controllerRef = undefined;\n    if (this.effect_instruction_i0.length !== 1) {\n      controllerRef = new AbortController();\n      cancelerRef = internalCall(() => this.effect_instruction_i0(proxyResume, controllerRef.signal));\n    } else {\n      cancelerRef = internalCall(() => this.effect_instruction_i0(proxyResume));\n    }\n    return cancelerRef || controllerRef ? onInterrupt(effect, _ => {\n      if (controllerRef) {\n        controllerRef.abort();\n      }\n      return cancelerRef ?? void_;\n    }) : effect;\n  });\n};\n/* @internal */\nexport const catchAllCause = /*#__PURE__*/dual(2, (self, f) => {\n  const effect = new EffectPrimitive(OpCodes.OP_ON_FAILURE);\n  effect.effect_instruction_i0 = self;\n  effect.effect_instruction_i1 = f;\n  return effect;\n});\n/* @internal */\nexport const catchAll = /*#__PURE__*/dual(2, (self, f) => matchEffect(self, {\n  onFailure: f,\n  onSuccess: succeed\n}));\n/* @internal */\nexport const catchIf = /*#__PURE__*/dual(3, (self, predicate, f) => catchAllCause(self, cause => {\n  const either = internalCause.failureOrCause(cause);\n  switch (either._tag) {\n    case \"Left\":\n      return predicate(either.left) ? f(either.left) : failCause(cause);\n    case \"Right\":\n      return failCause(either.right);\n  }\n}));\n/* @internal */\nexport const catchSome = /*#__PURE__*/dual(2, (self, pf) => catchAllCause(self, cause => {\n  const either = internalCause.failureOrCause(cause);\n  switch (either._tag) {\n    case \"Left\":\n      return pipe(pf(either.left), Option.getOrElse(() => failCause(cause)));\n    case \"Right\":\n      return failCause(either.right);\n  }\n}));\n/* @internal */\nexport const checkInterruptible = f => withFiberRuntime((_, status) => f(_runtimeFlags.interruption(status.runtimeFlags)));\nconst spanSymbol = /*#__PURE__*/Symbol.for(\"effect/SpanAnnotation\");\nconst originalSymbol = /*#__PURE__*/Symbol.for(\"effect/OriginalAnnotation\");\n/* @internal */\nexport const originalInstance = obj => {\n  if (hasProperty(obj, originalSymbol)) {\n    // @ts-expect-error\n    return obj[originalSymbol];\n  }\n  return obj;\n};\n/* @internal */\nconst capture = (obj, span) => {\n  if (Option.isSome(span)) {\n    return new Proxy(obj, {\n      has(target, p) {\n        return p === spanSymbol || p === originalSymbol || p in target;\n      },\n      get(target, p) {\n        if (p === spanSymbol) {\n          return span.value;\n        }\n        if (p === originalSymbol) {\n          return obj;\n        }\n        // @ts-expect-error\n        return target[p];\n      }\n    });\n  }\n  return obj;\n};\n/* @internal */\nexport const die = defect => isObject(defect) && !(spanSymbol in defect) ? withFiberRuntime(fiber => failCause(internalCause.die(capture(defect, currentSpanFromFiber(fiber))))) : failCause(internalCause.die(defect));\n/* @internal */\nexport const dieMessage = message => failCauseSync(() => internalCause.die(new RuntimeException(message)));\n/* @internal */\nexport const dieSync = evaluate => flatMap(sync(evaluate), die);\n/* @internal */\nexport const either = self => matchEffect(self, {\n  onFailure: e => succeed(Either.left(e)),\n  onSuccess: a => succeed(Either.right(a))\n});\n/* @internal */\nexport const exit = self => matchCause(self, {\n  onFailure: exitFailCause,\n  onSuccess: exitSucceed\n});\n/* @internal */\nexport const fail = error => isObject(error) && !(spanSymbol in error) ? withFiberRuntime(fiber => failCause(internalCause.fail(capture(error, currentSpanFromFiber(fiber))))) : failCause(internalCause.fail(error));\n/* @internal */\nexport const failSync = evaluate => flatMap(sync(evaluate), fail);\n/* @internal */\nexport const failCause = cause => {\n  const effect = new EffectPrimitiveFailure(OpCodes.OP_FAILURE);\n  effect.effect_instruction_i0 = cause;\n  return effect;\n};\n/* @internal */\nexport const failCauseSync = evaluate => flatMap(sync(evaluate), failCause);\n/* @internal */\nexport const fiberId = /*#__PURE__*/withFiberRuntime(state => succeed(state.id()));\n/* @internal */\nexport const fiberIdWith = f => withFiberRuntime(state => f(state.id()));\n/* @internal */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => {\n  const effect = new EffectPrimitive(OpCodes.OP_ON_SUCCESS);\n  effect.effect_instruction_i0 = self;\n  effect.effect_instruction_i1 = f;\n  return effect;\n});\n/* @internal */\nexport const andThen = /*#__PURE__*/dual(2, (self, f) => flatMap(self, a => {\n  const b = typeof f === \"function\" ? f(a) : f;\n  if (isEffect(b)) {\n    return b;\n  } else if (isPromiseLike(b)) {\n    return async(resume => {\n      b.then(a => resume(succeed(a)), e => resume(fail(new UnknownException(e))));\n    });\n  }\n  return succeed(b);\n}));\n/* @internal */\nexport const step = self => {\n  const effect = new EffectPrimitive(\"OnStep\");\n  effect.effect_instruction_i0 = self;\n  return effect;\n};\n/* @internal */\nexport const flatten = self => flatMap(self, identity);\n/* @internal */\nexport const flip = self => matchEffect(self, {\n  onFailure: succeed,\n  onSuccess: fail\n});\n/* @internal */\nexport const matchCause = /*#__PURE__*/dual(2, (self, options) => matchCauseEffect(self, {\n  onFailure: cause => succeed(options.onFailure(cause)),\n  onSuccess: a => succeed(options.onSuccess(a))\n}));\n/* @internal */\nexport const matchCauseEffect = /*#__PURE__*/dual(2, (self, options) => {\n  const effect = new EffectPrimitive(OpCodes.OP_ON_SUCCESS_AND_FAILURE);\n  effect.effect_instruction_i0 = self;\n  effect.effect_instruction_i1 = options.onFailure;\n  effect.effect_instruction_i2 = options.onSuccess;\n  return effect;\n});\n/* @internal */\nexport const matchEffect = /*#__PURE__*/dual(2, (self, options) => matchCauseEffect(self, {\n  onFailure: cause => {\n    const defects = internalCause.defects(cause);\n    if (defects.length > 0) {\n      return failCause(internalCause.electFailures(cause));\n    }\n    const failures = internalCause.failures(cause);\n    if (failures.length > 0) {\n      return options.onFailure(Chunk.unsafeHead(failures));\n    }\n    return failCause(cause);\n  },\n  onSuccess: options.onSuccess\n}));\n/* @internal */\nexport const forEachSequential = /*#__PURE__*/dual(2, (self, f) => suspend(() => {\n  const arr = Arr.fromIterable(self);\n  const ret = Arr.allocate(arr.length);\n  let i = 0;\n  return as(whileLoop({\n    while: () => i < arr.length,\n    body: () => f(arr[i], i),\n    step: b => {\n      ret[i++] = b;\n    }\n  }), ret);\n}));\n/* @internal */\nexport const forEachSequentialDiscard = /*#__PURE__*/dual(2, (self, f) => suspend(() => {\n  const arr = Arr.fromIterable(self);\n  let i = 0;\n  return whileLoop({\n    while: () => i < arr.length,\n    body: () => f(arr[i], i),\n    step: () => {\n      i++;\n    }\n  });\n}));\n/* @internal */\nexport const if_ = /*#__PURE__*/dual(args => typeof args[0] === \"boolean\" || isEffect(args[0]), (self, options) => isEffect(self) ? flatMap(self, b => b ? options.onTrue() : options.onFalse()) : self ? options.onTrue() : options.onFalse());\n/* @internal */\nexport const interrupt = /*#__PURE__*/flatMap(fiberId, fiberId => interruptWith(fiberId));\n/* @internal */\nexport const interruptWith = fiberId => failCause(internalCause.interrupt(fiberId));\n/* @internal */\nexport const interruptible = self => {\n  const effect = new EffectPrimitive(OpCodes.OP_UPDATE_RUNTIME_FLAGS);\n  effect.effect_instruction_i0 = RuntimeFlagsPatch.enable(_runtimeFlags.Interruption);\n  effect.effect_instruction_i1 = () => self;\n  return effect;\n};\n/* @internal */\nexport const interruptibleMask = f => custom(f, function () {\n  const effect = new EffectPrimitive(OpCodes.OP_UPDATE_RUNTIME_FLAGS);\n  effect.effect_instruction_i0 = RuntimeFlagsPatch.enable(_runtimeFlags.Interruption);\n  effect.effect_instruction_i1 = oldFlags => _runtimeFlags.interruption(oldFlags) ? internalCall(() => this.effect_instruction_i0(interruptible)) : internalCall(() => this.effect_instruction_i0(uninterruptible));\n  return effect;\n});\n/* @internal */\nexport const intoDeferred = /*#__PURE__*/dual(2, (self, deferred) => uninterruptibleMask(restore => flatMap(exit(restore(self)), exit => deferredDone(deferred, exit))));\n/* @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => flatMap(self, a => sync(() => f(a))));\n/* @internal */\nexport const mapBoth = /*#__PURE__*/dual(2, (self, options) => matchEffect(self, {\n  onFailure: e => failSync(() => options.onFailure(e)),\n  onSuccess: a => sync(() => options.onSuccess(a))\n}));\n/* @internal */\nexport const mapError = /*#__PURE__*/dual(2, (self, f) => matchCauseEffect(self, {\n  onFailure: cause => {\n    const either = internalCause.failureOrCause(cause);\n    switch (either._tag) {\n      case \"Left\":\n        {\n          return failSync(() => f(either.left));\n        }\n      case \"Right\":\n        {\n          return failCause(either.right);\n        }\n    }\n  },\n  onSuccess: succeed\n}));\n/* @internal */\nexport const onError = /*#__PURE__*/dual(2, (self, cleanup) => onExit(self, exit => exitIsSuccess(exit) ? void_ : cleanup(exit.effect_instruction_i0)));\n/* @internal */\nexport const onExit = /*#__PURE__*/dual(2, (self, cleanup) => uninterruptibleMask(restore => matchCauseEffect(restore(self), {\n  onFailure: cause1 => {\n    const result = exitFailCause(cause1);\n    return matchCauseEffect(cleanup(result), {\n      onFailure: cause2 => exitFailCause(internalCause.sequential(cause1, cause2)),\n      onSuccess: () => result\n    });\n  },\n  onSuccess: success => {\n    const result = exitSucceed(success);\n    return zipRight(cleanup(result), result);\n  }\n})));\n/* @internal */\nexport const onInterrupt = /*#__PURE__*/dual(2, (self, cleanup) => onExit(self, exitMatch({\n  onFailure: cause => internalCause.isInterruptedOnly(cause) ? asVoid(cleanup(internalCause.interruptors(cause))) : void_,\n  onSuccess: () => void_\n})));\n/* @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => attemptOrElse(self, that, succeed));\n/* @internal */\nexport const orDie = self => orDieWith(self, identity);\n/* @internal */\nexport const orDieWith = /*#__PURE__*/dual(2, (self, f) => matchEffect(self, {\n  onFailure: e => die(f(e)),\n  onSuccess: succeed\n}));\n/* @internal */\nexport const partitionMap = (elements, f) => Arr.fromIterable(elements).reduceRight(([lefts, rights], current) => {\n  const either = f(current);\n  switch (either._tag) {\n    case \"Left\":\n      {\n        return [[either.left, ...lefts], rights];\n      }\n    case \"Right\":\n      {\n        return [lefts, [either.right, ...rights]];\n      }\n  }\n}, [Arr.empty(), Arr.empty()]);\n/* @internal */\nexport const runtimeFlags = /*#__PURE__*/withFiberRuntime((_, status) => succeed(status.runtimeFlags));\n/* @internal */\nexport const succeed = value => {\n  const effect = new EffectPrimitiveSuccess(OpCodes.OP_SUCCESS);\n  effect.effect_instruction_i0 = value;\n  return effect;\n};\n/* @internal */\nexport const suspend = effect => flatMap(sync(effect), identity);\n/* @internal */\nexport const sync = evaluate => {\n  const effect = new EffectPrimitive(OpCodes.OP_SYNC);\n  effect.effect_instruction_i0 = evaluate;\n  return effect;\n};\n/* @internal */\nexport const tap = /*#__PURE__*/dual(2, (self, f) => flatMap(self, a => {\n  const b = typeof f === \"function\" ? f(a) : f;\n  if (isEffect(b)) {\n    return as(b, a);\n  } else if (isPromiseLike(b)) {\n    return async(resume => {\n      b.then(_ => resume(succeed(a)), e => resume(fail(new UnknownException(e))));\n    });\n  }\n  return succeed(a);\n}));\n/* @internal */\nexport const transplant = f => withFiberRuntime(state => {\n  const scopeOverride = state.getFiberRef(currentForkScopeOverride);\n  const scope = pipe(scopeOverride, Option.getOrElse(() => state.scope()));\n  return f(fiberRefLocally(currentForkScopeOverride, Option.some(scope)));\n});\n/* @internal */\nexport const attemptOrElse = /*#__PURE__*/dual(3, (self, that, onSuccess) => matchCauseEffect(self, {\n  onFailure: cause => {\n    const defects = internalCause.defects(cause);\n    if (defects.length > 0) {\n      return failCause(Option.getOrThrow(internalCause.keepDefectsAndElectFailures(cause)));\n    }\n    return that();\n  },\n  onSuccess\n}));\n/* @internal */\nexport const uninterruptible = self => {\n  const effect = new EffectPrimitive(OpCodes.OP_UPDATE_RUNTIME_FLAGS);\n  effect.effect_instruction_i0 = RuntimeFlagsPatch.disable(_runtimeFlags.Interruption);\n  effect.effect_instruction_i1 = () => self;\n  return effect;\n};\n/* @internal */\nexport const uninterruptibleMask = f => custom(f, function () {\n  const effect = new EffectPrimitive(OpCodes.OP_UPDATE_RUNTIME_FLAGS);\n  effect.effect_instruction_i0 = RuntimeFlagsPatch.disable(_runtimeFlags.Interruption);\n  effect.effect_instruction_i1 = oldFlags => _runtimeFlags.interruption(oldFlags) ? internalCall(() => this.effect_instruction_i0(interruptible)) : internalCall(() => this.effect_instruction_i0(uninterruptible));\n  return effect;\n});\nconst void_ = /*#__PURE__*/succeed(void 0);\nexport { /* @internal */\nvoid_ as void };\n/* @internal */\nexport const updateRuntimeFlags = patch => {\n  const effect = new EffectPrimitive(OpCodes.OP_UPDATE_RUNTIME_FLAGS);\n  effect.effect_instruction_i0 = patch;\n  effect.effect_instruction_i1 = void 0;\n  return effect;\n};\n/* @internal */\nexport const whenEffect = /*#__PURE__*/dual(2, (self, condition) => flatMap(condition, b => {\n  if (b) {\n    return pipe(self, map(Option.some));\n  }\n  return succeed(Option.none());\n}));\n/* @internal */\nexport const whileLoop = options => {\n  const effect = new EffectPrimitive(OpCodes.OP_WHILE);\n  effect.effect_instruction_i0 = options.while;\n  effect.effect_instruction_i1 = options.body;\n  effect.effect_instruction_i2 = options.step;\n  return effect;\n};\n/* @internal */\nexport const withConcurrency = /*#__PURE__*/dual(2, (self, concurrency) => fiberRefLocally(self, currentConcurrency, concurrency));\n/* @internal */\nexport const withRequestBatching = /*#__PURE__*/dual(2, (self, requestBatching) => fiberRefLocally(self, currentRequestBatching, requestBatching));\n/* @internal */\nexport const withRuntimeFlags = /*#__PURE__*/dual(2, (self, update) => {\n  const effect = new EffectPrimitive(OpCodes.OP_UPDATE_RUNTIME_FLAGS);\n  effect.effect_instruction_i0 = update;\n  effect.effect_instruction_i1 = () => self;\n  return effect;\n});\n/** @internal */\nexport const withTracerEnabled = /*#__PURE__*/dual(2, (effect, enabled) => fiberRefLocally(effect, currentTracerEnabled, enabled));\n/** @internal */\nexport const withTracerTiming = /*#__PURE__*/dual(2, (effect, enabled) => fiberRefLocally(effect, currentTracerTimingEnabled, enabled));\n/* @internal */\nexport const yieldNow = options => {\n  const effect = new EffectPrimitive(OpCodes.OP_YIELD);\n  return typeof options?.priority !== \"undefined\" ? withSchedulingPriority(effect, options.priority) : effect;\n};\n/* @internal */\nexport const zip = /*#__PURE__*/dual(2, (self, that) => flatMap(self, a => map(that, b => [a, b])));\n/* @internal */\nexport const zipFlatten = /*#__PURE__*/dual(2, (self, that) => flatMap(self, a => map(that, b => [...a, b])));\n/* @internal */\nexport const zipLeft = /*#__PURE__*/dual(2, (self, that) => flatMap(self, a => as(that, a)));\n/* @internal */\nexport const zipRight = /*#__PURE__*/dual(2, (self, that) => flatMap(self, () => that));\n/* @internal */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => flatMap(self, a => map(that, b => f(a, b))));\n/* @internal */\nexport const never = /*#__PURE__*/async(() => {\n  const interval = setInterval(() => {\n    //\n  }, 2 ** 31 - 1);\n  return sync(() => clearInterval(interval));\n});\n// -----------------------------------------------------------------------------\n// Fiber\n// -----------------------------------------------------------------------------\n/* @internal */\nexport const interruptFiber = self => flatMap(fiberId, fiberId => pipe(self, interruptAsFiber(fiberId)));\n/* @internal */\nexport const interruptAsFiber = /*#__PURE__*/dual(2, (self, fiberId) => flatMap(self.interruptAsFork(fiberId), () => self.await));\n// -----------------------------------------------------------------------------\n// LogLevel\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const logLevelAll = {\n  _tag: \"All\",\n  syslog: 0,\n  label: \"ALL\",\n  ordinal: Number.MIN_SAFE_INTEGER,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const logLevelFatal = {\n  _tag: \"Fatal\",\n  syslog: 2,\n  label: \"FATAL\",\n  ordinal: 50000,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const logLevelError = {\n  _tag: \"Error\",\n  syslog: 3,\n  label: \"ERROR\",\n  ordinal: 40000,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const logLevelWarning = {\n  _tag: \"Warning\",\n  syslog: 4,\n  label: \"WARN\",\n  ordinal: 30000,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const logLevelInfo = {\n  _tag: \"Info\",\n  syslog: 6,\n  label: \"INFO\",\n  ordinal: 20000,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const logLevelDebug = {\n  _tag: \"Debug\",\n  syslog: 7,\n  label: \"DEBUG\",\n  ordinal: 10000,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const logLevelTrace = {\n  _tag: \"Trace\",\n  syslog: 7,\n  label: \"TRACE\",\n  ordinal: 0,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const logLevelNone = {\n  _tag: \"None\",\n  syslog: 7,\n  label: \"OFF\",\n  ordinal: Number.MAX_SAFE_INTEGER,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const allLogLevels = [logLevelAll, logLevelTrace, logLevelDebug, logLevelInfo, logLevelWarning, logLevelError, logLevelFatal, logLevelNone];\n// -----------------------------------------------------------------------------\n// FiberRef\n// -----------------------------------------------------------------------------\n/** @internal */\nconst FiberRefSymbolKey = \"effect/FiberRef\";\n/** @internal */\nexport const FiberRefTypeId = /*#__PURE__*/Symbol.for(FiberRefSymbolKey);\nconst fiberRefVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\n/* @internal */\nexport const fiberRefGet = self => fiberRefModify(self, a => [a, a]);\n/* @internal */\nexport const fiberRefGetAndSet = /*#__PURE__*/dual(2, (self, value) => fiberRefModify(self, v => [v, value]));\n/* @internal */\nexport const fiberRefGetAndUpdate = /*#__PURE__*/dual(2, (self, f) => fiberRefModify(self, v => [v, f(v)]));\n/* @internal */\nexport const fiberRefGetAndUpdateSome = /*#__PURE__*/dual(2, (self, pf) => fiberRefModify(self, v => [v, Option.getOrElse(pf(v), () => v)]));\n/* @internal */\nexport const fiberRefGetWith = /*#__PURE__*/dual(2, (self, f) => flatMap(fiberRefGet(self), f));\n/* @internal */\nexport const fiberRefSet = /*#__PURE__*/dual(2, (self, value) => fiberRefModify(self, () => [void 0, value]));\n/* @internal */\nexport const fiberRefDelete = self => withFiberRuntime(state => {\n  state.unsafeDeleteFiberRef(self);\n  return void_;\n});\n/* @internal */\nexport const fiberRefReset = self => fiberRefSet(self, self.initial);\n/* @internal */\nexport const fiberRefModify = /*#__PURE__*/dual(2, (self, f) => withFiberRuntime(state => {\n  const [b, a] = f(state.getFiberRef(self));\n  state.setFiberRef(self, a);\n  return succeed(b);\n}));\n/* @internal */\nexport const fiberRefModifySome = (self, def, f) => fiberRefModify(self, v => Option.getOrElse(f(v), () => [def, v]));\n/* @internal */\nexport const fiberRefUpdate = /*#__PURE__*/dual(2, (self, f) => fiberRefModify(self, v => [void 0, f(v)]));\n/* @internal */\nexport const fiberRefUpdateSome = /*#__PURE__*/dual(2, (self, pf) => fiberRefModify(self, v => [void 0, Option.getOrElse(pf(v), () => v)]));\n/* @internal */\nexport const fiberRefUpdateAndGet = /*#__PURE__*/dual(2, (self, f) => fiberRefModify(self, v => {\n  const result = f(v);\n  return [result, result];\n}));\n/* @internal */\nexport const fiberRefUpdateSomeAndGet = /*#__PURE__*/dual(2, (self, pf) => fiberRefModify(self, v => {\n  const result = Option.getOrElse(pf(v), () => v);\n  return [result, result];\n}));\n// circular\n/** @internal */\nconst RequestResolverSymbolKey = \"effect/RequestResolver\";\n/** @internal */\nexport const RequestResolverTypeId = /*#__PURE__*/Symbol.for(RequestResolverSymbolKey);\nconst requestResolverVariance = {\n  /* c8 ignore next */\n  _A: _ => _,\n  /* c8 ignore next */\n  _R: _ => _\n};\n/** @internal */\nexport class RequestResolverImpl {\n  runAll;\n  target;\n  [RequestResolverTypeId] = requestResolverVariance;\n  constructor(runAll, target) {\n    this.runAll = runAll;\n    this.target = target;\n  }\n  [Hash.symbol]() {\n    return Hash.cached(this, this.target ? Hash.hash(this.target) : Hash.random(this));\n  }\n  [Equal.symbol](that) {\n    return this.target ? isRequestResolver(that) && Equal.equals(this.target, that.target) : this === that;\n  }\n  identified(...ids) {\n    return new RequestResolverImpl(this.runAll, Chunk.fromIterable(ids));\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const isRequestResolver = u => hasProperty(u, RequestResolverTypeId);\n// end\n/** @internal */\nexport const resolverLocally = /*#__PURE__*/dual(3, (use, self, value) => new RequestResolverImpl(requests => fiberRefLocally(use.runAll(requests), self, value), Chunk.make(\"Locally\", use, self, value)));\n/** @internal */\nexport const requestBlockLocally = (self, ref, value) => _blockedRequests.reduce(self, LocallyReducer(ref, value));\nconst LocallyReducer = (ref, value) => ({\n  emptyCase: () => _blockedRequests.empty,\n  parCase: (left, right) => _blockedRequests.par(left, right),\n  seqCase: (left, right) => _blockedRequests.seq(left, right),\n  singleCase: (dataSource, blockedRequest) => _blockedRequests.single(resolverLocally(dataSource, ref, value), blockedRequest)\n});\n/* @internal */\nexport const fiberRefLocally = /*#__PURE__*/dual(3, (use, self, value) => acquireUseRelease(zipLeft(fiberRefGet(self), fiberRefSet(self, value)), () => use, oldValue => fiberRefSet(self, oldValue)));\n/* @internal */\nexport const fiberRefLocallyWith = /*#__PURE__*/dual(3, (use, self, f) => fiberRefGetWith(self, a => fiberRefLocally(use, self, f(a))));\n/** @internal */\nexport const fiberRefUnsafeMake = (initial, options) => fiberRefUnsafeMakePatch(initial, {\n  differ: internalDiffer.update(),\n  fork: options?.fork ?? identity,\n  join: options?.join\n});\n/** @internal */\nexport const fiberRefUnsafeMakeHashSet = initial => {\n  const differ = internalDiffer.hashSet();\n  return fiberRefUnsafeMakePatch(initial, {\n    differ,\n    fork: differ.empty\n  });\n};\n/** @internal */\nexport const fiberRefUnsafeMakeReadonlyArray = initial => {\n  const differ = internalDiffer.readonlyArray(internalDiffer.update());\n  return fiberRefUnsafeMakePatch(initial, {\n    differ,\n    fork: differ.empty\n  });\n};\n/** @internal */\nexport const fiberRefUnsafeMakeContext = initial => {\n  const differ = internalDiffer.environment();\n  return fiberRefUnsafeMakePatch(initial, {\n    differ,\n    fork: differ.empty\n  });\n};\n/** @internal */\nexport const fiberRefUnsafeMakePatch = (initial, options) => ({\n  [FiberRefTypeId]: fiberRefVariance,\n  initial,\n  diff: (oldValue, newValue) => options.differ.diff(oldValue, newValue),\n  combine: (first, second) => options.differ.combine(first, second),\n  patch: patch => oldValue => options.differ.patch(patch, oldValue),\n  fork: options.fork,\n  join: options.join ?? ((_, n) => n),\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n});\n/** @internal */\nexport const fiberRefUnsafeMakeRuntimeFlags = initial => fiberRefUnsafeMakePatch(initial, {\n  differ: _runtimeFlags.differ,\n  fork: _runtimeFlags.differ.empty\n});\n/** @internal */\nexport const currentContext = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentContext\"), () => fiberRefUnsafeMakeContext(Context.empty()));\n/** @internal */\nexport const currentSchedulingPriority = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentSchedulingPriority\"), () => fiberRefUnsafeMake(0));\n/** @internal */\nexport const currentMaxOpsBeforeYield = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentMaxOpsBeforeYield\"), () => fiberRefUnsafeMake(2048));\n/** @internal */\nexport const currentLogAnnotations = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentLogAnnotation\"), () => fiberRefUnsafeMake(HashMap.empty()));\n/** @internal */\nexport const currentLogLevel = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentLogLevel\"), () => fiberRefUnsafeMake(logLevelInfo));\n/** @internal */\nexport const currentLogSpan = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentLogSpan\"), () => fiberRefUnsafeMake(List.empty()));\n/** @internal */\nexport const withSchedulingPriority = /*#__PURE__*/dual(2, (self, scheduler) => fiberRefLocally(self, currentSchedulingPriority, scheduler));\n/** @internal */\nexport const withMaxOpsBeforeYield = /*#__PURE__*/dual(2, (self, scheduler) => fiberRefLocally(self, currentMaxOpsBeforeYield, scheduler));\n/** @internal */\nexport const currentConcurrency = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentConcurrency\"), () => fiberRefUnsafeMake(\"unbounded\"));\n/**\n * @internal\n */\nexport const currentRequestBatching = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentRequestBatching\"), () => fiberRefUnsafeMake(true));\n/** @internal */\nexport const currentUnhandledErrorLogLevel = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentUnhandledErrorLogLevel\"), () => fiberRefUnsafeMake(Option.some(logLevelDebug)));\n/** @internal */\nexport const withUnhandledErrorLogLevel = /*#__PURE__*/dual(2, (self, level) => fiberRefLocally(self, currentUnhandledErrorLogLevel, level));\n/** @internal */\nexport const currentMetricLabels = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentMetricLabels\"), () => fiberRefUnsafeMakeReadonlyArray(Arr.empty()));\n/* @internal */\nexport const metricLabels = /*#__PURE__*/fiberRefGet(currentMetricLabels);\n/** @internal */\nexport const currentForkScopeOverride = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentForkScopeOverride\"), () => fiberRefUnsafeMake(Option.none(), {\n  fork: () => Option.none(),\n  join: (parent, _) => parent\n}));\n/** @internal */\nexport const currentInterruptedCause = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentInterruptedCause\"), () => fiberRefUnsafeMake(internalCause.empty, {\n  fork: () => internalCause.empty,\n  join: (parent, _) => parent\n}));\n/** @internal */\nexport const currentTracerEnabled = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentTracerEnabled\"), () => fiberRefUnsafeMake(true));\n/** @internal */\nexport const currentTracerTimingEnabled = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentTracerTiming\"), () => fiberRefUnsafeMake(true));\n/** @internal */\nexport const currentTracerSpanAnnotations = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentTracerSpanAnnotations\"), () => fiberRefUnsafeMake(HashMap.empty()));\n/** @internal */\nexport const currentTracerSpanLinks = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentTracerSpanLinks\"), () => fiberRefUnsafeMake(Chunk.empty()));\n// -----------------------------------------------------------------------------\n// Scope\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const ScopeTypeId = /*#__PURE__*/Symbol.for(\"effect/Scope\");\n/** @internal */\nexport const CloseableScopeTypeId = /*#__PURE__*/Symbol.for(\"effect/CloseableScope\");\n/* @internal */\nexport const scopeAddFinalizer = (self, finalizer) => self.addFinalizer(() => asVoid(finalizer));\n/* @internal */\nexport const scopeAddFinalizerExit = (self, finalizer) => self.addFinalizer(finalizer);\n/* @internal */\nexport const scopeClose = (self, exit) => self.close(exit);\n/* @internal */\nexport const scopeFork = (self, strategy) => self.fork(strategy);\n// -----------------------------------------------------------------------------\n// Cause\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const causeSquash = self => {\n  return causeSquashWith(identity)(self);\n};\n/** @internal */\nexport const causeSquashWith = /*#__PURE__*/dual(2, (self, f) => {\n  const option = pipe(self, internalCause.failureOption, Option.map(f));\n  switch (option._tag) {\n    case \"None\":\n      {\n        return pipe(internalCause.defects(self), Chunk.head, Option.match({\n          onNone: () => {\n            const interrupts = Arr.fromIterable(internalCause.interruptors(self)).flatMap(fiberId => Arr.fromIterable(FiberId.ids(fiberId)).map(id => `#${id}`));\n            return new InterruptedException(interrupts ? `Interrupted by fibers: ${interrupts.join(\", \")}` : void 0);\n          },\n          onSome: identity\n        }));\n      }\n    case \"Some\":\n      {\n        return option.value;\n      }\n  }\n});\n// -----------------------------------------------------------------------------\n// Errors\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const YieldableError = /*#__PURE__*/function () {\n  class YieldableError extends globalThis.Error {\n    commit() {\n      return fail(this);\n    }\n    toJSON() {\n      return {\n        ...this\n      };\n    }\n    [NodeInspectSymbol]() {\n      if (this.toString !== globalThis.Error.prototype.toString) {\n        return this.stack ? `${this.toString()}\\n${this.stack.split(\"\\n\").slice(1).join(\"\\n\")}` : this.toString();\n      } else if (\"Bun\" in globalThis) {\n        return internalCause.pretty(internalCause.fail(this), {\n          renderErrorCause: true\n        });\n      }\n      return this;\n    }\n  }\n  Object.assign(YieldableError.prototype, StructuralCommitPrototype);\n  return YieldableError;\n}();\nconst makeException = (proto, tag) => {\n  class Base extends YieldableError {\n    _tag = tag;\n  }\n  Object.assign(Base.prototype, proto);\n  Base.prototype.name = tag;\n  return Base;\n};\n/** @internal */\nexport const RuntimeExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Cause/errors/RuntimeException\");\n/** @internal */\nexport const RuntimeException = /*#__PURE__*/makeException({\n  [RuntimeExceptionTypeId]: RuntimeExceptionTypeId\n}, \"RuntimeException\");\n/** @internal */\nexport const isRuntimeException = u => hasProperty(u, RuntimeExceptionTypeId);\n/** @internal */\nexport const InterruptedExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Cause/errors/InterruptedException\");\n/** @internal */\nexport const InterruptedException = /*#__PURE__*/makeException({\n  [InterruptedExceptionTypeId]: InterruptedExceptionTypeId\n}, \"InterruptedException\");\n/** @internal */\nexport const isInterruptedException = u => hasProperty(u, InterruptedExceptionTypeId);\n/** @internal */\nexport const IllegalArgumentExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Cause/errors/IllegalArgument\");\n/** @internal */\nexport const IllegalArgumentException = /*#__PURE__*/makeException({\n  [IllegalArgumentExceptionTypeId]: IllegalArgumentExceptionTypeId\n}, \"IllegalArgumentException\");\n/** @internal */\nexport const isIllegalArgumentException = u => hasProperty(u, IllegalArgumentExceptionTypeId);\n/** @internal */\nexport const NoSuchElementExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Cause/errors/NoSuchElement\");\n/** @internal */\nexport const NoSuchElementException = /*#__PURE__*/makeException({\n  [NoSuchElementExceptionTypeId]: NoSuchElementExceptionTypeId\n}, \"NoSuchElementException\");\n/** @internal */\nexport const isNoSuchElementException = u => hasProperty(u, NoSuchElementExceptionTypeId);\n/** @internal */\nexport const InvalidPubSubCapacityExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Cause/errors/InvalidPubSubCapacityException\");\n/** @internal */\nexport const InvalidPubSubCapacityException = /*#__PURE__*/makeException({\n  [InvalidPubSubCapacityExceptionTypeId]: InvalidPubSubCapacityExceptionTypeId\n}, \"InvalidPubSubCapacityException\");\n/** @internal */\nexport const ExceededCapacityExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Cause/errors/ExceededCapacityException\");\n/** @internal */\nexport const ExceededCapacityException = /*#__PURE__*/makeException({\n  [ExceededCapacityExceptionTypeId]: ExceededCapacityExceptionTypeId\n}, \"ExceededCapacityException\");\n/** @internal */\nexport const isExceededCapacityException = u => hasProperty(u, ExceededCapacityExceptionTypeId);\n/** @internal */\nexport const isInvalidCapacityError = u => hasProperty(u, InvalidPubSubCapacityExceptionTypeId);\n/** @internal */\nexport const TimeoutExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Cause/errors/Timeout\");\n/** @internal */\nexport const TimeoutException = /*#__PURE__*/makeException({\n  [TimeoutExceptionTypeId]: TimeoutExceptionTypeId\n}, \"TimeoutException\");\n/** @internal */\nexport const timeoutExceptionFromDuration = duration => new TimeoutException(`Operation timed out before the specified duration of '${Duration.format(duration)}' elapsed`);\n/** @internal */\nexport const isTimeoutException = u => hasProperty(u, TimeoutExceptionTypeId);\n/** @internal */\nexport const UnknownExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Cause/errors/UnknownException\");\n/** @internal */\nexport const UnknownException = /*#__PURE__*/function () {\n  class UnknownException extends YieldableError {\n    cause;\n    _tag = \"UnknownException\";\n    error;\n    constructor(cause, message) {\n      super(message ?? \"An unknown error occurred\", {\n        cause\n      });\n      this.cause = cause;\n      this.error = cause;\n    }\n  }\n  Object.assign(UnknownException.prototype, {\n    [UnknownExceptionTypeId]: UnknownExceptionTypeId,\n    name: \"UnknownException\"\n  });\n  return UnknownException;\n}();\n/** @internal */\nexport const isUnknownException = u => hasProperty(u, UnknownExceptionTypeId);\n// -----------------------------------------------------------------------------\n// Exit\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const exitIsExit = u => isEffect(u) && \"_tag\" in u && (u._tag === \"Success\" || u._tag === \"Failure\");\n/** @internal */\nexport const exitIsFailure = self => self._tag === \"Failure\";\n/** @internal */\nexport const exitIsSuccess = self => self._tag === \"Success\";\n/** @internal */\nexport const exitIsInterrupted = self => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return internalCause.isInterrupted(self.effect_instruction_i0);\n    case OpCodes.OP_SUCCESS:\n      return false;\n  }\n};\n/** @internal */\nexport const exitAs = /*#__PURE__*/dual(2, (self, value) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      {\n        return exitFailCause(self.effect_instruction_i0);\n      }\n    case OpCodes.OP_SUCCESS:\n      {\n        return exitSucceed(value);\n      }\n  }\n});\n/** @internal */\nexport const exitAsVoid = self => exitAs(self, void 0);\n/** @internal */\nexport const exitCauseOption = self => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return Option.some(self.effect_instruction_i0);\n    case OpCodes.OP_SUCCESS:\n      return Option.none();\n  }\n};\n/** @internal */\nexport const exitCollectAll = (exits, options) => exitCollectAllInternal(exits, options?.parallel ? internalCause.parallel : internalCause.sequential);\n/** @internal */\nexport const exitDie = defect => exitFailCause(internalCause.die(defect));\n/** @internal */\nexport const exitExists = /*#__PURE__*/dual(2, (self, refinement) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return false;\n    case OpCodes.OP_SUCCESS:\n      return refinement(self.effect_instruction_i0);\n  }\n});\n/** @internal */\nexport const exitFail = error => exitFailCause(internalCause.fail(error));\n/** @internal */\nexport const exitFailCause = cause => {\n  const effect = new EffectPrimitiveFailure(OpCodes.OP_FAILURE);\n  effect.effect_instruction_i0 = cause;\n  return effect;\n};\n/** @internal */\nexport const exitFlatMap = /*#__PURE__*/dual(2, (self, f) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      {\n        return exitFailCause(self.effect_instruction_i0);\n      }\n    case OpCodes.OP_SUCCESS:\n      {\n        return f(self.effect_instruction_i0);\n      }\n  }\n});\n/** @internal */\nexport const exitFlatMapEffect = /*#__PURE__*/dual(2, (self, f) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      {\n        return succeed(exitFailCause(self.effect_instruction_i0));\n      }\n    case OpCodes.OP_SUCCESS:\n      {\n        return f(self.effect_instruction_i0);\n      }\n  }\n});\n/** @internal */\nexport const exitFlatten = self => pipe(self, exitFlatMap(identity));\n/** @internal */\nexport const exitForEachEffect = /*#__PURE__*/dual(2, (self, f) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      {\n        return succeed(exitFailCause(self.effect_instruction_i0));\n      }\n    case OpCodes.OP_SUCCESS:\n      {\n        return exit(f(self.effect_instruction_i0));\n      }\n  }\n});\n/** @internal */\nexport const exitFromEither = either => {\n  switch (either._tag) {\n    case \"Left\":\n      return exitFail(either.left);\n    case \"Right\":\n      return exitSucceed(either.right);\n  }\n};\n/** @internal */\nexport const exitFromOption = option => {\n  switch (option._tag) {\n    case \"None\":\n      return exitFail(void 0);\n    case \"Some\":\n      return exitSucceed(option.value);\n  }\n};\n/** @internal */\nexport const exitGetOrElse = /*#__PURE__*/dual(2, (self, orElse) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return orElse(self.effect_instruction_i0);\n    case OpCodes.OP_SUCCESS:\n      return self.effect_instruction_i0;\n  }\n});\n/** @internal */\nexport const exitInterrupt = fiberId => exitFailCause(internalCause.interrupt(fiberId));\n/** @internal */\nexport const exitMap = /*#__PURE__*/dual(2, (self, f) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return exitFailCause(self.effect_instruction_i0);\n    case OpCodes.OP_SUCCESS:\n      return exitSucceed(f(self.effect_instruction_i0));\n  }\n});\n/** @internal */\nexport const exitMapBoth = /*#__PURE__*/dual(2, (self, {\n  onFailure,\n  onSuccess\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return exitFailCause(pipe(self.effect_instruction_i0, internalCause.map(onFailure)));\n    case OpCodes.OP_SUCCESS:\n      return exitSucceed(onSuccess(self.effect_instruction_i0));\n  }\n});\n/** @internal */\nexport const exitMapError = /*#__PURE__*/dual(2, (self, f) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return exitFailCause(pipe(self.effect_instruction_i0, internalCause.map(f)));\n    case OpCodes.OP_SUCCESS:\n      return exitSucceed(self.effect_instruction_i0);\n  }\n});\n/** @internal */\nexport const exitMapErrorCause = /*#__PURE__*/dual(2, (self, f) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return exitFailCause(f(self.effect_instruction_i0));\n    case OpCodes.OP_SUCCESS:\n      return exitSucceed(self.effect_instruction_i0);\n  }\n});\n/** @internal */\nexport const exitMatch = /*#__PURE__*/dual(2, (self, {\n  onFailure,\n  onSuccess\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return onFailure(self.effect_instruction_i0);\n    case OpCodes.OP_SUCCESS:\n      return onSuccess(self.effect_instruction_i0);\n  }\n});\n/** @internal */\nexport const exitMatchEffect = /*#__PURE__*/dual(2, (self, {\n  onFailure,\n  onSuccess\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      return onFailure(self.effect_instruction_i0);\n    case OpCodes.OP_SUCCESS:\n      return onSuccess(self.effect_instruction_i0);\n  }\n});\n/** @internal */\nexport const exitSucceed = value => {\n  const effect = new EffectPrimitiveSuccess(OpCodes.OP_SUCCESS);\n  effect.effect_instruction_i0 = value;\n  return effect;\n};\n/** @internal */\nexport const exitVoid = /*#__PURE__*/exitSucceed(void 0);\n/** @internal */\nexport const exitZip = /*#__PURE__*/dual(2, (self, that) => exitZipWith(self, that, {\n  onSuccess: (a, a2) => [a, a2],\n  onFailure: internalCause.sequential\n}));\n/** @internal */\nexport const exitZipLeft = /*#__PURE__*/dual(2, (self, that) => exitZipWith(self, that, {\n  onSuccess: (a, _) => a,\n  onFailure: internalCause.sequential\n}));\n/** @internal */\nexport const exitZipRight = /*#__PURE__*/dual(2, (self, that) => exitZipWith(self, that, {\n  onSuccess: (_, a2) => a2,\n  onFailure: internalCause.sequential\n}));\n/** @internal */\nexport const exitZipPar = /*#__PURE__*/dual(2, (self, that) => exitZipWith(self, that, {\n  onSuccess: (a, a2) => [a, a2],\n  onFailure: internalCause.parallel\n}));\n/** @internal */\nexport const exitZipParLeft = /*#__PURE__*/dual(2, (self, that) => exitZipWith(self, that, {\n  onSuccess: (a, _) => a,\n  onFailure: internalCause.parallel\n}));\n/** @internal */\nexport const exitZipParRight = /*#__PURE__*/dual(2, (self, that) => exitZipWith(self, that, {\n  onSuccess: (_, a2) => a2,\n  onFailure: internalCause.parallel\n}));\n/** @internal */\nexport const exitZipWith = /*#__PURE__*/dual(3, (self, that, {\n  onFailure,\n  onSuccess\n}) => {\n  switch (self._tag) {\n    case OpCodes.OP_FAILURE:\n      {\n        switch (that._tag) {\n          case OpCodes.OP_SUCCESS:\n            return exitFailCause(self.effect_instruction_i0);\n          case OpCodes.OP_FAILURE:\n            {\n              return exitFailCause(onFailure(self.effect_instruction_i0, that.effect_instruction_i0));\n            }\n        }\n      }\n    case OpCodes.OP_SUCCESS:\n      {\n        switch (that._tag) {\n          case OpCodes.OP_SUCCESS:\n            return exitSucceed(onSuccess(self.effect_instruction_i0, that.effect_instruction_i0));\n          case OpCodes.OP_FAILURE:\n            return exitFailCause(that.effect_instruction_i0);\n        }\n      }\n  }\n});\nconst exitCollectAllInternal = (exits, combineCauses) => {\n  const list = Chunk.fromIterable(exits);\n  if (!Chunk.isNonEmpty(list)) {\n    return Option.none();\n  }\n  return pipe(Chunk.tailNonEmpty(list), Arr.reduce(pipe(Chunk.headNonEmpty(list), exitMap(Chunk.of)), (accumulator, current) => pipe(accumulator, exitZipWith(current, {\n    onSuccess: (list, value) => pipe(list, Chunk.prepend(value)),\n    onFailure: combineCauses\n  }))), exitMap(Chunk.reverse), exitMap(chunk => Chunk.toReadonlyArray(chunk)), Option.some);\n};\n// -----------------------------------------------------------------------------\n// Deferred\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const deferredUnsafeMake = fiberId => ({\n  [deferred.DeferredTypeId]: deferred.deferredVariance,\n  state: MutableRef.make(deferred.pending([])),\n  blockingOn: fiberId,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n});\n/* @internal */\nexport const deferredMake = () => flatMap(fiberId, id => deferredMakeAs(id));\n/* @internal */\nexport const deferredMakeAs = fiberId => sync(() => deferredUnsafeMake(fiberId));\n/* @internal */\nexport const deferredAwait = self => async(resume => {\n  const state = MutableRef.get(self.state);\n  switch (state._tag) {\n    case DeferredOpCodes.OP_STATE_DONE:\n      {\n        return resume(state.effect);\n      }\n    case DeferredOpCodes.OP_STATE_PENDING:\n      {\n        // we can push here as the internal state is mutable\n        state.joiners.push(resume);\n        return deferredInterruptJoiner(self, resume);\n      }\n  }\n}, self.blockingOn);\n/* @internal */\nexport const deferredComplete = /*#__PURE__*/dual(2, (self, effect) => intoDeferred(effect, self));\n/* @internal */\nexport const deferredCompleteWith = /*#__PURE__*/dual(2, (self, effect) => sync(() => {\n  const state = MutableRef.get(self.state);\n  switch (state._tag) {\n    case DeferredOpCodes.OP_STATE_DONE:\n      {\n        return false;\n      }\n    case DeferredOpCodes.OP_STATE_PENDING:\n      {\n        MutableRef.set(self.state, deferred.done(effect));\n        for (let i = 0, len = state.joiners.length; i < len; i++) {\n          state.joiners[i](effect);\n        }\n        return true;\n      }\n  }\n}));\n/* @internal */\nexport const deferredDone = /*#__PURE__*/dual(2, (self, exit) => deferredCompleteWith(self, exit));\n/* @internal */\nexport const deferredFail = /*#__PURE__*/dual(2, (self, error) => deferredCompleteWith(self, fail(error)));\n/* @internal */\nexport const deferredFailSync = /*#__PURE__*/dual(2, (self, evaluate) => deferredCompleteWith(self, failSync(evaluate)));\n/* @internal */\nexport const deferredFailCause = /*#__PURE__*/dual(2, (self, cause) => deferredCompleteWith(self, failCause(cause)));\n/* @internal */\nexport const deferredFailCauseSync = /*#__PURE__*/dual(2, (self, evaluate) => deferredCompleteWith(self, failCauseSync(evaluate)));\n/* @internal */\nexport const deferredDie = /*#__PURE__*/dual(2, (self, defect) => deferredCompleteWith(self, die(defect)));\n/* @internal */\nexport const deferredDieSync = /*#__PURE__*/dual(2, (self, evaluate) => deferredCompleteWith(self, dieSync(evaluate)));\n/* @internal */\nexport const deferredInterrupt = self => flatMap(fiberId, fiberId => deferredCompleteWith(self, interruptWith(fiberId)));\n/* @internal */\nexport const deferredInterruptWith = /*#__PURE__*/dual(2, (self, fiberId) => deferredCompleteWith(self, interruptWith(fiberId)));\n/* @internal */\nexport const deferredIsDone = self => sync(() => MutableRef.get(self.state)._tag === DeferredOpCodes.OP_STATE_DONE);\n/* @internal */\nexport const deferredPoll = self => sync(() => {\n  const state = MutableRef.get(self.state);\n  switch (state._tag) {\n    case DeferredOpCodes.OP_STATE_DONE:\n      {\n        return Option.some(state.effect);\n      }\n    case DeferredOpCodes.OP_STATE_PENDING:\n      {\n        return Option.none();\n      }\n  }\n});\n/* @internal */\nexport const deferredSucceed = /*#__PURE__*/dual(2, (self, value) => deferredCompleteWith(self, succeed(value)));\n/* @internal */\nexport const deferredSync = /*#__PURE__*/dual(2, (self, evaluate) => deferredCompleteWith(self, sync(evaluate)));\n/** @internal */\nexport const deferredUnsafeDone = (self, effect) => {\n  const state = MutableRef.get(self.state);\n  if (state._tag === DeferredOpCodes.OP_STATE_PENDING) {\n    MutableRef.set(self.state, deferred.done(effect));\n    for (let i = 0, len = state.joiners.length; i < len; i++) {\n      state.joiners[i](effect);\n    }\n  }\n};\nconst deferredInterruptJoiner = (self, joiner) => sync(() => {\n  const state = MutableRef.get(self.state);\n  if (state._tag === DeferredOpCodes.OP_STATE_PENDING) {\n    const index = state.joiners.indexOf(joiner);\n    if (index >= 0) {\n      // we can splice here as the internal state is mutable\n      state.joiners.splice(index, 1);\n    }\n  }\n});\n// -----------------------------------------------------------------------------\n// Context\n// -----------------------------------------------------------------------------\nconst constContext = /*#__PURE__*/fiberRefGet(currentContext);\n/* @internal */\nexport const context = () => constContext;\n/* @internal */\nexport const contextWith = f => map(context(), f);\n/* @internal */\nexport const contextWithEffect = f => flatMap(context(), f);\n/* @internal */\nexport const provideContext = /*#__PURE__*/dual(2, (self, context) => fiberRefLocally(currentContext, context)(self));\n/* @internal */\nexport const provideSomeContext = /*#__PURE__*/dual(2, (self, context) => fiberRefLocallyWith(currentContext, parent => Context.merge(parent, context))(self));\n/* @internal */\nexport const mapInputContext = /*#__PURE__*/dual(2, (self, f) => contextWithEffect(context => provideContext(self, f(context))));\n// -----------------------------------------------------------------------------\n// Tracing\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const currentSpanFromFiber = fiber => {\n  const span = fiber.getFiberRef(currentContext).unsafeMap.get(internalTracer.spanTag.key);\n  return span !== undefined && span._tag === \"Span\" ? Option.some(span) : Option.none();\n};\nconst NoopSpanProto = {\n  _tag: \"Span\",\n  spanId: \"noop\",\n  traceId: \"noop\",\n  name: \"noop\",\n  sampled: false,\n  parent: /*#__PURE__*/Option.none(),\n  context: /*#__PURE__*/Context.empty(),\n  status: {\n    _tag: \"Ended\",\n    startTime: /*#__PURE__*/BigInt(0),\n    endTime: /*#__PURE__*/BigInt(0),\n    exit: exitVoid\n  },\n  attributes: /*#__PURE__*/new Map(),\n  links: [],\n  kind: \"internal\",\n  attribute() {},\n  event() {},\n  end() {}\n};\n/** @internal */\nexport const noopSpan = name => {\n  const span = Object.create(NoopSpanProto);\n  span.name = name;\n  return span;\n};\n//# sourceMappingURL=core.js.map","import * as Equal from \"../Equal.js\";\nimport * as Hash from \"../Hash.js\";\nimport { StructuralPrototype } from \"./effectable.js\";\n/** @internal */\nexport const ArrayProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(Array.prototype), {\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.array(this));\n  },\n  [Equal.symbol](that) {\n    if (Array.isArray(that) && this.length === that.length) {\n      return this.every((v, i) => Equal.equals(v, that[i]));\n    } else {\n      return false;\n    }\n  }\n});\n/** @internal */\nexport const Structural = /*#__PURE__*/function () {\n  function Structural(args) {\n    if (args) {\n      Object.assign(this, args);\n    }\n  }\n  Structural.prototype = StructuralPrototype;\n  return Structural;\n}();\n/** @internal */\nexport const struct = as => Object.assign(Object.create(StructuralPrototype), as);\n//# sourceMappingURL=data.js.map","import * as Context from \"../Context.js\";\nimport * as Duration from \"../Duration.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as clock from \"./clock.js\";\nimport * as configProvider from \"./configProvider.js\";\nimport * as core from \"./core.js\";\nimport * as console_ from \"./defaultServices/console.js\";\nimport * as random from \"./random.js\";\nimport * as tracer from \"./tracer.js\";\n/** @internal */\nexport const liveServices = /*#__PURE__*/pipe( /*#__PURE__*/Context.empty(), /*#__PURE__*/Context.add(clock.clockTag, /*#__PURE__*/clock.make()), /*#__PURE__*/Context.add(console_.consoleTag, console_.defaultConsole), /*#__PURE__*/Context.add(random.randomTag, /*#__PURE__*/random.make( /*#__PURE__*/Math.random())), /*#__PURE__*/Context.add(configProvider.configProviderTag, /*#__PURE__*/configProvider.fromEnv()), /*#__PURE__*/Context.add(tracer.tracerTag, tracer.nativeTracer));\n/**\n * The `FiberRef` holding the default `Effect` services.\n *\n * @since 2.0.0\n * @category fiberRefs\n */\nexport const currentServices = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/DefaultServices/currentServices\"), () => core.fiberRefUnsafeMakeContext(liveServices));\n// circular with Clock\n/** @internal */\nexport const sleep = duration => {\n  const decodedDuration = Duration.decode(duration);\n  return clockWith(clock => clock.sleep(decodedDuration));\n};\n/** @internal */\nexport const clockWith = f => core.fiberRefGetWith(currentServices, services => f(Context.get(services, clock.clockTag)));\n/** @internal */\nexport const currentTimeMillis = /*#__PURE__*/clockWith(clock => clock.currentTimeMillis);\n/** @internal */\nexport const currentTimeNanos = /*#__PURE__*/clockWith(clock => clock.currentTimeNanos);\n/** @internal */\nexport const withClock = /*#__PURE__*/dual(2, (effect, value) => core.fiberRefLocallyWith(currentServices, Context.add(clock.clockTag, value))(effect));\n// circular with ConfigProvider\n/** @internal */\nexport const withConfigProvider = /*#__PURE__*/dual(2, (effect, value) => core.fiberRefLocallyWith(currentServices, Context.add(configProvider.configProviderTag, value))(effect));\n/** @internal */\nexport const configProviderWith = f => core.fiberRefGetWith(currentServices, services => f(Context.get(services, configProvider.configProviderTag)));\n/** @internal */\nexport const config = config => configProviderWith(_ => _.load(config));\n/** @internal */\nexport const configOrDie = config => core.orDie(configProviderWith(_ => _.load(config)));\n// circular with Random\n/** @internal */\nexport const randomWith = f => core.fiberRefGetWith(currentServices, services => f(Context.get(services, random.randomTag)));\n/** @internal */\nexport const withRandom = /*#__PURE__*/dual(2, (effect, value) => core.fiberRefLocallyWith(currentServices, Context.add(random.randomTag, value))(effect));\n/** @internal */\nexport const next = /*#__PURE__*/randomWith(random => random.next);\n/** @internal */\nexport const nextInt = /*#__PURE__*/randomWith(random => random.nextInt);\n/** @internal */\nexport const nextBoolean = /*#__PURE__*/randomWith(random => random.nextBoolean);\n/** @internal */\nexport const nextRange = (min, max) => randomWith(random => random.nextRange(min, max));\n/** @internal */\nexport const nextIntBetween = (min, max) => randomWith(random => random.nextIntBetween(min, max));\n/** @internal */\nexport const shuffle = elements => randomWith(random => random.shuffle(elements));\n// circular with Tracer\n/** @internal */\nexport const tracerWith = f => core.fiberRefGetWith(currentServices, services => f(Context.get(services, tracer.tracerTag)));\n/** @internal */\nexport const withTracer = /*#__PURE__*/dual(2, (effect, value) => core.fiberRefLocallyWith(currentServices, Context.add(tracer.tracerTag, value))(effect));\n//# sourceMappingURL=defaultServices.js.map","import * as Context from \"../../Context.js\";\nimport * as core from \"../core.js\";\n/** @internal */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/Console\");\n/** @internal */\nexport const consoleTag = /*#__PURE__*/Context.GenericTag(\"effect/Console\");\n/** @internal */\nexport const defaultConsole = {\n  [TypeId]: TypeId,\n  assert(condition, ...args) {\n    return core.sync(() => {\n      console.assert(condition, ...args);\n    });\n  },\n  clear: /*#__PURE__*/core.sync(() => {\n    console.clear();\n  }),\n  count(label) {\n    return core.sync(() => {\n      console.count(label);\n    });\n  },\n  countReset(label) {\n    return core.sync(() => {\n      console.countReset(label);\n    });\n  },\n  debug(...args) {\n    return core.sync(() => {\n      console.debug(...args);\n    });\n  },\n  dir(item, options) {\n    return core.sync(() => {\n      console.dir(item, options);\n    });\n  },\n  dirxml(...args) {\n    return core.sync(() => {\n      console.dirxml(...args);\n    });\n  },\n  error(...args) {\n    return core.sync(() => {\n      console.error(...args);\n    });\n  },\n  group(options) {\n    return options?.collapsed ? core.sync(() => console.groupCollapsed(options?.label)) : core.sync(() => console.group(options?.label));\n  },\n  groupEnd: /*#__PURE__*/core.sync(() => {\n    console.groupEnd();\n  }),\n  info(...args) {\n    return core.sync(() => {\n      console.info(...args);\n    });\n  },\n  log(...args) {\n    return core.sync(() => {\n      console.log(...args);\n    });\n  },\n  table(tabularData, properties) {\n    return core.sync(() => {\n      console.table(tabularData, properties);\n    });\n  },\n  time(label) {\n    return core.sync(() => console.time(label));\n  },\n  timeEnd(label) {\n    return core.sync(() => console.timeEnd(label));\n  },\n  timeLog(label, ...args) {\n    return core.sync(() => {\n      console.timeLog(label, ...args);\n    });\n  },\n  trace(...args) {\n    return core.sync(() => {\n      console.trace(...args);\n    });\n  },\n  warn(...args) {\n    return core.sync(() => {\n      console.warn(...args);\n    });\n  },\n  unsafe: console\n};\n//# sourceMappingURL=console.js.map","import * as OpCodes from \"./opCodes/deferred.js\";\n/** @internal */\nconst DeferredSymbolKey = \"effect/Deferred\";\n/** @internal */\nexport const DeferredTypeId = /*#__PURE__*/Symbol.for(DeferredSymbolKey);\n/** @internal */\nexport const deferredVariance = {\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _A: _ => _\n};\n/** @internal */\nexport const pending = joiners => {\n  return {\n    _tag: OpCodes.OP_STATE_PENDING,\n    joiners\n  };\n};\n/** @internal */\nexport const done = effect => {\n  return {\n    _tag: OpCodes.OP_STATE_DONE,\n    effect\n  };\n};\n//# sourceMappingURL=deferred.js.map","import * as Equal from \"../Equal.js\";\nimport * as Dual from \"../Function.js\";\nimport { constant, identity } from \"../Function.js\";\nimport * as ChunkPatch from \"./differ/chunkPatch.js\";\nimport * as ContextPatch from \"./differ/contextPatch.js\";\nimport * as HashMapPatch from \"./differ/hashMapPatch.js\";\nimport * as HashSetPatch from \"./differ/hashSetPatch.js\";\nimport * as OrPatch from \"./differ/orPatch.js\";\nimport * as ReadonlyArrayPatch from \"./differ/readonlyArrayPatch.js\";\n/** @internal */\nexport const DifferTypeId = /*#__PURE__*/Symbol.for(\"effect/Differ\");\n/** @internal */\nexport const DifferProto = {\n  [DifferTypeId]: {\n    _P: identity,\n    _V: identity\n  }\n};\n/** @internal */\nexport const make = params => {\n  const differ = Object.create(DifferProto);\n  differ.empty = params.empty;\n  differ.diff = params.diff;\n  differ.combine = params.combine;\n  differ.patch = params.patch;\n  return differ;\n};\n/** @internal */\nexport const environment = () => make({\n  empty: ContextPatch.empty(),\n  combine: (first, second) => ContextPatch.combine(second)(first),\n  diff: (oldValue, newValue) => ContextPatch.diff(oldValue, newValue),\n  patch: (patch, oldValue) => ContextPatch.patch(oldValue)(patch)\n});\n/** @internal */\nexport const chunk = differ => make({\n  empty: ChunkPatch.empty(),\n  combine: (first, second) => ChunkPatch.combine(second)(first),\n  diff: (oldValue, newValue) => ChunkPatch.diff({\n    oldValue,\n    newValue,\n    differ\n  }),\n  patch: (patch, oldValue) => ChunkPatch.patch(oldValue, differ)(patch)\n});\n/** @internal */\nexport const hashMap = differ => make({\n  empty: HashMapPatch.empty(),\n  combine: (first, second) => HashMapPatch.combine(second)(first),\n  diff: (oldValue, newValue) => HashMapPatch.diff({\n    oldValue,\n    newValue,\n    differ\n  }),\n  patch: (patch, oldValue) => HashMapPatch.patch(oldValue, differ)(patch)\n});\n/** @internal */\nexport const hashSet = () => make({\n  empty: HashSetPatch.empty(),\n  combine: (first, second) => HashSetPatch.combine(second)(first),\n  diff: (oldValue, newValue) => HashSetPatch.diff(oldValue, newValue),\n  patch: (patch, oldValue) => HashSetPatch.patch(oldValue)(patch)\n});\n/** @internal */\nexport const orElseEither = /*#__PURE__*/Dual.dual(2, (self, that) => make({\n  empty: OrPatch.empty(),\n  combine: (first, second) => OrPatch.combine(first, second),\n  diff: (oldValue, newValue) => OrPatch.diff({\n    oldValue,\n    newValue,\n    left: self,\n    right: that\n  }),\n  patch: (patch, oldValue) => OrPatch.patch(patch, {\n    oldValue,\n    left: self,\n    right: that\n  })\n}));\n/** @internal */\nexport const readonlyArray = differ => make({\n  empty: ReadonlyArrayPatch.empty(),\n  combine: (first, second) => ReadonlyArrayPatch.combine(first, second),\n  diff: (oldValue, newValue) => ReadonlyArrayPatch.diff({\n    oldValue,\n    newValue,\n    differ\n  }),\n  patch: (patch, oldValue) => ReadonlyArrayPatch.patch(patch, oldValue, differ)\n});\n/** @internal */\nexport const transform = /*#__PURE__*/Dual.dual(2, (self, {\n  toNew,\n  toOld\n}) => make({\n  empty: self.empty,\n  combine: (first, second) => self.combine(first, second),\n  diff: (oldValue, newValue) => self.diff(toOld(oldValue), toOld(newValue)),\n  patch: (patch, oldValue) => toNew(self.patch(patch, toOld(oldValue)))\n}));\n/** @internal */\nexport const update = () => updateWith((_, a) => a);\n/** @internal */\nexport const updateWith = f => make({\n  empty: identity,\n  combine: (first, second) => {\n    if (first === identity) {\n      return second;\n    }\n    if (second === identity) {\n      return first;\n    }\n    return a => second(first(a));\n  },\n  diff: (oldValue, newValue) => {\n    if (Equal.equals(oldValue, newValue)) {\n      return identity;\n    }\n    return constant(newValue);\n  },\n  patch: (patch, oldValue) => f(oldValue, patch(oldValue))\n});\n/** @internal */\nexport const zip = /*#__PURE__*/Dual.dual(2, (self, that) => make({\n  empty: [self.empty, that.empty],\n  combine: (first, second) => [self.combine(first[0], second[0]), that.combine(first[1], second[1])],\n  diff: (oldValue, newValue) => [self.diff(oldValue[0], newValue[0]), that.diff(oldValue[1], newValue[1])],\n  patch: (patch, oldValue) => [self.patch(patch[0], oldValue[0]), that.patch(patch[1], oldValue[1])]\n}));\n//# sourceMappingURL=differ.js.map","import * as Chunk from \"../../Chunk.js\";\nimport * as Equal from \"../../Equal.js\";\nimport * as Dual from \"../../Function.js\";\nimport { pipe } from \"../../Function.js\";\nimport * as Data from \"../data.js\";\n/** @internal */\nexport const ChunkPatchTypeId = /*#__PURE__*/Symbol.for(\"effect/DifferChunkPatch\");\nfunction variance(a) {\n  return a;\n}\nconst PatchProto = {\n  ...Data.Structural.prototype,\n  [ChunkPatchTypeId]: {\n    _Value: variance,\n    _Patch: variance\n  }\n};\nconst EmptyProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Empty\"\n});\nconst _empty = /*#__PURE__*/Object.create(EmptyProto);\n/**\n * @internal\n */\nexport const empty = () => _empty;\nconst AndThenProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"AndThen\"\n});\nconst makeAndThen = (first, second) => {\n  const o = Object.create(AndThenProto);\n  o.first = first;\n  o.second = second;\n  return o;\n};\nconst AppendProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Append\"\n});\nconst makeAppend = values => {\n  const o = Object.create(AppendProto);\n  o.values = values;\n  return o;\n};\nconst SliceProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Slice\"\n});\nconst makeSlice = (from, until) => {\n  const o = Object.create(SliceProto);\n  o.from = from;\n  o.until = until;\n  return o;\n};\nconst UpdateProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Update\"\n});\nconst makeUpdate = (index, patch) => {\n  const o = Object.create(UpdateProto);\n  o.index = index;\n  o.patch = patch;\n  return o;\n};\n/** @internal */\nexport const diff = options => {\n  let i = 0;\n  let patch = empty();\n  while (i < options.oldValue.length && i < options.newValue.length) {\n    const oldElement = Chunk.unsafeGet(i)(options.oldValue);\n    const newElement = Chunk.unsafeGet(i)(options.newValue);\n    const valuePatch = options.differ.diff(oldElement, newElement);\n    if (!Equal.equals(valuePatch, options.differ.empty)) {\n      patch = pipe(patch, combine(makeUpdate(i, valuePatch)));\n    }\n    i = i + 1;\n  }\n  if (i < options.oldValue.length) {\n    patch = pipe(patch, combine(makeSlice(0, i)));\n  }\n  if (i < options.newValue.length) {\n    patch = pipe(patch, combine(makeAppend(Chunk.drop(i)(options.newValue))));\n  }\n  return patch;\n};\n/** @internal */\nexport const combine = /*#__PURE__*/Dual.dual(2, (self, that) => makeAndThen(self, that));\n/** @internal */\nexport const patch = /*#__PURE__*/Dual.dual(3, (self, oldValue, differ) => {\n  if (self._tag === \"Empty\") {\n    return oldValue;\n  }\n  let chunk = oldValue;\n  let patches = Chunk.of(self);\n  while (Chunk.isNonEmpty(patches)) {\n    const head = Chunk.headNonEmpty(patches);\n    const tail = Chunk.tailNonEmpty(patches);\n    switch (head._tag) {\n      case \"Empty\":\n        {\n          patches = tail;\n          break;\n        }\n      case \"AndThen\":\n        {\n          patches = Chunk.prepend(head.first)(Chunk.prepend(head.second)(tail));\n          break;\n        }\n      case \"Append\":\n        {\n          chunk = Chunk.appendAll(head.values)(chunk);\n          patches = tail;\n          break;\n        }\n      case \"Slice\":\n        {\n          const array = Chunk.toReadonlyArray(chunk);\n          chunk = Chunk.unsafeFromArray(array.slice(head.from, head.until));\n          patches = tail;\n          break;\n        }\n      case \"Update\":\n        {\n          const array = Chunk.toReadonlyArray(chunk);\n          array[head.index] = differ.patch(head.patch, array[head.index]);\n          chunk = Chunk.unsafeFromArray(array);\n          patches = tail;\n          break;\n        }\n    }\n  }\n  return chunk;\n});\n//# sourceMappingURL=chunkPatch.js.map","import * as Chunk from \"../../Chunk.js\";\nimport * as Equal from \"../../Equal.js\";\nimport * as Dual from \"../../Function.js\";\nimport { makeContext } from \"../context.js\";\nimport { Structural } from \"../data.js\";\n/** @internal */\nexport const ContextPatchTypeId = /*#__PURE__*/Symbol.for(\"effect/DifferContextPatch\");\nfunction variance(a) {\n  return a;\n}\n/** @internal */\nconst PatchProto = {\n  ...Structural.prototype,\n  [ContextPatchTypeId]: {\n    _Value: variance,\n    _Patch: variance\n  }\n};\nconst EmptyProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Empty\"\n});\nconst _empty = /*#__PURE__*/Object.create(EmptyProto);\n/**\n * @internal\n */\nexport const empty = () => _empty;\nconst AndThenProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"AndThen\"\n});\nconst makeAndThen = (first, second) => {\n  const o = Object.create(AndThenProto);\n  o.first = first;\n  o.second = second;\n  return o;\n};\nconst AddServiceProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"AddService\"\n});\nconst makeAddService = (key, service) => {\n  const o = Object.create(AddServiceProto);\n  o.key = key;\n  o.service = service;\n  return o;\n};\nconst RemoveServiceProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"RemoveService\"\n});\nconst makeRemoveService = key => {\n  const o = Object.create(RemoveServiceProto);\n  o.key = key;\n  return o;\n};\nconst UpdateServiceProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"UpdateService\"\n});\nconst makeUpdateService = (key, update) => {\n  const o = Object.create(UpdateServiceProto);\n  o.key = key;\n  o.update = update;\n  return o;\n};\n/** @internal */\nexport const diff = (oldValue, newValue) => {\n  const missingServices = new Map(oldValue.unsafeMap);\n  let patch = empty();\n  for (const [tag, newService] of newValue.unsafeMap.entries()) {\n    if (missingServices.has(tag)) {\n      const old = missingServices.get(tag);\n      missingServices.delete(tag);\n      if (!Equal.equals(old, newService)) {\n        patch = combine(makeUpdateService(tag, () => newService))(patch);\n      }\n    } else {\n      missingServices.delete(tag);\n      patch = combine(makeAddService(tag, newService))(patch);\n    }\n  }\n  for (const [tag] of missingServices.entries()) {\n    patch = combine(makeRemoveService(tag))(patch);\n  }\n  return patch;\n};\n/** @internal */\nexport const combine = /*#__PURE__*/Dual.dual(2, (self, that) => makeAndThen(self, that));\n/** @internal */\nexport const patch = /*#__PURE__*/Dual.dual(2, (self, context) => {\n  if (self._tag === \"Empty\") {\n    return context;\n  }\n  let wasServiceUpdated = false;\n  let patches = Chunk.of(self);\n  const updatedContext = new Map(context.unsafeMap);\n  while (Chunk.isNonEmpty(patches)) {\n    const head = Chunk.headNonEmpty(patches);\n    const tail = Chunk.tailNonEmpty(patches);\n    switch (head._tag) {\n      case \"Empty\":\n        {\n          patches = tail;\n          break;\n        }\n      case \"AddService\":\n        {\n          updatedContext.set(head.key, head.service);\n          patches = tail;\n          break;\n        }\n      case \"AndThen\":\n        {\n          patches = Chunk.prepend(Chunk.prepend(tail, head.second), head.first);\n          break;\n        }\n      case \"RemoveService\":\n        {\n          updatedContext.delete(head.key);\n          patches = tail;\n          break;\n        }\n      case \"UpdateService\":\n        {\n          updatedContext.set(head.key, head.update(updatedContext.get(head.key)));\n          wasServiceUpdated = true;\n          patches = tail;\n          break;\n        }\n    }\n  }\n  if (!wasServiceUpdated) {\n    return makeContext(updatedContext);\n  }\n  const map = new Map();\n  for (const [tag] of context.unsafeMap) {\n    if (updatedContext.has(tag)) {\n      map.set(tag, updatedContext.get(tag));\n      updatedContext.delete(tag);\n    }\n  }\n  for (const [tag, s] of updatedContext) {\n    map.set(tag, s);\n  }\n  return makeContext(map);\n});\n//# sourceMappingURL=contextPatch.js.map","import * as Chunk from \"../../Chunk.js\";\nimport * as Equal from \"../../Equal.js\";\nimport * as Dual from \"../../Function.js\";\nimport * as HashMap from \"../../HashMap.js\";\nimport { Structural } from \"../data.js\";\n/** @internal */\nexport const HashMapPatchTypeId = /*#__PURE__*/Symbol.for(\"effect/DifferHashMapPatch\");\nfunction variance(a) {\n  return a;\n}\n/** @internal */\nconst PatchProto = {\n  ...Structural.prototype,\n  [HashMapPatchTypeId]: {\n    _Value: variance,\n    _Key: variance,\n    _Patch: variance\n  }\n};\nconst EmptyProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Empty\"\n});\nconst _empty = /*#__PURE__*/Object.create(EmptyProto);\n/** @internal */\nexport const empty = () => _empty;\nconst AndThenProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"AndThen\"\n});\nconst makeAndThen = (first, second) => {\n  const o = Object.create(AndThenProto);\n  o.first = first;\n  o.second = second;\n  return o;\n};\nconst AddProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Add\"\n});\nconst makeAdd = (key, value) => {\n  const o = Object.create(AddProto);\n  o.key = key;\n  o.value = value;\n  return o;\n};\nconst RemoveProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Remove\"\n});\nconst makeRemove = key => {\n  const o = Object.create(RemoveProto);\n  o.key = key;\n  return o;\n};\nconst UpdateProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Update\"\n});\nconst makeUpdate = (key, patch) => {\n  const o = Object.create(UpdateProto);\n  o.key = key;\n  o.patch = patch;\n  return o;\n};\n/** @internal */\nexport const diff = options => {\n  const [removed, patch] = HashMap.reduce([options.oldValue, empty()], ([map, patch], newValue, key) => {\n    const option = HashMap.get(key)(map);\n    switch (option._tag) {\n      case \"Some\":\n        {\n          const valuePatch = options.differ.diff(option.value, newValue);\n          if (Equal.equals(valuePatch, options.differ.empty)) {\n            return [HashMap.remove(key)(map), patch];\n          }\n          return [HashMap.remove(key)(map), combine(makeUpdate(key, valuePatch))(patch)];\n        }\n      case \"None\":\n        {\n          return [map, combine(makeAdd(key, newValue))(patch)];\n        }\n    }\n  })(options.newValue);\n  return HashMap.reduce(patch, (patch, _, key) => combine(makeRemove(key))(patch))(removed);\n};\n/** @internal */\nexport const combine = /*#__PURE__*/Dual.dual(2, (self, that) => makeAndThen(self, that));\n/** @internal */\nexport const patch = /*#__PURE__*/Dual.dual(3, (self, oldValue, differ) => {\n  if (self._tag === \"Empty\") {\n    return oldValue;\n  }\n  let map = oldValue;\n  let patches = Chunk.of(self);\n  while (Chunk.isNonEmpty(patches)) {\n    const head = Chunk.headNonEmpty(patches);\n    const tail = Chunk.tailNonEmpty(patches);\n    switch (head._tag) {\n      case \"Empty\":\n        {\n          patches = tail;\n          break;\n        }\n      case \"AndThen\":\n        {\n          patches = Chunk.prepend(head.first)(Chunk.prepend(head.second)(tail));\n          break;\n        }\n      case \"Add\":\n        {\n          map = HashMap.set(head.key, head.value)(map);\n          patches = tail;\n          break;\n        }\n      case \"Remove\":\n        {\n          map = HashMap.remove(head.key)(map);\n          patches = tail;\n          break;\n        }\n      case \"Update\":\n        {\n          const option = HashMap.get(head.key)(map);\n          if (option._tag === \"Some\") {\n            map = HashMap.set(head.key, differ.patch(head.patch, option.value))(map);\n          }\n          patches = tail;\n          break;\n        }\n    }\n  }\n  return map;\n});\n//# sourceMappingURL=hashMapPatch.js.map","import * as Chunk from \"../../Chunk.js\";\nimport * as Dual from \"../../Function.js\";\nimport * as HashSet from \"../../HashSet.js\";\nimport { Structural } from \"../data.js\";\n/** @internal */\nexport const HashSetPatchTypeId = /*#__PURE__*/Symbol.for(\"effect/DifferHashSetPatch\");\nfunction variance(a) {\n  return a;\n}\n/** @internal */\nconst PatchProto = {\n  ...Structural.prototype,\n  [HashSetPatchTypeId]: {\n    _Value: variance,\n    _Key: variance,\n    _Patch: variance\n  }\n};\nconst EmptyProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Empty\"\n});\nconst _empty = /*#__PURE__*/Object.create(EmptyProto);\n/** @internal */\nexport const empty = () => _empty;\nconst AndThenProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"AndThen\"\n});\n/** @internal */\nexport const makeAndThen = (first, second) => {\n  const o = Object.create(AndThenProto);\n  o.first = first;\n  o.second = second;\n  return o;\n};\nconst AddProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Add\"\n});\n/** @internal */\nexport const makeAdd = value => {\n  const o = Object.create(AddProto);\n  o.value = value;\n  return o;\n};\nconst RemoveProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Remove\"\n});\n/** @internal */\nexport const makeRemove = value => {\n  const o = Object.create(RemoveProto);\n  o.value = value;\n  return o;\n};\n/** @internal */\nexport const diff = (oldValue, newValue) => {\n  const [removed, patch] = HashSet.reduce([oldValue, empty()], ([set, patch], value) => {\n    if (HashSet.has(value)(set)) {\n      return [HashSet.remove(value)(set), patch];\n    }\n    return [set, combine(makeAdd(value))(patch)];\n  })(newValue);\n  return HashSet.reduce(patch, (patch, value) => combine(makeRemove(value))(patch))(removed);\n};\n/** @internal */\nexport const combine = /*#__PURE__*/Dual.dual(2, (self, that) => makeAndThen(self, that));\n/** @internal */\nexport const patch = /*#__PURE__*/Dual.dual(2, (self, oldValue) => {\n  if (self._tag === \"Empty\") {\n    return oldValue;\n  }\n  let set = oldValue;\n  let patches = Chunk.of(self);\n  while (Chunk.isNonEmpty(patches)) {\n    const head = Chunk.headNonEmpty(patches);\n    const tail = Chunk.tailNonEmpty(patches);\n    switch (head._tag) {\n      case \"Empty\":\n        {\n          patches = tail;\n          break;\n        }\n      case \"AndThen\":\n        {\n          patches = Chunk.prepend(head.first)(Chunk.prepend(head.second)(tail));\n          break;\n        }\n      case \"Add\":\n        {\n          set = HashSet.add(head.value)(set);\n          patches = tail;\n          break;\n        }\n      case \"Remove\":\n        {\n          set = HashSet.remove(head.value)(set);\n          patches = tail;\n        }\n    }\n  }\n  return set;\n});\n//# sourceMappingURL=hashSetPatch.js.map","import * as Chunk from \"../../Chunk.js\";\nimport * as E from \"../../Either.js\";\nimport * as Equal from \"../../Equal.js\";\nimport * as Dual from \"../../Function.js\";\nimport { Structural } from \"../data.js\";\n/** @internal */\nexport const OrPatchTypeId = /*#__PURE__*/Symbol.for(\"effect/DifferOrPatch\");\nfunction variance(a) {\n  return a;\n}\n/** @internal */\nconst PatchProto = {\n  ...Structural.prototype,\n  [OrPatchTypeId]: {\n    _Value: variance,\n    _Key: variance,\n    _Patch: variance\n  }\n};\nconst EmptyProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Empty\"\n});\nconst _empty = /*#__PURE__*/Object.create(EmptyProto);\n/** @internal */\nexport const empty = () => _empty;\nconst AndThenProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"AndThen\"\n});\n/** @internal */\nexport const makeAndThen = (first, second) => {\n  const o = Object.create(AndThenProto);\n  o.first = first;\n  o.second = second;\n  return o;\n};\nconst SetLeftProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"SetLeft\"\n});\n/** @internal */\nexport const makeSetLeft = value => {\n  const o = Object.create(SetLeftProto);\n  o.value = value;\n  return o;\n};\nconst SetRightProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"SetRight\"\n});\n/** @internal */\nexport const makeSetRight = value => {\n  const o = Object.create(SetRightProto);\n  o.value = value;\n  return o;\n};\nconst UpdateLeftProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"UpdateLeft\"\n});\n/** @internal */\nexport const makeUpdateLeft = patch => {\n  const o = Object.create(UpdateLeftProto);\n  o.patch = patch;\n  return o;\n};\nconst UpdateRightProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"UpdateRight\"\n});\n/** @internal */\nexport const makeUpdateRight = patch => {\n  const o = Object.create(UpdateRightProto);\n  o.patch = patch;\n  return o;\n};\n/** @internal */\nexport const diff = options => {\n  switch (options.oldValue._tag) {\n    case \"Left\":\n      {\n        switch (options.newValue._tag) {\n          case \"Left\":\n            {\n              const valuePatch = options.left.diff(options.oldValue.left, options.newValue.left);\n              if (Equal.equals(valuePatch, options.left.empty)) {\n                return empty();\n              }\n              return makeUpdateLeft(valuePatch);\n            }\n          case \"Right\":\n            {\n              return makeSetRight(options.newValue.right);\n            }\n        }\n      }\n    case \"Right\":\n      {\n        switch (options.newValue._tag) {\n          case \"Left\":\n            {\n              return makeSetLeft(options.newValue.left);\n            }\n          case \"Right\":\n            {\n              const valuePatch = options.right.diff(options.oldValue.right, options.newValue.right);\n              if (Equal.equals(valuePatch, options.right.empty)) {\n                return empty();\n              }\n              return makeUpdateRight(valuePatch);\n            }\n        }\n      }\n  }\n};\n/** @internal */\nexport const combine = /*#__PURE__*/Dual.dual(2, (self, that) => makeAndThen(self, that));\n/** @internal */\nexport const patch = /*#__PURE__*/Dual.dual(2, (self, {\n  left,\n  oldValue,\n  right\n}) => {\n  if (self._tag === \"Empty\") {\n    return oldValue;\n  }\n  let patches = Chunk.of(self);\n  let result = oldValue;\n  while (Chunk.isNonEmpty(patches)) {\n    const head = Chunk.headNonEmpty(patches);\n    const tail = Chunk.tailNonEmpty(patches);\n    switch (head._tag) {\n      case \"Empty\":\n        {\n          patches = tail;\n          break;\n        }\n      case \"AndThen\":\n        {\n          patches = Chunk.prepend(head.first)(Chunk.prepend(head.second)(tail));\n          break;\n        }\n      case \"UpdateLeft\":\n        {\n          if (result._tag === \"Left\") {\n            result = E.left(left.patch(head.patch, result.left));\n          }\n          patches = tail;\n          break;\n        }\n      case \"UpdateRight\":\n        {\n          if (result._tag === \"Right\") {\n            result = E.right(right.patch(head.patch, result.right));\n          }\n          patches = tail;\n          break;\n        }\n      case \"SetLeft\":\n        {\n          result = E.left(head.value);\n          patches = tail;\n          break;\n        }\n      case \"SetRight\":\n        {\n          result = E.right(head.value);\n          patches = tail;\n          break;\n        }\n    }\n  }\n  return result;\n});\n//# sourceMappingURL=orPatch.js.map","import * as Arr from \"../../Array.js\";\nimport * as Equal from \"../../Equal.js\";\nimport * as Dual from \"../../Function.js\";\nimport * as Data from \"../data.js\";\n/** @internal */\nexport const ReadonlyArrayPatchTypeId = /*#__PURE__*/Symbol.for(\"effect/DifferReadonlyArrayPatch\");\nfunction variance(a) {\n  return a;\n}\nconst PatchProto = {\n  ...Data.Structural.prototype,\n  [ReadonlyArrayPatchTypeId]: {\n    _Value: variance,\n    _Patch: variance\n  }\n};\nconst EmptyProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Empty\"\n});\nconst _empty = /*#__PURE__*/Object.create(EmptyProto);\n/**\n * @internal\n */\nexport const empty = () => _empty;\nconst AndThenProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"AndThen\"\n});\nconst makeAndThen = (first, second) => {\n  const o = Object.create(AndThenProto);\n  o.first = first;\n  o.second = second;\n  return o;\n};\nconst AppendProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Append\"\n});\nconst makeAppend = values => {\n  const o = Object.create(AppendProto);\n  o.values = values;\n  return o;\n};\nconst SliceProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Slice\"\n});\nconst makeSlice = (from, until) => {\n  const o = Object.create(SliceProto);\n  o.from = from;\n  o.until = until;\n  return o;\n};\nconst UpdateProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(PatchProto), {\n  _tag: \"Update\"\n});\nconst makeUpdate = (index, patch) => {\n  const o = Object.create(UpdateProto);\n  o.index = index;\n  o.patch = patch;\n  return o;\n};\n/** @internal */\nexport const diff = options => {\n  let i = 0;\n  let patch = empty();\n  while (i < options.oldValue.length && i < options.newValue.length) {\n    const oldElement = options.oldValue[i];\n    const newElement = options.newValue[i];\n    const valuePatch = options.differ.diff(oldElement, newElement);\n    if (!Equal.equals(valuePatch, options.differ.empty)) {\n      patch = combine(patch, makeUpdate(i, valuePatch));\n    }\n    i = i + 1;\n  }\n  if (i < options.oldValue.length) {\n    patch = combine(patch, makeSlice(0, i));\n  }\n  if (i < options.newValue.length) {\n    patch = combine(patch, makeAppend(Arr.drop(i)(options.newValue)));\n  }\n  return patch;\n};\n/** @internal */\nexport const combine = /*#__PURE__*/Dual.dual(2, (self, that) => makeAndThen(self, that));\n/** @internal */\nexport const patch = /*#__PURE__*/Dual.dual(3, (self, oldValue, differ) => {\n  if (self._tag === \"Empty\") {\n    return oldValue;\n  }\n  let readonlyArray = oldValue.slice();\n  let patches = Arr.of(self);\n  while (Arr.isNonEmptyArray(patches)) {\n    const head = Arr.headNonEmpty(patches);\n    const tail = Arr.tailNonEmpty(patches);\n    switch (head._tag) {\n      case \"Empty\":\n        {\n          patches = tail;\n          break;\n        }\n      case \"AndThen\":\n        {\n          tail.unshift(head.first, head.second);\n          patches = tail;\n          break;\n        }\n      case \"Append\":\n        {\n          for (const value of head.values) {\n            readonlyArray.push(value);\n          }\n          patches = tail;\n          break;\n        }\n      case \"Slice\":\n        {\n          readonlyArray = readonlyArray.slice(head.from, head.until);\n          patches = tail;\n          break;\n        }\n      case \"Update\":\n        {\n          readonlyArray[head.index] = differ.patch(head.patch, readonlyArray[head.index]);\n          patches = tail;\n          break;\n        }\n    }\n  }\n  return readonlyArray;\n});\n//# sourceMappingURL=readonlyArrayPatch.js.map","import { dual } from \"../Function.js\";\n/** @internal */\nexport const let_ = map => dual(3, (self, name, f) => map(self, a => Object.assign({}, a, {\n  [name]: f(a)\n})));\n/** @internal */\nexport const bindTo = map => dual(2, (self, name) => map(self, a => ({\n  [name]: a\n})));\n/** @internal */\nexport const bind = (map, flatMap) => dual(3, (self, name, f) => flatMap(self, a => map(f(a), b => Object.assign({}, a, {\n  [name]: b\n}))));\n//# sourceMappingURL=doNotation.js.map","import * as Duration from \"../../Duration.js\";\nimport * as Equal from \"../../Equal.js\";\nimport * as Exit from \"../../Exit.js\";\nimport * as FiberId from \"../../FiberId.js\";\nimport { dual, pipe } from \"../../Function.js\";\nimport * as Hash from \"../../Hash.js\";\nimport * as MutableHashMap from \"../../MutableHashMap.js\";\nimport * as Option from \"../../Option.js\";\nimport { pipeArguments } from \"../../Pipeable.js\";\nimport * as Predicate from \"../../Predicate.js\";\nimport * as Readable from \"../../Readable.js\";\nimport { currentScheduler } from \"../../Scheduler.js\";\nimport * as internalCause from \"../cause.js\";\nimport * as effect from \"../core-effect.js\";\nimport * as core from \"../core.js\";\nimport * as executionStrategy from \"../executionStrategy.js\";\nimport * as internalFiber from \"../fiber.js\";\nimport * as fiberRuntime from \"../fiberRuntime.js\";\nimport { globalScope } from \"../fiberScope.js\";\nimport * as internalRef from \"../ref.js\";\nimport * as _schedule from \"../schedule.js\";\nimport * as supervisor from \"../supervisor.js\";\n/** @internal */\nclass Semaphore {\n  permits;\n  waiters = /*#__PURE__*/new Set();\n  taken = 0;\n  constructor(permits) {\n    this.permits = permits;\n  }\n  get free() {\n    return this.permits - this.taken;\n  }\n  take = n => core.async(resume => {\n    if (this.free < n) {\n      const observer = () => {\n        if (this.free < n) {\n          return;\n        }\n        this.waiters.delete(observer);\n        this.taken += n;\n        resume(core.succeed(n));\n      };\n      this.waiters.add(observer);\n      return core.sync(() => {\n        this.waiters.delete(observer);\n      });\n    }\n    this.taken += n;\n    return resume(core.succeed(n));\n  });\n  updateTaken = f => core.withFiberRuntime(fiber => {\n    this.taken = f(this.taken);\n    if (this.waiters.size > 0) {\n      fiber.getFiberRef(currentScheduler).scheduleTask(() => {\n        const iter = this.waiters.values();\n        let item = iter.next();\n        while (item.done === false && this.free > 0) {\n          item.value();\n          item = iter.next();\n        }\n      }, fiber.getFiberRef(core.currentSchedulingPriority));\n    }\n    return core.succeed(this.free);\n  });\n  release = n => this.updateTaken(taken => taken - n);\n  releaseAll = /*#__PURE__*/this.updateTaken(_ => 0);\n  withPermits = n => self => core.uninterruptibleMask(restore => core.flatMap(restore(this.take(n)), permits => fiberRuntime.ensuring(restore(self), this.release(permits))));\n}\n/** @internal */\nexport const unsafeMakeSemaphore = permits => new Semaphore(permits);\n/** @internal */\nexport const makeSemaphore = permits => core.sync(() => unsafeMakeSemaphore(permits));\n/** @internal */\nexport const awaitAllChildren = self => ensuringChildren(self, fiberRuntime.fiberAwaitAll);\n/** @internal */\nexport const cached = /*#__PURE__*/dual(2, (self, timeToLive) => core.map(cachedInvalidateWithTTL(self, timeToLive), tuple => tuple[0]));\n/** @internal */\nexport const cachedInvalidateWithTTL = /*#__PURE__*/dual(2, (self, timeToLive) => {\n  const duration = Duration.decode(timeToLive);\n  return core.flatMap(core.context(), env => core.map(makeSynchronized(Option.none()), cache => [core.provideContext(getCachedValue(self, duration, cache), env), invalidateCache(cache)]));\n});\n/** @internal */\nconst computeCachedValue = (self, timeToLive, start) => {\n  const timeToLiveMillis = Duration.toMillis(Duration.decode(timeToLive));\n  return pipe(core.deferredMake(), core.tap(deferred => core.intoDeferred(self, deferred)), core.map(deferred => Option.some([start + timeToLiveMillis, deferred])));\n};\n/** @internal */\nconst getCachedValue = (self, timeToLive, cache) => core.uninterruptibleMask(restore => pipe(effect.clockWith(clock => clock.currentTimeMillis), core.flatMap(time => updateSomeAndGetEffectSynchronized(cache, option => {\n  switch (option._tag) {\n    case \"None\":\n      {\n        return Option.some(computeCachedValue(self, timeToLive, time));\n      }\n    case \"Some\":\n      {\n        const [end] = option.value;\n        return end - time <= 0 ? Option.some(computeCachedValue(self, timeToLive, time)) : Option.none();\n      }\n  }\n})), core.flatMap(option => Option.isNone(option) ? core.dieMessage(\"BUG: Effect.cachedInvalidate - please report an issue at https://github.com/Effect-TS/effect/issues\") : restore(core.deferredAwait(option.value[1])))));\n/** @internal */\nconst invalidateCache = cache => internalRef.set(cache, Option.none());\n/** @internal */\nexport const ensuringChild = /*#__PURE__*/dual(2, (self, f) => ensuringChildren(self, children => f(fiberRuntime.fiberAll(children))));\n/** @internal */\nexport const ensuringChildren = /*#__PURE__*/dual(2, (self, children) => core.flatMap(supervisor.track, supervisor => pipe(supervised(self, supervisor), fiberRuntime.ensuring(core.flatMap(supervisor.value, children)))));\n/** @internal */\nexport const forkAll = /*#__PURE__*/dual(args => Predicate.isIterable(args[0]), (effects, options) => options?.discard ? core.forEachSequentialDiscard(effects, fiberRuntime.fork) : core.map(core.forEachSequential(effects, fiberRuntime.fork), fiberRuntime.fiberAll));\n/** @internal */\nexport const forkIn = /*#__PURE__*/dual(2, (self, scope) => core.uninterruptibleMask(restore => core.flatMap(scope.fork(executionStrategy.sequential), child => pipe(restore(self), core.onExit(exit => child.close(exit)), fiberRuntime.forkDaemon, core.tap(fiber => child.addFinalizer(() => core.fiberIdWith(fiberId => Equal.equals(fiberId, fiber.id()) ? core.void : core.asVoid(core.interruptFiber(fiber)))))))));\n/** @internal */\nexport const forkScoped = self => fiberRuntime.scopeWith(scope => forkIn(self, scope));\n/** @internal */\nexport const fromFiber = fiber => internalFiber.join(fiber);\n/** @internal */\nexport const fromFiberEffect = fiber => core.suspend(() => core.flatMap(fiber, internalFiber.join));\nconst memoKeySymbol = /*#__PURE__*/Symbol.for(\"effect/Effect/memoizeFunction.key\");\nclass Key {\n  a;\n  eq;\n  [memoKeySymbol] = memoKeySymbol;\n  constructor(a, eq) {\n    this.a = a;\n    this.eq = eq;\n  }\n  [Equal.symbol](that) {\n    if (Predicate.hasProperty(that, memoKeySymbol)) {\n      if (this.eq) {\n        return this.eq(this.a, that.a);\n      } else {\n        return Equal.equals(this.a, that.a);\n      }\n    }\n    return false;\n  }\n  [Hash.symbol]() {\n    return this.eq ? 0 : Hash.cached(this, Hash.hash(this.a));\n  }\n}\n/** @internal */\nexport const cachedFunction = (f, eq) => {\n  return pipe(core.sync(() => MutableHashMap.empty()), core.flatMap(makeSynchronized), core.map(ref => a => pipe(ref.modifyEffect(map => {\n    const result = pipe(map, MutableHashMap.get(new Key(a, eq)));\n    if (Option.isNone(result)) {\n      return pipe(core.deferredMake(), core.tap(deferred => pipe(effect.diffFiberRefs(f(a)), core.intoDeferred(deferred), fiberRuntime.fork)), core.map(deferred => [deferred, pipe(map, MutableHashMap.set(new Key(a, eq), deferred))]));\n    }\n    return core.succeed([result.value, map]);\n  }), core.flatMap(core.deferredAwait), core.flatMap(([patch, b]) => pipe(effect.patchFiberRefs(patch), core.as(b))))));\n};\n/** @internal */\nexport const raceFirst = /*#__PURE__*/dual(2, (self, that) => pipe(core.exit(self), fiberRuntime.race(core.exit(that)), effect => core.flatten(effect)));\n/** @internal */\nexport const scheduleForked = /*#__PURE__*/dual(2, (self, schedule) => pipe(self, _schedule.schedule_Effect(schedule), forkScoped));\n/** @internal */\nexport const supervised = /*#__PURE__*/dual(2, (self, supervisor) => {\n  const supervise = core.fiberRefLocallyWith(fiberRuntime.currentSupervisor, s => s.zip(supervisor));\n  return supervise(self);\n});\n/** @internal */\nexport const timeout = /*#__PURE__*/dual(2, (self, duration) => timeoutFail(self, {\n  onTimeout: () => core.timeoutExceptionFromDuration(duration),\n  duration\n}));\n/** @internal */\nexport const timeoutFail = /*#__PURE__*/dual(2, (self, {\n  duration,\n  onTimeout\n}) => core.flatten(timeoutTo(self, {\n  onTimeout: () => core.failSync(onTimeout),\n  onSuccess: core.succeed,\n  duration\n})));\n/** @internal */\nexport const timeoutFailCause = /*#__PURE__*/dual(2, (self, {\n  duration,\n  onTimeout\n}) => core.flatten(timeoutTo(self, {\n  onTimeout: () => core.failCauseSync(onTimeout),\n  onSuccess: core.succeed,\n  duration\n})));\n/** @internal */\nexport const timeoutOption = /*#__PURE__*/dual(2, (self, duration) => timeoutTo(self, {\n  duration,\n  onSuccess: Option.some,\n  onTimeout: Option.none\n}));\n/** @internal */\nexport const timeoutTo = /*#__PURE__*/dual(2, (self, {\n  duration,\n  onSuccess,\n  onTimeout\n}) => core.fiberIdWith(parentFiberId => fiberRuntime.raceFibersWith(self, core.interruptible(effect.sleep(duration)), {\n  onSelfWin: (winner, loser) => core.flatMap(winner.await, exit => {\n    if (exit._tag === \"Success\") {\n      return core.flatMap(winner.inheritAll, () => core.as(core.interruptAsFiber(loser, parentFiberId), onSuccess(exit.value)));\n    } else {\n      return core.flatMap(core.interruptAsFiber(loser, parentFiberId), () => core.exitFailCause(exit.cause));\n    }\n  }),\n  onOtherWin: (winner, loser) => core.flatMap(winner.await, exit => {\n    if (exit._tag === \"Success\") {\n      return core.flatMap(winner.inheritAll, () => core.as(core.interruptAsFiber(loser, parentFiberId), onTimeout()));\n    } else {\n      return core.flatMap(core.interruptAsFiber(loser, parentFiberId), () => core.exitFailCause(exit.cause));\n    }\n  }),\n  otherScope: globalScope\n})));\n// circular with Synchronized\n/** @internal */\nconst SynchronizedSymbolKey = \"effect/Ref/SynchronizedRef\";\n/** @internal */\nexport const SynchronizedTypeId = /*#__PURE__*/Symbol.for(SynchronizedSymbolKey);\n/** @internal */\nexport const synchronizedVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\n/** @internal */\nclass SynchronizedImpl {\n  ref;\n  withLock;\n  [SynchronizedTypeId] = synchronizedVariance;\n  [internalRef.RefTypeId] = internalRef.refVariance;\n  [Readable.TypeId];\n  constructor(ref, withLock) {\n    this.ref = ref;\n    this.withLock = withLock;\n    this[Readable.TypeId] = Readable.TypeId;\n    this.get = internalRef.get(this.ref);\n  }\n  get;\n  modify(f) {\n    return this.modifyEffect(a => core.succeed(f(a)));\n  }\n  modifyEffect(f) {\n    return this.withLock(pipe(core.flatMap(internalRef.get(this.ref), f), core.flatMap(([b, a]) => core.as(internalRef.set(this.ref, a), b))));\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const makeSynchronized = value => core.sync(() => unsafeMakeSynchronized(value));\n/** @internal */\nexport const unsafeMakeSynchronized = value => {\n  const ref = internalRef.unsafeMake(value);\n  const sem = unsafeMakeSemaphore(1);\n  return new SynchronizedImpl(ref, sem.withPermits(1));\n};\n/** @internal */\nexport const updateSomeAndGetEffectSynchronized = /*#__PURE__*/dual(2, (self, pf) => self.modifyEffect(value => {\n  const result = pf(value);\n  switch (result._tag) {\n    case \"None\":\n      {\n        return core.succeed([value, value]);\n      }\n    case \"Some\":\n      {\n        return core.map(result.value, a => [a, a]);\n      }\n  }\n}));\n// circular with Fiber\n/** @internal */\nexport const zipFiber = /*#__PURE__*/dual(2, (self, that) => zipWithFiber(self, that, (a, b) => [a, b]));\n/** @internal */\nexport const zipLeftFiber = /*#__PURE__*/dual(2, (self, that) => zipWithFiber(self, that, (a, _) => a));\n/** @internal */\nexport const zipRightFiber = /*#__PURE__*/dual(2, (self, that) => zipWithFiber(self, that, (_, b) => b));\n/** @internal */\nexport const zipWithFiber = /*#__PURE__*/dual(3, (self, that, f) => ({\n  [internalFiber.FiberTypeId]: internalFiber.fiberVariance,\n  id: () => pipe(self.id(), FiberId.getOrElse(that.id())),\n  await: pipe(self.await, core.flatten, fiberRuntime.zipWithOptions(core.flatten(that.await), f, {\n    concurrent: true\n  }), core.exit),\n  children: self.children,\n  inheritAll: core.zipRight(that.inheritAll, self.inheritAll),\n  poll: core.zipWith(self.poll, that.poll, (optionA, optionB) => pipe(optionA, Option.flatMap(exitA => pipe(optionB, Option.map(exitB => Exit.zipWith(exitA, exitB, {\n    onSuccess: f,\n    onFailure: internalCause.parallel\n  })))))),\n  interruptAsFork: id => core.zipRight(self.interruptAsFork(id), that.interruptAsFork(id)),\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}));\n//# sourceMappingURL=circular.js.map","import * as Equal from \"../Equal.js\";\nimport * as Hash from \"../Hash.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { SingleShotGen, YieldWrap } from \"../Utils.js\";\nimport * as OpCodes from \"./opCodes/effect.js\";\nimport * as version from \"./version.js\";\n/** @internal */\nexport const EffectTypeId = /*#__PURE__*/Symbol.for(\"effect/Effect\");\n/** @internal */\nexport const StreamTypeId = /*#__PURE__*/Symbol.for(\"effect/Stream\");\n/** @internal */\nexport const SinkTypeId = /*#__PURE__*/Symbol.for(\"effect/Sink\");\n/** @internal */\nexport const ChannelTypeId = /*#__PURE__*/Symbol.for(\"effect/Channel\");\n/** @internal */\nexport const effectVariance = {\n  /* c8 ignore next */\n  _R: _ => _,\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _A: _ => _,\n  _V: /*#__PURE__*/version.getCurrentVersion()\n};\nconst sinkVariance = {\n  /* c8 ignore next */\n  _A: _ => _,\n  /* c8 ignore next */\n  _In: _ => _,\n  /* c8 ignore next */\n  _L: _ => _,\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _R: _ => _\n};\nconst channelVariance = {\n  /* c8 ignore next */\n  _Env: _ => _,\n  /* c8 ignore next */\n  _InErr: _ => _,\n  /* c8 ignore next */\n  _InElem: _ => _,\n  /* c8 ignore next */\n  _InDone: _ => _,\n  /* c8 ignore next */\n  _OutErr: _ => _,\n  /* c8 ignore next */\n  _OutElem: _ => _,\n  /* c8 ignore next */\n  _OutDone: _ => _\n};\n/** @internal */\nexport const EffectPrototype = {\n  [EffectTypeId]: effectVariance,\n  [StreamTypeId]: effectVariance,\n  [SinkTypeId]: sinkVariance,\n  [ChannelTypeId]: channelVariance,\n  [Equal.symbol](that) {\n    return this === that;\n  },\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.random(this));\n  },\n  [Symbol.iterator]() {\n    return new SingleShotGen(new YieldWrap(this));\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const StructuralPrototype = {\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.structure(this));\n  },\n  [Equal.symbol](that) {\n    const selfKeys = Object.keys(this);\n    const thatKeys = Object.keys(that);\n    if (selfKeys.length !== thatKeys.length) {\n      return false;\n    }\n    for (const key of selfKeys) {\n      if (!(key in that && Equal.equals(this[key], that[key]))) {\n        return false;\n      }\n    }\n    return true;\n  }\n};\n/** @internal */\nexport const CommitPrototype = {\n  ...EffectPrototype,\n  _op: OpCodes.OP_COMMIT\n};\n/** @internal */\nexport const StructuralCommitPrototype = {\n  ...CommitPrototype,\n  ...StructuralPrototype\n};\n/** @internal */\nexport const Base = /*#__PURE__*/function () {\n  function Base() {}\n  Base.prototype = CommitPrototype;\n  return Base;\n}();\n/** @internal */\nexport const StructuralBase = /*#__PURE__*/function () {\n  function Base() {}\n  Base.prototype = StructuralCommitPrototype;\n  return Base;\n}();\n//# sourceMappingURL=effectable.js.map","/**\n * @since 2.0.0\n */\nimport * as Equal from \"../Equal.js\";\nimport { dual } from \"../Function.js\";\nimport * as Hash from \"../Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport { EffectPrototype } from \"./effectable.js\";\nimport * as option from \"./option.js\";\n/**\n * @internal\n */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"effect/Either\");\nconst CommonProto = {\n  ...EffectPrototype,\n  [TypeId]: {\n    _R: _ => _\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  toString() {\n    return format(this.toJSON());\n  }\n};\nconst RightProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(CommonProto), {\n  _tag: \"Right\",\n  _op: \"Right\",\n  [Equal.symbol](that) {\n    return isEither(that) && isRight(that) && Equal.equals(this.right, that.right);\n  },\n  [Hash.symbol]() {\n    return Hash.combine(Hash.hash(this._tag))(Hash.hash(this.right));\n  },\n  toJSON() {\n    return {\n      _id: \"Either\",\n      _tag: this._tag,\n      right: toJSON(this.right)\n    };\n  }\n});\nconst LeftProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(CommonProto), {\n  _tag: \"Left\",\n  _op: \"Left\",\n  [Equal.symbol](that) {\n    return isEither(that) && isLeft(that) && Equal.equals(this.left, that.left);\n  },\n  [Hash.symbol]() {\n    return Hash.combine(Hash.hash(this._tag))(Hash.hash(this.left));\n  },\n  toJSON() {\n    return {\n      _id: \"Either\",\n      _tag: this._tag,\n      left: toJSON(this.left)\n    };\n  }\n});\n/** @internal */\nexport const isEither = input => hasProperty(input, TypeId);\n/** @internal */\nexport const isLeft = ma => ma._tag === \"Left\";\n/** @internal */\nexport const isRight = ma => ma._tag === \"Right\";\n/** @internal */\nexport const left = left => {\n  const a = Object.create(LeftProto);\n  a.left = left;\n  return a;\n};\n/** @internal */\nexport const right = right => {\n  const a = Object.create(RightProto);\n  a.right = right;\n  return a;\n};\n/** @internal */\nexport const getLeft = self => isRight(self) ? option.none : option.some(self.left);\n/** @internal */\nexport const getRight = self => isLeft(self) ? option.none : option.some(self.right);\n/** @internal */\nexport const fromOption = /*#__PURE__*/dual(2, (self, onNone) => option.isNone(self) ? left(onNone()) : right(self.value));\n//# sourceMappingURL=either.js.map","import * as Either from \"../../Either.js\";\nimport { DecodeException } from \"./common.js\";\n/** @internal */\nexport const encode = bytes => {\n  const length = bytes.length;\n  let result = \"\";\n  let i;\n  for (i = 2; i < length; i += 3) {\n    result += base64abc[bytes[i - 2] >> 2];\n    result += base64abc[(bytes[i - 2] & 0x03) << 4 | bytes[i - 1] >> 4];\n    result += base64abc[(bytes[i - 1] & 0x0f) << 2 | bytes[i] >> 6];\n    result += base64abc[bytes[i] & 0x3f];\n  }\n  if (i === length + 1) {\n    // 1 octet yet to write\n    result += base64abc[bytes[i - 2] >> 2];\n    result += base64abc[(bytes[i - 2] & 0x03) << 4];\n    result += \"==\";\n  }\n  if (i === length) {\n    // 2 octets yet to write\n    result += base64abc[bytes[i - 2] >> 2];\n    result += base64abc[(bytes[i - 2] & 0x03) << 4 | bytes[i - 1] >> 4];\n    result += base64abc[(bytes[i - 1] & 0x0f) << 2];\n    result += \"=\";\n  }\n  return result;\n};\n/** @internal */\nexport const decode = str => {\n  const length = str.length;\n  if (length % 4 !== 0) {\n    return Either.left(DecodeException(str, `Length must be a multiple of 4, but is ${length}`));\n  }\n  const index = str.indexOf(\"=\");\n  if (index !== -1 && (index < length - 2 || index === length - 2 && str[length - 1] !== \"=\")) {\n    return Either.left(DecodeException(str, \"Found a '=' character, but it is not at the end\"));\n  }\n  try {\n    const missingOctets = str.endsWith(\"==\") ? 2 : str.endsWith(\"=\") ? 1 : 0;\n    const result = new Uint8Array(3 * (length / 4));\n    for (let i = 0, j = 0; i < length; i += 4, j += 3) {\n      const buffer = getBase64Code(str.charCodeAt(i)) << 18 | getBase64Code(str.charCodeAt(i + 1)) << 12 | getBase64Code(str.charCodeAt(i + 2)) << 6 | getBase64Code(str.charCodeAt(i + 3));\n      result[j] = buffer >> 16;\n      result[j + 1] = buffer >> 8 & 0xff;\n      result[j + 2] = buffer & 0xff;\n    }\n    return Either.right(result.subarray(0, result.length - missingOctets));\n  } catch (e) {\n    return Either.left(DecodeException(str, e instanceof Error ? e.message : \"Invalid input\"));\n  }\n};\n/** @internal */\nfunction getBase64Code(charCode) {\n  if (charCode >= base64codes.length) {\n    throw new TypeError(`Invalid character ${String.fromCharCode(charCode)}`);\n  }\n  const code = base64codes[charCode];\n  if (code === 255) {\n    throw new TypeError(`Invalid character ${String.fromCharCode(charCode)}`);\n  }\n  return code;\n}\n/** @internal */\nconst base64abc = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"+\", \"/\"];\n/** @internal */\nconst base64codes = [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 62, 255, 255, 255, 63, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 255, 255, 255, 0, 255, 255, 255, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 255, 255, 255, 255, 255, 255, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51];\n//# sourceMappingURL=base64.js.map","import * as Either from \"../../Either.js\";\nimport * as Base64 from \"./base64.js\";\nimport { DecodeException } from \"./common.js\";\n/** @internal */\nexport const encode = data => Base64.encode(data).replace(/=/g, \"\").replace(/\\+/g, \"-\").replace(/\\//g, \"_\");\n/** @internal */\nexport const decode = str => {\n  const length = str.length;\n  if (length % 4 === 1) {\n    return Either.left(DecodeException(str, `Length should be a multiple of 4, but is ${length}`));\n  }\n  if (!/^[-_A-Z0-9]*?={0,2}$/i.test(str)) {\n    return Either.left(DecodeException(str, \"Invalid input\"));\n  }\n  // Some variants allow or require omitting the padding '=' signs\n  let sanitized = length % 4 === 2 ? `${str}==` : length % 4 === 3 ? `${str}=` : str;\n  sanitized = sanitized.replace(/-/g, \"+\").replace(/_/g, \"/\");\n  return Base64.decode(sanitized);\n};\n//# sourceMappingURL=base64Url.js.map","import { hasProperty, isString } from \"../../Predicate.js\";\n/** @internal */\nexport const DecodeExceptionTypeId = /*#__PURE__*/Symbol.for(\"effect/Encoding/errors/Decode\");\n/** @internal */\nexport const DecodeException = (input, message) => {\n  const out = {\n    _tag: \"DecodeException\",\n    [DecodeExceptionTypeId]: DecodeExceptionTypeId,\n    input\n  };\n  if (isString(message)) {\n    out.message = message;\n  }\n  return out;\n};\n/** @internal */\nexport const isDecodeException = u => hasProperty(u, DecodeExceptionTypeId);\n/** @interal */\nexport const encoder = /*#__PURE__*/new TextEncoder();\n/** @interal */\nexport const decoder = /*#__PURE__*/new TextDecoder();\n//# sourceMappingURL=common.js.map","import * as Either from \"../../Either.js\";\nimport { DecodeException } from \"./common.js\";\n/** @internal */\nexport const encode = bytes => {\n  let result = \"\";\n  for (let i = 0; i < bytes.length; ++i) {\n    result += bytesToHex[bytes[i]];\n  }\n  return result;\n};\n/** @internal */\nexport const decode = str => {\n  const bytes = new TextEncoder().encode(str);\n  if (bytes.length % 2 !== 0) {\n    return Either.left(DecodeException(str, `Length must be a multiple of 2, but is ${bytes.length}`));\n  }\n  try {\n    const length = bytes.length / 2;\n    const result = new Uint8Array(length);\n    for (let i = 0; i < length; i++) {\n      const a = fromHexChar(bytes[i * 2]);\n      const b = fromHexChar(bytes[i * 2 + 1]);\n      result[i] = a << 4 | b;\n    }\n    return Either.right(result);\n  } catch (e) {\n    return Either.left(DecodeException(str, e instanceof Error ? e.message : \"Invalid input\"));\n  }\n};\n/** @internal */\nconst bytesToHex = [\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"0a\", \"0b\", \"0c\", \"0d\", \"0e\", \"0f\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"1a\", \"1b\", \"1c\", \"1d\", \"1e\", \"1f\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"2a\", \"2b\", \"2c\", \"2d\", \"2e\", \"2f\", \"30\", \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"3a\", \"3b\", \"3c\", \"3d\", \"3e\", \"3f\", \"40\", \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"4a\", \"4b\", \"4c\", \"4d\", \"4e\", \"4f\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"5a\", \"5b\", \"5c\", \"5d\", \"5e\", \"5f\", \"60\", \"61\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"68\", \"69\", \"6a\", \"6b\", \"6c\", \"6d\", \"6e\", \"6f\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"7a\", \"7b\", \"7c\", \"7d\", \"7e\", \"7f\", \"80\", \"81\", \"82\", \"83\", \"84\", \"85\", \"86\", \"87\", \"88\", \"89\", \"8a\", \"8b\", \"8c\", \"8d\", \"8e\", \"8f\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"9a\", \"9b\", \"9c\", \"9d\", \"9e\", \"9f\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\", \"a7\", \"a8\", \"a9\", \"aa\", \"ab\", \"ac\", \"ad\", \"ae\", \"af\", \"b0\", \"b1\", \"b2\", \"b3\", \"b4\", \"b5\", \"b6\", \"b7\", \"b8\", \"b9\", \"ba\", \"bb\", \"bc\", \"bd\", \"be\", \"bf\", \"c0\", \"c1\", \"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c7\", \"c8\", \"c9\", \"ca\", \"cb\", \"cc\", \"cd\", \"ce\", \"cf\", \"d0\", \"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\", \"d8\", \"d9\", \"da\", \"db\", \"dc\", \"dd\", \"de\", \"df\", \"e0\", \"e1\", \"e2\", \"e3\", \"e4\", \"e5\", \"e6\", \"e7\", \"e8\", \"e9\", \"ea\", \"eb\", \"ec\", \"ed\", \"ee\", \"ef\", \"f0\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\", \"f9\", \"fa\", \"fb\", \"fc\", \"fd\", \"fe\", \"ff\"];\n/** @internal */\nconst fromHexChar = byte => {\n  // '0' <= byte && byte <= '9'\n  if (48 <= byte && byte <= 57) {\n    return byte - 48;\n  }\n  // 'a' <= byte && byte <= 'f'\n  if (97 <= byte && byte <= 102) {\n    return byte - 97 + 10;\n  }\n  // 'A' <= byte && byte <= 'F'\n  if (65 <= byte && byte <= 70) {\n    return byte - 65 + 10;\n  }\n  throw new TypeError(\"Invalid input\");\n};\n//# sourceMappingURL=hex.js.map","/**\n * @since 2.0.0\n */\n/** @internal */\nexport const getBugErrorMessage = message => `BUG: ${message} - please report an issue at https://github.com/Effect-TS/effect/issues`;\n//# sourceMappingURL=errors.js.map","import { dual } from \"../Function.js\";\n/** @internal */\nexport const OP_SEQUENTIAL = \"Sequential\";\n/** @internal */\nexport const OP_PARALLEL = \"Parallel\";\n/** @internal */\nexport const OP_PARALLEL_N = \"ParallelN\";\n/** @internal */\nexport const sequential = {\n  _tag: OP_SEQUENTIAL\n};\n/** @internal */\nexport const parallel = {\n  _tag: OP_PARALLEL\n};\n/** @internal */\nexport const parallelN = parallelism => ({\n  _tag: OP_PARALLEL_N,\n  parallelism\n});\n/** @internal */\nexport const isSequential = self => self._tag === OP_SEQUENTIAL;\n/** @internal */\nexport const isParallel = self => self._tag === OP_PARALLEL;\n/** @internal */\nexport const isParallelN = self => self._tag === OP_PARALLEL_N;\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, options) => {\n  switch (self._tag) {\n    case OP_SEQUENTIAL:\n      {\n        return options.onSequential();\n      }\n    case OP_PARALLEL:\n      {\n        return options.onParallel();\n      }\n    case OP_PARALLEL_N:\n      {\n        return options.onParallelN(self.parallelism);\n      }\n  }\n});\n//# sourceMappingURL=executionStrategy.js.map","import * as Clock from \"../Clock.js\";\nimport * as Either from \"../Either.js\";\nimport * as Exit from \"../Exit.js\";\nimport * as FiberId from \"../FiberId.js\";\nimport * as FiberStatus from \"../FiberStatus.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport * as number from \"../Number.js\";\nimport * as Option from \"../Option.js\";\nimport * as order from \"../Order.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as core from \"./core.js\";\nimport * as fiberScope from \"./fiberScope.js\";\nimport * as runtimeFlags from \"./runtimeFlags.js\";\n/** @internal */\nconst FiberSymbolKey = \"effect/Fiber\";\n/** @internal */\nexport const FiberTypeId = /*#__PURE__*/Symbol.for(FiberSymbolKey);\n/** @internal */\nexport const fiberVariance = {\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _A: _ => _\n};\n/** @internal */\nconst fiberProto = {\n  [FiberTypeId]: fiberVariance,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nconst RuntimeFiberSymbolKey = \"effect/Fiber\";\n/** @internal */\nexport const RuntimeFiberTypeId = /*#__PURE__*/Symbol.for(RuntimeFiberSymbolKey);\n/** @internal */\nexport const Order = /*#__PURE__*/pipe( /*#__PURE__*/order.tuple(number.Order, number.Order), /*#__PURE__*/order.mapInput(fiber => [fiber.id().startTimeMillis, fiber.id().id]));\n/** @internal */\nexport const isFiber = u => hasProperty(u, FiberTypeId);\n/** @internal */\nexport const isRuntimeFiber = self => RuntimeFiberTypeId in self;\n/** @internal */\nexport const _await = self => self.await;\n/** @internal */\nexport const children = self => self.children;\n/** @internal */\nexport const done = exit => ({\n  ...fiberProto,\n  id: () => FiberId.none,\n  await: core.succeed(exit),\n  children: core.succeed([]),\n  inheritAll: core.void,\n  poll: core.succeed(Option.some(exit)),\n  interruptAsFork: () => core.void\n});\n/** @internal */\nexport const dump = self => core.map(self.status, status => ({\n  id: self.id(),\n  status\n}));\n/** @internal */\nexport const dumpAll = fibers => core.forEachSequential(fibers, dump);\n/** @internal */\nexport const fail = error => done(Exit.fail(error));\n/** @internal */\nexport const failCause = cause => done(Exit.failCause(cause));\n/** @internal */\nexport const fromEffect = effect => core.map(core.exit(effect), done);\n/** @internal */\nexport const id = self => self.id();\n/** @internal */\nexport const inheritAll = self => self.inheritAll;\n/** @internal */\nexport const interrupted = fiberId => done(Exit.interrupt(fiberId));\n/** @internal */\nexport const interruptAll = fibers => core.flatMap(core.fiberId, fiberId => pipe(fibers, interruptAllAs(fiberId)));\n/** @internal */\nexport const interruptAllAs = /*#__PURE__*/dual(2, (fibers, fiberId) => pipe(core.forEachSequentialDiscard(fibers, interruptAsFork(fiberId)), core.zipRight(pipe(fibers, core.forEachSequentialDiscard(_await)))));\n/** @internal */\nexport const interruptAsFork = /*#__PURE__*/dual(2, (self, fiberId) => self.interruptAsFork(fiberId));\n/** @internal */\nexport const join = self => core.zipLeft(core.flatten(self.await), self.inheritAll);\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => mapEffect(self, a => core.sync(() => f(a))));\n/** @internal */\nexport const mapEffect = /*#__PURE__*/dual(2, (self, f) => ({\n  ...fiberProto,\n  id: () => self.id(),\n  await: core.flatMap(self.await, Exit.forEachEffect(f)),\n  children: self.children,\n  inheritAll: self.inheritAll,\n  poll: core.flatMap(self.poll, result => {\n    switch (result._tag) {\n      case \"None\":\n        return core.succeed(Option.none());\n      case \"Some\":\n        return pipe(Exit.forEachEffect(result.value, f), core.map(Option.some));\n    }\n  }),\n  interruptAsFork: id => self.interruptAsFork(id)\n}));\n/** @internal */\nexport const mapFiber = /*#__PURE__*/dual(2, (self, f) => core.map(self.await, Exit.match({\n  onFailure: cause => failCause(cause),\n  onSuccess: a => f(a)\n})));\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onFiber,\n  onRuntimeFiber\n}) => {\n  if (isRuntimeFiber(self)) {\n    return onRuntimeFiber(self);\n  }\n  return onFiber(self);\n});\n/** @internal */\nexport const never = {\n  ...fiberProto,\n  id: () => FiberId.none,\n  await: core.never,\n  children: /*#__PURE__*/core.succeed([]),\n  inheritAll: core.never,\n  poll: /*#__PURE__*/core.succeed( /*#__PURE__*/Option.none()),\n  interruptAsFork: () => core.never\n};\n/** @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => ({\n  ...fiberProto,\n  id: () => FiberId.getOrElse(self.id(), that.id()),\n  await: core.zipWith(self.await, that.await, (exit1, exit2) => Exit.isSuccess(exit1) ? exit1 : exit2),\n  children: self.children,\n  inheritAll: core.zipRight(that.inheritAll, self.inheritAll),\n  poll: core.zipWith(self.poll, that.poll, (option1, option2) => {\n    switch (option1._tag) {\n      case \"None\":\n        {\n          return Option.none();\n        }\n      case \"Some\":\n        {\n          return Exit.isSuccess(option1.value) ? option1 : option2;\n        }\n    }\n  }),\n  interruptAsFork: id => pipe(core.interruptAsFiber(self, id), core.zipRight(pipe(that, core.interruptAsFiber(id))), core.asVoid)\n}));\n/** @internal */\nexport const orElseEither = /*#__PURE__*/dual(2, (self, that) => orElse(map(self, Either.left), map(that, Either.right)));\n/** @internal */\nexport const poll = self => self.poll;\n// forked from https://github.com/sindresorhus/parse-ms/blob/4da2ffbdba02c6e288c08236695bdece0adca173/index.js\n// MIT License\n// Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)\n/** @internal */\nconst parseMs = milliseconds => {\n  const roundTowardsZero = milliseconds > 0 ? Math.floor : Math.ceil;\n  return {\n    days: roundTowardsZero(milliseconds / 86400000),\n    hours: roundTowardsZero(milliseconds / 3600000) % 24,\n    minutes: roundTowardsZero(milliseconds / 60000) % 60,\n    seconds: roundTowardsZero(milliseconds / 1000) % 60,\n    milliseconds: roundTowardsZero(milliseconds) % 1000,\n    microseconds: roundTowardsZero(milliseconds * 1000) % 1000,\n    nanoseconds: roundTowardsZero(milliseconds * 1e6) % 1000\n  };\n};\n/** @internal */\nconst renderStatus = status => {\n  if (FiberStatus.isDone(status)) {\n    return \"Done\";\n  }\n  if (FiberStatus.isRunning(status)) {\n    return \"Running\";\n  }\n  const isInterruptible = runtimeFlags.interruptible(status.runtimeFlags) ? \"interruptible\" : \"uninterruptible\";\n  return `Suspended(${isInterruptible})`;\n};\n/** @internal */\nexport const pretty = self => core.flatMap(Clock.currentTimeMillis, now => core.map(dump(self), dump => {\n  const time = now - dump.id.startTimeMillis;\n  const {\n    days,\n    hours,\n    milliseconds,\n    minutes,\n    seconds\n  } = parseMs(time);\n  const lifeMsg = (days === 0 ? \"\" : `${days}d`) + (days === 0 && hours === 0 ? \"\" : `${hours}h`) + (days === 0 && hours === 0 && minutes === 0 ? \"\" : `${minutes}m`) + (days === 0 && hours === 0 && minutes === 0 && seconds === 0 ? \"\" : `${seconds}s`) + `${milliseconds}ms`;\n  const waitMsg = FiberStatus.isSuspended(dump.status) ? (() => {\n    const ids = FiberId.ids(dump.status.blockingOn);\n    return HashSet.size(ids) > 0 ? `waiting on ` + Array.from(ids).map(id => `${id}`).join(\", \") : \"\";\n  })() : \"\";\n  const statusMsg = renderStatus(dump.status);\n  return `[Fiber](#${dump.id.id}) (${lifeMsg}) ${waitMsg}\\n   Status: ${statusMsg}`;\n}));\n/** @internal */\nexport const unsafeRoots = () => Array.from(fiberScope.globalScope.roots);\n/** @internal */\nexport const roots = /*#__PURE__*/core.sync(unsafeRoots);\n/** @internal */\nexport const status = self => self.status;\n/** @internal */\nexport const succeed = value => done(Exit.succeed(value));\nconst void_ = /*#__PURE__*/succeed(void 0);\nexport { /** @internal */\nvoid_ as void };\n/** @internal */\nexport const currentFiberURI = \"effect/FiberCurrent\";\n/** @internal */\nexport const getCurrentFiber = () => Option.fromNullable(globalThis[currentFiberURI]);\n//# sourceMappingURL=fiber.js.map","import * as Equal from \"../Equal.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as Hash from \"../Hash.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport * as MutableRef from \"../MutableRef.js\";\nimport * as Option from \"../Option.js\";\nimport { hasProperty } from \"../Predicate.js\";\n/** @internal */\nconst FiberIdSymbolKey = \"effect/FiberId\";\n/** @internal */\nexport const FiberIdTypeId = /*#__PURE__*/Symbol.for(FiberIdSymbolKey);\n/** @internal */\nconst OP_NONE = \"None\";\n/** @internal */\nconst OP_RUNTIME = \"Runtime\";\n/** @internal */\nconst OP_COMPOSITE = \"Composite\";\nconst emptyHash = /*#__PURE__*/Hash.string(`${FiberIdSymbolKey}-${OP_NONE}`);\n/** @internal */\nclass None {\n  [FiberIdTypeId] = FiberIdTypeId;\n  _tag = OP_NONE;\n  id = -1;\n  startTimeMillis = -1;\n  [Hash.symbol]() {\n    return emptyHash;\n  }\n  [Equal.symbol](that) {\n    return isFiberId(that) && that._tag === OP_NONE;\n  }\n  toString() {\n    return format(this.toJSON());\n  }\n  toJSON() {\n    return {\n      _id: \"FiberId\",\n      _tag: this._tag\n    };\n  }\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n}\n/** @internal */\nclass Runtime {\n  id;\n  startTimeMillis;\n  [FiberIdTypeId] = FiberIdTypeId;\n  _tag = OP_RUNTIME;\n  constructor(id, startTimeMillis) {\n    this.id = id;\n    this.startTimeMillis = startTimeMillis;\n  }\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.string(`${FiberIdSymbolKey}-${this._tag}-${this.id}-${this.startTimeMillis}`));\n  }\n  [Equal.symbol](that) {\n    return isFiberId(that) && that._tag === OP_RUNTIME && this.id === that.id && this.startTimeMillis === that.startTimeMillis;\n  }\n  toString() {\n    return format(this.toJSON());\n  }\n  toJSON() {\n    return {\n      _id: \"FiberId\",\n      _tag: this._tag,\n      id: this.id,\n      startTimeMillis: this.startTimeMillis\n    };\n  }\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n}\n/** @internal */\nclass Composite {\n  left;\n  right;\n  [FiberIdTypeId] = FiberIdTypeId;\n  _tag = OP_COMPOSITE;\n  constructor(left, right) {\n    this.left = left;\n    this.right = right;\n  }\n  _hash;\n  [Hash.symbol]() {\n    return pipe(Hash.string(`${FiberIdSymbolKey}-${this._tag}`), Hash.combine(Hash.hash(this.left)), Hash.combine(Hash.hash(this.right)), Hash.cached(this));\n  }\n  [Equal.symbol](that) {\n    return isFiberId(that) && that._tag === OP_COMPOSITE && Equal.equals(this.left, that.left) && Equal.equals(this.right, that.right);\n  }\n  toString() {\n    return format(this.toJSON());\n  }\n  toJSON() {\n    return {\n      _id: \"FiberId\",\n      _tag: this._tag,\n      left: toJSON(this.left),\n      right: toJSON(this.right)\n    };\n  }\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  }\n}\n/** @internal */\nexport const none = /*#__PURE__*/new None();\n/** @internal */\nexport const runtime = (id, startTimeMillis) => {\n  return new Runtime(id, startTimeMillis);\n};\n/** @internal */\nexport const composite = (left, right) => {\n  return new Composite(left, right);\n};\n/** @internal */\nexport const isFiberId = self => hasProperty(self, FiberIdTypeId);\n/** @internal */\nexport const isNone = self => {\n  return self._tag === OP_NONE || pipe(toSet(self), HashSet.every(id => isNone(id)));\n};\n/** @internal */\nexport const isRuntime = self => {\n  return self._tag === OP_RUNTIME;\n};\n/** @internal */\nexport const isComposite = self => {\n  return self._tag === OP_COMPOSITE;\n};\n/** @internal */\nexport const combine = /*#__PURE__*/dual(2, (self, that) => {\n  if (self._tag === OP_NONE) {\n    return that;\n  }\n  if (that._tag === OP_NONE) {\n    return self;\n  }\n  return new Composite(self, that);\n});\n/** @internal */\nexport const combineAll = fiberIds => {\n  return pipe(fiberIds, HashSet.reduce(none, (a, b) => combine(b)(a)));\n};\n/** @internal */\nexport const getOrElse = /*#__PURE__*/dual(2, (self, that) => isNone(self) ? that : self);\n/** @internal */\nexport const ids = self => {\n  switch (self._tag) {\n    case OP_NONE:\n      {\n        return HashSet.empty();\n      }\n    case OP_RUNTIME:\n      {\n        return HashSet.make(self.id);\n      }\n    case OP_COMPOSITE:\n      {\n        return pipe(ids(self.left), HashSet.union(ids(self.right)));\n      }\n  }\n};\nconst _fiberCounter = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Fiber/Id/_fiberCounter\"), () => MutableRef.make(0));\n/** @internal */\nexport const make = (id, startTimeSeconds) => {\n  return new Runtime(id, startTimeSeconds);\n};\n/** @internal */\nexport const threadName = self => {\n  const identifiers = Array.from(ids(self)).map(n => `#${n}`).join(\",\");\n  return identifiers;\n};\n/** @internal */\nexport const toOption = self => {\n  const fiberIds = toSet(self);\n  if (HashSet.size(fiberIds) === 0) {\n    return Option.none();\n  }\n  let first = true;\n  let acc;\n  for (const fiberId of fiberIds) {\n    if (first) {\n      acc = fiberId;\n      first = false;\n    } else {\n      // @ts-expect-error\n      acc = pipe(acc, combine(fiberId));\n    }\n  }\n  // @ts-expect-error\n  return Option.some(acc);\n};\n/** @internal */\nexport const toSet = self => {\n  switch (self._tag) {\n    case OP_NONE:\n      {\n        return HashSet.empty();\n      }\n    case OP_RUNTIME:\n      {\n        return HashSet.make(self);\n      }\n    case OP_COMPOSITE:\n      {\n        return pipe(toSet(self.left), HashSet.union(toSet(self.right)));\n      }\n  }\n};\n/** @internal */\nexport const unsafeMake = () => {\n  const id = MutableRef.get(_fiberCounter);\n  pipe(_fiberCounter, MutableRef.set(id + 1));\n  return new Runtime(id, Date.now());\n};\n//# sourceMappingURL=fiberId.js.map","/** @internal */\nexport const OP_INTERRUPT_SIGNAL = \"InterruptSignal\";\n/** @internal */\nexport const OP_STATEFUL = \"Stateful\";\n/** @internal */\nexport const OP_RESUME = \"Resume\";\n/** @internal */\nexport const OP_YIELD_NOW = \"YieldNow\";\n/** @internal */\nexport const interruptSignal = cause => ({\n  _tag: OP_INTERRUPT_SIGNAL,\n  cause\n});\n/** @internal */\nexport const stateful = onFiber => ({\n  _tag: OP_STATEFUL,\n  onFiber\n});\n/** @internal */\nexport const resume = effect => ({\n  _tag: OP_RESUME,\n  effect\n});\n/** @internal */\nexport const yieldNow = () => ({\n  _tag: OP_YIELD_NOW\n});\n//# sourceMappingURL=fiberMessage.js.map","import * as Arr from \"../Array.js\";\nimport * as Equal from \"../Equal.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport * as core from \"./core.js\";\n/** @internal */\nexport function unsafeMake(fiberRefLocals) {\n  return new FiberRefsImpl(fiberRefLocals);\n}\n/** @internal */\nexport function empty() {\n  return unsafeMake(new Map());\n}\n/** @internal */\nexport const FiberRefsSym = /*#__PURE__*/Symbol.for(\"effect/FiberRefs\");\n/** @internal */\nexport class FiberRefsImpl {\n  locals;\n  [FiberRefsSym] = FiberRefsSym;\n  constructor(locals) {\n    this.locals = locals;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nconst findAncestor = (_ref, _parentStack, _childStack, _childModified = false) => {\n  const ref = _ref;\n  let parentStack = _parentStack;\n  let childStack = _childStack;\n  let childModified = _childModified;\n  let ret = undefined;\n  while (ret === undefined) {\n    if (Arr.isNonEmptyReadonlyArray(parentStack) && Arr.isNonEmptyReadonlyArray(childStack)) {\n      const parentFiberId = Arr.headNonEmpty(parentStack)[0];\n      const parentAncestors = Arr.tailNonEmpty(parentStack);\n      const childFiberId = Arr.headNonEmpty(childStack)[0];\n      const childRefValue = Arr.headNonEmpty(childStack)[1];\n      const childAncestors = Arr.tailNonEmpty(childStack);\n      if (parentFiberId.startTimeMillis < childFiberId.startTimeMillis) {\n        childStack = childAncestors;\n        childModified = true;\n      } else if (parentFiberId.startTimeMillis > childFiberId.startTimeMillis) {\n        parentStack = parentAncestors;\n      } else {\n        if (parentFiberId.id < childFiberId.id) {\n          childStack = childAncestors;\n          childModified = true;\n        } else if (parentFiberId.id > childFiberId.id) {\n          parentStack = parentAncestors;\n        } else {\n          ret = [childRefValue, childModified];\n        }\n      }\n    } else {\n      ret = [ref.initial, true];\n    }\n  }\n  return ret;\n};\n/** @internal */\nexport const joinAs = /*#__PURE__*/dual(3, (self, fiberId, that) => {\n  const parentFiberRefs = new Map(self.locals);\n  that.locals.forEach((childStack, fiberRef) => {\n    const childValue = childStack[0][1];\n    if (!childStack[0][0][Equal.symbol](fiberId)) {\n      if (!parentFiberRefs.has(fiberRef)) {\n        if (Equal.equals(childValue, fiberRef.initial)) {\n          return;\n        }\n        parentFiberRefs.set(fiberRef, [[fiberId, fiberRef.join(fiberRef.initial, childValue)]]);\n        return;\n      }\n      const parentStack = parentFiberRefs.get(fiberRef);\n      const [ancestor, wasModified] = findAncestor(fiberRef, parentStack, childStack);\n      if (wasModified) {\n        const patch = fiberRef.diff(ancestor, childValue);\n        const oldValue = parentStack[0][1];\n        const newValue = fiberRef.join(oldValue, fiberRef.patch(patch)(oldValue));\n        if (!Equal.equals(oldValue, newValue)) {\n          let newStack;\n          const parentFiberId = parentStack[0][0];\n          if (parentFiberId[Equal.symbol](fiberId)) {\n            newStack = [[parentFiberId, newValue], ...parentStack.slice(1)];\n          } else {\n            newStack = [[fiberId, newValue], ...parentStack];\n          }\n          parentFiberRefs.set(fiberRef, newStack);\n        }\n      }\n    }\n  });\n  return new FiberRefsImpl(parentFiberRefs);\n});\n/** @internal */\nexport const forkAs = /*#__PURE__*/dual(2, (self, childId) => {\n  const map = new Map();\n  unsafeForkAs(self, map, childId);\n  return new FiberRefsImpl(map);\n});\nconst unsafeForkAs = (self, map, fiberId) => {\n  self.locals.forEach((stack, fiberRef) => {\n    const oldValue = stack[0][1];\n    const newValue = fiberRef.patch(fiberRef.fork)(oldValue);\n    if (Equal.equals(oldValue, newValue)) {\n      map.set(fiberRef, stack);\n    } else {\n      map.set(fiberRef, [[fiberId, newValue], ...stack]);\n    }\n  });\n};\n/** @internal */\nexport const fiberRefs = self => HashSet.fromIterable(self.locals.keys());\n/** @internal */\nexport const setAll = self => core.forEachSequentialDiscard(fiberRefs(self), fiberRef => core.fiberRefSet(fiberRef, getOrDefault(self, fiberRef)));\n/** @internal */\nexport const delete_ = /*#__PURE__*/dual(2, (self, fiberRef) => {\n  const locals = new Map(self.locals);\n  locals.delete(fiberRef);\n  return new FiberRefsImpl(locals);\n});\n/** @internal */\nexport const get = /*#__PURE__*/dual(2, (self, fiberRef) => {\n  if (!self.locals.has(fiberRef)) {\n    return Option.none();\n  }\n  return Option.some(Arr.headNonEmpty(self.locals.get(fiberRef))[1]);\n});\n/** @internal */\nexport const getOrDefault = /*#__PURE__*/dual(2, (self, fiberRef) => pipe(get(self, fiberRef), Option.getOrElse(() => fiberRef.initial)));\n/** @internal */\nexport const updateAs = /*#__PURE__*/dual(2, (self, {\n  fiberId,\n  fiberRef,\n  value\n}) => {\n  if (self.locals.size === 0) {\n    return new FiberRefsImpl(new Map([[fiberRef, [[fiberId, value]]]]));\n  }\n  const locals = new Map(self.locals);\n  unsafeUpdateAs(locals, fiberId, fiberRef, value);\n  return new FiberRefsImpl(locals);\n});\nconst unsafeUpdateAs = (locals, fiberId, fiberRef, value) => {\n  const oldStack = locals.get(fiberRef) ?? [];\n  let newStack;\n  if (Arr.isNonEmptyReadonlyArray(oldStack)) {\n    const [currentId, currentValue] = Arr.headNonEmpty(oldStack);\n    if (currentId[Equal.symbol](fiberId)) {\n      if (Equal.equals(currentValue, value)) {\n        return;\n      } else {\n        newStack = [[fiberId, value], ...oldStack.slice(1)];\n      }\n    } else {\n      newStack = [[fiberId, value], ...oldStack];\n    }\n  } else {\n    newStack = [[fiberId, value]];\n  }\n  locals.set(fiberRef, newStack);\n};\n/** @internal */\nexport const updateManyAs = /*#__PURE__*/dual(2, (self, {\n  entries,\n  forkAs\n}) => {\n  if (self.locals.size === 0) {\n    return new FiberRefsImpl(new Map(entries));\n  }\n  const locals = new Map(self.locals);\n  if (forkAs !== undefined) {\n    unsafeForkAs(self, locals, forkAs);\n  }\n  entries.forEach(([fiberRef, values]) => {\n    if (values.length === 1) {\n      unsafeUpdateAs(locals, values[0][0], fiberRef, values[0][1]);\n    } else {\n      values.forEach(([fiberId, value]) => {\n        unsafeUpdateAs(locals, fiberId, fiberRef, value);\n      });\n    }\n  });\n  return new FiberRefsImpl(locals);\n});\n//# sourceMappingURL=fiberRefs.js.map","import * as Arr from \"../../Array.js\";\nimport { equals } from \"../../Equal.js\";\nimport { dual } from \"../../Function.js\";\nimport * as _fiberRefs from \"../fiberRefs.js\";\n/** @internal */\nexport const OP_EMPTY = \"Empty\";\n/** @internal */\nexport const OP_ADD = \"Add\";\n/** @internal */\nexport const OP_REMOVE = \"Remove\";\n/** @internal */\nexport const OP_UPDATE = \"Update\";\n/** @internal */\nexport const OP_AND_THEN = \"AndThen\";\n/** @internal */\nexport const empty = {\n  _tag: OP_EMPTY\n};\n/** @internal */\nexport const diff = (oldValue, newValue) => {\n  const missingLocals = new Map(oldValue.locals);\n  let patch = empty;\n  for (const [fiberRef, pairs] of newValue.locals.entries()) {\n    const newValue = Arr.headNonEmpty(pairs)[1];\n    const old = missingLocals.get(fiberRef);\n    if (old !== undefined) {\n      const oldValue = Arr.headNonEmpty(old)[1];\n      if (!equals(oldValue, newValue)) {\n        patch = combine({\n          _tag: OP_UPDATE,\n          fiberRef,\n          patch: fiberRef.diff(oldValue, newValue)\n        })(patch);\n      }\n    } else {\n      patch = combine({\n        _tag: OP_ADD,\n        fiberRef,\n        value: newValue\n      })(patch);\n    }\n    missingLocals.delete(fiberRef);\n  }\n  for (const [fiberRef] of missingLocals.entries()) {\n    patch = combine({\n      _tag: OP_REMOVE,\n      fiberRef\n    })(patch);\n  }\n  return patch;\n};\n/** @internal */\nexport const combine = /*#__PURE__*/dual(2, (self, that) => ({\n  _tag: OP_AND_THEN,\n  first: self,\n  second: that\n}));\n/** @internal */\nexport const patch = /*#__PURE__*/dual(3, (self, fiberId, oldValue) => {\n  let fiberRefs = oldValue;\n  let patches = Arr.of(self);\n  while (Arr.isNonEmptyReadonlyArray(patches)) {\n    const head = Arr.headNonEmpty(patches);\n    const tail = Arr.tailNonEmpty(patches);\n    switch (head._tag) {\n      case OP_EMPTY:\n        {\n          patches = tail;\n          break;\n        }\n      case OP_ADD:\n        {\n          fiberRefs = _fiberRefs.updateAs(fiberRefs, {\n            fiberId,\n            fiberRef: head.fiberRef,\n            value: head.value\n          });\n          patches = tail;\n          break;\n        }\n      case OP_REMOVE:\n        {\n          fiberRefs = _fiberRefs.delete_(fiberRefs, head.fiberRef);\n          patches = tail;\n          break;\n        }\n      case OP_UPDATE:\n        {\n          const value = _fiberRefs.getOrDefault(fiberRefs, head.fiberRef);\n          fiberRefs = _fiberRefs.updateAs(fiberRefs, {\n            fiberId,\n            fiberRef: head.fiberRef,\n            value: head.fiberRef.patch(head.patch)(value)\n          });\n          patches = tail;\n          break;\n        }\n      case OP_AND_THEN:\n        {\n          patches = Arr.prepend(head.first)(Arr.prepend(head.second)(tail));\n          break;\n        }\n    }\n  }\n  return fiberRefs;\n});\n//# sourceMappingURL=patch.js.map","import { internalCall } from \"effect/Utils\";\nimport * as RA from \"../Array.js\";\nimport * as Boolean from \"../Boolean.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Context from \"../Context.js\";\nimport * as Deferred from \"../Deferred.js\";\nimport { EffectTypeId } from \"../Effectable.js\";\nimport * as ExecutionStrategy from \"../ExecutionStrategy.js\";\nimport * as FiberId from \"../FiberId.js\";\nimport * as FiberRefs from \"../FiberRefs.js\";\nimport * as FiberRefsPatch from \"../FiberRefsPatch.js\";\nimport * as FiberStatus from \"../FiberStatus.js\";\nimport { dual, identity, pipe } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport * as Inspectable from \"../Inspectable.js\";\nimport * as LogLevel from \"../LogLevel.js\";\nimport * as Micro from \"../Micro.js\";\nimport * as MRef from \"../MutableRef.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport * as Predicate from \"../Predicate.js\";\nimport * as Ref from \"../Ref.js\";\nimport * as RuntimeFlagsPatch from \"../RuntimeFlagsPatch.js\";\nimport { currentScheduler } from \"../Scheduler.js\";\nimport * as _RequestBlock from \"./blockedRequests.js\";\nimport * as internalCause from \"./cause.js\";\nimport * as clock from \"./clock.js\";\nimport { currentRequestMap } from \"./completedRequestMap.js\";\nimport * as concurrency from \"./concurrency.js\";\nimport { configProviderTag } from \"./configProvider.js\";\nimport * as internalEffect from \"./core-effect.js\";\nimport * as core from \"./core.js\";\nimport * as defaultServices from \"./defaultServices.js\";\nimport { consoleTag } from \"./defaultServices/console.js\";\nimport * as executionStrategy from \"./executionStrategy.js\";\nimport * as internalFiber from \"./fiber.js\";\nimport * as FiberMessage from \"./fiberMessage.js\";\nimport * as fiberRefs from \"./fiberRefs.js\";\nimport * as fiberScope from \"./fiberScope.js\";\nimport * as internalLogger from \"./logger.js\";\nimport * as metric from \"./metric.js\";\nimport * as metricBoundaries from \"./metric/boundaries.js\";\nimport * as metricLabel from \"./metric/label.js\";\nimport * as OpCodes from \"./opCodes/effect.js\";\nimport { randomTag } from \"./random.js\";\nimport { complete } from \"./request.js\";\nimport * as _runtimeFlags from \"./runtimeFlags.js\";\nimport { OpSupervision } from \"./runtimeFlags.js\";\nimport * as supervisor from \"./supervisor.js\";\nimport * as SupervisorPatch from \"./supervisor/patch.js\";\nimport * as tracer from \"./tracer.js\";\nimport * as version from \"./version.js\";\n/** @internal */\nexport const fiberStarted = /*#__PURE__*/metric.counter(\"effect_fiber_started\", {\n  incremental: true\n});\n/** @internal */\nexport const fiberActive = /*#__PURE__*/metric.counter(\"effect_fiber_active\");\n/** @internal */\nexport const fiberSuccesses = /*#__PURE__*/metric.counter(\"effect_fiber_successes\", {\n  incremental: true\n});\n/** @internal */\nexport const fiberFailures = /*#__PURE__*/metric.counter(\"effect_fiber_failures\", {\n  incremental: true\n});\n/** @internal */\nexport const fiberLifetimes = /*#__PURE__*/metric.tagged( /*#__PURE__*/metric.histogram(\"effect_fiber_lifetimes\", /*#__PURE__*/metricBoundaries.exponential({\n  start: 0.5,\n  factor: 2,\n  count: 35\n})), \"time_unit\", \"milliseconds\");\n/** @internal */\nconst EvaluationSignalContinue = \"Continue\";\n/** @internal */\nconst EvaluationSignalDone = \"Done\";\n/** @internal */\nconst EvaluationSignalYieldNow = \"Yield\";\nconst runtimeFiberVariance = {\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _A: _ => _\n};\nconst absurd = _ => {\n  throw new Error(`BUG: FiberRuntime - ${Inspectable.toStringUnknown(_)} - please report an issue at https://github.com/Effect-TS/effect/issues`);\n};\nconst YieldedOp = /*#__PURE__*/Symbol.for(\"effect/internal/fiberRuntime/YieldedOp\");\nconst yieldedOpChannel = /*#__PURE__*/globalValue(\"effect/internal/fiberRuntime/yieldedOpChannel\", () => ({\n  currentOp: null\n}));\nconst contOpSuccess = {\n  [OpCodes.OP_ON_SUCCESS]: (_, cont, value) => {\n    return internalCall(() => cont.effect_instruction_i1(value));\n  },\n  [\"OnStep\"]: (_, _cont, value) => {\n    return core.exitSucceed(core.exitSucceed(value));\n  },\n  [OpCodes.OP_ON_SUCCESS_AND_FAILURE]: (_, cont, value) => {\n    return internalCall(() => cont.effect_instruction_i2(value));\n  },\n  [OpCodes.OP_REVERT_FLAGS]: (self, cont, value) => {\n    self.patchRuntimeFlags(self._runtimeFlags, cont.patch);\n    if (_runtimeFlags.interruptible(self._runtimeFlags) && self.isInterrupted()) {\n      return core.exitFailCause(self.getInterruptedCause());\n    } else {\n      return core.exitSucceed(value);\n    }\n  },\n  [OpCodes.OP_WHILE]: (self, cont, value) => {\n    internalCall(() => cont.effect_instruction_i2(value));\n    if (internalCall(() => cont.effect_instruction_i0())) {\n      self.pushStack(cont);\n      return internalCall(() => cont.effect_instruction_i1());\n    } else {\n      return core.void;\n    }\n  }\n};\nconst drainQueueWhileRunningTable = {\n  [FiberMessage.OP_INTERRUPT_SIGNAL]: (self, runtimeFlags, cur, message) => {\n    self.processNewInterruptSignal(message.cause);\n    return _runtimeFlags.interruptible(runtimeFlags) ? core.exitFailCause(message.cause) : cur;\n  },\n  [FiberMessage.OP_RESUME]: (_self, _runtimeFlags, _cur, _message) => {\n    throw new Error(\"It is illegal to have multiple concurrent run loops in a single fiber\");\n  },\n  [FiberMessage.OP_STATEFUL]: (self, runtimeFlags, cur, message) => {\n    message.onFiber(self, FiberStatus.running(runtimeFlags));\n    return cur;\n  },\n  [FiberMessage.OP_YIELD_NOW]: (_self, _runtimeFlags, cur, _message) => {\n    return core.flatMap(core.yieldNow(), () => cur);\n  }\n};\n/**\n * Executes all requests, submitting requests to each data source in parallel.\n */\nconst runBlockedRequests = self => core.forEachSequentialDiscard(_RequestBlock.flatten(self), requestsByRequestResolver => forEachConcurrentDiscard(_RequestBlock.sequentialCollectionToChunk(requestsByRequestResolver), ([dataSource, sequential]) => {\n  const map = new Map();\n  const arr = [];\n  for (const block of sequential) {\n    arr.push(Chunk.toReadonlyArray(block));\n    for (const entry of block) {\n      map.set(entry.request, entry);\n    }\n  }\n  const flat = arr.flat();\n  return core.fiberRefLocally(invokeWithInterrupt(dataSource.runAll(arr), flat, () => flat.forEach(entry => {\n    entry.listeners.interrupted = true;\n  })), currentRequestMap, map);\n}, false, false));\n/** @internal */\nexport class FiberRuntime {\n  [internalFiber.FiberTypeId] = internalFiber.fiberVariance;\n  [internalFiber.RuntimeFiberTypeId] = runtimeFiberVariance;\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  _fiberRefs;\n  _fiberId;\n  _runtimeFlags;\n  _queue = /*#__PURE__*/new Array();\n  _children = null;\n  _observers = /*#__PURE__*/new Array();\n  _running = false;\n  _stack = [];\n  _asyncInterruptor = null;\n  _asyncBlockingOn = null;\n  _exitValue = null;\n  _steps = [];\n  _supervisor;\n  _scheduler;\n  _tracer;\n  currentOpCount = 0;\n  isYielding = false;\n  constructor(fiberId, fiberRefs0, runtimeFlags0) {\n    this._runtimeFlags = runtimeFlags0;\n    this._fiberId = fiberId;\n    this._fiberRefs = fiberRefs0;\n    this._supervisor = this.getFiberRef(currentSupervisor);\n    this._scheduler = this.getFiberRef(currentScheduler);\n    if (_runtimeFlags.runtimeMetrics(runtimeFlags0)) {\n      const tags = this.getFiberRef(core.currentMetricLabels);\n      fiberStarted.unsafeUpdate(1, tags);\n      fiberActive.unsafeUpdate(1, tags);\n    }\n    this._tracer = Context.get(this.getFiberRef(defaultServices.currentServices), tracer.tracerTag);\n  }\n  /**\n   * The identity of the fiber.\n   */\n  id() {\n    return this._fiberId;\n  }\n  /**\n   * Begins execution of the effect associated with this fiber on in the\n   * background. This can be called to \"kick off\" execution of a fiber after\n   * it has been created.\n   */\n  resume(effect) {\n    this.tell(FiberMessage.resume(effect));\n  }\n  /**\n   * The status of the fiber.\n   */\n  get status() {\n    return this.ask((_, status) => status);\n  }\n  /**\n   * Gets the fiber runtime flags.\n   */\n  get runtimeFlags() {\n    return this.ask((state, status) => {\n      if (FiberStatus.isDone(status)) {\n        return state._runtimeFlags;\n      }\n      return status.runtimeFlags;\n    });\n  }\n  /**\n   * Returns the current `FiberScope` for the fiber.\n   */\n  scope() {\n    return fiberScope.unsafeMake(this);\n  }\n  /**\n   * Retrieves the immediate children of the fiber.\n   */\n  get children() {\n    return this.ask(fiber => Array.from(fiber.getChildren()));\n  }\n  /**\n   * Gets the fiber's set of children.\n   */\n  getChildren() {\n    if (this._children === null) {\n      this._children = new Set();\n    }\n    return this._children;\n  }\n  /**\n   * Retrieves the interrupted cause of the fiber, which will be `Cause.empty`\n   * if the fiber has not been interrupted.\n   *\n   * **NOTE**: This method is safe to invoke on any fiber, but if not invoked\n   * on this fiber, then values derived from the fiber's state (including the\n   * log annotations and log level) may not be up-to-date.\n   */\n  getInterruptedCause() {\n    return this.getFiberRef(core.currentInterruptedCause);\n  }\n  /**\n   * Retrieves the whole set of fiber refs.\n   */\n  fiberRefs() {\n    return this.ask(fiber => fiber.getFiberRefs());\n  }\n  /**\n   * Returns an effect that will contain information computed from the fiber\n   * state and status while running on the fiber.\n   *\n   * This allows the outside world to interact safely with mutable fiber state\n   * without locks or immutable data.\n   */\n  ask(f) {\n    return core.suspend(() => {\n      const deferred = core.deferredUnsafeMake(this._fiberId);\n      this.tell(FiberMessage.stateful((fiber, status) => {\n        core.deferredUnsafeDone(deferred, core.sync(() => f(fiber, status)));\n      }));\n      return core.deferredAwait(deferred);\n    });\n  }\n  /**\n   * Adds a message to be processed by the fiber on the fiber.\n   */\n  tell(message) {\n    this._queue.push(message);\n    if (!this._running) {\n      this._running = true;\n      this.drainQueueLaterOnExecutor();\n    }\n  }\n  get await() {\n    return core.async(resume => {\n      const cb = exit => resume(core.succeed(exit));\n      this.tell(FiberMessage.stateful((fiber, _) => {\n        if (fiber._exitValue !== null) {\n          cb(this._exitValue);\n        } else {\n          fiber.addObserver(cb);\n        }\n      }));\n      return core.sync(() => this.tell(FiberMessage.stateful((fiber, _) => {\n        fiber.removeObserver(cb);\n      })));\n    }, this.id());\n  }\n  get inheritAll() {\n    return core.withFiberRuntime((parentFiber, parentStatus) => {\n      const parentFiberId = parentFiber.id();\n      const parentFiberRefs = parentFiber.getFiberRefs();\n      const parentRuntimeFlags = parentStatus.runtimeFlags;\n      const childFiberRefs = this.getFiberRefs();\n      const updatedFiberRefs = fiberRefs.joinAs(parentFiberRefs, parentFiberId, childFiberRefs);\n      parentFiber.setFiberRefs(updatedFiberRefs);\n      const updatedRuntimeFlags = parentFiber.getFiberRef(currentRuntimeFlags);\n      const patch = pipe(_runtimeFlags.diff(parentRuntimeFlags, updatedRuntimeFlags),\n      // Do not inherit WindDown or Interruption!\n      RuntimeFlagsPatch.exclude(_runtimeFlags.Interruption), RuntimeFlagsPatch.exclude(_runtimeFlags.WindDown));\n      return core.updateRuntimeFlags(patch);\n    });\n  }\n  /**\n   * Tentatively observes the fiber, but returns immediately if it is not\n   * already done.\n   */\n  get poll() {\n    return core.sync(() => Option.fromNullable(this._exitValue));\n  }\n  /**\n   * Unsafely observes the fiber, but returns immediately if it is not\n   * already done.\n   */\n  unsafePoll() {\n    return this._exitValue;\n  }\n  /**\n   * In the background, interrupts the fiber as if interrupted from the specified fiber.\n   */\n  interruptAsFork(fiberId) {\n    return core.sync(() => this.tell(FiberMessage.interruptSignal(internalCause.interrupt(fiberId))));\n  }\n  /**\n   * In the background, interrupts the fiber as if interrupted from the specified fiber.\n   */\n  unsafeInterruptAsFork(fiberId) {\n    this.tell(FiberMessage.interruptSignal(internalCause.interrupt(fiberId)));\n  }\n  /**\n   * Adds an observer to the list of observers.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  addObserver(observer) {\n    if (this._exitValue !== null) {\n      observer(this._exitValue);\n    } else {\n      this._observers.push(observer);\n    }\n  }\n  /**\n   * Removes the specified observer from the list of observers that will be\n   * notified when the fiber exits.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  removeObserver(observer) {\n    this._observers = this._observers.filter(o => o !== observer);\n  }\n  /**\n   * Retrieves all fiber refs of the fiber.\n   *\n   * **NOTE**: This method is safe to invoke on any fiber, but if not invoked\n   * on this fiber, then values derived from the fiber's state (including the\n   * log annotations and log level) may not be up-to-date.\n   */\n  getFiberRefs() {\n    this.setFiberRef(currentRuntimeFlags, this._runtimeFlags);\n    return this._fiberRefs;\n  }\n  /**\n   * Deletes the specified fiber ref.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  unsafeDeleteFiberRef(fiberRef) {\n    this._fiberRefs = fiberRefs.delete_(this._fiberRefs, fiberRef);\n  }\n  /**\n   * Retrieves the state of the fiber ref, or else its initial value.\n   *\n   * **NOTE**: This method is safe to invoke on any fiber, but if not invoked\n   * on this fiber, then values derived from the fiber's state (including the\n   * log annotations and log level) may not be up-to-date.\n   */\n  getFiberRef(fiberRef) {\n    if (this._fiberRefs.locals.has(fiberRef)) {\n      return this._fiberRefs.locals.get(fiberRef)[0][1];\n    }\n    return fiberRef.initial;\n  }\n  /**\n   * Sets the fiber ref to the specified value.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  setFiberRef(fiberRef, value) {\n    this._fiberRefs = fiberRefs.updateAs(this._fiberRefs, {\n      fiberId: this._fiberId,\n      fiberRef,\n      value\n    });\n    this.refreshRefCache();\n  }\n  refreshRefCache() {\n    this._tracer = Context.get(this.getFiberRef(defaultServices.currentServices), tracer.tracerTag);\n    this._supervisor = this.getFiberRef(currentSupervisor);\n    this._scheduler = this.getFiberRef(currentScheduler);\n  }\n  /**\n   * Wholesale replaces all fiber refs of this fiber.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  setFiberRefs(fiberRefs) {\n    this._fiberRefs = fiberRefs;\n    this.refreshRefCache();\n  }\n  /**\n   * Adds a reference to the specified fiber inside the children set.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  addChild(child) {\n    this.getChildren().add(child);\n  }\n  /**\n   * Removes a reference to the specified fiber inside the children set.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  removeChild(child) {\n    this.getChildren().delete(child);\n  }\n  /**\n   * On the current thread, executes all messages in the fiber's inbox. This\n   * method may return before all work is done, in the event the fiber executes\n   * an asynchronous operation.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  drainQueueOnCurrentThread() {\n    let recurse = true;\n    while (recurse) {\n      let evaluationSignal = EvaluationSignalContinue;\n      const prev = globalThis[internalFiber.currentFiberURI];\n      globalThis[internalFiber.currentFiberURI] = this;\n      try {\n        while (evaluationSignal === EvaluationSignalContinue) {\n          evaluationSignal = this._queue.length === 0 ? EvaluationSignalDone : this.evaluateMessageWhileSuspended(this._queue.splice(0, 1)[0]);\n        }\n      } finally {\n        this._running = false;\n        globalThis[internalFiber.currentFiberURI] = prev;\n      }\n      // Maybe someone added something to the queue between us checking, and us\n      // giving up the drain. If so, we need to restart the draining, but only\n      // if we beat everyone else to the restart:\n      if (this._queue.length > 0 && !this._running) {\n        this._running = true;\n        if (evaluationSignal === EvaluationSignalYieldNow) {\n          this.drainQueueLaterOnExecutor();\n          recurse = false;\n        } else {\n          recurse = true;\n        }\n      } else {\n        recurse = false;\n      }\n    }\n  }\n  /**\n   * Schedules the execution of all messages in the fiber's inbox.\n   *\n   * This method will return immediately after the scheduling\n   * operation is completed, but potentially before such messages have been\n   * executed.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  drainQueueLaterOnExecutor() {\n    this._scheduler.scheduleTask(this.run, this.getFiberRef(core.currentSchedulingPriority));\n  }\n  /**\n   * Drains the fiber's message queue while the fiber is actively running,\n   * returning the next effect to execute, which may be the input effect if no\n   * additional effect needs to be executed.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  drainQueueWhileRunning(runtimeFlags, cur0) {\n    let cur = cur0;\n    while (this._queue.length > 0) {\n      const message = this._queue.splice(0, 1)[0];\n      // @ts-expect-error\n      cur = drainQueueWhileRunningTable[message._tag](this, runtimeFlags, cur, message);\n    }\n    return cur;\n  }\n  /**\n   * Determines if the fiber is interrupted.\n   *\n   * **NOTE**: This method is safe to invoke on any fiber, but if not invoked\n   * on this fiber, then values derived from the fiber's state (including the\n   * log annotations and log level) may not be up-to-date.\n   */\n  isInterrupted() {\n    return !internalCause.isEmpty(this.getFiberRef(core.currentInterruptedCause));\n  }\n  /**\n   * Adds an interruptor to the set of interruptors that are interrupting this\n   * fiber.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  addInterruptedCause(cause) {\n    const oldSC = this.getFiberRef(core.currentInterruptedCause);\n    this.setFiberRef(core.currentInterruptedCause, internalCause.sequential(oldSC, cause));\n  }\n  /**\n   * Processes a new incoming interrupt signal.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  processNewInterruptSignal(cause) {\n    this.addInterruptedCause(cause);\n    this.sendInterruptSignalToAllChildren();\n  }\n  /**\n   * Interrupts all children of the current fiber, returning an effect that will\n   * await the exit of the children. This method will return null if the fiber\n   * has no children.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  sendInterruptSignalToAllChildren() {\n    if (this._children === null || this._children.size === 0) {\n      return false;\n    }\n    let told = false;\n    for (const child of this._children) {\n      child.tell(FiberMessage.interruptSignal(internalCause.interrupt(this.id())));\n      told = true;\n    }\n    return told;\n  }\n  /**\n   * Interrupts all children of the current fiber, returning an effect that will\n   * await the exit of the children. This method will return null if the fiber\n   * has no children.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  interruptAllChildren() {\n    if (this.sendInterruptSignalToAllChildren()) {\n      const it = this._children.values();\n      this._children = null;\n      let isDone = false;\n      const body = () => {\n        const next = it.next();\n        if (!next.done) {\n          return core.asVoid(next.value.await);\n        } else {\n          return core.sync(() => {\n            isDone = true;\n          });\n        }\n      };\n      return core.whileLoop({\n        while: () => !isDone,\n        body,\n        step: () => {\n          //\n        }\n      });\n    }\n    return null;\n  }\n  reportExitValue(exit) {\n    if (_runtimeFlags.runtimeMetrics(this._runtimeFlags)) {\n      const tags = this.getFiberRef(core.currentMetricLabels);\n      const startTimeMillis = this.id().startTimeMillis;\n      const endTimeMillis = Date.now();\n      fiberLifetimes.unsafeUpdate(endTimeMillis - startTimeMillis, tags);\n      fiberActive.unsafeUpdate(-1, tags);\n      switch (exit._tag) {\n        case OpCodes.OP_SUCCESS:\n          {\n            fiberSuccesses.unsafeUpdate(1, tags);\n            break;\n          }\n        case OpCodes.OP_FAILURE:\n          {\n            fiberFailures.unsafeUpdate(1, tags);\n            break;\n          }\n      }\n    }\n    if (exit._tag === \"Failure\") {\n      const level = this.getFiberRef(core.currentUnhandledErrorLogLevel);\n      if (!internalCause.isInterruptedOnly(exit.cause) && level._tag === \"Some\") {\n        this.log(\"Fiber terminated with an unhandled error\", exit.cause, level);\n      }\n    }\n  }\n  setExitValue(exit) {\n    this._exitValue = exit;\n    this.reportExitValue(exit);\n    for (let i = this._observers.length - 1; i >= 0; i--) {\n      this._observers[i](exit);\n    }\n  }\n  getLoggers() {\n    return this.getFiberRef(currentLoggers);\n  }\n  log(message, cause, overrideLogLevel) {\n    const logLevel = Option.isSome(overrideLogLevel) ? overrideLogLevel.value : this.getFiberRef(core.currentLogLevel);\n    const minimumLogLevel = this.getFiberRef(currentMinimumLogLevel);\n    if (LogLevel.greaterThan(minimumLogLevel, logLevel)) {\n      return;\n    }\n    const spans = this.getFiberRef(core.currentLogSpan);\n    const annotations = this.getFiberRef(core.currentLogAnnotations);\n    const loggers = this.getLoggers();\n    const contextMap = this.getFiberRefs();\n    if (HashSet.size(loggers) > 0) {\n      const clockService = Context.get(this.getFiberRef(defaultServices.currentServices), clock.clockTag);\n      const date = new Date(clockService.unsafeCurrentTimeMillis());\n      for (const logger of loggers) {\n        logger.log({\n          fiberId: this.id(),\n          logLevel,\n          message,\n          cause,\n          context: contextMap,\n          spans,\n          annotations,\n          date\n        });\n      }\n    }\n  }\n  /**\n   * Evaluates a single message on the current thread, while the fiber is\n   * suspended. This method should only be called while evaluation of the\n   * fiber's effect is suspended due to an asynchronous operation.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  evaluateMessageWhileSuspended(message) {\n    switch (message._tag) {\n      case FiberMessage.OP_YIELD_NOW:\n        {\n          return EvaluationSignalYieldNow;\n        }\n      case FiberMessage.OP_INTERRUPT_SIGNAL:\n        {\n          this.processNewInterruptSignal(message.cause);\n          if (this._asyncInterruptor !== null) {\n            this._asyncInterruptor(core.exitFailCause(message.cause));\n            this._asyncInterruptor = null;\n          }\n          return EvaluationSignalContinue;\n        }\n      case FiberMessage.OP_RESUME:\n        {\n          this._asyncInterruptor = null;\n          this._asyncBlockingOn = null;\n          this.evaluateEffect(message.effect);\n          return EvaluationSignalContinue;\n        }\n      case FiberMessage.OP_STATEFUL:\n        {\n          message.onFiber(this, this._exitValue !== null ? FiberStatus.done : FiberStatus.suspended(this._runtimeFlags, this._asyncBlockingOn));\n          return EvaluationSignalContinue;\n        }\n      default:\n        {\n          return absurd(message);\n        }\n    }\n  }\n  /**\n   * Evaluates an effect until completion, potentially asynchronously.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  evaluateEffect(effect0) {\n    this._supervisor.onResume(this);\n    try {\n      let effect = _runtimeFlags.interruptible(this._runtimeFlags) && this.isInterrupted() ? core.exitFailCause(this.getInterruptedCause()) : effect0;\n      while (effect !== null) {\n        const eff = effect;\n        const exit = this.runLoop(eff);\n        if (exit === YieldedOp) {\n          const op = yieldedOpChannel.currentOp;\n          yieldedOpChannel.currentOp = null;\n          if (op._op === OpCodes.OP_YIELD) {\n            if (_runtimeFlags.cooperativeYielding(this._runtimeFlags)) {\n              this.tell(FiberMessage.yieldNow());\n              this.tell(FiberMessage.resume(core.exitVoid));\n              effect = null;\n            } else {\n              effect = core.exitVoid;\n            }\n          } else if (op._op === OpCodes.OP_ASYNC) {\n            // Terminate this evaluation, async resumption will continue evaluation:\n            effect = null;\n          }\n        } else {\n          this._runtimeFlags = pipe(this._runtimeFlags, _runtimeFlags.enable(_runtimeFlags.WindDown));\n          const interruption = this.interruptAllChildren();\n          if (interruption !== null) {\n            effect = core.flatMap(interruption, () => exit);\n          } else {\n            if (this._queue.length === 0) {\n              // No more messages to process, so we will allow the fiber to end life:\n              this.setExitValue(exit);\n            } else {\n              // There are messages, possibly added by the final op executed by\n              // the fiber. To be safe, we should execute those now before we\n              // allow the fiber to end life:\n              this.tell(FiberMessage.resume(exit));\n            }\n            effect = null;\n          }\n        }\n      }\n    } finally {\n      this._supervisor.onSuspend(this);\n    }\n  }\n  /**\n   * Begins execution of the effect associated with this fiber on the current\n   * thread. This can be called to \"kick off\" execution of a fiber after it has\n   * been created, in hopes that the effect can be executed synchronously.\n   *\n   * This is not the normal way of starting a fiber, but it is useful when the\n   * express goal of executing the fiber is to synchronously produce its exit.\n   */\n  start(effect) {\n    if (!this._running) {\n      this._running = true;\n      const prev = globalThis[internalFiber.currentFiberURI];\n      globalThis[internalFiber.currentFiberURI] = this;\n      try {\n        this.evaluateEffect(effect);\n      } finally {\n        this._running = false;\n        globalThis[internalFiber.currentFiberURI] = prev;\n        // Because we're special casing `start`, we have to be responsible\n        // for spinning up the fiber if there were new messages added to\n        // the queue between the completion of the effect and the transition\n        // to the not running state.\n        if (this._queue.length > 0) {\n          this.drainQueueLaterOnExecutor();\n        }\n      }\n    } else {\n      this.tell(FiberMessage.resume(effect));\n    }\n  }\n  /**\n   * Begins execution of the effect associated with this fiber on in the\n   * background, and on the correct thread pool. This can be called to \"kick\n   * off\" execution of a fiber after it has been created, in hopes that the\n   * effect can be executed synchronously.\n   */\n  startFork(effect) {\n    this.tell(FiberMessage.resume(effect));\n  }\n  /**\n   * Takes the current runtime flags, patches them to return the new runtime\n   * flags, and then makes any changes necessary to fiber state based on the\n   * specified patch.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  patchRuntimeFlags(oldRuntimeFlags, patch) {\n    const newRuntimeFlags = _runtimeFlags.patch(oldRuntimeFlags, patch);\n    globalThis[internalFiber.currentFiberURI] = this;\n    this._runtimeFlags = newRuntimeFlags;\n    return newRuntimeFlags;\n  }\n  /**\n   * Initiates an asynchronous operation, by building a callback that will\n   * resume execution, and then feeding that callback to the registration\n   * function, handling error cases and repeated resumptions appropriately.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  initiateAsync(runtimeFlags, asyncRegister) {\n    let alreadyCalled = false;\n    const callback = effect => {\n      if (!alreadyCalled) {\n        alreadyCalled = true;\n        this.tell(FiberMessage.resume(effect));\n      }\n    };\n    if (_runtimeFlags.interruptible(runtimeFlags)) {\n      this._asyncInterruptor = callback;\n    }\n    try {\n      asyncRegister(callback);\n    } catch (e) {\n      callback(core.failCause(internalCause.die(e)));\n    }\n  }\n  pushStack(cont) {\n    this._stack.push(cont);\n    if (cont._op === \"OnStep\") {\n      this._steps.push({\n        refs: this.getFiberRefs(),\n        flags: this._runtimeFlags\n      });\n    }\n  }\n  popStack() {\n    const item = this._stack.pop();\n    if (item) {\n      if (item._op === \"OnStep\") {\n        this._steps.pop();\n      }\n      return item;\n    }\n    return;\n  }\n  getNextSuccessCont() {\n    let frame = this.popStack();\n    while (frame) {\n      if (frame._op !== OpCodes.OP_ON_FAILURE) {\n        return frame;\n      }\n      frame = this.popStack();\n    }\n  }\n  getNextFailCont() {\n    let frame = this.popStack();\n    while (frame) {\n      if (frame._op !== OpCodes.OP_ON_SUCCESS && frame._op !== OpCodes.OP_WHILE) {\n        return frame;\n      }\n      frame = this.popStack();\n    }\n  }\n  [OpCodes.OP_TAG](op) {\n    return core.map(core.fiberRefGet(core.currentContext), context => Context.unsafeGet(context, op));\n  }\n  [\"Left\"](op) {\n    return core.fail(op.left);\n  }\n  [\"None\"](_) {\n    return core.fail(new core.NoSuchElementException());\n  }\n  [\"Right\"](op) {\n    return core.exitSucceed(op.right);\n  }\n  [\"Some\"](op) {\n    return core.exitSucceed(op.value);\n  }\n  [\"Micro\"](op) {\n    return core.unsafeAsync(microResume => {\n      const env = Micro.envUnsafeMakeEmpty().pipe(Micro.envSet(Micro.currentContext, this.getFiberRef(core.currentContext)));\n      let resume = microResume;\n      op[Micro.runSymbol](env, result => {\n        if (result._tag === \"Right\") {\n          return resume(core.exitSucceed(result.right));\n        }\n        switch (result.left._tag) {\n          case \"Interrupt\":\n            {\n              return resume(core.exitFailCause(internalCause.interrupt(FiberId.none)));\n            }\n          case \"Fail\":\n            {\n              return resume(core.fail(result.left.error));\n            }\n          case \"Die\":\n            {\n              return resume(core.die(result.left.defect));\n            }\n        }\n      });\n      return core.async(abortResume => {\n        resume = _ => {\n          abortResume(core.void);\n        };\n        Micro.envGet(env, Micro.currentAbortController).abort();\n      });\n    });\n  }\n  [OpCodes.OP_SYNC](op) {\n    const value = internalCall(() => op.effect_instruction_i0());\n    const cont = this.getNextSuccessCont();\n    if (cont !== undefined) {\n      if (!(cont._op in contOpSuccess)) {\n        // @ts-expect-error\n        absurd(cont);\n      }\n      // @ts-expect-error\n      return contOpSuccess[cont._op](this, cont, value);\n    } else {\n      yieldedOpChannel.currentOp = core.exitSucceed(value);\n      return YieldedOp;\n    }\n  }\n  [OpCodes.OP_SUCCESS](op) {\n    const oldCur = op;\n    const cont = this.getNextSuccessCont();\n    if (cont !== undefined) {\n      if (!(cont._op in contOpSuccess)) {\n        // @ts-expect-error\n        absurd(cont);\n      }\n      // @ts-expect-error\n      return contOpSuccess[cont._op](this, cont, oldCur.effect_instruction_i0);\n    } else {\n      yieldedOpChannel.currentOp = oldCur;\n      return YieldedOp;\n    }\n  }\n  [OpCodes.OP_FAILURE](op) {\n    const cause = op.effect_instruction_i0;\n    const cont = this.getNextFailCont();\n    if (cont !== undefined) {\n      switch (cont._op) {\n        case OpCodes.OP_ON_FAILURE:\n        case OpCodes.OP_ON_SUCCESS_AND_FAILURE:\n          {\n            if (!(_runtimeFlags.interruptible(this._runtimeFlags) && this.isInterrupted())) {\n              return internalCall(() => cont.effect_instruction_i1(cause));\n            } else {\n              return core.exitFailCause(internalCause.stripFailures(cause));\n            }\n          }\n        case \"OnStep\":\n          {\n            if (!(_runtimeFlags.interruptible(this._runtimeFlags) && this.isInterrupted())) {\n              return core.exitSucceed(core.exitFailCause(cause));\n            } else {\n              return core.exitFailCause(internalCause.stripFailures(cause));\n            }\n          }\n        case OpCodes.OP_REVERT_FLAGS:\n          {\n            this.patchRuntimeFlags(this._runtimeFlags, cont.patch);\n            if (_runtimeFlags.interruptible(this._runtimeFlags) && this.isInterrupted()) {\n              return core.exitFailCause(internalCause.sequential(cause, this.getInterruptedCause()));\n            } else {\n              return core.exitFailCause(cause);\n            }\n          }\n        default:\n          {\n            absurd(cont);\n          }\n      }\n    } else {\n      yieldedOpChannel.currentOp = core.exitFailCause(cause);\n      return YieldedOp;\n    }\n  }\n  [OpCodes.OP_WITH_RUNTIME](op) {\n    return internalCall(() => op.effect_instruction_i0(this, FiberStatus.running(this._runtimeFlags)));\n  }\n  [\"Blocked\"](op) {\n    const refs = this.getFiberRefs();\n    const flags = this._runtimeFlags;\n    if (this._steps.length > 0) {\n      const frames = [];\n      const snap = this._steps[this._steps.length - 1];\n      let frame = this.popStack();\n      while (frame && frame._op !== \"OnStep\") {\n        frames.push(frame);\n        frame = this.popStack();\n      }\n      this.setFiberRefs(snap.refs);\n      this._runtimeFlags = snap.flags;\n      const patchRefs = FiberRefsPatch.diff(snap.refs, refs);\n      const patchFlags = _runtimeFlags.diff(snap.flags, flags);\n      return core.exitSucceed(core.blocked(op.effect_instruction_i0, core.withFiberRuntime(newFiber => {\n        while (frames.length > 0) {\n          newFiber.pushStack(frames.pop());\n        }\n        newFiber.setFiberRefs(FiberRefsPatch.patch(newFiber.id(), newFiber.getFiberRefs())(patchRefs));\n        newFiber._runtimeFlags = _runtimeFlags.patch(patchFlags)(newFiber._runtimeFlags);\n        return op.effect_instruction_i1;\n      })));\n    }\n    return core.uninterruptibleMask(restore => core.flatMap(forkDaemon(core.runRequestBlock(op.effect_instruction_i0)), () => restore(op.effect_instruction_i1)));\n  }\n  [\"RunBlocked\"](op) {\n    return runBlockedRequests(op.effect_instruction_i0);\n  }\n  [OpCodes.OP_UPDATE_RUNTIME_FLAGS](op) {\n    const updateFlags = op.effect_instruction_i0;\n    const oldRuntimeFlags = this._runtimeFlags;\n    const newRuntimeFlags = _runtimeFlags.patch(oldRuntimeFlags, updateFlags);\n    // One more chance to short circuit: if we're immediately going\n    // to interrupt. Interruption will cause immediate reversion of\n    // the flag, so as long as we \"peek ahead\", there's no need to\n    // set them to begin with.\n    if (_runtimeFlags.interruptible(newRuntimeFlags) && this.isInterrupted()) {\n      return core.exitFailCause(this.getInterruptedCause());\n    } else {\n      // Impossible to short circuit, so record the changes\n      this.patchRuntimeFlags(this._runtimeFlags, updateFlags);\n      if (op.effect_instruction_i1) {\n        // Since we updated the flags, we need to revert them\n        const revertFlags = _runtimeFlags.diff(newRuntimeFlags, oldRuntimeFlags);\n        this.pushStack(new core.RevertFlags(revertFlags, op));\n        return internalCall(() => op.effect_instruction_i1(oldRuntimeFlags));\n      } else {\n        return core.exitVoid;\n      }\n    }\n  }\n  [OpCodes.OP_ON_SUCCESS](op) {\n    this.pushStack(op);\n    return op.effect_instruction_i0;\n  }\n  [\"OnStep\"](op) {\n    this.pushStack(op);\n    return op.effect_instruction_i0;\n  }\n  [OpCodes.OP_ON_FAILURE](op) {\n    this.pushStack(op);\n    return op.effect_instruction_i0;\n  }\n  [OpCodes.OP_ON_SUCCESS_AND_FAILURE](op) {\n    this.pushStack(op);\n    return op.effect_instruction_i0;\n  }\n  [OpCodes.OP_ASYNC](op) {\n    this._asyncBlockingOn = op.effect_instruction_i1;\n    this.initiateAsync(this._runtimeFlags, op.effect_instruction_i0);\n    yieldedOpChannel.currentOp = op;\n    return YieldedOp;\n  }\n  [OpCodes.OP_YIELD](op) {\n    this.isYielding = false;\n    yieldedOpChannel.currentOp = op;\n    return YieldedOp;\n  }\n  [OpCodes.OP_WHILE](op) {\n    const check = op.effect_instruction_i0;\n    const body = op.effect_instruction_i1;\n    if (check()) {\n      this.pushStack(op);\n      return body();\n    } else {\n      return core.exitVoid;\n    }\n  }\n  [OpCodes.OP_COMMIT](op) {\n    return internalCall(() => op.commit());\n  }\n  /**\n   * The main run-loop for evaluating effects.\n   *\n   * **NOTE**: This method must be invoked by the fiber itself.\n   */\n  runLoop(effect0) {\n    let cur = effect0;\n    this.currentOpCount = 0;\n    // eslint-disable-next-line no-constant-condition\n    while (true) {\n      if ((this._runtimeFlags & OpSupervision) !== 0) {\n        this._supervisor.onEffect(this, cur);\n      }\n      if (this._queue.length > 0) {\n        cur = this.drainQueueWhileRunning(this._runtimeFlags, cur);\n      }\n      if (!this.isYielding) {\n        this.currentOpCount += 1;\n        const shouldYield = this._scheduler.shouldYield(this);\n        if (shouldYield !== false) {\n          this.isYielding = true;\n          this.currentOpCount = 0;\n          const oldCur = cur;\n          cur = core.flatMap(core.yieldNow({\n            priority: shouldYield\n          }), () => oldCur);\n        }\n      }\n      try {\n        if (!(\"_op\" in cur) || !(cur._op in this)) {\n          // @ts-expect-error\n          absurd(cur);\n        }\n        // @ts-expect-error\n        cur = this._tracer.context(() => {\n          if (version.getCurrentVersion() !== cur[EffectTypeId]._V) {\n            return core.dieMessage(`Cannot execute an Effect versioned ${cur[EffectTypeId]._V} with a Runtime of version ${version.getCurrentVersion()}`);\n          }\n          // @ts-expect-error\n          return this[cur._op](cur);\n        }, this);\n        if (cur === YieldedOp) {\n          const op = yieldedOpChannel.currentOp;\n          if (op._op === OpCodes.OP_YIELD || op._op === OpCodes.OP_ASYNC) {\n            return YieldedOp;\n          }\n          yieldedOpChannel.currentOp = null;\n          return op._op === OpCodes.OP_SUCCESS || op._op === OpCodes.OP_FAILURE ? op : core.exitFailCause(internalCause.die(op));\n        }\n      } catch (e) {\n        if (core.isEffectError(e)) {\n          cur = core.exitFailCause(e.cause);\n        } else if (core.isInterruptedException(e)) {\n          cur = core.exitFailCause(internalCause.sequential(internalCause.die(e), internalCause.interrupt(FiberId.none)));\n        } else {\n          cur = core.die(e);\n        }\n      }\n    }\n  }\n  run = () => {\n    this.drainQueueOnCurrentThread();\n  };\n}\n// circular with Logger\n/** @internal */\nexport const currentMinimumLogLevel = /*#__PURE__*/globalValue(\"effect/FiberRef/currentMinimumLogLevel\", () => core.fiberRefUnsafeMake(LogLevel.fromLiteral(\"Info\")));\n/** @internal */\nexport const loggerWithConsoleLog = self => internalLogger.makeLogger(opts => {\n  const services = FiberRefs.getOrDefault(opts.context, defaultServices.currentServices);\n  Context.get(services, consoleTag).unsafe.log(self.log(opts));\n});\n/** @internal */\nexport const loggerWithConsoleError = self => internalLogger.makeLogger(opts => {\n  const services = FiberRefs.getOrDefault(opts.context, defaultServices.currentServices);\n  Context.get(services, consoleTag).unsafe.error(self.log(opts));\n});\n/** @internal */\nexport const defaultLogger = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Logger/defaultLogger\"), () => loggerWithConsoleLog(internalLogger.stringLogger));\n/** @internal */\nexport const jsonLogger = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Logger/jsonLogger\"), () => loggerWithConsoleLog(internalLogger.jsonLogger));\n/** @internal */\nexport const logFmtLogger = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Logger/logFmtLogger\"), () => loggerWithConsoleLog(internalLogger.logfmtLogger));\n/** @internal */\nexport const prettyLogger = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Logger/prettyLogger\"), () => internalLogger.prettyLogger());\n/** @internal */\nexport const structuredLogger = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Logger/structuredLogger\"), () => loggerWithConsoleLog(internalLogger.structuredLogger));\n/** @internal */\nexport const tracerLogger = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Logger/tracerLogger\"), () => internalLogger.makeLogger(({\n  annotations,\n  cause,\n  context,\n  fiberId,\n  logLevel,\n  message\n}) => {\n  const span = Option.flatMap(fiberRefs.get(context, core.currentContext), Context.getOption(tracer.spanTag));\n  const clockService = Option.map(fiberRefs.get(context, defaultServices.currentServices), _ => Context.get(_, clock.clockTag));\n  if (span._tag === \"None\" || span.value._tag === \"ExternalSpan\" || clockService._tag === \"None\") {\n    return;\n  }\n  const attributes = Object.fromEntries(HashMap.map(annotations, Inspectable.toStringUnknown));\n  attributes[\"effect.fiberId\"] = FiberId.threadName(fiberId);\n  attributes[\"effect.logLevel\"] = logLevel.label;\n  if (cause !== null && cause._tag !== \"Empty\") {\n    attributes[\"effect.cause\"] = internalCause.pretty(cause);\n  }\n  span.value.event(String(message), clockService.value.unsafeCurrentTimeNanos(), attributes);\n}));\n/** @internal */\nexport const loggerWithSpanAnnotations = self => internalLogger.mapInputOptions(self, options => {\n  const span = Option.flatMap(fiberRefs.get(options.context, core.currentContext), Context.getOption(tracer.spanTag));\n  if (span._tag === \"None\") {\n    return options;\n  }\n  return {\n    ...options,\n    annotations: pipe(options.annotations, HashMap.set(\"effect.traceId\", span.value.traceId), HashMap.set(\"effect.spanId\", span.value.spanId), span.value._tag === \"Span\" ? HashMap.set(\"effect.spanName\", span.value.name) : identity)\n  };\n});\n/** @internal */\nexport const currentLoggers = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentLoggers\"), () => core.fiberRefUnsafeMakeHashSet(HashSet.make(defaultLogger, tracerLogger)));\n/** @internal */\nexport const batchedLogger = /*#__PURE__*/dual(3, (self, window, f) => core.flatMap(scope, scope => {\n  let buffer = [];\n  const flush = core.suspend(() => {\n    if (buffer.length === 0) {\n      return core.void;\n    }\n    const arr = buffer;\n    buffer = [];\n    return f(arr);\n  });\n  return core.uninterruptibleMask(restore => pipe(internalEffect.sleep(window), core.zipRight(flush), internalEffect.forever, restore, forkDaemon, core.flatMap(fiber => core.scopeAddFinalizer(scope, core.interruptFiber(fiber))), core.zipRight(addFinalizer(() => flush)), core.as(internalLogger.makeLogger(options => {\n    buffer.push(self.log(options));\n  }))));\n}));\nexport const annotateLogsScoped = function () {\n  if (typeof arguments[0] === \"string\") {\n    return fiberRefLocallyScopedWith(core.currentLogAnnotations, HashMap.set(arguments[0], arguments[1]));\n  }\n  const entries = Object.entries(arguments[0]);\n  return fiberRefLocallyScopedWith(core.currentLogAnnotations, HashMap.mutate(annotations => {\n    for (let i = 0; i < entries.length; i++) {\n      const [key, value] = entries[i];\n      HashMap.set(annotations, key, value);\n    }\n    return annotations;\n  }));\n};\n// circular with Effect\n/* @internal */\nexport const acquireRelease = /*#__PURE__*/dual(args => core.isEffect(args[0]), (acquire, release) => core.uninterruptible(core.tap(acquire, a => addFinalizer(exit => release(a, exit)))));\n/* @internal */\nexport const acquireReleaseInterruptible = /*#__PURE__*/dual(args => core.isEffect(args[0]), (acquire, release) => ensuring(acquire, addFinalizer(exit => release(exit))));\n/* @internal */\nexport const addFinalizer = finalizer => core.withFiberRuntime(runtime => {\n  const acquireRefs = runtime.getFiberRefs();\n  const acquireFlags = runtime._runtimeFlags;\n  return core.flatMap(scope, scope => core.scopeAddFinalizerExit(scope, exit => core.withFiberRuntime(runtimeFinalizer => {\n    const preRefs = runtimeFinalizer.getFiberRefs();\n    const preFlags = runtimeFinalizer._runtimeFlags;\n    const patchRefs = FiberRefsPatch.diff(preRefs, acquireRefs);\n    const patchFlags = _runtimeFlags.diff(preFlags, acquireFlags);\n    const inverseRefs = FiberRefsPatch.diff(acquireRefs, preRefs);\n    runtimeFinalizer.setFiberRefs(FiberRefsPatch.patch(patchRefs, runtimeFinalizer.id(), acquireRefs));\n    return ensuring(core.withRuntimeFlags(finalizer(exit), patchFlags), core.sync(() => {\n      runtimeFinalizer.setFiberRefs(FiberRefsPatch.patch(inverseRefs, runtimeFinalizer.id(), runtimeFinalizer.getFiberRefs()));\n    }));\n  })));\n});\n/* @internal */\nexport const daemonChildren = self => {\n  const forkScope = core.fiberRefLocally(core.currentForkScopeOverride, Option.some(fiberScope.globalScope));\n  return forkScope(self);\n};\n/** @internal */\nconst _existsParFound = /*#__PURE__*/Symbol.for(\"effect/Effect/existsPar/found\");\n/* @internal */\nexport const exists = /*#__PURE__*/dual(args => Predicate.isIterable(args[0]) && !core.isEffect(args[0]), (elements, f, options) => concurrency.matchSimple(options?.concurrency, () => core.suspend(() => existsLoop(elements[Symbol.iterator](), 0, f)), () => core.matchEffect(forEach(elements, (a, i) => core.if_(f(a, i), {\n  onTrue: () => core.fail(_existsParFound),\n  onFalse: () => core.void\n}), options), {\n  onFailure: e => e === _existsParFound ? core.succeed(true) : core.fail(e),\n  onSuccess: () => core.succeed(false)\n})));\nconst existsLoop = (iterator, index, f) => {\n  const next = iterator.next();\n  if (next.done) {\n    return core.succeed(false);\n  }\n  return pipe(core.flatMap(f(next.value, index), b => b ? core.succeed(b) : existsLoop(iterator, index + 1, f)));\n};\n/* @internal */\nexport const filter = /*#__PURE__*/dual(args => Predicate.isIterable(args[0]) && !core.isEffect(args[0]), (elements, f, options) => {\n  const predicate = options?.negate ? (a, i) => core.map(f(a, i), Boolean.not) : f;\n  return concurrency.matchSimple(options?.concurrency, () => core.suspend(() => RA.fromIterable(elements).reduceRight((effect, a, i) => core.zipWith(effect, core.suspend(() => predicate(a, i)), (list, b) => b ? [a, ...list] : list), core.sync(() => new Array()))), () => core.map(forEach(elements, (a, i) => core.map(predicate(a, i), b => b ? Option.some(a) : Option.none()), options), RA.getSomes));\n});\n// === all\nconst allResolveInput = input => {\n  if (Array.isArray(input) || Predicate.isIterable(input)) {\n    return [input, Option.none()];\n  }\n  const keys = Object.keys(input);\n  const size = keys.length;\n  return [keys.map(k => input[k]), Option.some(values => {\n    const res = {};\n    for (let i = 0; i < size; i++) {\n      ;\n      res[keys[i]] = values[i];\n    }\n    return res;\n  })];\n};\nconst allValidate = (effects, reconcile, options) => {\n  const eitherEffects = [];\n  for (const effect of effects) {\n    eitherEffects.push(core.either(effect));\n  }\n  return core.flatMap(forEach(eitherEffects, identity, {\n    concurrency: options?.concurrency,\n    batching: options?.batching\n  }), eithers => {\n    const none = Option.none();\n    const size = eithers.length;\n    const errors = new Array(size);\n    const successes = new Array(size);\n    let errored = false;\n    for (let i = 0; i < size; i++) {\n      const either = eithers[i];\n      if (either._tag === \"Left\") {\n        errors[i] = Option.some(either.left);\n        errored = true;\n      } else {\n        successes[i] = either.right;\n        errors[i] = none;\n      }\n    }\n    if (errored) {\n      return reconcile._tag === \"Some\" ? core.fail(reconcile.value(errors)) : core.fail(errors);\n    } else if (options?.discard) {\n      return core.void;\n    }\n    return reconcile._tag === \"Some\" ? core.succeed(reconcile.value(successes)) : core.succeed(successes);\n  });\n};\nconst allEither = (effects, reconcile, options) => {\n  const eitherEffects = [];\n  for (const effect of effects) {\n    eitherEffects.push(core.either(effect));\n  }\n  if (options?.discard) {\n    return forEach(eitherEffects, identity, {\n      concurrency: options?.concurrency,\n      batching: options?.batching,\n      discard: true\n    });\n  }\n  return core.map(forEach(eitherEffects, identity, {\n    concurrency: options?.concurrency,\n    batching: options?.batching\n  }), eithers => reconcile._tag === \"Some\" ? reconcile.value(eithers) : eithers);\n};\n/* @internal */\nexport const all = (arg, options) => {\n  const [effects, reconcile] = allResolveInput(arg);\n  if (options?.mode === \"validate\") {\n    return allValidate(effects, reconcile, options);\n  } else if (options?.mode === \"either\") {\n    return allEither(effects, reconcile, options);\n  }\n  return options?.discard !== true && reconcile._tag === \"Some\" ? core.map(forEach(effects, identity, options), reconcile.value) : forEach(effects, identity, options);\n};\n/* @internal */\nexport const allWith = options => arg => all(arg, options);\n/* @internal */\nexport const allSuccesses = (elements, options) => core.map(all(RA.fromIterable(elements).map(core.exit), options), RA.filterMap(exit => core.exitIsSuccess(exit) ? Option.some(exit.effect_instruction_i0) : Option.none()));\n/* @internal */\nexport const replicate = /*#__PURE__*/dual(2, (self, n) => Array.from({\n  length: n\n}, () => self));\n/* @internal */\nexport const replicateEffect = /*#__PURE__*/dual(args => core.isEffect(args[0]), (self, n, options) => all(replicate(self, n), options));\n/* @internal */\nexport const forEach = /*#__PURE__*/dual(args => Predicate.isIterable(args[0]), (self, f, options) => core.withFiberRuntime(r => {\n  const isRequestBatchingEnabled = options?.batching === true || options?.batching === \"inherit\" && r.getFiberRef(core.currentRequestBatching);\n  if (options?.discard) {\n    return concurrency.match(options.concurrency, () => finalizersMask(ExecutionStrategy.sequential)(restore => isRequestBatchingEnabled ? forEachConcurrentDiscard(self, (a, i) => restore(f(a, i)), true, false, 1) : core.forEachSequentialDiscard(self, (a, i) => restore(f(a, i)))), () => finalizersMask(ExecutionStrategy.parallel)(restore => forEachConcurrentDiscard(self, (a, i) => restore(f(a, i)), isRequestBatchingEnabled, false)), n => finalizersMask(ExecutionStrategy.parallelN(n))(restore => forEachConcurrentDiscard(self, (a, i) => restore(f(a, i)), isRequestBatchingEnabled, false, n)));\n  }\n  return concurrency.match(options?.concurrency, () => finalizersMask(ExecutionStrategy.sequential)(restore => isRequestBatchingEnabled ? forEachParN(self, 1, (a, i) => restore(f(a, i)), true) : core.forEachSequential(self, (a, i) => restore(f(a, i)))), () => finalizersMask(ExecutionStrategy.parallel)(restore => forEachParUnbounded(self, (a, i) => restore(f(a, i)), isRequestBatchingEnabled)), n => finalizersMask(ExecutionStrategy.parallelN(n))(restore => forEachParN(self, n, (a, i) => restore(f(a, i)), isRequestBatchingEnabled)));\n}));\n/* @internal */\nexport const forEachParUnbounded = (self, f, batching) => core.suspend(() => {\n  const as = RA.fromIterable(self);\n  const array = new Array(as.length);\n  const fn = (a, i) => core.flatMap(f(a, i), b => core.sync(() => array[i] = b));\n  return core.zipRight(forEachConcurrentDiscard(as, fn, batching, false), core.succeed(array));\n});\n/** @internal */\nexport const forEachConcurrentDiscard = (self, f, batching, processAll, n) => core.uninterruptibleMask(restore => core.transplant(graft => core.withFiberRuntime(parent => {\n  let todos = Array.from(self).reverse();\n  let target = todos.length;\n  if (target === 0) {\n    return core.void;\n  }\n  let counter = 0;\n  let interrupted = false;\n  const fibersCount = n ? Math.min(todos.length, n) : todos.length;\n  const fibers = new Set();\n  const results = new Array();\n  const interruptAll = () => fibers.forEach(fiber => {\n    fiber._scheduler.scheduleTask(() => {\n      fiber.unsafeInterruptAsFork(parent.id());\n    }, 0);\n  });\n  const startOrder = new Array();\n  const joinOrder = new Array();\n  const residual = new Array();\n  const collectExits = () => {\n    const exits = results.filter(({\n      exit\n    }) => exit._tag === \"Failure\").sort((a, b) => a.index < b.index ? -1 : a.index === b.index ? 0 : 1).map(({\n      exit\n    }) => exit);\n    if (exits.length === 0) {\n      exits.push(core.exitVoid);\n    }\n    return exits;\n  };\n  const runFiber = (eff, interruptImmediately = false) => {\n    const runnable = core.uninterruptible(graft(eff));\n    const fiber = unsafeForkUnstarted(runnable, parent, parent._runtimeFlags, fiberScope.globalScope);\n    parent._scheduler.scheduleTask(() => {\n      if (interruptImmediately) {\n        fiber.unsafeInterruptAsFork(parent.id());\n      }\n      fiber.resume(runnable);\n    }, 0);\n    return fiber;\n  };\n  const onInterruptSignal = () => {\n    if (!processAll) {\n      target -= todos.length;\n      todos = [];\n    }\n    interrupted = true;\n    interruptAll();\n  };\n  const stepOrExit = batching ? core.step : core.exit;\n  const processingFiber = runFiber(core.async(resume => {\n    const pushResult = (res, index) => {\n      if (res._op === \"Blocked\") {\n        residual.push(res);\n      } else {\n        results.push({\n          index,\n          exit: res\n        });\n        if (res._op === \"Failure\" && !interrupted) {\n          onInterruptSignal();\n        }\n      }\n    };\n    const next = () => {\n      if (todos.length > 0) {\n        const a = todos.pop();\n        let index = counter++;\n        const returnNextElement = () => {\n          const a = todos.pop();\n          index = counter++;\n          return core.flatMap(core.yieldNow(), () => core.flatMap(stepOrExit(restore(f(a, index))), onRes));\n        };\n        const onRes = res => {\n          if (todos.length > 0) {\n            pushResult(res, index);\n            if (todos.length > 0) {\n              return returnNextElement();\n            }\n          }\n          return core.succeed(res);\n        };\n        const todo = core.flatMap(stepOrExit(restore(f(a, index))), onRes);\n        const fiber = runFiber(todo);\n        startOrder.push(fiber);\n        fibers.add(fiber);\n        if (interrupted) {\n          fiber._scheduler.scheduleTask(() => {\n            fiber.unsafeInterruptAsFork(parent.id());\n          }, 0);\n        }\n        fiber.addObserver(wrapped => {\n          let exit;\n          if (wrapped._op === \"Failure\") {\n            exit = wrapped;\n          } else {\n            exit = wrapped.effect_instruction_i0;\n          }\n          joinOrder.push(fiber);\n          fibers.delete(fiber);\n          pushResult(exit, index);\n          if (results.length === target) {\n            resume(core.succeed(Option.getOrElse(core.exitCollectAll(collectExits(), {\n              parallel: true\n            }), () => core.exitVoid)));\n          } else if (residual.length + results.length === target) {\n            const requests = residual.map(blocked => blocked.effect_instruction_i0).reduce(_RequestBlock.par);\n            resume(core.succeed(core.blocked(requests, forEachConcurrentDiscard([Option.getOrElse(core.exitCollectAll(collectExits(), {\n              parallel: true\n            }), () => core.exitVoid), ...residual.map(blocked => blocked.effect_instruction_i1)], i => i, batching, true, n))));\n          } else {\n            next();\n          }\n        });\n      }\n    };\n    for (let i = 0; i < fibersCount; i++) {\n      next();\n    }\n  }));\n  return core.asVoid(core.onExit(core.flatten(restore(internalFiber.join(processingFiber))), core.exitMatch({\n    onFailure: () => {\n      onInterruptSignal();\n      const target = residual.length + 1;\n      const concurrency = Math.min(typeof n === \"number\" ? n : residual.length, residual.length);\n      const toPop = Array.from(residual);\n      return core.async(cb => {\n        const exits = [];\n        let count = 0;\n        let index = 0;\n        const check = (index, hitNext) => exit => {\n          exits[index] = exit;\n          count++;\n          if (count === target) {\n            cb(Option.getOrThrow(core.exitCollectAll(exits, {\n              parallel: true\n            })));\n          }\n          if (toPop.length > 0 && hitNext) {\n            next();\n          }\n        };\n        const next = () => {\n          runFiber(toPop.pop(), true).addObserver(check(index, true));\n          index++;\n        };\n        processingFiber.addObserver(check(index, false));\n        index++;\n        for (let i = 0; i < concurrency; i++) {\n          next();\n        }\n      });\n    },\n    onSuccess: () => core.forEachSequential(joinOrder, f => f.inheritAll)\n  })));\n})));\n/* @internal */\nexport const forEachParN = (self, n, f, batching) => core.suspend(() => {\n  const as = RA.fromIterable(self);\n  const array = new Array(as.length);\n  const fn = (a, i) => core.map(f(a, i), b => array[i] = b);\n  return core.zipRight(forEachConcurrentDiscard(as, fn, batching, false, n), core.succeed(array));\n});\n/* @internal */\nexport const fork = self => core.withFiberRuntime((state, status) => core.succeed(unsafeFork(self, state, status.runtimeFlags)));\n/* @internal */\nexport const forkDaemon = self => forkWithScopeOverride(self, fiberScope.globalScope);\n/* @internal */\nexport const forkWithErrorHandler = /*#__PURE__*/dual(2, (self, handler) => fork(core.onError(self, cause => {\n  const either = internalCause.failureOrCause(cause);\n  switch (either._tag) {\n    case \"Left\":\n      return handler(either.left);\n    case \"Right\":\n      return core.failCause(either.right);\n  }\n})));\n/** @internal */\nexport const unsafeFork = (effect, parentFiber, parentRuntimeFlags, overrideScope = null) => {\n  const childFiber = unsafeMakeChildFiber(effect, parentFiber, parentRuntimeFlags, overrideScope);\n  childFiber.resume(effect);\n  return childFiber;\n};\n/** @internal */\nexport const unsafeForkUnstarted = (effect, parentFiber, parentRuntimeFlags, overrideScope = null) => {\n  const childFiber = unsafeMakeChildFiber(effect, parentFiber, parentRuntimeFlags, overrideScope);\n  return childFiber;\n};\n/** @internal */\nexport const unsafeMakeChildFiber = (effect, parentFiber, parentRuntimeFlags, overrideScope = null) => {\n  const childId = FiberId.unsafeMake();\n  const parentFiberRefs = parentFiber.getFiberRefs();\n  const childFiberRefs = fiberRefs.forkAs(parentFiberRefs, childId);\n  const childFiber = new FiberRuntime(childId, childFiberRefs, parentRuntimeFlags);\n  const childContext = fiberRefs.getOrDefault(childFiberRefs, core.currentContext);\n  const supervisor = childFiber._supervisor;\n  supervisor.onStart(childContext, effect, Option.some(parentFiber), childFiber);\n  childFiber.addObserver(exit => supervisor.onEnd(exit, childFiber));\n  const parentScope = overrideScope !== null ? overrideScope : pipe(parentFiber.getFiberRef(core.currentForkScopeOverride), Option.getOrElse(() => parentFiber.scope()));\n  parentScope.add(parentRuntimeFlags, childFiber);\n  return childFiber;\n};\n/* @internal */\nconst forkWithScopeOverride = (self, scopeOverride) => core.withFiberRuntime((parentFiber, parentStatus) => core.succeed(unsafeFork(self, parentFiber, parentStatus.runtimeFlags, scopeOverride)));\n/* @internal */\nexport const mergeAll = /*#__PURE__*/dual(args => Predicate.isFunction(args[2]), (elements, zero, f, options) => concurrency.matchSimple(options?.concurrency, () => RA.fromIterable(elements).reduce((acc, a, i) => core.zipWith(acc, a, (acc, a) => f(acc, a, i)), core.succeed(zero)), () => core.flatMap(Ref.make(zero), acc => core.flatMap(forEach(elements, (effect, i) => core.flatMap(effect, a => Ref.update(acc, b => f(b, a, i))), options), () => Ref.get(acc)))));\n/* @internal */\nexport const partition = /*#__PURE__*/dual(args => Predicate.isIterable(args[0]), (elements, f, options) => pipe(forEach(elements, (a, i) => core.either(f(a, i)), options), core.map(chunk => core.partitionMap(chunk, identity))));\n/* @internal */\nexport const validateAll = /*#__PURE__*/dual(args => Predicate.isIterable(args[0]), (elements, f, options) => core.flatMap(partition(elements, f, {\n  concurrency: options?.concurrency,\n  batching: options?.batching\n}), ([es, bs]) => es.length === 0 ? options?.discard ? core.void : core.succeed(bs) : core.fail(es)));\n/* @internal */\nexport const raceAll = all => {\n  const list = Chunk.fromIterable(all);\n  if (!Chunk.isNonEmpty(list)) {\n    return core.dieSync(() => new core.IllegalArgumentException(`Received an empty collection of effects`));\n  }\n  const self = Chunk.headNonEmpty(list);\n  const effects = Chunk.tailNonEmpty(list);\n  const inheritAll = res => pipe(internalFiber.inheritAll(res[1]), core.as(res[0]));\n  return pipe(core.deferredMake(), core.flatMap(done => pipe(Ref.make(effects.length), core.flatMap(fails => core.uninterruptibleMask(restore => pipe(fork(core.interruptible(self)), core.flatMap(head => pipe(effects, core.forEachSequential(effect => fork(core.interruptible(effect))), core.map(fibers => Chunk.unsafeFromArray(fibers)), core.map(tail => pipe(tail, Chunk.prepend(head))), core.tap(fibers => pipe(fibers, RA.reduce(core.void, (effect, fiber) => pipe(effect, core.zipRight(pipe(internalFiber._await(fiber), core.flatMap(raceAllArbiter(fibers, fiber, done, fails)), fork, core.asVoid)))))), core.flatMap(fibers => pipe(restore(pipe(Deferred.await(done), core.flatMap(inheritAll))), core.onInterrupt(() => pipe(fibers, RA.reduce(core.void, (effect, fiber) => pipe(effect, core.zipLeft(core.interruptFiber(fiber))))))))))))))));\n};\nconst raceAllArbiter = (fibers, winner, deferred, fails) => exit => core.exitMatchEffect(exit, {\n  onFailure: cause => pipe(Ref.modify(fails, fails => [fails === 0 ? pipe(core.deferredFailCause(deferred, cause), core.asVoid) : core.void, fails - 1]), core.flatten),\n  onSuccess: value => pipe(core.deferredSucceed(deferred, [value, winner]), core.flatMap(set => set ? pipe(Chunk.fromIterable(fibers), RA.reduce(core.void, (effect, fiber) => fiber === winner ? effect : pipe(effect, core.zipLeft(core.interruptFiber(fiber))))) : core.void))\n});\n/* @internal */\nexport const reduceEffect = /*#__PURE__*/dual(args => Predicate.isIterable(args[0]) && !core.isEffect(args[0]), (elements, zero, f, options) => concurrency.matchSimple(options?.concurrency, () => RA.fromIterable(elements).reduce((acc, a, i) => core.zipWith(acc, a, (acc, a) => f(acc, a, i)), zero), () => core.suspend(() => pipe(mergeAll([zero, ...elements], Option.none(), (acc, elem, i) => {\n  switch (acc._tag) {\n    case \"None\":\n      {\n        return Option.some(elem);\n      }\n    case \"Some\":\n      {\n        return Option.some(f(acc.value, elem, i));\n      }\n  }\n}, options), core.map(option => {\n  switch (option._tag) {\n    case \"None\":\n      {\n        throw new Error(\"BUG: Effect.reduceEffect - please report an issue at https://github.com/Effect-TS/effect/issues\");\n      }\n    case \"Some\":\n      {\n        return option.value;\n      }\n  }\n})))));\n/* @internal */\nexport const parallelFinalizers = self => core.contextWithEffect(context => Option.match(Context.getOption(context, scopeTag), {\n  onNone: () => self,\n  onSome: scope => {\n    switch (scope.strategy._tag) {\n      case \"Parallel\":\n        return self;\n      case \"Sequential\":\n      case \"ParallelN\":\n        return core.flatMap(core.scopeFork(scope, ExecutionStrategy.parallel), inner => scopeExtend(self, inner));\n    }\n  }\n}));\n/* @internal */\nexport const parallelNFinalizers = parallelism => self => core.contextWithEffect(context => Option.match(Context.getOption(context, scopeTag), {\n  onNone: () => self,\n  onSome: scope => {\n    if (scope.strategy._tag === \"ParallelN\" && scope.strategy.parallelism === parallelism) {\n      return self;\n    }\n    return core.flatMap(core.scopeFork(scope, ExecutionStrategy.parallelN(parallelism)), inner => scopeExtend(self, inner));\n  }\n}));\n/* @internal */\nexport const finalizersMask = strategy => self => core.contextWithEffect(context => Option.match(Context.getOption(context, scopeTag), {\n  onNone: () => self(identity),\n  onSome: scope => {\n    const patch = strategy._tag === \"Parallel\" ? parallelFinalizers : strategy._tag === \"Sequential\" ? sequentialFinalizers : parallelNFinalizers(strategy.parallelism);\n    switch (scope.strategy._tag) {\n      case \"Parallel\":\n        return patch(self(parallelFinalizers));\n      case \"Sequential\":\n        return patch(self(sequentialFinalizers));\n      case \"ParallelN\":\n        return patch(self(parallelNFinalizers(scope.strategy.parallelism)));\n    }\n  }\n}));\n/* @internal */\nexport const scopeWith = f => core.flatMap(scopeTag, f);\n/* @internal */\nexport const scopedEffect = effect => core.flatMap(scopeMake(), scope => scopeUse(effect, scope));\n/* @internal */\nexport const sequentialFinalizers = self => core.contextWithEffect(context => Option.match(Context.getOption(context, scopeTag), {\n  onNone: () => self,\n  onSome: scope => {\n    switch (scope.strategy._tag) {\n      case \"Sequential\":\n        return self;\n      case \"Parallel\":\n      case \"ParallelN\":\n        return core.flatMap(core.scopeFork(scope, ExecutionStrategy.sequential), inner => scopeExtend(self, inner));\n    }\n  }\n}));\n/* @internal */\nexport const tagMetricsScoped = (key, value) => labelMetricsScoped([metricLabel.make(key, value)]);\n/* @internal */\nexport const labelMetricsScoped = labels => fiberRefLocallyScopedWith(core.currentMetricLabels, old => RA.union(old, labels));\n/* @internal */\nexport const using = /*#__PURE__*/dual(2, (self, use) => core.acquireUseRelease(scopeMake(), scope => core.flatMap(scopeExtend(self, scope), use), (scope, exit) => core.scopeClose(scope, exit)));\n/** @internal */\nexport const validate = /*#__PURE__*/dual(args => core.isEffect(args[1]), (self, that, options) => validateWith(self, that, (a, b) => [a, b], options));\n/** @internal */\nexport const validateWith = /*#__PURE__*/dual(args => core.isEffect(args[1]), (self, that, f, options) => core.flatten(zipWithOptions(core.exit(self), core.exit(that), (ea, eb) => core.exitZipWith(ea, eb, {\n  onSuccess: f,\n  onFailure: (ca, cb) => options?.concurrent ? internalCause.parallel(ca, cb) : internalCause.sequential(ca, cb)\n}), options)));\n/* @internal */\nexport const validateAllPar = /*#__PURE__*/dual(2, (elements, f) => core.flatMap(partition(elements, f), ([es, bs]) => es.length === 0 ? core.succeed(bs) : core.fail(es)));\n/* @internal */\nexport const validateAllParDiscard = /*#__PURE__*/dual(2, (elements, f) => core.flatMap(partition(elements, f), ([es, _]) => es.length === 0 ? core.void : core.fail(es)));\n/* @internal */\nexport const validateFirst = /*#__PURE__*/dual(args => Predicate.isIterable(args[0]), (elements, f, options) => core.flip(forEach(elements, (a, i) => core.flip(f(a, i)), options)));\n/* @internal */\nexport const withClockScoped = value => fiberRefLocallyScopedWith(defaultServices.currentServices, Context.add(clock.clockTag, value));\n/* @internal */\nexport const withRandomScoped = value => fiberRefLocallyScopedWith(defaultServices.currentServices, Context.add(randomTag, value));\n/* @internal */\nexport const withConfigProviderScoped = value => fiberRefLocallyScopedWith(defaultServices.currentServices, Context.add(configProviderTag, value));\n/* @internal */\nexport const withEarlyRelease = self => scopeWith(parent => core.flatMap(core.scopeFork(parent, executionStrategy.sequential), child => pipe(self, scopeExtend(child), core.map(value => [core.fiberIdWith(fiberId => core.scopeClose(child, core.exitInterrupt(fiberId))), value]))));\n/** @internal */\nexport const zipOptions = /*#__PURE__*/dual(args => core.isEffect(args[1]), (self, that, options) => zipWithOptions(self, that, (a, b) => [a, b], options));\n/** @internal */\nexport const zipLeftOptions = /*#__PURE__*/dual(args => core.isEffect(args[1]), (self, that, options) => {\n  if (options?.concurrent !== true && (options?.batching === undefined || options.batching === false)) {\n    return core.zipLeft(self, that);\n  }\n  return zipWithOptions(self, that, (a, _) => a, options);\n});\n/** @internal */\nexport const zipRightOptions = /*#__PURE__*/dual(args => core.isEffect(args[1]), (self, that, options) => {\n  if (options?.concurrent !== true && (options?.batching === undefined || options.batching === false)) {\n    return core.zipRight(self, that);\n  }\n  return zipWithOptions(self, that, (_, b) => b, options);\n});\n/** @internal */\nexport const zipWithOptions = /*#__PURE__*/dual(args => core.isEffect(args[1]), (self, that, f, options) => core.map(all([self, that], {\n  concurrency: options?.concurrent ? 2 : 1,\n  batching: options?.batching\n}), ([a, a2]) => f(a, a2)));\n/* @internal */\nexport const withRuntimeFlagsScoped = update => {\n  if (update === RuntimeFlagsPatch.empty) {\n    return core.void;\n  }\n  return pipe(core.runtimeFlags, core.flatMap(runtimeFlags => {\n    const updatedRuntimeFlags = _runtimeFlags.patch(runtimeFlags, update);\n    const revertRuntimeFlags = _runtimeFlags.diff(updatedRuntimeFlags, runtimeFlags);\n    return pipe(core.updateRuntimeFlags(update), core.zipRight(addFinalizer(() => core.updateRuntimeFlags(revertRuntimeFlags))), core.asVoid);\n  }), core.uninterruptible);\n};\n// circular with Scope\n/** @internal */\nexport const scopeTag = /*#__PURE__*/Context.GenericTag(\"effect/Scope\");\n/* @internal */\nexport const scope = scopeTag;\nconst scopeUnsafeAddFinalizer = (scope, fin) => {\n  if (scope.state._tag === \"Open\") {\n    scope.state.finalizers.add(fin);\n  }\n};\nconst ScopeImplProto = {\n  [core.ScopeTypeId]: core.ScopeTypeId,\n  [core.CloseableScopeTypeId]: core.CloseableScopeTypeId,\n  pipe() {\n    return pipeArguments(this, arguments);\n  },\n  fork(strategy) {\n    return core.sync(() => {\n      const newScope = scopeUnsafeMake(strategy);\n      if (this.state._tag === \"Closed\") {\n        newScope.state = this.state;\n        return newScope;\n      }\n      const fin = exit => newScope.close(exit);\n      this.state.finalizers.add(fin);\n      scopeUnsafeAddFinalizer(newScope, _ => core.sync(() => {\n        if (this.state._tag === \"Open\") {\n          this.state.finalizers.delete(fin);\n        }\n      }));\n      return newScope;\n    });\n  },\n  close(exit) {\n    return core.suspend(() => {\n      if (this.state._tag === \"Closed\") {\n        return core.void;\n      }\n      const finalizers = Array.from(this.state.finalizers.values()).reverse();\n      this.state = {\n        _tag: \"Closed\",\n        exit\n      };\n      if (finalizers.length === 0) {\n        return core.void;\n      }\n      return executionStrategy.isSequential(this.strategy) ? pipe(core.forEachSequential(finalizers, fin => core.exit(fin(exit))), core.flatMap(results => pipe(core.exitCollectAll(results), Option.map(core.exitAsVoid), Option.getOrElse(() => core.exitVoid)))) : executionStrategy.isParallel(this.strategy) ? pipe(forEachParUnbounded(finalizers, fin => core.exit(fin(exit)), false), core.flatMap(results => pipe(core.exitCollectAll(results, {\n        parallel: true\n      }), Option.map(core.exitAsVoid), Option.getOrElse(() => core.exitVoid)))) : pipe(forEachParN(finalizers, this.strategy.parallelism, fin => core.exit(fin(exit)), false), core.flatMap(results => pipe(core.exitCollectAll(results, {\n        parallel: true\n      }), Option.map(core.exitAsVoid), Option.getOrElse(() => core.exitVoid))));\n    });\n  },\n  addFinalizer(fin) {\n    return core.suspend(() => {\n      if (this.state._tag === \"Closed\") {\n        return fin(this.state.exit);\n      }\n      this.state.finalizers.add(fin);\n      return core.void;\n    });\n  }\n};\nconst scopeUnsafeMake = (strategy = executionStrategy.sequential) => {\n  const scope = Object.create(ScopeImplProto);\n  scope.strategy = strategy;\n  scope.state = {\n    _tag: \"Open\",\n    finalizers: new Set()\n  };\n  return scope;\n};\n/* @internal */\nexport const scopeMake = (strategy = executionStrategy.sequential) => core.sync(() => scopeUnsafeMake(strategy));\n/* @internal */\nexport const scopeExtend = /*#__PURE__*/dual(2, (effect, scope) => core.mapInputContext(effect,\n// @ts-expect-error\nContext.merge(Context.make(scopeTag, scope))));\n/* @internal */\nexport const scopeUse = /*#__PURE__*/dual(2, (effect, scope) => pipe(effect, scopeExtend(scope), core.onExit(exit => scope.close(exit))));\n// circular with Supervisor\n/** @internal */\nexport const fiberRefUnsafeMakeSupervisor = initial => core.fiberRefUnsafeMakePatch(initial, {\n  differ: SupervisorPatch.differ,\n  fork: SupervisorPatch.empty\n});\n// circular with FiberRef\n/* @internal */\nexport const fiberRefLocallyScoped = /*#__PURE__*/dual(2, (self, value) => core.asVoid(acquireRelease(core.flatMap(core.fiberRefGet(self), oldValue => core.as(core.fiberRefSet(self, value), oldValue)), oldValue => core.fiberRefSet(self, oldValue))));\n/* @internal */\nexport const fiberRefLocallyScopedWith = /*#__PURE__*/dual(2, (self, f) => core.fiberRefGetWith(self, a => fiberRefLocallyScoped(self, f(a))));\n/* @internal */\nexport const fiberRefMake = (initial, options) => fiberRefMakeWith(() => core.fiberRefUnsafeMake(initial, options));\n/* @internal */\nexport const fiberRefMakeWith = ref => acquireRelease(core.tap(core.sync(ref), ref => core.fiberRefUpdate(ref, identity)), fiberRef => core.fiberRefDelete(fiberRef));\n/* @internal */\nexport const fiberRefMakeContext = initial => fiberRefMakeWith(() => core.fiberRefUnsafeMakeContext(initial));\n/* @internal */\nexport const fiberRefMakeRuntimeFlags = initial => fiberRefMakeWith(() => core.fiberRefUnsafeMakeRuntimeFlags(initial));\n/** @internal */\nexport const currentRuntimeFlags = /*#__PURE__*/core.fiberRefUnsafeMakeRuntimeFlags(_runtimeFlags.none);\n/** @internal */\nexport const currentSupervisor = /*#__PURE__*/fiberRefUnsafeMakeSupervisor(supervisor.none);\n// circular with Fiber\n/* @internal */\nexport const fiberAwaitAll = fibers => core.asVoid(internalFiber._await(fiberAll(fibers)));\n/** @internal */\nexport const fiberAll = fibers => ({\n  [internalFiber.FiberTypeId]: internalFiber.fiberVariance,\n  id: () => RA.fromIterable(fibers).reduce((id, fiber) => FiberId.combine(id, fiber.id()), FiberId.none),\n  await: core.exit(forEachParUnbounded(fibers, fiber => core.flatten(fiber.await), false)),\n  children: core.map(forEachParUnbounded(fibers, fiber => fiber.children, false), RA.flatten),\n  inheritAll: core.forEachSequentialDiscard(fibers, fiber => fiber.inheritAll),\n  poll: core.map(core.forEachSequential(fibers, fiber => fiber.poll), RA.reduceRight(Option.some(core.exitSucceed(new Array())), (optionB, optionA) => {\n    switch (optionA._tag) {\n      case \"None\":\n        {\n          return Option.none();\n        }\n      case \"Some\":\n        {\n          switch (optionB._tag) {\n            case \"None\":\n              {\n                return Option.none();\n              }\n            case \"Some\":\n              {\n                return Option.some(core.exitZipWith(optionA.value, optionB.value, {\n                  onSuccess: (a, chunk) => [a, ...chunk],\n                  onFailure: internalCause.parallel\n                }));\n              }\n          }\n        }\n    }\n  })),\n  interruptAsFork: fiberId => core.forEachSequentialDiscard(fibers, fiber => fiber.interruptAsFork(fiberId)),\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n});\n/* @internal */\nexport const fiberInterruptFork = self => core.asVoid(forkDaemon(core.interruptFiber(self)));\n/* @internal */\nexport const fiberJoinAll = fibers => internalFiber.join(fiberAll(fibers));\n/* @internal */\nexport const fiberScoped = self => acquireRelease(core.succeed(self), core.interruptFiber);\n//\n// circular race\n//\n/** @internal */\nexport const raceWith = /*#__PURE__*/dual(3, (self, other, options) => raceFibersWith(self, other, {\n  onSelfWin: (winner, loser) => core.flatMap(winner.await, exit => {\n    switch (exit._tag) {\n      case OpCodes.OP_SUCCESS:\n        {\n          return core.flatMap(winner.inheritAll, () => options.onSelfDone(exit, loser));\n        }\n      case OpCodes.OP_FAILURE:\n        {\n          return options.onSelfDone(exit, loser);\n        }\n    }\n  }),\n  onOtherWin: (winner, loser) => core.flatMap(winner.await, exit => {\n    switch (exit._tag) {\n      case OpCodes.OP_SUCCESS:\n        {\n          return core.flatMap(winner.inheritAll, () => options.onOtherDone(exit, loser));\n        }\n      case OpCodes.OP_FAILURE:\n        {\n          return options.onOtherDone(exit, loser);\n        }\n    }\n  })\n}));\n/** @internal */\nexport const disconnect = self => core.uninterruptibleMask(restore => core.fiberIdWith(fiberId => core.flatMap(forkDaemon(restore(self)), fiber => pipe(restore(internalFiber.join(fiber)), core.onInterrupt(() => pipe(fiber, internalFiber.interruptAsFork(fiberId)))))));\n/** @internal */\nexport const race = /*#__PURE__*/dual(2, (self, that) => core.fiberIdWith(parentFiberId => raceWith(self, that, {\n  onSelfDone: (exit, right) => core.exitMatchEffect(exit, {\n    onFailure: cause => pipe(internalFiber.join(right), internalEffect.mapErrorCause(cause2 => internalCause.parallel(cause, cause2))),\n    onSuccess: value => pipe(right, core.interruptAsFiber(parentFiberId), core.as(value))\n  }),\n  onOtherDone: (exit, left) => core.exitMatchEffect(exit, {\n    onFailure: cause => pipe(internalFiber.join(left), internalEffect.mapErrorCause(cause2 => internalCause.parallel(cause2, cause))),\n    onSuccess: value => pipe(left, core.interruptAsFiber(parentFiberId), core.as(value))\n  })\n})));\n/** @internal */\nexport const raceFibersWith = /*#__PURE__*/dual(3, (self, other, options) => core.withFiberRuntime((parentFiber, parentStatus) => {\n  const parentRuntimeFlags = parentStatus.runtimeFlags;\n  const raceIndicator = MRef.make(true);\n  const leftFiber = unsafeMakeChildFiber(self, parentFiber, parentRuntimeFlags, options.selfScope);\n  const rightFiber = unsafeMakeChildFiber(other, parentFiber, parentRuntimeFlags, options.otherScope);\n  return core.async(cb => {\n    leftFiber.addObserver(() => completeRace(leftFiber, rightFiber, options.onSelfWin, raceIndicator, cb));\n    rightFiber.addObserver(() => completeRace(rightFiber, leftFiber, options.onOtherWin, raceIndicator, cb));\n    leftFiber.startFork(self);\n    rightFiber.startFork(other);\n  }, FiberId.combine(leftFiber.id(), rightFiber.id()));\n}));\nconst completeRace = (winner, loser, cont, ab, cb) => {\n  if (MRef.compareAndSet(true, false)(ab)) {\n    cb(cont(winner, loser));\n  }\n};\n/** @internal */\nexport const ensuring = /*#__PURE__*/dual(2, (self, finalizer) => core.uninterruptibleMask(restore => core.matchCauseEffect(restore(self), {\n  onFailure: cause1 => core.matchCauseEffect(finalizer, {\n    onFailure: cause2 => core.failCause(internalCause.sequential(cause1, cause2)),\n    onSuccess: () => core.failCause(cause1)\n  }),\n  onSuccess: a => core.as(finalizer, a)\n})));\n/** @internal */\nexport const invokeWithInterrupt = (self, entries, onInterrupt) => core.fiberIdWith(id => core.flatMap(core.flatMap(forkDaemon(core.interruptible(self)), processing => core.async(cb => {\n  const counts = entries.map(_ => _.listeners.count);\n  const checkDone = () => {\n    if (counts.every(count => count === 0)) {\n      if (entries.every(_ => {\n        if (_.result.state.current._tag === \"Pending\") {\n          return true;\n        } else if (_.result.state.current._tag === \"Done\" && core.exitIsExit(_.result.state.current.effect) && _.result.state.current.effect._tag === \"Failure\" && internalCause.isInterrupted(_.result.state.current.effect.cause)) {\n          return true;\n        } else {\n          return false;\n        }\n      })) {\n        cleanup.forEach(f => f());\n        onInterrupt?.();\n        cb(core.interruptFiber(processing));\n      }\n    }\n  };\n  processing.addObserver(exit => {\n    cleanup.forEach(f => f());\n    cb(exit);\n  });\n  const cleanup = entries.map((r, i) => {\n    const observer = count => {\n      counts[i] = count;\n      checkDone();\n    };\n    r.listeners.addObserver(observer);\n    return () => r.listeners.removeObserver(observer);\n  });\n  checkDone();\n  return core.sync(() => {\n    cleanup.forEach(f => f());\n  });\n})), () => core.suspend(() => {\n  const residual = entries.flatMap(entry => {\n    if (!entry.state.completed) {\n      return [entry];\n    }\n    return [];\n  });\n  return core.forEachSequentialDiscard(residual, entry => complete(entry.request, core.exitInterrupt(id)));\n})));\n/** @internal */\nexport const interruptWhenPossible = /*#__PURE__*/dual(2, (self, all) => core.fiberRefGetWith(currentRequestMap, map => core.suspend(() => {\n  const entries = RA.fromIterable(all).flatMap(_ => map.has(_) ? [map.get(_)] : []);\n  return invokeWithInterrupt(self, entries);\n})));\n// circular Tracer\n/** @internal */\nexport const makeSpanScoped = (name, options) => {\n  options = tracer.addSpanStackTrace(options);\n  return core.uninterruptible(core.withFiberRuntime(fiber => {\n    const scope = Context.unsafeGet(fiber.getFiberRef(core.currentContext), scopeTag);\n    const span = internalEffect.unsafeMakeSpan(fiber, name, options);\n    const timingEnabled = fiber.getFiberRef(core.currentTracerTimingEnabled);\n    const clock_ = Context.get(fiber.getFiberRef(defaultServices.currentServices), clock.clockTag);\n    return core.as(core.scopeAddFinalizerExit(scope, exit => internalEffect.endSpan(span, exit, clock_, timingEnabled)), span);\n  }));\n};\n/* @internal */\nexport const withTracerScoped = value => fiberRefLocallyScopedWith(defaultServices.currentServices, Context.add(tracer.tracerTag, value));\n/** @internal */\nexport const withSpanScoped = function () {\n  const dataFirst = typeof arguments[0] !== \"string\";\n  const name = dataFirst ? arguments[1] : arguments[0];\n  const options = tracer.addSpanStackTrace(dataFirst ? arguments[2] : arguments[1]);\n  if (dataFirst) {\n    const self = arguments[0];\n    return core.flatMap(makeSpanScoped(name, tracer.addSpanStackTrace(options)), span => internalEffect.provideService(self, tracer.spanTag, span));\n  }\n  return self => core.flatMap(makeSpanScoped(name, tracer.addSpanStackTrace(options)), span => internalEffect.provideService(self, tracer.spanTag, span));\n};\n//# sourceMappingURL=fiberRuntime.js.map","import * as FiberId from \"../FiberId.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as FiberMessage from \"./fiberMessage.js\";\n/** @internal */\nconst FiberScopeSymbolKey = \"effect/FiberScope\";\n/** @internal */\nexport const FiberScopeTypeId = /*#__PURE__*/Symbol.for(FiberScopeSymbolKey);\n/** @internal */\nclass Global {\n  [FiberScopeTypeId] = FiberScopeTypeId;\n  fiberId = FiberId.none;\n  roots = /*#__PURE__*/new Set();\n  add(_runtimeFlags, child) {\n    this.roots.add(child);\n    child.addObserver(() => {\n      this.roots.delete(child);\n    });\n  }\n}\n/** @internal */\nclass Local {\n  fiberId;\n  parent;\n  [FiberScopeTypeId] = FiberScopeTypeId;\n  constructor(fiberId, parent) {\n    this.fiberId = fiberId;\n    this.parent = parent;\n  }\n  add(_runtimeFlags, child) {\n    this.parent.tell(FiberMessage.stateful(parentFiber => {\n      parentFiber.addChild(child);\n      child.addObserver(() => {\n        parentFiber.removeChild(child);\n      });\n    }));\n  }\n}\n/** @internal */\nexport const unsafeMake = fiber => {\n  return new Local(fiber.id(), fiber);\n};\n/** @internal */\nexport const globalScope = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberScope/Global\"), () => new Global());\n//# sourceMappingURL=fiberScope.js.map","import * as Equal from \"../Equal.js\";\nimport { pipe } from \"../Function.js\";\nimport * as Hash from \"../Hash.js\";\nimport { hasProperty } from \"../Predicate.js\";\nconst FiberStatusSymbolKey = \"effect/FiberStatus\";\n/** @internal */\nexport const FiberStatusTypeId = /*#__PURE__*/Symbol.for(FiberStatusSymbolKey);\n/** @internal */\nexport const OP_DONE = \"Done\";\n/** @internal */\nexport const OP_RUNNING = \"Running\";\n/** @internal */\nexport const OP_SUSPENDED = \"Suspended\";\nconst DoneHash = /*#__PURE__*/Hash.string(`${FiberStatusSymbolKey}-${OP_DONE}`);\n/** @internal */\nclass Done {\n  [FiberStatusTypeId] = FiberStatusTypeId;\n  _tag = OP_DONE;\n  [Hash.symbol]() {\n    return DoneHash;\n  }\n  [Equal.symbol](that) {\n    return isFiberStatus(that) && that._tag === OP_DONE;\n  }\n}\n/** @internal */\nclass Running {\n  runtimeFlags;\n  [FiberStatusTypeId] = FiberStatusTypeId;\n  _tag = OP_RUNNING;\n  constructor(runtimeFlags) {\n    this.runtimeFlags = runtimeFlags;\n  }\n  [Hash.symbol]() {\n    return pipe(Hash.hash(FiberStatusSymbolKey), Hash.combine(Hash.hash(this._tag)), Hash.combine(Hash.hash(this.runtimeFlags)), Hash.cached(this));\n  }\n  [Equal.symbol](that) {\n    return isFiberStatus(that) && that._tag === OP_RUNNING && this.runtimeFlags === that.runtimeFlags;\n  }\n}\n/** @internal */\nclass Suspended {\n  runtimeFlags;\n  blockingOn;\n  [FiberStatusTypeId] = FiberStatusTypeId;\n  _tag = OP_SUSPENDED;\n  constructor(runtimeFlags, blockingOn) {\n    this.runtimeFlags = runtimeFlags;\n    this.blockingOn = blockingOn;\n  }\n  [Hash.symbol]() {\n    return pipe(Hash.hash(FiberStatusSymbolKey), Hash.combine(Hash.hash(this._tag)), Hash.combine(Hash.hash(this.runtimeFlags)), Hash.combine(Hash.hash(this.blockingOn)), Hash.cached(this));\n  }\n  [Equal.symbol](that) {\n    return isFiberStatus(that) && that._tag === OP_SUSPENDED && this.runtimeFlags === that.runtimeFlags && Equal.equals(this.blockingOn, that.blockingOn);\n  }\n}\n/** @internal */\nexport const done = /*#__PURE__*/new Done();\n/** @internal */\nexport const running = runtimeFlags => new Running(runtimeFlags);\n/** @internal */\nexport const suspended = (runtimeFlags, blockingOn) => new Suspended(runtimeFlags, blockingOn);\n/** @internal */\nexport const isFiberStatus = u => hasProperty(u, FiberStatusTypeId);\n/** @internal */\nexport const isDone = self => self._tag === OP_DONE;\n/** @internal */\nexport const isRunning = self => self._tag === OP_RUNNING;\n/** @internal */\nexport const isSuspended = self => self._tag === OP_SUSPENDED;\n//# sourceMappingURL=fiberStatus.js.map","import * as Cause from \"../Cause.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Deferred from \"../Deferred.js\";\nimport * as Effect from \"../Effect.js\";\nimport * as Exit from \"../Exit.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as Queue from \"../Queue.js\";\nimport * as Ref from \"../Ref.js\";\nimport * as channel from \"./channel.js\";\nimport * as channelExecutor from \"./channel/channelExecutor.js\";\nimport * as core from \"./core-stream.js\";\nimport * as stream from \"./stream.js\";\nimport * as take from \"./take.js\";\n/** @internal */\nconst GroupBySymbolKey = \"effect/GroupBy\";\n/** @internal */\nexport const GroupByTypeId = /*#__PURE__*/Symbol.for(GroupBySymbolKey);\nconst groupByVariance = {\n  /* c8 ignore next */\n  _R: _ => _,\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _K: _ => _,\n  /* c8 ignore next */\n  _V: _ => _\n};\n/** @internal */\nexport const isGroupBy = u => hasProperty(u, GroupByTypeId);\n/** @internal */\nexport const evaluate = /*#__PURE__*/dual(args => isGroupBy(args[0]), (self, f, options) => stream.flatMap(self.grouped, ([key, queue]) => f(key, stream.flattenTake(stream.fromQueue(queue, {\n  shutdown: true\n}))), {\n  concurrency: \"unbounded\",\n  bufferSize: options?.bufferSize ?? 16\n}));\n/** @internal */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => make(pipe(self.grouped, stream.filterEffect(tuple => {\n  if (predicate(tuple[0])) {\n    return pipe(Effect.succeed(tuple), Effect.as(true));\n  }\n  return pipe(Queue.shutdown(tuple[1]), Effect.as(false));\n}))));\n/** @internal */\nexport const first = /*#__PURE__*/dual(2, (self, n) => make(pipe(stream.zipWithIndex(self.grouped), stream.filterEffect(tuple => {\n  const index = tuple[1];\n  const queue = tuple[0][1];\n  if (index < n) {\n    return pipe(Effect.succeed(tuple), Effect.as(true));\n  }\n  return pipe(Queue.shutdown(queue), Effect.as(false));\n}), stream.map(tuple => tuple[0]))));\n/** @internal */\nexport const make = grouped => ({\n  [GroupByTypeId]: groupByVariance,\n  pipe() {\n    return pipeArguments(this, arguments);\n  },\n  grouped\n});\n// Circular with Stream\n/** @internal */\nexport const groupBy = /*#__PURE__*/dual(args => stream.isStream(args[0]), (self, f, options) => make(stream.unwrapScoped(Effect.gen(function* ($) {\n  const decider = yield* $(Deferred.make());\n  const output = yield* $(Effect.acquireRelease(Queue.bounded(options?.bufferSize ?? 16), queue => Queue.shutdown(queue)));\n  const ref = yield* $(Ref.make(new Map()));\n  const add = yield* $(stream.mapEffectSequential(self, f), stream.distributedWithDynamicCallback(options?.bufferSize ?? 16, ([key, value]) => Effect.flatMap(Deferred.await(decider), f => f(key, value)), exit => Queue.offer(output, exit)));\n  yield* $(Deferred.succeed(decider, (key, _) => pipe(Ref.get(ref), Effect.map(map => Option.fromNullable(map.get(key))), Effect.flatMap(Option.match({\n    onNone: () => Effect.flatMap(add, ([index, queue]) => Effect.zipRight(Ref.update(ref, map => map.set(key, index)), pipe(Queue.offer(output, Exit.succeed([key, mapDequeue(queue, exit => new take.TakeImpl(pipe(exit, Exit.map(tuple => Chunk.of(tuple[1])))))])), Effect.as(n => n === index)))),\n    onSome: index => Effect.succeed(n => n === index)\n  })))));\n  return stream.flattenExitOption(stream.fromQueue(output, {\n    shutdown: true\n  }));\n}))));\n/** @internal */\nexport const mapEffectOptions = /*#__PURE__*/dual(args => typeof args[0] !== \"function\", (self, f, options) => {\n  if (options?.key) {\n    return evaluate(groupByKey(self, options.key, {\n      bufferSize: options.bufferSize\n    }), (_, s) => stream.mapEffectSequential(s, f));\n  }\n  return stream.matchConcurrency(options?.concurrency, () => stream.mapEffectSequential(self, f), n => options?.unordered ? stream.flatMap(self, a => stream.fromEffect(f(a)), {\n    concurrency: n\n  }) : stream.mapEffectPar(self, n, f));\n});\n/** @internal */\nexport const bindEffect = /*#__PURE__*/dual(args => typeof args[0] !== \"string\", (self, tag, f, options) => mapEffectOptions(self, k => Effect.map(f(k), a => ({\n  ...k,\n  [tag]: a\n})), options));\nconst mapDequeue = (dequeue, f) => new MapDequeue(dequeue, f);\nclass MapDequeue {\n  dequeue;\n  f;\n  [Queue.DequeueTypeId] = {\n    _Out: _ => _\n  };\n  constructor(dequeue, f) {\n    this.dequeue = dequeue;\n    this.f = f;\n  }\n  capacity() {\n    return Queue.capacity(this.dequeue);\n  }\n  get size() {\n    return Queue.size(this.dequeue);\n  }\n  unsafeSize() {\n    return this.dequeue.unsafeSize();\n  }\n  get awaitShutdown() {\n    return Queue.awaitShutdown(this.dequeue);\n  }\n  isActive() {\n    return this.dequeue.isActive();\n  }\n  get isShutdown() {\n    return Queue.isShutdown(this.dequeue);\n  }\n  get shutdown() {\n    return Queue.shutdown(this.dequeue);\n  }\n  get isFull() {\n    return Queue.isFull(this.dequeue);\n  }\n  get isEmpty() {\n    return Queue.isEmpty(this.dequeue);\n  }\n  get take() {\n    return pipe(Queue.take(this.dequeue), Effect.map(a => this.f(a)));\n  }\n  get takeAll() {\n    return pipe(Queue.takeAll(this.dequeue), Effect.map(Chunk.map(a => this.f(a))));\n  }\n  takeUpTo(max) {\n    return pipe(Queue.takeUpTo(this.dequeue, max), Effect.map(Chunk.map(a => this.f(a))));\n  }\n  takeBetween(min, max) {\n    return pipe(Queue.takeBetween(this.dequeue, min, max), Effect.map(Chunk.map(a => this.f(a))));\n  }\n  takeN(n) {\n    return pipe(Queue.takeN(this.dequeue, n), Effect.map(Chunk.map(a => this.f(a))));\n  }\n  poll() {\n    return pipe(Queue.poll(this.dequeue), Effect.map(Option.map(a => this.f(a))));\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const groupByKey = /*#__PURE__*/dual(args => typeof args[0] !== \"function\", (self, f, options) => {\n  const loop = (map, outerQueue) => core.readWithCause({\n    onInput: input => core.flatMap(core.fromEffect(Effect.forEach(groupByIterable(input, f), ([key, values]) => {\n      const innerQueue = map.get(key);\n      if (innerQueue === undefined) {\n        return pipe(Queue.bounded(options?.bufferSize ?? 16), Effect.flatMap(innerQueue => pipe(Effect.sync(() => {\n          map.set(key, innerQueue);\n        }), Effect.zipRight(Queue.offer(outerQueue, take.of([key, innerQueue]))), Effect.zipRight(pipe(Queue.offer(innerQueue, take.chunk(values)), Effect.catchSomeCause(cause => Cause.isInterruptedOnly(cause) ? Option.some(Effect.void) : Option.none()))))));\n      }\n      return Effect.catchSomeCause(Queue.offer(innerQueue, take.chunk(values)), cause => Cause.isInterruptedOnly(cause) ? Option.some(Effect.void) : Option.none());\n    }, {\n      discard: true\n    })), () => loop(map, outerQueue)),\n    onFailure: cause => core.fromEffect(Queue.offer(outerQueue, take.failCause(cause))),\n    onDone: () => pipe(core.fromEffect(pipe(Effect.forEach(map.entries(), ([_, innerQueue]) => pipe(Queue.offer(innerQueue, take.end), Effect.catchSomeCause(cause => Cause.isInterruptedOnly(cause) ? Option.some(Effect.void) : Option.none())), {\n      discard: true\n    }), Effect.zipRight(Queue.offer(outerQueue, take.end)))))\n  });\n  return make(stream.unwrapScoped(pipe(Effect.sync(() => new Map()), Effect.flatMap(map => pipe(Effect.acquireRelease(Queue.unbounded(), queue => Queue.shutdown(queue)), Effect.flatMap(queue => pipe(self, stream.toChannel, core.pipeTo(loop(map, queue)), channel.drain, channelExecutor.runScoped, Effect.forkScoped, Effect.as(stream.flattenTake(stream.fromQueue(queue, {\n    shutdown: true\n  }))))))))));\n});\n/**\n * A variant of `groupBy` that retains the insertion order of keys.\n *\n * @internal\n */\nconst groupByIterable = /*#__PURE__*/dual(2, (iterable, f) => {\n  const builder = [];\n  const iterator = iterable[Symbol.iterator]();\n  const map = new Map();\n  let next;\n  while ((next = iterator.next()) && !next.done) {\n    const value = next.value;\n    const key = f(value);\n    if (map.has(key)) {\n      const innerBuilder = map.get(key);\n      innerBuilder.push(value);\n    } else {\n      const innerBuilder = [value];\n      builder.push([key, innerBuilder]);\n      map.set(key, innerBuilder);\n    }\n  }\n  return Chunk.unsafeFromArray(builder.map(tuple => [tuple[0], Chunk.unsafeFromArray(tuple[1])]));\n});\n//# sourceMappingURL=groupBy.js.map","import * as Equal from \"../Equal.js\";\nimport * as Dual from \"../Function.js\";\nimport { identity, pipe } from \"../Function.js\";\nimport * as Hash from \"../Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport { fromBitmap, hashFragment, toBitmap } from \"./hashMap/bitwise.js\";\nimport { SIZE } from \"./hashMap/config.js\";\nimport * as Node from \"./hashMap/node.js\";\nconst HashMapSymbolKey = \"effect/HashMap\";\n/** @internal */\nexport const HashMapTypeId = /*#__PURE__*/Symbol.for(HashMapSymbolKey);\nconst HashMapProto = {\n  [HashMapTypeId]: HashMapTypeId,\n  [Symbol.iterator]() {\n    return new HashMapIterator(this, (k, v) => [k, v]);\n  },\n  [Hash.symbol]() {\n    let hash = Hash.hash(HashMapSymbolKey);\n    for (const item of this) {\n      hash ^= pipe(Hash.hash(item[0]), Hash.combine(Hash.hash(item[1])));\n    }\n    return Hash.cached(this, hash);\n  },\n  [Equal.symbol](that) {\n    if (isHashMap(that)) {\n      if (that._size !== this._size) {\n        return false;\n      }\n      for (const item of this) {\n        const elem = pipe(that, getHash(item[0], Hash.hash(item[0])));\n        if (Option.isNone(elem)) {\n          return false;\n        } else {\n          if (!Equal.equals(item[1], elem.value)) {\n            return false;\n          }\n        }\n      }\n      return true;\n    }\n    return false;\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"HashMap\",\n      values: Array.from(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst makeImpl = (editable, edit, root, size) => {\n  const map = Object.create(HashMapProto);\n  map._editable = editable;\n  map._edit = edit;\n  map._root = root;\n  map._size = size;\n  return map;\n};\nclass HashMapIterator {\n  map;\n  f;\n  v;\n  constructor(map, f) {\n    this.map = map;\n    this.f = f;\n    this.v = visitLazy(this.map._root, this.f, undefined);\n  }\n  next() {\n    if (Option.isNone(this.v)) {\n      return {\n        done: true,\n        value: undefined\n      };\n    }\n    const v0 = this.v.value;\n    this.v = applyCont(v0.cont);\n    return {\n      done: false,\n      value: v0.value\n    };\n  }\n  [Symbol.iterator]() {\n    return new HashMapIterator(this.map, this.f);\n  }\n}\nconst applyCont = cont => cont ? visitLazyChildren(cont[0], cont[1], cont[2], cont[3], cont[4]) : Option.none();\nconst visitLazy = (node, f, cont = undefined) => {\n  switch (node._tag) {\n    case \"LeafNode\":\n      {\n        if (Option.isSome(node.value)) {\n          return Option.some({\n            value: f(node.key, node.value.value),\n            cont\n          });\n        }\n        return applyCont(cont);\n      }\n    case \"CollisionNode\":\n    case \"ArrayNode\":\n    case \"IndexedNode\":\n      {\n        const children = node.children;\n        return visitLazyChildren(children.length, children, 0, f, cont);\n      }\n    default:\n      {\n        return applyCont(cont);\n      }\n  }\n};\nconst visitLazyChildren = (len, children, i, f, cont) => {\n  while (i < len) {\n    const child = children[i++];\n    if (child && !Node.isEmptyNode(child)) {\n      return visitLazy(child, f, [len, children, i, f, cont]);\n    }\n  }\n  return applyCont(cont);\n};\nconst _empty = /*#__PURE__*/makeImpl(false, 0, /*#__PURE__*/new Node.EmptyNode(), 0);\n/** @internal */\nexport const empty = () => _empty;\n/** @internal */\nexport const make = (...entries) => fromIterable(entries);\n/** @internal */\nexport const fromIterable = entries => {\n  const map = beginMutation(empty());\n  for (const entry of entries) {\n    set(map, entry[0], entry[1]);\n  }\n  return endMutation(map);\n};\n/** @internal */\nexport const isHashMap = u => hasProperty(u, HashMapTypeId);\n/** @internal */\nexport const isEmpty = self => self && Node.isEmptyNode(self._root);\n/** @internal */\nexport const get = /*#__PURE__*/Dual.dual(2, (self, key) => getHash(self, key, Hash.hash(key)));\n/** @internal */\nexport const getHash = /*#__PURE__*/Dual.dual(3, (self, key, hash) => {\n  let node = self._root;\n  let shift = 0;\n  // eslint-disable-next-line no-constant-condition\n  while (true) {\n    switch (node._tag) {\n      case \"LeafNode\":\n        {\n          return Equal.equals(key, node.key) ? node.value : Option.none();\n        }\n      case \"CollisionNode\":\n        {\n          if (hash === node.hash) {\n            const children = node.children;\n            for (let i = 0, len = children.length; i < len; ++i) {\n              const child = children[i];\n              if (\"key\" in child && Equal.equals(key, child.key)) {\n                return child.value;\n              }\n            }\n          }\n          return Option.none();\n        }\n      case \"IndexedNode\":\n        {\n          const frag = hashFragment(shift, hash);\n          const bit = toBitmap(frag);\n          if (node.mask & bit) {\n            node = node.children[fromBitmap(node.mask, bit)];\n            shift += SIZE;\n            break;\n          }\n          return Option.none();\n        }\n      case \"ArrayNode\":\n        {\n          node = node.children[hashFragment(shift, hash)];\n          if (node) {\n            shift += SIZE;\n            break;\n          }\n          return Option.none();\n        }\n      default:\n        return Option.none();\n    }\n  }\n});\n/** @internal */\nexport const unsafeGet = /*#__PURE__*/Dual.dual(2, (self, key) => {\n  const element = getHash(self, key, Hash.hash(key));\n  if (Option.isNone(element)) {\n    throw new Error(\"Expected map to contain key\");\n  }\n  return element.value;\n});\n/** @internal */\nexport const has = /*#__PURE__*/Dual.dual(2, (self, key) => Option.isSome(getHash(self, key, Hash.hash(key))));\n/** @internal */\nexport const hasHash = /*#__PURE__*/Dual.dual(3, (self, key, hash) => Option.isSome(getHash(self, key, hash)));\n/** @internal */\nexport const set = /*#__PURE__*/Dual.dual(3, (self, key, value) => modifyAt(self, key, () => Option.some(value)));\n/** @internal */\nexport const setTree = /*#__PURE__*/Dual.dual(3, (self, newRoot, newSize) => {\n  if (self._editable) {\n    ;\n    self._root = newRoot;\n    self._size = newSize;\n    return self;\n  }\n  return newRoot === self._root ? self : makeImpl(self._editable, self._edit, newRoot, newSize);\n});\n/** @internal */\nexport const keys = self => new HashMapIterator(self, key => key);\n/** @internal */\nexport const values = self => new HashMapIterator(self, (_, value) => value);\n/** @internal */\nexport const entries = self => new HashMapIterator(self, (key, value) => [key, value]);\n/** @internal */\nexport const size = self => self._size;\n/** @internal */\nexport const beginMutation = self => makeImpl(true, self._edit + 1, self._root, self._size);\n/** @internal */\nexport const endMutation = self => {\n  ;\n  self._editable = false;\n  return self;\n};\n/** @internal */\nexport const mutate = /*#__PURE__*/Dual.dual(2, (self, f) => {\n  const transient = beginMutation(self);\n  f(transient);\n  return endMutation(transient);\n});\n/** @internal */\nexport const modifyAt = /*#__PURE__*/Dual.dual(3, (self, key, f) => modifyHash(self, key, Hash.hash(key), f));\n/** @internal */\nexport const modifyHash = /*#__PURE__*/Dual.dual(4, (self, key, hash, f) => {\n  const size = {\n    value: self._size\n  };\n  const newRoot = self._root.modify(self._editable ? self._edit : NaN, 0, f, hash, key, size);\n  return pipe(self, setTree(newRoot, size.value));\n});\n/** @internal */\nexport const modify = /*#__PURE__*/Dual.dual(3, (self, key, f) => modifyAt(self, key, Option.map(f)));\n/** @internal */\nexport const union = /*#__PURE__*/Dual.dual(2, (self, that) => {\n  const result = beginMutation(self);\n  forEach(that, (v, k) => set(result, k, v));\n  return endMutation(result);\n});\n/** @internal */\nexport const remove = /*#__PURE__*/Dual.dual(2, (self, key) => modifyAt(self, key, Option.none));\n/** @internal */\nexport const removeMany = /*#__PURE__*/Dual.dual(2, (self, keys) => mutate(self, map => {\n  for (const key of keys) {\n    remove(key)(map);\n  }\n}));\n/**\n * Maps over the entries of the `HashMap` using the specified function.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = /*#__PURE__*/Dual.dual(2, (self, f) => reduce(self, empty(), (map, value, key) => set(map, key, f(value, key))));\n/** @internal */\nexport const flatMap = /*#__PURE__*/Dual.dual(2, (self, f) => reduce(self, empty(), (zero, value, key) => mutate(zero, map => forEach(f(value, key), (value, key) => set(map, key, value)))));\n/** @internal */\nexport const forEach = /*#__PURE__*/Dual.dual(2, (self, f) => reduce(self, void 0, (_, value, key) => f(value, key)));\n/** @internal */\nexport const reduce = /*#__PURE__*/Dual.dual(3, (self, zero, f) => {\n  const root = self._root;\n  if (root._tag === \"LeafNode\") {\n    return Option.isSome(root.value) ? f(zero, root.value.value, root.key) : zero;\n  }\n  if (root._tag === \"EmptyNode\") {\n    return zero;\n  }\n  const toVisit = [root.children];\n  let children;\n  while (children = toVisit.pop()) {\n    for (let i = 0, len = children.length; i < len;) {\n      const child = children[i++];\n      if (child && !Node.isEmptyNode(child)) {\n        if (child._tag === \"LeafNode\") {\n          if (Option.isSome(child.value)) {\n            zero = f(zero, child.value.value, child.key);\n          }\n        } else {\n          toVisit.push(child.children);\n        }\n      }\n    }\n  }\n  return zero;\n});\n/** @internal */\nexport const filter = /*#__PURE__*/Dual.dual(2, (self, f) => mutate(empty(), map => {\n  for (const [k, a] of self) {\n    if (f(a, k)) {\n      set(map, k, a);\n    }\n  }\n}));\n/** @internal */\nexport const compact = self => filterMap(self, identity);\n/** @internal */\nexport const filterMap = /*#__PURE__*/Dual.dual(2, (self, f) => mutate(empty(), map => {\n  for (const [k, a] of self) {\n    const option = f(a, k);\n    if (Option.isSome(option)) {\n      set(map, k, option.value);\n    }\n  }\n}));\n/** @internal */\nexport const findFirst = /*#__PURE__*/Dual.dual(2, (self, predicate) => {\n  for (const ka of self) {\n    if (predicate(ka[1], ka[0])) {\n      return Option.some(ka);\n    }\n  }\n  return Option.none();\n});\n//# sourceMappingURL=hashMap.js.map","/** @internal */\nexport function arrayUpdate(mutate, at, v, arr) {\n  let out = arr;\n  if (!mutate) {\n    const len = arr.length;\n    out = new Array(len);\n    for (let i = 0; i < len; ++i) out[i] = arr[i];\n  }\n  out[at] = v;\n  return out;\n}\n/** @internal */\nexport function arraySpliceOut(mutate, at, arr) {\n  const newLen = arr.length - 1;\n  let i = 0;\n  let g = 0;\n  let out = arr;\n  if (mutate) {\n    i = g = at;\n  } else {\n    out = new Array(newLen);\n    while (i < at) out[g++] = arr[i++];\n  }\n  ;\n  ++i;\n  while (i <= newLen) out[g++] = arr[i++];\n  if (mutate) {\n    out.length = newLen;\n  }\n  return out;\n}\n/** @internal */\nexport function arraySpliceIn(mutate, at, v, arr) {\n  const len = arr.length;\n  if (mutate) {\n    let i = len;\n    while (i >= at) arr[i--] = arr[i];\n    arr[at] = v;\n    return arr;\n  }\n  let i = 0,\n    g = 0;\n  const out = new Array(len + 1);\n  while (i < at) out[g++] = arr[i++];\n  out[at] = v;\n  while (i < len) out[++g] = arr[i++];\n  return out;\n}\n//# sourceMappingURL=array.js.map","import { MASK } from \"./config.js\";\n/**\n * Hamming weight.\n *\n * Taken from: http://jsperf.com/hamming-weight\n *\n * @internal\n */\nexport function popcount(x) {\n  x -= x >> 1 & 0x55555555;\n  x = (x & 0x33333333) + (x >> 2 & 0x33333333);\n  x = x + (x >> 4) & 0x0f0f0f0f;\n  x += x >> 8;\n  x += x >> 16;\n  return x & 0x7f;\n}\n/** @internal */\nexport function hashFragment(shift, h) {\n  return h >>> shift & MASK;\n}\n/** @internal */\nexport function toBitmap(x) {\n  return 1 << x;\n}\n/** @internal */\nexport function fromBitmap(bitmap, bit) {\n  return popcount(bitmap & bit - 1);\n}\n//# sourceMappingURL=bitwise.js.map","/** @internal */\nexport const SIZE = 5;\n/** @internal */\nexport const BUCKET_SIZE = /*#__PURE__*/Math.pow(2, SIZE);\n/** @internal */\nexport const MASK = BUCKET_SIZE - 1;\n/** @internal */\nexport const MAX_INDEX_NODE = BUCKET_SIZE / 2;\n/** @internal */\nexport const MIN_ARRAY_NODE = BUCKET_SIZE / 4;\n//# sourceMappingURL=config.js.map","import { makeImpl } from \"../hashSet.js\";\n/** @internal */\nexport function keySet(self) {\n  return makeImpl(self);\n}\n//# sourceMappingURL=keySet.js.map","import { equals } from \"../../Equal.js\";\nimport * as O from \"../../Option.js\";\nimport { isTagged } from \"../../Predicate.js\";\nimport * as Stack from \"../stack.js\";\nimport { arraySpliceIn, arraySpliceOut, arrayUpdate } from \"./array.js\";\nimport { fromBitmap, hashFragment, toBitmap } from \"./bitwise.js\";\nimport { MAX_INDEX_NODE, MIN_ARRAY_NODE, SIZE } from \"./config.js\";\n/** @internal */\nexport class EmptyNode {\n  _tag = \"EmptyNode\";\n  modify(edit, _shift, f, hash, key, size) {\n    const v = f(O.none());\n    if (O.isNone(v)) return new EmptyNode();\n    ++size.value;\n    return new LeafNode(edit, hash, key, v);\n  }\n}\n/** @internal */\nexport function isEmptyNode(a) {\n  return isTagged(a, \"EmptyNode\");\n}\n/** @internal */\nexport function isLeafNode(node) {\n  return isEmptyNode(node) || node._tag === \"LeafNode\" || node._tag === \"CollisionNode\";\n}\n/** @internal */\nexport function canEditNode(node, edit) {\n  return isEmptyNode(node) ? false : edit === node.edit;\n}\n/** @internal */\nexport class LeafNode {\n  edit;\n  hash;\n  key;\n  value;\n  _tag = \"LeafNode\";\n  constructor(edit, hash, key, value) {\n    this.edit = edit;\n    this.hash = hash;\n    this.key = key;\n    this.value = value;\n  }\n  modify(edit, shift, f, hash, key, size) {\n    if (equals(key, this.key)) {\n      const v = f(this.value);\n      if (v === this.value) return this;else if (O.isNone(v)) {\n        ;\n        --size.value;\n        return new EmptyNode();\n      }\n      if (canEditNode(this, edit)) {\n        this.value = v;\n        return this;\n      }\n      return new LeafNode(edit, hash, key, v);\n    }\n    const v = f(O.none());\n    if (O.isNone(v)) return this;\n    ++size.value;\n    return mergeLeaves(edit, shift, this.hash, this, hash, new LeafNode(edit, hash, key, v));\n  }\n}\n/** @internal */\nexport class CollisionNode {\n  edit;\n  hash;\n  children;\n  _tag = \"CollisionNode\";\n  constructor(edit, hash, children) {\n    this.edit = edit;\n    this.hash = hash;\n    this.children = children;\n  }\n  modify(edit, shift, f, hash, key, size) {\n    if (hash === this.hash) {\n      const canEdit = canEditNode(this, edit);\n      const list = this.updateCollisionList(canEdit, edit, this.hash, this.children, f, key, size);\n      if (list === this.children) return this;\n      return list.length > 1 ? new CollisionNode(edit, this.hash, list) : list[0]; // collapse single element collision list\n    }\n    const v = f(O.none());\n    if (O.isNone(v)) return this;\n    ++size.value;\n    return mergeLeaves(edit, shift, this.hash, this, hash, new LeafNode(edit, hash, key, v));\n  }\n  updateCollisionList(mutate, edit, hash, list, f, key, size) {\n    const len = list.length;\n    for (let i = 0; i < len; ++i) {\n      const child = list[i];\n      if (\"key\" in child && equals(key, child.key)) {\n        const value = child.value;\n        const newValue = f(value);\n        if (newValue === value) return list;\n        if (O.isNone(newValue)) {\n          ;\n          --size.value;\n          return arraySpliceOut(mutate, i, list);\n        }\n        return arrayUpdate(mutate, i, new LeafNode(edit, hash, key, newValue), list);\n      }\n    }\n    const newValue = f(O.none());\n    if (O.isNone(newValue)) return list;\n    ++size.value;\n    return arrayUpdate(mutate, len, new LeafNode(edit, hash, key, newValue), list);\n  }\n}\n/** @internal */\nexport class IndexedNode {\n  edit;\n  mask;\n  children;\n  _tag = \"IndexedNode\";\n  constructor(edit, mask, children) {\n    this.edit = edit;\n    this.mask = mask;\n    this.children = children;\n  }\n  modify(edit, shift, f, hash, key, size) {\n    const mask = this.mask;\n    const children = this.children;\n    const frag = hashFragment(shift, hash);\n    const bit = toBitmap(frag);\n    const indx = fromBitmap(mask, bit);\n    const exists = mask & bit;\n    const canEdit = canEditNode(this, edit);\n    if (!exists) {\n      const _newChild = new EmptyNode().modify(edit, shift + SIZE, f, hash, key, size);\n      if (!_newChild) return this;\n      return children.length >= MAX_INDEX_NODE ? expand(edit, frag, _newChild, mask, children) : new IndexedNode(edit, mask | bit, arraySpliceIn(canEdit, indx, _newChild, children));\n    }\n    const current = children[indx];\n    const child = current.modify(edit, shift + SIZE, f, hash, key, size);\n    if (current === child) return this;\n    let bitmap = mask;\n    let newChildren;\n    if (isEmptyNode(child)) {\n      // remove\n      bitmap &= ~bit;\n      if (!bitmap) return new EmptyNode();\n      if (children.length <= 2 && isLeafNode(children[indx ^ 1])) {\n        return children[indx ^ 1]; // collapse\n      }\n      newChildren = arraySpliceOut(canEdit, indx, children);\n    } else {\n      // modify\n      newChildren = arrayUpdate(canEdit, indx, child, children);\n    }\n    if (canEdit) {\n      this.mask = bitmap;\n      this.children = newChildren;\n      return this;\n    }\n    return new IndexedNode(edit, bitmap, newChildren);\n  }\n}\n/** @internal */\nexport class ArrayNode {\n  edit;\n  size;\n  children;\n  _tag = \"ArrayNode\";\n  constructor(edit, size, children) {\n    this.edit = edit;\n    this.size = size;\n    this.children = children;\n  }\n  modify(edit, shift, f, hash, key, size) {\n    let count = this.size;\n    const children = this.children;\n    const frag = hashFragment(shift, hash);\n    const child = children[frag];\n    const newChild = (child || new EmptyNode()).modify(edit, shift + SIZE, f, hash, key, size);\n    if (child === newChild) return this;\n    const canEdit = canEditNode(this, edit);\n    let newChildren;\n    if (isEmptyNode(child) && !isEmptyNode(newChild)) {\n      // add\n      ;\n      ++count;\n      newChildren = arrayUpdate(canEdit, frag, newChild, children);\n    } else if (!isEmptyNode(child) && isEmptyNode(newChild)) {\n      // remove\n      ;\n      --count;\n      if (count <= MIN_ARRAY_NODE) {\n        return pack(edit, count, frag, children);\n      }\n      newChildren = arrayUpdate(canEdit, frag, new EmptyNode(), children);\n    } else {\n      // modify\n      newChildren = arrayUpdate(canEdit, frag, newChild, children);\n    }\n    if (canEdit) {\n      this.size = count;\n      this.children = newChildren;\n      return this;\n    }\n    return new ArrayNode(edit, count, newChildren);\n  }\n}\nfunction pack(edit, count, removed, elements) {\n  const children = new Array(count - 1);\n  let g = 0;\n  let bitmap = 0;\n  for (let i = 0, len = elements.length; i < len; ++i) {\n    if (i !== removed) {\n      const elem = elements[i];\n      if (elem && !isEmptyNode(elem)) {\n        children[g++] = elem;\n        bitmap |= 1 << i;\n      }\n    }\n  }\n  return new IndexedNode(edit, bitmap, children);\n}\nfunction expand(edit, frag, child, bitmap, subNodes) {\n  const arr = [];\n  let bit = bitmap;\n  let count = 0;\n  for (let i = 0; bit; ++i) {\n    if (bit & 1) arr[i] = subNodes[count++];\n    bit >>>= 1;\n  }\n  arr[frag] = child;\n  return new ArrayNode(edit, count + 1, arr);\n}\nfunction mergeLeavesInner(edit, shift, h1, n1, h2, n2) {\n  if (h1 === h2) return new CollisionNode(edit, h1, [n2, n1]);\n  const subH1 = hashFragment(shift, h1);\n  const subH2 = hashFragment(shift, h2);\n  if (subH1 === subH2) {\n    return child => new IndexedNode(edit, toBitmap(subH1) | toBitmap(subH2), [child]);\n  } else {\n    const children = subH1 < subH2 ? [n1, n2] : [n2, n1];\n    return new IndexedNode(edit, toBitmap(subH1) | toBitmap(subH2), children);\n  }\n}\nfunction mergeLeaves(edit, shift, h1, n1, h2, n2) {\n  let stack = undefined;\n  let currentShift = shift;\n  // eslint-disable-next-line no-constant-condition\n  while (true) {\n    const res = mergeLeavesInner(edit, currentShift, h1, n1, h2, n2);\n    if (typeof res === \"function\") {\n      stack = Stack.make(res, stack);\n      currentShift = currentShift + SIZE;\n    } else {\n      let final = res;\n      while (stack != null) {\n        final = stack.value(final);\n        stack = stack.previous;\n      }\n      return final;\n    }\n  }\n}\n//# sourceMappingURL=node.js.map","import * as Equal from \"../Equal.js\";\nimport { dual } from \"../Function.js\";\nimport * as Hash from \"../Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as HM from \"./hashMap.js\";\nconst HashSetSymbolKey = \"effect/HashSet\";\n/** @internal */\nexport const HashSetTypeId = /*#__PURE__*/Symbol.for(HashSetSymbolKey);\nconst HashSetProto = {\n  [HashSetTypeId]: HashSetTypeId,\n  [Symbol.iterator]() {\n    return HM.keys(this._keyMap);\n  },\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.combine(Hash.hash(this._keyMap))(Hash.hash(HashSetSymbolKey)));\n  },\n  [Equal.symbol](that) {\n    if (isHashSet(that)) {\n      return HM.size(this._keyMap) === HM.size(that._keyMap) && Equal.equals(this._keyMap, that._keyMap);\n    }\n    return false;\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"HashSet\",\n      values: Array.from(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const makeImpl = keyMap => {\n  const set = Object.create(HashSetProto);\n  set._keyMap = keyMap;\n  return set;\n};\n/** @internal */\nexport const isHashSet = u => hasProperty(u, HashSetTypeId);\nconst _empty = /*#__PURE__*/makeImpl( /*#__PURE__*/HM.empty());\n/** @internal */\nexport const empty = () => _empty;\n/** @internal */\nexport const fromIterable = elements => {\n  const set = beginMutation(empty());\n  for (const value of elements) {\n    add(set, value);\n  }\n  return endMutation(set);\n};\n/** @internal */\nexport const make = (...elements) => {\n  const set = beginMutation(empty());\n  for (const value of elements) {\n    add(set, value);\n  }\n  return endMutation(set);\n};\n/** @internal */\nexport const has = /*#__PURE__*/dual(2, (self, value) => HM.has(self._keyMap, value));\n/** @internal */\nexport const some = /*#__PURE__*/dual(2, (self, f) => {\n  let found = false;\n  for (const value of self) {\n    found = f(value);\n    if (found) {\n      break;\n    }\n  }\n  return found;\n});\n/** @internal */\nexport const every = /*#__PURE__*/dual(2, (self, refinement) => !some(self, a => !refinement(a)));\n/** @internal */\nexport const isSubset = /*#__PURE__*/dual(2, (self, that) => every(self, value => has(that, value)));\n/** @internal */\nexport const values = self => HM.keys(self._keyMap);\n/** @internal */\nexport const size = self => HM.size(self._keyMap);\n/** @internal */\nexport const beginMutation = self => makeImpl(HM.beginMutation(self._keyMap));\n/** @internal */\nexport const endMutation = self => {\n  ;\n  self._keyMap._editable = false;\n  return self;\n};\n/** @internal */\nexport const mutate = /*#__PURE__*/dual(2, (self, f) => {\n  const transient = beginMutation(self);\n  f(transient);\n  return endMutation(transient);\n});\n/** @internal */\nexport const add = /*#__PURE__*/dual(2, (self, value) => self._keyMap._editable ? (HM.set(value, true)(self._keyMap), self) : makeImpl(HM.set(value, true)(self._keyMap)));\n/** @internal */\nexport const remove = /*#__PURE__*/dual(2, (self, value) => self._keyMap._editable ? (HM.remove(value)(self._keyMap), self) : makeImpl(HM.remove(value)(self._keyMap)));\n/** @internal */\nexport const difference = /*#__PURE__*/dual(2, (self, that) => mutate(self, set => {\n  for (const value of that) {\n    remove(set, value);\n  }\n}));\n/** @internal */\nexport const intersection = /*#__PURE__*/dual(2, (self, that) => mutate(empty(), set => {\n  for (const value of that) {\n    if (has(value)(self)) {\n      add(value)(set);\n    }\n  }\n}));\n/** @internal */\nexport const union = /*#__PURE__*/dual(2, (self, that) => mutate(empty(), set => {\n  forEach(self, value => add(set, value));\n  for (const value of that) {\n    add(set, value);\n  }\n}));\n/** @internal */\nexport const toggle = /*#__PURE__*/dual(2, (self, value) => has(self, value) ? remove(self, value) : add(self, value));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => mutate(empty(), set => {\n  forEach(self, a => {\n    const b = f(a);\n    if (!has(set, b)) {\n      add(set, b);\n    }\n  });\n}));\n/** @internal */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => mutate(empty(), set => {\n  forEach(self, a => {\n    for (const b of f(a)) {\n      if (!has(set, b)) {\n        add(set, b);\n      }\n    }\n  });\n}));\n/** @internal */\nexport const forEach = /*#__PURE__*/dual(2, (self, f) => HM.forEach(self._keyMap, (_, k) => f(k)));\n/** @internal */\nexport const reduce = /*#__PURE__*/dual(3, (self, zero, f) => HM.reduce(self._keyMap, zero, (z, _, a) => f(z, a)));\n/** @internal */\nexport const filter = /*#__PURE__*/dual(2, (self, f) => {\n  return mutate(empty(), set => {\n    const iterator = values(self);\n    let next;\n    while (!(next = iterator.next()).done) {\n      const value = next.value;\n      if (f(value)) {\n        add(set, value);\n      }\n    }\n  });\n});\n/** @internal */\nexport const partition = /*#__PURE__*/dual(2, (self, predicate) => {\n  const iterator = values(self);\n  let next;\n  const right = beginMutation(empty());\n  const left = beginMutation(empty());\n  while (!(next = iterator.next()).done) {\n    const value = next.value;\n    if (predicate(value)) {\n      add(right, value);\n    } else {\n      add(left, value);\n    }\n  }\n  return [endMutation(left), endMutation(right)];\n});\n//# sourceMappingURL=hashSet.js.map","import * as Cause from \"../Cause.js\";\nimport * as Clock from \"../Clock.js\";\nimport * as Context from \"../Context.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as FiberRefsPatch from \"../FiberRefsPatch.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as ScheduleDecision from \"../ScheduleDecision.js\";\nimport * as Intervals from \"../ScheduleIntervals.js\";\nimport * as Scope from \"../Scope.js\";\nimport * as effect from \"./core-effect.js\";\nimport * as core from \"./core.js\";\nimport * as circular from \"./effect/circular.js\";\nimport * as fiberRuntime from \"./fiberRuntime.js\";\nimport * as EffectOpCodes from \"./opCodes/effect.js\";\nimport * as OpCodes from \"./opCodes/layer.js\";\nimport * as ref from \"./ref.js\";\nimport * as runtime from \"./runtime.js\";\nimport * as runtimeFlags from \"./runtimeFlags.js\";\nimport * as synchronized from \"./synchronizedRef.js\";\nimport * as tracer from \"./tracer.js\";\n/** @internal */\nconst LayerSymbolKey = \"effect/Layer\";\n/** @internal */\nexport const LayerTypeId = /*#__PURE__*/Symbol.for(LayerSymbolKey);\nconst layerVariance = {\n  /* c8 ignore next */\n  _RIn: _ => _,\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _ROut: _ => _\n};\n/** @internal */\nconst proto = {\n  [LayerTypeId]: layerVariance,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nconst MemoMapTypeIdKey = \"effect/Layer/MemoMap\";\n/** @internal */\nexport const MemoMapTypeId = /*#__PURE__*/Symbol.for(MemoMapTypeIdKey);\n/** @internal */\nexport const isLayer = u => hasProperty(u, LayerTypeId);\n/** @internal */\nexport const isFresh = self => {\n  return self._tag === OpCodes.OP_FRESH;\n};\n// -----------------------------------------------------------------------------\n// MemoMap\n// -----------------------------------------------------------------------------\n/** @internal */\nclass MemoMapImpl {\n  ref;\n  [MemoMapTypeId];\n  constructor(ref) {\n    this.ref = ref;\n    this[MemoMapTypeId] = MemoMapTypeId;\n  }\n  /**\n   * Checks the memo map to see if a layer exists. If it is, immediately\n   * returns it. Otherwise, obtains the layer, stores it in the memo map,\n   * and adds a finalizer to the `Scope`.\n   */\n  getOrElseMemoize(layer, scope) {\n    return pipe(synchronized.modifyEffect(this.ref, map => {\n      const inMap = map.get(layer);\n      if (inMap !== undefined) {\n        const [acquire, release] = inMap;\n        const cached = pipe(acquire, core.flatMap(([patch, b]) => pipe(effect.patchFiberRefs(patch), core.as(b))), core.onExit(core.exitMatch({\n          onFailure: () => core.void,\n          onSuccess: () => core.scopeAddFinalizerExit(scope, release)\n        })));\n        return core.succeed([cached, map]);\n      }\n      return pipe(ref.make(0), core.flatMap(observers => pipe(core.deferredMake(), core.flatMap(deferred => pipe(ref.make(() => core.void), core.map(finalizerRef => {\n        const resource = core.uninterruptibleMask(restore => pipe(fiberRuntime.scopeMake(), core.flatMap(innerScope => pipe(restore(core.flatMap(makeBuilder(layer, innerScope, true), f => effect.diffFiberRefs(f(this)))), core.exit, core.flatMap(exit => {\n          switch (exit._tag) {\n            case EffectOpCodes.OP_FAILURE:\n              {\n                return pipe(core.deferredFailCause(deferred, exit.effect_instruction_i0), core.zipRight(core.scopeClose(innerScope, exit)), core.zipRight(core.failCause(exit.effect_instruction_i0)));\n              }\n            case EffectOpCodes.OP_SUCCESS:\n              {\n                return pipe(ref.set(finalizerRef, exit => pipe(core.scopeClose(innerScope, exit), core.whenEffect(ref.modify(observers, n => [n === 1, n - 1])), core.asVoid)), core.zipRight(ref.update(observers, n => n + 1)), core.zipRight(core.scopeAddFinalizerExit(scope, exit => pipe(core.sync(() => map.delete(layer)), core.zipRight(ref.get(finalizerRef)), core.flatMap(finalizer => finalizer(exit))))), core.zipRight(core.deferredSucceed(deferred, exit.effect_instruction_i0)), core.as(exit.effect_instruction_i0[1]));\n              }\n          }\n        })))));\n        const memoized = [pipe(core.deferredAwait(deferred), core.onExit(core.exitMatchEffect({\n          onFailure: () => core.void,\n          onSuccess: () => ref.update(observers, n => n + 1)\n        }))), exit => pipe(ref.get(finalizerRef), core.flatMap(finalizer => finalizer(exit)))];\n        return [resource, isFresh(layer) ? map : map.set(layer, memoized)];\n      }))))));\n    }), core.flatten);\n  }\n}\n/** @internal */\nexport const makeMemoMap = /*#__PURE__*/core.suspend(() => core.map(circular.makeSynchronized(new Map()), ref => new MemoMapImpl(ref)));\n/** @internal */\nexport const unsafeMakeMemoMap = () => new MemoMapImpl(circular.unsafeMakeSynchronized(new Map()));\n/** @internal */\nexport const build = self => fiberRuntime.scopeWith(scope => buildWithScope(self, scope));\n/** @internal */\nexport const buildWithScope = /*#__PURE__*/dual(2, (self, scope) => core.flatMap(makeMemoMap, memoMap => core.flatMap(makeBuilder(self, scope), run => run(memoMap))));\n/** @internal */\nexport const buildWithMemoMap = /*#__PURE__*/dual(3, (self, memoMap, scope) => core.flatMap(makeBuilder(self, scope), run => run(memoMap)));\nconst makeBuilder = (self, scope, inMemoMap = false) => {\n  const op = self;\n  switch (op._tag) {\n    case \"Locally\":\n      {\n        return core.sync(() => memoMap => op.f(memoMap.getOrElseMemoize(op.self, scope)));\n      }\n    case \"ExtendScope\":\n      {\n        return core.sync(() => memoMap => fiberRuntime.scopeWith(scope => memoMap.getOrElseMemoize(op.layer, scope)));\n      }\n    case \"Fold\":\n      {\n        return core.sync(() => memoMap => pipe(memoMap.getOrElseMemoize(op.layer, scope), core.matchCauseEffect({\n          onFailure: cause => memoMap.getOrElseMemoize(op.failureK(cause), scope),\n          onSuccess: value => memoMap.getOrElseMemoize(op.successK(value), scope)\n        })));\n      }\n    case \"Fresh\":\n      {\n        return core.sync(() => _ => pipe(op.layer, buildWithScope(scope)));\n      }\n    case \"FromEffect\":\n      {\n        return inMemoMap ? core.sync(() => _ => op.effect) : core.sync(() => memoMap => memoMap.getOrElseMemoize(self, scope));\n      }\n    case \"Provide\":\n      {\n        return core.sync(() => memoMap => pipe(memoMap.getOrElseMemoize(op.first, scope), core.flatMap(env => pipe(memoMap.getOrElseMemoize(op.second, scope), core.provideContext(env)))));\n      }\n    case \"Scoped\":\n      {\n        return inMemoMap ? core.sync(() => _ => fiberRuntime.scopeExtend(op.effect, scope)) : core.sync(() => memoMap => memoMap.getOrElseMemoize(self, scope));\n      }\n    case \"Suspend\":\n      {\n        return core.sync(() => memoMap => memoMap.getOrElseMemoize(op.evaluate(), scope));\n      }\n    case \"ProvideMerge\":\n      {\n        return core.sync(() => memoMap => pipe(memoMap.getOrElseMemoize(op.first, scope), core.zipWith(memoMap.getOrElseMemoize(op.second, scope), op.zipK)));\n      }\n    case \"ZipWith\":\n      {\n        return core.sync(() => memoMap => pipe(memoMap.getOrElseMemoize(op.first, scope), fiberRuntime.zipWithOptions(memoMap.getOrElseMemoize(op.second, scope), op.zipK, {\n          concurrent: true\n        })));\n      }\n  }\n};\n// -----------------------------------------------------------------------------\n// Layer\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const catchAll = /*#__PURE__*/dual(2, (self, onFailure) => match(self, {\n  onFailure,\n  onSuccess: succeedContext\n}));\n/** @internal */\nexport const catchAllCause = /*#__PURE__*/dual(2, (self, onFailure) => matchCause(self, {\n  onFailure,\n  onSuccess: succeedContext\n}));\n/** @internal */\nexport const die = defect => failCause(Cause.die(defect));\n/** @internal */\nexport const dieSync = evaluate => failCauseSync(() => Cause.die(evaluate()));\n/** @internal */\nexport const discard = self => map(self, () => Context.empty());\n/** @internal */\nexport const context = () => fromEffectContext(core.context());\n/** @internal */\nexport const extendScope = self => {\n  const extendScope = Object.create(proto);\n  extendScope._tag = OpCodes.OP_EXTEND_SCOPE;\n  extendScope.layer = self;\n  return extendScope;\n};\n/** @internal */\nexport const fail = error => failCause(Cause.fail(error));\n/** @internal */\nexport const failSync = evaluate => failCauseSync(() => Cause.fail(evaluate()));\n/** @internal */\nexport const failCause = cause => fromEffectContext(core.failCause(cause));\n/** @internal */\nexport const failCauseSync = evaluate => fromEffectContext(core.failCauseSync(evaluate));\n/** @internal */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => match(self, {\n  onFailure: fail,\n  onSuccess: f\n}));\n/** @internal */\nexport const flatten = /*#__PURE__*/dual(2, (self, tag) => flatMap(self, Context.get(tag)));\n/** @internal */\nexport const fresh = self => {\n  const fresh = Object.create(proto);\n  fresh._tag = OpCodes.OP_FRESH;\n  fresh.layer = self;\n  return fresh;\n};\n/** @internal */\nexport const fromEffect = /*#__PURE__*/dual(2, (a, b) => {\n  const tagFirst = Context.isTag(a);\n  const tag = tagFirst ? a : b;\n  const effect = tagFirst ? b : a;\n  return fromEffectContext(core.map(effect, service => Context.make(tag, service)));\n});\n/** @internal */\nexport const fromEffectDiscard = effect => fromEffectContext(core.map(effect, () => Context.empty()));\n/** @internal */\nexport function fromEffectContext(effect) {\n  const fromEffect = Object.create(proto);\n  fromEffect._tag = OpCodes.OP_FROM_EFFECT;\n  fromEffect.effect = effect;\n  return fromEffect;\n}\n/** @internal */\nexport const fiberRefLocally = /*#__PURE__*/dual(3, (self, ref, value) => locallyEffect(self, core.fiberRefLocally(ref, value)));\n/** @internal */\nexport const locallyEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const locally = Object.create(proto);\n  locally._tag = \"Locally\";\n  locally.self = self;\n  locally.f = f;\n  return locally;\n});\n/** @internal */\nexport const fiberRefLocallyWith = /*#__PURE__*/dual(3, (self, ref, value) => locallyEffect(self, core.fiberRefLocallyWith(ref, value)));\n/** @internal */\nexport const fiberRefLocallyScoped = (self, value) => scopedDiscard(fiberRuntime.fiberRefLocallyScoped(self, value));\n/** @internal */\nexport const fiberRefLocallyScopedWith = (self, value) => scopedDiscard(fiberRuntime.fiberRefLocallyScopedWith(self, value));\n/** @internal */\nexport const fromFunction = (tagA, tagB, f) => fromEffectContext(core.map(tagA, a => Context.make(tagB, f(a))));\n/** @internal */\nexport const launch = self => fiberRuntime.scopedEffect(core.zipRight(fiberRuntime.scopeWith(scope => pipe(self, buildWithScope(scope))), core.never));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => flatMap(self, context => succeedContext(f(context))));\n/** @internal */\nexport const mapError = /*#__PURE__*/dual(2, (self, f) => catchAll(self, error => failSync(() => f(error))));\n/** @internal */\nexport const matchCause = /*#__PURE__*/dual(2, (self, {\n  onFailure,\n  onSuccess\n}) => {\n  const fold = Object.create(proto);\n  fold._tag = OpCodes.OP_FOLD;\n  fold.layer = self;\n  fold.failureK = onFailure;\n  fold.successK = onSuccess;\n  return fold;\n});\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onFailure,\n  onSuccess\n}) => matchCause(self, {\n  onFailure: cause => {\n    const failureOrCause = Cause.failureOrCause(cause);\n    switch (failureOrCause._tag) {\n      case \"Left\":\n        {\n          return onFailure(failureOrCause.left);\n        }\n      case \"Right\":\n        {\n          return failCause(failureOrCause.right);\n        }\n    }\n  },\n  onSuccess\n}));\n/** @internal */\nexport const memoize = self => fiberRuntime.scopeWith(scope => core.map(effect.memoize(buildWithScope(self, scope)), fromEffectContext));\n/** @internal */\nexport const merge = /*#__PURE__*/dual(2, (self, that) => zipWith(self, that, (a, b) => Context.merge(a, b)));\n/** @internal */\nexport const mergeAll = (...layers) => {\n  let final = layers[0];\n  for (let i = 1; i < layers.length; i++) {\n    final = merge(final, layers[i]);\n  }\n  return final;\n};\n/** @internal */\nexport const orDie = self => catchAll(self, defect => die(defect));\n/** @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => catchAll(self, that));\n/** @internal */\nexport const passthrough = self => merge(context(), self);\n/** @internal */\nexport const project = /*#__PURE__*/dual(4, (self, tagA, tagB, f) => map(self, context => Context.make(tagB, f(Context.unsafeGet(context, tagA)))));\n/** @internal */\nexport const retry = /*#__PURE__*/dual(2, (self, schedule) => suspend(() => {\n  const stateTag = Context.GenericTag(\"effect/Layer/retry/{ state: unknown }\");\n  return pipe(succeed(stateTag, {\n    state: schedule.initial\n  }), flatMap(env => retryLoop(self, schedule, stateTag, pipe(env, Context.get(stateTag)).state)));\n}));\nconst retryLoop = (self, schedule, stateTag, state) => {\n  return pipe(self, catchAll(error => pipe(retryUpdate(schedule, stateTag, error, state), flatMap(env => fresh(retryLoop(self, schedule, stateTag, pipe(env, Context.get(stateTag)).state))))));\n};\nconst retryUpdate = (schedule, stateTag, error, state) => {\n  return fromEffect(stateTag, pipe(Clock.currentTimeMillis, core.flatMap(now => pipe(schedule.step(now, error, state), core.flatMap(([state, _, decision]) => ScheduleDecision.isDone(decision) ? core.fail(error) : pipe(Clock.sleep(Duration.millis(Intervals.start(decision.intervals) - now)), core.as({\n    state\n  })))))));\n};\n/** @internal */\nexport const scoped = /*#__PURE__*/dual(2, (a, b) => {\n  const tagFirst = Context.isTag(a);\n  const tag = tagFirst ? a : b;\n  const effect = tagFirst ? b : a;\n  return scopedContext(core.map(effect, service => Context.make(tag, service)));\n});\n/** @internal */\nexport const scopedDiscard = effect => scopedContext(pipe(effect, core.as(Context.empty())));\n/** @internal */\nexport const scopedContext = effect => {\n  const scoped = Object.create(proto);\n  scoped._tag = OpCodes.OP_SCOPED;\n  scoped.effect = effect;\n  return scoped;\n};\n/** @internal */\nexport const scope = /*#__PURE__*/scopedContext( /*#__PURE__*/core.map( /*#__PURE__*/fiberRuntime.acquireRelease( /*#__PURE__*/fiberRuntime.scopeMake(), (scope, exit) => scope.close(exit)), scope => Context.make(Scope.Scope, scope)));\n/** @internal */\nexport const service = tag => fromEffect(tag, tag);\n/** @internal */\nexport const succeed = /*#__PURE__*/dual(2, (a, b) => {\n  const tagFirst = Context.isTag(a);\n  const tag = tagFirst ? a : b;\n  const resource = tagFirst ? b : a;\n  return fromEffectContext(core.succeed(Context.make(tag, resource)));\n});\n/** @internal */\nexport const succeedContext = context => {\n  return fromEffectContext(core.succeed(context));\n};\n/** @internal */\nexport const empty = /*#__PURE__*/succeedContext( /*#__PURE__*/Context.empty());\n/** @internal */\nexport const suspend = evaluate => {\n  const suspend = Object.create(proto);\n  suspend._tag = OpCodes.OP_SUSPEND;\n  suspend.evaluate = evaluate;\n  return suspend;\n};\n/** @internal */\nexport const sync = /*#__PURE__*/dual(2, (a, b) => {\n  const tagFirst = Context.isTag(a);\n  const tag = tagFirst ? a : b;\n  const evaluate = tagFirst ? b : a;\n  return fromEffectContext(core.sync(() => Context.make(tag, evaluate())));\n});\n/** @internal */\nexport const syncContext = evaluate => {\n  return fromEffectContext(core.sync(evaluate));\n};\n/** @internal */\nexport const tap = /*#__PURE__*/dual(2, (self, f) => flatMap(self, context => fromEffectContext(core.as(f(context), context))));\n/** @internal */\nexport const tapError = /*#__PURE__*/dual(2, (self, f) => catchAll(self, e => fromEffectContext(core.flatMap(f(e), () => core.fail(e)))));\n/** @internal */\nexport const tapErrorCause = /*#__PURE__*/dual(2, (self, f) => catchAllCause(self, cause => fromEffectContext(core.flatMap(f(cause), () => core.failCause(cause)))));\n/** @internal */\nexport const toRuntime = self => pipe(fiberRuntime.scopeWith(scope => buildWithScope(self, scope)), core.flatMap(context => pipe(runtime.runtime(), core.provideContext(context))));\n/** @internal */\nexport const toRuntimeWithMemoMap = /*#__PURE__*/dual(2, (self, memoMap) => core.flatMap(fiberRuntime.scopeWith(scope => buildWithMemoMap(self, memoMap, scope)), context => pipe(runtime.runtime(), core.provideContext(context))));\n/** @internal */\nexport const provide = /*#__PURE__*/dual(2, (that, self) => suspend(() => {\n  const provideTo = Object.create(proto);\n  provideTo._tag = OpCodes.OP_PROVIDE;\n  provideTo.first = Object.create(proto, {\n    _tag: {\n      value: OpCodes.OP_PROVIDE_MERGE,\n      enumerable: true\n    },\n    first: {\n      value: context(),\n      enumerable: true\n    },\n    second: {\n      value: self\n    },\n    zipK: {\n      value: (a, b) => pipe(a, Context.merge(b))\n    }\n  });\n  provideTo.second = that;\n  return provideTo;\n}));\n/** @internal */\nexport const provideMerge = /*#__PURE__*/dual(2, (that, self) => {\n  const zipWith = Object.create(proto);\n  zipWith._tag = OpCodes.OP_PROVIDE_MERGE;\n  zipWith.first = self;\n  zipWith.second = provide(that, self);\n  zipWith.zipK = (a, b) => {\n    return pipe(a, Context.merge(b));\n  };\n  return zipWith;\n});\n/** @internal */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => suspend(() => {\n  const zipWith = Object.create(proto);\n  zipWith._tag = OpCodes.OP_ZIP_WITH;\n  zipWith.first = self;\n  zipWith.second = that;\n  zipWith.zipK = f;\n  return zipWith;\n}));\n/** @internal */\nexport const unwrapEffect = self => {\n  const tag = Context.GenericTag(\"effect/Layer/unwrapEffect/Layer.Layer<R1, E1, A>\");\n  return flatMap(fromEffect(tag, self), context => Context.get(context, tag));\n};\n/** @internal */\nexport const unwrapScoped = self => {\n  const tag = Context.GenericTag(\"effect/Layer/unwrapScoped/Layer.Layer<R1, E1, A>\");\n  return flatMap(scoped(tag, self), context => Context.get(context, tag));\n};\n// -----------------------------------------------------------------------------\n// logging\n// -----------------------------------------------------------------------------\nexport const annotateLogs = /*#__PURE__*/dual(args => isLayer(args[0]), function () {\n  const args = arguments;\n  return fiberRefLocallyWith(args[0], core.currentLogAnnotations, typeof args[1] === \"string\" ? HashMap.set(args[1], args[2]) : annotations => Object.entries(args[1]).reduce((acc, [key, value]) => HashMap.set(acc, key, value), annotations));\n});\n// -----------------------------------------------------------------------------\n// tracing\n// -----------------------------------------------------------------------------\nexport const annotateSpans = /*#__PURE__*/dual(args => isLayer(args[0]), function () {\n  const args = arguments;\n  return fiberRefLocallyWith(args[0], core.currentTracerSpanAnnotations, typeof args[1] === \"string\" ? HashMap.set(args[1], args[2]) : annotations => Object.entries(args[1]).reduce((acc, [key, value]) => HashMap.set(acc, key, value), annotations));\n});\n/** @internal */\nexport const withSpan = function () {\n  const dataFirst = typeof arguments[0] !== \"string\";\n  const name = dataFirst ? arguments[1] : arguments[0];\n  const options = tracer.addSpanStackTrace(dataFirst ? arguments[2] : arguments[1]);\n  if (dataFirst) {\n    const self = arguments[0];\n    return unwrapScoped(core.map(options?.onEnd ? core.tap(fiberRuntime.makeSpanScoped(name, options), span => fiberRuntime.addFinalizer(exit => options.onEnd(span, exit))) : fiberRuntime.makeSpanScoped(name, options), span => withParentSpan(self, span)));\n  }\n  return self => unwrapScoped(core.map(options?.onEnd ? core.tap(fiberRuntime.makeSpanScoped(name, options), span => fiberRuntime.addFinalizer(exit => options.onEnd(span, exit))) : fiberRuntime.makeSpanScoped(name, options), span => withParentSpan(self, span)));\n};\n/** @internal */\nexport const withParentSpan = /*#__PURE__*/dual(2, (self, span) => provide(self, succeedContext(Context.make(tracer.spanTag, span))));\n// circular with Effect\nconst provideSomeLayer = /*#__PURE__*/dual(2, (self, layer) => core.acquireUseRelease(fiberRuntime.scopeMake(), scope => core.flatMap(buildWithScope(layer, scope), context => core.provideSomeContext(self, context)), (scope, exit) => core.scopeClose(scope, exit)));\nconst provideSomeRuntime = /*#__PURE__*/dual(2, (self, rt) => {\n  const patchRefs = FiberRefsPatch.diff(runtime.defaultRuntime.fiberRefs, rt.fiberRefs);\n  const patchFlags = runtimeFlags.diff(runtime.defaultRuntime.runtimeFlags, rt.runtimeFlags);\n  return core.uninterruptibleMask(restore => core.withFiberRuntime(fiber => {\n    const oldContext = fiber.getFiberRef(core.currentContext);\n    const oldRefs = fiber.getFiberRefs();\n    const newRefs = FiberRefsPatch.patch(fiber.id(), oldRefs)(patchRefs);\n    const oldFlags = fiber._runtimeFlags;\n    const newFlags = runtimeFlags.patch(patchFlags)(oldFlags);\n    const rollbackRefs = FiberRefsPatch.diff(newRefs, oldRefs);\n    const rollbackFlags = runtimeFlags.diff(newFlags, oldFlags);\n    fiber.setFiberRefs(newRefs);\n    fiber._runtimeFlags = newFlags;\n    return fiberRuntime.ensuring(core.provideSomeContext(restore(self), Context.merge(oldContext, rt.context)), core.withFiberRuntime(fiber => {\n      fiber.setFiberRefs(FiberRefsPatch.patch(fiber.id(), fiber.getFiberRefs())(rollbackRefs));\n      fiber._runtimeFlags = runtimeFlags.patch(rollbackFlags)(fiber._runtimeFlags);\n      return core.void;\n    }));\n  }));\n});\n/** @internal */\nexport const effect_provide = /*#__PURE__*/dual(2, (self, source) => isLayer(source) ? provideSomeLayer(self, source) : Context.isContext(source) ? core.provideSomeContext(self, source) : provideSomeRuntime(self, source));\n//# sourceMappingURL=layer.js.map","import * as Context from \"../../Context.js\";\nimport { dual } from \"../../Function.js\";\nimport * as HashSet from \"../../HashSet.js\";\nimport * as core from \"../core.js\";\nimport * as fiberRuntime from \"../fiberRuntime.js\";\nimport * as layer from \"../layer.js\";\nimport * as runtimeFlags from \"../runtimeFlags.js\";\nimport * as runtimeFlagsPatch from \"../runtimeFlagsPatch.js\";\nimport * as _supervisor from \"../supervisor.js\";\nimport * as tracer from \"../tracer.js\";\n// circular with Logger\n/** @internal */\nexport const minimumLogLevel = level => layer.scopedDiscard(fiberRuntime.fiberRefLocallyScoped(fiberRuntime.currentMinimumLogLevel, level));\n/** @internal */\nexport const withMinimumLogLevel = /*#__PURE__*/dual(2, (self, level) => core.fiberRefLocally(fiberRuntime.currentMinimumLogLevel, level)(self));\n/** @internal */\nexport const addLogger = logger => layer.scopedDiscard(fiberRuntime.fiberRefLocallyScopedWith(fiberRuntime.currentLoggers, HashSet.add(logger)));\n/** @internal */\nexport const addLoggerEffect = effect => layer.unwrapEffect(core.map(effect, addLogger));\n/** @internal */\nexport const addLoggerScoped = effect => layer.unwrapScoped(core.map(effect, addLogger));\n/** @internal */\nexport const removeLogger = logger => layer.scopedDiscard(fiberRuntime.fiberRefLocallyScopedWith(fiberRuntime.currentLoggers, HashSet.remove(logger)));\n/** @internal */\nexport const replaceLogger = /*#__PURE__*/dual(2, (self, that) => layer.flatMap(removeLogger(self), () => addLogger(that)));\n/** @internal */\nexport const replaceLoggerEffect = /*#__PURE__*/dual(2, (self, that) => layer.flatMap(removeLogger(self), () => addLoggerEffect(that)));\n/** @internal */\nexport const replaceLoggerScoped = /*#__PURE__*/dual(2, (self, that) => layer.flatMap(removeLogger(self), () => addLoggerScoped(that)));\n/** @internal */\nexport const addSupervisor = supervisor => layer.scopedDiscard(fiberRuntime.fiberRefLocallyScopedWith(fiberRuntime.currentSupervisor, current => new _supervisor.Zip(current, supervisor)));\n/** @internal */\nexport const enableCooperativeYielding = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.enable(runtimeFlags.CooperativeYielding)));\n/** @internal */\nexport const enableInterruption = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.enable(runtimeFlags.Interruption)));\n/** @internal */\nexport const enableOpSupervision = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.enable(runtimeFlags.OpSupervision)));\n/** @internal */\nexport const enableRuntimeMetrics = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.enable(runtimeFlags.RuntimeMetrics)));\n/** @internal */\nexport const enableWindDown = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.enable(runtimeFlags.WindDown)));\n/** @internal */\nexport const disableCooperativeYielding = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.disable(runtimeFlags.CooperativeYielding)));\n/** @internal */\nexport const disableInterruption = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.disable(runtimeFlags.Interruption)));\n/** @internal */\nexport const disableOpSupervision = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.disable(runtimeFlags.OpSupervision)));\n/** @internal */\nexport const disableRuntimeMetrics = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.disable(runtimeFlags.RuntimeMetrics)));\n/** @internal */\nexport const disableWindDown = /*#__PURE__*/layer.scopedDiscard( /*#__PURE__*/fiberRuntime.withRuntimeFlagsScoped( /*#__PURE__*/runtimeFlagsPatch.disable(runtimeFlags.WindDown)));\n/** @internal */\nexport const setConfigProvider = configProvider => layer.scopedDiscard(fiberRuntime.withConfigProviderScoped(configProvider));\n/** @internal */\nexport const parentSpan = span => layer.succeedContext(Context.make(tracer.spanTag, span));\n/** @internal */\nexport const span = (name, options) => {\n  options = tracer.addSpanStackTrace(options);\n  return layer.scoped(tracer.spanTag, options?.onEnd ? core.tap(fiberRuntime.makeSpanScoped(name, options), span => fiberRuntime.addFinalizer(exit => options.onEnd(span, exit))) : fiberRuntime.makeSpanScoped(name, options));\n};\n/** @internal */\nexport const setTracer = tracer => layer.scopedDiscard(fiberRuntime.withTracerScoped(tracer));\n//# sourceMappingURL=circular.js.map","/** @internal */\nexport const make = (label, startTime) => ({\n  label,\n  startTime\n});\n/** @internal */\nexport const render = now => self => {\n  const label = self.label.replace(/[\\s=\"]/g, \"_\");\n  return `${label}=${now - self.startTime}ms`;\n};\n//# sourceMappingURL=logSpan.js.map","import * as Cause from \"../Cause.js\";\nimport { dual } from \"../Function.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport * as List from \"../List.js\";\nimport * as core from \"./core.js\";\nimport * as _fiberId from \"./fiberId.js\";\nimport * as fiberRefs from \"./fiberRefs.js\";\n/** @internal */\nexport const test = /*#__PURE__*/dual(2, (self, input) => self.log({\n  fiberId: _fiberId.none,\n  logLevel: core.logLevelInfo,\n  message: input,\n  cause: Cause.empty,\n  context: fiberRefs.empty(),\n  spans: List.empty(),\n  annotations: HashMap.empty(),\n  date: new Date()\n}));\n//# sourceMappingURL=logger-circular.js.map","import * as Arr from \"../Array.js\";\nimport * as Context from \"../Context.js\";\nimport * as FiberRefs from \"../FiberRefs.js\";\nimport { constVoid, dual, pipe } from \"../Function.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport * as Inspectable from \"../Inspectable.js\";\nimport * as List from \"../List.js\";\nimport * as LogSpan from \"../LogSpan.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport * as Cause from \"./cause.js\";\nimport * as defaultServices from \"./defaultServices.js\";\nimport { consoleTag } from \"./defaultServices/console.js\";\nimport * as _fiberId from \"./fiberId.js\";\n/** @internal */\nconst LoggerSymbolKey = \"effect/Logger\";\n/** @internal */\nexport const LoggerTypeId = /*#__PURE__*/Symbol.for(LoggerSymbolKey);\nconst loggerVariance = {\n  /* c8 ignore next */\n  _Message: _ => _,\n  /* c8 ignore next */\n  _Output: _ => _\n};\n/** @internal */\nexport const makeLogger = log => ({\n  [LoggerTypeId]: loggerVariance,\n  log,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n});\n/** @internal */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => makeLogger(options => self.log({\n  ...options,\n  message: f(options.message)\n})));\n/** @internal */\nexport const mapInputOptions = /*#__PURE__*/dual(2, (self, f) => makeLogger(options => self.log(f(options))));\n/** @internal */\nexport const filterLogLevel = /*#__PURE__*/dual(2, (self, f) => makeLogger(options => f(options.logLevel) ? Option.some(self.log(options)) : Option.none()));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => makeLogger(options => f(self.log(options))));\n/** @internal */\nexport const none = {\n  [LoggerTypeId]: loggerVariance,\n  log: constVoid,\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\n/** @internal */\nexport const simple = log => ({\n  [LoggerTypeId]: loggerVariance,\n  log: ({\n    message\n  }) => log(message),\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n});\n/** @internal */\nexport const succeed = value => {\n  return simple(() => value);\n};\n/** @internal */\nexport const sync = evaluate => {\n  return simple(evaluate);\n};\n/** @internal */\nexport const zip = /*#__PURE__*/dual(2, (self, that) => makeLogger(options => [self.log(options), that.log(options)]));\n/** @internal */\nexport const zipLeft = /*#__PURE__*/dual(2, (self, that) => map(zip(self, that), tuple => tuple[0]));\n/** @internal */\nexport const zipRight = /*#__PURE__*/dual(2, (self, that) => map(zip(self, that), tuple => tuple[1]));\n/** @internal */\nexport const stringLogger = /*#__PURE__*/makeLogger(({\n  annotations,\n  cause,\n  date,\n  fiberId,\n  logLevel,\n  message,\n  spans\n}) => {\n  const nowMillis = date.getTime();\n  const outputArray = [`timestamp=${date.toISOString()}`, `level=${logLevel.label}`, `fiber=${_fiberId.threadName(fiberId)}`];\n  let output = outputArray.join(\" \");\n  const messageArr = Arr.ensure(message);\n  for (let i = 0; i < messageArr.length; i++) {\n    const stringMessage = Inspectable.toStringUnknown(messageArr[i]);\n    if (stringMessage.length > 0) {\n      output = output + \" message=\";\n      output = appendQuoted(stringMessage, output);\n    }\n  }\n  if (cause != null && cause._tag !== \"Empty\") {\n    output = output + \" cause=\";\n    output = appendQuoted(Cause.pretty(cause, {\n      renderErrorCause: true\n    }), output);\n  }\n  if (List.isCons(spans)) {\n    output = output + \" \";\n    let first = true;\n    for (const span of spans) {\n      if (first) {\n        first = false;\n      } else {\n        output = output + \" \";\n      }\n      output = output + pipe(span, LogSpan.render(nowMillis));\n    }\n  }\n  if (HashMap.size(annotations) > 0) {\n    output = output + \" \";\n    let first = true;\n    for (const [key, value] of annotations) {\n      if (first) {\n        first = false;\n      } else {\n        output = output + \" \";\n      }\n      output = output + filterKeyName(key);\n      output = output + \"=\";\n      output = appendQuoted(Inspectable.toStringUnknown(value), output);\n    }\n  }\n  return output;\n});\n/** @internal */\nconst escapeDoubleQuotes = str => `\"${str.replace(/\\\\([\\s\\S])|(\")/g, \"\\\\$1$2\")}\"`;\nconst textOnly = /^[^\\s\"=]+$/;\n/** @internal */\nconst appendQuoted = (label, output) => output + (label.match(textOnly) ? label : escapeDoubleQuotes(label));\n/** @internal */\nexport const logfmtLogger = /*#__PURE__*/makeLogger(({\n  annotations,\n  cause,\n  date,\n  fiberId,\n  logLevel,\n  message,\n  spans\n}) => {\n  const nowMillis = date.getTime();\n  const outputArray = [`timestamp=${date.toISOString()}`, `level=${logLevel.label}`, `fiber=${_fiberId.threadName(fiberId)}`];\n  let output = outputArray.join(\" \");\n  const messageArr = Arr.ensure(message);\n  for (let i = 0; i < messageArr.length; i++) {\n    const stringMessage = Inspectable.toStringUnknown(messageArr[i], 0);\n    if (stringMessage.length > 0) {\n      output = output + \" message=\";\n      output = appendQuotedLogfmt(stringMessage, output);\n    }\n  }\n  if (cause != null && cause._tag !== \"Empty\") {\n    output = output + \" cause=\";\n    output = appendQuotedLogfmt(Cause.pretty(cause, {\n      renderErrorCause: true\n    }), output);\n  }\n  if (List.isCons(spans)) {\n    output = output + \" \";\n    let first = true;\n    for (const span of spans) {\n      if (first) {\n        first = false;\n      } else {\n        output = output + \" \";\n      }\n      output = output + pipe(span, renderLogSpanLogfmt(nowMillis));\n    }\n  }\n  if (HashMap.size(annotations) > 0) {\n    output = output + \" \";\n    let first = true;\n    for (const [key, value] of annotations) {\n      if (first) {\n        first = false;\n      } else {\n        output = output + \" \";\n      }\n      output = output + filterKeyName(key);\n      output = output + \"=\";\n      output = appendQuotedLogfmt(Inspectable.toStringUnknown(value, 0), output);\n    }\n  }\n  return output;\n});\n/** @internal */\nexport const structuredLogger = /*#__PURE__*/makeLogger(({\n  annotations,\n  cause,\n  date,\n  fiberId,\n  logLevel,\n  message,\n  spans\n}) => {\n  const now = date.getTime();\n  const annotationsObj = {};\n  const spansObj = {};\n  if (HashMap.size(annotations) > 0) {\n    for (const [k, v] of annotations) {\n      annotationsObj[k] = structuredMessage(v);\n    }\n  }\n  if (List.isCons(spans)) {\n    for (const span of spans) {\n      spansObj[span.label] = now - span.startTime;\n    }\n  }\n  const messageArr = Arr.ensure(message);\n  return {\n    message: messageArr.length === 1 ? structuredMessage(messageArr[0]) : messageArr.map(structuredMessage),\n    logLevel: logLevel.label,\n    timestamp: date.toISOString(),\n    cause: Cause.isEmpty(cause) ? undefined : Cause.pretty(cause, {\n      renderErrorCause: true\n    }),\n    annotations: annotationsObj,\n    spans: spansObj,\n    fiberId: _fiberId.threadName(fiberId)\n  };\n});\nexport const structuredMessage = u => {\n  switch (typeof u) {\n    case \"bigint\":\n    case \"function\":\n    case \"symbol\":\n      {\n        return String(u);\n      }\n    default:\n      {\n        return u;\n      }\n  }\n};\n/** @internal */\nexport const jsonLogger = /*#__PURE__*/map(structuredLogger, Inspectable.stringifyCircular);\n/** @internal */\nconst filterKeyName = key => key.replace(/[\\s=\"]/g, \"_\");\n/** @internal */\nconst escapeDoubleQuotesLogfmt = str => JSON.stringify(str);\n/** @internal */\nconst appendQuotedLogfmt = (label, output) => output + (label.match(textOnly) ? label : escapeDoubleQuotesLogfmt(label));\n/** @internal */\nconst renderLogSpanLogfmt = now => self => {\n  const label = filterKeyName(self.label);\n  return `${label}=${now - self.startTime}ms`;\n};\n/** @internal */\nexport const isLogger = u => {\n  return typeof u === \"object\" && u != null && LoggerTypeId in u;\n};\nconst withColor = (text, ...colors) => {\n  let out = \"\";\n  for (let i = 0; i < colors.length; i++) {\n    out += `\\x1b[${colors[i]}m`;\n  }\n  return out + text + \"\\x1b[0m\";\n};\nconst withColorNoop = (text, ..._colors) => text;\nconst colors = {\n  bold: \"1\",\n  red: \"31\",\n  green: \"32\",\n  yellow: \"33\",\n  blue: \"34\",\n  cyan: \"36\",\n  white: \"37\",\n  gray: \"90\",\n  black: \"30\",\n  bgBrightRed: \"101\"\n};\nconst logLevelColors = {\n  None: [],\n  All: [],\n  Trace: [colors.gray],\n  Debug: [colors.blue],\n  Info: [colors.green],\n  Warning: [colors.yellow],\n  Error: [colors.red],\n  Fatal: [colors.bgBrightRed, colors.black]\n};\nconst logLevelStyle = {\n  None: \"\",\n  All: \"\",\n  Trace: \"color:gray\",\n  Debug: \"color:blue\",\n  Info: \"color:green\",\n  Warning: \"color:orange\",\n  Error: \"color:red\",\n  Fatal: \"background-color:red;color:white\"\n};\nconst defaultDateFormat = date => `${date.getHours().toString().padStart(2, \"0\")}:${date.getMinutes().toString().padStart(2, \"0\")}:${date.getSeconds().toString().padStart(2, \"0\")}.${date.getMilliseconds().toString().padStart(3, \"0\")}`;\nconst processStdoutIsTTY = typeof process === \"object\" && process !== null && typeof process.stdout === \"object\" && process.stdout !== null && process.stdout.isTTY === true;\nconst hasWindow = typeof window === \"object\";\nconst isWorker = typeof self === \"object\" && self !== null && typeof self.constructor === \"function\" && /*#__PURE__*/self.constructor.name.includes(\"Worker\");\n/** @internal */\nexport const prettyLogger = options => {\n  const mode_ = options?.mode ?? \"auto\";\n  const mode = mode_ === \"auto\" ? hasWindow || isWorker ? \"browser\" : \"tty\" : mode_;\n  const isBrowser = mode === \"browser\";\n  const showColors = typeof options?.colors === \"boolean\" ? options.colors : processStdoutIsTTY || isBrowser;\n  const formatDate = options?.formatDate ?? defaultDateFormat;\n  return isBrowser ? prettyLoggerBrowser({\n    colors: showColors,\n    formatDate\n  }) : prettyLoggerTty({\n    colors: showColors,\n    formatDate,\n    stderr: options?.stderr === true\n  });\n};\nconst prettyLoggerTty = options => {\n  const processIsBun = typeof process === \"object\" && \"isBun\" in process && process.isBun === true;\n  const color = options.colors && processStdoutIsTTY ? withColor : withColorNoop;\n  return makeLogger(({\n    annotations,\n    cause,\n    context,\n    date,\n    fiberId,\n    logLevel,\n    message: message_,\n    spans\n  }) => {\n    const services = FiberRefs.getOrDefault(context, defaultServices.currentServices);\n    const console = Context.get(services, consoleTag).unsafe;\n    const log = options.stderr === true ? console.error : console.log;\n    const message = Arr.ensure(message_);\n    let firstLine = color(`[${options.formatDate(date)}]`, colors.white) + ` ${color(logLevel.label, ...logLevelColors[logLevel._tag])}` + ` (${_fiberId.threadName(fiberId)})`;\n    if (List.isCons(spans)) {\n      const now = date.getTime();\n      const render = renderLogSpanLogfmt(now);\n      for (const span of spans) {\n        firstLine += \" \" + render(span);\n      }\n    }\n    firstLine += \":\";\n    let messageIndex = 0;\n    if (message.length > 0) {\n      const firstMaybeString = structuredMessage(message[0]);\n      if (typeof firstMaybeString === \"string\") {\n        firstLine += \" \" + color(firstMaybeString, colors.bold, colors.cyan);\n        messageIndex++;\n      }\n    }\n    log(firstLine);\n    if (!processIsBun) console.group();\n    if (!Cause.isEmpty(cause)) {\n      log(Cause.pretty(cause, {\n        renderErrorCause: true\n      }));\n    }\n    if (messageIndex < message.length) {\n      for (; messageIndex < message.length; messageIndex++) {\n        log(message[messageIndex]);\n      }\n    }\n    if (HashMap.size(annotations) > 0) {\n      for (const [key, value] of annotations) {\n        log(color(`${key}:`, colors.bold, colors.white), value);\n      }\n    }\n    if (!processIsBun) console.groupEnd();\n  });\n};\nconst prettyLoggerBrowser = options => {\n  const color = options.colors ? \"%c\" : \"\";\n  return makeLogger(({\n    annotations,\n    cause,\n    context,\n    date,\n    fiberId,\n    logLevel,\n    message: message_,\n    spans\n  }) => {\n    const services = FiberRefs.getOrDefault(context, defaultServices.currentServices);\n    const console = Context.get(services, consoleTag).unsafe;\n    const message = Arr.ensure(message_);\n    let firstLine = `${color}[${options.formatDate(date)}]`;\n    const firstParams = [];\n    if (options.colors) {\n      firstParams.push(\"color:gray\");\n    }\n    firstLine += ` ${color}${logLevel.label}${color} (${_fiberId.threadName(fiberId)})`;\n    if (options.colors) {\n      firstParams.push(logLevelStyle[logLevel._tag], \"\");\n    }\n    if (List.isCons(spans)) {\n      const now = date.getTime();\n      const render = renderLogSpanLogfmt(now);\n      for (const span of spans) {\n        firstLine += \" \" + render(span);\n      }\n    }\n    firstLine += \":\";\n    let messageIndex = 0;\n    if (message.length > 0) {\n      const firstMaybeString = structuredMessage(message[0]);\n      if (typeof firstMaybeString === \"string\") {\n        firstLine += ` ${color}${firstMaybeString}`;\n        if (options.colors) {\n          firstParams.push(\"color:deepskyblue\");\n        }\n        messageIndex++;\n      }\n    }\n    console.groupCollapsed(firstLine, ...firstParams);\n    if (!Cause.isEmpty(cause)) {\n      console.error(Cause.pretty(cause, {\n        renderErrorCause: true\n      }));\n    }\n    if (messageIndex < message.length) {\n      for (; messageIndex < message.length; messageIndex++) {\n        console.log(message[messageIndex]);\n      }\n    }\n    if (HashMap.size(annotations) > 0) {\n      for (const [key, value] of annotations) {\n        if (options.colors) {\n          console.log(`%c${key}:`, \"color:gray\", value);\n        } else {\n          console.log(`${key}:`, value);\n        }\n      }\n    }\n    console.groupEnd();\n  });\n};\n//# sourceMappingURL=logger.js.map","import { pipeArguments } from \"../Pipeable.js\";\nimport * as Scope from \"../Scope.js\";\nimport * as effect from \"./core-effect.js\";\nimport * as core from \"./core.js\";\nimport * as fiberRuntime from \"./fiberRuntime.js\";\nimport * as internalLayer from \"./layer.js\";\nimport * as internalRuntime from \"./runtime.js\";\nfunction provide(managed, effect) {\n  return core.flatMap(managed.runtimeEffect, rt => core.withFiberRuntime(fiber => {\n    fiber.setFiberRefs(rt.fiberRefs);\n    fiber._runtimeFlags = rt.runtimeFlags;\n    return core.provideContext(effect, rt.context);\n  }));\n}\n/** @internal */\nexport const make = (layer, memoMap) => {\n  memoMap = memoMap ?? internalLayer.unsafeMakeMemoMap();\n  const scope = internalRuntime.unsafeRunSyncEffect(fiberRuntime.scopeMake());\n  const self = {\n    memoMap,\n    scope,\n    runtimeEffect: internalRuntime.unsafeRunSyncEffect(effect.memoize(core.tap(Scope.extend(internalLayer.toRuntimeWithMemoMap(layer, memoMap), scope), rt => {\n      self.cachedRuntime = rt;\n    }))),\n    cachedRuntime: undefined,\n    pipe() {\n      return pipeArguments(this, arguments);\n    },\n    runtime() {\n      return self.cachedRuntime === undefined ? internalRuntime.unsafeRunPromiseEffect(self.runtimeEffect) : Promise.resolve(self.cachedRuntime);\n    },\n    dispose() {\n      return internalRuntime.unsafeRunPromiseEffect(self.disposeEffect);\n    },\n    disposeEffect: core.suspend(() => {\n      ;\n      self.runtime = core.die(\"ManagedRuntime disposed\");\n      self.cachedRuntime = undefined;\n      return Scope.close(self.scope, core.exitVoid);\n    }),\n    runFork(effect, options) {\n      return self.cachedRuntime === undefined ? internalRuntime.unsafeForkEffect(provide(self, effect), options) : internalRuntime.unsafeFork(self.cachedRuntime)(effect, options);\n    },\n    runSyncExit(effect) {\n      return self.cachedRuntime === undefined ? internalRuntime.unsafeRunSyncExitEffect(provide(self, effect)) : internalRuntime.unsafeRunSyncExit(self.cachedRuntime)(effect);\n    },\n    runSync(effect) {\n      return self.cachedRuntime === undefined ? internalRuntime.unsafeRunSyncEffect(provide(self, effect)) : internalRuntime.unsafeRunSync(self.cachedRuntime)(effect);\n    },\n    runPromiseExit(effect, options) {\n      return self.cachedRuntime === undefined ? internalRuntime.unsafeRunPromiseExitEffect(provide(self, effect), options) : internalRuntime.unsafeRunPromiseExit(self.cachedRuntime)(effect, options);\n    },\n    runCallback(effect, options) {\n      return self.cachedRuntime === undefined ? internalRuntime.unsafeRunCallback(internalRuntime.defaultRuntime)(provide(self, effect), options) : internalRuntime.unsafeRunCallback(self.cachedRuntime)(effect, options);\n    },\n    runPromise(effect, options) {\n      return self.cachedRuntime === undefined ? internalRuntime.unsafeRunPromiseEffect(provide(self, effect), options) : internalRuntime.unsafeRunPromise(self.cachedRuntime)(effect, options);\n    }\n  };\n  return self;\n};\n//# sourceMappingURL=managedRuntime.js.map","import * as Either from \"../Either.js\";\nimport { identity } from \"../Function.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\n/** @internal */\nexport const TypeId = /*#__PURE__*/Symbol.for(\"@effect/matcher/Matcher\");\nconst TypeMatcherProto = {\n  [TypeId]: {\n    _input: identity,\n    _filters: identity,\n    _remaining: identity,\n    _result: identity,\n    _return: identity\n  },\n  _tag: \"TypeMatcher\",\n  add(_case) {\n    return makeTypeMatcher([...this.cases, _case]);\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nfunction makeTypeMatcher(cases) {\n  const matcher = Object.create(TypeMatcherProto);\n  matcher.cases = cases;\n  return matcher;\n}\nconst ValueMatcherProto = {\n  [TypeId]: {\n    _input: identity,\n    _filters: identity,\n    _result: identity,\n    _return: identity\n  },\n  _tag: \"ValueMatcher\",\n  add(_case) {\n    if (this.value._tag === \"Right\") {\n      return this;\n    }\n    if (_case._tag === \"When\" && _case.guard(this.provided) === true) {\n      return makeValueMatcher(this.provided, Either.right(_case.evaluate(this.provided)));\n    } else if (_case._tag === \"Not\" && _case.guard(this.provided) === false) {\n      return makeValueMatcher(this.provided, Either.right(_case.evaluate(this.provided)));\n    }\n    return this;\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nfunction makeValueMatcher(provided, value) {\n  const matcher = Object.create(ValueMatcherProto);\n  matcher.provided = provided;\n  matcher.value = value;\n  return matcher;\n}\nconst makeWhen = (guard, evaluate) => ({\n  _tag: \"When\",\n  guard,\n  evaluate\n});\nconst makeNot = (guard, evaluate) => ({\n  _tag: \"Not\",\n  guard,\n  evaluate\n});\nconst makePredicate = pattern => {\n  if (typeof pattern === \"function\") {\n    return pattern;\n  } else if (Array.isArray(pattern)) {\n    const predicates = pattern.map(makePredicate);\n    const len = predicates.length;\n    return u => {\n      if (!Array.isArray(u)) {\n        return false;\n      }\n      for (let i = 0; i < len; i++) {\n        if (predicates[i](u[i]) === false) {\n          return false;\n        }\n      }\n      return true;\n    };\n  } else if (pattern !== null && typeof pattern === \"object\") {\n    const keysAndPredicates = Object.entries(pattern).map(([k, p]) => [k, makePredicate(p)]);\n    const len = keysAndPredicates.length;\n    return u => {\n      if (typeof u !== \"object\" || u === null) {\n        return false;\n      }\n      for (let i = 0; i < len; i++) {\n        const [key, predicate] = keysAndPredicates[i];\n        if (!(key in u) || predicate(u[key]) === false) {\n          return false;\n        }\n      }\n      return true;\n    };\n  }\n  return u => u === pattern;\n};\nconst makeOrPredicate = patterns => {\n  const predicates = patterns.map(makePredicate);\n  const len = predicates.length;\n  return u => {\n    for (let i = 0; i < len; i++) {\n      if (predicates[i](u) === true) {\n        return true;\n      }\n    }\n    return false;\n  };\n};\nconst makeAndPredicate = patterns => {\n  const predicates = patterns.map(makePredicate);\n  const len = predicates.length;\n  return u => {\n    for (let i = 0; i < len; i++) {\n      if (predicates[i](u) === false) {\n        return false;\n      }\n    }\n    return true;\n  };\n};\n/** @internal */\nexport const type = () => makeTypeMatcher([]);\n/** @internal */\nexport const value = i => makeValueMatcher(i, Either.left(i));\n/** @internal */\nexport const valueTags = fields => {\n  const match = tagsExhaustive(fields)(makeTypeMatcher([]));\n  return input => match(input);\n};\n/** @internal */\nexport const typeTags = () => fields => {\n  const match = tagsExhaustive(fields)(makeTypeMatcher([]));\n  return input => match(input);\n};\n/** @internal */\nexport const withReturnType = () => self => self;\n/** @internal */\nexport const when = (pattern, f) => self => self.add(makeWhen(makePredicate(pattern), f));\n/** @internal */\nexport const whenOr = (...args) => self => {\n  const onMatch = args[args.length - 1];\n  const patterns = args.slice(0, -1);\n  return self.add(makeWhen(makeOrPredicate(patterns), onMatch));\n};\n/** @internal */\nexport const whenAnd = (...args) => self => {\n  const onMatch = args[args.length - 1];\n  const patterns = args.slice(0, -1);\n  return self.add(makeWhen(makeAndPredicate(patterns), onMatch));\n};\n/** @internal */\nexport const discriminator = field => (...pattern) => {\n  const f = pattern[pattern.length - 1];\n  const values = pattern.slice(0, -1);\n  const pred = values.length === 1 ? _ => _[field] === values[0] : _ => values.includes(_[field]);\n  return self => self.add(makeWhen(pred, f));\n};\n/** @internal */\nexport const discriminatorStartsWith = field => (pattern, f) => {\n  const pred = _ => typeof _[field] === \"string\" && _[field].startsWith(pattern);\n  return self => self.add(makeWhen(pred, f));\n};\n/** @internal */\nexport const discriminators = field => fields => {\n  const predicate = makeWhen(_ => _[field] in fields, data => fields[data[field]](data));\n  return self => self.add(predicate);\n};\n/** @internal */\nexport const discriminatorsExhaustive = field => fields => {\n  const addCases = discriminators(field)(fields);\n  return matcher => exhaustive(addCases(matcher));\n};\n/** @internal */\nexport const tag = /*#__PURE__*/discriminator(\"_tag\");\n/** @internal */\nexport const tagStartsWith = /*#__PURE__*/discriminatorStartsWith(\"_tag\");\n/** @internal */\nexport const tags = /*#__PURE__*/discriminators(\"_tag\");\n/** @internal */\nexport const tagsExhaustive = /*#__PURE__*/discriminatorsExhaustive(\"_tag\");\n/** @internal */\nexport const not = (pattern, f) => self => self.add(makeNot(makePredicate(pattern), f));\n/** @internal */\nexport const nonEmptyString = u => typeof u === \"string\" && u.length > 0;\n/** @internal */\nexport const is = (...literals) => {\n  const len = literals.length;\n  return u => {\n    for (let i = 0; i < len; i++) {\n      if (u === literals[i]) {\n        return true;\n      }\n    }\n    return false;\n  };\n};\n/** @internal */\nexport const any = () => true;\n/** @internal */\nexport const defined = u => u !== undefined && u !== null;\n/** @internal */\nexport const instanceOf = constructor => u => u instanceof constructor;\n/** @internal */\nexport const instanceOfUnsafe = instanceOf;\n/** @internal */\nexport const orElse = f => self => {\n  const result = either(self);\n  if (Either.isEither(result)) {\n    // @ts-expect-error\n    return result._tag === \"Right\" ? result.right : f(result.left);\n  }\n  // @ts-expect-error\n  return input => {\n    const a = result(input);\n    return a._tag === \"Right\" ? a.right : f(a.left);\n  };\n};\n/** @internal */\nexport const orElseAbsurd = self => orElse(() => {\n  throw new Error(\"effect/Match/orElseAbsurd: absurd\");\n})(self);\n/** @internal */\nexport const either = self => {\n  if (self._tag === \"ValueMatcher\") {\n    return self.value;\n  }\n  const len = self.cases.length;\n  if (len === 1) {\n    const _case = self.cases[0];\n    return input => {\n      if (_case._tag === \"When\" && _case.guard(input) === true) {\n        return Either.right(_case.evaluate(input));\n      } else if (_case._tag === \"Not\" && _case.guard(input) === false) {\n        return Either.right(_case.evaluate(input));\n      }\n      return Either.left(input);\n    };\n  }\n  return input => {\n    for (let i = 0; i < len; i++) {\n      const _case = self.cases[i];\n      if (_case._tag === \"When\" && _case.guard(input) === true) {\n        return Either.right(_case.evaluate(input));\n      } else if (_case._tag === \"Not\" && _case.guard(input) === false) {\n        return Either.right(_case.evaluate(input));\n      }\n    }\n    return Either.left(input);\n  };\n};\n/** @internal */\nexport const option = self => {\n  const toEither = either(self);\n  if (Either.isEither(toEither)) {\n    return Either.match(toEither, {\n      onLeft: () => Option.none(),\n      onRight: Option.some\n    });\n  }\n  return input => Either.match(toEither(input), {\n    onLeft: () => Option.none(),\n    onRight: Option.some\n  });\n};\nconst getExhaustiveAbsurdErrorMessage = \"effect/Match/exhaustive: absurd\";\n/** @internal */\nexport const exhaustive = self => {\n  const toEither = either(self);\n  if (Either.isEither(toEither)) {\n    if (toEither._tag === \"Right\") {\n      return toEither.right;\n    }\n    throw new Error(getExhaustiveAbsurdErrorMessage);\n  }\n  return u => {\n    // @ts-expect-error\n    const result = toEither(u);\n    if (result._tag === \"Right\") {\n      return result.right;\n    }\n    throw new Error(getExhaustiveAbsurdErrorMessage);\n  };\n};\n//# sourceMappingURL=matcher.js.map","import * as Arr from \"../Array.js\";\nimport * as Clock from \"../Clock.js\";\nimport * as Duration from \"../Duration.js\";\nimport { constVoid, dual, identity, pipe } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport * as Cause from \"./cause.js\";\nimport * as _effect from \"./core-effect.js\";\nimport * as core from \"./core.js\";\nimport * as metricBoundaries from \"./metric/boundaries.js\";\nimport * as metricKey from \"./metric/key.js\";\nimport * as metricLabel from \"./metric/label.js\";\nimport * as metricRegistry from \"./metric/registry.js\";\n/** @internal */\nconst MetricSymbolKey = \"effect/Metric\";\n/** @internal */\nexport const MetricTypeId = /*#__PURE__*/Symbol.for(MetricSymbolKey);\nconst metricVariance = {\n  /* c8 ignore next */\n  _Type: _ => _,\n  /* c8 ignore next */\n  _In: _ => _,\n  /* c8 ignore next */\n  _Out: _ => _\n};\n/** @internal */\nexport const globalMetricRegistry = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/Metric/globalMetricRegistry\"), () => metricRegistry.make());\n/** @internal */\nexport const make = function (keyType, unsafeUpdate, unsafeValue) {\n  const metric = Object.assign(effect => core.tap(effect, a => update(metric, a)), {\n    [MetricTypeId]: metricVariance,\n    keyType,\n    unsafeUpdate,\n    unsafeValue,\n    register() {\n      this.unsafeValue([]);\n      return this;\n    },\n    pipe() {\n      return pipeArguments(this, arguments);\n    }\n  });\n  return metric;\n};\n/** @internal */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => make(self.keyType, (input, extraTags) => self.unsafeUpdate(f(input), extraTags), self.unsafeValue));\n/** @internal */\nexport const counter = (name, options) => fromMetricKey(metricKey.counter(name, options));\n/** @internal */\nexport const frequency = (name, options) => fromMetricKey(metricKey.frequency(name, options));\n/** @internal */\nexport const withConstantInput = /*#__PURE__*/dual(2, (self, input) => mapInput(self, () => input));\n/** @internal */\nexport const fromMetricKey = key => {\n  let untaggedHook;\n  const hookCache = new WeakMap();\n  const hook = extraTags => {\n    if (extraTags.length === 0) {\n      if (untaggedHook !== undefined) {\n        return untaggedHook;\n      }\n      untaggedHook = globalMetricRegistry.get(key);\n      return untaggedHook;\n    }\n    let hook = hookCache.get(extraTags);\n    if (hook !== undefined) {\n      return hook;\n    }\n    hook = globalMetricRegistry.get(metricKey.taggedWithLabels(key, extraTags));\n    hookCache.set(extraTags, hook);\n    return hook;\n  };\n  return make(key.keyType, (input, extraTags) => hook(extraTags).update(input), extraTags => hook(extraTags).get());\n};\n/** @internal */\nexport const gauge = (name, options) => fromMetricKey(metricKey.gauge(name, options));\n/** @internal */\nexport const histogram = (name, boundaries, description) => fromMetricKey(metricKey.histogram(name, boundaries, description));\n/* @internal */\nexport const increment = self => update(self, self.keyType.bigint ? BigInt(1) : 1);\n/* @internal */\nexport const incrementBy = /*#__PURE__*/dual(2, (self, amount) => update(self, amount));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => make(self.keyType, self.unsafeUpdate, extraTags => f(self.unsafeValue(extraTags))));\n/** @internal */\nexport const mapType = /*#__PURE__*/dual(2, (self, f) => make(f(self.keyType), self.unsafeUpdate, self.unsafeValue));\n/* @internal */\nexport const set = /*#__PURE__*/dual(2, (self, value) => update(self, value));\n/** @internal */\nexport const succeed = out => make(void 0, constVoid, () => out);\n/** @internal */\nexport const sync = evaluate => make(void 0, constVoid, evaluate);\n/** @internal */\nexport const summary = options => withNow(summaryTimestamp(options));\n/** @internal */\nexport const summaryTimestamp = options => fromMetricKey(metricKey.summary(options));\n/** @internal */\nexport const tagged = /*#__PURE__*/dual(3, (self, key, value) => taggedWithLabels(self, [metricLabel.make(key, value)]));\n/** @internal */\nexport const taggedWithLabelsInput = /*#__PURE__*/dual(2, (self, f) => map(make(self.keyType, (input, extraTags) => self.unsafeUpdate(input, Arr.union(f(input), extraTags)), self.unsafeValue), constVoid));\n/** @internal */\nexport const taggedWithLabels = /*#__PURE__*/dual(2, (self, extraTags) => {\n  return make(self.keyType, (input, extraTags1) => self.unsafeUpdate(input, Arr.union(extraTags, extraTags1)), extraTags1 => self.unsafeValue(Arr.union(extraTags, extraTags1)));\n});\n/** @internal */\nexport const timer = (name, description) => {\n  const boundaries = metricBoundaries.exponential({\n    start: 0.5,\n    factor: 2,\n    count: 35\n  });\n  const base = pipe(histogram(name, boundaries, description), tagged(\"time_unit\", \"milliseconds\"));\n  return mapInput(base, Duration.toMillis);\n};\n/** @internal */\nexport const timerWithBoundaries = (name, boundaries, description) => {\n  const base = pipe(histogram(name, metricBoundaries.fromIterable(boundaries), description), tagged(\"time_unit\", \"milliseconds\"));\n  return mapInput(base, Duration.toMillis);\n};\n/* @internal */\nexport const trackAll = /*#__PURE__*/dual(2, (self, input) => effect => core.matchCauseEffect(effect, {\n  onFailure: cause => core.zipRight(update(self, input), core.failCause(cause)),\n  onSuccess: value => core.zipRight(update(self, input), core.succeed(value))\n}));\n/* @internal */\nexport const trackDefect = /*#__PURE__*/dual(2, (self, metric) => trackDefectWith(self, metric, identity));\n/* @internal */\nexport const trackDefectWith = /*#__PURE__*/dual(3, (self, metric, f) => {\n  const updater = defect => update(metric, f(defect));\n  return _effect.tapDefect(self, cause => core.forEachSequentialDiscard(Cause.defects(cause), updater));\n});\n/* @internal */\nexport const trackDuration = /*#__PURE__*/dual(2, (self, metric) => trackDurationWith(self, metric, identity));\n/* @internal */\nexport const trackDurationWith = /*#__PURE__*/dual(3, (self, metric, f) => Clock.clockWith(clock => {\n  const startTime = clock.unsafeCurrentTimeNanos();\n  return core.tap(self, _ => {\n    const endTime = clock.unsafeCurrentTimeNanos();\n    const duration = Duration.nanos(endTime - startTime);\n    return update(metric, f(duration));\n  });\n}));\n/* @internal */\nexport const trackError = /*#__PURE__*/dual(2, (self, metric) => trackErrorWith(self, metric, a => a));\n/* @internal */\nexport const trackErrorWith = /*#__PURE__*/dual(3, (self, metric, f) => {\n  const updater = error => update(metric, f(error));\n  return _effect.tapError(self, updater);\n});\n/* @internal */\nexport const trackSuccess = /*#__PURE__*/dual(2, (self, metric) => trackSuccessWith(self, metric, a => a));\n/* @internal */\nexport const trackSuccessWith = /*#__PURE__*/dual(3, (self, metric, f) => {\n  const updater = value => update(metric, f(value));\n  return core.tap(self, updater);\n});\n/* @internal */\nexport const update = /*#__PURE__*/dual(2, (self, input) => core.fiberRefGetWith(core.currentMetricLabels, tags => core.sync(() => self.unsafeUpdate(input, tags))));\n/* @internal */\nexport const value = self => core.fiberRefGetWith(core.currentMetricLabels, tags => core.sync(() => self.unsafeValue(tags)));\n/** @internal */\nexport const withNow = self => mapInput(self, input => [input, Date.now()]);\n/** @internal */\nexport const zip = /*#__PURE__*/dual(2, (self, that) => make([self.keyType, that.keyType], (input, extraTags) => {\n  const [l, r] = input;\n  self.unsafeUpdate(l, extraTags);\n  that.unsafeUpdate(r, extraTags);\n}, extraTags => [self.unsafeValue(extraTags), that.unsafeValue(extraTags)]));\n/** @internal */\nexport const unsafeSnapshot = () => globalMetricRegistry.snapshot();\n/** @internal */\nexport const snapshot = /*#__PURE__*/core.sync(unsafeSnapshot);\n//# sourceMappingURL=metric.js.map","import * as Arr from \"../../Array.js\";\nimport * as Chunk from \"../../Chunk.js\";\nimport * as Equal from \"../../Equal.js\";\nimport { pipe } from \"../../Function.js\";\nimport * as Hash from \"../../Hash.js\";\nimport { pipeArguments } from \"../../Pipeable.js\";\nimport { hasProperty } from \"../../Predicate.js\";\n/** @internal */\nconst MetricBoundariesSymbolKey = \"effect/MetricBoundaries\";\n/** @internal */\nexport const MetricBoundariesTypeId = /*#__PURE__*/Symbol.for(MetricBoundariesSymbolKey);\n/** @internal */\nclass MetricBoundariesImpl {\n  values;\n  [MetricBoundariesTypeId] = MetricBoundariesTypeId;\n  constructor(values) {\n    this.values = values;\n    this._hash = pipe(Hash.string(MetricBoundariesSymbolKey), Hash.combine(Hash.array(this.values)));\n  }\n  _hash;\n  [Hash.symbol]() {\n    return this._hash;\n  }\n  [Equal.symbol](u) {\n    return isMetricBoundaries(u) && Equal.equals(this.values, u.values);\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const isMetricBoundaries = u => hasProperty(u, MetricBoundariesTypeId);\n/** @internal */\nexport const fromIterable = iterable => {\n  const values = pipe(iterable, Arr.appendAll(Chunk.of(Number.POSITIVE_INFINITY)), Arr.dedupe);\n  return new MetricBoundariesImpl(values);\n};\n/** @internal */\nexport const linear = options => pipe(Arr.makeBy(options.count - 1, i => options.start + i * options.width), Chunk.unsafeFromArray, fromIterable);\n/** @internal */\nexport const exponential = options => pipe(Arr.makeBy(options.count - 1, i => options.start * Math.pow(options.factor, i)), Chunk.unsafeFromArray, fromIterable);\n//# sourceMappingURL=boundaries.js.map","import * as Arr from \"../../Array.js\";\nimport * as Duration from \"../../Duration.js\";\nimport { dual, pipe } from \"../../Function.js\";\nimport * as number from \"../../Number.js\";\nimport * as Option from \"../../Option.js\";\nimport { pipeArguments } from \"../../Pipeable.js\";\nimport * as metricState from \"./state.js\";\n/** @internal */\nconst MetricHookSymbolKey = \"effect/MetricHook\";\n/** @internal */\nexport const MetricHookTypeId = /*#__PURE__*/Symbol.for(MetricHookSymbolKey);\nconst metricHookVariance = {\n  /* c8 ignore next */\n  _In: _ => _,\n  /* c8 ignore next */\n  _Out: _ => _\n};\n/** @internal */\nexport const make = options => ({\n  [MetricHookTypeId]: metricHookVariance,\n  pipe() {\n    return pipeArguments(this, arguments);\n  },\n  ...options\n});\n/** @internal */\nexport const onUpdate = /*#__PURE__*/dual(2, (self, f) => ({\n  [MetricHookTypeId]: metricHookVariance,\n  pipe() {\n    return pipeArguments(this, arguments);\n  },\n  get: self.get,\n  update: input => {\n    self.update(input);\n    return f(input);\n  }\n}));\nconst bigint0 = /*#__PURE__*/BigInt(0);\n/** @internal */\nexport const counter = key => {\n  let sum = key.keyType.bigint ? bigint0 : 0;\n  const canUpdate = key.keyType.incremental ? key.keyType.bigint ? value => value >= bigint0 : value => value >= 0 : _value => true;\n  return make({\n    get: () => metricState.counter(sum),\n    update: value => {\n      if (canUpdate(value)) {\n        sum = sum + value;\n      }\n    }\n  });\n};\n/** @internal */\nexport const frequency = key => {\n  const values = new Map();\n  for (const word of key.keyType.preregisteredWords) {\n    values.set(word, 0);\n  }\n  const update = word => {\n    const slotCount = values.get(word) ?? 0;\n    values.set(word, slotCount + 1);\n  };\n  return make({\n    get: () => metricState.frequency(values),\n    update\n  });\n};\n/** @internal */\nexport const gauge = (_key, startAt) => {\n  let value = startAt;\n  return make({\n    get: () => metricState.gauge(value),\n    update: v => {\n      value = v;\n    }\n  });\n};\n/** @internal */\nexport const histogram = key => {\n  const bounds = key.keyType.boundaries.values;\n  const size = bounds.length;\n  const values = new Uint32Array(size + 1);\n  const boundaries = new Float32Array(size);\n  let count = 0;\n  let sum = 0;\n  let min = Number.MAX_VALUE;\n  let max = Number.MIN_VALUE;\n  pipe(bounds, Arr.sort(number.Order), Arr.map((n, i) => {\n    boundaries[i] = n;\n  }));\n  // Insert the value into the right bucket with a binary search\n  const update = value => {\n    let from = 0;\n    let to = size;\n    while (from !== to) {\n      const mid = Math.floor(from + (to - from) / 2);\n      const boundary = boundaries[mid];\n      if (value <= boundary) {\n        to = mid;\n      } else {\n        from = mid;\n      }\n      // The special case when to / from have a distance of one\n      if (to === from + 1) {\n        if (value <= boundaries[from]) {\n          to = from;\n        } else {\n          from = to;\n        }\n      }\n    }\n    values[from] = values[from] + 1;\n    count = count + 1;\n    sum = sum + value;\n    if (value < min) {\n      min = value;\n    }\n    if (value > max) {\n      max = value;\n    }\n  };\n  const getBuckets = () => {\n    const builder = Arr.allocate(size);\n    let cumulated = 0;\n    for (let i = 0; i < size; i++) {\n      const boundary = boundaries[i];\n      const value = values[i];\n      cumulated = cumulated + value;\n      builder[i] = [boundary, cumulated];\n    }\n    return builder;\n  };\n  return make({\n    get: () => metricState.histogram({\n      buckets: getBuckets(),\n      count,\n      min,\n      max,\n      sum\n    }),\n    update\n  });\n};\n/** @internal */\nexport const summary = key => {\n  const {\n    error,\n    maxAge,\n    maxSize,\n    quantiles\n  } = key.keyType;\n  const sortedQuantiles = pipe(quantiles, Arr.sort(number.Order));\n  const values = Arr.allocate(maxSize);\n  let head = 0;\n  let count = 0;\n  let sum = 0;\n  let min = Number.MAX_VALUE;\n  let max = Number.MIN_VALUE;\n  // Just before the snapshot we filter out all values older than maxAge\n  const snapshot = now => {\n    const builder = [];\n    // If the buffer is not full yet it contains valid items at the 0..last\n    // indices and null values at the rest of the positions.\n    //\n    // If the buffer is already full then all elements contains a valid\n    // measurement with timestamp.\n    //\n    // At any given point in time we can enumerate all the non-null elements in\n    // the buffer and filter them by timestamp to get a valid view of a time\n    // window.\n    //\n    // The order does not matter because it gets sorted before passing to\n    // `calculateQuantiles`.\n    let i = 0;\n    while (i !== maxSize - 1) {\n      const item = values[i];\n      if (item != null) {\n        const [t, v] = item;\n        const age = Duration.millis(now - t);\n        if (Duration.greaterThanOrEqualTo(age, Duration.zero) && age <= maxAge) {\n          builder.push(v);\n        }\n      }\n      i = i + 1;\n    }\n    return calculateQuantiles(error, sortedQuantiles, Arr.sort(builder, number.Order));\n  };\n  const observe = (value, timestamp) => {\n    if (maxSize > 0) {\n      head = head + 1;\n      const target = head % maxSize;\n      values[target] = [timestamp, value];\n    }\n    count = count + 1;\n    sum = sum + value;\n    if (value < min) {\n      min = value;\n    }\n    if (value > max) {\n      max = value;\n    }\n  };\n  return make({\n    get: () => metricState.summary({\n      error,\n      quantiles: snapshot(Date.now()),\n      count,\n      min,\n      max,\n      sum\n    }),\n    update: ([value, timestamp]) => observe(value, timestamp)\n  });\n};\n/** @internal */\nconst calculateQuantiles = (error, sortedQuantiles, sortedSamples) => {\n  // The number of samples examined\n  const sampleCount = sortedSamples.length;\n  if (!Arr.isNonEmptyReadonlyArray(sortedQuantiles)) {\n    return Arr.empty();\n  }\n  const head = sortedQuantiles[0];\n  const tail = sortedQuantiles.slice(1);\n  const resolvedHead = resolveQuantile(error, sampleCount, Option.none(), 0, head, sortedSamples);\n  const resolved = Arr.of(resolvedHead);\n  tail.forEach(quantile => {\n    resolved.push(resolveQuantile(error, sampleCount, resolvedHead.value, resolvedHead.consumed, quantile, resolvedHead.rest));\n  });\n  return Arr.map(resolved, rq => [rq.quantile, rq.value]);\n};\n/** @internal */\nconst resolveQuantile = (error, sampleCount, current, consumed, quantile, rest) => {\n  let error_1 = error;\n  let sampleCount_1 = sampleCount;\n  let current_1 = current;\n  let consumed_1 = consumed;\n  let quantile_1 = quantile;\n  let rest_1 = rest;\n  let error_2 = error;\n  let sampleCount_2 = sampleCount;\n  let current_2 = current;\n  let consumed_2 = consumed;\n  let quantile_2 = quantile;\n  let rest_2 = rest;\n  // eslint-disable-next-line no-constant-condition\n  while (1) {\n    // If the remaining list of samples is empty, there is nothing more to resolve\n    if (!Arr.isNonEmptyReadonlyArray(rest_1)) {\n      return {\n        quantile: quantile_1,\n        value: Option.none(),\n        consumed: consumed_1,\n        rest: []\n      };\n    }\n    // If the quantile is the 100% quantile, we can take the maximum of all the\n    // remaining values as the result\n    if (quantile_1 === 1) {\n      return {\n        quantile: quantile_1,\n        value: Option.some(Arr.lastNonEmpty(rest_1)),\n        consumed: consumed_1 + rest_1.length,\n        rest: []\n      };\n    }\n    // Split into two chunks - the first chunk contains all elements of the same\n    // value as the chunk head\n    const sameHead = Arr.span(rest_1, n => n <= rest_1[0]);\n    // How many elements do we want to accept for this quantile\n    const desired = quantile_1 * sampleCount_1;\n    // The error margin\n    const allowedError = error_1 / 2 * desired;\n    // Taking into account the elements consumed from the samples so far and the\n    // number of same elements at the beginning of the chunk, calculate the number\n    // of elements we would have if we selected the current head as result\n    const candConsumed = consumed_1 + sameHead[0].length;\n    const candError = Math.abs(candConsumed - desired);\n    // If we haven't got enough elements yet, recurse\n    if (candConsumed < desired - allowedError) {\n      error_2 = error_1;\n      sampleCount_2 = sampleCount_1;\n      current_2 = Arr.head(rest_1);\n      consumed_2 = candConsumed;\n      quantile_2 = quantile_1;\n      rest_2 = sameHead[1];\n      error_1 = error_2;\n      sampleCount_1 = sampleCount_2;\n      current_1 = current_2;\n      consumed_1 = consumed_2;\n      quantile_1 = quantile_2;\n      rest_1 = rest_2;\n      continue;\n    }\n    // If we have too many elements, select the previous value and hand back the\n    // the rest as leftover\n    if (candConsumed > desired + allowedError) {\n      return {\n        quantile: quantile_1,\n        value: current_1,\n        consumed: consumed_1,\n        rest: rest_1\n      };\n    }\n    // If we are in the target interval, select the current head and hand back the leftover after dropping all elements\n    // from the sample chunk that are equal to the current head\n    switch (current_1._tag) {\n      case \"None\":\n        {\n          error_2 = error_1;\n          sampleCount_2 = sampleCount_1;\n          current_2 = Arr.head(rest_1);\n          consumed_2 = candConsumed;\n          quantile_2 = quantile_1;\n          rest_2 = sameHead[1];\n          error_1 = error_2;\n          sampleCount_1 = sampleCount_2;\n          current_1 = current_2;\n          consumed_1 = consumed_2;\n          quantile_1 = quantile_2;\n          rest_1 = rest_2;\n          continue;\n        }\n      case \"Some\":\n        {\n          const prevError = Math.abs(desired - current_1.value);\n          if (candError < prevError) {\n            error_2 = error_1;\n            sampleCount_2 = sampleCount_1;\n            current_2 = Arr.head(rest_1);\n            consumed_2 = candConsumed;\n            quantile_2 = quantile_1;\n            rest_2 = sameHead[1];\n            error_1 = error_2;\n            sampleCount_1 = sampleCount_2;\n            current_1 = current_2;\n            consumed_1 = consumed_2;\n            quantile_1 = quantile_2;\n            rest_1 = rest_2;\n            continue;\n          }\n          return {\n            quantile: quantile_1,\n            value: Option.some(current_1.value),\n            consumed: consumed_1,\n            rest: rest_1\n          };\n        }\n    }\n  }\n  throw new Error(\"BUG: MetricHook.resolveQuantiles - please report an issue at https://github.com/Effect-TS/effect/issues\");\n};\n//# sourceMappingURL=hook.js.map","import * as Arr from \"../../Array.js\";\nimport * as Equal from \"../../Equal.js\";\nimport { dual, pipe } from \"../../Function.js\";\nimport * as Hash from \"../../Hash.js\";\nimport * as Option from \"../../Option.js\";\nimport { pipeArguments } from \"../../Pipeable.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as metricKeyType from \"./keyType.js\";\nimport * as metricLabel from \"./label.js\";\n/** @internal */\nconst MetricKeySymbolKey = \"effect/MetricKey\";\n/** @internal */\nexport const MetricKeyTypeId = /*#__PURE__*/Symbol.for(MetricKeySymbolKey);\nconst metricKeyVariance = {\n  /* c8 ignore next */\n  _Type: _ => _\n};\nconst arrayEquivilence = /*#__PURE__*/Arr.getEquivalence(Equal.equals);\n/** @internal */\nclass MetricKeyImpl {\n  name;\n  keyType;\n  description;\n  tags;\n  [MetricKeyTypeId] = metricKeyVariance;\n  constructor(name, keyType, description, tags = []) {\n    this.name = name;\n    this.keyType = keyType;\n    this.description = description;\n    this.tags = tags;\n    this._hash = pipe(Hash.string(this.name + this.description), Hash.combine(Hash.hash(this.keyType)), Hash.combine(Hash.array(this.tags)));\n  }\n  _hash;\n  [Hash.symbol]() {\n    return this._hash;\n  }\n  [Equal.symbol](u) {\n    return isMetricKey(u) && this.name === u.name && Equal.equals(this.keyType, u.keyType) && Equal.equals(this.description, u.description) && arrayEquivilence(this.tags, u.tags);\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const isMetricKey = u => hasProperty(u, MetricKeyTypeId);\n/** @internal */\nexport const counter = (name, options) => new MetricKeyImpl(name, metricKeyType.counter(options), Option.fromNullable(options?.description));\n/** @internal */\nexport const frequency = (name, options) => new MetricKeyImpl(name, metricKeyType.frequency(options), Option.fromNullable(options?.description));\n/** @internal */\nexport const gauge = (name, options) => new MetricKeyImpl(name, metricKeyType.gauge(options), Option.fromNullable(options?.description));\n/** @internal */\nexport const histogram = (name, boundaries, description) => new MetricKeyImpl(name, metricKeyType.histogram(boundaries), Option.fromNullable(description));\n/** @internal */\nexport const summary = options => new MetricKeyImpl(options.name, metricKeyType.summary(options), Option.fromNullable(options.description));\n/** @internal */\nexport const tagged = /*#__PURE__*/dual(3, (self, key, value) => taggedWithLabels(self, [metricLabel.make(key, value)]));\n/** @internal */\nexport const taggedWithLabels = /*#__PURE__*/dual(2, (self, extraTags) => extraTags.length === 0 ? self : new MetricKeyImpl(self.name, self.keyType, self.description, Arr.union(self.tags, extraTags)));\n//# sourceMappingURL=key.js.map","import * as Duration from \"../../Duration.js\";\nimport * as Equal from \"../../Equal.js\";\nimport { pipe } from \"../../Function.js\";\nimport * as Hash from \"../../Hash.js\";\nimport { pipeArguments } from \"../../Pipeable.js\";\nimport { hasProperty } from \"../../Predicate.js\";\n/** @internal */\nconst MetricKeyTypeSymbolKey = \"effect/MetricKeyType\";\n/** @internal */\nexport const MetricKeyTypeTypeId = /*#__PURE__*/Symbol.for(MetricKeyTypeSymbolKey);\n/** @internal */\nconst CounterKeyTypeSymbolKey = \"effect/MetricKeyType/Counter\";\n/** @internal */\nexport const CounterKeyTypeTypeId = /*#__PURE__*/Symbol.for(CounterKeyTypeSymbolKey);\n/** @internal */\nconst FrequencyKeyTypeSymbolKey = \"effect/MetricKeyType/Frequency\";\n/** @internal */\nexport const FrequencyKeyTypeTypeId = /*#__PURE__*/Symbol.for(FrequencyKeyTypeSymbolKey);\n/** @internal */\nconst GaugeKeyTypeSymbolKey = \"effect/MetricKeyType/Gauge\";\n/** @internal */\nexport const GaugeKeyTypeTypeId = /*#__PURE__*/Symbol.for(GaugeKeyTypeSymbolKey);\n/** @internal */\nconst HistogramKeyTypeSymbolKey = \"effect/MetricKeyType/Histogram\";\n/** @internal */\nexport const HistogramKeyTypeTypeId = /*#__PURE__*/Symbol.for(HistogramKeyTypeSymbolKey);\n/** @internal */\nconst SummaryKeyTypeSymbolKey = \"effect/MetricKeyType/Summary\";\n/** @internal */\nexport const SummaryKeyTypeTypeId = /*#__PURE__*/Symbol.for(SummaryKeyTypeSymbolKey);\nconst metricKeyTypeVariance = {\n  /* c8 ignore next */\n  _In: _ => _,\n  /* c8 ignore next */\n  _Out: _ => _\n};\n/** @internal */\nclass CounterKeyType {\n  incremental;\n  bigint;\n  [MetricKeyTypeTypeId] = metricKeyTypeVariance;\n  [CounterKeyTypeTypeId] = CounterKeyTypeTypeId;\n  constructor(incremental, bigint) {\n    this.incremental = incremental;\n    this.bigint = bigint;\n    this._hash = Hash.string(CounterKeyTypeSymbolKey);\n  }\n  _hash;\n  [Hash.symbol]() {\n    return this._hash;\n  }\n  [Equal.symbol](that) {\n    return isCounterKey(that);\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\nconst FrequencyKeyTypeHash = /*#__PURE__*/Hash.string(FrequencyKeyTypeSymbolKey);\n/** @internal */\nclass FrequencyKeyType {\n  preregisteredWords;\n  [MetricKeyTypeTypeId] = metricKeyTypeVariance;\n  [FrequencyKeyTypeTypeId] = FrequencyKeyTypeTypeId;\n  constructor(preregisteredWords) {\n    this.preregisteredWords = preregisteredWords;\n  }\n  [Hash.symbol]() {\n    return FrequencyKeyTypeHash;\n  }\n  [Equal.symbol](that) {\n    return isFrequencyKey(that);\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\nconst GaugeKeyTypeHash = /*#__PURE__*/Hash.string(GaugeKeyTypeSymbolKey);\n/** @internal */\nclass GaugeKeyType {\n  bigint;\n  [MetricKeyTypeTypeId] = metricKeyTypeVariance;\n  [GaugeKeyTypeTypeId] = GaugeKeyTypeTypeId;\n  constructor(bigint) {\n    this.bigint = bigint;\n  }\n  [Hash.symbol]() {\n    return GaugeKeyTypeHash;\n  }\n  [Equal.symbol](that) {\n    return isGaugeKey(that);\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/**\n * @category model\n * @since 2.0.0\n */\nexport class HistogramKeyType {\n  boundaries;\n  [MetricKeyTypeTypeId] = metricKeyTypeVariance;\n  [HistogramKeyTypeTypeId] = HistogramKeyTypeTypeId;\n  constructor(boundaries) {\n    this.boundaries = boundaries;\n    this._hash = pipe(Hash.string(HistogramKeyTypeSymbolKey), Hash.combine(Hash.hash(this.boundaries)));\n  }\n  _hash;\n  [Hash.symbol]() {\n    return this._hash;\n  }\n  [Equal.symbol](that) {\n    return isHistogramKey(that) && Equal.equals(this.boundaries, that.boundaries);\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nclass SummaryKeyType {\n  maxAge;\n  maxSize;\n  error;\n  quantiles;\n  [MetricKeyTypeTypeId] = metricKeyTypeVariance;\n  [SummaryKeyTypeTypeId] = SummaryKeyTypeTypeId;\n  constructor(maxAge, maxSize, error, quantiles) {\n    this.maxAge = maxAge;\n    this.maxSize = maxSize;\n    this.error = error;\n    this.quantiles = quantiles;\n    this._hash = pipe(Hash.string(SummaryKeyTypeSymbolKey), Hash.combine(Hash.hash(this.maxAge)), Hash.combine(Hash.hash(this.maxSize)), Hash.combine(Hash.hash(this.error)), Hash.combine(Hash.array(this.quantiles)));\n  }\n  _hash;\n  [Hash.symbol]() {\n    return this._hash;\n  }\n  [Equal.symbol](that) {\n    return isSummaryKey(that) && Equal.equals(this.maxAge, that.maxAge) && this.maxSize === that.maxSize && this.error === that.error && Equal.equals(this.quantiles, that.quantiles);\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const counter = options => new CounterKeyType(options?.incremental ?? false, options?.bigint ?? false);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const frequency = options => new FrequencyKeyType(options?.preregisteredWords ?? []);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const gauge = options => new GaugeKeyType(options?.bigint ?? false);\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const histogram = boundaries => {\n  return new HistogramKeyType(boundaries);\n};\n/**\n * @since 2.0.0\n * @category constructors\n */\nexport const summary = options => {\n  return new SummaryKeyType(Duration.decode(options.maxAge), options.maxSize, options.error, options.quantiles);\n};\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isMetricKeyType = u => hasProperty(u, MetricKeyTypeTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isCounterKey = u => hasProperty(u, CounterKeyTypeTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isFrequencyKey = u => hasProperty(u, FrequencyKeyTypeTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isGaugeKey = u => hasProperty(u, GaugeKeyTypeTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isHistogramKey = u => hasProperty(u, HistogramKeyTypeTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isSummaryKey = u => hasProperty(u, SummaryKeyTypeTypeId);\n//# sourceMappingURL=keyType.js.map","import * as Equal from \"../../Equal.js\";\nimport * as Hash from \"../../Hash.js\";\nimport { pipeArguments } from \"../../Pipeable.js\";\nimport { hasProperty } from \"../../Predicate.js\";\n/** @internal */\nconst MetricLabelSymbolKey = \"effect/MetricLabel\";\n/** @internal */\nexport const MetricLabelTypeId = /*#__PURE__*/Symbol.for(MetricLabelSymbolKey);\n/** @internal */\nclass MetricLabelImpl {\n  key;\n  value;\n  [MetricLabelTypeId] = MetricLabelTypeId;\n  _hash;\n  constructor(key, value) {\n    this.key = key;\n    this.value = value;\n    this._hash = Hash.string(MetricLabelSymbolKey + this.key + this.value);\n  }\n  [Hash.symbol]() {\n    return this._hash;\n  }\n  [Equal.symbol](that) {\n    return isMetricLabel(that) && this.key === that.key && this.value === that.value;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const make = (key, value) => {\n  return new MetricLabelImpl(key, value);\n};\n/** @internal */\nexport const isMetricLabel = u => hasProperty(u, MetricLabelTypeId);\n//# sourceMappingURL=label.js.map","import { pipeArguments } from \"../../Pipeable.js\";\n/** @internal */\nconst MetricPairSymbolKey = \"effect/MetricPair\";\n/** @internal */\nexport const MetricPairTypeId = /*#__PURE__*/Symbol.for(MetricPairSymbolKey);\nconst metricPairVariance = {\n  /* c8 ignore next */\n  _Type: _ => _\n};\n/** @internal */\nexport const make = (metricKey, metricState) => {\n  return {\n    [MetricPairTypeId]: metricPairVariance,\n    metricKey,\n    metricState,\n    pipe() {\n      return pipeArguments(this, arguments);\n    }\n  };\n};\n/** @internal */\nexport const unsafeMake = (metricKey, metricState) => {\n  return {\n    [MetricPairTypeId]: metricPairVariance,\n    metricKey,\n    metricState,\n    pipe() {\n      return pipeArguments(this, arguments);\n    }\n  };\n};\n//# sourceMappingURL=pair.js.map","import { pipe } from \"../../Function.js\";\nimport * as MutableHashMap from \"../../MutableHashMap.js\";\nimport * as Option from \"../../Option.js\";\nimport * as metricHook from \"./hook.js\";\nimport * as metricKeyType from \"./keyType.js\";\nimport * as metricPair from \"./pair.js\";\n/** @internal */\nconst MetricRegistrySymbolKey = \"effect/MetricRegistry\";\n/** @internal */\nexport const MetricRegistryTypeId = /*#__PURE__*/Symbol.for(MetricRegistrySymbolKey);\n/** @internal */\nclass MetricRegistryImpl {\n  [MetricRegistryTypeId] = MetricRegistryTypeId;\n  map = /*#__PURE__*/MutableHashMap.empty();\n  snapshot() {\n    const result = [];\n    for (const [key, hook] of this.map) {\n      result.push(metricPair.unsafeMake(key, hook.get()));\n    }\n    return result;\n  }\n  get(key) {\n    const hook = pipe(this.map, MutableHashMap.get(key), Option.getOrUndefined);\n    if (hook == null) {\n      if (metricKeyType.isCounterKey(key.keyType)) {\n        return this.getCounter(key);\n      }\n      if (metricKeyType.isGaugeKey(key.keyType)) {\n        return this.getGauge(key);\n      }\n      if (metricKeyType.isFrequencyKey(key.keyType)) {\n        return this.getFrequency(key);\n      }\n      if (metricKeyType.isHistogramKey(key.keyType)) {\n        return this.getHistogram(key);\n      }\n      if (metricKeyType.isSummaryKey(key.keyType)) {\n        return this.getSummary(key);\n      }\n      throw new Error(\"BUG: MetricRegistry.get - unknown MetricKeyType - please report an issue at https://github.com/Effect-TS/effect/issues\");\n    } else {\n      return hook;\n    }\n  }\n  getCounter(key) {\n    let value = pipe(this.map, MutableHashMap.get(key), Option.getOrUndefined);\n    if (value == null) {\n      const counter = metricHook.counter(key);\n      if (!pipe(this.map, MutableHashMap.has(key))) {\n        pipe(this.map, MutableHashMap.set(key, counter));\n      }\n      value = counter;\n    }\n    return value;\n  }\n  getFrequency(key) {\n    let value = pipe(this.map, MutableHashMap.get(key), Option.getOrUndefined);\n    if (value == null) {\n      const frequency = metricHook.frequency(key);\n      if (!pipe(this.map, MutableHashMap.has(key))) {\n        pipe(this.map, MutableHashMap.set(key, frequency));\n      }\n      value = frequency;\n    }\n    return value;\n  }\n  getGauge(key) {\n    let value = pipe(this.map, MutableHashMap.get(key), Option.getOrUndefined);\n    if (value == null) {\n      const gauge = metricHook.gauge(key, key.keyType.bigint ? BigInt(0) : 0);\n      if (!pipe(this.map, MutableHashMap.has(key))) {\n        pipe(this.map, MutableHashMap.set(key, gauge));\n      }\n      value = gauge;\n    }\n    return value;\n  }\n  getHistogram(key) {\n    let value = pipe(this.map, MutableHashMap.get(key), Option.getOrUndefined);\n    if (value == null) {\n      const histogram = metricHook.histogram(key);\n      if (!pipe(this.map, MutableHashMap.has(key))) {\n        pipe(this.map, MutableHashMap.set(key, histogram));\n      }\n      value = histogram;\n    }\n    return value;\n  }\n  getSummary(key) {\n    let value = pipe(this.map, MutableHashMap.get(key), Option.getOrUndefined);\n    if (value == null) {\n      const summary = metricHook.summary(key);\n      if (!pipe(this.map, MutableHashMap.has(key))) {\n        pipe(this.map, MutableHashMap.set(key, summary));\n      }\n      value = summary;\n    }\n    return value;\n  }\n}\n/** @internal */\nexport const make = () => {\n  return new MetricRegistryImpl();\n};\n//# sourceMappingURL=registry.js.map","import * as Arr from \"../../Array.js\";\nimport * as Equal from \"../../Equal.js\";\nimport { pipe } from \"../../Function.js\";\nimport * as Hash from \"../../Hash.js\";\nimport { pipeArguments } from \"../../Pipeable.js\";\nimport { hasProperty } from \"../../Predicate.js\";\n/** @internal */\nconst MetricStateSymbolKey = \"effect/MetricState\";\n/** @internal */\nexport const MetricStateTypeId = /*#__PURE__*/Symbol.for(MetricStateSymbolKey);\n/** @internal */\nconst CounterStateSymbolKey = \"effect/MetricState/Counter\";\n/** @internal */\nexport const CounterStateTypeId = /*#__PURE__*/Symbol.for(CounterStateSymbolKey);\n/** @internal */\nconst FrequencyStateSymbolKey = \"effect/MetricState/Frequency\";\n/** @internal */\nexport const FrequencyStateTypeId = /*#__PURE__*/Symbol.for(FrequencyStateSymbolKey);\n/** @internal */\nconst GaugeStateSymbolKey = \"effect/MetricState/Gauge\";\n/** @internal */\nexport const GaugeStateTypeId = /*#__PURE__*/Symbol.for(GaugeStateSymbolKey);\n/** @internal */\nconst HistogramStateSymbolKey = \"effect/MetricState/Histogram\";\n/** @internal */\nexport const HistogramStateTypeId = /*#__PURE__*/Symbol.for(HistogramStateSymbolKey);\n/** @internal */\nconst SummaryStateSymbolKey = \"effect/MetricState/Summary\";\n/** @internal */\nexport const SummaryStateTypeId = /*#__PURE__*/Symbol.for(SummaryStateSymbolKey);\nconst metricStateVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\n/** @internal */\nclass CounterState {\n  count;\n  [MetricStateTypeId] = metricStateVariance;\n  [CounterStateTypeId] = CounterStateTypeId;\n  constructor(count) {\n    this.count = count;\n  }\n  [Hash.symbol]() {\n    return pipe(Hash.hash(CounterStateSymbolKey), Hash.combine(Hash.hash(this.count)), Hash.cached(this));\n  }\n  [Equal.symbol](that) {\n    return isCounterState(that) && this.count === that.count;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\nconst arrayEquals = /*#__PURE__*/Arr.getEquivalence(Equal.equals);\n/** @internal */\nclass FrequencyState {\n  occurrences;\n  [MetricStateTypeId] = metricStateVariance;\n  [FrequencyStateTypeId] = FrequencyStateTypeId;\n  constructor(occurrences) {\n    this.occurrences = occurrences;\n  }\n  _hash;\n  [Hash.symbol]() {\n    return pipe(Hash.string(FrequencyStateSymbolKey), Hash.combine(Hash.array(Arr.fromIterable(this.occurrences.entries()))), Hash.cached(this));\n  }\n  [Equal.symbol](that) {\n    return isFrequencyState(that) && arrayEquals(Arr.fromIterable(this.occurrences.entries()), Arr.fromIterable(that.occurrences.entries()));\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nclass GaugeState {\n  value;\n  [MetricStateTypeId] = metricStateVariance;\n  [GaugeStateTypeId] = GaugeStateTypeId;\n  constructor(value) {\n    this.value = value;\n  }\n  [Hash.symbol]() {\n    return pipe(Hash.hash(GaugeStateSymbolKey), Hash.combine(Hash.hash(this.value)), Hash.cached(this));\n  }\n  [Equal.symbol](u) {\n    return isGaugeState(u) && this.value === u.value;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport class HistogramState {\n  buckets;\n  count;\n  min;\n  max;\n  sum;\n  [MetricStateTypeId] = metricStateVariance;\n  [HistogramStateTypeId] = HistogramStateTypeId;\n  constructor(buckets, count, min, max, sum) {\n    this.buckets = buckets;\n    this.count = count;\n    this.min = min;\n    this.max = max;\n    this.sum = sum;\n  }\n  [Hash.symbol]() {\n    return pipe(Hash.hash(HistogramStateSymbolKey), Hash.combine(Hash.hash(this.buckets)), Hash.combine(Hash.hash(this.count)), Hash.combine(Hash.hash(this.min)), Hash.combine(Hash.hash(this.max)), Hash.combine(Hash.hash(this.sum)), Hash.cached(this));\n  }\n  [Equal.symbol](that) {\n    return isHistogramState(that) && Equal.equals(this.buckets, that.buckets) && this.count === that.count && this.min === that.min && this.max === that.max && this.sum === that.sum;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport class SummaryState {\n  error;\n  quantiles;\n  count;\n  min;\n  max;\n  sum;\n  [MetricStateTypeId] = metricStateVariance;\n  [SummaryStateTypeId] = SummaryStateTypeId;\n  constructor(error, quantiles, count, min, max, sum) {\n    this.error = error;\n    this.quantiles = quantiles;\n    this.count = count;\n    this.min = min;\n    this.max = max;\n    this.sum = sum;\n  }\n  [Hash.symbol]() {\n    return pipe(Hash.hash(SummaryStateSymbolKey), Hash.combine(Hash.hash(this.error)), Hash.combine(Hash.hash(this.quantiles)), Hash.combine(Hash.hash(this.count)), Hash.combine(Hash.hash(this.min)), Hash.combine(Hash.hash(this.max)), Hash.combine(Hash.hash(this.sum)), Hash.cached(this));\n  }\n  [Equal.symbol](that) {\n    return isSummaryState(that) && this.error === that.error && Equal.equals(this.quantiles, that.quantiles) && this.count === that.count && this.min === that.min && this.max === that.max && this.sum === that.sum;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const counter = count => new CounterState(count);\n/** @internal */\nexport const frequency = occurrences => {\n  return new FrequencyState(occurrences);\n};\n/** @internal */\nexport const gauge = count => new GaugeState(count);\n/** @internal */\nexport const histogram = options => new HistogramState(options.buckets, options.count, options.min, options.max, options.sum);\n/** @internal */\nexport const summary = options => new SummaryState(options.error, options.quantiles, options.count, options.min, options.max, options.sum);\n/** @internal */\nexport const isMetricState = u => hasProperty(u, MetricStateTypeId);\n/** @internal */\nexport const isCounterState = u => hasProperty(u, CounterStateTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isFrequencyState = u => hasProperty(u, FrequencyStateTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isGaugeState = u => hasProperty(u, GaugeStateTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isHistogramState = u => hasProperty(u, HistogramStateTypeId);\n/**\n * @since 2.0.0\n * @category refinements\n */\nexport const isSummaryState = u => hasProperty(u, SummaryStateTypeId);\n//# sourceMappingURL=state.js.map","/** @internal */\nexport const OP_DIE = \"Die\";\n/** @internal */\nexport const OP_EMPTY = \"Empty\";\n/** @internal */\nexport const OP_FAIL = \"Fail\";\n/** @internal */\nexport const OP_INTERRUPT = \"Interrupt\";\n/** @internal */\nexport const OP_PARALLEL = \"Parallel\";\n/** @internal */\nexport const OP_SEQUENTIAL = \"Sequential\";\n//# sourceMappingURL=cause.js.map","/** @internal */\nexport const OP_BRACKET_OUT = \"BracketOut\";\n/** @internal */\nexport const OP_BRIDGE = \"Bridge\";\n/** @internal */\nexport const OP_CONCAT_ALL = \"ConcatAll\";\n/** @internal */\nexport const OP_EMIT = \"Emit\";\n/** @internal */\nexport const OP_ENSURING = \"Ensuring\";\n/** @internal */\nexport const OP_FAIL = \"Fail\";\n/** @internal */\nexport const OP_FOLD = \"Fold\";\n/** @internal */\nexport const OP_FROM_EFFECT = \"FromEffect\";\n/** @internal */\nexport const OP_PIPE_TO = \"PipeTo\";\n/** @internal */\nexport const OP_PROVIDE = \"Provide\";\n/** @internal */\nexport const OP_READ = \"Read\";\n/** @internal */\nexport const OP_SUCCEED = \"Succeed\";\n/** @internal */\nexport const OP_SUCCEED_NOW = \"SucceedNow\";\n/** @internal */\nexport const OP_SUSPEND = \"Suspend\";\n//# sourceMappingURL=channel.js.map","/** @internal */\nexport const OP_CONTINUE = \"Continue\";\n/** @internal */\nexport const OP_CLOSE = \"Close\";\n/** @internal */\nexport const OP_YIELD = \"Yield\";\n//# sourceMappingURL=channelChildExecutorDecision.js.map","/** @internal */\nexport const OP_DONE = \"Done\";\n/** @internal */\nexport const OP_AWAIT = \"Await\";\n//# sourceMappingURL=channelMergeDecision.js.map","/** @internal */\nexport const OP_BOTH_RUNNING = \"BothRunning\";\n/** @internal */\nexport const OP_LEFT_DONE = \"LeftDone\";\n/** @internal */\nexport const OP_RIGHT_DONE = \"RightDone\";\n//# sourceMappingURL=channelMergeState.js.map","/** @internal */\nexport const OP_BACK_PRESSURE = \"BackPressure\";\n/** @internal */\nexport const OP_BUFFER_SLIDING = \"BufferSliding\";\n//# sourceMappingURL=channelMergeStrategy.js.map","/** @internal */\nexport const OP_DONE = \"Done\";\n/** @internal */\nexport const OP_EMIT = \"Emit\";\n/** @internal */\nexport const OP_FROM_EFFECT = \"FromEffect\";\n/** @internal */\nexport const OP_READ = \"Read\";\n//# sourceMappingURL=channelState.js.map","/** @internal */\nexport const OP_PULLED = \"Pulled\";\n/** @internal */\nexport const OP_NO_UPSTREAM = \"NoUpstream\";\n//# sourceMappingURL=channelUpstreamPullRequest.js.map","/** @internal */\nexport const OP_PULL_AFTER_NEXT = \"PullAfterNext\";\n/** @internal */\nexport const OP_PULL_AFTER_ALL_ENQUEUED = \"PullAfterAllEnqueued\";\n//# sourceMappingURL=channelUpstreamPullStrategy.js.map","/** @internal */\nexport const OP_CONSTANT = \"Constant\";\n/** @internal */\nexport const OP_FAIL = \"Fail\";\n/** @internal */\nexport const OP_FALLBACK = \"Fallback\";\n/** @internal */\nexport const OP_DESCRIBED = \"Described\";\n/** @internal */\nexport const OP_LAZY = \"Lazy\";\n/** @internal */\nexport const OP_MAP_OR_FAIL = \"MapOrFail\";\n/** @internal */\nexport const OP_NESTED = \"Nested\";\n/** @internal */\nexport const OP_PRIMITIVE = \"Primitive\";\n/** @internal */\nexport const OP_SEQUENCE = \"Sequence\";\n/** @internal */\nexport const OP_HASHMAP = \"HashMap\";\n/** @internal */\nexport const OP_ZIP_WITH = \"ZipWith\";\n//# sourceMappingURL=config.js.map","/** @internal */\nexport const OP_AND = \"And\";\n/** @internal */\nexport const OP_OR = \"Or\";\n/** @internal */\nexport const OP_INVALID_DATA = \"InvalidData\";\n/** @internal */\nexport const OP_MISSING_DATA = \"MissingData\";\n/** @internal */\nexport const OP_SOURCE_UNAVAILABLE = \"SourceUnavailable\";\n/** @internal */\nexport const OP_UNSUPPORTED = \"Unsupported\";\n//# sourceMappingURL=configError.js.map","/** @internal */\nexport const OP_CONTINUATION_K = \"ContinuationK\";\n/** @internal */\nexport const OP_CONTINUATION_FINALIZER = \"ContinuationFinalizer\";\n//# sourceMappingURL=continuation.js.map","/** @internal */\nexport const OP_STATE_PENDING = \"Pending\";\n/** @internal */\nexport const OP_STATE_DONE = \"Done\";\n//# sourceMappingURL=deferred.js.map","/** @internal */\nexport const OP_ASYNC = \"Async\";\n/** @internal */\nexport const OP_COMMIT = \"Commit\";\n/** @internal */\nexport const OP_FAILURE = \"Failure\";\n/** @internal */\nexport const OP_ON_FAILURE = \"OnFailure\";\n/** @internal */\nexport const OP_ON_SUCCESS = \"OnSuccess\";\n/** @internal */\nexport const OP_ON_SUCCESS_AND_FAILURE = \"OnSuccessAndFailure\";\n/** @internal */\nexport const OP_SUCCESS = \"Success\";\n/** @internal */\nexport const OP_SYNC = \"Sync\";\n/** @internal */\nexport const OP_TAG = \"Tag\";\n/** @internal */\nexport const OP_UPDATE_RUNTIME_FLAGS = \"UpdateRuntimeFlags\";\n/** @internal */\nexport const OP_WHILE = \"While\";\n/** @internal */\nexport const OP_WITH_RUNTIME = \"WithRuntime\";\n/** @internal */\nexport const OP_YIELD = \"Yield\";\n/** @internal */\nexport const OP_REVERT_FLAGS = \"RevertFlags\";\n//# sourceMappingURL=effect.js.map","/** @internal */\nexport const OP_EXTEND_SCOPE = \"ExtendScope\";\n/** @internal */\nexport const OP_FOLD = \"Fold\";\n/** @internal */\nexport const OP_FRESH = \"Fresh\";\n/** @internal */\nexport const OP_FROM_EFFECT = \"FromEffect\";\n/** @internal */\nexport const OP_SCOPED = \"Scoped\";\n/** @internal */\nexport const OP_SUSPEND = \"Suspend\";\n/** @internal */\nexport const OP_PROVIDE = \"Provide\";\n/** @internal */\nexport const OP_PROVIDE_MERGE = \"ProvideMerge\";\n/** @internal */\nexport const OP_ZIP_WITH = \"ZipWith\";\n//# sourceMappingURL=layer.js.map","/** @internal */\nexport const OP_LEFT = \"Left\";\n/** @internal */\nexport const OP_RIGHT = \"Right\";\n/** @internal */\nexport const OP_BOTH = \"Both\";\n/** @internal */\nexport const OP_EITHER = \"Either\";\n//# sourceMappingURL=streamHaltStrategy.js.map","/**\n * @since 2.0.0\n */\nimport * as Equal from \"../Equal.js\";\nimport * as Hash from \"../Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport { EffectPrototype } from \"./effectable.js\";\nconst TypeId = /*#__PURE__*/Symbol.for(\"effect/Option\");\nconst CommonProto = {\n  ...EffectPrototype,\n  [TypeId]: {\n    _A: _ => _\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  toString() {\n    return format(this.toJSON());\n  }\n};\nconst SomeProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(CommonProto), {\n  _tag: \"Some\",\n  _op: \"Some\",\n  [Equal.symbol](that) {\n    return isOption(that) && isSome(that) && Equal.equals(this.value, that.value);\n  },\n  [Hash.symbol]() {\n    return Hash.cached(this, Hash.combine(Hash.hash(this._tag))(Hash.hash(this.value)));\n  },\n  toJSON() {\n    return {\n      _id: \"Option\",\n      _tag: this._tag,\n      value: toJSON(this.value)\n    };\n  }\n});\nconst NoneHash = /*#__PURE__*/Hash.hash(\"None\");\nconst NoneProto = /*#__PURE__*/Object.assign( /*#__PURE__*/Object.create(CommonProto), {\n  _tag: \"None\",\n  _op: \"None\",\n  [Equal.symbol](that) {\n    return isOption(that) && isNone(that);\n  },\n  [Hash.symbol]() {\n    return NoneHash;\n  },\n  toJSON() {\n    return {\n      _id: \"Option\",\n      _tag: this._tag\n    };\n  }\n});\n/** @internal */\nexport const isOption = input => hasProperty(input, TypeId);\n/** @internal */\nexport const isNone = fa => fa._tag === \"None\";\n/** @internal */\nexport const isSome = fa => fa._tag === \"Some\";\n/** @internal */\nexport const none = /*#__PURE__*/Object.create(NoneProto);\n/** @internal */\nexport const some = value => {\n  const a = Object.create(SomeProto);\n  a.value = value;\n  return a;\n};\n//# sourceMappingURL=option.js.map","import * as Chunk from \"../Chunk.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as MutableQueue from \"../MutableQueue.js\";\nimport * as MutableRef from \"../MutableRef.js\";\nimport { nextPow2 } from \"../Number.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport * as core from \"./core.js\";\nimport * as executionStrategy from \"./executionStrategy.js\";\nimport * as fiberRuntime from \"./fiberRuntime.js\";\nimport * as queue from \"./queue.js\";\nconst AbsentValue = /*#__PURE__*/Symbol.for(\"effect/PubSub/AbsentValue\");\nconst addSubscribers = (subscription, pollers) => subscribers => {\n  if (!subscribers.has(subscription)) {\n    subscribers.set(subscription, new Set());\n  }\n  const set = subscribers.get(subscription);\n  set.add(pollers);\n};\nconst removeSubscribers = (subscription, pollers) => subscribers => {\n  if (!subscribers.has(subscription)) {\n    return;\n  }\n  const set = subscribers.get(subscription);\n  set.delete(pollers);\n  if (set.size === 0) {\n    subscribers.delete(subscription);\n  }\n};\n/** @internal */\nexport const bounded = capacity => core.suspend(() => {\n  const pubsub = makeBoundedPubSub(capacity);\n  return makePubSub(pubsub, new BackPressureStrategy());\n});\n/** @internal */\nexport const dropping = capacity => core.suspend(() => {\n  const pubsub = makeBoundedPubSub(capacity);\n  return makePubSub(pubsub, new DroppingStrategy());\n});\n/** @internal */\nexport const sliding = capacity => core.suspend(() => {\n  const pubsub = makeBoundedPubSub(capacity);\n  return makePubSub(pubsub, new SlidingStrategy());\n});\n/** @internal */\nexport const unbounded = options => core.suspend(() => {\n  const pubsub = makeUnboundedPubSub(options);\n  return makePubSub(pubsub, new DroppingStrategy());\n});\n/** @internal */\nexport const capacity = self => self.capacity();\n/** @internal */\nexport const size = self => self.size;\n/** @internal */\nexport const isFull = self => self.isFull;\n/** @internal */\nexport const isEmpty = self => self.isEmpty;\n/** @internal */\nexport const shutdown = self => self.shutdown;\n/** @internal */\nexport const isShutdown = self => self.isShutdown;\n/** @internal */\nexport const awaitShutdown = self => self.awaitShutdown;\n/** @internal */\nexport const publish = /*#__PURE__*/dual(2, (self, value) => self.publish(value));\n/** @internal */\nexport const publishAll = /*#__PURE__*/dual(2, (self, elements) => self.publishAll(elements));\n/** @internal */\nexport const subscribe = self => self.subscribe;\n/** @internal */\nconst makeBoundedPubSub = capacity => {\n  const options = typeof capacity === \"number\" ? {\n    capacity\n  } : capacity;\n  ensureCapacity(options.capacity);\n  const replayBuffer = options.replay && options.replay > 0 ? new ReplayBuffer(Math.ceil(options.replay)) : undefined;\n  if (options.capacity === 1) {\n    return new BoundedPubSubSingle(replayBuffer);\n  } else if (nextPow2(options.capacity) === options.capacity) {\n    return new BoundedPubSubPow2(options.capacity, replayBuffer);\n  } else {\n    return new BoundedPubSubArb(options.capacity, replayBuffer);\n  }\n};\n/** @internal */\nconst makeUnboundedPubSub = options => new UnboundedPubSub(options?.replay ? new ReplayBuffer(options.replay) : undefined);\n/** @internal */\nconst makeSubscription = (pubsub, subscribers, strategy) => core.map(core.deferredMake(), deferred => unsafeMakeSubscription(pubsub, subscribers, pubsub.subscribe(), MutableQueue.unbounded(), deferred, MutableRef.make(false), strategy));\n/** @internal */\nexport const unsafeMakeSubscription = (pubsub, subscribers, subscription, pollers, shutdownHook, shutdownFlag, strategy) => new SubscriptionImpl(pubsub, subscribers, subscription, pollers, shutdownHook, shutdownFlag, strategy, pubsub.replayWindow());\n/** @internal */\nclass BoundedPubSubArb {\n  capacity;\n  replayBuffer;\n  array;\n  publisherIndex = 0;\n  subscribers;\n  subscriberCount = 0;\n  subscribersIndex = 0;\n  constructor(capacity, replayBuffer) {\n    this.capacity = capacity;\n    this.replayBuffer = replayBuffer;\n    this.array = Array.from({\n      length: capacity\n    });\n    this.subscribers = Array.from({\n      length: capacity\n    });\n  }\n  replayWindow() {\n    return this.replayBuffer ? new ReplayWindowImpl(this.replayBuffer) : emptyReplayWindow;\n  }\n  isEmpty() {\n    return this.publisherIndex === this.subscribersIndex;\n  }\n  isFull() {\n    return this.publisherIndex === this.subscribersIndex + this.capacity;\n  }\n  size() {\n    return this.publisherIndex - this.subscribersIndex;\n  }\n  publish(value) {\n    if (this.isFull()) {\n      return false;\n    }\n    if (this.subscriberCount !== 0) {\n      const index = this.publisherIndex % this.capacity;\n      this.array[index] = value;\n      this.subscribers[index] = this.subscriberCount;\n      this.publisherIndex += 1;\n    }\n    if (this.replayBuffer) {\n      this.replayBuffer.offer(value);\n    }\n    return true;\n  }\n  publishAll(elements) {\n    if (this.subscriberCount === 0) {\n      if (this.replayBuffer) {\n        this.replayBuffer.offerAll(elements);\n      }\n      return Chunk.empty();\n    }\n    const chunk = Chunk.fromIterable(elements);\n    const n = chunk.length;\n    const size = this.publisherIndex - this.subscribersIndex;\n    const available = this.capacity - size;\n    const forPubSub = Math.min(n, available);\n    if (forPubSub === 0) {\n      return chunk;\n    }\n    let iteratorIndex = 0;\n    const publishAllIndex = this.publisherIndex + forPubSub;\n    while (this.publisherIndex !== publishAllIndex) {\n      const a = Chunk.unsafeGet(chunk, iteratorIndex++);\n      const index = this.publisherIndex % this.capacity;\n      this.array[index] = a;\n      this.subscribers[index] = this.subscriberCount;\n      this.publisherIndex += 1;\n      if (this.replayBuffer) {\n        this.replayBuffer.offer(a);\n      }\n    }\n    return Chunk.drop(chunk, iteratorIndex);\n  }\n  slide() {\n    if (this.subscribersIndex !== this.publisherIndex) {\n      const index = this.subscribersIndex % this.capacity;\n      this.array[index] = AbsentValue;\n      this.subscribers[index] = 0;\n      this.subscribersIndex += 1;\n    }\n    if (this.replayBuffer) {\n      this.replayBuffer.slide();\n    }\n  }\n  subscribe() {\n    this.subscriberCount += 1;\n    return new BoundedPubSubArbSubscription(this, this.publisherIndex, false);\n  }\n}\nclass BoundedPubSubArbSubscription {\n  self;\n  subscriberIndex;\n  unsubscribed;\n  constructor(self, subscriberIndex, unsubscribed) {\n    this.self = self;\n    this.subscriberIndex = subscriberIndex;\n    this.unsubscribed = unsubscribed;\n  }\n  isEmpty() {\n    return this.unsubscribed || this.self.publisherIndex === this.subscriberIndex || this.self.publisherIndex === this.self.subscribersIndex;\n  }\n  size() {\n    if (this.unsubscribed) {\n      return 0;\n    }\n    return this.self.publisherIndex - Math.max(this.subscriberIndex, this.self.subscribersIndex);\n  }\n  poll(default_) {\n    if (this.unsubscribed) {\n      return default_;\n    }\n    this.subscriberIndex = Math.max(this.subscriberIndex, this.self.subscribersIndex);\n    if (this.subscriberIndex !== this.self.publisherIndex) {\n      const index = this.subscriberIndex % this.self.capacity;\n      const elem = this.self.array[index];\n      this.self.subscribers[index] -= 1;\n      if (this.self.subscribers[index] === 0) {\n        this.self.array[index] = AbsentValue;\n        this.self.subscribersIndex += 1;\n      }\n      this.subscriberIndex += 1;\n      return elem;\n    }\n    return default_;\n  }\n  pollUpTo(n) {\n    if (this.unsubscribed) {\n      return Chunk.empty();\n    }\n    this.subscriberIndex = Math.max(this.subscriberIndex, this.self.subscribersIndex);\n    const size = this.self.publisherIndex - this.subscriberIndex;\n    const toPoll = Math.min(n, size);\n    if (toPoll <= 0) {\n      return Chunk.empty();\n    }\n    const builder = [];\n    const pollUpToIndex = this.subscriberIndex + toPoll;\n    while (this.subscriberIndex !== pollUpToIndex) {\n      const index = this.subscriberIndex % this.self.capacity;\n      const a = this.self.array[index];\n      this.self.subscribers[index] -= 1;\n      if (this.self.subscribers[index] === 0) {\n        this.self.array[index] = AbsentValue;\n        this.self.subscribersIndex += 1;\n      }\n      builder.push(a);\n      this.subscriberIndex += 1;\n    }\n    return Chunk.fromIterable(builder);\n  }\n  unsubscribe() {\n    if (!this.unsubscribed) {\n      this.unsubscribed = true;\n      this.self.subscriberCount -= 1;\n      this.subscriberIndex = Math.max(this.subscriberIndex, this.self.subscribersIndex);\n      while (this.subscriberIndex !== this.self.publisherIndex) {\n        const index = this.subscriberIndex % this.self.capacity;\n        this.self.subscribers[index] -= 1;\n        if (this.self.subscribers[index] === 0) {\n          this.self.array[index] = AbsentValue;\n          this.self.subscribersIndex += 1;\n        }\n        this.subscriberIndex += 1;\n      }\n    }\n  }\n}\n/** @internal */\nclass BoundedPubSubPow2 {\n  capacity;\n  replayBuffer;\n  array;\n  mask;\n  publisherIndex = 0;\n  subscribers;\n  subscriberCount = 0;\n  subscribersIndex = 0;\n  constructor(capacity, replayBuffer) {\n    this.capacity = capacity;\n    this.replayBuffer = replayBuffer;\n    this.array = Array.from({\n      length: capacity\n    });\n    this.mask = capacity - 1;\n    this.subscribers = Array.from({\n      length: capacity\n    });\n  }\n  replayWindow() {\n    return this.replayBuffer ? new ReplayWindowImpl(this.replayBuffer) : emptyReplayWindow;\n  }\n  isEmpty() {\n    return this.publisherIndex === this.subscribersIndex;\n  }\n  isFull() {\n    return this.publisherIndex === this.subscribersIndex + this.capacity;\n  }\n  size() {\n    return this.publisherIndex - this.subscribersIndex;\n  }\n  publish(value) {\n    if (this.isFull()) {\n      return false;\n    }\n    if (this.subscriberCount !== 0) {\n      const index = this.publisherIndex & this.mask;\n      this.array[index] = value;\n      this.subscribers[index] = this.subscriberCount;\n      this.publisherIndex += 1;\n    }\n    if (this.replayBuffer) {\n      this.replayBuffer.offer(value);\n    }\n    return true;\n  }\n  publishAll(elements) {\n    if (this.subscriberCount === 0) {\n      if (this.replayBuffer) {\n        this.replayBuffer.offerAll(elements);\n      }\n      return Chunk.empty();\n    }\n    const chunk = Chunk.fromIterable(elements);\n    const n = chunk.length;\n    const size = this.publisherIndex - this.subscribersIndex;\n    const available = this.capacity - size;\n    const forPubSub = Math.min(n, available);\n    if (forPubSub === 0) {\n      return chunk;\n    }\n    let iteratorIndex = 0;\n    const publishAllIndex = this.publisherIndex + forPubSub;\n    while (this.publisherIndex !== publishAllIndex) {\n      const elem = Chunk.unsafeGet(chunk, iteratorIndex++);\n      const index = this.publisherIndex & this.mask;\n      this.array[index] = elem;\n      this.subscribers[index] = this.subscriberCount;\n      this.publisherIndex += 1;\n      if (this.replayBuffer) {\n        this.replayBuffer.offer(elem);\n      }\n    }\n    return Chunk.drop(chunk, iteratorIndex);\n  }\n  slide() {\n    if (this.subscribersIndex !== this.publisherIndex) {\n      const index = this.subscribersIndex & this.mask;\n      this.array[index] = AbsentValue;\n      this.subscribers[index] = 0;\n      this.subscribersIndex += 1;\n    }\n    if (this.replayBuffer) {\n      this.replayBuffer.slide();\n    }\n  }\n  subscribe() {\n    this.subscriberCount += 1;\n    return new BoundedPubSubPow2Subscription(this, this.publisherIndex, false);\n  }\n}\n/** @internal */\nclass BoundedPubSubPow2Subscription {\n  self;\n  subscriberIndex;\n  unsubscribed;\n  constructor(self, subscriberIndex, unsubscribed) {\n    this.self = self;\n    this.subscriberIndex = subscriberIndex;\n    this.unsubscribed = unsubscribed;\n  }\n  isEmpty() {\n    return this.unsubscribed || this.self.publisherIndex === this.subscriberIndex || this.self.publisherIndex === this.self.subscribersIndex;\n  }\n  size() {\n    if (this.unsubscribed) {\n      return 0;\n    }\n    return this.self.publisherIndex - Math.max(this.subscriberIndex, this.self.subscribersIndex);\n  }\n  poll(default_) {\n    if (this.unsubscribed) {\n      return default_;\n    }\n    this.subscriberIndex = Math.max(this.subscriberIndex, this.self.subscribersIndex);\n    if (this.subscriberIndex !== this.self.publisherIndex) {\n      const index = this.subscriberIndex & this.self.mask;\n      const elem = this.self.array[index];\n      this.self.subscribers[index] -= 1;\n      if (this.self.subscribers[index] === 0) {\n        this.self.array[index] = AbsentValue;\n        this.self.subscribersIndex += 1;\n      }\n      this.subscriberIndex += 1;\n      return elem;\n    }\n    return default_;\n  }\n  pollUpTo(n) {\n    if (this.unsubscribed) {\n      return Chunk.empty();\n    }\n    this.subscriberIndex = Math.max(this.subscriberIndex, this.self.subscribersIndex);\n    const size = this.self.publisherIndex - this.subscriberIndex;\n    const toPoll = Math.min(n, size);\n    if (toPoll <= 0) {\n      return Chunk.empty();\n    }\n    const builder = [];\n    const pollUpToIndex = this.subscriberIndex + toPoll;\n    while (this.subscriberIndex !== pollUpToIndex) {\n      const index = this.subscriberIndex & this.self.mask;\n      const elem = this.self.array[index];\n      this.self.subscribers[index] -= 1;\n      if (this.self.subscribers[index] === 0) {\n        this.self.array[index] = AbsentValue;\n        this.self.subscribersIndex += 1;\n      }\n      builder.push(elem);\n      this.subscriberIndex += 1;\n    }\n    return Chunk.fromIterable(builder);\n  }\n  unsubscribe() {\n    if (!this.unsubscribed) {\n      this.unsubscribed = true;\n      this.self.subscriberCount -= 1;\n      this.subscriberIndex = Math.max(this.subscriberIndex, this.self.subscribersIndex);\n      while (this.subscriberIndex !== this.self.publisherIndex) {\n        const index = this.subscriberIndex & this.self.mask;\n        this.self.subscribers[index] -= 1;\n        if (this.self.subscribers[index] === 0) {\n          this.self.array[index] = AbsentValue;\n          this.self.subscribersIndex += 1;\n        }\n        this.subscriberIndex += 1;\n      }\n    }\n  }\n}\n/** @internal */\nclass BoundedPubSubSingle {\n  replayBuffer;\n  publisherIndex = 0;\n  subscriberCount = 0;\n  subscribers = 0;\n  value = AbsentValue;\n  capacity = 1;\n  constructor(replayBuffer) {\n    this.replayBuffer = replayBuffer;\n  }\n  replayWindow() {\n    return this.replayBuffer ? new ReplayWindowImpl(this.replayBuffer) : emptyReplayWindow;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  isEmpty() {\n    return this.subscribers === 0;\n  }\n  isFull() {\n    return !this.isEmpty();\n  }\n  size() {\n    return this.isEmpty() ? 0 : 1;\n  }\n  publish(value) {\n    if (this.isFull()) {\n      return false;\n    }\n    if (this.subscriberCount !== 0) {\n      this.value = value;\n      this.subscribers = this.subscriberCount;\n      this.publisherIndex += 1;\n    }\n    if (this.replayBuffer) {\n      this.replayBuffer.offer(value);\n    }\n    return true;\n  }\n  publishAll(elements) {\n    if (this.subscriberCount === 0) {\n      if (this.replayBuffer) {\n        this.replayBuffer.offerAll(elements);\n      }\n      return Chunk.empty();\n    }\n    const chunk = Chunk.fromIterable(elements);\n    if (Chunk.isEmpty(chunk)) {\n      return chunk;\n    }\n    if (this.publish(Chunk.unsafeHead(chunk))) {\n      return Chunk.drop(chunk, 1);\n    } else {\n      return chunk;\n    }\n  }\n  slide() {\n    if (this.isFull()) {\n      this.subscribers = 0;\n      this.value = AbsentValue;\n    }\n    if (this.replayBuffer) {\n      this.replayBuffer.slide();\n    }\n  }\n  subscribe() {\n    this.subscriberCount += 1;\n    return new BoundedPubSubSingleSubscription(this, this.publisherIndex, false);\n  }\n}\n/** @internal */\nclass BoundedPubSubSingleSubscription {\n  self;\n  subscriberIndex;\n  unsubscribed;\n  constructor(self, subscriberIndex, unsubscribed) {\n    this.self = self;\n    this.subscriberIndex = subscriberIndex;\n    this.unsubscribed = unsubscribed;\n  }\n  isEmpty() {\n    return this.unsubscribed || this.self.subscribers === 0 || this.subscriberIndex === this.self.publisherIndex;\n  }\n  size() {\n    return this.isEmpty() ? 0 : 1;\n  }\n  poll(default_) {\n    if (this.isEmpty()) {\n      return default_;\n    }\n    const elem = this.self.value;\n    this.self.subscribers -= 1;\n    if (this.self.subscribers === 0) {\n      this.self.value = AbsentValue;\n    }\n    this.subscriberIndex += 1;\n    return elem;\n  }\n  pollUpTo(n) {\n    if (this.isEmpty() || n < 1) {\n      return Chunk.empty();\n    }\n    const a = this.self.value;\n    this.self.subscribers -= 1;\n    if (this.self.subscribers === 0) {\n      this.self.value = AbsentValue;\n    }\n    this.subscriberIndex += 1;\n    return Chunk.of(a);\n  }\n  unsubscribe() {\n    if (!this.unsubscribed) {\n      this.unsubscribed = true;\n      this.self.subscriberCount -= 1;\n      if (this.subscriberIndex !== this.self.publisherIndex) {\n        this.self.subscribers -= 1;\n        if (this.self.subscribers === 0) {\n          this.self.value = AbsentValue;\n        }\n      }\n    }\n  }\n}\n/** @internal */\nclass UnboundedPubSub {\n  replayBuffer;\n  publisherHead = {\n    value: AbsentValue,\n    subscribers: 0,\n    next: null\n  };\n  publisherTail = this.publisherHead;\n  publisherIndex = 0;\n  subscribersIndex = 0;\n  capacity = Number.MAX_SAFE_INTEGER;\n  constructor(replayBuffer) {\n    this.replayBuffer = replayBuffer;\n  }\n  replayWindow() {\n    return this.replayBuffer ? new ReplayWindowImpl(this.replayBuffer) : emptyReplayWindow;\n  }\n  isEmpty() {\n    return this.publisherHead === this.publisherTail;\n  }\n  isFull() {\n    return false;\n  }\n  size() {\n    return this.publisherIndex - this.subscribersIndex;\n  }\n  publish(value) {\n    const subscribers = this.publisherTail.subscribers;\n    if (subscribers !== 0) {\n      this.publisherTail.next = {\n        value,\n        subscribers,\n        next: null\n      };\n      this.publisherTail = this.publisherTail.next;\n      this.publisherIndex += 1;\n    }\n    if (this.replayBuffer) {\n      this.replayBuffer.offer(value);\n    }\n    return true;\n  }\n  publishAll(elements) {\n    if (this.publisherTail.subscribers !== 0) {\n      for (const a of elements) {\n        this.publish(a);\n      }\n    } else if (this.replayBuffer) {\n      this.replayBuffer.offerAll(elements);\n    }\n    return Chunk.empty();\n  }\n  slide() {\n    if (this.publisherHead !== this.publisherTail) {\n      this.publisherHead = this.publisherHead.next;\n      this.publisherHead.value = AbsentValue;\n      this.subscribersIndex += 1;\n    }\n    if (this.replayBuffer) {\n      this.replayBuffer.slide();\n    }\n  }\n  subscribe() {\n    this.publisherTail.subscribers += 1;\n    return new UnboundedPubSubSubscription(this, this.publisherTail, this.publisherIndex, false);\n  }\n}\n/** @internal */\nclass UnboundedPubSubSubscription {\n  self;\n  subscriberHead;\n  subscriberIndex;\n  unsubscribed;\n  constructor(self, subscriberHead, subscriberIndex, unsubscribed) {\n    this.self = self;\n    this.subscriberHead = subscriberHead;\n    this.subscriberIndex = subscriberIndex;\n    this.unsubscribed = unsubscribed;\n  }\n  isEmpty() {\n    if (this.unsubscribed) {\n      return true;\n    }\n    let empty = true;\n    let loop = true;\n    while (loop) {\n      if (this.subscriberHead === this.self.publisherTail) {\n        loop = false;\n      } else {\n        if (this.subscriberHead.next.value !== AbsentValue) {\n          empty = false;\n          loop = false;\n        } else {\n          this.subscriberHead = this.subscriberHead.next;\n          this.subscriberIndex += 1;\n        }\n      }\n    }\n    return empty;\n  }\n  size() {\n    if (this.unsubscribed) {\n      return 0;\n    }\n    return this.self.publisherIndex - Math.max(this.subscriberIndex, this.self.subscribersIndex);\n  }\n  poll(default_) {\n    if (this.unsubscribed) {\n      return default_;\n    }\n    let loop = true;\n    let polled = default_;\n    while (loop) {\n      if (this.subscriberHead === this.self.publisherTail) {\n        loop = false;\n      } else {\n        const elem = this.subscriberHead.next.value;\n        if (elem !== AbsentValue) {\n          polled = elem;\n          this.subscriberHead.subscribers -= 1;\n          if (this.subscriberHead.subscribers === 0) {\n            this.self.publisherHead = this.self.publisherHead.next;\n            this.self.publisherHead.value = AbsentValue;\n            this.self.subscribersIndex += 1;\n          }\n          loop = false;\n        }\n        this.subscriberHead = this.subscriberHead.next;\n        this.subscriberIndex += 1;\n      }\n    }\n    return polled;\n  }\n  pollUpTo(n) {\n    const builder = [];\n    const default_ = AbsentValue;\n    let i = 0;\n    while (i !== n) {\n      const a = this.poll(default_);\n      if (a === default_) {\n        i = n;\n      } else {\n        builder.push(a);\n        i += 1;\n      }\n    }\n    return Chunk.fromIterable(builder);\n  }\n  unsubscribe() {\n    if (!this.unsubscribed) {\n      this.unsubscribed = true;\n      this.self.publisherTail.subscribers -= 1;\n      while (this.subscriberHead !== this.self.publisherTail) {\n        if (this.subscriberHead.next.value !== AbsentValue) {\n          this.subscriberHead.subscribers -= 1;\n          if (this.subscriberHead.subscribers === 0) {\n            this.self.publisherHead = this.self.publisherHead.next;\n            this.self.publisherHead.value = AbsentValue;\n            this.self.subscribersIndex += 1;\n          }\n        }\n        this.subscriberHead = this.subscriberHead.next;\n      }\n    }\n  }\n}\n/** @internal */\nclass SubscriptionImpl {\n  pubsub;\n  subscribers;\n  subscription;\n  pollers;\n  shutdownHook;\n  shutdownFlag;\n  strategy;\n  replayWindow;\n  [queue.DequeueTypeId] = queue.dequeueVariance;\n  constructor(pubsub, subscribers, subscription, pollers, shutdownHook, shutdownFlag, strategy, replayWindow) {\n    this.pubsub = pubsub;\n    this.subscribers = subscribers;\n    this.subscription = subscription;\n    this.pollers = pollers;\n    this.shutdownHook = shutdownHook;\n    this.shutdownFlag = shutdownFlag;\n    this.strategy = strategy;\n    this.replayWindow = replayWindow;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  capacity() {\n    return this.pubsub.capacity;\n  }\n  isActive() {\n    return !MutableRef.get(this.shutdownFlag);\n  }\n  get size() {\n    return core.suspend(() => MutableRef.get(this.shutdownFlag) ? core.interrupt : core.succeed(this.subscription.size() + this.replayWindow.remaining));\n  }\n  unsafeSize() {\n    if (MutableRef.get(this.shutdownFlag)) {\n      return Option.none();\n    }\n    return Option.some(this.subscription.size() + this.replayWindow.remaining);\n  }\n  get isFull() {\n    return core.suspend(() => MutableRef.get(this.shutdownFlag) ? core.interrupt : core.succeed(this.subscription.size() === this.capacity()));\n  }\n  get isEmpty() {\n    return core.map(this.size, size => size === 0);\n  }\n  get shutdown() {\n    return core.uninterruptible(core.withFiberRuntime(state => {\n      MutableRef.set(this.shutdownFlag, true);\n      return pipe(fiberRuntime.forEachParUnbounded(unsafePollAllQueue(this.pollers), d => core.deferredInterruptWith(d, state.id()), false), core.zipRight(core.sync(() => {\n        this.subscribers.delete(this.subscription);\n        this.subscription.unsubscribe();\n        this.strategy.unsafeOnPubSubEmptySpace(this.pubsub, this.subscribers);\n      })), core.whenEffect(core.deferredSucceed(this.shutdownHook, void 0)), core.asVoid);\n    }));\n  }\n  get isShutdown() {\n    return core.sync(() => MutableRef.get(this.shutdownFlag));\n  }\n  get awaitShutdown() {\n    return core.deferredAwait(this.shutdownHook);\n  }\n  get take() {\n    return core.withFiberRuntime(state => {\n      if (MutableRef.get(this.shutdownFlag)) {\n        return core.interrupt;\n      }\n      if (this.replayWindow.remaining > 0) {\n        const message = this.replayWindow.take();\n        return core.succeed(message);\n      }\n      const message = MutableQueue.isEmpty(this.pollers) ? this.subscription.poll(MutableQueue.EmptyMutableQueue) : MutableQueue.EmptyMutableQueue;\n      if (message === MutableQueue.EmptyMutableQueue) {\n        const deferred = core.deferredUnsafeMake(state.id());\n        return pipe(core.suspend(() => {\n          pipe(this.pollers, MutableQueue.offer(deferred));\n          pipe(this.subscribers, addSubscribers(this.subscription, this.pollers));\n          this.strategy.unsafeCompletePollers(this.pubsub, this.subscribers, this.subscription, this.pollers);\n          return MutableRef.get(this.shutdownFlag) ? core.interrupt : core.deferredAwait(deferred);\n        }), core.onInterrupt(() => core.sync(() => unsafeRemove(this.pollers, deferred))));\n      } else {\n        this.strategy.unsafeOnPubSubEmptySpace(this.pubsub, this.subscribers);\n        return core.succeed(message);\n      }\n    });\n  }\n  get takeAll() {\n    return core.suspend(() => {\n      if (MutableRef.get(this.shutdownFlag)) {\n        return core.interrupt;\n      }\n      const as = MutableQueue.isEmpty(this.pollers) ? unsafePollAllSubscription(this.subscription) : Chunk.empty();\n      this.strategy.unsafeOnPubSubEmptySpace(this.pubsub, this.subscribers);\n      if (this.replayWindow.remaining > 0) {\n        return core.succeed(Chunk.appendAll(this.replayWindow.takeAll(), as));\n      }\n      return core.succeed(as);\n    });\n  }\n  takeUpTo(max) {\n    return core.suspend(() => {\n      if (MutableRef.get(this.shutdownFlag)) {\n        return core.interrupt;\n      }\n      let replay = undefined;\n      if (this.replayWindow.remaining >= max) {\n        const as = this.replayWindow.takeN(max);\n        return core.succeed(as);\n      } else if (this.replayWindow.remaining > 0) {\n        replay = this.replayWindow.takeAll();\n        max = max - replay.length;\n      }\n      const as = MutableQueue.isEmpty(this.pollers) ? unsafePollN(this.subscription, max) : Chunk.empty();\n      this.strategy.unsafeOnPubSubEmptySpace(this.pubsub, this.subscribers);\n      return replay ? core.succeed(Chunk.appendAll(replay, as)) : core.succeed(as);\n    });\n  }\n  takeBetween(min, max) {\n    return core.suspend(() => takeRemainderLoop(this, min, max, Chunk.empty()));\n  }\n}\n/** @internal */\nconst takeRemainderLoop = (self, min, max, acc) => {\n  if (max < min) {\n    return core.succeed(acc);\n  }\n  return pipe(self.takeUpTo(max), core.flatMap(bs => {\n    const remaining = min - bs.length;\n    if (remaining === 1) {\n      return pipe(self.take, core.map(b => pipe(acc, Chunk.appendAll(bs), Chunk.append(b))));\n    }\n    if (remaining > 1) {\n      return pipe(self.take, core.flatMap(b => takeRemainderLoop(self, remaining - 1, max - bs.length - 1, pipe(acc, Chunk.appendAll(bs), Chunk.append(b)))));\n    }\n    return core.succeed(pipe(acc, Chunk.appendAll(bs)));\n  }));\n};\n/** @internal */\nclass PubSubImpl {\n  pubsub;\n  subscribers;\n  scope;\n  shutdownHook;\n  shutdownFlag;\n  strategy;\n  [queue.EnqueueTypeId] = queue.enqueueVariance;\n  [queue.DequeueTypeId] = queue.dequeueVariance;\n  constructor(pubsub, subscribers, scope, shutdownHook, shutdownFlag, strategy) {\n    this.pubsub = pubsub;\n    this.subscribers = subscribers;\n    this.scope = scope;\n    this.shutdownHook = shutdownHook;\n    this.shutdownFlag = shutdownFlag;\n    this.strategy = strategy;\n  }\n  capacity() {\n    return this.pubsub.capacity;\n  }\n  get size() {\n    return core.suspend(() => MutableRef.get(this.shutdownFlag) ? core.interrupt : core.sync(() => this.pubsub.size()));\n  }\n  unsafeSize() {\n    if (MutableRef.get(this.shutdownFlag)) {\n      return Option.none();\n    }\n    return Option.some(this.pubsub.size());\n  }\n  get isFull() {\n    return core.map(this.size, size => size === this.capacity());\n  }\n  get isEmpty() {\n    return core.map(this.size, size => size === 0);\n  }\n  get awaitShutdown() {\n    return core.deferredAwait(this.shutdownHook);\n  }\n  get isShutdown() {\n    return core.sync(() => MutableRef.get(this.shutdownFlag));\n  }\n  get shutdown() {\n    return core.uninterruptible(core.withFiberRuntime(state => {\n      pipe(this.shutdownFlag, MutableRef.set(true));\n      return pipe(this.scope.close(core.exitInterrupt(state.id())), core.zipRight(this.strategy.shutdown), core.whenEffect(core.deferredSucceed(this.shutdownHook, void 0)), core.asVoid);\n    }));\n  }\n  publish(value) {\n    return core.suspend(() => {\n      if (MutableRef.get(this.shutdownFlag)) {\n        return core.interrupt;\n      }\n      if (this.pubsub.publish(value)) {\n        this.strategy.unsafeCompleteSubscribers(this.pubsub, this.subscribers);\n        return core.succeed(true);\n      }\n      return this.strategy.handleSurplus(this.pubsub, this.subscribers, Chunk.of(value), this.shutdownFlag);\n    });\n  }\n  isActive() {\n    return !MutableRef.get(this.shutdownFlag);\n  }\n  unsafeOffer(value) {\n    if (MutableRef.get(this.shutdownFlag)) {\n      return false;\n    }\n    if (this.pubsub.publish(value)) {\n      this.strategy.unsafeCompleteSubscribers(this.pubsub, this.subscribers);\n      return true;\n    }\n    return false;\n  }\n  publishAll(elements) {\n    return core.suspend(() => {\n      if (MutableRef.get(this.shutdownFlag)) {\n        return core.interrupt;\n      }\n      const surplus = unsafePublishAll(this.pubsub, elements);\n      this.strategy.unsafeCompleteSubscribers(this.pubsub, this.subscribers);\n      if (Chunk.isEmpty(surplus)) {\n        return core.succeed(true);\n      }\n      return this.strategy.handleSurplus(this.pubsub, this.subscribers, surplus, this.shutdownFlag);\n    });\n  }\n  get subscribe() {\n    const acquire = core.tap(fiberRuntime.all([this.scope.fork(executionStrategy.sequential), makeSubscription(this.pubsub, this.subscribers, this.strategy)]), tuple => tuple[0].addFinalizer(() => tuple[1].shutdown));\n    return core.map(fiberRuntime.acquireRelease(acquire, (tuple, exit) => tuple[0].close(exit)), tuple => tuple[1]);\n  }\n  offer(value) {\n    return this.publish(value);\n  }\n  offerAll(elements) {\n    return this.publishAll(elements);\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const makePubSub = (pubsub, strategy) => core.flatMap(fiberRuntime.scopeMake(), scope => core.map(core.deferredMake(), deferred => unsafeMakePubSub(pubsub, new Map(), scope, deferred, MutableRef.make(false), strategy)));\n/** @internal */\nexport const unsafeMakePubSub = (pubsub, subscribers, scope, shutdownHook, shutdownFlag, strategy) => new PubSubImpl(pubsub, subscribers, scope, shutdownHook, shutdownFlag, strategy);\n/** @internal */\nconst ensureCapacity = capacity => {\n  if (capacity <= 0) {\n    throw new core.InvalidPubSubCapacityException(`Cannot construct PubSub with capacity of ${capacity}`);\n  }\n};\n/** @internal */\nconst unsafeCompleteDeferred = (deferred, a) => {\n  core.deferredUnsafeDone(deferred, core.succeed(a));\n};\n/** @internal */\nconst unsafeOfferAll = (queue, as) => {\n  return pipe(queue, MutableQueue.offerAll(as));\n};\n/** @internal */\nconst unsafePollAllQueue = queue => {\n  return pipe(queue, MutableQueue.pollUpTo(Number.POSITIVE_INFINITY));\n};\n/** @internal */\nconst unsafePollAllSubscription = subscription => {\n  return subscription.pollUpTo(Number.POSITIVE_INFINITY);\n};\n/** @internal */\nconst unsafePollN = (subscription, max) => {\n  return subscription.pollUpTo(max);\n};\n/** @internal */\nconst unsafePublishAll = (pubsub, as) => {\n  return pubsub.publishAll(as);\n};\n/** @internal */\nconst unsafeRemove = (queue, value) => {\n  unsafeOfferAll(queue, pipe(unsafePollAllQueue(queue), Chunk.filter(elem => elem !== value)));\n};\n/**\n * A strategy that applies back pressure to publishers when the `PubSub` is at\n * capacity. This guarantees that all subscribers will receive all messages\n * published to the `PubSub` while they are subscribed. However, it creates the\n * risk that a slow subscriber will slow down the rate at which messages\n * are published and received by other subscribers.\n *\n * @internal\n */\nclass BackPressureStrategy {\n  publishers = /*#__PURE__*/MutableQueue.unbounded();\n  get shutdown() {\n    return core.flatMap(core.fiberId, fiberId => core.flatMap(core.sync(() => unsafePollAllQueue(this.publishers)), publishers => fiberRuntime.forEachConcurrentDiscard(publishers, ([_, deferred, last]) => last ? pipe(core.deferredInterruptWith(deferred, fiberId), core.asVoid) : core.void, false, false)));\n  }\n  handleSurplus(pubsub, subscribers, elements, isShutdown) {\n    return core.withFiberRuntime(state => {\n      const deferred = core.deferredUnsafeMake(state.id());\n      return pipe(core.suspend(() => {\n        this.unsafeOffer(elements, deferred);\n        this.unsafeOnPubSubEmptySpace(pubsub, subscribers);\n        this.unsafeCompleteSubscribers(pubsub, subscribers);\n        return MutableRef.get(isShutdown) ? core.interrupt : core.deferredAwait(deferred);\n      }), core.onInterrupt(() => core.sync(() => this.unsafeRemove(deferred))));\n    });\n  }\n  unsafeOnPubSubEmptySpace(pubsub, subscribers) {\n    let keepPolling = true;\n    while (keepPolling && !pubsub.isFull()) {\n      const publisher = pipe(this.publishers, MutableQueue.poll(MutableQueue.EmptyMutableQueue));\n      if (publisher === MutableQueue.EmptyMutableQueue) {\n        keepPolling = false;\n      } else {\n        const published = pubsub.publish(publisher[0]);\n        if (published && publisher[2]) {\n          unsafeCompleteDeferred(publisher[1], true);\n        } else if (!published) {\n          unsafeOfferAll(this.publishers, pipe(unsafePollAllQueue(this.publishers), Chunk.prepend(publisher)));\n        }\n        this.unsafeCompleteSubscribers(pubsub, subscribers);\n      }\n    }\n  }\n  unsafeCompletePollers(pubsub, subscribers, subscription, pollers) {\n    return unsafeStrategyCompletePollers(this, pubsub, subscribers, subscription, pollers);\n  }\n  unsafeCompleteSubscribers(pubsub, subscribers) {\n    return unsafeStrategyCompleteSubscribers(this, pubsub, subscribers);\n  }\n  unsafeOffer(elements, deferred) {\n    const iterator = elements[Symbol.iterator]();\n    let next = iterator.next();\n    if (!next.done) {\n      // eslint-disable-next-line no-constant-condition\n      while (1) {\n        const value = next.value;\n        next = iterator.next();\n        if (next.done) {\n          pipe(this.publishers, MutableQueue.offer([value, deferred, true]));\n          break;\n        }\n        pipe(this.publishers, MutableQueue.offer([value, deferred, false]));\n      }\n    }\n  }\n  unsafeRemove(deferred) {\n    unsafeOfferAll(this.publishers, pipe(unsafePollAllQueue(this.publishers), Chunk.filter(([_, a]) => a !== deferred)));\n  }\n}\n/**\n * A strategy that drops new messages when the `PubSub` is at capacity. This\n * guarantees that a slow subscriber will not slow down the rate at which\n * messages are published. However, it creates the risk that a slow\n * subscriber will slow down the rate at which messages are received by\n * other subscribers and that subscribers may not receive all messages\n * published to the `PubSub` while they are subscribed.\n *\n * @internal\n */\nexport class DroppingStrategy {\n  get shutdown() {\n    return core.void;\n  }\n  handleSurplus(_pubsub, _subscribers, _elements, _isShutdown) {\n    return core.succeed(false);\n  }\n  unsafeOnPubSubEmptySpace(_pubsub, _subscribers) {\n    //\n  }\n  unsafeCompletePollers(pubsub, subscribers, subscription, pollers) {\n    return unsafeStrategyCompletePollers(this, pubsub, subscribers, subscription, pollers);\n  }\n  unsafeCompleteSubscribers(pubsub, subscribers) {\n    return unsafeStrategyCompleteSubscribers(this, pubsub, subscribers);\n  }\n}\n/**\n * A strategy that adds new messages and drops old messages when the `PubSub` is\n * at capacity. This guarantees that a slow subscriber will not slow down\n * the rate at which messages are published and received by other\n * subscribers. However, it creates the risk that a slow subscriber will\n * not receive some messages published to the `PubSub` while it is subscribed.\n *\n * @internal\n */\nexport class SlidingStrategy {\n  get shutdown() {\n    return core.void;\n  }\n  handleSurplus(pubsub, subscribers, elements, _isShutdown) {\n    return core.sync(() => {\n      this.unsafeSlidingPublish(pubsub, elements);\n      this.unsafeCompleteSubscribers(pubsub, subscribers);\n      return true;\n    });\n  }\n  unsafeOnPubSubEmptySpace(_pubsub, _subscribers) {\n    //\n  }\n  unsafeCompletePollers(pubsub, subscribers, subscription, pollers) {\n    return unsafeStrategyCompletePollers(this, pubsub, subscribers, subscription, pollers);\n  }\n  unsafeCompleteSubscribers(pubsub, subscribers) {\n    return unsafeStrategyCompleteSubscribers(this, pubsub, subscribers);\n  }\n  unsafeSlidingPublish(pubsub, elements) {\n    const it = elements[Symbol.iterator]();\n    let next = it.next();\n    if (!next.done && pubsub.capacity > 0) {\n      let a = next.value;\n      let loop = true;\n      while (loop) {\n        pubsub.slide();\n        const pub = pubsub.publish(a);\n        if (pub && (next = it.next()) && !next.done) {\n          a = next.value;\n        } else if (pub) {\n          loop = false;\n        }\n      }\n    }\n  }\n}\n/** @internal */\nconst unsafeStrategyCompletePollers = (strategy, pubsub, subscribers, subscription, pollers) => {\n  let keepPolling = true;\n  while (keepPolling && !subscription.isEmpty()) {\n    const poller = pipe(pollers, MutableQueue.poll(MutableQueue.EmptyMutableQueue));\n    if (poller === MutableQueue.EmptyMutableQueue) {\n      pipe(subscribers, removeSubscribers(subscription, pollers));\n      if (MutableQueue.isEmpty(pollers)) {\n        keepPolling = false;\n      } else {\n        pipe(subscribers, addSubscribers(subscription, pollers));\n      }\n    } else {\n      const pollResult = subscription.poll(MutableQueue.EmptyMutableQueue);\n      if (pollResult === MutableQueue.EmptyMutableQueue) {\n        unsafeOfferAll(pollers, pipe(unsafePollAllQueue(pollers), Chunk.prepend(poller)));\n      } else {\n        unsafeCompleteDeferred(poller, pollResult);\n        strategy.unsafeOnPubSubEmptySpace(pubsub, subscribers);\n      }\n    }\n  }\n};\n/** @internal */\nconst unsafeStrategyCompleteSubscribers = (strategy, pubsub, subscribers) => {\n  for (const [subscription, pollersSet] of subscribers) {\n    for (const pollers of pollersSet) {\n      strategy.unsafeCompletePollers(pubsub, subscribers, subscription, pollers);\n    }\n  }\n};\nclass ReplayBuffer {\n  capacity;\n  constructor(capacity) {\n    this.capacity = capacity;\n  }\n  head = {\n    value: AbsentValue,\n    next: null\n  };\n  tail = this.head;\n  size = 0;\n  index = 0;\n  slide() {\n    this.index++;\n  }\n  offer(a) {\n    this.tail.value = a;\n    this.tail.next = {\n      value: AbsentValue,\n      next: null\n    };\n    this.tail = this.tail.next;\n    if (this.size === this.capacity) {\n      this.head = this.head.next;\n    } else {\n      this.size += 1;\n    }\n  }\n  offerAll(as) {\n    for (const a of as) {\n      this.offer(a);\n    }\n  }\n}\nclass ReplayWindowImpl {\n  buffer;\n  head;\n  index;\n  remaining;\n  constructor(buffer) {\n    this.buffer = buffer;\n    this.index = buffer.index;\n    this.remaining = buffer.size;\n    this.head = buffer.head;\n  }\n  fastForward() {\n    while (this.index < this.buffer.index) {\n      this.head = this.head.next;\n      this.index++;\n    }\n  }\n  take() {\n    if (this.remaining === 0) {\n      return undefined;\n    } else if (this.index < this.buffer.index) {\n      this.fastForward();\n    }\n    this.remaining--;\n    const value = this.head.value;\n    this.head = this.head.next;\n    return value;\n  }\n  takeN(n) {\n    if (this.remaining === 0) {\n      return Chunk.empty();\n    } else if (this.index < this.buffer.index) {\n      this.fastForward();\n    }\n    const len = Math.min(n, this.remaining);\n    const items = new Array(len);\n    for (let i = 0; i < len; i++) {\n      const value = this.head.value;\n      this.head = this.head.next;\n      items[i] = value;\n    }\n    this.remaining -= len;\n    return Chunk.unsafeFromArray(items);\n  }\n  takeAll() {\n    return this.takeN(this.remaining);\n  }\n}\nconst emptyReplayWindow = {\n  remaining: 0,\n  take: () => undefined,\n  takeN: () => Chunk.empty(),\n  takeAll: () => Chunk.empty()\n};\n//# sourceMappingURL=pubsub.js.map","import { seconds } from \"../Duration.js\";\nimport { dual } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as BlockedRequests from \"./blockedRequests.js\";\nimport { unsafeMakeWith } from \"./cache.js\";\nimport * as core from \"./core.js\";\nimport { ensuring } from \"./fiberRuntime.js\";\nimport { Listeners } from \"./request.js\";\n/** @internal */\nexport const currentCache = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentCache\"), () => core.fiberRefUnsafeMake(unsafeMakeWith(65536, () => core.map(core.deferredMake(), handle => ({\n  listeners: new Listeners(),\n  handle\n})), () => seconds(60))));\n/** @internal */\nexport const currentCacheEnabled = /*#__PURE__*/globalValue( /*#__PURE__*/Symbol.for(\"effect/FiberRef/currentCacheEnabled\"), () => core.fiberRefUnsafeMake(false));\n/** @internal */\nexport const fromRequest = (request, dataSource) => core.flatMap(core.isEffect(dataSource) ? dataSource : core.succeed(dataSource), ds => core.fiberIdWith(id => {\n  const proxy = new Proxy(request, {});\n  return core.fiberRefGetWith(currentCacheEnabled, cacheEnabled => {\n    if (cacheEnabled) {\n      const cached = core.fiberRefGetWith(currentCache, cache => core.flatMap(cache.getEither(proxy), orNew => {\n        switch (orNew._tag) {\n          case \"Left\":\n            {\n              if (orNew.left.listeners.interrupted) {\n                return core.flatMap(cache.invalidateWhen(proxy, entry => entry.handle === orNew.left.handle), () => cached);\n              }\n              orNew.left.listeners.increment();\n              return core.uninterruptibleMask(restore => core.flatMap(core.exit(core.blocked(BlockedRequests.empty, restore(core.deferredAwait(orNew.left.handle)))), exit => {\n                orNew.left.listeners.decrement();\n                return exit;\n              }));\n            }\n          case \"Right\":\n            {\n              orNew.right.listeners.increment();\n              return core.uninterruptibleMask(restore => core.flatMap(core.exit(core.blocked(BlockedRequests.single(ds, BlockedRequests.makeEntry({\n                request: proxy,\n                result: orNew.right.handle,\n                listeners: orNew.right.listeners,\n                ownerId: id,\n                state: {\n                  completed: false\n                }\n              })), restore(core.deferredAwait(orNew.right.handle)))), () => {\n                orNew.right.listeners.decrement();\n                return core.deferredAwait(orNew.right.handle);\n              }));\n            }\n        }\n      }));\n      return cached;\n    }\n    const listeners = new Listeners();\n    listeners.increment();\n    return core.flatMap(core.deferredMake(), ref => ensuring(core.blocked(BlockedRequests.single(ds, BlockedRequests.makeEntry({\n      request: proxy,\n      result: ref,\n      listeners,\n      ownerId: id,\n      state: {\n        completed: false\n      }\n    })), core.deferredAwait(ref)), core.sync(() => listeners.decrement())));\n  });\n}));\n/** @internal */\nexport const cacheRequest = (request, result) => {\n  return core.fiberRefGetWith(currentCacheEnabled, cacheEnabled => {\n    if (cacheEnabled) {\n      return core.fiberRefGetWith(currentCache, cache => core.flatMap(cache.getEither(request), orNew => {\n        switch (orNew._tag) {\n          case \"Left\":\n            {\n              return core.void;\n            }\n          case \"Right\":\n            {\n              return core.deferredComplete(orNew.right.handle, result);\n            }\n        }\n      }));\n    }\n    return core.void;\n  });\n};\n/** @internal */\nexport const withRequestCaching = /*#__PURE__*/dual(2, (self, strategy) => core.fiberRefLocally(self, currentCacheEnabled, strategy));\n/** @internal */\nexport const withRequestCache = /*#__PURE__*/dual(2,\n// @ts-expect-error\n(self, cache) => core.fiberRefLocally(self, currentCache, cache));\n//# sourceMappingURL=query.js.map","import * as Arr from \"../Array.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as MutableQueue from \"../MutableQueue.js\";\nimport * as MutableRef from \"../MutableRef.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as core from \"./core.js\";\nimport * as fiberRuntime from \"./fiberRuntime.js\";\n/** @internal */\nconst EnqueueSymbolKey = \"effect/QueueEnqueue\";\n/** @internal */\nexport const EnqueueTypeId = /*#__PURE__*/Symbol.for(EnqueueSymbolKey);\n/** @internal */\nconst DequeueSymbolKey = \"effect/QueueDequeue\";\n/** @internal */\nexport const DequeueTypeId = /*#__PURE__*/Symbol.for(DequeueSymbolKey);\n/** @internal */\nconst QueueStrategySymbolKey = \"effect/QueueStrategy\";\n/** @internal */\nexport const QueueStrategyTypeId = /*#__PURE__*/Symbol.for(QueueStrategySymbolKey);\n/** @internal */\nconst BackingQueueSymbolKey = \"effect/BackingQueue\";\n/** @internal */\nexport const BackingQueueTypeId = /*#__PURE__*/Symbol.for(BackingQueueSymbolKey);\nconst queueStrategyVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\nconst backingQueueVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\n/** @internal */\nexport const enqueueVariance = {\n  /* c8 ignore next */\n  _In: _ => _\n};\n/** @internal */\nexport const dequeueVariance = {\n  /* c8 ignore next */\n  _Out: _ => _\n};\n/** @internal */\nclass QueueImpl {\n  queue;\n  takers;\n  shutdownHook;\n  shutdownFlag;\n  strategy;\n  [EnqueueTypeId] = enqueueVariance;\n  [DequeueTypeId] = dequeueVariance;\n  constructor( /** @internal */\n  queue, /** @internal */\n  takers, /** @internal */\n  shutdownHook, /** @internal */\n  shutdownFlag, /** @internal */\n  strategy) {\n    this.queue = queue;\n    this.takers = takers;\n    this.shutdownHook = shutdownHook;\n    this.shutdownFlag = shutdownFlag;\n    this.strategy = strategy;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n  capacity() {\n    return this.queue.capacity();\n  }\n  get size() {\n    return core.suspend(() => core.catchAll(this.unsafeSize(), () => core.interrupt));\n  }\n  unsafeSize() {\n    if (MutableRef.get(this.shutdownFlag)) {\n      return Option.none();\n    }\n    return Option.some(this.queue.length() - MutableQueue.length(this.takers) + this.strategy.surplusSize());\n  }\n  get isEmpty() {\n    return core.map(this.size, size => size <= 0);\n  }\n  get isFull() {\n    return core.map(this.size, size => size >= this.capacity());\n  }\n  get shutdown() {\n    return core.uninterruptible(core.withFiberRuntime(state => {\n      pipe(this.shutdownFlag, MutableRef.set(true));\n      return pipe(fiberRuntime.forEachConcurrentDiscard(unsafePollAll(this.takers), d => core.deferredInterruptWith(d, state.id()), false, false), core.zipRight(this.strategy.shutdown), core.whenEffect(core.deferredSucceed(this.shutdownHook, void 0)), core.asVoid);\n    }));\n  }\n  get isShutdown() {\n    return core.sync(() => MutableRef.get(this.shutdownFlag));\n  }\n  get awaitShutdown() {\n    return core.deferredAwait(this.shutdownHook);\n  }\n  isActive() {\n    return !MutableRef.get(this.shutdownFlag);\n  }\n  unsafeOffer(value) {\n    if (MutableRef.get(this.shutdownFlag)) {\n      return false;\n    }\n    let noRemaining;\n    if (this.queue.length() === 0) {\n      const taker = pipe(this.takers, MutableQueue.poll(MutableQueue.EmptyMutableQueue));\n      if (taker !== MutableQueue.EmptyMutableQueue) {\n        unsafeCompleteDeferred(taker, value);\n        noRemaining = true;\n      } else {\n        noRemaining = false;\n      }\n    } else {\n      noRemaining = false;\n    }\n    if (noRemaining) {\n      return true;\n    }\n    // Not enough takers, offer to the queue\n    const succeeded = this.queue.offer(value);\n    unsafeCompleteTakers(this.strategy, this.queue, this.takers);\n    return succeeded;\n  }\n  offer(value) {\n    return core.suspend(() => {\n      if (MutableRef.get(this.shutdownFlag)) {\n        return core.interrupt;\n      }\n      let noRemaining;\n      if (this.queue.length() === 0) {\n        const taker = pipe(this.takers, MutableQueue.poll(MutableQueue.EmptyMutableQueue));\n        if (taker !== MutableQueue.EmptyMutableQueue) {\n          unsafeCompleteDeferred(taker, value);\n          noRemaining = true;\n        } else {\n          noRemaining = false;\n        }\n      } else {\n        noRemaining = false;\n      }\n      if (noRemaining) {\n        return core.succeed(true);\n      }\n      // Not enough takers, offer to the queue\n      const succeeded = this.queue.offer(value);\n      unsafeCompleteTakers(this.strategy, this.queue, this.takers);\n      return succeeded ? core.succeed(true) : this.strategy.handleSurplus([value], this.queue, this.takers, this.shutdownFlag);\n    });\n  }\n  offerAll(iterable) {\n    return core.suspend(() => {\n      if (MutableRef.get(this.shutdownFlag)) {\n        return core.interrupt;\n      }\n      const values = Arr.fromIterable(iterable);\n      const pTakers = this.queue.length() === 0 ? Arr.fromIterable(unsafePollN(this.takers, values.length)) : Arr.empty;\n      const [forTakers, remaining] = pipe(values, Arr.splitAt(pTakers.length));\n      for (let i = 0; i < pTakers.length; i++) {\n        const taker = pTakers[i];\n        const item = forTakers[i];\n        unsafeCompleteDeferred(taker, item);\n      }\n      if (remaining.length === 0) {\n        return core.succeed(true);\n      }\n      // Not enough takers, offer to the queue\n      const surplus = this.queue.offerAll(remaining);\n      unsafeCompleteTakers(this.strategy, this.queue, this.takers);\n      return Chunk.isEmpty(surplus) ? core.succeed(true) : this.strategy.handleSurplus(surplus, this.queue, this.takers, this.shutdownFlag);\n    });\n  }\n  get take() {\n    return core.withFiberRuntime(state => {\n      if (MutableRef.get(this.shutdownFlag)) {\n        return core.interrupt;\n      }\n      const item = this.queue.poll(MutableQueue.EmptyMutableQueue);\n      if (item !== MutableQueue.EmptyMutableQueue) {\n        this.strategy.unsafeOnQueueEmptySpace(this.queue, this.takers);\n        return core.succeed(item);\n      } else {\n        // Add the deferred to takers, then:\n        // - Try to take again in case a value was added since\n        // - Wait for the deferred to be completed\n        // - Clean up resources in case of interruption\n        const deferred = core.deferredUnsafeMake(state.id());\n        return pipe(core.suspend(() => {\n          pipe(this.takers, MutableQueue.offer(deferred));\n          unsafeCompleteTakers(this.strategy, this.queue, this.takers);\n          return MutableRef.get(this.shutdownFlag) ? core.interrupt : core.deferredAwait(deferred);\n        }), core.onInterrupt(() => {\n          return core.sync(() => unsafeRemove(this.takers, deferred));\n        }));\n      }\n    });\n  }\n  get takeAll() {\n    return core.suspend(() => {\n      return MutableRef.get(this.shutdownFlag) ? core.interrupt : core.sync(() => {\n        const values = this.queue.pollUpTo(Number.POSITIVE_INFINITY);\n        this.strategy.unsafeOnQueueEmptySpace(this.queue, this.takers);\n        return Chunk.fromIterable(values);\n      });\n    });\n  }\n  takeUpTo(max) {\n    return core.suspend(() => MutableRef.get(this.shutdownFlag) ? core.interrupt : core.sync(() => {\n      const values = this.queue.pollUpTo(max);\n      this.strategy.unsafeOnQueueEmptySpace(this.queue, this.takers);\n      return Chunk.fromIterable(values);\n    }));\n  }\n  takeBetween(min, max) {\n    return core.suspend(() => takeRemainderLoop(this, min, max, Chunk.empty()));\n  }\n}\n/** @internal */\nconst takeRemainderLoop = (self, min, max, acc) => {\n  if (max < min) {\n    return core.succeed(acc);\n  }\n  return pipe(takeUpTo(self, max), core.flatMap(bs => {\n    const remaining = min - bs.length;\n    if (remaining === 1) {\n      return pipe(take(self), core.map(b => pipe(acc, Chunk.appendAll(bs), Chunk.append(b))));\n    }\n    if (remaining > 1) {\n      return pipe(take(self), core.flatMap(b => takeRemainderLoop(self, remaining - 1, max - bs.length - 1, pipe(acc, Chunk.appendAll(bs), Chunk.append(b)))));\n    }\n    return core.succeed(pipe(acc, Chunk.appendAll(bs)));\n  }));\n};\n/** @internal */\nexport const isQueue = u => isEnqueue(u) && isDequeue(u);\n/** @internal */\nexport const isEnqueue = u => hasProperty(u, EnqueueTypeId);\n/** @internal */\nexport const isDequeue = u => hasProperty(u, DequeueTypeId);\n/** @internal */\nexport const bounded = requestedCapacity => pipe(core.sync(() => MutableQueue.bounded(requestedCapacity)), core.flatMap(queue => make(backingQueueFromMutableQueue(queue), backPressureStrategy())));\n/** @internal */\nexport const dropping = requestedCapacity => pipe(core.sync(() => MutableQueue.bounded(requestedCapacity)), core.flatMap(queue => make(backingQueueFromMutableQueue(queue), droppingStrategy())));\n/** @internal */\nexport const sliding = requestedCapacity => pipe(core.sync(() => MutableQueue.bounded(requestedCapacity)), core.flatMap(queue => make(backingQueueFromMutableQueue(queue), slidingStrategy())));\n/** @internal */\nexport const unbounded = () => pipe(core.sync(() => MutableQueue.unbounded()), core.flatMap(queue => make(backingQueueFromMutableQueue(queue), droppingStrategy())));\n/** @internal */\nconst unsafeMake = (queue, takers, shutdownHook, shutdownFlag, strategy) => {\n  return new QueueImpl(queue, takers, shutdownHook, shutdownFlag, strategy);\n};\n/** @internal */\nexport const make = (queue, strategy) => pipe(core.deferredMake(), core.map(deferred => unsafeMake(queue, MutableQueue.unbounded(), deferred, MutableRef.make(false), strategy)));\n/** @internal */\nexport class BackingQueueFromMutableQueue {\n  mutable;\n  [BackingQueueTypeId] = backingQueueVariance;\n  constructor(mutable) {\n    this.mutable = mutable;\n  }\n  poll(def) {\n    return MutableQueue.poll(this.mutable, def);\n  }\n  pollUpTo(limit) {\n    return MutableQueue.pollUpTo(this.mutable, limit);\n  }\n  offerAll(elements) {\n    return MutableQueue.offerAll(this.mutable, elements);\n  }\n  offer(element) {\n    return MutableQueue.offer(this.mutable, element);\n  }\n  capacity() {\n    return MutableQueue.capacity(this.mutable);\n  }\n  length() {\n    return MutableQueue.length(this.mutable);\n  }\n}\n/** @internal */\nexport const backingQueueFromMutableQueue = mutable => new BackingQueueFromMutableQueue(mutable);\n/** @internal */\nexport const capacity = self => self.capacity();\n/** @internal */\nexport const size = self => self.size;\n/** @internal */\nexport const isFull = self => self.isFull;\n/** @internal */\nexport const isEmpty = self => self.isEmpty;\n/** @internal */\nexport const isShutdown = self => self.isShutdown;\n/** @internal */\nexport const awaitShutdown = self => self.awaitShutdown;\n/** @internal */\nexport const shutdown = self => self.shutdown;\n/** @internal */\nexport const offer = /*#__PURE__*/dual(2, (self, value) => self.offer(value));\n/** @internal */\nexport const unsafeOffer = /*#__PURE__*/dual(2, (self, value) => self.unsafeOffer(value));\n/** @internal */\nexport const offerAll = /*#__PURE__*/dual(2, (self, iterable) => self.offerAll(iterable));\n/** @internal */\nexport const poll = self => core.map(self.takeUpTo(1), Chunk.head);\n/** @internal */\nexport const take = self => self.take;\n/** @internal */\nexport const takeAll = self => self.takeAll;\n/** @internal */\nexport const takeUpTo = /*#__PURE__*/dual(2, (self, max) => self.takeUpTo(max));\n/** @internal */\nexport const takeBetween = /*#__PURE__*/dual(3, (self, min, max) => self.takeBetween(min, max));\n/** @internal */\nexport const takeN = /*#__PURE__*/dual(2, (self, n) => self.takeBetween(n, n));\n// -----------------------------------------------------------------------------\n// Strategy\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const backPressureStrategy = () => new BackPressureStrategy();\n/** @internal */\nexport const droppingStrategy = () => new DroppingStrategy();\n/** @internal */\nexport const slidingStrategy = () => new SlidingStrategy();\n/** @internal */\nclass BackPressureStrategy {\n  [QueueStrategyTypeId] = queueStrategyVariance;\n  putters = /*#__PURE__*/MutableQueue.unbounded();\n  surplusSize() {\n    return MutableQueue.length(this.putters);\n  }\n  onCompleteTakersWithEmptyQueue(takers) {\n    while (!MutableQueue.isEmpty(this.putters) && !MutableQueue.isEmpty(takers)) {\n      const taker = MutableQueue.poll(takers, void 0);\n      const putter = MutableQueue.poll(this.putters, void 0);\n      if (putter[2]) {\n        unsafeCompleteDeferred(putter[1], true);\n      }\n      unsafeCompleteDeferred(taker, putter[0]);\n    }\n  }\n  get shutdown() {\n    return pipe(core.fiberId, core.flatMap(fiberId => pipe(core.sync(() => unsafePollAll(this.putters)), core.flatMap(putters => fiberRuntime.forEachConcurrentDiscard(putters, ([_, deferred, isLastItem]) => isLastItem ? pipe(core.deferredInterruptWith(deferred, fiberId), core.asVoid) : core.void, false, false)))));\n  }\n  handleSurplus(iterable, queue, takers, isShutdown) {\n    return core.withFiberRuntime(state => {\n      const deferred = core.deferredUnsafeMake(state.id());\n      return pipe(core.suspend(() => {\n        this.unsafeOffer(iterable, deferred);\n        this.unsafeOnQueueEmptySpace(queue, takers);\n        unsafeCompleteTakers(this, queue, takers);\n        return MutableRef.get(isShutdown) ? core.interrupt : core.deferredAwait(deferred);\n      }), core.onInterrupt(() => core.sync(() => this.unsafeRemove(deferred))));\n    });\n  }\n  unsafeOnQueueEmptySpace(queue, takers) {\n    let keepPolling = true;\n    while (keepPolling && (queue.capacity() === Number.POSITIVE_INFINITY || queue.length() < queue.capacity())) {\n      const putter = pipe(this.putters, MutableQueue.poll(MutableQueue.EmptyMutableQueue));\n      if (putter === MutableQueue.EmptyMutableQueue) {\n        keepPolling = false;\n      } else {\n        const offered = queue.offer(putter[0]);\n        if (offered && putter[2]) {\n          unsafeCompleteDeferred(putter[1], true);\n        } else if (!offered) {\n          unsafeOfferAll(this.putters, pipe(unsafePollAll(this.putters), Chunk.prepend(putter)));\n        }\n        unsafeCompleteTakers(this, queue, takers);\n      }\n    }\n  }\n  unsafeOffer(iterable, deferred) {\n    const stuff = Arr.fromIterable(iterable);\n    for (let i = 0; i < stuff.length; i++) {\n      const value = stuff[i];\n      if (i === stuff.length - 1) {\n        pipe(this.putters, MutableQueue.offer([value, deferred, true]));\n      } else {\n        pipe(this.putters, MutableQueue.offer([value, deferred, false]));\n      }\n    }\n  }\n  unsafeRemove(deferred) {\n    unsafeOfferAll(this.putters, pipe(unsafePollAll(this.putters), Chunk.filter(([, _]) => _ !== deferred)));\n  }\n}\n/** @internal */\nclass DroppingStrategy {\n  [QueueStrategyTypeId] = queueStrategyVariance;\n  surplusSize() {\n    return 0;\n  }\n  get shutdown() {\n    return core.void;\n  }\n  onCompleteTakersWithEmptyQueue() {}\n  handleSurplus(_iterable, _queue, _takers, _isShutdown) {\n    return core.succeed(false);\n  }\n  unsafeOnQueueEmptySpace(_queue, _takers) {\n    //\n  }\n}\n/** @internal */\nclass SlidingStrategy {\n  [QueueStrategyTypeId] = queueStrategyVariance;\n  surplusSize() {\n    return 0;\n  }\n  get shutdown() {\n    return core.void;\n  }\n  onCompleteTakersWithEmptyQueue() {}\n  handleSurplus(iterable, queue, takers, _isShutdown) {\n    return core.sync(() => {\n      this.unsafeOffer(queue, iterable);\n      unsafeCompleteTakers(this, queue, takers);\n      return true;\n    });\n  }\n  unsafeOnQueueEmptySpace(_queue, _takers) {\n    //\n  }\n  unsafeOffer(queue, iterable) {\n    const iterator = iterable[Symbol.iterator]();\n    let next;\n    let offering = true;\n    while (!(next = iterator.next()).done && offering) {\n      if (queue.capacity() === 0) {\n        return;\n      }\n      // Poll 1 and retry\n      queue.poll(MutableQueue.EmptyMutableQueue);\n      offering = queue.offer(next.value);\n    }\n  }\n}\n/** @internal */\nconst unsafeCompleteDeferred = (deferred, a) => {\n  return core.deferredUnsafeDone(deferred, core.succeed(a));\n};\n/** @internal */\nconst unsafeOfferAll = (queue, as) => {\n  return pipe(queue, MutableQueue.offerAll(as));\n};\n/** @internal */\nconst unsafePollAll = queue => {\n  return pipe(queue, MutableQueue.pollUpTo(Number.POSITIVE_INFINITY));\n};\n/** @internal */\nconst unsafePollN = (queue, max) => {\n  return pipe(queue, MutableQueue.pollUpTo(max));\n};\n/** @internal */\nexport const unsafeRemove = (queue, a) => {\n  unsafeOfferAll(queue, pipe(unsafePollAll(queue), Chunk.filter(b => a !== b)));\n};\n/** @internal */\nexport const unsafeCompleteTakers = (strategy, queue, takers) => {\n  // Check both a taker and an item are in the queue, starting with the taker\n  let keepPolling = true;\n  while (keepPolling && queue.length() !== 0) {\n    const taker = pipe(takers, MutableQueue.poll(MutableQueue.EmptyMutableQueue));\n    if (taker !== MutableQueue.EmptyMutableQueue) {\n      const element = queue.poll(MutableQueue.EmptyMutableQueue);\n      if (element !== MutableQueue.EmptyMutableQueue) {\n        unsafeCompleteDeferred(taker, element);\n        strategy.unsafeOnQueueEmptySpace(queue, takers);\n      } else {\n        unsafeOfferAll(takers, pipe(unsafePollAll(takers), Chunk.prepend(taker)));\n      }\n      keepPolling = true;\n    } else {\n      keepPolling = false;\n    }\n  }\n  if (keepPolling && queue.length() === 0 && !MutableQueue.isEmpty(takers)) {\n    strategy.onCompleteTakersWithEmptyQueue(takers);\n  }\n};\n//# sourceMappingURL=queue.js.map","import * as Chunk from \"../Chunk.js\";\nimport * as Context from \"../Context.js\";\nimport { pipe } from \"../Function.js\";\nimport * as Hash from \"../Hash.js\";\nimport * as PCGRandom from \"../Utils.js\";\nimport * as core from \"./core.js\";\n/** @internal */\nconst RandomSymbolKey = \"effect/Random\";\n/** @internal */\nexport const RandomTypeId = /*#__PURE__*/Symbol.for(RandomSymbolKey);\n/** @internal */\nexport const randomTag = /*#__PURE__*/Context.GenericTag(\"effect/Random\");\n/** @internal */\nclass RandomImpl {\n  seed;\n  [RandomTypeId] = RandomTypeId;\n  PRNG;\n  constructor(seed) {\n    this.seed = seed;\n    this.PRNG = new PCGRandom.PCGRandom(seed);\n  }\n  get next() {\n    return core.sync(() => this.PRNG.number());\n  }\n  get nextBoolean() {\n    return core.map(this.next, n => n > 0.5);\n  }\n  get nextInt() {\n    return core.sync(() => this.PRNG.integer(Number.MAX_SAFE_INTEGER));\n  }\n  nextRange(min, max) {\n    return core.map(this.next, n => (max - min) * n + min);\n  }\n  nextIntBetween(min, max) {\n    return core.sync(() => this.PRNG.integer(max - min) + min);\n  }\n  shuffle(elements) {\n    return shuffleWith(elements, n => this.nextIntBetween(0, n));\n  }\n}\nconst shuffleWith = (elements, nextIntBounded) => {\n  return core.suspend(() => pipe(core.sync(() => Array.from(elements)), core.flatMap(buffer => {\n    const numbers = [];\n    for (let i = buffer.length; i >= 2; i = i - 1) {\n      numbers.push(i);\n    }\n    return pipe(numbers, core.forEachSequentialDiscard(n => pipe(nextIntBounded(n), core.map(k => swap(buffer, n - 1, k)))), core.as(Chunk.fromIterable(buffer)));\n  })));\n};\nconst swap = (buffer, index1, index2) => {\n  const tmp = buffer[index1];\n  buffer[index1] = buffer[index2];\n  buffer[index2] = tmp;\n  return buffer;\n};\nexport const make = seed => new RandomImpl(Hash.hash(seed));\n//# sourceMappingURL=random.js.map","import * as Chunk from \"../Chunk.js\";\nimport * as Equal from \"../Equal.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as Hash from \"../Hash.js\";\nimport { format, NodeInspectSymbol, toJSON } from \"../Inspectable.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport { Direction, RedBlackTreeIterator } from \"./redBlackTree/iterator.js\";\nimport * as Node from \"./redBlackTree/node.js\";\nimport * as Stack from \"./stack.js\";\nconst RedBlackTreeSymbolKey = \"effect/RedBlackTree\";\n/** @internal */\nexport const RedBlackTreeTypeId = /*#__PURE__*/Symbol.for(RedBlackTreeSymbolKey);\nconst redBlackTreeVariance = {\n  /* c8 ignore next */\n  _Key: _ => _,\n  /* c8 ignore next */\n  _Value: _ => _\n};\nconst RedBlackTreeProto = {\n  [RedBlackTreeTypeId]: redBlackTreeVariance,\n  [Hash.symbol]() {\n    let hash = Hash.hash(RedBlackTreeSymbolKey);\n    for (const item of this) {\n      hash ^= pipe(Hash.hash(item[0]), Hash.combine(Hash.hash(item[1])));\n    }\n    return Hash.cached(this, hash);\n  },\n  [Equal.symbol](that) {\n    if (isRedBlackTree(that)) {\n      if ((this._root?.count ?? 0) !== (that._root?.count ?? 0)) {\n        return false;\n      }\n      const entries = Array.from(that);\n      return Array.from(this).every((itemSelf, i) => {\n        const itemThat = entries[i];\n        return Equal.equals(itemSelf[0], itemThat[0]) && Equal.equals(itemSelf[1], itemThat[1]);\n      });\n    }\n    return false;\n  },\n  [Symbol.iterator]() {\n    const stack = [];\n    let n = this._root;\n    while (n != null) {\n      stack.push(n);\n      n = n.left;\n    }\n    return new RedBlackTreeIterator(this, stack, Direction.Forward);\n  },\n  toString() {\n    return format(this.toJSON());\n  },\n  toJSON() {\n    return {\n      _id: \"RedBlackTree\",\n      values: Array.from(this).map(toJSON)\n    };\n  },\n  [NodeInspectSymbol]() {\n    return this.toJSON();\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n};\nconst makeImpl = (ord, root) => {\n  const tree = Object.create(RedBlackTreeProto);\n  tree._ord = ord;\n  tree._root = root;\n  return tree;\n};\n/** @internal */\nexport const isRedBlackTree = u => hasProperty(u, RedBlackTreeTypeId);\n/** @internal */\nexport const empty = ord => makeImpl(ord, undefined);\n/** @internal */\nexport const fromIterable = /*#__PURE__*/dual(2, (entries, ord) => {\n  let tree = empty(ord);\n  for (const [key, value] of entries) {\n    tree = insert(tree, key, value);\n  }\n  return tree;\n});\n/** @internal */\nexport const make = ord => (...entries) => {\n  return fromIterable(entries, ord);\n};\n/** @internal */\nexport const atBackwards = /*#__PURE__*/dual(2, (self, index) => at(self, index, Direction.Backward));\n/** @internal */\nexport const atForwards = /*#__PURE__*/dual(2, (self, index) => at(self, index, Direction.Forward));\nconst at = (self, index, direction) => {\n  return {\n    [Symbol.iterator]: () => {\n      if (index < 0) {\n        return new RedBlackTreeIterator(self, [], direction);\n      }\n      let node = self._root;\n      const stack = [];\n      while (node !== undefined) {\n        stack.push(node);\n        if (node.left !== undefined) {\n          if (index < node.left.count) {\n            node = node.left;\n            continue;\n          }\n          index -= node.left.count;\n        }\n        if (!index) {\n          return new RedBlackTreeIterator(self, stack, direction);\n        }\n        index -= 1;\n        if (node.right !== undefined) {\n          if (index >= node.right.count) {\n            break;\n          }\n          node = node.right;\n        } else {\n          break;\n        }\n      }\n      return new RedBlackTreeIterator(self, [], direction);\n    }\n  };\n};\n/** @internal */\nexport const findAll = /*#__PURE__*/dual(2, (self, key) => {\n  const stack = [];\n  let node = self._root;\n  let result = Chunk.empty();\n  while (node !== undefined || stack.length > 0) {\n    if (node) {\n      stack.push(node);\n      node = node.left;\n    } else {\n      const current = stack.pop();\n      if (Equal.equals(key, current.key)) {\n        result = Chunk.prepend(current.value)(result);\n      }\n      node = current.right;\n    }\n  }\n  return result;\n});\n/** @internal */\nexport const findFirst = /*#__PURE__*/dual(2, (self, key) => {\n  const cmp = self._ord;\n  let node = self._root;\n  while (node !== undefined) {\n    const d = cmp(key, node.key);\n    if (Equal.equals(key, node.key)) {\n      return Option.some(node.value);\n    }\n    if (d <= 0) {\n      node = node.left;\n    } else {\n      node = node.right;\n    }\n  }\n  return Option.none();\n});\n/** @internal */\nexport const first = self => {\n  let node = self._root;\n  let current = self._root;\n  while (node !== undefined) {\n    current = node;\n    node = node.left;\n  }\n  return current ? Option.some([current.key, current.value]) : Option.none();\n};\n/** @internal */\nexport const getAt = /*#__PURE__*/dual(2, (self, index) => {\n  if (index < 0) {\n    return Option.none();\n  }\n  let root = self._root;\n  let node = undefined;\n  while (root !== undefined) {\n    node = root;\n    if (root.left) {\n      if (index < root.left.count) {\n        root = root.left;\n        continue;\n      }\n      index -= root.left.count;\n    }\n    if (!index) {\n      return Option.some([node.key, node.value]);\n    }\n    index -= 1;\n    if (root.right) {\n      if (index >= root.right.count) {\n        break;\n      }\n      root = root.right;\n    } else {\n      break;\n    }\n  }\n  return Option.none();\n});\n/** @internal */\nexport const getOrder = tree => tree._ord;\n/** @internal */\nexport const has = /*#__PURE__*/dual(2, (self, key) => Option.isSome(findFirst(self, key)));\n/** @internal */\nexport const insert = /*#__PURE__*/dual(3, (self, key, value) => {\n  const cmp = self._ord;\n  // Find point to insert new node at\n  let n = self._root;\n  const n_stack = [];\n  const d_stack = [];\n  while (n != null) {\n    const d = cmp(key, n.key);\n    n_stack.push(n);\n    d_stack.push(d);\n    if (d <= 0) {\n      n = n.left;\n    } else {\n      n = n.right;\n    }\n  }\n  // Rebuild path to leaf node\n  n_stack.push({\n    color: Node.Color.Red,\n    key,\n    value,\n    left: undefined,\n    right: undefined,\n    count: 1\n  });\n  for (let s = n_stack.length - 2; s >= 0; --s) {\n    const n2 = n_stack[s];\n    if (d_stack[s] <= 0) {\n      n_stack[s] = {\n        color: n2.color,\n        key: n2.key,\n        value: n2.value,\n        left: n_stack[s + 1],\n        right: n2.right,\n        count: n2.count + 1\n      };\n    } else {\n      n_stack[s] = {\n        color: n2.color,\n        key: n2.key,\n        value: n2.value,\n        left: n2.left,\n        right: n_stack[s + 1],\n        count: n2.count + 1\n      };\n    }\n  }\n  // Rebalance tree using rotations\n  for (let s = n_stack.length - 1; s > 1; --s) {\n    const p = n_stack[s - 1];\n    const n3 = n_stack[s];\n    if (p.color === Node.Color.Black || n3.color === Node.Color.Black) {\n      break;\n    }\n    const pp = n_stack[s - 2];\n    if (pp.left === p) {\n      if (p.left === n3) {\n        const y = pp.right;\n        if (y && y.color === Node.Color.Red) {\n          p.color = Node.Color.Black;\n          pp.right = Node.repaint(y, Node.Color.Black);\n          pp.color = Node.Color.Red;\n          s -= 1;\n        } else {\n          pp.color = Node.Color.Red;\n          pp.left = p.right;\n          p.color = Node.Color.Black;\n          p.right = pp;\n          n_stack[s - 2] = p;\n          n_stack[s - 1] = n3;\n          Node.recount(pp);\n          Node.recount(p);\n          if (s >= 3) {\n            const ppp = n_stack[s - 3];\n            if (ppp.left === pp) {\n              ppp.left = p;\n            } else {\n              ppp.right = p;\n            }\n          }\n          break;\n        }\n      } else {\n        const y = pp.right;\n        if (y && y.color === Node.Color.Red) {\n          p.color = Node.Color.Black;\n          pp.right = Node.repaint(y, Node.Color.Black);\n          pp.color = Node.Color.Red;\n          s -= 1;\n        } else {\n          p.right = n3.left;\n          pp.color = Node.Color.Red;\n          pp.left = n3.right;\n          n3.color = Node.Color.Black;\n          n3.left = p;\n          n3.right = pp;\n          n_stack[s - 2] = n3;\n          n_stack[s - 1] = p;\n          Node.recount(pp);\n          Node.recount(p);\n          Node.recount(n3);\n          if (s >= 3) {\n            const ppp = n_stack[s - 3];\n            if (ppp.left === pp) {\n              ppp.left = n3;\n            } else {\n              ppp.right = n3;\n            }\n          }\n          break;\n        }\n      }\n    } else {\n      if (p.right === n3) {\n        const y = pp.left;\n        if (y && y.color === Node.Color.Red) {\n          p.color = Node.Color.Black;\n          pp.left = Node.repaint(y, Node.Color.Black);\n          pp.color = Node.Color.Red;\n          s -= 1;\n        } else {\n          pp.color = Node.Color.Red;\n          pp.right = p.left;\n          p.color = Node.Color.Black;\n          p.left = pp;\n          n_stack[s - 2] = p;\n          n_stack[s - 1] = n3;\n          Node.recount(pp);\n          Node.recount(p);\n          if (s >= 3) {\n            const ppp = n_stack[s - 3];\n            if (ppp.right === pp) {\n              ppp.right = p;\n            } else {\n              ppp.left = p;\n            }\n          }\n          break;\n        }\n      } else {\n        const y = pp.left;\n        if (y && y.color === Node.Color.Red) {\n          p.color = Node.Color.Black;\n          pp.left = Node.repaint(y, Node.Color.Black);\n          pp.color = Node.Color.Red;\n          s -= 1;\n        } else {\n          p.left = n3.right;\n          pp.color = Node.Color.Red;\n          pp.right = n3.left;\n          n3.color = Node.Color.Black;\n          n3.right = p;\n          n3.left = pp;\n          n_stack[s - 2] = n3;\n          n_stack[s - 1] = p;\n          Node.recount(pp);\n          Node.recount(p);\n          Node.recount(n3);\n          if (s >= 3) {\n            const ppp = n_stack[s - 3];\n            if (ppp.right === pp) {\n              ppp.right = n3;\n            } else {\n              ppp.left = n3;\n            }\n          }\n          break;\n        }\n      }\n    }\n  }\n  // Return new tree\n  n_stack[0].color = Node.Color.Black;\n  return makeImpl(self._ord, n_stack[0]);\n});\n/** @internal */\nexport const keysForward = self => keys(self, Direction.Forward);\n/** @internal */\nexport const keysBackward = self => keys(self, Direction.Backward);\nconst keys = (self, direction) => {\n  const begin = self[Symbol.iterator]();\n  let count = 0;\n  return {\n    [Symbol.iterator]: () => keys(self, direction),\n    next: () => {\n      count++;\n      const entry = begin.key;\n      if (direction === Direction.Forward) {\n        begin.moveNext();\n      } else {\n        begin.movePrev();\n      }\n      switch (entry._tag) {\n        case \"None\":\n          {\n            return {\n              done: true,\n              value: count\n            };\n          }\n        case \"Some\":\n          {\n            return {\n              done: false,\n              value: entry.value\n            };\n          }\n      }\n    }\n  };\n};\n/** @internal */\nexport const last = self => {\n  let node = self._root;\n  let current = self._root;\n  while (node !== undefined) {\n    current = node;\n    node = node.right;\n  }\n  return current ? Option.some([current.key, current.value]) : Option.none();\n};\n/** @internal */\nexport const reversed = self => {\n  return {\n    [Symbol.iterator]: () => {\n      const stack = [];\n      let node = self._root;\n      while (node !== undefined) {\n        stack.push(node);\n        node = node.right;\n      }\n      return new RedBlackTreeIterator(self, stack, Direction.Backward);\n    }\n  };\n};\n/** @internal */\nexport const greaterThanBackwards = /*#__PURE__*/dual(2, (self, key) => greaterThan(self, key, Direction.Backward));\n/** @internal */\nexport const greaterThanForwards = /*#__PURE__*/dual(2, (self, key) => greaterThan(self, key, Direction.Forward));\nconst greaterThan = (self, key, direction) => {\n  return {\n    [Symbol.iterator]: () => {\n      const cmp = self._ord;\n      let node = self._root;\n      const stack = [];\n      let last_ptr = 0;\n      while (node !== undefined) {\n        const d = cmp(key, node.key);\n        stack.push(node);\n        if (d < 0) {\n          last_ptr = stack.length;\n        }\n        if (d < 0) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      }\n      stack.length = last_ptr;\n      return new RedBlackTreeIterator(self, stack, direction);\n    }\n  };\n};\n/** @internal */\nexport const greaterThanEqualBackwards = /*#__PURE__*/dual(2, (self, key) => greaterThanEqual(self, key, Direction.Backward));\n/** @internal */\nexport const greaterThanEqualForwards = /*#__PURE__*/dual(2, (self, key) => greaterThanEqual(self, key, Direction.Forward));\nconst greaterThanEqual = (self, key, direction = Direction.Forward) => {\n  return {\n    [Symbol.iterator]: () => {\n      const cmp = self._ord;\n      let node = self._root;\n      const stack = [];\n      let last_ptr = 0;\n      while (node !== undefined) {\n        const d = cmp(key, node.key);\n        stack.push(node);\n        if (d <= 0) {\n          last_ptr = stack.length;\n        }\n        if (d <= 0) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      }\n      stack.length = last_ptr;\n      return new RedBlackTreeIterator(self, stack, direction);\n    }\n  };\n};\n/** @internal */\nexport const lessThanBackwards = /*#__PURE__*/dual(2, (self, key) => lessThan(self, key, Direction.Backward));\n/** @internal */\nexport const lessThanForwards = /*#__PURE__*/dual(2, (self, key) => lessThan(self, key, Direction.Forward));\nconst lessThan = (self, key, direction) => {\n  return {\n    [Symbol.iterator]: () => {\n      const cmp = self._ord;\n      let node = self._root;\n      const stack = [];\n      let last_ptr = 0;\n      while (node !== undefined) {\n        const d = cmp(key, node.key);\n        stack.push(node);\n        if (d > 0) {\n          last_ptr = stack.length;\n        }\n        if (d <= 0) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      }\n      stack.length = last_ptr;\n      return new RedBlackTreeIterator(self, stack, direction);\n    }\n  };\n};\n/** @internal */\nexport const lessThanEqualBackwards = /*#__PURE__*/dual(2, (self, key) => lessThanEqual(self, key, Direction.Backward));\n/** @internal */\nexport const lessThanEqualForwards = /*#__PURE__*/dual(2, (self, key) => lessThanEqual(self, key, Direction.Forward));\nconst lessThanEqual = (self, key, direction) => {\n  return {\n    [Symbol.iterator]: () => {\n      const cmp = self._ord;\n      let node = self._root;\n      const stack = [];\n      let last_ptr = 0;\n      while (node !== undefined) {\n        const d = cmp(key, node.key);\n        stack.push(node);\n        if (d >= 0) {\n          last_ptr = stack.length;\n        }\n        if (d < 0) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      }\n      stack.length = last_ptr;\n      return new RedBlackTreeIterator(self, stack, direction);\n    }\n  };\n};\n/** @internal */\nexport const forEach = /*#__PURE__*/dual(2, (self, f) => {\n  const root = self._root;\n  if (root !== undefined) {\n    visitFull(root, (key, value) => {\n      f(key, value);\n      return Option.none();\n    });\n  }\n});\n/** @internal */\nexport const forEachGreaterThanEqual = /*#__PURE__*/dual(3, (self, min, f) => {\n  const root = self._root;\n  const ord = self._ord;\n  if (root !== undefined) {\n    visitGreaterThanEqual(root, min, ord, (key, value) => {\n      f(key, value);\n      return Option.none();\n    });\n  }\n});\n/** @internal */\nexport const forEachLessThan = /*#__PURE__*/dual(3, (self, max, f) => {\n  const root = self._root;\n  const ord = self._ord;\n  if (root !== undefined) {\n    visitLessThan(root, max, ord, (key, value) => {\n      f(key, value);\n      return Option.none();\n    });\n  }\n});\n/** @internal */\nexport const forEachBetween = /*#__PURE__*/dual(2, (self, {\n  body,\n  max,\n  min\n}) => {\n  const root = self._root;\n  const ord = self._ord;\n  if (root) {\n    visitBetween(root, min, max, ord, (key, value) => {\n      body(key, value);\n      return Option.none();\n    });\n  }\n});\n/** @internal */\nexport const reduce = /*#__PURE__*/dual(3, (self, zero, f) => {\n  let accumulator = zero;\n  for (const entry of self) {\n    accumulator = f(accumulator, entry[1], entry[0]);\n  }\n  return accumulator;\n});\n/** @internal */\nexport const removeFirst = /*#__PURE__*/dual(2, (self, key) => {\n  if (!has(self, key)) {\n    return self;\n  }\n  const ord = self._ord;\n  const cmp = ord;\n  let node = self._root;\n  const stack = [];\n  while (node !== undefined) {\n    const d = cmp(key, node.key);\n    stack.push(node);\n    if (Equal.equals(key, node.key)) {\n      node = undefined;\n    } else if (d <= 0) {\n      node = node.left;\n    } else {\n      node = node.right;\n    }\n  }\n  if (stack.length === 0) {\n    return self;\n  }\n  const cstack = new Array(stack.length);\n  let n = stack[stack.length - 1];\n  cstack[cstack.length - 1] = {\n    color: n.color,\n    key: n.key,\n    value: n.value,\n    left: n.left,\n    right: n.right,\n    count: n.count\n  };\n  for (let i = stack.length - 2; i >= 0; --i) {\n    n = stack[i];\n    if (n.left === stack[i + 1]) {\n      cstack[i] = {\n        color: n.color,\n        key: n.key,\n        value: n.value,\n        left: cstack[i + 1],\n        right: n.right,\n        count: n.count\n      };\n    } else {\n      cstack[i] = {\n        color: n.color,\n        key: n.key,\n        value: n.value,\n        left: n.left,\n        right: cstack[i + 1],\n        count: n.count\n      };\n    }\n  }\n  // Get node\n  n = cstack[cstack.length - 1];\n  // If not leaf, then swap with previous node\n  if (n.left !== undefined && n.right !== undefined) {\n    // First walk to previous leaf\n    const split = cstack.length;\n    n = n.left;\n    while (n.right != null) {\n      cstack.push(n);\n      n = n.right;\n    }\n    // Copy path to leaf\n    const v = cstack[split - 1];\n    cstack.push({\n      color: n.color,\n      key: v.key,\n      value: v.value,\n      left: n.left,\n      right: n.right,\n      count: n.count\n    });\n    cstack[split - 1].key = n.key;\n    cstack[split - 1].value = n.value;\n    // Fix up stack\n    for (let i = cstack.length - 2; i >= split; --i) {\n      n = cstack[i];\n      cstack[i] = {\n        color: n.color,\n        key: n.key,\n        value: n.value,\n        left: n.left,\n        right: cstack[i + 1],\n        count: n.count\n      };\n    }\n    cstack[split - 1].left = cstack[split];\n  }\n  // Remove leaf node\n  n = cstack[cstack.length - 1];\n  if (n.color === Node.Color.Red) {\n    // Easy case: removing red leaf\n    const p = cstack[cstack.length - 2];\n    if (p.left === n) {\n      p.left = undefined;\n    } else if (p.right === n) {\n      p.right = undefined;\n    }\n    cstack.pop();\n    for (let i = 0; i < cstack.length; ++i) {\n      cstack[i].count--;\n    }\n    return makeImpl(ord, cstack[0]);\n  } else {\n    if (n.left !== undefined || n.right !== undefined) {\n      // Second easy case:  Single child black parent\n      if (n.left !== undefined) {\n        Node.swap(n, n.left);\n      } else if (n.right !== undefined) {\n        Node.swap(n, n.right);\n      }\n      // Child must be red, so repaint it black to balance color\n      n.color = Node.Color.Black;\n      for (let i = 0; i < cstack.length - 1; ++i) {\n        cstack[i].count--;\n      }\n      return makeImpl(ord, cstack[0]);\n    } else if (cstack.length === 1) {\n      // Third easy case: root\n      return makeImpl(ord, undefined);\n    } else {\n      // Hard case: Repaint n, and then do some nasty stuff\n      for (let i = 0; i < cstack.length; ++i) {\n        cstack[i].count--;\n      }\n      const parent = cstack[cstack.length - 2];\n      fixDoubleBlack(cstack);\n      // Fix up links\n      if (parent.left === n) {\n        parent.left = undefined;\n      } else {\n        parent.right = undefined;\n      }\n    }\n  }\n  return makeImpl(ord, cstack[0]);\n});\n/** @internal */\nexport const size = self => self._root?.count ?? 0;\n/** @internal */\nexport const valuesForward = self => values(self, Direction.Forward);\n/** @internal */\nexport const valuesBackward = self => values(self, Direction.Backward);\n/** @internal */\nconst values = (self, direction) => {\n  const begin = self[Symbol.iterator]();\n  let count = 0;\n  return {\n    [Symbol.iterator]: () => values(self, direction),\n    next: () => {\n      count++;\n      const entry = begin.value;\n      if (direction === Direction.Forward) {\n        begin.moveNext();\n      } else {\n        begin.movePrev();\n      }\n      switch (entry._tag) {\n        case \"None\":\n          {\n            return {\n              done: true,\n              value: count\n            };\n          }\n        case \"Some\":\n          {\n            return {\n              done: false,\n              value: entry.value\n            };\n          }\n      }\n    }\n  };\n};\nconst visitFull = (node, visit) => {\n  let current = node;\n  let stack = undefined;\n  let done = false;\n  while (!done) {\n    if (current != null) {\n      stack = Stack.make(current, stack);\n      current = current.left;\n    } else if (stack != null) {\n      const value = visit(stack.value.key, stack.value.value);\n      if (Option.isSome(value)) {\n        return value;\n      }\n      current = stack.value.right;\n      stack = stack.previous;\n    } else {\n      done = true;\n    }\n  }\n  return Option.none();\n};\nconst visitGreaterThanEqual = (node, min, ord, visit) => {\n  let current = node;\n  let stack = undefined;\n  let done = false;\n  while (!done) {\n    if (current !== undefined) {\n      stack = Stack.make(current, stack);\n      if (ord(min, current.key) <= 0) {\n        current = current.left;\n      } else {\n        current = undefined;\n      }\n    } else if (stack !== undefined) {\n      if (ord(min, stack.value.key) <= 0) {\n        const value = visit(stack.value.key, stack.value.value);\n        if (Option.isSome(value)) {\n          return value;\n        }\n      }\n      current = stack.value.right;\n      stack = stack.previous;\n    } else {\n      done = true;\n    }\n  }\n  return Option.none();\n};\nconst visitLessThan = (node, max, ord, visit) => {\n  let current = node;\n  let stack = undefined;\n  let done = false;\n  while (!done) {\n    if (current !== undefined) {\n      stack = Stack.make(current, stack);\n      current = current.left;\n    } else if (stack !== undefined && ord(max, stack.value.key) > 0) {\n      const value = visit(stack.value.key, stack.value.value);\n      if (Option.isSome(value)) {\n        return value;\n      }\n      current = stack.value.right;\n      stack = stack.previous;\n    } else {\n      done = true;\n    }\n  }\n  return Option.none();\n};\nconst visitBetween = (node, min, max, ord, visit) => {\n  let current = node;\n  let stack = undefined;\n  let done = false;\n  while (!done) {\n    if (current !== undefined) {\n      stack = Stack.make(current, stack);\n      if (ord(min, current.key) <= 0) {\n        current = current.left;\n      } else {\n        current = undefined;\n      }\n    } else if (stack !== undefined && ord(max, stack.value.key) > 0) {\n      if (ord(min, stack.value.key) <= 0) {\n        const value = visit(stack.value.key, stack.value.value);\n        if (Option.isSome(value)) {\n          return value;\n        }\n      }\n      current = stack.value.right;\n      stack = stack.previous;\n    } else {\n      done = true;\n    }\n  }\n  return Option.none();\n};\n/**\n * Fix up a double black node in a Red-Black Tree.\n */\nconst fixDoubleBlack = stack => {\n  let n, p, s, z;\n  for (let i = stack.length - 1; i >= 0; --i) {\n    n = stack[i];\n    if (i === 0) {\n      n.color = Node.Color.Black;\n      return;\n    }\n    p = stack[i - 1];\n    if (p.left === n) {\n      s = p.right;\n      if (s !== undefined && s.right !== undefined && s.right.color === Node.Color.Red) {\n        s = p.right = Node.clone(s);\n        z = s.right = Node.clone(s.right);\n        p.right = s.left;\n        s.left = p;\n        s.right = z;\n        s.color = p.color;\n        n.color = Node.Color.Black;\n        p.color = Node.Color.Black;\n        z.color = Node.Color.Black;\n        Node.recount(p);\n        Node.recount(s);\n        if (i > 1) {\n          const pp = stack[i - 2];\n          if (pp.left === p) {\n            pp.left = s;\n          } else {\n            pp.right = s;\n          }\n        }\n        stack[i - 1] = s;\n        return;\n      } else if (s !== undefined && s.left !== undefined && s.left.color === Node.Color.Red) {\n        s = p.right = Node.clone(s);\n        z = s.left = Node.clone(s.left);\n        p.right = z.left;\n        s.left = z.right;\n        z.left = p;\n        z.right = s;\n        z.color = p.color;\n        p.color = Node.Color.Black;\n        s.color = Node.Color.Black;\n        n.color = Node.Color.Black;\n        Node.recount(p);\n        Node.recount(s);\n        Node.recount(z);\n        if (i > 1) {\n          const pp = stack[i - 2];\n          if (pp.left === p) {\n            pp.left = z;\n          } else {\n            pp.right = z;\n          }\n        }\n        stack[i - 1] = z;\n        return;\n      }\n      if (s !== undefined && s.color === Node.Color.Black) {\n        if (p.color === Node.Color.Red) {\n          p.color = Node.Color.Black;\n          p.right = Node.repaint(s, Node.Color.Red);\n          return;\n        } else {\n          p.right = Node.repaint(s, Node.Color.Red);\n          continue;\n        }\n      } else if (s !== undefined) {\n        s = Node.clone(s);\n        p.right = s.left;\n        s.left = p;\n        s.color = p.color;\n        p.color = Node.Color.Red;\n        Node.recount(p);\n        Node.recount(s);\n        if (i > 1) {\n          const pp = stack[i - 2];\n          if (pp.left === p) {\n            pp.left = s;\n          } else {\n            pp.right = s;\n          }\n        }\n        stack[i - 1] = s;\n        stack[i] = p;\n        if (i + 1 < stack.length) {\n          stack[i + 1] = n;\n        } else {\n          stack.push(n);\n        }\n        i = i + 2;\n      }\n    } else {\n      s = p.left;\n      if (s !== undefined && s.left !== undefined && s.left.color === Node.Color.Red) {\n        s = p.left = Node.clone(s);\n        z = s.left = Node.clone(s.left);\n        p.left = s.right;\n        s.right = p;\n        s.left = z;\n        s.color = p.color;\n        n.color = Node.Color.Black;\n        p.color = Node.Color.Black;\n        z.color = Node.Color.Black;\n        Node.recount(p);\n        Node.recount(s);\n        if (i > 1) {\n          const pp = stack[i - 2];\n          if (pp.right === p) {\n            pp.right = s;\n          } else {\n            pp.left = s;\n          }\n        }\n        stack[i - 1] = s;\n        return;\n      } else if (s !== undefined && s.right !== undefined && s.right.color === Node.Color.Red) {\n        s = p.left = Node.clone(s);\n        z = s.right = Node.clone(s.right);\n        p.left = z.right;\n        s.right = z.left;\n        z.right = p;\n        z.left = s;\n        z.color = p.color;\n        p.color = Node.Color.Black;\n        s.color = Node.Color.Black;\n        n.color = Node.Color.Black;\n        Node.recount(p);\n        Node.recount(s);\n        Node.recount(z);\n        if (i > 1) {\n          const pp = stack[i - 2];\n          if (pp.right === p) {\n            pp.right = z;\n          } else {\n            pp.left = z;\n          }\n        }\n        stack[i - 1] = z;\n        return;\n      }\n      if (s !== undefined && s.color === Node.Color.Black) {\n        if (p.color === Node.Color.Red) {\n          p.color = Node.Color.Black;\n          p.left = Node.repaint(s, Node.Color.Red);\n          return;\n        } else {\n          p.left = Node.repaint(s, Node.Color.Red);\n          continue;\n        }\n      } else if (s !== undefined) {\n        s = Node.clone(s);\n        p.left = s.right;\n        s.right = p;\n        s.color = p.color;\n        p.color = Node.Color.Red;\n        Node.recount(p);\n        Node.recount(s);\n        if (i > 1) {\n          const pp = stack[i - 2];\n          if (pp.right === p) {\n            pp.right = s;\n          } else {\n            pp.left = s;\n          }\n        }\n        stack[i - 1] = s;\n        stack[i] = p;\n        if (i + 1 < stack.length) {\n          stack[i + 1] = n;\n        } else {\n          stack.push(n);\n        }\n        i = i + 2;\n      }\n    }\n  }\n};\n//# sourceMappingURL=redBlackTree.js.map","import * as Arr from \"../../Array.js\";\nimport * as Option from \"../../Option.js\";\n/** @internal */\nexport const Direction = {\n  Forward: 0,\n  Backward: 1 << 0\n};\n/** @internal */\nexport class RedBlackTreeIterator {\n  self;\n  stack;\n  direction;\n  count = 0;\n  constructor(self, stack, direction) {\n    this.self = self;\n    this.stack = stack;\n    this.direction = direction;\n  }\n  /**\n   * Clones the iterator\n   */\n  clone() {\n    return new RedBlackTreeIterator(this.self, this.stack.slice(), this.direction);\n  }\n  /**\n   * Reverse the traversal direction\n   */\n  reversed() {\n    return new RedBlackTreeIterator(this.self, this.stack.slice(), this.direction === Direction.Forward ? Direction.Backward : Direction.Forward);\n  }\n  /**\n   * Iterator next\n   */\n  next() {\n    const entry = this.entry;\n    this.count++;\n    if (this.direction === Direction.Forward) {\n      this.moveNext();\n    } else {\n      this.movePrev();\n    }\n    switch (entry._tag) {\n      case \"None\":\n        {\n          return {\n            done: true,\n            value: this.count\n          };\n        }\n      case \"Some\":\n        {\n          return {\n            done: false,\n            value: entry.value\n          };\n        }\n    }\n  }\n  /**\n   * Returns the key\n   */\n  get key() {\n    if (this.stack.length > 0) {\n      return Option.some(this.stack[this.stack.length - 1].key);\n    }\n    return Option.none();\n  }\n  /**\n   * Returns the value\n   */\n  get value() {\n    if (this.stack.length > 0) {\n      return Option.some(this.stack[this.stack.length - 1].value);\n    }\n    return Option.none();\n  }\n  /**\n   * Returns the key\n   */\n  get entry() {\n    return Option.map(Arr.last(this.stack), node => [node.key, node.value]);\n  }\n  /**\n   * Returns the position of this iterator in the sorted list\n   */\n  get index() {\n    let idx = 0;\n    const stack = this.stack;\n    if (stack.length === 0) {\n      const r = this.self._root;\n      if (r != null) {\n        return r.count;\n      }\n      return 0;\n    } else if (stack[stack.length - 1].left != null) {\n      idx = stack[stack.length - 1].left.count;\n    }\n    for (let s = stack.length - 2; s >= 0; --s) {\n      if (stack[s + 1] === stack[s].right) {\n        ;\n        ++idx;\n        if (stack[s].left != null) {\n          idx += stack[s].left.count;\n        }\n      }\n    }\n    return idx;\n  }\n  /**\n   * Advances iterator to next element in list\n   */\n  moveNext() {\n    const stack = this.stack;\n    if (stack.length === 0) {\n      return;\n    }\n    let n = stack[stack.length - 1];\n    if (n.right != null) {\n      n = n.right;\n      while (n != null) {\n        stack.push(n);\n        n = n.left;\n      }\n    } else {\n      stack.pop();\n      while (stack.length > 0 && stack[stack.length - 1].right === n) {\n        n = stack[stack.length - 1];\n        stack.pop();\n      }\n    }\n  }\n  /**\n   * Checks if there is a next element\n   */\n  get hasNext() {\n    const stack = this.stack;\n    if (stack.length === 0) {\n      return false;\n    }\n    if (stack[stack.length - 1].right != null) {\n      return true;\n    }\n    for (let s = stack.length - 1; s > 0; --s) {\n      if (stack[s - 1].left === stack[s]) {\n        return true;\n      }\n    }\n    return false;\n  }\n  /**\n   * Advances iterator to previous element in list\n   */\n  movePrev() {\n    const stack = this.stack;\n    if (stack.length === 0) {\n      return;\n    }\n    let n = stack[stack.length - 1];\n    if (n != null && n.left != null) {\n      n = n.left;\n      while (n != null) {\n        stack.push(n);\n        n = n.right;\n      }\n    } else {\n      stack.pop();\n      while (stack.length > 0 && stack[stack.length - 1].left === n) {\n        n = stack[stack.length - 1];\n        stack.pop();\n      }\n    }\n  }\n  /**\n   * Checks if there is a previous element\n   */\n  get hasPrev() {\n    const stack = this.stack;\n    if (stack.length === 0) {\n      return false;\n    }\n    if (stack[stack.length - 1].left != null) {\n      return true;\n    }\n    for (let s = stack.length - 1; s > 0; --s) {\n      if (stack[s - 1].right === stack[s]) {\n        return true;\n      }\n    }\n    return false;\n  }\n}\n//# sourceMappingURL=iterator.js.map","/** @internal */\nexport const Color = {\n  Red: 0,\n  Black: 1 << 0\n};\n/** @internal */\nexport const clone = ({\n  color,\n  count,\n  key,\n  left,\n  right,\n  value\n}) => ({\n  color,\n  key,\n  value,\n  left,\n  right,\n  count\n});\n/** @internal */\nexport function swap(n, v) {\n  n.key = v.key;\n  n.value = v.value;\n  n.left = v.left;\n  n.right = v.right;\n  n.color = v.color;\n  n.count = v.count;\n}\n/** @internal */\nexport const repaint = ({\n  count,\n  key,\n  left,\n  right,\n  value\n}, color) => ({\n  color,\n  key,\n  value,\n  left,\n  right,\n  count\n});\n/** @internal */\nexport const recount = node => {\n  node.count = 1 + (node.left?.count ?? 0) + (node.right?.count ?? 0);\n};\n//# sourceMappingURL=node.js.map","import * as Equal from \"../Equal.js\";\nimport { pipe } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as Hash from \"../Hash.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\n/** @internal */\nconst RedactedSymbolKey = \"effect/Redacted\";\n/** @internal */\nexport const redactedRegistry = /*#__PURE__*/globalValue(\"effect/Redacted/redactedRegistry\", () => new WeakMap());\n/** @internal */\nexport const RedactedTypeId = /*#__PURE__*/Symbol.for(RedactedSymbolKey);\n/** @internal */\nexport const proto = {\n  [RedactedTypeId]: {\n    _A: _ => _\n  },\n  pipe() {\n    return pipeArguments(this, arguments);\n  },\n  toString() {\n    return \"<redacted>\";\n  },\n  toJSON() {\n    return \"<redacted>\";\n  },\n  [Hash.symbol]() {\n    return pipe(Hash.hash(RedactedSymbolKey), Hash.combine(Hash.hash(redactedRegistry.get(this))), Hash.cached(this));\n  },\n  [Equal.symbol](that) {\n    return isRedacted(that) && Equal.equals(redactedRegistry.get(this), redactedRegistry.get(that));\n  }\n};\n/** @internal */\nexport const isRedacted = u => hasProperty(u, RedactedTypeId);\n/** @internal */\nexport const make = value => {\n  const redacted = Object.create(proto);\n  redactedRegistry.set(redacted, value);\n  return redacted;\n};\n/** @internal */\nexport const value = self => {\n  if (redactedRegistry.has(self)) {\n    return redactedRegistry.get(self);\n  } else {\n    throw new Error(\"Unable to get redacted value\");\n  }\n};\n/** @internal */\nexport const unsafeWipe = self => redactedRegistry.delete(self);\n//# sourceMappingURL=redacted.js.map","import { dual } from \"../Function.js\";\nimport * as MutableRef from \"../MutableRef.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport * as Readable from \"../Readable.js\";\nimport * as core from \"./core.js\";\n/** @internal */\nexport const RefTypeId = /*#__PURE__*/Symbol.for(\"effect/Ref\");\n/** @internal */\nexport const refVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\nclass RefImpl {\n  ref;\n  [RefTypeId] = refVariance;\n  [Readable.TypeId];\n  constructor(ref) {\n    this.ref = ref;\n    this[Readable.TypeId] = Readable.TypeId;\n    this.get = core.sync(() => MutableRef.get(this.ref));\n  }\n  get;\n  modify(f) {\n    return core.sync(() => {\n      const current = MutableRef.get(this.ref);\n      const [b, a] = f(current);\n      if (current !== a) {\n        MutableRef.set(a)(this.ref);\n      }\n      return b;\n    });\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const unsafeMake = value => new RefImpl(MutableRef.make(value));\n/** @internal */\nexport const make = value => core.sync(() => unsafeMake(value));\n/** @internal */\nexport const get = self => self.get;\n/** @internal */\nexport const set = /*#__PURE__*/dual(2, (self, value) => self.modify(() => [void 0, value]));\n/** @internal */\nexport const getAndSet = /*#__PURE__*/dual(2, (self, value) => self.modify(a => [a, value]));\n/** @internal */\nexport const getAndUpdate = /*#__PURE__*/dual(2, (self, f) => self.modify(a => [a, f(a)]));\n/** @internal */\nexport const getAndUpdateSome = /*#__PURE__*/dual(2, (self, pf) => self.modify(value => {\n  const option = pf(value);\n  switch (option._tag) {\n    case \"None\":\n      {\n        return [value, value];\n      }\n    case \"Some\":\n      {\n        return [value, option.value];\n      }\n  }\n}));\n/** @internal */\nexport const setAndGet = /*#__PURE__*/dual(2, (self, value) => self.modify(() => [value, value]));\n/** @internal */\nexport const modify = /*#__PURE__*/dual(2, (self, f) => self.modify(f));\n/** @internal */\nexport const modifySome = /*#__PURE__*/dual(3, (self, fallback, pf) => self.modify(value => {\n  const option = pf(value);\n  switch (option._tag) {\n    case \"None\":\n      {\n        return [fallback, value];\n      }\n    case \"Some\":\n      {\n        return option.value;\n      }\n  }\n}));\n/** @internal */\nexport const update = /*#__PURE__*/dual(2, (self, f) => self.modify(a => [void 0, f(a)]));\n/** @internal */\nexport const updateAndGet = /*#__PURE__*/dual(2, (self, f) => self.modify(a => {\n  const result = f(a);\n  return [result, result];\n}));\n/** @internal */\nexport const updateSome = /*#__PURE__*/dual(2, (self, f) => self.modify(a => [void 0, Option.match(f(a), {\n  onNone: () => a,\n  onSome: b => b\n})]));\n/** @internal */\nexport const updateSomeAndGet = /*#__PURE__*/dual(2, (self, pf) => self.modify(value => {\n  const option = pf(value);\n  switch (option._tag) {\n    case \"None\":\n      {\n        return [value, value];\n      }\n    case \"Some\":\n      {\n        return [option.value, option.value];\n      }\n  }\n}));\n/** @internal */\nexport const unsafeGet = self => MutableRef.get(self.ref);\n//# sourceMappingURL=ref.js.map","import { dual } from \"../Function.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as completedRequestMap from \"./completedRequestMap.js\";\nimport * as core from \"./core.js\";\nimport { StructuralPrototype } from \"./effectable.js\";\n/** @internal */\nconst RequestSymbolKey = \"effect/Request\";\n/** @internal */\nexport const RequestTypeId = /*#__PURE__*/Symbol.for(RequestSymbolKey);\nconst requestVariance = {\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _A: _ => _\n};\nconst RequestPrototype = {\n  ...StructuralPrototype,\n  [RequestTypeId]: requestVariance\n};\n/** @internal */\nexport const isRequest = u => hasProperty(u, RequestTypeId);\n/** @internal */\nexport const of = () => args => Object.assign(Object.create(RequestPrototype), args);\n/** @internal */\nexport const tagged = tag => args => {\n  const request = Object.assign(Object.create(RequestPrototype), args);\n  request._tag = tag;\n  return request;\n};\n/** @internal */\nexport const Class = /*#__PURE__*/function () {\n  function Class(args) {\n    if (args) {\n      Object.assign(this, args);\n    }\n  }\n  Class.prototype = RequestPrototype;\n  return Class;\n}();\n/** @internal */\nexport const TaggedClass = tag => {\n  return class TaggedClass extends Class {\n    _tag = tag;\n  };\n};\n/** @internal */\nexport const complete = /*#__PURE__*/dual(2, (self, result) => core.fiberRefGetWith(completedRequestMap.currentRequestMap, map => core.sync(() => {\n  if (map.has(self)) {\n    const entry = map.get(self);\n    if (!entry.state.completed) {\n      entry.state.completed = true;\n      core.deferredUnsafeDone(entry.result, result);\n    }\n  }\n})));\n/** @internal */\nexport const completeEffect = /*#__PURE__*/dual(2, (self, effect) => core.matchEffect(effect, {\n  onFailure: error => complete(self, core.exitFail(error)),\n  onSuccess: value => complete(self, core.exitSucceed(value))\n}));\n/** @internal */\nexport const fail = /*#__PURE__*/dual(2, (self, error) => complete(self, core.exitFail(error)));\n/** @internal */\nexport const failCause = /*#__PURE__*/dual(2, (self, cause) => complete(self, core.exitFailCause(cause)));\n/** @internal */\nexport const succeed = /*#__PURE__*/dual(2, (self, value) => complete(self, core.exitSucceed(value)));\n/** @internal */\nexport class Listeners {\n  count = 0;\n  observers = /*#__PURE__*/new Set();\n  interrupted = false;\n  addObserver(f) {\n    this.observers.add(f);\n  }\n  removeObserver(f) {\n    this.observers.delete(f);\n  }\n  increment() {\n    this.count++;\n    this.observers.forEach(f => f(this.count));\n  }\n  decrement() {\n    this.count--;\n    this.observers.forEach(f => f(this.count));\n  }\n}\n/**\n * @internal\n */\nexport const filterOutCompleted = requests => core.fiberRefGetWith(completedRequestMap.currentRequestMap, map => core.succeed(requests.filter(request => !(map.get(request)?.state.completed === true))));\n//# sourceMappingURL=request.js.map","import * as Chunk from \"../Chunk.js\";\nimport { constUndefined } from \"../Function.js\";\nimport * as Option from \"../Option.js\";\n/** @internal */\nexport class RingBuffer {\n  capacity;\n  array;\n  size = 0;\n  current = 0;\n  constructor(capacity) {\n    this.capacity = capacity;\n    this.array = Array.from({\n      length: capacity\n    }, constUndefined);\n  }\n  head() {\n    return Option.fromNullable(this.array[this.current]);\n  }\n  lastOrNull() {\n    if (this.size === 0) {\n      return undefined;\n    }\n    const index = this.current === 0 ? this.array.length - 1 : this.current - 1;\n    return this.array[index] ?? undefined;\n  }\n  put(value) {\n    this.array[this.current] = value;\n    this.increment();\n  }\n  dropLast() {\n    if (this.size > 0) {\n      this.decrement();\n      this.array[this.current] = undefined;\n    }\n  }\n  toChunk() {\n    const begin = this.current - this.size;\n    const newArray = begin < 0 ? [...this.array.slice(this.capacity + begin, this.capacity), ...this.array.slice(0, this.current)] : this.array.slice(begin, this.current);\n    return Chunk.fromIterable(newArray);\n  }\n  increment() {\n    if (this.size < this.capacity) {\n      this.size += 1;\n    }\n    this.current = (this.current + 1) % this.capacity;\n  }\n  decrement() {\n    this.size -= 1;\n    if (this.current > 0) {\n      this.current -= 1;\n    } else {\n      this.current = this.capacity - 1;\n    }\n  }\n}\n//# sourceMappingURL=ringBuffer.js.map","import { equals } from \"effect/Equal\";\nimport * as Context from \"../Context.js\";\nimport * as Exit from \"../Exit.js\";\nimport * as Fiber from \"../Fiber.js\";\nimport * as FiberId from \"../FiberId.js\";\nimport * as FiberRefs from \"../FiberRefs.js\";\nimport { dual, pipe } from \"../Function.js\";\nimport * as Inspectable from \"../Inspectable.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport * as Predicate from \"../Predicate.js\";\nimport * as _scheduler from \"../Scheduler.js\";\nimport * as _scope from \"../Scope.js\";\nimport * as InternalCause from \"./cause.js\";\nimport * as core from \"./core.js\";\nimport * as executionStrategy from \"./executionStrategy.js\";\nimport * as FiberRuntime from \"./fiberRuntime.js\";\nimport * as fiberScope from \"./fiberScope.js\";\nimport * as OpCodes from \"./opCodes/effect.js\";\nimport * as runtimeFlags from \"./runtimeFlags.js\";\nimport * as _supervisor from \"./supervisor.js\";\n/** @internal */\nexport const unsafeFork = runtime => (self, options) => {\n  const fiberId = FiberId.unsafeMake();\n  const fiberRefUpdates = [[core.currentContext, [[fiberId, runtime.context]]]];\n  if (options?.scheduler) {\n    fiberRefUpdates.push([_scheduler.currentScheduler, [[fiberId, options.scheduler]]]);\n  }\n  let fiberRefs = FiberRefs.updateManyAs(runtime.fiberRefs, {\n    entries: fiberRefUpdates,\n    forkAs: fiberId\n  });\n  if (options?.updateRefs) {\n    fiberRefs = options.updateRefs(fiberRefs, fiberId);\n  }\n  const fiberRuntime = new FiberRuntime.FiberRuntime(fiberId, fiberRefs, runtime.runtimeFlags);\n  let effect = self;\n  if (options?.scope) {\n    effect = core.flatMap(_scope.fork(options.scope, executionStrategy.sequential), closeableScope => core.zipRight(core.scopeAddFinalizer(closeableScope, core.fiberIdWith(id => equals(id, fiberRuntime.id()) ? core.void : core.interruptAsFiber(fiberRuntime, id))), core.onExit(self, exit => _scope.close(closeableScope, exit))));\n  }\n  const supervisor = fiberRuntime._supervisor;\n  // we can compare by reference here as _supervisor.none is wrapped with globalValue\n  if (supervisor !== _supervisor.none) {\n    supervisor.onStart(runtime.context, effect, Option.none(), fiberRuntime);\n    fiberRuntime.addObserver(exit => supervisor.onEnd(exit, fiberRuntime));\n  }\n  fiberScope.globalScope.add(runtime.runtimeFlags, fiberRuntime);\n  // Only an explicit false will prevent immediate execution\n  if (options?.immediate === false) {\n    fiberRuntime.resume(effect);\n  } else {\n    fiberRuntime.start(effect);\n  }\n  return fiberRuntime;\n};\n/** @internal */\nexport const unsafeRunCallback = runtime => (effect, options = {}) => {\n  const fiberRuntime = unsafeFork(runtime)(effect, options);\n  if (options.onExit) {\n    fiberRuntime.addObserver(exit => {\n      options.onExit(exit);\n    });\n  }\n  return (id, cancelOptions) => unsafeRunCallback(runtime)(pipe(fiberRuntime, Fiber.interruptAs(id ?? FiberId.none)), {\n    ...cancelOptions,\n    onExit: cancelOptions?.onExit ? exit => cancelOptions.onExit(Exit.flatten(exit)) : undefined\n  });\n};\n/** @internal */\nexport const unsafeRunSync = runtime => effect => {\n  const result = unsafeRunSyncExit(runtime)(effect);\n  if (result._tag === \"Failure\") {\n    throw fiberFailure(result.effect_instruction_i0);\n  } else {\n    return result.effect_instruction_i0;\n  }\n};\nclass AsyncFiberExceptionImpl extends Error {\n  fiber;\n  _tag = \"AsyncFiberException\";\n  constructor(fiber) {\n    super(`Fiber #${fiber.id().id} cannot be resolved synchronously. This is caused by using runSync on an effect that performs async work`);\n    this.fiber = fiber;\n    this.name = this._tag;\n    this.stack = this.message;\n  }\n}\nconst asyncFiberException = fiber => {\n  const limit = Error.stackTraceLimit;\n  Error.stackTraceLimit = 0;\n  const error = new AsyncFiberExceptionImpl(fiber);\n  Error.stackTraceLimit = limit;\n  return error;\n};\n/** @internal */\nexport const isAsyncFiberException = u => Predicate.isTagged(u, \"AsyncFiberException\") && \"fiber\" in u;\n/** @internal */\nexport const FiberFailureId = /*#__PURE__*/Symbol.for(\"effect/Runtime/FiberFailure\");\n/** @internal */\nexport const FiberFailureCauseId = /*#__PURE__*/Symbol.for(\"effect/Runtime/FiberFailure/Cause\");\nclass FiberFailureImpl extends Error {\n  [FiberFailureId];\n  [FiberFailureCauseId];\n  constructor(cause) {\n    super();\n    this[FiberFailureId] = FiberFailureId;\n    this[FiberFailureCauseId] = cause;\n    const prettyErrors = InternalCause.prettyErrors(cause);\n    if (prettyErrors.length > 0) {\n      const head = prettyErrors[0];\n      this.name = head.name;\n      this.message = head.message;\n      this.stack = head.stack;\n    }\n    this.name = `(FiberFailure) ${this.name}`;\n    if (this.message === undefined || this.message.length === 0) {\n      this.message = \"An error has occurred\";\n    }\n  }\n  toJSON() {\n    return {\n      _id: \"FiberFailure\",\n      cause: this[FiberFailureCauseId].toJSON()\n    };\n  }\n  toString() {\n    return \"(FiberFailure) \" + (this.stack ?? this.message);\n  }\n  [Inspectable.NodeInspectSymbol]() {\n    return this.toString();\n  }\n}\n/** @internal */\nexport const fiberFailure = cause => {\n  const limit = Error.stackTraceLimit;\n  Error.stackTraceLimit = 0;\n  const error = new FiberFailureImpl(cause);\n  Error.stackTraceLimit = limit;\n  return error;\n};\n/** @internal */\nexport const isFiberFailure = u => Predicate.hasProperty(u, FiberFailureId);\nconst fastPath = effect => {\n  const op = effect;\n  switch (op._op) {\n    case \"Failure\":\n    case \"Success\":\n      {\n        // @ts-expect-error\n        return op;\n      }\n    case \"Left\":\n      {\n        return core.exitFail(op.left);\n      }\n    case \"Right\":\n      {\n        return core.exitSucceed(op.right);\n      }\n    case \"Some\":\n      {\n        return core.exitSucceed(op.value);\n      }\n    case \"None\":\n      {\n        // @ts-expect-error\n        return core.exitFail(core.NoSuchElementException());\n      }\n  }\n};\n/** @internal */\nexport const unsafeRunSyncExit = runtime => effect => {\n  const op = fastPath(effect);\n  if (op) {\n    return op;\n  }\n  const scheduler = new _scheduler.SyncScheduler();\n  const fiberRuntime = unsafeFork(runtime)(effect, {\n    scheduler\n  });\n  scheduler.flush();\n  const result = fiberRuntime.unsafePoll();\n  if (result) {\n    return result;\n  }\n  throw asyncFiberException(fiberRuntime);\n};\n/** @internal */\nexport const unsafeRunPromise = runtime => (effect, options) => unsafeRunPromiseExit(runtime)(effect, options).then(result => {\n  switch (result._tag) {\n    case OpCodes.OP_SUCCESS:\n      {\n        return result.effect_instruction_i0;\n      }\n    case OpCodes.OP_FAILURE:\n      {\n        throw fiberFailure(result.effect_instruction_i0);\n      }\n  }\n});\n/** @internal */\nexport const unsafeRunPromiseExit = runtime => (effect, options) => new Promise(resolve => {\n  const op = fastPath(effect);\n  if (op) {\n    resolve(op);\n  }\n  const fiber = unsafeFork(runtime)(effect);\n  fiber.addObserver(exit => {\n    resolve(exit);\n  });\n  if (options?.signal !== undefined) {\n    if (options.signal.aborted) {\n      fiber.unsafeInterruptAsFork(fiber.id());\n    } else {\n      options.signal.addEventListener(\"abort\", () => {\n        fiber.unsafeInterruptAsFork(fiber.id());\n      }, {\n        once: true\n      });\n    }\n  }\n});\n/** @internal */\nexport class RuntimeImpl {\n  context;\n  runtimeFlags;\n  fiberRefs;\n  constructor(context, runtimeFlags, fiberRefs) {\n    this.context = context;\n    this.runtimeFlags = runtimeFlags;\n    this.fiberRefs = fiberRefs;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const make = options => new RuntimeImpl(options.context, options.runtimeFlags, options.fiberRefs);\n/** @internal */\nexport const runtime = () => core.withFiberRuntime((state, status) => core.succeed(new RuntimeImpl(state.getFiberRef(core.currentContext), status.runtimeFlags, state.getFiberRefs())));\n/** @internal */\nexport const defaultRuntimeFlags = /*#__PURE__*/runtimeFlags.make(runtimeFlags.Interruption, runtimeFlags.CooperativeYielding, runtimeFlags.RuntimeMetrics);\n/** @internal */\nexport const defaultRuntime = /*#__PURE__*/make({\n  context: /*#__PURE__*/Context.empty(),\n  runtimeFlags: defaultRuntimeFlags,\n  fiberRefs: /*#__PURE__*/FiberRefs.empty()\n});\n/** @internal */\nexport const updateRuntimeFlags = /*#__PURE__*/dual(2, (self, f) => make({\n  context: self.context,\n  runtimeFlags: f(self.runtimeFlags),\n  fiberRefs: self.fiberRefs\n}));\n/** @internal */\nexport const disableRuntimeFlag = /*#__PURE__*/dual(2, (self, flag) => updateRuntimeFlags(self, runtimeFlags.disable(flag)));\n/** @internal */\nexport const enableRuntimeFlag = /*#__PURE__*/dual(2, (self, flag) => updateRuntimeFlags(self, runtimeFlags.enable(flag)));\n/** @internal */\nexport const updateContext = /*#__PURE__*/dual(2, (self, f) => make({\n  context: f(self.context),\n  runtimeFlags: self.runtimeFlags,\n  fiberRefs: self.fiberRefs\n}));\n/** @internal */\nexport const provideService = /*#__PURE__*/dual(3, (self, tag, service) => updateContext(self, Context.add(tag, service)));\n/** @internal */\nexport const updateFiberRefs = /*#__PURE__*/dual(2, (self, f) => make({\n  context: self.context,\n  runtimeFlags: self.runtimeFlags,\n  fiberRefs: f(self.fiberRefs)\n}));\n/** @internal */\nexport const setFiberRef = /*#__PURE__*/dual(3, (self, fiberRef, value) => updateFiberRefs(self, FiberRefs.updateAs({\n  fiberId: FiberId.none,\n  fiberRef,\n  value\n})));\n/** @internal */\nexport const deleteFiberRef = /*#__PURE__*/dual(2, (self, fiberRef) => updateFiberRefs(self, FiberRefs.delete(fiberRef)));\n/** @internal */\nexport const unsafeRunEffect = /*#__PURE__*/unsafeRunCallback(defaultRuntime);\n/** @internal */\nexport const unsafeForkEffect = /*#__PURE__*/unsafeFork(defaultRuntime);\n/** @internal */\nexport const unsafeRunPromiseEffect = /*#__PURE__*/unsafeRunPromise(defaultRuntime);\n/** @internal */\nexport const unsafeRunPromiseExitEffect = /*#__PURE__*/unsafeRunPromiseExit(defaultRuntime);\n/** @internal */\nexport const unsafeRunSyncEffect = /*#__PURE__*/unsafeRunSync(defaultRuntime);\n/** @internal */\nexport const unsafeRunSyncExitEffect = /*#__PURE__*/unsafeRunSyncExit(defaultRuntime);\n// circular with Effect\n/** @internal */\nexport const asyncEffect = register => core.suspend(() => {\n  let cleanup = undefined;\n  return core.flatMap(core.deferredMake(), deferred => core.flatMap(runtime(), runtime => core.uninterruptibleMask(restore => core.zipRight(FiberRuntime.fork(restore(core.matchCauseEffect(register(cb => unsafeRunCallback(runtime)(core.intoDeferred(cb, deferred))), {\n    onFailure: cause => core.deferredFailCause(deferred, cause),\n    onSuccess: cleanup_ => {\n      cleanup = cleanup_;\n      return core.void;\n    }\n  }))), restore(core.onInterrupt(core.deferredAwait(deferred), () => cleanup ?? core.void))))));\n});\n//# sourceMappingURL=runtime.js.map","import { dual } from \"../Function.js\";\nimport * as internalDiffer from \"./differ.js\";\nimport * as runtimeFlagsPatch from \"./runtimeFlagsPatch.js\";\n/** @internal */\nexport const None = 0;\n/** @internal */\nexport const Interruption = 1 << 0;\n/** @internal */\nexport const OpSupervision = 1 << 1;\n/** @internal */\nexport const RuntimeMetrics = 1 << 2;\n/** @internal */\nexport const WindDown = 1 << 4;\n/** @internal */\nexport const CooperativeYielding = 1 << 5;\n/** @internal */\nexport const allFlags = [None, Interruption, OpSupervision, RuntimeMetrics, WindDown, CooperativeYielding];\nconst print = flag => {\n  switch (flag) {\n    case CooperativeYielding:\n      {\n        return \"CooperativeYielding\";\n      }\n    case WindDown:\n      {\n        return \"WindDown\";\n      }\n    case RuntimeMetrics:\n      {\n        return \"RuntimeMetrics\";\n      }\n    case OpSupervision:\n      {\n        return \"OpSupervision\";\n      }\n    case Interruption:\n      {\n        return \"Interruption\";\n      }\n    case None:\n      {\n        return \"None\";\n      }\n  }\n};\n/** @internal */\nexport const cooperativeYielding = self => isEnabled(self, CooperativeYielding);\n/** @internal */\nexport const disable = /*#__PURE__*/dual(2, (self, flag) => self & ~flag);\n/** @internal */\nexport const disableAll = /*#__PURE__*/dual(2, (self, flags) => self & ~flags);\n/** @internal */\nexport const enable = /*#__PURE__*/dual(2, (self, flag) => self | flag);\n/** @internal */\nexport const enableAll = /*#__PURE__*/dual(2, (self, flags) => self | flags);\n/** @internal */\nexport const interruptible = self => interruption(self) && !windDown(self);\n/** @internal */\nexport const interruption = self => isEnabled(self, Interruption);\n/** @internal */\nexport const isDisabled = /*#__PURE__*/dual(2, (self, flag) => !isEnabled(self, flag));\n/** @internal */\nexport const isEnabled = /*#__PURE__*/dual(2, (self, flag) => (self & flag) !== 0);\n/** @internal */\nexport const make = (...flags) => flags.reduce((a, b) => a | b, 0);\n/** @internal */\nexport const none = /*#__PURE__*/make(None);\n/** @internal */\nexport const opSupervision = self => isEnabled(self, OpSupervision);\n/** @internal */\nexport const render = self => {\n  const active = [];\n  allFlags.forEach(flag => {\n    if (isEnabled(self, flag)) {\n      active.push(`${print(flag)}`);\n    }\n  });\n  return `RuntimeFlags(${active.join(\", \")})`;\n};\n/** @internal */\nexport const runtimeMetrics = self => isEnabled(self, RuntimeMetrics);\n/** @internal */\nexport const toSet = self => new Set(allFlags.filter(flag => isEnabled(self, flag)));\nexport const windDown = self => isEnabled(self, WindDown);\n// circular with RuntimeFlagsPatch\n/** @internal */\nexport const enabledSet = self => toSet(runtimeFlagsPatch.active(self) & runtimeFlagsPatch.enabled(self));\n/** @internal */\nexport const disabledSet = self => toSet(runtimeFlagsPatch.active(self) & ~runtimeFlagsPatch.enabled(self));\n/** @internal */\nexport const diff = /*#__PURE__*/dual(2, (self, that) => runtimeFlagsPatch.make(self ^ that, that));\n/** @internal */\nexport const patch = /*#__PURE__*/dual(2, (self, patch) => self & (runtimeFlagsPatch.invert(runtimeFlagsPatch.active(patch)) | runtimeFlagsPatch.enabled(patch)) | runtimeFlagsPatch.active(patch) & runtimeFlagsPatch.enabled(patch));\n/** @internal */\nexport const renderPatch = self => {\n  const enabled = Array.from(enabledSet(self)).map(flag => print(flag)).join(\", \");\n  const disabled = Array.from(disabledSet(self)).map(flag => print(flag)).join(\", \");\n  return `RuntimeFlagsPatch(enabled = (${enabled}), disabled = (${disabled}))`;\n};\n/** @internal */\nexport const differ = /*#__PURE__*/internalDiffer.make({\n  empty: runtimeFlagsPatch.empty,\n  diff: (oldValue, newValue) => diff(oldValue, newValue),\n  combine: (first, second) => runtimeFlagsPatch.andThen(second)(first),\n  patch: (_patch, oldValue) => patch(oldValue, _patch)\n});\n//# sourceMappingURL=runtimeFlags.js.map","import { dual } from \"../Function.js\";\n/** @internal */\nconst BIT_MASK = 0xff;\n/** @internal */\nconst BIT_SHIFT = 0x08;\n/** @internal */\nexport const active = patch => patch & BIT_MASK;\n/** @internal */\nexport const enabled = patch => patch >> BIT_SHIFT & BIT_MASK;\n/** @internal */\nexport const make = (active, enabled) => (active & BIT_MASK) + ((enabled & active & BIT_MASK) << BIT_SHIFT);\n/** @internal */\nexport const empty = /*#__PURE__*/make(0, 0);\n/** @internal */\nexport const enable = flag => make(flag, flag);\n/** @internal */\nexport const disable = flag => make(flag, 0);\n/** @internal */\nexport const isEmpty = patch => patch === 0;\n/** @internal */\nexport const isActive = /*#__PURE__*/dual(2, (self, flag) => (active(self) & flag) !== 0);\n/** @internal */\nexport const isEnabled = /*#__PURE__*/dual(2, (self, flag) => (enabled(self) & flag) !== 0);\n/** @internal */\nexport const isDisabled = /*#__PURE__*/dual(2, (self, flag) => (active(self) & flag) !== 0 && (enabled(self) & flag) === 0);\n/** @internal */\nexport const exclude = /*#__PURE__*/dual(2, (self, flag) => make(active(self) & ~flag, enabled(self)));\n/** @internal */\nexport const both = /*#__PURE__*/dual(2, (self, that) => make(active(self) | active(that), enabled(self) & enabled(that)));\n/** @internal */\nexport const either = /*#__PURE__*/dual(2, (self, that) => make(active(self) | active(that), enabled(self) | enabled(that)));\n/** @internal */\nexport const andThen = /*#__PURE__*/dual(2, (self, that) => self | that);\n/** @internal */\nexport const inverse = patch => make(enabled(patch), invert(active(patch)));\n/** @internal */\nexport const invert = n => ~n >>> 0 & BIT_MASK;\n//# sourceMappingURL=runtimeFlagsPatch.js.map","import * as Chunk from \"../Chunk.js\";\nimport * as Clock from \"../Clock.js\";\nimport * as Context from \"../Context.js\";\nimport * as Cron from \"../Cron.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as Either from \"../Either.js\";\nimport * as Equal from \"../Equal.js\";\nimport { constVoid, dual, pipe } from \"../Function.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as Random from \"../Random.js\";\nimport * as ScheduleDecision from \"../ScheduleDecision.js\";\nimport * as Interval from \"../ScheduleInterval.js\";\nimport * as Intervals from \"../ScheduleIntervals.js\";\nimport * as internalCause from \"./cause.js\";\nimport * as effect from \"./core-effect.js\";\nimport * as core from \"./core.js\";\nimport * as ref from \"./ref.js\";\n/** @internal */\nconst ScheduleSymbolKey = \"effect/Schedule\";\n/** @internal */\nexport const ScheduleTypeId = /*#__PURE__*/Symbol.for(ScheduleSymbolKey);\n/** @internal */\nexport const isSchedule = u => hasProperty(u, ScheduleTypeId);\n/** @internal */\nconst ScheduleDriverSymbolKey = \"effect/ScheduleDriver\";\n/** @internal */\nexport const ScheduleDriverTypeId = /*#__PURE__*/Symbol.for(ScheduleDriverSymbolKey);\nconst scheduleVariance = {\n  /* c8 ignore next */\n  _Out: _ => _,\n  /* c8 ignore next */\n  _In: _ => _,\n  /* c8 ignore next */\n  _R: _ => _\n};\nconst scheduleDriverVariance = {\n  /* c8 ignore next */\n  _Out: _ => _,\n  /* c8 ignore next */\n  _In: _ => _,\n  /* c8 ignore next */\n  _R: _ => _\n};\n/** @internal */\nclass ScheduleImpl {\n  initial;\n  step;\n  [ScheduleTypeId] = scheduleVariance;\n  constructor(initial, step) {\n    this.initial = initial;\n    this.step = step;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nclass ScheduleDriverImpl {\n  schedule;\n  ref;\n  [ScheduleDriverTypeId] = scheduleDriverVariance;\n  constructor(schedule, ref) {\n    this.schedule = schedule;\n    this.ref = ref;\n  }\n  get state() {\n    return core.map(ref.get(this.ref), tuple => tuple[1]);\n  }\n  get last() {\n    return core.flatMap(ref.get(this.ref), ([element, _]) => {\n      switch (element._tag) {\n        case \"None\":\n          {\n            return core.failSync(() => new core.NoSuchElementException());\n          }\n        case \"Some\":\n          {\n            return core.succeed(element.value);\n          }\n      }\n    });\n  }\n  get reset() {\n    return ref.set(this.ref, [Option.none(), this.schedule.initial]);\n  }\n  next(input) {\n    return pipe(core.map(ref.get(this.ref), tuple => tuple[1]), core.flatMap(state => pipe(Clock.currentTimeMillis, core.flatMap(now => pipe(core.suspend(() => this.schedule.step(now, input, state)), core.flatMap(([state, out, decision]) => {\n      const setState = ref.set(this.ref, [Option.some(out), state]);\n      if (ScheduleDecision.isDone(decision)) {\n        return core.zipRight(setState, core.fail(Option.none()));\n      }\n      const millis = Intervals.start(decision.intervals) - now;\n      if (millis <= 0) {\n        return core.as(setState, out);\n      }\n      return pipe(setState, core.zipRight(effect.sleep(Duration.millis(millis))), core.as(out));\n    }))))));\n  }\n}\n/** @internal */\nexport const makeWithState = (initial, step) => new ScheduleImpl(initial, step);\n/** @internal */\nexport const addDelay = /*#__PURE__*/dual(2, (self, f) => addDelayEffect(self, out => core.sync(() => f(out))));\n/** @internal */\nexport const addDelayEffect = /*#__PURE__*/dual(2, (self, f) => modifyDelayEffect(self, (out, duration) => core.map(f(out), delay => Duration.sum(duration, Duration.decode(delay)))));\n/** @internal */\nexport const andThen = /*#__PURE__*/dual(2, (self, that) => map(andThenEither(self, that), Either.merge));\n/** @internal */\nexport const andThenEither = /*#__PURE__*/dual(2, (self, that) => makeWithState([self.initial, that.initial, true], (now, input, state) => state[2] ? core.flatMap(self.step(now, input, state[0]), ([lState, out, decision]) => {\n  if (ScheduleDecision.isDone(decision)) {\n    return core.map(that.step(now, input, state[1]), ([rState, out, decision]) => [[lState, rState, false], Either.right(out), decision]);\n  }\n  return core.succeed([[lState, state[1], true], Either.left(out), decision]);\n}) : core.map(that.step(now, input, state[1]), ([rState, out, decision]) => [[state[0], rState, false], Either.right(out), decision])));\n/** @internal */\nexport const as = /*#__PURE__*/dual(2, (self, out) => map(self, () => out));\n/** @internal */\nexport const asVoid = self => map(self, constVoid);\n/** @internal */\nexport const bothInOut = /*#__PURE__*/dual(2, (self, that) => makeWithState([self.initial, that.initial], (now, [in1, in2], state) => core.zipWith(self.step(now, in1, state[0]), that.step(now, in2, state[1]), ([lState, out, lDecision], [rState, out2, rDecision]) => {\n  if (ScheduleDecision.isContinue(lDecision) && ScheduleDecision.isContinue(rDecision)) {\n    const interval = pipe(lDecision.intervals, Intervals.union(rDecision.intervals));\n    return [[lState, rState], [out, out2], ScheduleDecision.continue(interval)];\n  }\n  return [[lState, rState], [out, out2], ScheduleDecision.done];\n})));\n/** @internal */\nexport const check = /*#__PURE__*/dual(2, (self, test) => checkEffect(self, (input, out) => core.sync(() => test(input, out))));\n/** @internal */\nexport const checkEffect = /*#__PURE__*/dual(2, (self, test) => makeWithState(self.initial, (now, input, state) => core.flatMap(self.step(now, input, state), ([state, out, decision]) => {\n  if (ScheduleDecision.isDone(decision)) {\n    return core.succeed([state, out, ScheduleDecision.done]);\n  }\n  return core.map(test(input, out), cont => cont ? [state, out, decision] : [state, out, ScheduleDecision.done]);\n})));\n/** @internal */\nexport const collectAllInputs = () => collectAllOutputs(identity());\n/** @internal */\nexport const collectAllOutputs = self => reduce(self, Chunk.empty(), (outs, out) => pipe(outs, Chunk.append(out)));\n/** @internal */\nexport const collectUntil = f => collectAllOutputs(recurUntil(f));\n/** @internal */\nexport const collectUntilEffect = f => collectAllOutputs(recurUntilEffect(f));\n/** @internal */\nexport const collectWhile = f => collectAllOutputs(recurWhile(f));\n/** @internal */\nexport const collectWhileEffect = f => collectAllOutputs(recurWhileEffect(f));\n/** @internal */\nexport const compose = /*#__PURE__*/dual(2, (self, that) => makeWithState([self.initial, that.initial], (now, input, state) => core.flatMap(self.step(now, input, state[0]), ([lState, out, lDecision]) => core.map(that.step(now, out, state[1]), ([rState, out2, rDecision]) => ScheduleDecision.isDone(lDecision) ? [[lState, rState], out2, ScheduleDecision.done] : ScheduleDecision.isDone(rDecision) ? [[lState, rState], out2, ScheduleDecision.done] : [[lState, rState], out2, ScheduleDecision.continue(pipe(lDecision.intervals, Intervals.max(rDecision.intervals)))]))));\n/** @internal */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => mapInputEffect(self, input2 => core.sync(() => f(input2))));\n/** @internal */\nexport const mapInputContext = /*#__PURE__*/dual(2, (self, f) => makeWithState(self.initial, (now, input, state) => core.mapInputContext(self.step(now, input, state), f)));\n/** @internal */\nexport const mapInputEffect = /*#__PURE__*/dual(2, (self, f) => makeWithState(self.initial, (now, input2, state) => core.flatMap(f(input2), input => self.step(now, input, state))));\n/** @internal */\nexport const cron = expression => {\n  const parsed = Cron.isCron(expression) ? Either.right(expression) : Cron.parse(expression);\n  return makeWithState([true, [Number.MIN_SAFE_INTEGER, 0, 0]], (now, _, [initial, previous]) => {\n    if (now < previous[0]) {\n      return core.succeed([[false, previous], [previous[1], previous[2]], ScheduleDecision.continueWith(Interval.make(previous[1], previous[2]))]);\n    }\n    if (Either.isLeft(parsed)) {\n      return core.die(parsed.left);\n    }\n    const cron = parsed.right;\n    const date = new Date(now);\n    let next;\n    if (initial && Cron.match(cron, date)) {\n      next = now;\n    } else {\n      const result = Cron.next(cron, date);\n      next = result.getTime();\n    }\n    const start = beginningOfMinute(next);\n    const end = endOfMinute(next);\n    const interval = Interval.make(start, end);\n    return core.succeed([[false, [next, start, end]], [start, end], ScheduleDecision.continueWith(interval)]);\n  });\n};\n/** @internal */\nexport const dayOfMonth = day => {\n  return makeWithState([Number.NEGATIVE_INFINITY, 0], (now, _, state) => {\n    if (!Number.isInteger(day) || day < 1 || 31 < day) {\n      return core.dieSync(() => new core.IllegalArgumentException(`Invalid argument in: dayOfMonth(${day}). Must be in range 1...31`));\n    }\n    const n = state[1];\n    const initial = n === 0;\n    const day0 = nextDayOfMonth(now, day, initial);\n    const start = beginningOfDay(day0);\n    const end = endOfDay(day0);\n    const interval = Interval.make(start, end);\n    return core.succeed([[end, n + 1], n, ScheduleDecision.continueWith(interval)]);\n  });\n};\n/** @internal */\nexport const dayOfWeek = day => {\n  return makeWithState([Number.MIN_SAFE_INTEGER, 0], (now, _, state) => {\n    if (!Number.isInteger(day) || day < 1 || 7 < day) {\n      return core.dieSync(() => new core.IllegalArgumentException(`Invalid argument in: dayOfWeek(${day}). Must be in range 1 (Monday)...7 (Sunday)`));\n    }\n    const n = state[1];\n    const initial = n === 0;\n    const day0 = nextDay(now, day, initial);\n    const start = beginningOfDay(day0);\n    const end = endOfDay(day0);\n    const interval = Interval.make(start, end);\n    return core.succeed([[end, n + 1], n, ScheduleDecision.continueWith(interval)]);\n  });\n};\n/** @internal */\nexport const delayed = /*#__PURE__*/dual(2, (self, f) => delayedEffect(self, duration => core.sync(() => f(duration))));\n/** @internal */\nexport const delayedEffect = /*#__PURE__*/dual(2, (self, f) => modifyDelayEffect(self, (_, delay) => f(delay)));\n/** @internal */\nexport const delayedSchedule = schedule => addDelay(schedule, x => x);\n/** @internal */\nexport const delays = self => makeWithState(self.initial, (now, input, state) => pipe(self.step(now, input, state), core.flatMap(([state, _, decision]) => {\n  if (ScheduleDecision.isDone(decision)) {\n    return core.succeed([state, Duration.zero, decision]);\n  }\n  return core.succeed([state, Duration.millis(Intervals.start(decision.intervals) - now), decision]);\n})));\n/** @internal */\nexport const mapBoth = /*#__PURE__*/dual(2, (self, {\n  onInput,\n  onOutput\n}) => map(mapInput(self, onInput), onOutput));\n/** @internal */\nexport const mapBothEffect = /*#__PURE__*/dual(2, (self, {\n  onInput,\n  onOutput\n}) => mapEffect(mapInputEffect(self, onInput), onOutput));\n/** @internal */\nexport const driver = self => pipe(ref.make([Option.none(), self.initial]), core.map(ref => new ScheduleDriverImpl(self, ref)));\n/** @internal */\nexport const duration = durationInput => {\n  const duration = Duration.decode(durationInput);\n  const durationMillis = Duration.toMillis(duration);\n  return makeWithState(true, (now, _, state) => core.succeed(state ? [false, duration, ScheduleDecision.continueWith(Interval.after(now + durationMillis))] : [false, Duration.zero, ScheduleDecision.done]));\n};\n/** @internal */\nexport const either = /*#__PURE__*/dual(2, (self, that) => union(self, that));\n/** @internal */\nexport const eitherWith = /*#__PURE__*/dual(3, (self, that, f) => unionWith(self, that, f));\n/** @internal */\nexport const ensuring = /*#__PURE__*/dual(2, (self, finalizer) => makeWithState(self.initial, (now, input, state) => core.flatMap(self.step(now, input, state), ([state, out, decision]) => ScheduleDecision.isDone(decision) ? core.as(finalizer, [state, out, decision]) : core.succeed([state, out, decision]))));\n/** @internal */\nexport const exponential = (baseInput, factor = 2.0) => {\n  const base = Duration.decode(baseInput);\n  return delayedSchedule(map(forever, i => Duration.times(base, Math.pow(factor, i))));\n};\n/** @internal */\nexport const fibonacci = oneInput => {\n  const one = Duration.decode(oneInput);\n  return delayedSchedule(pipe(unfold([one, one], ([a, b]) => [b, Duration.sum(a, b)]), map(out => out[0])));\n};\n/** @internal */\nexport const fixed = intervalInput => {\n  const interval = Duration.decode(intervalInput);\n  const intervalMillis = Duration.toMillis(interval);\n  return makeWithState([Option.none(), 0], (now, _, [option, n]) => core.sync(() => {\n    switch (option._tag) {\n      case \"None\":\n        {\n          return [[Option.some([now, now + intervalMillis]), n + 1], n, ScheduleDecision.continueWith(Interval.after(now + intervalMillis))];\n        }\n      case \"Some\":\n        {\n          const [startMillis, lastRun] = option.value;\n          const runningBehind = now > lastRun + intervalMillis;\n          const boundary = Equal.equals(interval, Duration.zero) ? interval : Duration.millis(intervalMillis - (now - startMillis) % intervalMillis);\n          const sleepTime = Equal.equals(boundary, Duration.zero) ? interval : boundary;\n          const nextRun = runningBehind ? now : now + Duration.toMillis(sleepTime);\n          return [[Option.some([startMillis, nextRun]), n + 1], n, ScheduleDecision.continueWith(Interval.after(nextRun))];\n        }\n    }\n  }));\n};\n/** @internal */\nexport const fromDelay = delay => duration(delay);\n/** @internal */\nexport const fromDelays = (delay, ...delays) => makeWithState([[delay, ...delays].map(_ => Duration.decode(_)), true], (now, _, [durations, cont]) => core.sync(() => {\n  if (cont) {\n    const x = durations[0];\n    const interval = Interval.after(now + Duration.toMillis(x));\n    if (durations.length >= 2) {\n      return [[durations.slice(1), true], x, ScheduleDecision.continueWith(interval)];\n    }\n    const y = durations.slice(1);\n    return [[[x, ...y], false], x, ScheduleDecision.continueWith(interval)];\n  }\n  return [[durations, false], Duration.zero, ScheduleDecision.done];\n}));\n/** @internal */\nexport const fromFunction = f => map(identity(), f);\n/** @internal */\nexport const hourOfDay = hour => makeWithState([Number.NEGATIVE_INFINITY, 0], (now, _, state) => {\n  if (!Number.isInteger(hour) || hour < 0 || 23 < hour) {\n    return core.dieSync(() => new core.IllegalArgumentException(`Invalid argument in: hourOfDay(${hour}). Must be in range 0...23`));\n  }\n  const n = state[1];\n  const initial = n === 0;\n  const hour0 = nextHour(now, hour, initial);\n  const start = beginningOfHour(hour0);\n  const end = endOfHour(hour0);\n  const interval = Interval.make(start, end);\n  return core.succeed([[end, n + 1], n, ScheduleDecision.continueWith(interval)]);\n});\n/** @internal */\nexport const identity = () => makeWithState(void 0, (now, input, state) => core.succeed([state, input, ScheduleDecision.continueWith(Interval.after(now))]));\n/** @internal */\nexport const intersect = /*#__PURE__*/dual(2, (self, that) => intersectWith(self, that, Intervals.intersect));\n/** @internal */\nexport const intersectWith = /*#__PURE__*/dual(3, (self, that, f) => makeWithState([self.initial, that.initial], (now, input, state) => pipe(core.zipWith(self.step(now, input, state[0]), that.step(now, input, state[1]), (a, b) => [a, b]), core.flatMap(([[lState, out, lDecision], [rState, out2, rDecision]]) => {\n  if (ScheduleDecision.isContinue(lDecision) && ScheduleDecision.isContinue(rDecision)) {\n    return intersectWithLoop(self, that, input, lState, out, lDecision.intervals, rState, out2, rDecision.intervals, f);\n  }\n  return core.succeed([[lState, rState], [out, out2], ScheduleDecision.done]);\n}))));\n/** @internal */\nconst intersectWithLoop = (self, that, input, lState, out, lInterval, rState, out2, rInterval, f) => {\n  const combined = f(lInterval, rInterval);\n  if (Intervals.isNonEmpty(combined)) {\n    return core.succeed([[lState, rState], [out, out2], ScheduleDecision.continue(combined)]);\n  }\n  if (pipe(lInterval, Intervals.lessThan(rInterval))) {\n    return core.flatMap(self.step(Intervals.end(lInterval), input, lState), ([lState, out, decision]) => {\n      if (ScheduleDecision.isDone(decision)) {\n        return core.succeed([[lState, rState], [out, out2], ScheduleDecision.done]);\n      }\n      return intersectWithLoop(self, that, input, lState, out, decision.intervals, rState, out2, rInterval, f);\n    });\n  }\n  return core.flatMap(that.step(Intervals.end(rInterval), input, rState), ([rState, out2, decision]) => {\n    if (ScheduleDecision.isDone(decision)) {\n      return core.succeed([[lState, rState], [out, out2], ScheduleDecision.done]);\n    }\n    return intersectWithLoop(self, that, input, lState, out, lInterval, rState, out2, decision.intervals, f);\n  });\n};\n/** @internal */\nexport const jittered = self => jitteredWith(self, {\n  min: 0.8,\n  max: 1.2\n});\n/** @internal */\nexport const jitteredWith = /*#__PURE__*/dual(2, (self, options) => {\n  const {\n    max,\n    min\n  } = Object.assign({\n    min: 0.8,\n    max: 1.2\n  }, options);\n  return delayedEffect(self, duration => core.map(Random.next, random => {\n    const d = Duration.toMillis(duration);\n    const jittered = d * min * (1 - random) + d * max * random;\n    return Duration.millis(jittered);\n  }));\n});\n/** @internal */\nexport const linear = baseInput => {\n  const base = Duration.decode(baseInput);\n  return delayedSchedule(map(forever, i => Duration.times(base, i + 1)));\n};\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => mapEffect(self, out => core.sync(() => f(out))));\n/** @internal */\nexport const mapEffect = /*#__PURE__*/dual(2, (self, f) => makeWithState(self.initial, (now, input, state) => core.flatMap(self.step(now, input, state), ([state, out, decision]) => core.map(f(out), out2 => [state, out2, decision]))));\n/** @internal */\nexport const minuteOfHour = minute => makeWithState([Number.MIN_SAFE_INTEGER, 0], (now, _, state) => {\n  if (!Number.isInteger(minute) || minute < 0 || 59 < minute) {\n    return core.dieSync(() => new core.IllegalArgumentException(`Invalid argument in: minuteOfHour(${minute}). Must be in range 0...59`));\n  }\n  const n = state[1];\n  const initial = n === 0;\n  const minute0 = nextMinute(now, minute, initial);\n  const start = beginningOfMinute(minute0);\n  const end = endOfMinute(minute0);\n  const interval = Interval.make(start, end);\n  return core.succeed([[end, n + 1], n, ScheduleDecision.continueWith(interval)]);\n});\n/** @internal */\nexport const modifyDelay = /*#__PURE__*/dual(2, (self, f) => modifyDelayEffect(self, (out, duration) => core.sync(() => f(out, duration))));\n/** @internal */\nexport const modifyDelayEffect = /*#__PURE__*/dual(2, (self, f) => makeWithState(self.initial, (now, input, state) => core.flatMap(self.step(now, input, state), ([state, out, decision]) => {\n  if (ScheduleDecision.isDone(decision)) {\n    return core.succeed([state, out, decision]);\n  }\n  const intervals = decision.intervals;\n  const delay = Interval.size(Interval.make(now, Intervals.start(intervals)));\n  return core.map(f(out, delay), durationInput => {\n    const duration = Duration.decode(durationInput);\n    const oldStart = Intervals.start(intervals);\n    const newStart = now + Duration.toMillis(duration);\n    const delta = newStart - oldStart;\n    const newEnd = Math.max(0, Intervals.end(intervals) + delta);\n    const newInterval = Interval.make(newStart, newEnd);\n    return [state, out, ScheduleDecision.continueWith(newInterval)];\n  });\n})));\n/** @internal */\nexport const onDecision = /*#__PURE__*/dual(2, (self, f) => makeWithState(self.initial, (now, input, state) => core.flatMap(self.step(now, input, state), ([state, out, decision]) => core.as(f(out, decision), [state, out, decision]))));\n/** @internal */\nexport const passthrough = self => makeWithState(self.initial, (now, input, state) => pipe(self.step(now, input, state), core.map(([state, _, decision]) => [state, input, decision])));\n/** @internal */\nexport const provideContext = /*#__PURE__*/dual(2, (self, context) => makeWithState(self.initial, (now, input, state) => core.provideContext(self.step(now, input, state), context)));\n/** @internal */\nexport const provideService = /*#__PURE__*/dual(3, (self, tag, service) => makeWithState(self.initial, (now, input, state) => core.contextWithEffect(env => core.provideContext(\n// @ts-expect-error\nself.step(now, input, state), Context.add(env, tag, service)))));\n/** @internal */\nexport const recurUntil = f => untilInput(identity(), f);\n/** @internal */\nexport const recurUntilEffect = f => untilInputEffect(identity(), f);\n/** @internal */\nexport const recurUntilOption = pf => untilOutput(map(identity(), pf), Option.isSome);\n/** @internal */\nexport const recurUpTo = durationInput => {\n  const duration = Duration.decode(durationInput);\n  return whileOutput(elapsed, elapsed => Duration.lessThan(elapsed, duration));\n};\n/** @internal */\nexport const recurWhile = f => whileInput(identity(), f);\n/** @internal */\nexport const recurWhileEffect = f => whileInputEffect(identity(), f);\n/** @internal */\nexport const recurs = n => whileOutput(forever, out => out < n);\n/** @internal */\nexport const reduce = /*#__PURE__*/dual(3, (self, zero, f) => reduceEffect(self, zero, (z, out) => core.sync(() => f(z, out))));\n/** @internal */\nexport const reduceEffect = /*#__PURE__*/dual(3, (self, zero, f) => makeWithState([self.initial, zero], (now, input, [s, z]) => core.flatMap(self.step(now, input, s), ([s, out, decision]) => ScheduleDecision.isDone(decision) ? core.succeed([[s, z], z, decision]) : core.map(f(z, out), z2 => [[s, z2], z, decision]))));\n/** @internal */\nexport const repeatForever = self => makeWithState(self.initial, (now, input, state) => {\n  const step = (now, input, state) => core.flatMap(self.step(now, input, state), ([state, out, decision]) => ScheduleDecision.isDone(decision) ? step(now, input, self.initial) : core.succeed([state, out, decision]));\n  return step(now, input, state);\n});\n/** @internal */\nexport const repetitions = self => reduce(self, 0, (n, _) => n + 1);\n/** @internal */\nexport const resetAfter = /*#__PURE__*/dual(2, (self, durationInput) => {\n  const duration = Duration.decode(durationInput);\n  return pipe(self, intersect(elapsed), resetWhen(([, time]) => Duration.greaterThanOrEqualTo(time, duration)), map(out => out[0]));\n});\n/** @internal */\nexport const resetWhen = /*#__PURE__*/dual(2, (self, f) => makeWithState(self.initial, (now, input, state) => core.flatMap(self.step(now, input, state), ([state, out, decision]) => f(out) ? self.step(now, input, self.initial) : core.succeed([state, out, decision]))));\n/** @internal */\nexport const run = /*#__PURE__*/dual(3, (self, now, input) => pipe(runLoop(self, now, Chunk.fromIterable(input), self.initial, Chunk.empty()), core.map(list => Chunk.reverse(list))));\n/** @internal */\nconst runLoop = (self, now, inputs, state, acc) => {\n  if (!Chunk.isNonEmpty(inputs)) {\n    return core.succeed(acc);\n  }\n  const input = Chunk.headNonEmpty(inputs);\n  const nextInputs = Chunk.tailNonEmpty(inputs);\n  return core.flatMap(self.step(now, input, state), ([state, out, decision]) => {\n    if (ScheduleDecision.isDone(decision)) {\n      return core.sync(() => pipe(acc, Chunk.prepend(out)));\n    }\n    return runLoop(self, Intervals.start(decision.intervals), nextInputs, state, Chunk.prepend(acc, out));\n  });\n};\n/** @internal */\nexport const secondOfMinute = second => makeWithState([Number.NEGATIVE_INFINITY, 0], (now, _, state) => {\n  if (!Number.isInteger(second) || second < 0 || 59 < second) {\n    return core.dieSync(() => new core.IllegalArgumentException(`Invalid argument in: secondOfMinute(${second}). Must be in range 0...59`));\n  }\n  const n = state[1];\n  const initial = n === 0;\n  const second0 = nextSecond(now, second, initial);\n  const start = beginningOfSecond(second0);\n  const end = endOfSecond(second0);\n  const interval = Interval.make(start, end);\n  return core.succeed([[end, n + 1], n, ScheduleDecision.continueWith(interval)]);\n});\n/** @internal */\nexport const spaced = duration => addDelay(forever, () => duration);\n/** @internal */\nexport const succeed = value => map(forever, () => value);\n/** @internal */\nexport const sync = evaluate => map(forever, evaluate);\n/** @internal */\nexport const tapInput = /*#__PURE__*/dual(2, (self, f) => makeWithState(self.initial, (now, input, state) => core.zipRight(f(input), self.step(now, input, state))));\n/** @internal */\nexport const tapOutput = /*#__PURE__*/dual(2, (self, f) => makeWithState(self.initial, (now, input, state) => core.tap(self.step(now, input, state), ([, out]) => f(out))));\n/** @internal */\nexport const unfold = (initial, f) => makeWithState(initial, (now, _, state) => core.sync(() => [f(state), state, ScheduleDecision.continueWith(Interval.after(now))]));\n/** @internal */\nexport const union = /*#__PURE__*/dual(2, (self, that) => unionWith(self, that, Intervals.union));\n/** @internal */\nexport const unionWith = /*#__PURE__*/dual(3, (self, that, f) => makeWithState([self.initial, that.initial], (now, input, state) => core.zipWith(self.step(now, input, state[0]), that.step(now, input, state[1]), ([lState, l, lDecision], [rState, r, rDecision]) => {\n  if (ScheduleDecision.isDone(lDecision) && ScheduleDecision.isDone(rDecision)) {\n    return [[lState, rState], [l, r], ScheduleDecision.done];\n  }\n  if (ScheduleDecision.isDone(lDecision) && ScheduleDecision.isContinue(rDecision)) {\n    return [[lState, rState], [l, r], ScheduleDecision.continue(rDecision.intervals)];\n  }\n  if (ScheduleDecision.isContinue(lDecision) && ScheduleDecision.isDone(rDecision)) {\n    return [[lState, rState], [l, r], ScheduleDecision.continue(lDecision.intervals)];\n  }\n  if (ScheduleDecision.isContinue(lDecision) && ScheduleDecision.isContinue(rDecision)) {\n    const combined = f(lDecision.intervals, rDecision.intervals);\n    return [[lState, rState], [l, r], ScheduleDecision.continue(combined)];\n  }\n  throw new Error(\"BUG: Schedule.unionWith - please report an issue at https://github.com/Effect-TS/effect/issues\");\n})));\n/** @internal */\nexport const untilInput = /*#__PURE__*/dual(2, (self, f) => check(self, (input, _) => !f(input)));\n/** @internal */\nexport const untilInputEffect = /*#__PURE__*/dual(2, (self, f) => checkEffect(self, (input, _) => effect.negate(f(input))));\n/** @internal */\nexport const untilOutput = /*#__PURE__*/dual(2, (self, f) => check(self, (_, out) => !f(out)));\n/** @internal */\nexport const untilOutputEffect = /*#__PURE__*/dual(2, (self, f) => checkEffect(self, (_, out) => effect.negate(f(out))));\n/** @internal */\nexport const upTo = /*#__PURE__*/dual(2, (self, duration) => zipLeft(self, recurUpTo(duration)));\n/** @internal */\nexport const whileInput = /*#__PURE__*/dual(2, (self, f) => check(self, (input, _) => f(input)));\n/** @internal */\nexport const whileInputEffect = /*#__PURE__*/dual(2, (self, f) => checkEffect(self, (input, _) => f(input)));\n/** @internal */\nexport const whileOutput = /*#__PURE__*/dual(2, (self, f) => check(self, (_, out) => f(out)));\n/** @internal */\nexport const whileOutputEffect = /*#__PURE__*/dual(2, (self, f) => checkEffect(self, (_, out) => f(out)));\n/** @internal */\nexport const windowed = intervalInput => {\n  const interval = Duration.decode(intervalInput);\n  const millis = Duration.toMillis(interval);\n  return makeWithState([Option.none(), 0], (now, _, [option, n]) => {\n    switch (option._tag) {\n      case \"None\":\n        {\n          return core.succeed([[Option.some(now), n + 1], n, ScheduleDecision.continueWith(Interval.after(now + millis))]);\n        }\n      case \"Some\":\n        {\n          return core.succeed([[Option.some(option.value), n + 1], n, ScheduleDecision.continueWith(Interval.after(now + (millis - (now - option.value) % millis)))]);\n        }\n    }\n  });\n};\n/** @internal */\nexport const zipLeft = /*#__PURE__*/dual(2, (self, that) => map(intersect(self, that), out => out[0]));\n/** @internal */\nexport const zipRight = /*#__PURE__*/dual(2, (self, that) => map(intersect(self, that), out => out[1]));\n/** @internal */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => map(intersect(self, that), ([out, out2]) => f(out, out2)));\n// -----------------------------------------------------------------------------\n// Seconds\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const beginningOfSecond = now => {\n  const date = new Date(now);\n  return new Date(date.getFullYear(), date.getMonth(), date.getDate(), date.getHours(), date.getMinutes(), date.getSeconds(), 0).getTime();\n};\n/** @internal */\nexport const endOfSecond = now => {\n  const date = new Date(beginningOfSecond(now));\n  return date.setSeconds(date.getSeconds() + 1);\n};\n/** @internal */\nexport const nextSecond = (now, second, initial) => {\n  const date = new Date(now);\n  if (date.getSeconds() === second && initial) {\n    return now;\n  }\n  if (date.getSeconds() < second) {\n    return date.setSeconds(second);\n  }\n  // Set seconds to the provided value and add one minute\n  const newDate = new Date(date.setSeconds(second));\n  return newDate.setTime(newDate.getTime() + 1000 * 60);\n};\n// -----------------------------------------------------------------------------\n// Minutes\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const beginningOfMinute = now => {\n  const date = new Date(now);\n  return new Date(date.getFullYear(), date.getMonth(), date.getDate(), date.getHours(), date.getMinutes(), 0, 0).getTime();\n};\n/** @internal */\nexport const endOfMinute = now => {\n  const date = new Date(beginningOfMinute(now));\n  return date.setMinutes(date.getMinutes() + 1);\n};\n/** @internal */\nexport const nextMinute = (now, minute, initial) => {\n  const date = new Date(now);\n  if (date.getMinutes() === minute && initial) {\n    return now;\n  }\n  if (date.getMinutes() < minute) {\n    return date.setMinutes(minute);\n  }\n  // Set minutes to the provided value and add one hour\n  const newDate = new Date(date.setMinutes(minute));\n  return newDate.setTime(newDate.getTime() + 1000 * 60 * 60);\n};\n// -----------------------------------------------------------------------------\n// Hours\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const beginningOfHour = now => {\n  const date = new Date(now);\n  return new Date(date.getFullYear(), date.getMonth(), date.getDate(), date.getHours(), 0, 0, 0).getTime();\n};\n/** @internal */\nexport const endOfHour = now => {\n  const date = new Date(beginningOfHour(now));\n  return date.setHours(date.getHours() + 1);\n};\n/** @internal */\nexport const nextHour = (now, hour, initial) => {\n  const date = new Date(now);\n  if (date.getHours() === hour && initial) {\n    return now;\n  }\n  if (date.getHours() < hour) {\n    return date.setHours(hour);\n  }\n  // Set hours to the provided value and add one day\n  const newDate = new Date(date.setHours(hour));\n  return newDate.setTime(newDate.getTime() + 1000 * 60 * 60 * 24);\n};\n// -----------------------------------------------------------------------------\n// Days\n// -----------------------------------------------------------------------------\n/** @internal */\nexport const beginningOfDay = now => {\n  const date = new Date(now);\n  return new Date(date.getFullYear(), date.getMonth(), date.getDate(), 0, 0, 0, 0).getTime();\n};\n/** @internal */\nexport const endOfDay = now => {\n  const date = new Date(beginningOfDay(now));\n  return date.setDate(date.getDate() + 1);\n};\n/** @internal */\nexport const nextDay = (now, dayOfWeek, initial) => {\n  const date = new Date(now);\n  if (date.getDay() === dayOfWeek && initial) {\n    return now;\n  }\n  const nextDayOfWeek = (7 + dayOfWeek - date.getDay()) % 7;\n  return date.setDate(date.getDate() + (nextDayOfWeek === 0 ? 7 : nextDayOfWeek));\n};\n/** @internal */\nexport const nextDayOfMonth = (now, day, initial) => {\n  const date = new Date(now);\n  if (date.getDate() === day && initial) {\n    return now;\n  }\n  if (date.getDate() < day) {\n    return date.setDate(day);\n  }\n  return findNextMonth(now, day, 1);\n};\n/** @internal */\nexport const findNextMonth = (now, day, months) => {\n  const d = new Date(now);\n  const tmp1 = new Date(d.setDate(day));\n  const tmp2 = new Date(tmp1.setMonth(tmp1.getMonth() + months));\n  if (tmp2.getDate() === day) {\n    const d2 = new Date(now);\n    const tmp3 = new Date(d2.setDate(day));\n    return tmp3.setMonth(tmp3.getMonth() + months);\n  }\n  return findNextMonth(now, day, months + 1);\n};\n// circular with Effect\nconst ScheduleDefectTypeId = /*#__PURE__*/Symbol.for(\"effect/Schedule/ScheduleDefect\");\nclass ScheduleDefect {\n  error;\n  [ScheduleDefectTypeId];\n  constructor(error) {\n    this.error = error;\n    this[ScheduleDefectTypeId] = ScheduleDefectTypeId;\n  }\n}\nconst isScheduleDefect = u => hasProperty(u, ScheduleDefectTypeId);\nconst scheduleDefectWrap = self => core.catchAll(self, e => core.die(new ScheduleDefect(e)));\nconst scheduleDefectRefail = self => core.catchAllCause(self, cause => Option.match(internalCause.find(cause, _ => internalCause.isDieType(_) && isScheduleDefect(_.defect) ? Option.some(_.defect) : Option.none()), {\n  onNone: () => core.failCause(cause),\n  onSome: error => core.fail(error.error)\n}));\n/** @internal */\nexport const repeat_Effect = /*#__PURE__*/dual(2, (self, schedule) => repeatOrElse_Effect(self, schedule, (e, _) => core.fail(e)));\n/** @internal */\nexport const repeat_combined = /*#__PURE__*/dual(2, (self, options) => {\n  if (isSchedule(options)) {\n    return repeat_Effect(self, options);\n  }\n  const base = options.schedule ?? passthrough(forever);\n  const withWhile = options.while ? whileInputEffect(base, a => {\n    const applied = options.while(a);\n    if (typeof applied === \"boolean\") {\n      return core.succeed(applied);\n    }\n    return scheduleDefectWrap(applied);\n  }) : base;\n  const withUntil = options.until ? untilInputEffect(withWhile, a => {\n    const applied = options.until(a);\n    if (typeof applied === \"boolean\") {\n      return core.succeed(applied);\n    }\n    return scheduleDefectWrap(applied);\n  }) : withWhile;\n  const withTimes = options.times ? intersect(withUntil, recurs(options.times)) : withUntil;\n  return scheduleDefectRefail(repeat_Effect(self, withTimes));\n});\n/** @internal */\nexport const repeatOrElse_Effect = /*#__PURE__*/dual(3, (self, schedule, orElse) => core.flatMap(driver(schedule), driver => core.matchEffect(self, {\n  onFailure: error => orElse(error, Option.none()),\n  onSuccess: value => repeatOrElseEffectLoop(self, driver, orElse, value)\n})));\n/** @internal */\nconst repeatOrElseEffectLoop = (self, driver, orElse, value) => {\n  return core.matchEffect(driver.next(value), {\n    onFailure: () => core.orDie(driver.last),\n    onSuccess: b => core.matchEffect(self, {\n      onFailure: error => orElse(error, Option.some(b)),\n      onSuccess: value => repeatOrElseEffectLoop(self, driver, orElse, value)\n    })\n  });\n};\n/** @internal */\nexport const retry_Effect = /*#__PURE__*/dual(2, (self, policy) => retryOrElse_Effect(self, policy, (e, _) => core.fail(e)));\n/** @internal */\nexport const retry_combined = /*#__PURE__*/dual(2, (self, options) => {\n  if (isSchedule(options)) {\n    return retry_Effect(self, options);\n  }\n  const base = options.schedule ?? forever;\n  const withWhile = options.while ? whileInputEffect(base, e => {\n    const applied = options.while(e);\n    if (typeof applied === \"boolean\") {\n      return core.succeed(applied);\n    }\n    return scheduleDefectWrap(applied);\n  }) : base;\n  const withUntil = options.until ? untilInputEffect(withWhile, e => {\n    const applied = options.until(e);\n    if (typeof applied === \"boolean\") {\n      return core.succeed(applied);\n    }\n    return scheduleDefectWrap(applied);\n  }) : withWhile;\n  const withTimes = options.times ? intersect(withUntil, recurs(options.times)) : withUntil;\n  return scheduleDefectRefail(retry_Effect(self, withTimes));\n});\n/** @internal */\nexport const retryOrElse_Effect = /*#__PURE__*/dual(3, (self, policy, orElse) => core.flatMap(driver(policy), driver => retryOrElse_EffectLoop(self, driver, orElse)));\n/** @internal */\nconst retryOrElse_EffectLoop = (self, driver, orElse) => {\n  return core.catchAll(self, e => core.matchEffect(driver.next(e), {\n    onFailure: () => pipe(driver.last, core.orDie, core.flatMap(out => orElse(e, out))),\n    onSuccess: () => retryOrElse_EffectLoop(self, driver, orElse)\n  }));\n};\n/** @internal */\nexport const schedule_Effect = /*#__PURE__*/dual(2, (self, schedule) => scheduleFrom_Effect(self, void 0, schedule));\n/** @internal */\nexport const scheduleFrom_Effect = /*#__PURE__*/dual(3, (self, initial, schedule) => core.flatMap(driver(schedule), driver => scheduleFrom_EffectLoop(self, initial, driver)));\n/** @internal */\nconst scheduleFrom_EffectLoop = (self, initial, driver) => core.matchEffect(driver.next(initial), {\n  onFailure: () => core.orDie(driver.last),\n  onSuccess: () => core.flatMap(self, a => scheduleFrom_EffectLoop(self, a, driver))\n});\n/** @internal */\nexport const count = /*#__PURE__*/unfold(0, n => n + 1);\n/** @internal */\nexport const elapsed = /*#__PURE__*/makeWithState( /*#__PURE__*/Option.none(), (now, _, state) => {\n  switch (state._tag) {\n    case \"None\":\n      {\n        return core.succeed([Option.some(now), Duration.zero, ScheduleDecision.continueWith(Interval.after(now))]);\n      }\n    case \"Some\":\n      {\n        return core.succeed([Option.some(state.value), Duration.millis(now - state.value), ScheduleDecision.continueWith(Interval.after(now))]);\n      }\n  }\n});\n/** @internal */\nexport const forever = /*#__PURE__*/unfold(0, n => n + 1);\n/** @internal */\nexport const once = /*#__PURE__*/asVoid( /*#__PURE__*/recurs(1));\n/** @internal */\nexport const stop = /*#__PURE__*/asVoid( /*#__PURE__*/recurs(0));\n//# sourceMappingURL=schedule.js.map","import * as Chunk from \"../../Chunk.js\";\nimport * as Intervals from \"../../ScheduleIntervals.js\";\n/** @internal */\nexport const OP_CONTINUE = \"Continue\";\n/** @internal */\nexport const OP_DONE = \"Done\";\n/** @internal */\nexport const _continue = intervals => {\n  return {\n    _tag: OP_CONTINUE,\n    intervals\n  };\n};\n/** @internal */\nexport const continueWith = interval => {\n  return {\n    _tag: OP_CONTINUE,\n    intervals: Intervals.make(Chunk.of(interval))\n  };\n};\n/** @internal */\nexport const done = {\n  _tag: OP_DONE\n};\n/** @internal */\nexport const isContinue = self => {\n  return self._tag === OP_CONTINUE;\n};\n/** @internal */\nexport const isDone = self => {\n  return self._tag === OP_DONE;\n};\n//# sourceMappingURL=decision.js.map","import * as Duration from \"../../Duration.js\";\nimport { dual } from \"../../Function.js\";\nimport * as Option from \"../../Option.js\";\n/** @internal */\nconst IntervalSymbolKey = \"effect/ScheduleInterval\";\n/** @internal */\nexport const IntervalTypeId = /*#__PURE__*/Symbol.for(IntervalSymbolKey);\n/** @internal */\nexport const empty = {\n  [IntervalTypeId]: IntervalTypeId,\n  startMillis: 0,\n  endMillis: 0\n};\n/** @internal */\nexport const make = (startMillis, endMillis) => {\n  if (startMillis > endMillis) {\n    return empty;\n  }\n  return {\n    [IntervalTypeId]: IntervalTypeId,\n    startMillis,\n    endMillis\n  };\n};\n/** @internal */\nexport const lessThan = /*#__PURE__*/dual(2, (self, that) => min(self, that) === self);\n/** @internal */\nexport const min = /*#__PURE__*/dual(2, (self, that) => {\n  if (self.endMillis <= that.startMillis) return self;\n  if (that.endMillis <= self.startMillis) return that;\n  if (self.startMillis < that.startMillis) return self;\n  if (that.startMillis < self.startMillis) return that;\n  if (self.endMillis <= that.endMillis) return self;\n  return that;\n});\n/** @internal */\nexport const max = /*#__PURE__*/dual(2, (self, that) => min(self, that) === self ? that : self);\n/** @internal */\nexport const isEmpty = self => {\n  return self.startMillis >= self.endMillis;\n};\n/** @internal */\nexport const isNonEmpty = self => {\n  return !isEmpty(self);\n};\n/** @internal */\nexport const intersect = /*#__PURE__*/dual(2, (self, that) => {\n  const start = Math.max(self.startMillis, that.startMillis);\n  const end = Math.min(self.endMillis, that.endMillis);\n  return make(start, end);\n});\n/** @internal */\nexport const size = self => {\n  return Duration.millis(self.endMillis - self.startMillis);\n};\n/** @internal */\nexport const union = /*#__PURE__*/dual(2, (self, that) => {\n  const start = Math.max(self.startMillis, that.startMillis);\n  const end = Math.min(self.endMillis, that.endMillis);\n  return start < end ? Option.none() : Option.some(make(start, end));\n});\n/** @internal */\nexport const after = startMilliseconds => {\n  return make(startMilliseconds, Number.POSITIVE_INFINITY);\n};\n/** @internal */\nexport const before = endMilliseconds => {\n  return make(Number.NEGATIVE_INFINITY, endMilliseconds);\n};\n//# sourceMappingURL=interval.js.map","import * as Chunk from \"../../Chunk.js\";\nimport { dual, pipe } from \"../../Function.js\";\nimport * as Option from \"../../Option.js\";\nimport * as Interval from \"../../ScheduleInterval.js\";\nimport { getBugErrorMessage } from \"../errors.js\";\n/** @internal */\nconst IntervalsSymbolKey = \"effect/ScheduleIntervals\";\n/** @internal */\nexport const IntervalsTypeId = /*#__PURE__*/Symbol.for(IntervalsSymbolKey);\n/** @internal */\nexport const make = intervals => {\n  return {\n    [IntervalsTypeId]: IntervalsTypeId,\n    intervals\n  };\n};\n/** @internal */\nexport const empty = /*#__PURE__*/make( /*#__PURE__*/Chunk.empty());\n/** @internal */\nexport const fromIterable = intervals => Array.from(intervals).reduce((intervals, interval) => pipe(intervals, union(make(Chunk.of(interval)))), empty);\n/** @internal */\nexport const union = /*#__PURE__*/dual(2, (self, that) => {\n  if (!Chunk.isNonEmpty(that.intervals)) {\n    return self;\n  }\n  if (!Chunk.isNonEmpty(self.intervals)) {\n    return that;\n  }\n  if (Chunk.headNonEmpty(self.intervals).startMillis < Chunk.headNonEmpty(that.intervals).startMillis) {\n    return unionLoop(Chunk.tailNonEmpty(self.intervals), that.intervals, Chunk.headNonEmpty(self.intervals), Chunk.empty());\n  }\n  return unionLoop(self.intervals, Chunk.tailNonEmpty(that.intervals), Chunk.headNonEmpty(that.intervals), Chunk.empty());\n});\n/** @internal */\nconst unionLoop = (_self, _that, _interval, _acc) => {\n  let self = _self;\n  let that = _that;\n  let interval = _interval;\n  let acc = _acc;\n  while (Chunk.isNonEmpty(self) || Chunk.isNonEmpty(that)) {\n    if (!Chunk.isNonEmpty(self) && Chunk.isNonEmpty(that)) {\n      if (interval.endMillis < Chunk.headNonEmpty(that).startMillis) {\n        acc = pipe(acc, Chunk.prepend(interval));\n        interval = Chunk.headNonEmpty(that);\n        that = Chunk.tailNonEmpty(that);\n        self = Chunk.empty();\n      } else {\n        interval = Interval.make(interval.startMillis, Chunk.headNonEmpty(that).endMillis);\n        that = Chunk.tailNonEmpty(that);\n        self = Chunk.empty();\n      }\n    } else if (Chunk.isNonEmpty(self) && Chunk.isEmpty(that)) {\n      if (interval.endMillis < Chunk.headNonEmpty(self).startMillis) {\n        acc = pipe(acc, Chunk.prepend(interval));\n        interval = Chunk.headNonEmpty(self);\n        that = Chunk.empty();\n        self = Chunk.tailNonEmpty(self);\n      } else {\n        interval = Interval.make(interval.startMillis, Chunk.headNonEmpty(self).endMillis);\n        that = Chunk.empty();\n        self = Chunk.tailNonEmpty(self);\n      }\n    } else if (Chunk.isNonEmpty(self) && Chunk.isNonEmpty(that)) {\n      if (Chunk.headNonEmpty(self).startMillis < Chunk.headNonEmpty(that).startMillis) {\n        if (interval.endMillis < Chunk.headNonEmpty(self).startMillis) {\n          acc = pipe(acc, Chunk.prepend(interval));\n          interval = Chunk.headNonEmpty(self);\n          self = Chunk.tailNonEmpty(self);\n        } else {\n          interval = Interval.make(interval.startMillis, Chunk.headNonEmpty(self).endMillis);\n          self = Chunk.tailNonEmpty(self);\n        }\n      } else if (interval.endMillis < Chunk.headNonEmpty(that).startMillis) {\n        acc = pipe(acc, Chunk.prepend(interval));\n        interval = Chunk.headNonEmpty(that);\n        that = Chunk.tailNonEmpty(that);\n      } else {\n        interval = Interval.make(interval.startMillis, Chunk.headNonEmpty(that).endMillis);\n        that = Chunk.tailNonEmpty(that);\n      }\n    } else {\n      throw new Error(getBugErrorMessage(\"Intervals.unionLoop\"));\n    }\n  }\n  return make(pipe(acc, Chunk.prepend(interval), Chunk.reverse));\n};\n/** @internal */\nexport const intersect = /*#__PURE__*/dual(2, (self, that) => intersectLoop(self.intervals, that.intervals, Chunk.empty()));\n/** @internal */\nconst intersectLoop = (_left, _right, _acc) => {\n  let left = _left;\n  let right = _right;\n  let acc = _acc;\n  while (Chunk.isNonEmpty(left) && Chunk.isNonEmpty(right)) {\n    const interval = pipe(Chunk.headNonEmpty(left), Interval.intersect(Chunk.headNonEmpty(right)));\n    const intervals = Interval.isEmpty(interval) ? acc : pipe(acc, Chunk.prepend(interval));\n    if (pipe(Chunk.headNonEmpty(left), Interval.lessThan(Chunk.headNonEmpty(right)))) {\n      left = Chunk.tailNonEmpty(left);\n    } else {\n      right = Chunk.tailNonEmpty(right);\n    }\n    acc = intervals;\n  }\n  return make(Chunk.reverse(acc));\n};\n/** @internal */\nexport const start = self => {\n  return pipe(self.intervals, Chunk.head, Option.getOrElse(() => Interval.empty)).startMillis;\n};\n/** @internal */\nexport const end = self => {\n  return pipe(self.intervals, Chunk.head, Option.getOrElse(() => Interval.empty)).endMillis;\n};\n/** @internal */\nexport const lessThan = /*#__PURE__*/dual(2, (self, that) => start(self) < start(that));\n/** @internal */\nexport const isNonEmpty = self => {\n  return Chunk.isNonEmpty(self.intervals);\n};\n/** @internal */\nexport const max = /*#__PURE__*/dual(2, (self, that) => lessThan(self, that) ? that : self);\n//# sourceMappingURL=intervals.js.map","import * as Arr from \"../Array.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as redacted_ from \"./redacted.js\";\n/**\n * @internal\n * @deprecated\n */\nconst SecretSymbolKey = \"effect/Secret\";\n/**\n * @internal\n * @deprecated\n */\nexport const SecretTypeId = /*#__PURE__*/Symbol.for(SecretSymbolKey);\n/**\n * @internal\n * @deprecated\n */\nexport const isSecret = u => hasProperty(u, SecretTypeId);\n/**\n * @internal\n * @deprecated\n */\nexport const make = bytes => {\n  const secret = Object.create({\n    ...redacted_.proto,\n    [SecretTypeId]: SecretTypeId\n  });\n  Object.defineProperty(secret, \"toString\", {\n    enumerable: false,\n    value() {\n      return \"Secret(<redacted>)\";\n    }\n  });\n  Object.defineProperty(secret, \"toJSON\", {\n    enumerable: false,\n    value() {\n      return \"<redacted>\";\n    }\n  });\n  Object.defineProperty(secret, \"raw\", {\n    enumerable: false,\n    value: bytes\n  });\n  redacted_.redactedRegistry.set(secret, bytes.map(byte => String.fromCharCode(byte)).join(\"\"));\n  return secret;\n};\n/**\n * @internal\n * @deprecated\n */\nexport const fromIterable = iterable => make(Arr.fromIterable(iterable).map(char => char.charCodeAt(0)));\n/**\n * @internal\n * @deprecated\n */\nexport const fromString = text => {\n  return make(text.split(\"\").map(char => char.charCodeAt(0)));\n};\n/**\n * @internal\n * @deprecated\n */\nexport const value = self => {\n  return self.raw.map(byte => String.fromCharCode(byte)).join(\"\");\n};\n/**\n * @internal\n * @deprecated\n */\nexport const unsafeWipe = self => {\n  for (let i = 0; i < self.raw.length; i++) {\n    self.raw[i] = 0;\n  }\n  redacted_.redactedRegistry.delete(self);\n};\n//# sourceMappingURL=secret.js.map","/** @internal */\nexport class SingleShotGen {\n  self;\n  called = false;\n  constructor(self) {\n    this.self = self;\n  }\n  next(a) {\n    return this.called ? {\n      value: a,\n      done: true\n    } : (this.called = true, {\n      value: this.self,\n      done: false\n    });\n  }\n  return(a) {\n    return {\n      value: a,\n      done: true\n    };\n  }\n  throw(e) {\n    throw e;\n  }\n  [Symbol.iterator]() {\n    return new SingleShotGen(this.self);\n  }\n}\n//# sourceMappingURL=singleShotGen.js.map","import * as Arr from \"../Array.js\";\nimport * as Cause from \"../Cause.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Clock from \"../Clock.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as Effect from \"../Effect.js\";\nimport * as Either from \"../Either.js\";\nimport * as Exit from \"../Exit.js\";\nimport { constTrue, dual, identity, pipe } from \"../Function.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as PubSub from \"../PubSub.js\";\nimport * as Queue from \"../Queue.js\";\nimport * as Ref from \"../Ref.js\";\nimport * as channel from \"./channel.js\";\nimport * as mergeDecision from \"./channel/mergeDecision.js\";\nimport * as core from \"./core-stream.js\";\n/** @internal */\nexport const SinkTypeId = /*#__PURE__*/Symbol.for(\"effect/Sink\");\nconst sinkVariance = {\n  /* c8 ignore next */\n  _A: _ => _,\n  /* c8 ignore next */\n  _In: _ => _,\n  /* c8 ignore next */\n  _L: _ => _,\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _R: _ => _\n};\n/** @internal */\nexport class SinkImpl {\n  channel;\n  [SinkTypeId] = sinkVariance;\n  constructor(channel) {\n    this.channel = channel;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const isSink = u => hasProperty(u, SinkTypeId);\n/** @internal */\nexport const suspend = evaluate => new SinkImpl(core.suspend(() => toChannel(evaluate())));\n/** @internal */\nexport const as = /*#__PURE__*/dual(2, (self, a) => pipe(self, map(() => a)));\n/** @internal */\nexport const collectAll = () => new SinkImpl(collectAllLoop(Chunk.empty()));\n/** @internal */\nconst collectAllLoop = acc => core.readWithCause({\n  onInput: chunk => collectAllLoop(pipe(acc, Chunk.appendAll(chunk))),\n  onFailure: core.failCause,\n  onDone: () => core.succeed(acc)\n});\n/** @internal */\nexport const collectAllN = n => suspend(() => fromChannel(collectAllNLoop(n, Chunk.empty())));\n/** @internal */\nconst collectAllNLoop = (n, acc) => core.readWithCause({\n  onInput: chunk => {\n    const [collected, leftovers] = Chunk.splitAt(chunk, n);\n    if (collected.length < n) {\n      return collectAllNLoop(n - collected.length, Chunk.appendAll(acc, collected));\n    }\n    if (Chunk.isEmpty(leftovers)) {\n      return core.succeed(Chunk.appendAll(acc, collected));\n    }\n    return core.flatMap(core.write(leftovers), () => core.succeed(Chunk.appendAll(acc, collected)));\n  },\n  onFailure: core.failCause,\n  onDone: () => core.succeed(acc)\n});\n/** @internal */\nexport const collectAllFrom = self => collectAllWhileWith(self, {\n  initial: Chunk.empty(),\n  while: constTrue,\n  body: (chunk, a) => pipe(chunk, Chunk.append(a))\n});\n/** @internal */\nexport const collectAllToMap = (key, merge) => {\n  return pipe(foldLeftChunks(HashMap.empty(), (map, chunk) => pipe(chunk, Chunk.reduce(map, (map, input) => {\n    const k = key(input);\n    const v = pipe(map, HashMap.has(k)) ? merge(pipe(map, HashMap.unsafeGet(k)), input) : input;\n    return pipe(map, HashMap.set(k, v));\n  }))));\n};\n/** @internal */\nexport const collectAllToMapN = (n, key, merge) => {\n  return foldWeighted({\n    initial: HashMap.empty(),\n    maxCost: n,\n    cost: (acc, input) => pipe(acc, HashMap.has(key(input))) ? 0 : 1,\n    body: (acc, input) => {\n      const k = key(input);\n      const v = pipe(acc, HashMap.has(k)) ? merge(pipe(acc, HashMap.unsafeGet(k)), input) : input;\n      return pipe(acc, HashMap.set(k, v));\n    }\n  });\n};\n/** @internal */\nexport const collectAllToSet = () => foldLeftChunks(HashSet.empty(), (acc, chunk) => pipe(chunk, Chunk.reduce(acc, (acc, input) => pipe(acc, HashSet.add(input)))));\n/** @internal */\nexport const collectAllToSetN = n => foldWeighted({\n  initial: HashSet.empty(),\n  maxCost: n,\n  cost: (acc, input) => HashSet.has(acc, input) ? 0 : 1,\n  body: (acc, input) => HashSet.add(acc, input)\n});\n/** @internal */\nexport const collectAllUntil = p => {\n  return pipe(fold([Chunk.empty(), true], tuple => tuple[1], ([chunk, _], input) => [pipe(chunk, Chunk.append(input)), !p(input)]), map(tuple => tuple[0]));\n};\n/** @internal */\nexport const collectAllUntilEffect = p => {\n  return pipe(foldEffect([Chunk.empty(), true], tuple => tuple[1], ([chunk, _], input) => pipe(p(input), Effect.map(bool => [pipe(chunk, Chunk.append(input)), !bool]))), map(tuple => tuple[0]));\n};\n/** @internal */\nexport const collectAllWhile = predicate => fromChannel(collectAllWhileReader(predicate, Chunk.empty()));\n/** @internal */\nconst collectAllWhileReader = (predicate, done) => core.readWith({\n  onInput: input => {\n    const [collected, leftovers] = pipe(Chunk.toReadonlyArray(input), Arr.span(predicate));\n    if (leftovers.length === 0) {\n      return collectAllWhileReader(predicate, pipe(done, Chunk.appendAll(Chunk.unsafeFromArray(collected))));\n    }\n    return pipe(core.write(Chunk.unsafeFromArray(leftovers)), channel.zipRight(core.succeed(pipe(done, Chunk.appendAll(Chunk.unsafeFromArray(collected))))));\n  },\n  onFailure: core.fail,\n  onDone: () => core.succeed(done)\n});\n/** @internal */\nexport const collectAllWhileEffect = predicate => fromChannel(collectAllWhileEffectReader(predicate, Chunk.empty()));\n/** @internal */\nconst collectAllWhileEffectReader = (predicate, done) => core.readWith({\n  onInput: input => pipe(core.fromEffect(pipe(input, Effect.takeWhile(predicate), Effect.map(Chunk.unsafeFromArray))), core.flatMap(collected => {\n    const leftovers = pipe(input, Chunk.drop(collected.length));\n    if (Chunk.isEmpty(leftovers)) {\n      return collectAllWhileEffectReader(predicate, pipe(done, Chunk.appendAll(collected)));\n    }\n    return pipe(core.write(leftovers), channel.zipRight(core.succeed(pipe(done, Chunk.appendAll(collected)))));\n  })),\n  onFailure: core.fail,\n  onDone: () => core.succeed(done)\n});\n/** @internal */\nexport const collectAllWhileWith = /*#__PURE__*/dual(2, (self, options) => {\n  const refs = pipe(Ref.make(Chunk.empty()), Effect.zip(Ref.make(false)));\n  const newChannel = pipe(core.fromEffect(refs), core.flatMap(([leftoversRef, upstreamDoneRef]) => {\n    const upstreamMarker = core.readWith({\n      onInput: input => pipe(core.write(input), core.flatMap(() => upstreamMarker)),\n      onFailure: core.fail,\n      onDone: done => pipe(core.fromEffect(Ref.set(upstreamDoneRef, true)), channel.as(done))\n    });\n    return pipe(upstreamMarker, core.pipeTo(channel.bufferChunk(leftoversRef)), core.pipeTo(collectAllWhileWithLoop(self, leftoversRef, upstreamDoneRef, options.initial, options.while, options.body)));\n  }));\n  return new SinkImpl(newChannel);\n});\nconst collectAllWhileWithLoop = (self, leftoversRef, upstreamDoneRef, currentResult, p, f) => {\n  return pipe(toChannel(self), channel.doneCollect, channel.foldChannel({\n    onFailure: core.fail,\n    onSuccess: ([leftovers, doneValue]) => p(doneValue) ? pipe(core.fromEffect(Ref.set(leftoversRef, Chunk.flatten(leftovers))), core.flatMap(() => pipe(core.fromEffect(Ref.get(upstreamDoneRef)), core.flatMap(upstreamDone => {\n      const accumulatedResult = f(currentResult, doneValue);\n      return upstreamDone ? pipe(core.write(Chunk.flatten(leftovers)), channel.as(accumulatedResult)) : collectAllWhileWithLoop(self, leftoversRef, upstreamDoneRef, accumulatedResult, p, f);\n    })))) : pipe(core.write(Chunk.flatten(leftovers)), channel.as(currentResult))\n  }));\n};\n/** @internal */\nexport const collectLeftover = self => new SinkImpl(pipe(core.collectElements(toChannel(self)), channel.map(([chunks, z]) => [z, Chunk.flatten(chunks)])));\n/** @internal */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => pipe(self, mapInputChunks(Chunk.map(f))));\n/** @internal */\nexport const mapInputEffect = /*#__PURE__*/dual(2, (self, f) => mapInputChunksEffect(self, chunk => Effect.map(Effect.forEach(chunk, v => f(v)), Chunk.unsafeFromArray)));\n/** @internal */\nexport const mapInputChunks = /*#__PURE__*/dual(2, (self, f) => {\n  const loop = core.readWith({\n    onInput: chunk => pipe(core.write(f(chunk)), core.flatMap(() => loop)),\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n  return new SinkImpl(pipe(loop, core.pipeTo(toChannel(self))));\n});\n/** @internal */\nexport const mapInputChunksEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const loop = core.readWith({\n    onInput: chunk => pipe(core.fromEffect(f(chunk)), core.flatMap(core.write), core.flatMap(() => loop)),\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n  return new SinkImpl(pipe(loop, channel.pipeToOrFail(toChannel(self))));\n});\n/** @internal */\nexport const die = defect => failCause(Cause.die(defect));\n/** @internal */\nexport const dieMessage = message => failCause(Cause.die(new Cause.RuntimeException(message)));\n/** @internal */\nexport const dieSync = evaluate => failCauseSync(() => Cause.die(evaluate()));\n/** @internal */\nexport const dimap = /*#__PURE__*/dual(2, (self, options) => map(mapInput(self, options.onInput), options.onDone));\n/** @internal */\nexport const dimapEffect = /*#__PURE__*/dual(2, (self, options) => mapEffect(mapInputEffect(self, options.onInput), options.onDone));\n/** @internal */\nexport const dimapChunks = /*#__PURE__*/dual(2, (self, options) => map(mapInputChunks(self, options.onInput), options.onDone));\n/** @internal */\nexport const dimapChunksEffect = /*#__PURE__*/dual(2, (self, options) => mapEffect(mapInputChunksEffect(self, options.onInput), options.onDone));\n/** @internal */\nexport const drain = /*#__PURE__*/new SinkImpl( /*#__PURE__*/channel.drain( /*#__PURE__*/channel.identityChannel()));\n/** @internal */\nexport const drop = n => suspend(() => new SinkImpl(dropLoop(n)));\n/** @internal */\nconst dropLoop = n => core.readWith({\n  onInput: input => {\n    const dropped = pipe(input, Chunk.drop(n));\n    const leftover = Math.max(n - input.length, 0);\n    const more = Chunk.isEmpty(input) || leftover > 0;\n    if (more) {\n      return dropLoop(leftover);\n    }\n    return pipe(core.write(dropped), channel.zipRight(channel.identityChannel()));\n  },\n  onFailure: core.fail,\n  onDone: () => core.void\n});\n/** @internal */\nexport const dropUntil = predicate => new SinkImpl(pipe(toChannel(dropWhile(input => !predicate(input))), channel.pipeToOrFail(toChannel(drop(1)))));\n/** @internal */\nexport const dropUntilEffect = predicate => suspend(() => new SinkImpl(dropUntilEffectReader(predicate)));\n/** @internal */\nconst dropUntilEffectReader = predicate => core.readWith({\n  onInput: input => pipe(input, Effect.dropUntil(predicate), Effect.map(leftover => {\n    const more = leftover.length === 0;\n    return more ? dropUntilEffectReader(predicate) : pipe(core.write(Chunk.unsafeFromArray(leftover)), channel.zipRight(channel.identityChannel()));\n  }), channel.unwrap),\n  onFailure: core.fail,\n  onDone: () => core.void\n});\n/** @internal */\nexport const dropWhile = predicate => new SinkImpl(dropWhileReader(predicate));\n/** @internal */\nconst dropWhileReader = predicate => core.readWith({\n  onInput: input => {\n    const out = pipe(input, Chunk.dropWhile(predicate));\n    if (Chunk.isEmpty(out)) {\n      return dropWhileReader(predicate);\n    }\n    return pipe(core.write(out), channel.zipRight(channel.identityChannel()));\n  },\n  onFailure: core.fail,\n  onDone: core.succeedNow\n});\n/** @internal */\nexport const dropWhileEffect = predicate => suspend(() => new SinkImpl(dropWhileEffectReader(predicate)));\n/** @internal */\nconst dropWhileEffectReader = predicate => core.readWith({\n  onInput: input => pipe(input, Effect.dropWhile(predicate), Effect.map(leftover => {\n    const more = leftover.length === 0;\n    return more ? dropWhileEffectReader(predicate) : pipe(core.write(Chunk.unsafeFromArray(leftover)), channel.zipRight(channel.identityChannel()));\n  }), channel.unwrap),\n  onFailure: core.fail,\n  onDone: () => core.void\n});\n/** @internal */\nexport const ensuring = /*#__PURE__*/dual(2, (self, finalizer) => new SinkImpl(pipe(self, toChannel, channel.ensuring(finalizer))));\n/** @internal */\nexport const ensuringWith = /*#__PURE__*/dual(2, (self, finalizer) => new SinkImpl(pipe(self, toChannel, core.ensuringWith(finalizer))));\n/** @internal */\nexport const context = () => fromEffect(Effect.context());\n/** @internal */\nexport const contextWith = f => pipe(context(), map(f));\n/** @internal */\nexport const contextWithEffect = f => pipe(context(), mapEffect(f));\n/** @internal */\nexport const contextWithSink = f => new SinkImpl(channel.unwrap(pipe(Effect.contextWith(context => toChannel(f(context))))));\n/** @internal */\nexport const every = predicate => fold(true, identity, (acc, input) => acc && predicate(input));\n/** @internal */\nexport const fail = e => new SinkImpl(core.fail(e));\n/** @internal */\nexport const failSync = evaluate => new SinkImpl(core.failSync(evaluate));\n/** @internal */\nexport const failCause = cause => new SinkImpl(core.failCause(cause));\n/** @internal */\nexport const failCauseSync = evaluate => new SinkImpl(core.failCauseSync(evaluate));\n/** @internal */\nexport const filterInput = f => {\n  return self => pipe(self, mapInputChunks(Chunk.filter(f)));\n};\n/** @internal */\nexport const filterInputEffect = /*#__PURE__*/dual(2, (self, f) => mapInputChunksEffect(self, chunk => Effect.map(Effect.filter(chunk, f), Chunk.unsafeFromArray)));\n/** @internal */\nexport const findEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const newChannel = pipe(core.fromEffect(pipe(Ref.make(Chunk.empty()), Effect.zip(Ref.make(false)))), core.flatMap(([leftoversRef, upstreamDoneRef]) => {\n    const upstreamMarker = core.readWith({\n      onInput: input => pipe(core.write(input), core.flatMap(() => upstreamMarker)),\n      onFailure: core.fail,\n      onDone: done => pipe(core.fromEffect(Ref.set(upstreamDoneRef, true)), channel.as(done))\n    });\n    const loop = channel.foldChannel(core.collectElements(toChannel(self)), {\n      onFailure: core.fail,\n      onSuccess: ([leftovers, doneValue]) => pipe(core.fromEffect(f(doneValue)), core.flatMap(satisfied => pipe(core.fromEffect(Ref.set(leftoversRef, Chunk.flatten(leftovers))), channel.zipRight(pipe(core.fromEffect(Ref.get(upstreamDoneRef)), core.flatMap(upstreamDone => {\n        if (satisfied) {\n          return pipe(core.write(Chunk.flatten(leftovers)), channel.as(Option.some(doneValue)));\n        }\n        if (upstreamDone) {\n          return pipe(core.write(Chunk.flatten(leftovers)), channel.as(Option.none()));\n        }\n        return loop;\n      }))))))\n    });\n    return pipe(upstreamMarker, core.pipeTo(channel.bufferChunk(leftoversRef)), core.pipeTo(loop));\n  }));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nexport const fold = (s, contFn, f) => suspend(() => new SinkImpl(foldReader(s, contFn, f)));\n/** @internal */\nconst foldReader = (s, contFn, f) => {\n  if (!contFn(s)) {\n    return core.succeedNow(s);\n  }\n  return core.readWith({\n    onInput: input => {\n      const [nextS, leftovers] = foldChunkSplit(s, input, contFn, f, 0, input.length);\n      if (Chunk.isNonEmpty(leftovers)) {\n        return pipe(core.write(leftovers), channel.as(nextS));\n      }\n      return foldReader(nextS, contFn, f);\n    },\n    onFailure: core.fail,\n    onDone: () => core.succeedNow(s)\n  });\n};\n/** @internal */\nconst foldChunkSplit = (s, chunk, contFn, f, index, length) => {\n  if (index === length) {\n    return [s, Chunk.empty()];\n  }\n  const s1 = f(s, pipe(chunk, Chunk.unsafeGet(index)));\n  if (contFn(s1)) {\n    return foldChunkSplit(s1, chunk, contFn, f, index + 1, length);\n  }\n  return [s1, pipe(chunk, Chunk.drop(index + 1))];\n};\n/** @internal */\nexport const foldSink = /*#__PURE__*/dual(2, (self, options) => {\n  const newChannel = pipe(toChannel(self), core.collectElements, channel.foldChannel({\n    onFailure: error => toChannel(options.onFailure(error)),\n    onSuccess: ([leftovers, z]) => core.suspend(() => {\n      const leftoversRef = {\n        ref: pipe(leftovers, Chunk.filter(Chunk.isNonEmpty))\n      };\n      const refReader = pipe(core.sync(() => {\n        const ref = leftoversRef.ref;\n        leftoversRef.ref = Chunk.empty();\n        return ref;\n      }),\n      // This cast is safe because of the L1 >: L <: In1 bound. It follows that\n      // L <: In1 and therefore Chunk[L] can be safely cast to Chunk[In1].\n      core.flatMap(chunk => channel.writeChunk(chunk)));\n      const passthrough = channel.identityChannel();\n      const continuationSink = pipe(refReader, channel.zipRight(passthrough), core.pipeTo(toChannel(options.onSuccess(z))));\n      return core.flatMap(core.collectElements(continuationSink), ([newLeftovers, z1]) => pipe(core.succeed(leftoversRef.ref), core.flatMap(channel.writeChunk), channel.zipRight(channel.writeChunk(newLeftovers)), channel.as(z1)));\n    })\n  }));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nexport const foldChunks = (s, contFn, f) => suspend(() => new SinkImpl(foldChunksReader(s, contFn, f)));\n/** @internal */\nconst foldChunksReader = (s, contFn, f) => {\n  if (!contFn(s)) {\n    return core.succeedNow(s);\n  }\n  return core.readWith({\n    onInput: input => foldChunksReader(f(s, input), contFn, f),\n    onFailure: core.fail,\n    onDone: () => core.succeedNow(s)\n  });\n};\n/** @internal */\nexport const foldChunksEffect = (s, contFn, f) => suspend(() => new SinkImpl(foldChunksEffectReader(s, contFn, f)));\n/** @internal */\nconst foldChunksEffectReader = (s, contFn, f) => {\n  if (!contFn(s)) {\n    return core.succeedNow(s);\n  }\n  return core.readWith({\n    onInput: input => pipe(core.fromEffect(f(s, input)), core.flatMap(s => foldChunksEffectReader(s, contFn, f))),\n    onFailure: core.fail,\n    onDone: () => core.succeedNow(s)\n  });\n};\n/** @internal */\nexport const foldEffect = (s, contFn, f) => suspend(() => new SinkImpl(foldEffectReader(s, contFn, f)));\n/** @internal */\nconst foldEffectReader = (s, contFn, f) => {\n  if (!contFn(s)) {\n    return core.succeedNow(s);\n  }\n  return core.readWith({\n    onInput: input => pipe(core.fromEffect(foldChunkSplitEffect(s, input, contFn, f)), core.flatMap(([nextS, leftovers]) => pipe(leftovers, Option.match({\n      onNone: () => foldEffectReader(nextS, contFn, f),\n      onSome: leftover => pipe(core.write(leftover), channel.as(nextS))\n    })))),\n    onFailure: core.fail,\n    onDone: () => core.succeedNow(s)\n  });\n};\n/** @internal */\nconst foldChunkSplitEffect = (s, chunk, contFn, f) => foldChunkSplitEffectInternal(s, chunk, 0, chunk.length, contFn, f);\n/** @internal */\nconst foldChunkSplitEffectInternal = (s, chunk, index, length, contFn, f) => {\n  if (index === length) {\n    return Effect.succeed([s, Option.none()]);\n  }\n  return pipe(f(s, pipe(chunk, Chunk.unsafeGet(index))), Effect.flatMap(s1 => contFn(s1) ? foldChunkSplitEffectInternal(s1, chunk, index + 1, length, contFn, f) : Effect.succeed([s1, Option.some(pipe(chunk, Chunk.drop(index + 1)))])));\n};\n/** @internal */\nexport const foldLeft = (s, f) => ignoreLeftover(fold(s, constTrue, f));\n/** @internal */\nexport const foldLeftChunks = (s, f) => foldChunks(s, constTrue, f);\n/** @internal */\nexport const foldLeftChunksEffect = (s, f) => ignoreLeftover(foldChunksEffect(s, constTrue, f));\n/** @internal */\nexport const foldLeftEffect = (s, f) => foldEffect(s, constTrue, f);\n/** @internal */\nexport const foldUntil = (s, max, f) => pipe(fold([s, 0], tuple => tuple[1] < max, ([output, count], input) => [f(output, input), count + 1]), map(tuple => tuple[0]));\n/** @internal */\nexport const foldUntilEffect = (s, max, f) => pipe(foldEffect([s, 0], tuple => tuple[1] < max, ([output, count], input) => pipe(f(output, input), Effect.map(s => [s, count + 1]))), map(tuple => tuple[0]));\n/** @internal */\nexport const foldWeighted = options => foldWeightedDecompose({\n  ...options,\n  decompose: Chunk.of\n});\n/** @internal */\nexport const foldWeightedDecompose = options => suspend(() => new SinkImpl(foldWeightedDecomposeLoop(options.initial, 0, false, options.maxCost, options.cost, options.decompose, options.body)));\n/** @internal */\nconst foldWeightedDecomposeLoop = (s, cost, dirty, max, costFn, decompose, f) => core.readWith({\n  onInput: input => {\n    const [nextS, nextCost, nextDirty, leftovers] = foldWeightedDecomposeFold(input, 0, s, cost, dirty, max, costFn, decompose, f);\n    if (Chunk.isNonEmpty(leftovers)) {\n      return pipe(core.write(leftovers), channel.zipRight(core.succeedNow(nextS)));\n    }\n    if (cost > max) {\n      return core.succeedNow(nextS);\n    }\n    return foldWeightedDecomposeLoop(nextS, nextCost, nextDirty, max, costFn, decompose, f);\n  },\n  onFailure: core.fail,\n  onDone: () => core.succeedNow(s)\n});\n/** @internal */\nconst foldWeightedDecomposeFold = (input, index, s, cost, dirty, max, costFn, decompose, f) => {\n  if (index === input.length) {\n    return [s, cost, dirty, Chunk.empty()];\n  }\n  const elem = pipe(input, Chunk.unsafeGet(index));\n  const total = cost + costFn(s, elem);\n  if (total <= max) {\n    return foldWeightedDecomposeFold(input, index + 1, f(s, elem), total, true, max, costFn, decompose, f);\n  }\n  const decomposed = decompose(elem);\n  if (decomposed.length <= 1 && !dirty) {\n    // If `elem` cannot be decomposed, we need to cross the `max` threshold. To\n    // minimize \"injury\", we only allow this when we haven't added anything else\n    // to the aggregate (dirty = false).\n    return [f(s, elem), total, true, pipe(input, Chunk.drop(index + 1))];\n  }\n  if (decomposed.length <= 1 && dirty) {\n    // If the state is dirty and `elem` cannot be decomposed, we stop folding\n    // and include `elem` in the leftovers.\n    return [s, cost, dirty, pipe(input, Chunk.drop(index))];\n  }\n  // `elem` got decomposed, so we will recurse with the decomposed elements pushed\n  // into the chunk we're processing and see if we can aggregate further.\n  const next = pipe(decomposed, Chunk.appendAll(pipe(input, Chunk.drop(index + 1))));\n  return foldWeightedDecomposeFold(next, 0, s, cost, dirty, max, costFn, decompose, f);\n};\n/** @internal */\nexport const foldWeightedDecomposeEffect = options => suspend(() => new SinkImpl(foldWeightedDecomposeEffectLoop(options.initial, options.maxCost, options.cost, options.decompose, options.body, 0, false)));\n/** @internal */\nexport const foldWeightedEffect = options => foldWeightedDecomposeEffect({\n  ...options,\n  decompose: input => Effect.succeed(Chunk.of(input))\n});\nconst foldWeightedDecomposeEffectLoop = (s, max, costFn, decompose, f, cost, dirty) => core.readWith({\n  onInput: input => pipe(core.fromEffect(foldWeightedDecomposeEffectFold(s, max, costFn, decompose, f, input, dirty, cost, 0)), core.flatMap(([nextS, nextCost, nextDirty, leftovers]) => {\n    if (Chunk.isNonEmpty(leftovers)) {\n      return pipe(core.write(leftovers), channel.zipRight(core.succeedNow(nextS)));\n    }\n    if (cost > max) {\n      return core.succeedNow(nextS);\n    }\n    return foldWeightedDecomposeEffectLoop(nextS, max, costFn, decompose, f, nextCost, nextDirty);\n  })),\n  onFailure: core.fail,\n  onDone: () => core.succeedNow(s)\n});\n/** @internal */\nconst foldWeightedDecomposeEffectFold = (s, max, costFn, decompose, f, input, dirty, cost, index) => {\n  if (index === input.length) {\n    return Effect.succeed([s, cost, dirty, Chunk.empty()]);\n  }\n  const elem = pipe(input, Chunk.unsafeGet(index));\n  return pipe(costFn(s, elem), Effect.map(newCost => cost + newCost), Effect.flatMap(total => {\n    if (total <= max) {\n      return pipe(f(s, elem), Effect.flatMap(s => foldWeightedDecomposeEffectFold(s, max, costFn, decompose, f, input, true, total, index + 1)));\n    }\n    return pipe(decompose(elem), Effect.flatMap(decomposed => {\n      if (decomposed.length <= 1 && !dirty) {\n        // If `elem` cannot be decomposed, we need to cross the `max` threshold. To\n        // minimize \"injury\", we only allow this when we haven't added anything else\n        // to the aggregate (dirty = false).\n        return pipe(f(s, elem), Effect.map(s => [s, total, true, pipe(input, Chunk.drop(index + 1))]));\n      }\n      if (decomposed.length <= 1 && dirty) {\n        // If the state is dirty and `elem` cannot be decomposed, we stop folding\n        // and include `elem` in th leftovers.\n        return Effect.succeed([s, cost, dirty, pipe(input, Chunk.drop(index))]);\n      }\n      // `elem` got decomposed, so we will recurse with the decomposed elements pushed\n      // into the chunk we're processing and see if we can aggregate further.\n      const next = pipe(decomposed, Chunk.appendAll(pipe(input, Chunk.drop(index + 1))));\n      return foldWeightedDecomposeEffectFold(s, max, costFn, decompose, f, next, dirty, cost, 0);\n    }));\n  }));\n};\n/** @internal */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => foldSink(self, {\n  onFailure: fail,\n  onSuccess: f\n}));\n/** @internal */\nexport const forEach = f => {\n  const process = core.readWithCause({\n    onInput: input => pipe(core.fromEffect(Effect.forEach(input, v => f(v), {\n      discard: true\n    })), core.flatMap(() => process)),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new SinkImpl(process);\n};\n/** @internal */\nexport const forEachChunk = f => {\n  const process = core.readWithCause({\n    onInput: input => pipe(core.fromEffect(f(input)), core.flatMap(() => process)),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new SinkImpl(process);\n};\n/** @internal */\nexport const forEachWhile = f => {\n  const process = core.readWithCause({\n    onInput: input => forEachWhileReader(f, input, 0, input.length, process),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new SinkImpl(process);\n};\n/** @internal */\nconst forEachWhileReader = (f, input, index, length, cont) => {\n  if (index === length) {\n    return cont;\n  }\n  return pipe(core.fromEffect(f(pipe(input, Chunk.unsafeGet(index)))), core.flatMap(bool => bool ? forEachWhileReader(f, input, index + 1, length, cont) : core.write(pipe(input, Chunk.drop(index)))), channel.catchAll(error => pipe(core.write(pipe(input, Chunk.drop(index))), channel.zipRight(core.fail(error)))));\n};\n/** @internal */\nexport const forEachChunkWhile = f => {\n  const reader = core.readWith({\n    onInput: input => pipe(core.fromEffect(f(input)), core.flatMap(cont => cont ? reader : core.void)),\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new SinkImpl(reader);\n};\n/** @internal */\nexport const fromChannel = channel => new SinkImpl(channel);\n/** @internal */\nexport const fromEffect = effect => new SinkImpl(core.fromEffect(effect));\n/** @internal */\nexport const fromPubSub = (pubsub, options) => fromQueue(pubsub, options);\n/** @internal */\nexport const fromPush = push => new SinkImpl(channel.unwrapScoped(pipe(push, Effect.map(fromPushPull))));\nconst fromPushPull = push => core.readWith({\n  onInput: input => channel.foldChannel(core.fromEffect(push(Option.some(input))), {\n    onFailure: ([either, leftovers]) => Either.match(either, {\n      onLeft: error => pipe(core.write(leftovers), channel.zipRight(core.fail(error))),\n      onRight: z => pipe(core.write(leftovers), channel.zipRight(core.succeedNow(z)))\n    }),\n    onSuccess: () => fromPushPull(push)\n  }),\n  onFailure: core.fail,\n  onDone: () => channel.foldChannel(core.fromEffect(push(Option.none())), {\n    onFailure: ([either, leftovers]) => Either.match(either, {\n      onLeft: error => pipe(core.write(leftovers), channel.zipRight(core.fail(error))),\n      onRight: z => pipe(core.write(leftovers), channel.zipRight(core.succeedNow(z)))\n    }),\n    onSuccess: () => core.fromEffect(Effect.dieMessage(\"BUG: Sink.fromPush - please report an issue at https://github.com/Effect-TS/effect/issues\"))\n  })\n});\n/** @internal */\nexport const fromQueue = (queue, options) => options?.shutdown ? unwrapScoped(Effect.map(Effect.acquireRelease(Effect.succeed(queue), Queue.shutdown), fromQueue)) : forEachChunk(input => pipe(Queue.offerAll(queue, input)));\n/** @internal */\nexport const head = () => fold(Option.none(), Option.isNone, (option, input) => Option.match(option, {\n  onNone: () => Option.some(input),\n  onSome: () => option\n}));\n/** @internal */\nexport const ignoreLeftover = self => new SinkImpl(channel.drain(toChannel(self)));\n/** @internal */\nexport const last = () => foldLeftChunks(Option.none(), (s, input) => Option.orElse(Chunk.last(input), () => s));\n/** @internal */\nexport const leftover = chunk => new SinkImpl(core.suspend(() => core.write(chunk)));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => {\n  return new SinkImpl(pipe(toChannel(self), channel.map(f)));\n});\n/** @internal */\nexport const mapEffect = /*#__PURE__*/dual(2, (self, f) => new SinkImpl(pipe(toChannel(self), channel.mapEffect(f))));\n/** @internal */\nexport const mapError = /*#__PURE__*/dual(2, (self, f) => new SinkImpl(pipe(toChannel(self), channel.mapError(f))));\n/** @internal */\nexport const mapLeftover = /*#__PURE__*/dual(2, (self, f) => new SinkImpl(pipe(toChannel(self), channel.mapOut(Chunk.map(f)))));\n/** @internal */\nexport const never = /*#__PURE__*/fromEffect(Effect.never);\n/** @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => new SinkImpl(pipe(toChannel(self), channel.orElse(() => toChannel(that())))));\n/** @internal */\nexport const provideContext = /*#__PURE__*/dual(2, (self, context) => new SinkImpl(pipe(toChannel(self), core.provideContext(context))));\n/** @internal */\nexport const race = /*#__PURE__*/dual(2, (self, that) => pipe(self, raceBoth(that), map(Either.merge)));\n/** @internal */\nexport const raceBoth = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, options) => raceWith(self, {\n  other: that,\n  onSelfDone: selfDone => mergeDecision.Done(Effect.map(selfDone, Either.left)),\n  onOtherDone: thatDone => mergeDecision.Done(Effect.map(thatDone, Either.right)),\n  capacity: options?.capacity ?? 16\n}));\n/** @internal */\nexport const raceWith = /*#__PURE__*/dual(2, (self, options) => {\n  const scoped = Effect.gen(function* ($) {\n    const pubsub = yield* $(PubSub.bounded(options?.capacity ?? 16));\n    const channel1 = yield* $(channel.fromPubSubScoped(pubsub));\n    const channel2 = yield* $(channel.fromPubSubScoped(pubsub));\n    const reader = channel.toPubSub(pubsub);\n    const writer = pipe(channel1, core.pipeTo(toChannel(self)), channel.mergeWith({\n      other: pipe(channel2, core.pipeTo(toChannel(options.other))),\n      onSelfDone: options.onSelfDone,\n      onOtherDone: options.onOtherDone\n    }));\n    const racedChannel = channel.mergeWith(reader, {\n      other: writer,\n      onSelfDone: _ => mergeDecision.Await(exit => Effect.suspend(() => exit)),\n      onOtherDone: done => mergeDecision.Done(Effect.suspend(() => done))\n    });\n    return new SinkImpl(racedChannel);\n  });\n  return unwrapScoped(scoped);\n});\n/** @internal */\nexport const refineOrDie = /*#__PURE__*/dual(2, (self, pf) => pipe(self, refineOrDieWith(pf, identity)));\n/** @internal */\nexport const refineOrDieWith = /*#__PURE__*/dual(3, (self, pf, f) => {\n  const newChannel = pipe(self, toChannel, channel.catchAll(error => Option.match(pf(error), {\n    onNone: () => core.failCauseSync(() => Cause.die(f(error))),\n    onSome: core.fail\n  })));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nexport const service = tag => serviceWith(tag, identity);\n/** @internal */\nexport const serviceWith = (tag, f) => fromEffect(Effect.map(tag, f));\n/** @internal */\nexport const serviceWithEffect = (tag, f) => fromEffect(Effect.flatMap(tag, f));\n/** @internal */\nexport const serviceWithSink = (tag, f) => new SinkImpl(pipe(Effect.map(tag, service => toChannel(f(service))), channel.unwrap));\n/** @internal */\nexport const some = predicate => fold(false, bool => !bool, (acc, input) => acc || predicate(input));\n/** @internal */\nexport const splitWhere = /*#__PURE__*/dual(2, (self, f) => {\n  const newChannel = pipe(core.fromEffect(Ref.make(Chunk.empty())), core.flatMap(ref => pipe(splitWhereSplitter(false, ref, f), channel.pipeToOrFail(toChannel(self)), core.collectElements, core.flatMap(([leftovers, z]) => pipe(core.fromEffect(Ref.get(ref)), core.flatMap(leftover => pipe(core.write(pipe(leftover, Chunk.appendAll(Chunk.flatten(leftovers)))), channel.zipRight(core.succeed(z)))))))));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nconst splitWhereSplitter = (written, leftovers, f) => core.readWithCause({\n  onInput: input => {\n    if (Chunk.isEmpty(input)) {\n      return splitWhereSplitter(written, leftovers, f);\n    }\n    if (written) {\n      const index = indexWhere(input, f);\n      if (index === -1) {\n        return channel.zipRight(core.write(input), splitWhereSplitter(true, leftovers, f));\n      }\n      const [left, right] = Chunk.splitAt(input, index);\n      return channel.zipRight(core.write(left), core.fromEffect(Ref.set(leftovers, right)));\n    }\n    const index = indexWhere(input, f, 1);\n    if (index === -1) {\n      return channel.zipRight(core.write(input), splitWhereSplitter(true, leftovers, f));\n    }\n    const [left, right] = pipe(input, Chunk.splitAt(Math.max(index, 1)));\n    return channel.zipRight(core.write(left), core.fromEffect(Ref.set(leftovers, right)));\n  },\n  onFailure: core.failCause,\n  onDone: core.succeed\n});\n/** @internal */\nconst indexWhere = (self, predicate, from = 0) => {\n  const iterator = self[Symbol.iterator]();\n  let index = 0;\n  let result = -1;\n  let next;\n  while (result < 0 && (next = iterator.next()) && !next.done) {\n    const a = next.value;\n    if (index >= from && predicate(a)) {\n      result = index;\n    }\n    index = index + 1;\n  }\n  return result;\n};\n/** @internal */\nexport const succeed = a => new SinkImpl(core.succeed(a));\n/** @internal */\nexport const sum = /*#__PURE__*/foldLeftChunks(0, (acc, chunk) => acc + Chunk.reduce(chunk, 0, (s, a) => s + a));\n/** @internal */\nexport const summarized = /*#__PURE__*/dual(3, (self, summary, f) => {\n  const newChannel = pipe(core.fromEffect(summary), core.flatMap(start => pipe(self, toChannel, core.flatMap(done => pipe(core.fromEffect(summary), channel.map(end => [done, f(start, end)]))))));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nexport const sync = evaluate => new SinkImpl(core.sync(evaluate));\n/** @internal */\nexport const take = n => pipe(foldChunks(Chunk.empty(), chunk => chunk.length < n, (acc, chunk) => pipe(acc, Chunk.appendAll(chunk))), flatMap(acc => {\n  const [taken, leftover] = pipe(acc, Chunk.splitAt(n));\n  return new SinkImpl(pipe(core.write(leftover), channel.zipRight(core.succeedNow(taken))));\n}));\n/** @internal */\nexport const toChannel = self => Effect.isEffect(self) ? toChannel(fromEffect(self)) : self.channel;\n/** @internal */\nexport const unwrap = effect => new SinkImpl(channel.unwrap(pipe(effect, Effect.map(sink => toChannel(sink)))));\n/** @internal */\nexport const unwrapScoped = effect => {\n  return new SinkImpl(channel.unwrapScoped(pipe(effect, Effect.map(sink => toChannel(sink)))));\n};\n/** @internal */\nexport const withDuration = self => pipe(self, summarized(Clock.currentTimeMillis, (start, end) => Duration.millis(end - start)));\n/** @internal */\nexport const zip = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, options) => zipWith(self, that, (z, z2) => [z, z2], options));\n/** @internal */\nexport const zipLeft = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, options) => zipWith(self, that, (z, _) => z, options));\n/** @internal */\nexport const zipRight = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, options) => zipWith(self, that, (_, z2) => z2, options));\n/** @internal */\nexport const zipWith = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, f, options) => options?.concurrent ? raceWith(self, {\n  other: that,\n  onSelfDone: Exit.match({\n    onFailure: cause => mergeDecision.Done(Effect.failCause(cause)),\n    onSuccess: leftZ => mergeDecision.Await(Exit.match({\n      onFailure: Effect.failCause,\n      onSuccess: rightZ => Effect.succeed(f(leftZ, rightZ))\n    }))\n  }),\n  onOtherDone: Exit.match({\n    onFailure: cause => mergeDecision.Done(Effect.failCause(cause)),\n    onSuccess: rightZ => mergeDecision.Await(Exit.match({\n      onFailure: Effect.failCause,\n      onSuccess: leftZ => Effect.succeed(f(leftZ, rightZ))\n    }))\n  })\n}) : flatMap(self, z => map(that, z2 => f(z, z2))));\n// Circular with Channel\n/** @internal */\nexport const channelToSink = self => new SinkImpl(self);\n// Constants\n/** @internal */\nexport const count = /*#__PURE__*/foldLeftChunks(0, (acc, chunk) => acc + chunk.length);\n/** @internal */\nexport const mkString = /*#__PURE__*/suspend(() => {\n  const strings = [];\n  return pipe(foldLeftChunks(void 0, (_, elems) => Chunk.map(elems, elem => {\n    strings.push(String(elem));\n  })), map(() => strings.join(\"\")));\n});\n/** @internal */\nexport const timed = /*#__PURE__*/pipe( /*#__PURE__*/withDuration(drain), /*#__PURE__*/map(tuple => tuple[1]));\n//# sourceMappingURL=sink.js.map","export const make = (value, previous) => ({\n  value,\n  previous\n});\n//# sourceMappingURL=stack.js.map","import * as Cause from \"../Cause.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Clock from \"../Clock.js\";\nimport * as Context from \"../Context.js\";\nimport * as Deferred from \"../Deferred.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as Effect from \"../Effect.js\";\nimport * as Either from \"../Either.js\";\nimport * as Equal from \"../Equal.js\";\nimport * as Exit from \"../Exit.js\";\nimport * as Fiber from \"../Fiber.js\";\nimport { constTrue, dual, identity, pipe } from \"../Function.js\";\nimport * as Layer from \"../Layer.js\";\nimport * as MergeDecision from \"../MergeDecision.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty, isTagged } from \"../Predicate.js\";\nimport * as PubSub from \"../PubSub.js\";\nimport * as Queue from \"../Queue.js\";\nimport * as Ref from \"../Ref.js\";\nimport * as Runtime from \"../Runtime.js\";\nimport * as Schedule from \"../Schedule.js\";\nimport * as Scope from \"../Scope.js\";\nimport * as HaltStrategy from \"../StreamHaltStrategy.js\";\nimport * as Tuple from \"../Tuple.js\";\nimport * as channel from \"./channel.js\";\nimport * as channelExecutor from \"./channel/channelExecutor.js\";\nimport * as MergeStrategy from \"./channel/mergeStrategy.js\";\nimport * as singleProducerAsyncInput from \"./channel/singleProducerAsyncInput.js\";\nimport * as core from \"./core-stream.js\";\nimport * as doNotation from \"./doNotation.js\";\nimport { RingBuffer } from \"./ringBuffer.js\";\nimport * as _sink from \"./sink.js\";\nimport * as DebounceState from \"./stream/debounceState.js\";\nimport * as emit from \"./stream/emit.js\";\nimport * as haltStrategy from \"./stream/haltStrategy.js\";\nimport * as Handoff from \"./stream/handoff.js\";\nimport * as HandoffSignal from \"./stream/handoffSignal.js\";\nimport * as pull from \"./stream/pull.js\";\nimport * as SinkEndReason from \"./stream/sinkEndReason.js\";\nimport * as ZipAllState from \"./stream/zipAllState.js\";\nimport * as ZipChunksState from \"./stream/zipChunksState.js\";\nimport * as InternalTake from \"./take.js\";\nimport * as InternalTracer from \"./tracer.js\";\n/** @internal */\nconst StreamSymbolKey = \"effect/Stream\";\n/** @internal */\nexport const StreamTypeId = /*#__PURE__*/Symbol.for(StreamSymbolKey);\n/** @internal */\nconst streamVariance = {\n  _R: _ => _,\n  _E: _ => _,\n  _A: _ => _\n};\n/** @internal */\nexport class StreamImpl {\n  channel;\n  [StreamTypeId] = streamVariance;\n  constructor(channel) {\n    this.channel = channel;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const isStream = u => hasProperty(u, StreamTypeId) || Effect.isEffect(u);\n/** @internal */\nexport const DefaultChunkSize = 4096;\n/** @internal */\nexport const accumulate = self => chunks(accumulateChunks(self));\n/** @internal */\nexport const accumulateChunks = self => {\n  const accumulator = s => core.readWith({\n    onInput: input => {\n      const next = Chunk.appendAll(s, input);\n      return core.flatMap(core.write(next), () => accumulator(next));\n    },\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new StreamImpl(core.pipeTo(toChannel(self), accumulator(Chunk.empty())));\n};\n/** @internal */\nexport const acquireRelease = (acquire, release) => scoped(Effect.acquireRelease(acquire, release));\n/** @internal */\nexport const aggregate = /*#__PURE__*/dual(2, (self, sink) => aggregateWithin(self, sink, Schedule.forever));\n/** @internal */\nexport const aggregateWithin = /*#__PURE__*/dual(3, (self, sink, schedule) => filterMap(aggregateWithinEither(self, sink, schedule), _ => Either.match(_, {\n  onLeft: Option.none,\n  onRight: Option.some\n})));\n/** @internal */\nexport const aggregateWithinEither = /*#__PURE__*/dual(3, (self, sink, schedule) => {\n  const layer = Effect.all([Handoff.make(), Ref.make(SinkEndReason.ScheduleEnd), Ref.make(Chunk.empty()), Schedule.driver(schedule), Ref.make(false), Ref.make(false)]);\n  return pipe(fromEffect(layer), flatMap(([handoff, sinkEndReason, sinkLeftovers, scheduleDriver, consumed, endAfterEmit]) => {\n    const handoffProducer = core.readWithCause({\n      onInput: input => core.flatMap(core.fromEffect(pipe(handoff, Handoff.offer(HandoffSignal.emit(input)), Effect.when(() => Chunk.isNonEmpty(input)))), () => handoffProducer),\n      onFailure: cause => core.fromEffect(Handoff.offer(handoff, HandoffSignal.halt(cause))),\n      onDone: () => core.fromEffect(Handoff.offer(handoff, HandoffSignal.end(SinkEndReason.UpstreamEnd)))\n    });\n    const handoffConsumer = pipe(Ref.getAndSet(sinkLeftovers, Chunk.empty()), Effect.flatMap(leftovers => {\n      if (Chunk.isNonEmpty(leftovers)) {\n        return pipe(Ref.set(consumed, true), Effect.zipRight(Effect.succeed(pipe(core.write(leftovers), core.flatMap(() => handoffConsumer)))));\n      }\n      return pipe(Handoff.take(handoff), Effect.map(signal => {\n        switch (signal._tag) {\n          case HandoffSignal.OP_EMIT:\n            {\n              return pipe(core.fromEffect(Ref.set(consumed, true)), channel.zipRight(core.write(signal.elements)), channel.zipRight(core.fromEffect(Ref.get(endAfterEmit))), core.flatMap(bool => bool ? core.void : handoffConsumer));\n            }\n          case HandoffSignal.OP_HALT:\n            {\n              return core.failCause(signal.cause);\n            }\n          case HandoffSignal.OP_END:\n            {\n              if (signal.reason._tag === SinkEndReason.OP_SCHEDULE_END) {\n                return pipe(Ref.get(consumed), Effect.map(bool => bool ? core.fromEffect(pipe(Ref.set(sinkEndReason, SinkEndReason.ScheduleEnd), Effect.zipRight(Ref.set(endAfterEmit, true)))) : pipe(core.fromEffect(pipe(Ref.set(sinkEndReason, SinkEndReason.ScheduleEnd), Effect.zipRight(Ref.set(endAfterEmit, true)))), core.flatMap(() => handoffConsumer))), channel.unwrap);\n              }\n              return pipe(Ref.set(sinkEndReason, signal.reason), Effect.zipRight(Ref.set(endAfterEmit, true)), core.fromEffect);\n            }\n        }\n      }));\n    }), channel.unwrap);\n    const timeout = lastB => scheduleDriver.next(lastB);\n    const scheduledAggregator = (sinkFiber, scheduleFiber, scope) => {\n      const forkSink = pipe(Ref.set(consumed, false), Effect.zipRight(Ref.set(endAfterEmit, false)), Effect.zipRight(pipe(handoffConsumer, channel.pipeToOrFail(_sink.toChannel(sink)), core.collectElements, channelExecutor.run, Effect.forkIn(scope))));\n      const handleSide = (leftovers, b, c) => pipe(Ref.set(sinkLeftovers, Chunk.flatten(leftovers)), Effect.zipRight(Effect.map(Ref.get(sinkEndReason), reason => {\n        switch (reason._tag) {\n          case SinkEndReason.OP_SCHEDULE_END:\n            {\n              return pipe(Effect.all([Ref.get(consumed), forkSink, pipe(timeout(Option.some(b)), Effect.forkIn(scope))]), Effect.map(([wasConsumed, sinkFiber, scheduleFiber]) => {\n                const toWrite = pipe(c, Option.match({\n                  onNone: () => Chunk.of(Either.right(b)),\n                  onSome: c => Chunk.make(Either.right(b), Either.left(c))\n                }));\n                if (wasConsumed) {\n                  return pipe(core.write(toWrite), core.flatMap(() => scheduledAggregator(sinkFiber, scheduleFiber, scope)));\n                }\n                return scheduledAggregator(sinkFiber, scheduleFiber, scope);\n              }), channel.unwrap);\n            }\n          case SinkEndReason.OP_UPSTREAM_END:\n            {\n              return pipe(Ref.get(consumed), Effect.map(wasConsumed => wasConsumed ? core.write(Chunk.of(Either.right(b))) : core.void), channel.unwrap);\n            }\n        }\n      })), channel.unwrap);\n      return channel.unwrap(Effect.raceWith(Fiber.join(sinkFiber), Fiber.join(scheduleFiber), {\n        onSelfDone: (sinkExit, _) => pipe(Fiber.interrupt(scheduleFiber), Effect.zipRight(pipe(Effect.suspend(() => sinkExit), Effect.map(([leftovers, b]) => handleSide(leftovers, b, Option.none()))))),\n        onOtherDone: (scheduleExit, _) => Effect.matchCauseEffect(Effect.suspend(() => scheduleExit), {\n          onFailure: cause => Either.match(Cause.failureOrCause(cause), {\n            onLeft: () => pipe(handoff, Handoff.offer(HandoffSignal.end(SinkEndReason.ScheduleEnd)), Effect.forkDaemon, Effect.zipRight(pipe(Fiber.join(sinkFiber), Effect.map(([leftovers, b]) => handleSide(leftovers, b, Option.none()))))),\n            onRight: cause => pipe(handoff, Handoff.offer(HandoffSignal.halt(cause)), Effect.forkDaemon, Effect.zipRight(pipe(Fiber.join(sinkFiber), Effect.map(([leftovers, b]) => handleSide(leftovers, b, Option.none())))))\n          }),\n          onSuccess: c => pipe(handoff, Handoff.offer(HandoffSignal.end(SinkEndReason.ScheduleEnd)), Effect.forkDaemon, Effect.zipRight(pipe(Fiber.join(sinkFiber), Effect.map(([leftovers, b]) => handleSide(leftovers, b, Option.some(c))))))\n        })\n      }));\n    };\n    return unwrapScoped(pipe(self, toChannel, core.pipeTo(handoffProducer), channelExecutor.run, Effect.forkScoped, Effect.zipRight(pipe(handoffConsumer, channel.pipeToOrFail(_sink.toChannel(sink)), core.collectElements, channelExecutor.run, Effect.forkScoped, Effect.flatMap(sinkFiber => pipe(Effect.forkScoped(timeout(Option.none())), Effect.flatMap(scheduleFiber => pipe(Effect.scope, Effect.map(scope => new StreamImpl(scheduledAggregator(sinkFiber, scheduleFiber, scope)))))))))));\n  }));\n});\n/** @internal */\nexport const as = /*#__PURE__*/dual(2, (self, value) => map(self, () => value));\nconst queueFromBufferOptions = bufferSize => {\n  if (bufferSize === \"unbounded\") {\n    return Queue.unbounded();\n  } else if (typeof bufferSize === \"number\" || bufferSize === undefined) {\n    return Queue.bounded(bufferSize ?? 16);\n  }\n  switch (bufferSize.strategy) {\n    case \"dropping\":\n      return Queue.dropping(bufferSize.bufferSize ?? 16);\n    case \"sliding\":\n      return Queue.sliding(bufferSize.bufferSize ?? 16);\n    default:\n      return Queue.bounded(bufferSize.bufferSize ?? 16);\n  }\n};\n/** @internal */\nexport const _async = (register, bufferSize) => Effect.acquireRelease(queueFromBufferOptions(bufferSize), queue => Queue.shutdown(queue)).pipe(Effect.flatMap(output => Effect.runtime().pipe(Effect.flatMap(runtime => Effect.sync(() => {\n  const runPromiseExit = Runtime.runPromiseExit(runtime);\n  const canceler = register(emit.make(resume => InternalTake.fromPull(resume).pipe(Effect.flatMap(take => Queue.offer(output, take)), Effect.asVoid, runPromiseExit).then(exit => {\n    if (Exit.isFailure(exit)) {\n      if (!Cause.isInterrupted(exit.cause)) {\n        throw Cause.squash(exit.cause);\n      }\n    }\n  })));\n  return canceler;\n})), Effect.map(value => {\n  const loop = Queue.take(output).pipe(Effect.flatMap(take => InternalTake.done(take)), Effect.match({\n    onFailure: maybeError => core.fromEffect(Queue.shutdown(output)).pipe(channel.zipRight(Option.match(maybeError, {\n      onNone: () => core.void,\n      onSome: error => core.fail(error)\n    }))),\n    onSuccess: chunk => core.write(chunk).pipe(core.flatMap(() => loop))\n  }), channel.unwrap);\n  return fromChannel(loop).pipe(ensuring(value ?? Effect.void));\n}))), unwrapScoped);\n/** @internal */\nexport const asyncEffect = (register, bufferSize) => pipe(Effect.acquireRelease(queueFromBufferOptions(bufferSize), queue => Queue.shutdown(queue)), Effect.flatMap(output => pipe(Effect.runtime(), Effect.flatMap(runtime => pipe(register(emit.make(k => pipe(InternalTake.fromPull(k), Effect.flatMap(take => Queue.offer(output, take)), Effect.asVoid, Runtime.runPromiseExit(runtime)).then(exit => {\n  if (Exit.isFailure(exit)) {\n    if (!Cause.isInterrupted(exit.cause)) {\n      throw Cause.squash(exit.cause);\n    }\n  }\n}))), Effect.map(() => {\n  const loop = pipe(Queue.take(output), Effect.flatMap(InternalTake.done), Effect.match({\n    onFailure: maybeError => pipe(core.fromEffect(Queue.shutdown(output)), channel.zipRight(Option.match(maybeError, {\n      onNone: () => core.void,\n      onSome: core.fail\n    }))),\n    onSuccess: chunk => pipe(core.write(chunk), core.flatMap(() => loop))\n  }), channel.unwrap);\n  return loop;\n}))))), channel.unwrapScoped, fromChannel);\n/** @internal */\nexport const asyncScoped = (register, bufferSize) => pipe(Effect.acquireRelease(queueFromBufferOptions(bufferSize), queue => Queue.shutdown(queue)), Effect.flatMap(output => pipe(Effect.runtime(), Effect.flatMap(runtime => pipe(register(emit.make(k => pipe(InternalTake.fromPull(k), Effect.flatMap(take => Queue.offer(output, take)), Effect.asVoid, Runtime.runPromiseExit(runtime)).then(exit => {\n  if (Exit.isFailure(exit)) {\n    if (!Cause.isInterrupted(exit.cause)) {\n      throw Cause.squash(exit.cause);\n    }\n  }\n}))), Effect.zipRight(Ref.make(false)), Effect.flatMap(ref => pipe(Ref.get(ref), Effect.map(isDone => isDone ? pull.end() : pipe(Queue.take(output), Effect.flatMap(InternalTake.done), Effect.onError(() => pipe(Ref.set(ref, true), Effect.zipRight(Queue.shutdown(output)))))))))))), scoped, flatMap(repeatEffectChunkOption));\n/** @internal */\nexport const branchAfter = /*#__PURE__*/dual(3, (self, n, f) => suspend(() => {\n  const buffering = acc => core.readWith({\n    onInput: input => {\n      const nextSize = acc.length + input.length;\n      if (nextSize >= n) {\n        const [b1, b2] = pipe(input, Chunk.splitAt(n - acc.length));\n        return running(pipe(acc, Chunk.appendAll(b1)), b2);\n      }\n      return buffering(pipe(acc, Chunk.appendAll(input)));\n    },\n    onFailure: core.fail,\n    onDone: () => running(acc, Chunk.empty())\n  });\n  const running = (prefix, leftover) => core.pipeTo(channel.zipRight(core.write(leftover), channel.identityChannel()), toChannel(f(prefix)));\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(buffering(Chunk.empty()))));\n}));\n/** @internal */\nexport const broadcast = /*#__PURE__*/dual(3, (self, n, maximumLag) => pipe(self, broadcastedQueues(n, maximumLag), Effect.map(tuple => tuple.map(queue => flattenTake(fromQueue(queue, {\n  shutdown: true\n}))))));\n/** @internal */\nexport const broadcastDynamic = /*#__PURE__*/dual(2, (self, maximumLag) => Effect.map(toPubSub(self, maximumLag), pubsub => flattenTake(fromPubSub(pubsub))));\n/** @internal */\nexport const broadcastedQueues = /*#__PURE__*/dual(3, (self, n, maximumLag) => Effect.flatMap(pubsubFromOptions(maximumLag), pubsub => pipe(Effect.all(Array.from({\n  length: n\n}, () => PubSub.subscribe(pubsub))), Effect.tap(() => Effect.forkScoped(runIntoPubSubScoped(self, pubsub))))));\n/** @internal */\nexport const broadcastedQueuesDynamic = /*#__PURE__*/dual(2, (self, maximumLag) => Effect.map(toPubSub(self, maximumLag), PubSub.subscribe));\n/** @internal */\nexport const buffer = /*#__PURE__*/dual(2, (self, options) => {\n  if (options.capacity === \"unbounded\") {\n    return bufferUnbounded(self);\n  } else if (options.strategy === \"dropping\") {\n    return bufferDropping(self, options.capacity);\n  } else if (options.strategy === \"sliding\") {\n    return bufferSliding(self, options.capacity);\n  }\n  const queue = toQueueOfElements(self, options);\n  return new StreamImpl(channel.unwrapScoped(Effect.map(queue, queue => {\n    const process = pipe(core.fromEffect(Queue.take(queue)), core.flatMap(Exit.match({\n      onFailure: cause => pipe(Cause.flipCauseOption(cause), Option.match({\n        onNone: () => core.void,\n        onSome: core.failCause\n      })),\n      onSuccess: value => core.flatMap(core.write(Chunk.of(value)), () => process)\n    })));\n    return process;\n  })));\n});\n/** @internal */\nexport const bufferChunks = /*#__PURE__*/dual(2, (self, options) => {\n  if (options.strategy === \"dropping\") {\n    return bufferChunksDropping(self, options.capacity);\n  } else if (options.strategy === \"sliding\") {\n    return bufferChunksSliding(self, options.capacity);\n  }\n  const queue = toQueue(self, options);\n  return new StreamImpl(channel.unwrapScoped(Effect.map(queue, queue => {\n    const process = pipe(core.fromEffect(Queue.take(queue)), core.flatMap(InternalTake.match({\n      onEnd: () => core.void,\n      onFailure: core.failCause,\n      onSuccess: value => pipe(core.write(value), core.flatMap(() => process))\n    })));\n    return process;\n  })));\n});\nconst bufferChunksDropping = /*#__PURE__*/dual(2, (self, capacity) => {\n  const queue = Effect.acquireRelease(Queue.dropping(capacity), queue => Queue.shutdown(queue));\n  return new StreamImpl(bufferSignal(queue, toChannel(self)));\n});\nconst bufferChunksSliding = /*#__PURE__*/dual(2, (self, capacity) => {\n  const queue = Effect.acquireRelease(Queue.sliding(capacity), queue => Queue.shutdown(queue));\n  return new StreamImpl(bufferSignal(queue, toChannel(self)));\n});\nconst bufferDropping = /*#__PURE__*/dual(2, (self, capacity) => {\n  const queue = Effect.acquireRelease(Queue.dropping(capacity), queue => Queue.shutdown(queue));\n  return new StreamImpl(bufferSignal(queue, toChannel(rechunk(1)(self))));\n});\nconst bufferSliding = /*#__PURE__*/dual(2, (self, capacity) => {\n  const queue = Effect.acquireRelease(Queue.sliding(capacity), queue => Queue.shutdown(queue));\n  return new StreamImpl(bufferSignal(queue, toChannel(pipe(self, rechunk(1)))));\n});\nconst bufferUnbounded = self => {\n  const queue = toQueue(self, {\n    strategy: \"unbounded\"\n  });\n  return new StreamImpl(channel.unwrapScoped(Effect.map(queue, queue => {\n    const process = pipe(core.fromEffect(Queue.take(queue)), core.flatMap(InternalTake.match({\n      onEnd: () => core.void,\n      onFailure: core.failCause,\n      onSuccess: value => core.flatMap(core.write(value), () => process)\n    })));\n    return process;\n  })));\n};\nconst bufferSignal = (scoped, bufferChannel) => {\n  const producer = (queue, ref) => {\n    const terminate = take => pipe(Ref.get(ref), Effect.tap(Deferred.await), Effect.zipRight(Deferred.make()), Effect.flatMap(deferred => pipe(Queue.offer(queue, [take, deferred]), Effect.zipRight(Ref.set(ref, deferred)), Effect.zipRight(Deferred.await(deferred)))), Effect.asVoid, core.fromEffect);\n    return core.readWithCause({\n      onInput: input => pipe(Deferred.make(), Effect.flatMap(deferred => pipe(Queue.offer(queue, [InternalTake.chunk(input), deferred]), Effect.flatMap(added => pipe(Ref.set(ref, deferred), Effect.when(() => added))))), Effect.asVoid, core.fromEffect, core.flatMap(() => producer(queue, ref))),\n      onFailure: error => terminate(InternalTake.failCause(error)),\n      onDone: () => terminate(InternalTake.end)\n    });\n  };\n  const consumer = queue => {\n    const process = pipe(core.fromEffect(Queue.take(queue)), core.flatMap(([take, deferred]) => channel.zipRight(core.fromEffect(Deferred.succeed(deferred, void 0)), InternalTake.match(take, {\n      onEnd: () => core.void,\n      onFailure: core.failCause,\n      onSuccess: value => pipe(core.write(value), core.flatMap(() => process))\n    }))));\n    return process;\n  };\n  return channel.unwrapScoped(pipe(scoped, Effect.flatMap(queue => pipe(Deferred.make(), Effect.tap(start => Deferred.succeed(start, void 0)), Effect.flatMap(start => pipe(Ref.make(start), Effect.flatMap(ref => pipe(bufferChannel, core.pipeTo(producer(queue, ref)), channelExecutor.runScoped, Effect.forkScoped)), Effect.as(consumer(queue))))))));\n};\n/** @internal */\nexport const catchAll = /*#__PURE__*/dual(2, (self, f) => catchAllCause(self, cause => Either.match(Cause.failureOrCause(cause), {\n  onLeft: f,\n  onRight: failCause\n})));\n/** @internal */\nexport const catchAllCause = /*#__PURE__*/dual(2, (self, f) => new StreamImpl(pipe(toChannel(self), core.catchAllCause(cause => toChannel(f(cause))))));\n/** @internal */\nexport const catchSome = /*#__PURE__*/dual(2, (self, pf) => pipe(self, catchAll(error => pipe(pf(error), Option.getOrElse(() => fail(error))))));\n/** @internal */\nexport const catchSomeCause = /*#__PURE__*/dual(2, (self, pf) => pipe(self, catchAllCause(cause => pipe(pf(cause), Option.getOrElse(() => failCause(cause))))));\n/* @internal */\nexport const catchTag = /*#__PURE__*/dual(3, (self, k, f) => catchAll(self, e => {\n  if (\"_tag\" in e && e[\"_tag\"] === k) {\n    return f(e);\n  }\n  return fail(e);\n}));\n/** @internal */\nexport const catchTags = /*#__PURE__*/dual(2, (self, cases) => catchAll(self, e => {\n  const keys = Object.keys(cases);\n  if (\"_tag\" in e && keys.includes(e[\"_tag\"])) {\n    return cases[e[\"_tag\"]](e);\n  }\n  return fail(e);\n}));\n/** @internal */\nexport const changes = self => pipe(self, changesWith((x, y) => Equal.equals(y)(x)));\n/** @internal */\nexport const changesWith = /*#__PURE__*/dual(2, (self, f) => {\n  const writer = last => core.readWithCause({\n    onInput: input => {\n      const [newLast, newChunk] = Chunk.reduce(input, [last, Chunk.empty()], ([option, outputs], output) => {\n        if (Option.isSome(option) && f(option.value, output)) {\n          return [Option.some(output), outputs];\n        }\n        return [Option.some(output), pipe(outputs, Chunk.append(output))];\n      });\n      return core.flatMap(core.write(newChunk), () => writer(newLast));\n    },\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(writer(Option.none()))));\n});\n/** @internal */\nexport const changesWithEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const writer = last => core.readWithCause({\n    onInput: input => pipe(input, Effect.reduce([last, Chunk.empty()], ([option, outputs], output) => {\n      if (Option.isSome(option)) {\n        return pipe(f(option.value, output), Effect.map(bool => bool ? [Option.some(output), outputs] : [Option.some(output), pipe(outputs, Chunk.append(output))]));\n      }\n      return Effect.succeed([Option.some(output), pipe(outputs, Chunk.append(output))]);\n    }), core.fromEffect, core.flatMap(([newLast, newChunk]) => pipe(core.write(newChunk), core.flatMap(() => writer(newLast))))),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(writer(Option.none()))));\n});\n/** @internal */\nexport const chunks = self => pipe(self, mapChunks(Chunk.of));\n/** @internal */\nexport const chunksWith = /*#__PURE__*/dual(2, (self, f) => flattenChunks(f(chunks(self))));\nconst unsome = effect => Effect.catchAll(Effect.asSome(effect), o => o._tag === \"None\" ? Effect.succeedNone : Effect.fail(o.value));\n/** @internal */\nexport const combine = /*#__PURE__*/dual(4, (self, that, s, f) => {\n  const producer = (handoff, latch) => pipe(core.fromEffect(Handoff.take(latch)), channel.zipRight(core.readWithCause({\n    onInput: input => core.flatMap(core.fromEffect(pipe(handoff, Handoff.offer(Exit.succeed(input)))), () => producer(handoff, latch)),\n    onFailure: cause => core.fromEffect(Handoff.offer(handoff, Exit.failCause(pipe(cause, Cause.map(Option.some))))),\n    onDone: () => core.flatMap(core.fromEffect(Handoff.offer(handoff, Exit.fail(Option.none()))), () => producer(handoff, latch))\n  })));\n  return new StreamImpl(channel.unwrapScoped(Effect.gen(function* ($) {\n    const left = yield* $(Handoff.make());\n    const right = yield* $(Handoff.make());\n    const latchL = yield* $(Handoff.make());\n    const latchR = yield* $(Handoff.make());\n    yield* $(toChannel(self), channel.concatMap(channel.writeChunk), core.pipeTo(producer(left, latchL)), channelExecutor.runScoped, Effect.forkScoped);\n    yield* $(toChannel(that), channel.concatMap(channel.writeChunk), core.pipeTo(producer(right, latchR)), channelExecutor.runScoped, Effect.forkScoped);\n    const pullLeft = pipe(latchL, Handoff.offer(void 0),\n    // TODO: remove\n    Effect.zipRight(pipe(Handoff.take(left), Effect.flatMap(exit => Effect.suspend(() => exit)))));\n    const pullRight = pipe(latchR, Handoff.offer(void 0),\n    // TODO: remove\n    Effect.zipRight(pipe(Handoff.take(right), Effect.flatMap(exit => Effect.suspend(() => exit)))));\n    return toChannel(unfoldEffect(s, s => Effect.flatMap(f(s, pullLeft, pullRight), unsome)));\n  })));\n});\n/** @internal */\nexport const combineChunks = /*#__PURE__*/dual(4, (self, that, s, f) => {\n  const producer = (handoff, latch) => channel.zipRight(core.fromEffect(Handoff.take(latch)), core.readWithCause({\n    onInput: input => core.flatMap(core.fromEffect(pipe(handoff, Handoff.offer(InternalTake.chunk(input)))), () => producer(handoff, latch)),\n    onFailure: cause => core.fromEffect(Handoff.offer(handoff, InternalTake.failCause(cause))),\n    onDone: () => core.fromEffect(Handoff.offer(handoff, InternalTake.end))\n  }));\n  return new StreamImpl(pipe(Effect.all([Handoff.make(), Handoff.make(), Handoff.make(), Handoff.make()]), Effect.tap(([left, _, latchL]) => pipe(toChannel(self), core.pipeTo(producer(left, latchL)), channelExecutor.runScoped, Effect.forkScoped)), Effect.tap(([_, right, __, latchR]) => pipe(toChannel(that), core.pipeTo(producer(right, latchR)), channelExecutor.runScoped, Effect.forkScoped)), Effect.map(([left, right, latchL, latchR]) => {\n    const pullLeft = pipe(latchL, Handoff.offer(void 0), Effect.zipRight(pipe(Handoff.take(left), Effect.flatMap(InternalTake.done))));\n    const pullRight = pipe(latchR, Handoff.offer(void 0), Effect.zipRight(pipe(Handoff.take(right), Effect.flatMap(InternalTake.done))));\n    return toChannel(unfoldChunkEffect(s, s => Effect.flatMap(f(s, pullLeft, pullRight), unsome)));\n  }), channel.unwrapScoped));\n});\n/** @internal */\nexport const concat = /*#__PURE__*/dual(2, (self, that) => new StreamImpl(pipe(toChannel(self), channel.zipRight(toChannel(that)))));\n/** @internal */\nexport const concatAll = streams => suspend(() => pipe(streams, Chunk.reduce(empty, (x, y) => concat(y)(x))));\n/** @internal */\nexport const cross = /*#__PURE__*/dual(2, (self, that) => pipe(self, crossWith(that, (a, a2) => [a, a2])));\n/** @internal */\nexport const crossLeft = /*#__PURE__*/dual(2, (self, that) => pipe(self, crossWith(that, (a, _) => a)));\n/** @internal */\nexport const crossRight = /*#__PURE__*/dual(2, (self, that) => flatMap(self, () => that));\n/** @internal */\nexport const crossWith = /*#__PURE__*/dual(3, (self, that, f) => pipe(self, flatMap(a => pipe(that, map(b => f(a, b))))));\n/** @internal */\nexport const debounce = /*#__PURE__*/dual(2, (self, duration) => pipe(singleProducerAsyncInput.make(), Effect.flatMap(input => Effect.transplant(grafter => pipe(Handoff.make(), Effect.map(handoff => {\n  const enqueue = last => pipe(Clock.sleep(duration), Effect.as(last), Effect.fork, grafter, Effect.map(fiber => consumer(DebounceState.previous(fiber))));\n  const producer = core.readWithCause({\n    onInput: input => Option.match(Chunk.last(input), {\n      onNone: () => producer,\n      onSome: last => core.flatMap(core.fromEffect(Handoff.offer(handoff, HandoffSignal.emit(Chunk.of(last)))), () => producer)\n    }),\n    onFailure: cause => core.fromEffect(Handoff.offer(handoff, HandoffSignal.halt(cause))),\n    onDone: () => core.fromEffect(Handoff.offer(handoff, HandoffSignal.end(SinkEndReason.UpstreamEnd)))\n  });\n  const consumer = state => {\n    switch (state._tag) {\n      case DebounceState.OP_NOT_STARTED:\n        {\n          return pipe(Handoff.take(handoff), Effect.map(signal => {\n            switch (signal._tag) {\n              case HandoffSignal.OP_EMIT:\n                {\n                  return channel.unwrap(enqueue(signal.elements));\n                }\n              case HandoffSignal.OP_HALT:\n                {\n                  return core.failCause(signal.cause);\n                }\n              case HandoffSignal.OP_END:\n                {\n                  return core.void;\n                }\n            }\n          }), channel.unwrap);\n        }\n      case DebounceState.OP_PREVIOUS:\n        {\n          return channel.unwrap(Effect.raceWith(Fiber.join(state.fiber), Handoff.take(handoff), {\n            onSelfDone: (leftExit, current) => Exit.match(leftExit, {\n              onFailure: cause => pipe(Fiber.interrupt(current), Effect.as(core.failCause(cause))),\n              onSuccess: chunk => Effect.succeed(pipe(core.write(chunk), core.flatMap(() => consumer(DebounceState.current(current)))))\n            }),\n            onOtherDone: (rightExit, previous) => Exit.match(rightExit, {\n              onFailure: cause => pipe(Fiber.interrupt(previous), Effect.as(core.failCause(cause))),\n              onSuccess: signal => {\n                switch (signal._tag) {\n                  case HandoffSignal.OP_EMIT:\n                    {\n                      return pipe(Fiber.interrupt(previous), Effect.zipRight(enqueue(signal.elements)));\n                    }\n                  case HandoffSignal.OP_HALT:\n                    {\n                      return pipe(Fiber.interrupt(previous), Effect.as(core.failCause(signal.cause)));\n                    }\n                  case HandoffSignal.OP_END:\n                    {\n                      return pipe(Fiber.join(previous), Effect.map(chunk => pipe(core.write(chunk), channel.zipRight(core.void))));\n                    }\n                }\n              }\n            })\n          }));\n        }\n      case DebounceState.OP_CURRENT:\n        {\n          return pipe(Fiber.join(state.fiber), Effect.map(signal => {\n            switch (signal._tag) {\n              case HandoffSignal.OP_EMIT:\n                {\n                  return channel.unwrap(enqueue(signal.elements));\n                }\n              case HandoffSignal.OP_HALT:\n                {\n                  return core.failCause(signal.cause);\n                }\n              case HandoffSignal.OP_END:\n                {\n                  return core.void;\n                }\n            }\n          }), channel.unwrap);\n        }\n    }\n  };\n  const debounceChannel = pipe(channel.fromInput(input), core.pipeTo(producer), channelExecutor.run, Effect.forkScoped, Effect.as(pipe(consumer(DebounceState.notStarted), core.embedInput(input))), channel.unwrapScoped);\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(debounceChannel)));\n})))), unwrap));\n/** @internal */\nexport const die = defect => fromEffect(Effect.die(defect));\n/** @internal */\nexport const dieSync = evaluate => fromEffect(Effect.dieSync(evaluate));\n/** @internal */\nexport const dieMessage = message => fromEffect(Effect.dieMessage(message));\n/** @internal */\nexport const distributedWith = /*#__PURE__*/dual(2, (self, options) => pipe(Deferred.make(), Effect.flatMap(deferred => pipe(self, distributedWithDynamic({\n  maximumLag: options.maximumLag,\n  decide: a => Effect.flatMap(Deferred.await(deferred), f => f(a))\n}), Effect.flatMap(next => pipe(Effect.all(Chunk.map(Chunk.range(0, options.size - 1), id => Effect.map(next, ([key, queue]) => [[key, id], queue]))), Effect.map(Chunk.unsafeFromArray), Effect.flatMap(entries => {\n  const [mappings, queues] = Chunk.reduceRight(entries, [new Map(), Chunk.empty()], ([mappings, queues], [mapping, queue]) => [mappings.set(mapping[0], mapping[1]), pipe(queues, Chunk.prepend(queue))]);\n  return pipe(Deferred.succeed(deferred, a => Effect.map(options.decide(a), f => key => pipe(f(mappings.get(key))))), Effect.as(Array.from(queues)));\n})))))));\n/** @internal */\nconst distributedWithDynamicId = {\n  ref: 0\n};\nconst newDistributedWithDynamicId = () => {\n  const current = distributedWithDynamicId.ref;\n  distributedWithDynamicId.ref = current + 1;\n  return current;\n};\n/** @internal */\nexport const distributedWithDynamic = /*#__PURE__*/dual(2, (self, options) => distributedWithDynamicCallback(self, options.maximumLag, options.decide, () => Effect.void));\n/** @internal */\nexport const distributedWithDynamicCallback = /*#__PURE__*/dual(4, (self, maximumLag, decide, done) => pipe(Effect.acquireRelease(Ref.make(new Map()), (ref, _) => pipe(Ref.get(ref), Effect.flatMap(queues => pipe(queues.values(), Effect.forEach(Queue.shutdown))))), Effect.flatMap(queuesRef => Effect.gen(function* ($) {\n  const offer = a => pipe(decide(a), Effect.flatMap(shouldProcess => pipe(Ref.get(queuesRef), Effect.flatMap(queues => pipe(queues.entries(), Effect.reduce(Chunk.empty(), (acc, [id, queue]) => {\n    if (shouldProcess(id)) {\n      return pipe(Queue.offer(queue, Exit.succeed(a)), Effect.matchCauseEffect({\n        onFailure: cause =>\n        // Ignore all downstream queues that were shut\n        // down and remove them later\n        Cause.isInterrupted(cause) ? Effect.succeed(pipe(acc, Chunk.prepend(id))) : Effect.failCause(cause),\n        onSuccess: () => Effect.succeed(acc)\n      }));\n    }\n    return Effect.succeed(acc);\n  }), Effect.flatMap(ids => {\n    if (Chunk.isNonEmpty(ids)) {\n      return pipe(Ref.update(queuesRef, map => {\n        for (const id of ids) {\n          map.delete(id);\n        }\n        return map;\n      }));\n    }\n    return Effect.void;\n  }))))), Effect.asVoid);\n  const queuesLock = yield* $(Effect.makeSemaphore(1));\n  const newQueue = yield* $(Ref.make(pipe(Queue.bounded(maximumLag), Effect.flatMap(queue => {\n    const id = newDistributedWithDynamicId();\n    return pipe(Ref.update(queuesRef, map => map.set(id, queue)), Effect.as([id, queue]));\n  }))));\n  const finalize = endTake =>\n  // Make sure that no queues are currently being added\n  queuesLock.withPermits(1)(pipe(Ref.set(newQueue, pipe(\n  // All newly created queues should end immediately\n  Queue.bounded(1), Effect.tap(queue => Queue.offer(queue, endTake)), Effect.flatMap(queue => {\n    const id = newDistributedWithDynamicId();\n    return pipe(Ref.update(queuesRef, map => map.set(id, queue)), Effect.as(Tuple.make(id, queue)));\n  }))), Effect.zipRight(pipe(Ref.get(queuesRef), Effect.flatMap(map => pipe(Chunk.fromIterable(map.values()), Effect.forEach(queue => pipe(Queue.offer(queue, endTake), Effect.catchSomeCause(cause => Cause.isInterrupted(cause) ? Option.some(Effect.void) : Option.none()))))))), Effect.zipRight(done(endTake)), Effect.asVoid));\n  yield* $(self, runForEachScoped(offer), Effect.matchCauseEffect({\n    onFailure: cause => finalize(Exit.failCause(pipe(cause, Cause.map(Option.some)))),\n    onSuccess: () => finalize(Exit.fail(Option.none()))\n  }), Effect.forkScoped);\n  return queuesLock.withPermits(1)(Effect.flatten(Ref.get(newQueue)));\n}))));\n/** @internal */\nexport const drain = self => new StreamImpl(channel.drain(toChannel(self)));\n/** @internal */\nexport const drainFork = /*#__PURE__*/dual(2, (self, that) => pipe(fromEffect(Deferred.make()), flatMap(backgroundDied => pipe(scoped(pipe(that, runForEachScoped(() => Effect.void), Effect.catchAllCause(cause => Deferred.failCause(backgroundDied, cause)), Effect.forkScoped)), crossRight(pipe(self, interruptWhenDeferred(backgroundDied)))))));\n/** @internal */\nexport const drop = /*#__PURE__*/dual(2, (self, n) => {\n  const loop = r => core.readWith({\n    onInput: input => {\n      const dropped = pipe(input, Chunk.drop(r));\n      const leftover = Math.max(0, r - input.length);\n      const more = Chunk.isEmpty(input) || leftover > 0;\n      if (more) {\n        return loop(leftover);\n      }\n      return pipe(core.write(dropped), channel.zipRight(channel.identityChannel()));\n    },\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(loop(n))));\n});\n/** @internal */\nexport const dropRight = /*#__PURE__*/dual(2, (self, n) => {\n  if (n <= 0) {\n    return identityStream();\n  }\n  return suspend(() => {\n    const queue = new RingBuffer(n);\n    const reader = core.readWith({\n      onInput: input => {\n        const outputs = pipe(input, Chunk.filterMap(elem => {\n          const head = queue.head();\n          queue.put(elem);\n          return head;\n        }));\n        return pipe(core.write(outputs), core.flatMap(() => reader));\n      },\n      onFailure: core.fail,\n      onDone: () => core.void\n    });\n    return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(reader)));\n  });\n});\n/** @internal */\nexport const dropUntil = /*#__PURE__*/dual(2, (self, predicate) => drop(dropWhile(self, a => !predicate(a)), 1));\n/** @internal */\nexport const dropUntilEffect = /*#__PURE__*/dual(2, (self, predicate) => {\n  const loop = core.readWith({\n    onInput: input => pipe(Effect.dropUntil(input, predicate), Effect.map(Chunk.unsafeFromArray), Effect.map(leftover => {\n      const more = Chunk.isEmpty(leftover);\n      if (more) {\n        return core.suspend(() => loop);\n      }\n      return pipe(core.write(leftover), channel.zipRight(channel.identityChannel()));\n    }), channel.unwrap),\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(loop)));\n});\n/** @internal */\nexport const dropWhile = /*#__PURE__*/dual(2, (self, predicate) => {\n  const loop = core.readWith({\n    onInput: input => {\n      const output = Chunk.dropWhile(input, predicate);\n      if (Chunk.isEmpty(output)) {\n        return core.suspend(() => loop);\n      }\n      return channel.zipRight(core.write(output), channel.identityChannel());\n    },\n    onFailure: core.fail,\n    onDone: core.succeedNow\n  });\n  return new StreamImpl(channel.pipeToOrFail(toChannel(self), loop));\n});\n/** @internal */\nexport const dropWhileEffect = /*#__PURE__*/dual(2, (self, predicate) => {\n  const loop = core.readWith({\n    onInput: input => pipe(Effect.dropWhile(input, predicate), Effect.map(Chunk.unsafeFromArray), Effect.map(leftover => {\n      const more = Chunk.isEmpty(leftover);\n      if (more) {\n        return core.suspend(() => loop);\n      }\n      return channel.zipRight(core.write(leftover), channel.identityChannel());\n    }), channel.unwrap),\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new StreamImpl(channel.pipeToOrFail(toChannel(self), loop));\n});\n/** @internal */\nexport const either = self => pipe(self, map(Either.right), catchAll(error => make(Either.left(error))));\n/** @internal */\nexport const empty = /*#__PURE__*/new StreamImpl( /*#__PURE__*/core.write( /*#__PURE__*/Chunk.empty()));\n/** @internal */\nexport const ensuring = /*#__PURE__*/dual(2, (self, finalizer) => new StreamImpl(pipe(toChannel(self), channel.ensuring(finalizer))));\n/** @internal */\nexport const ensuringWith = /*#__PURE__*/dual(2, (self, finalizer) => new StreamImpl(core.ensuringWith(toChannel(self), finalizer)));\n/** @internal */\nexport const context = () => fromEffect(Effect.context());\n/** @internal */\nexport const contextWith = f => pipe(context(), map(f));\n/** @internal */\nexport const contextWithEffect = f => pipe(context(), mapEffectSequential(f));\n/** @internal */\nexport const contextWithStream = f => pipe(context(), flatMap(f));\n/** @internal */\nexport const execute = effect => drain(fromEffect(effect));\n/** @internal */\nexport const fail = error => fromEffectOption(Effect.fail(Option.some(error)));\n/** @internal */\nexport const failSync = evaluate => fromEffectOption(Effect.failSync(() => Option.some(evaluate())));\n/** @internal */\nexport const failCause = cause => fromEffect(Effect.failCause(cause));\n/** @internal */\nexport const failCauseSync = evaluate => fromEffect(Effect.failCauseSync(evaluate));\n/** @internal */\nexport const filter = /*#__PURE__*/dual(2, (self, predicate) => mapChunks(self, Chunk.filter(predicate)));\n/** @internal */\nexport const filterEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const loop = iterator => {\n    const next = iterator.next();\n    if (next.done) {\n      return core.readWithCause({\n        onInput: input => loop(input[Symbol.iterator]()),\n        onFailure: core.failCause,\n        onDone: core.succeed\n      });\n    } else {\n      return pipe(f(next.value), Effect.map(bool => bool ? pipe(core.write(Chunk.of(next.value)), core.flatMap(() => loop(iterator))) : loop(iterator)), channel.unwrap);\n    }\n  };\n  return new StreamImpl(core.suspend(() => pipe(toChannel(self), core.pipeTo(loop(Chunk.empty()[Symbol.iterator]())))));\n});\n/** @internal */\nexport const filterMap = /*#__PURE__*/dual(2, (self, pf) => mapChunks(self, Chunk.filterMap(pf)));\n/** @internal */\nexport const filterMapEffect = /*#__PURE__*/dual(2, (self, pf) => suspend(() => {\n  const loop = iterator => {\n    const next = iterator.next();\n    if (next.done) {\n      return core.readWithCause({\n        onInput: input => loop(input[Symbol.iterator]()),\n        onFailure: core.failCause,\n        onDone: core.succeed\n      });\n    } else {\n      return pipe(pf(next.value), Option.match({\n        onNone: () => Effect.sync(() => loop(iterator)),\n        onSome: Effect.map(a2 => core.flatMap(core.write(Chunk.of(a2)), () => loop(iterator)))\n      }), channel.unwrap);\n    }\n  };\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(loop(Chunk.empty()[Symbol.iterator]()))));\n}));\n/** @internal */\nexport const filterMapWhile = /*#__PURE__*/dual(2, (self, pf) => {\n  const loop = core.readWith({\n    onInput: input => {\n      const mapped = Chunk.filterMapWhile(input, pf);\n      if (mapped.length === input.length) {\n        return pipe(core.write(mapped), core.flatMap(() => loop));\n      }\n      return core.write(mapped);\n    },\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(loop)));\n});\n/** @internal */\nexport const filterMapWhileEffect = /*#__PURE__*/dual(2, (self, pf) => suspend(() => {\n  const loop = iterator => {\n    const next = iterator.next();\n    if (next.done) {\n      return core.readWithCause({\n        onInput: input => loop(input[Symbol.iterator]()),\n        onFailure: core.failCause,\n        onDone: core.succeed\n      });\n    } else {\n      return channel.unwrap(Option.match(pf(next.value), {\n        onNone: () => Effect.succeed(core.void),\n        onSome: Effect.map(a2 => core.flatMap(core.write(Chunk.of(a2)), () => loop(iterator)))\n      }));\n    }\n  };\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(loop(Chunk.empty()[Symbol.iterator]()))));\n}));\n/** @internal */\nexport const finalizer = finalizer => acquireRelease(Effect.void, () => finalizer);\n/** @internal */\nexport const find = /*#__PURE__*/dual(2, (self, predicate) => {\n  const loop = core.readWith({\n    onInput: input => Option.match(Chunk.findFirst(input, predicate), {\n      onNone: () => loop,\n      onSome: n => core.write(Chunk.of(n))\n    }),\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(loop)));\n});\n/** @internal */\nexport const findEffect = /*#__PURE__*/dual(2, (self, predicate) => {\n  const loop = core.readWith({\n    onInput: input => pipe(Effect.findFirst(input, predicate), Effect.map(Option.match({\n      onNone: () => loop,\n      onSome: n => core.write(Chunk.of(n))\n    })), channel.unwrap),\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(loop)));\n});\n/** @internal */\nexport const flatMap = /*#__PURE__*/dual(args => isStream(args[0]), (self, f, options) => {\n  const bufferSize = options?.bufferSize ?? 16;\n  if (options?.switch) {\n    return matchConcurrency(options?.concurrency, () => flatMapParSwitchBuffer(self, 1, bufferSize, f), n => flatMapParSwitchBuffer(self, n, bufferSize, f));\n  }\n  return matchConcurrency(options?.concurrency, () => new StreamImpl(channel.concatMap(toChannel(self), as => pipe(as, Chunk.map(a => toChannel(f(a))), Chunk.reduce(core.void, (left, right) => pipe(left, channel.zipRight(right)))))), _ => new StreamImpl(pipe(toChannel(self), channel.concatMap(channel.writeChunk), channel.mergeMap(out => toChannel(f(out)), options))));\n});\n/** @internal */\nexport const matchConcurrency = (concurrency, sequential, bounded) => {\n  switch (concurrency) {\n    case undefined:\n      return sequential();\n    case \"unbounded\":\n      return bounded(Number.MAX_SAFE_INTEGER);\n    default:\n      return concurrency > 1 ? bounded(concurrency) : sequential();\n  }\n};\nconst flatMapParSwitchBuffer = /*#__PURE__*/dual(4, (self, n, bufferSize, f) => new StreamImpl(pipe(toChannel(self), channel.concatMap(channel.writeChunk), channel.mergeMap(out => toChannel(f(out)), {\n  concurrency: n,\n  mergeStrategy: MergeStrategy.BufferSliding(),\n  bufferSize\n}))));\n/** @internal */\nexport const flatten = /*#__PURE__*/dual(args => isStream(args[0]), (self, options) => flatMap(self, identity, options));\n/** @internal */\nexport const flattenChunks = self => {\n  const flatten = core.readWithCause({\n    onInput: chunks => core.flatMap(channel.writeChunk(chunks), () => flatten),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(flatten)));\n};\n/** @internal */\nexport const flattenEffect = /*#__PURE__*/dual(args => isStream(args[0]), (self, options) => options?.unordered ? flatMap(self, a => fromEffect(a), {\n  concurrency: options.concurrency\n}) : matchConcurrency(options?.concurrency, () => mapEffectSequential(self, identity), n => new StreamImpl(pipe(toChannel(self), channel.concatMap(channel.writeChunk), channel.mapOutEffectPar(identity, n), channel.mapOut(Chunk.of)))));\n/** @internal */\nexport const flattenExitOption = self => {\n  const processChunk = (chunk, cont) => {\n    const [toEmit, rest] = pipe(chunk, Chunk.splitWhere(exit => !Exit.isSuccess(exit)));\n    const next = pipe(Chunk.head(rest), Option.match({\n      onNone: () => cont,\n      onSome: Exit.match({\n        onFailure: cause => Option.match(Cause.flipCauseOption(cause), {\n          onNone: () => core.void,\n          onSome: core.failCause\n        }),\n        onSuccess: () => core.void\n      })\n    }));\n    return pipe(core.write(pipe(toEmit, Chunk.filterMap(exit => Exit.isSuccess(exit) ? Option.some(exit.value) : Option.none()))), core.flatMap(() => next));\n  };\n  const process = core.readWithCause({\n    onInput: chunk => processChunk(chunk, process),\n    onFailure: cause => core.failCause(cause),\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(process)));\n};\n/** @internal */\nexport const flattenIterables = self => pipe(self, map(Chunk.fromIterable), flattenChunks);\n/** @internal */\nexport const flattenTake = self => flattenChunks(flattenExitOption(pipe(self, map(take => take.exit))));\n/** @internal */\nexport const forever = self => new StreamImpl(channel.repeated(toChannel(self)));\n/** @internal */\nexport const fromAsyncIterable = (iterable, onError) => pipe(Effect.acquireRelease(Effect.sync(() => iterable[Symbol.asyncIterator]()), iterator => iterator.return ? Effect.promise(async () => iterator.return()) : Effect.void), Effect.map(iterator => repeatEffectOption(pipe(Effect.tryPromise({\n  try: async () => iterator.next(),\n  catch: reason => Option.some(onError(reason))\n}), Effect.flatMap(result => result.done ? Effect.fail(Option.none()) : Effect.succeed(result.value))))), unwrapScoped);\n/** @internal */\nexport const fromChannel = channel => new StreamImpl(channel);\n/** @internal */\nexport const toChannel = stream => {\n  if (\"channel\" in stream) {\n    return stream.channel;\n  } else if (Effect.isEffect(stream)) {\n    return toChannel(fromEffect(stream));\n  } else {\n    throw new TypeError(`Expected a Stream.`);\n  }\n};\n/** @internal */\nexport const fromChunk = chunk => new StreamImpl(Chunk.isEmpty(chunk) ? core.void : core.write(chunk));\n/** @internal */\nexport const fromChunkPubSub = (pubsub, options) => {\n  if (options?.scoped) {\n    const effect = Effect.map(PubSub.subscribe(pubsub), fromChunkQueue);\n    return options.shutdown ? Effect.map(effect, ensuring(PubSub.shutdown(pubsub))) : effect;\n  }\n  const stream = flatMap(scoped(PubSub.subscribe(pubsub)), fromChunkQueue);\n  return options?.shutdown ? ensuring(stream, PubSub.shutdown(pubsub)) : stream;\n};\n/** @internal */\nexport const fromChunkQueue = (queue, options) => pipe(Queue.take(queue), Effect.catchAllCause(cause => pipe(Queue.isShutdown(queue), Effect.flatMap(isShutdown => isShutdown && Cause.isInterrupted(cause) ? pull.end() : pull.failCause(cause)))), repeatEffectChunkOption, options?.shutdown ? ensuring(Queue.shutdown(queue)) : identity);\n/** @internal */\nexport const fromChunks = (...chunks) => pipe(fromIterable(chunks), flatMap(fromChunk));\n/** @internal */\nexport const fromEffect = effect => pipe(effect, Effect.mapError(Option.some), fromEffectOption);\n/** @internal */\nexport const fromEffectOption = effect => new StreamImpl(channel.unwrap(Effect.match(effect, {\n  onFailure: Option.match({\n    onNone: () => core.void,\n    onSome: core.fail\n  }),\n  onSuccess: a => core.write(Chunk.of(a))\n})));\n/** @internal */\nexport const fromPubSub = (pubsub, options) => {\n  const maxChunkSize = options?.maxChunkSize ?? DefaultChunkSize;\n  if (options?.scoped) {\n    const effect = Effect.map(PubSub.subscribe(pubsub), queue => fromQueue(queue, {\n      maxChunkSize,\n      shutdown: true\n    }));\n    return options.shutdown ? Effect.map(effect, ensuring(PubSub.shutdown(pubsub))) : effect;\n  }\n  const stream = flatMap(scoped(PubSub.subscribe(pubsub)), queue => fromQueue(queue, {\n    maxChunkSize\n  }));\n  return options?.shutdown ? ensuring(stream, PubSub.shutdown(pubsub)) : stream;\n};\n/** @internal */\nexport const fromIterable = iterable => suspend(() => Chunk.isChunk(iterable) ? fromChunk(iterable) : fromIteratorSucceed(iterable[Symbol.iterator]()));\n/** @internal */\nexport const fromIterableEffect = effect => pipe(effect, Effect.map(fromIterable), unwrap);\n/** @internal */\nexport const fromIteratorSucceed = (iterator, maxChunkSize = DefaultChunkSize) => {\n  return pipe(Effect.sync(() => {\n    let builder = [];\n    const loop = iterator => pipe(Effect.sync(() => {\n      let next = iterator.next();\n      if (maxChunkSize === 1) {\n        if (next.done) {\n          return core.void;\n        }\n        return pipe(core.write(Chunk.of(next.value)), core.flatMap(() => loop(iterator)));\n      }\n      builder = [];\n      let count = 0;\n      while (next.done === false) {\n        builder.push(next.value);\n        count = count + 1;\n        if (count >= maxChunkSize) {\n          break;\n        }\n        next = iterator.next();\n      }\n      if (count > 0) {\n        return pipe(core.write(Chunk.unsafeFromArray(builder)), core.flatMap(() => loop(iterator)));\n      }\n      return core.void;\n    }), channel.unwrap);\n    return new StreamImpl(loop(iterator));\n  }), unwrap);\n};\n/** @internal */\nexport const fromPull = effect => pipe(effect, Effect.map(repeatEffectChunkOption), unwrapScoped);\n/** @internal */\nexport const fromQueue = (queue, options) => pipe(Queue.takeBetween(queue, 1, options?.maxChunkSize ?? DefaultChunkSize), Effect.catchAllCause(cause => pipe(Queue.isShutdown(queue), Effect.flatMap(isShutdown => isShutdown && Cause.isInterrupted(cause) ? pull.end() : pull.failCause(cause)))), repeatEffectChunkOption, options?.shutdown ? ensuring(Queue.shutdown(queue)) : identity);\n/** @internal */\nexport const fromSchedule = schedule => pipe(Schedule.driver(schedule), Effect.map(driver => repeatEffectOption(driver.next(void 0))), unwrap);\n/** @internal */\nexport const fromReadableStream = (evaluate, onError) => unwrapScoped(Effect.map(Effect.acquireRelease(Effect.sync(() => evaluate().getReader()), reader => Effect.promise(() => reader.cancel())), reader => repeatEffectOption(Effect.flatMap(Effect.tryPromise({\n  try: () => reader.read(),\n  catch: reason => Option.some(onError(reason))\n}), ({\n  done,\n  value\n}) => done ? Effect.fail(Option.none()) : Effect.succeed(value)))));\n/** @internal */\nexport const fromReadableStreamByob = (evaluate, onError, allocSize = 4096) => unwrapScoped(Effect.map(Effect.acquireRelease(Effect.sync(() => evaluate().getReader({\n  mode: \"byob\"\n})), reader => Effect.promise(() => reader.cancel())), reader => catchAll(forever(readChunkStreamByobReader(reader, onError, allocSize)), error => isTagged(error, \"EOF\") ? empty : fail(error))));\nconst readChunkStreamByobReader = (reader, onError, size) => {\n  const buffer = new ArrayBuffer(size);\n  return paginateEffect(0, offset => Effect.flatMap(Effect.tryPromise({\n    try: () => reader.read(new Uint8Array(buffer, offset, buffer.byteLength - offset)),\n    catch: reason => onError(reason)\n  }), ({\n    done,\n    value\n  }) => {\n    if (done) {\n      return Effect.fail({\n        _tag: \"EOF\"\n      });\n    }\n    const newOffset = offset + value.byteLength;\n    return Effect.succeed([value, newOffset >= buffer.byteLength ? Option.none() : Option.some(newOffset)]);\n  }));\n};\n/** @internal */\nexport const groupAdjacentBy = /*#__PURE__*/dual(2, (self, f) => {\n  const groupAdjacentByChunk = (state, chunk) => {\n    if (Chunk.isEmpty(chunk)) {\n      return [state, Chunk.empty()];\n    }\n    const builder = [];\n    let from = 0;\n    let until = 0;\n    let key = undefined;\n    let previousChunk = Chunk.empty();\n    switch (state._tag) {\n      case \"Some\":\n        {\n          const tuple = state.value;\n          key = tuple[0];\n          let loop = true;\n          while (loop && until < chunk.length) {\n            const input = Chunk.unsafeGet(chunk, until);\n            const updatedKey = f(input);\n            if (!Equal.equals(key, updatedKey)) {\n              const previousChunk = tuple[1];\n              const additionalChunk = Chunk.unsafeFromArray(Array.from(chunk).slice(from, until));\n              const group = Chunk.appendAll(previousChunk, additionalChunk);\n              builder.push([key, group]);\n              key = updatedKey;\n              from = until;\n              loop = false;\n            }\n            until = until + 1;\n          }\n          if (loop) {\n            previousChunk = tuple[1];\n          }\n          break;\n        }\n      case \"None\":\n        {\n          key = f(Chunk.unsafeGet(chunk, until));\n          until = until + 1;\n          break;\n        }\n    }\n    while (until < chunk.length) {\n      const input = Chunk.unsafeGet(chunk, until);\n      const updatedKey = f(input);\n      if (!Equal.equals(key, updatedKey)) {\n        builder.push([key, Chunk.unsafeFromArray(Array.from(chunk).slice(from, until))]);\n        key = updatedKey;\n        from = until;\n      }\n      until = until + 1;\n    }\n    const nonEmptyChunk = Chunk.appendAll(previousChunk, Chunk.unsafeFromArray(Array.from(chunk).slice(from, until)));\n    const output = Chunk.unsafeFromArray(builder);\n    return [Option.some([key, nonEmptyChunk]), output];\n  };\n  const groupAdjacent = state => core.readWithCause({\n    onInput: input => {\n      const [updatedState, output] = groupAdjacentByChunk(state, input);\n      return Chunk.isEmpty(output) ? groupAdjacent(updatedState) : core.flatMap(core.write(output), () => groupAdjacent(updatedState));\n    },\n    onFailure: cause => Option.match(state, {\n      onNone: () => core.failCause(cause),\n      onSome: output => core.flatMap(core.write(Chunk.of(output)), () => core.failCause(cause))\n    }),\n    onDone: done => Option.match(state, {\n      onNone: () => core.succeedNow(done),\n      onSome: output => core.flatMap(core.write(Chunk.of(output)), () => core.succeedNow(done))\n    })\n  });\n  return new StreamImpl(channel.pipeToOrFail(toChannel(self), groupAdjacent(Option.none())));\n});\n/** @internal */\nexport const grouped = /*#__PURE__*/dual(2, (self, chunkSize) => pipe(self, rechunk(chunkSize), chunks));\n/** @internal */\nexport const groupedWithin = /*#__PURE__*/dual(3, (self, chunkSize, duration) => aggregateWithin(self, _sink.collectAllN(chunkSize), Schedule.spaced(duration)));\n/** @internal */\nexport const haltWhen = /*#__PURE__*/dual(2, (self, effect) => {\n  const writer = fiber => pipe(Fiber.poll(fiber), Effect.map(Option.match({\n    onNone: () => core.readWith({\n      onInput: input => core.flatMap(core.write(input), () => writer(fiber)),\n      onFailure: core.fail,\n      onDone: () => core.void\n    }),\n    onSome: Exit.match({\n      onFailure: core.failCause,\n      onSuccess: () => core.void\n    })\n  })), channel.unwrap);\n  return new StreamImpl(pipe(Effect.forkScoped(effect), Effect.map(fiber => pipe(toChannel(self), core.pipeTo(writer(fiber)))), channel.unwrapScoped));\n});\n/** @internal */\nexport const haltAfter = /*#__PURE__*/dual(2, (self, duration) => pipe(self, haltWhen(Clock.sleep(duration))));\n/** @internal */\nexport const haltWhenDeferred = /*#__PURE__*/dual(2, (self, deferred) => {\n  const writer = pipe(Deferred.poll(deferred), Effect.map(Option.match({\n    onNone: () => core.readWith({\n      onInput: input => pipe(core.write(input), core.flatMap(() => writer)),\n      onFailure: core.fail,\n      onDone: () => core.void\n    }),\n    onSome: effect => channel.unwrap(Effect.match(effect, {\n      onFailure: core.fail,\n      onSuccess: () => core.void\n    }))\n  })), channel.unwrap);\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(writer)));\n});\n/** @internal */\nexport const identityStream = () => new StreamImpl(channel.identityChannel());\n/** @internal */\nexport const interleave = /*#__PURE__*/dual(2, (self, that) => pipe(self, interleaveWith(that, forever(make(true, false)))));\n/** @internal */\nexport const interleaveWith = /*#__PURE__*/dual(3, (self, that, decider) => {\n  const producer = handoff => core.readWithCause({\n    onInput: value => core.flatMap(core.fromEffect(Handoff.offer(handoff, InternalTake.of(value))), () => producer(handoff)),\n    onFailure: cause => core.fromEffect(Handoff.offer(handoff, InternalTake.failCause(cause))),\n    onDone: () => core.fromEffect(Handoff.offer(handoff, InternalTake.end))\n  });\n  return new StreamImpl(channel.unwrapScoped(pipe(Handoff.make(), Effect.zip(Handoff.make()), Effect.tap(([left]) => pipe(toChannel(self), channel.concatMap(channel.writeChunk), core.pipeTo(producer(left)), channelExecutor.runScoped, Effect.forkScoped)), Effect.tap(([_, right]) => pipe(toChannel(that), channel.concatMap(channel.writeChunk), core.pipeTo(producer(right)), channelExecutor.runScoped, Effect.forkScoped)), Effect.map(([left, right]) => {\n    const process = (leftDone, rightDone) => core.readWithCause({\n      onInput: bool => {\n        if (bool && !leftDone) {\n          return pipe(core.fromEffect(Handoff.take(left)), core.flatMap(InternalTake.match({\n            onEnd: () => rightDone ? core.void : process(true, rightDone),\n            onFailure: core.failCause,\n            onSuccess: chunk => pipe(core.write(chunk), core.flatMap(() => process(leftDone, rightDone)))\n          })));\n        }\n        if (!bool && !rightDone) {\n          return pipe(core.fromEffect(Handoff.take(right)), core.flatMap(InternalTake.match({\n            onEnd: () => leftDone ? core.void : process(leftDone, true),\n            onFailure: core.failCause,\n            onSuccess: chunk => pipe(core.write(chunk), core.flatMap(() => process(leftDone, rightDone)))\n          })));\n        }\n        return process(leftDone, rightDone);\n      },\n      onFailure: core.failCause,\n      onDone: () => core.void\n    });\n    return pipe(toChannel(decider), channel.concatMap(channel.writeChunk), core.pipeTo(process(false, false)));\n  }))));\n});\n/** @internal */\nexport const intersperse = /*#__PURE__*/dual(2, (self, element) => new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(core.suspend(() => {\n  const writer = isFirst => core.readWithCause({\n    onInput: chunk => {\n      const builder = [];\n      let flagResult = isFirst;\n      for (const output of chunk) {\n        if (flagResult) {\n          flagResult = false;\n          builder.push(output);\n        } else {\n          builder.push(element);\n          builder.push(output);\n        }\n      }\n      return pipe(core.write(Chunk.unsafeFromArray(builder)), core.flatMap(() => writer(flagResult)));\n    },\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return writer(true);\n})))));\n/** @internal */\nexport const intersperseAffixes = /*#__PURE__*/dual(2, (self, {\n  end,\n  middle,\n  start\n}) => pipe(make(start), concat(pipe(self, intersperse(middle))), concat(make(end))));\n/** @internal */\nexport const interruptAfter = /*#__PURE__*/dual(2, (self, duration) => pipe(self, interruptWhen(Clock.sleep(duration))));\n/** @internal */\nexport const interruptWhen = /*#__PURE__*/dual(2, (self, effect) => new StreamImpl(pipe(toChannel(self), channel.interruptWhen(effect))));\n/** @internal */\nexport const interruptWhenDeferred = /*#__PURE__*/dual(2, (self, deferred) => new StreamImpl(pipe(toChannel(self), channel.interruptWhenDeferred(deferred))));\n/** @internal */\nexport const iterate = (value, next) => unfold(value, a => Option.some([a, next(a)]));\n/** @internal */\nexport const make = (...as) => fromIterable(as);\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => new StreamImpl(pipe(toChannel(self), channel.mapOut(Chunk.map(f)))));\n/** @internal */\nexport const mapAccum = /*#__PURE__*/dual(3, (self, s, f) => {\n  const accumulator = s => core.readWith({\n    onInput: input => {\n      const [nextS, chunk] = Chunk.mapAccum(input, s, f);\n      return core.flatMap(core.write(chunk), () => accumulator(nextS));\n    },\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(accumulator(s))));\n});\n/** @internal */\nexport const mapAccumEffect = /*#__PURE__*/dual(3, (self, s, f) => suspend(() => {\n  const accumulator = s => core.readWith({\n    onInput: input => pipe(Effect.suspend(() => {\n      const outputs = [];\n      const emit = output => Effect.sync(() => {\n        outputs.push(output);\n      });\n      return pipe(input, Effect.reduce(s, (s, a) => pipe(f(s, a), Effect.flatMap(([s, a]) => pipe(emit(a), Effect.as(s))))), Effect.match({\n        onFailure: error => {\n          if (outputs.length !== 0) {\n            return channel.zipRight(core.write(Chunk.unsafeFromArray(outputs)), core.fail(error));\n          }\n          return core.fail(error);\n        },\n        onSuccess: s => core.flatMap(core.write(Chunk.unsafeFromArray(outputs)), () => accumulator(s))\n      }));\n    }), channel.unwrap),\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(accumulator(s))));\n}));\n/** @internal */\nexport const mapBoth = /*#__PURE__*/dual(2, (self, options) => pipe(self, mapError(options.onFailure), map(options.onSuccess)));\n/** @internal */\nexport const mapChunks = /*#__PURE__*/dual(2, (self, f) => new StreamImpl(pipe(toChannel(self), channel.mapOut(f))));\n/** @internal */\nexport const mapChunksEffect = /*#__PURE__*/dual(2, (self, f) => new StreamImpl(pipe(toChannel(self), channel.mapOutEffect(f))));\n/** @internal */\nexport const mapConcat = /*#__PURE__*/dual(2, (self, f) => pipe(self, mapConcatChunk(a => Chunk.fromIterable(f(a)))));\n/** @internal */\nexport const mapConcatChunk = /*#__PURE__*/dual(2, (self, f) => pipe(self, mapChunks(Chunk.flatMap(f))));\n/** @internal */\nexport const mapConcatChunkEffect = /*#__PURE__*/dual(2, (self, f) => pipe(self, mapEffectSequential(f), mapConcatChunk(identity)));\n/** @internal */\nexport const mapConcatEffect = /*#__PURE__*/dual(2, (self, f) => pipe(self, mapEffectSequential(a => pipe(f(a), Effect.map(Chunk.fromIterable))), mapConcatChunk(identity)));\n/** @internal */\nexport const mapEffectSequential = /*#__PURE__*/dual(2, (self, f) => {\n  const loop = iterator => {\n    const next = iterator.next();\n    if (next.done) {\n      return core.readWithCause({\n        onInput: elem => loop(elem[Symbol.iterator]()),\n        onFailure: core.failCause,\n        onDone: core.succeed\n      });\n    } else {\n      const value = next.value;\n      return channel.unwrap(Effect.map(f(value), a2 => core.flatMap(core.write(Chunk.of(a2)), () => loop(iterator))));\n    }\n  };\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(core.suspend(() => loop(Chunk.empty()[Symbol.iterator]())))));\n});\n/** @internal */\nexport const mapEffectPar = /*#__PURE__*/dual(3, (self, n, f) => new StreamImpl(pipe(toChannel(self), channel.concatMap(channel.writeChunk), channel.mapOutEffectPar(f, n), channel.mapOut(Chunk.of))));\n/** @internal */\nexport const mapError = /*#__PURE__*/dual(2, (self, f) => new StreamImpl(pipe(toChannel(self), channel.mapError(f))));\n/** @internal */\nexport const mapErrorCause = /*#__PURE__*/dual(2, (self, f) => new StreamImpl(pipe(toChannel(self), channel.mapErrorCause(f))));\n/** @internal */\nexport const merge = /*#__PURE__*/dual(args => isStream(args[1]), (self, that, options) => mergeWith(self, that, {\n  onSelf: identity,\n  onOther: identity,\n  haltStrategy: options?.haltStrategy\n}));\n/** @internal */\nexport const mergeAll = /*#__PURE__*/dual(args => Symbol.iterator in args[0], (streams, options) => flatten(fromIterable(streams), options));\n/** @internal */\nexport const mergeEither = /*#__PURE__*/dual(2, (self, that) => mergeWith(self, that, {\n  onSelf: Either.left,\n  onOther: Either.right\n}));\n/** @internal */\nexport const mergeLeft = /*#__PURE__*/dual(2, (left, right) => pipe(left, merge(drain(right))));\n/** @internal */\nexport const mergeRight = /*#__PURE__*/dual(2, (left, right) => pipe(drain(left), merge(right)));\n/** @internal */\nexport const mergeWith = /*#__PURE__*/dual(3, (self, other, options) => {\n  const strategy = options.haltStrategy ? haltStrategy.fromInput(options.haltStrategy) : HaltStrategy.Both;\n  const handler = terminate => exit => terminate || !Exit.isSuccess(exit) ?\n  // TODO: remove\n  MergeDecision.Done(Effect.suspend(() => exit)) : MergeDecision.Await(exit => Effect.suspend(() => exit));\n  return new StreamImpl(channel.mergeWith(toChannel(map(self, options.onSelf)), {\n    other: toChannel(map(other, options.onOther)),\n    onSelfDone: handler(strategy._tag === \"Either\" || strategy._tag === \"Left\"),\n    onOtherDone: handler(strategy._tag === \"Either\" || strategy._tag === \"Right\")\n  }));\n});\n/** @internal */\nexport const mkString = self => run(self, _sink.mkString);\n/** @internal */\nexport const never = /*#__PURE__*/fromEffect(Effect.never);\n/** @internal */\nexport const onError = /*#__PURE__*/dual(2, (self, cleanup) => pipe(self, catchAllCause(cause => fromEffect(pipe(cleanup(cause), Effect.zipRight(Effect.failCause(cause)))))));\n/** @internal */\nexport const onDone = /*#__PURE__*/dual(2, (self, cleanup) => new StreamImpl(pipe(toChannel(self), core.ensuringWith(exit => Exit.isSuccess(exit) ? cleanup() : Effect.void))));\n/** @internal */\nexport const orDie = self => pipe(self, orDieWith(identity));\n/** @internal */\nexport const orDieWith = /*#__PURE__*/dual(2, (self, f) => new StreamImpl(pipe(toChannel(self), channel.orDieWith(f))));\n/** @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => new StreamImpl(pipe(toChannel(self), channel.orElse(() => toChannel(that())))));\n/** @internal */\nexport const orElseEither = /*#__PURE__*/dual(2, (self, that) => pipe(self, map(Either.left), orElse(() => pipe(that(), map(Either.right)))));\n/** @internal */\nexport const orElseFail = /*#__PURE__*/dual(2, (self, error) => pipe(self, orElse(() => failSync(error))));\n/** @internal */\nexport const orElseIfEmpty = /*#__PURE__*/dual(2, (self, element) => pipe(self, orElseIfEmptyChunk(() => Chunk.of(element()))));\n/** @internal */\nexport const orElseIfEmptyChunk = /*#__PURE__*/dual(2, (self, chunk) => pipe(self, orElseIfEmptyStream(() => new StreamImpl(core.write(chunk())))));\n/** @internal */\nexport const orElseIfEmptyStream = /*#__PURE__*/dual(2, (self, stream) => {\n  const writer = core.readWith({\n    onInput: input => {\n      if (Chunk.isEmpty(input)) {\n        return core.suspend(() => writer);\n      }\n      return pipe(core.write(input), channel.zipRight(channel.identityChannel()));\n    },\n    onFailure: core.fail,\n    onDone: () => core.suspend(() => toChannel(stream()))\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(writer)));\n});\n/** @internal */\nexport const orElseSucceed = /*#__PURE__*/dual(2, (self, value) => pipe(self, orElse(() => sync(value))));\n/** @internal */\nexport const paginate = (s, f) => paginateChunk(s, s => {\n  const page = f(s);\n  return [Chunk.of(page[0]), page[1]];\n});\n/** @internal */\nexport const paginateChunk = (s, f) => {\n  const loop = s => {\n    const page = f(s);\n    return Option.match(page[1], {\n      onNone: () => channel.zipRight(core.write(page[0]), core.void),\n      onSome: s => core.flatMap(core.write(page[0]), () => loop(s))\n    });\n  };\n  return new StreamImpl(core.suspend(() => loop(s)));\n};\n/** @internal */\nexport const paginateChunkEffect = (s, f) => {\n  const loop = s => channel.unwrap(Effect.map(f(s), ([chunk, option]) => Option.match(option, {\n    onNone: () => channel.zipRight(core.write(chunk), core.void),\n    onSome: s => core.flatMap(core.write(chunk), () => loop(s))\n  })));\n  return new StreamImpl(core.suspend(() => loop(s)));\n};\n/** @internal */\nexport const paginateEffect = (s, f) => paginateChunkEffect(s, s => pipe(f(s), Effect.map(([a, s]) => [Chunk.of(a), s])));\n/** @internal */\nexport const peel = /*#__PURE__*/dual(2, (self, sink) => {\n  const OP_EMIT = \"Emit\";\n  const OP_HALT = \"Halt\";\n  const OP_END = \"End\";\n  return pipe(Deferred.make(), Effect.flatMap(deferred => pipe(Handoff.make(), Effect.map(handoff => {\n    const consumer = _sink.foldSink(_sink.collectLeftover(sink), {\n      onFailure: error => _sink.zipRight(_sink.fromEffect(Deferred.fail(deferred, error)), _sink.fail(error)),\n      onSuccess: ([z, leftovers]) => {\n        const loop = core.readWithCause({\n          onInput: elements => core.flatMap(core.fromEffect(Handoff.offer(handoff, {\n            _tag: OP_EMIT,\n            elements\n          })), () => loop),\n          onFailure: cause => channel.zipRight(core.fromEffect(Handoff.offer(handoff, {\n            _tag: OP_HALT,\n            cause\n          })), core.failCause(cause)),\n          onDone: _ => channel.zipRight(core.fromEffect(Handoff.offer(handoff, {\n            _tag: OP_END\n          })), core.void)\n        });\n        return _sink.fromChannel(pipe(core.fromEffect(Deferred.succeed(deferred, z)), channel.zipRight(core.fromEffect(pipe(handoff, Handoff.offer({\n          _tag: OP_EMIT,\n          elements: leftovers\n        })))), channel.zipRight(loop)));\n      }\n    });\n    const producer = pipe(Handoff.take(handoff), Effect.map(signal => {\n      switch (signal._tag) {\n        case OP_EMIT:\n          {\n            return pipe(core.write(signal.elements), core.flatMap(() => producer));\n          }\n        case OP_HALT:\n          {\n            return core.failCause(signal.cause);\n          }\n        case OP_END:\n          {\n            return core.void;\n          }\n      }\n    }), channel.unwrap);\n    return pipe(self, tapErrorCause(cause => Deferred.failCause(deferred, cause)), run(consumer), Effect.forkScoped, Effect.zipRight(Deferred.await(deferred)), Effect.map(z => [z, new StreamImpl(producer)]));\n  }))), Effect.flatten);\n});\n/** @internal */\nexport const partition = /*#__PURE__*/dual(args => typeof args[1] === \"function\", (self, predicate, options) => partitionEither(self, a => Effect.succeed(predicate(a) ? Either.left(a) : Either.right(a)), options));\n/** @internal */\nexport const partitionEither = /*#__PURE__*/dual(args => typeof args[1] === \"function\", (self, predicate, options) => pipe(mapEffectSequential(self, predicate), distributedWith({\n  size: 2,\n  maximumLag: options?.bufferSize ?? 16,\n  decide: Either.match({\n    onLeft: () => Effect.succeed(n => n === 0),\n    onRight: () => Effect.succeed(n => n === 1)\n  })\n}), Effect.flatMap(([queue1, queue2]) => Effect.succeed([filterMap(flattenExitOption(fromQueue(queue1, {\n  shutdown: true\n})), _ => Either.match(_, {\n  onLeft: Option.some,\n  onRight: Option.none\n})), filterMap(flattenExitOption(fromQueue(queue2, {\n  shutdown: true\n})), _ => Either.match(_, {\n  onLeft: Option.none,\n  onRight: Option.some\n}))]))));\n/** @internal */\nexport const pipeThrough = /*#__PURE__*/dual(2, (self, sink) => new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(_sink.toChannel(sink)))));\n/** @internal */\nexport const pipeThroughChannel = /*#__PURE__*/dual(2, (self, channel) => new StreamImpl(core.pipeTo(toChannel(self), channel)));\n/** @internal */\nexport const pipeThroughChannelOrFail = /*#__PURE__*/dual(2, (self, chan) => new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(chan))));\n/** @internal */\nexport const prepend = /*#__PURE__*/dual(2, (self, values) => new StreamImpl(channel.zipRight(core.write(values), toChannel(self))));\n/** @internal */\nexport const provideContext = /*#__PURE__*/dual(2, (self, context) => new StreamImpl(pipe(toChannel(self), core.provideContext(context))));\n/** @internal */\nexport const provideLayer = /*#__PURE__*/dual(2, (self, layer) => new StreamImpl(channel.unwrapScoped(pipe(Layer.build(layer), Effect.map(env => pipe(toChannel(self), core.provideContext(env)))))));\n/** @internal */\nexport const provideService = /*#__PURE__*/dual(3, (self, tag, resource) => provideServiceEffect(self, tag, Effect.succeed(resource)));\n/** @internal */\nexport const provideServiceEffect = /*#__PURE__*/dual(3, (self, tag, effect) => provideServiceStream(self, tag, fromEffect(effect)));\n/** @internal */\nexport const provideServiceStream = /*#__PURE__*/dual(3, (self, tag, stream) => contextWithStream(env => flatMap(stream, service => pipe(self, provideContext(Context.add(env, tag, service))))));\n/** @internal */\nexport const mapInputContext = /*#__PURE__*/dual(2, (self, f) => contextWithStream(env => pipe(self, provideContext(f(env)))));\n/** @internal */\nexport const provideSomeLayer = /*#__PURE__*/dual(2, (self, layer) =>\n// @ts-expect-error\npipe(self, provideLayer(pipe(Layer.context(), Layer.merge(layer)))));\n/** @internal */\nexport const range = (min, max, chunkSize = DefaultChunkSize) => suspend(() => {\n  if (min > max) {\n    return empty;\n  }\n  const go = (min, max, chunkSize) => {\n    const remaining = max - min + 1;\n    if (remaining > chunkSize) {\n      return pipe(core.write(Chunk.range(min, min + chunkSize - 1)), core.flatMap(() => go(min + chunkSize, max, chunkSize)));\n    }\n    return core.write(Chunk.range(min, min + remaining - 1));\n  };\n  return new StreamImpl(go(min, max, chunkSize));\n});\nexport const raceAll = (...streams) => Deferred.make().pipe(Effect.map(halt => {\n  let winner = null;\n  return mergeAll(streams.map((stream, index) => stream.pipe(takeWhile(() => {\n    if (winner === null) {\n      winner = index;\n      Deferred.unsafeDone(halt, Exit.void);\n      return true;\n    }\n    return winner === index;\n  }), interruptWhen(Deferred.await(halt).pipe(Effect.flatMap(() => winner === index ? Effect.never : Effect.void))))), {\n    concurrency: streams.length\n  });\n}), unwrap);\n/** @internal */\nexport const rechunk = /*#__PURE__*/dual(2, (self, n) => suspend(() => {\n  const target = Math.max(n, 1);\n  const process = rechunkProcess(new StreamRechunker(target), target);\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(process)));\n}));\n/** @internal */\nconst rechunkProcess = (rechunker, target) => core.readWithCause({\n  onInput: chunk => {\n    if (chunk.length === target && rechunker.isEmpty()) {\n      return core.flatMap(core.write(chunk), () => rechunkProcess(rechunker, target));\n    }\n    if (chunk.length > 0) {\n      const chunks = [];\n      let result = undefined;\n      let index = 0;\n      while (index < chunk.length) {\n        while (index < chunk.length && result === undefined) {\n          result = rechunker.write(pipe(chunk, Chunk.unsafeGet(index)));\n          index = index + 1;\n        }\n        if (result !== undefined) {\n          chunks.push(result);\n          result = undefined;\n        }\n      }\n      return core.flatMap(channel.writeAll(...chunks), () => rechunkProcess(rechunker, target));\n    }\n    return core.suspend(() => rechunkProcess(rechunker, target));\n  },\n  onFailure: cause => channel.zipRight(rechunker.emitIfNotEmpty(), core.failCause(cause)),\n  onDone: () => rechunker.emitIfNotEmpty()\n});\nclass StreamRechunker {\n  n;\n  builder = [];\n  pos = 0;\n  constructor(n) {\n    this.n = n;\n  }\n  isEmpty() {\n    return this.pos === 0;\n  }\n  write(elem) {\n    this.builder.push(elem);\n    this.pos += 1;\n    if (this.pos === this.n) {\n      const result = Chunk.unsafeFromArray(this.builder);\n      this.builder = [];\n      this.pos = 0;\n      return result;\n    }\n    return undefined;\n  }\n  emitIfNotEmpty() {\n    if (this.pos !== 0) {\n      return core.write(Chunk.unsafeFromArray(this.builder));\n    }\n    return core.void;\n  }\n}\n/** @internal */\nexport const refineOrDie = /*#__PURE__*/dual(2, (self, pf) => pipe(self, refineOrDieWith(pf, identity)));\n/** @internal */\nexport const refineOrDieWith = /*#__PURE__*/dual(3, (self, pf, f) => new StreamImpl(channel.catchAll(toChannel(self), error => Option.match(pf(error), {\n  onNone: () => core.failCause(Cause.die(f(error))),\n  onSome: core.fail\n}))));\n/** @internal */\nexport const repeat = /*#__PURE__*/dual(2, (self, schedule) => filterMap(repeatEither(self, schedule), _ => Either.match(_, {\n  onLeft: Option.none,\n  onRight: Option.some\n})));\n/** @internal */\nexport const repeatEffect = effect => repeatEffectOption(pipe(effect, Effect.mapError(Option.some)));\n/** @internal */\nexport const repeatEffectChunk = effect => repeatEffectChunkOption(pipe(effect, Effect.mapError(Option.some)));\n/** @internal */\nexport const repeatEffectChunkOption = effect => unfoldChunkEffect(effect, effect => pipe(Effect.map(effect, chunk => Option.some([chunk, effect])), Effect.catchAll(Option.match({\n  onNone: () => Effect.succeed(Option.none()),\n  onSome: Effect.fail\n}))));\n/** @internal */\nexport const repeatEffectOption = effect => repeatEffectChunkOption(pipe(effect, Effect.map(Chunk.of)));\n/** @internal */\nexport const repeatEither = /*#__PURE__*/dual(2, (self, schedule) => repeatWith(self, schedule, {\n  onElement: a => Either.right(a),\n  onSchedule: Either.left\n}));\n/** @internal */\nexport const repeatElements = /*#__PURE__*/dual(2, (self, schedule) => filterMap(repeatElementsWith(self, schedule, {\n  onElement: a => Option.some(a),\n  onSchedule: Option.none\n}), identity));\n/** @internal */\nexport const repeatElementsWith = /*#__PURE__*/dual(3, (self, schedule, options) => {\n  const driver = pipe(Schedule.driver(schedule), Effect.map(driver => {\n    const feed = input => Option.match(Chunk.head(input), {\n      onNone: () => loop,\n      onSome: a => channel.zipRight(core.write(Chunk.of(options.onElement(a))), step(pipe(input, Chunk.drop(1)), a))\n    });\n    const step = (input, a) => {\n      const advance = pipe(driver.next(a), Effect.as(pipe(core.write(Chunk.of(options.onElement(a))), core.flatMap(() => step(input, a)))));\n      const reset = pipe(driver.last, Effect.orDie, Effect.flatMap(b => pipe(driver.reset, Effect.map(() => pipe(core.write(Chunk.of(options.onSchedule(b))), channel.zipRight(feed(input)))))));\n      return pipe(advance, Effect.orElse(() => reset), channel.unwrap);\n    };\n    const loop = core.readWith({\n      onInput: feed,\n      onFailure: core.fail,\n      onDone: () => core.void\n    });\n    return loop;\n  }), channel.unwrap);\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(driver)));\n});\n/** @internal */\nexport const repeatValue = value => new StreamImpl(channel.repeated(core.write(Chunk.of(value))));\n/** @internal */\nexport const repeatWith = /*#__PURE__*/dual(3, (self, schedule, options) => {\n  return pipe(Schedule.driver(schedule), Effect.map(driver => {\n    const scheduleOutput = pipe(driver.last, Effect.orDie, Effect.map(options.onSchedule));\n    const process = pipe(self, map(options.onElement), toChannel);\n    const loop = channel.unwrap(Effect.match(driver.next(void 0), {\n      onFailure: () => core.void,\n      onSuccess: () => pipe(process, channel.zipRight(pipe(scheduleOutput, Effect.map(c => pipe(core.write(Chunk.of(c)), core.flatMap(() => loop))), channel.unwrap)))\n    }));\n    return new StreamImpl(pipe(process, channel.zipRight(loop)));\n  }), unwrap);\n});\nconst repeatWithSchedule = (value, schedule) => repeatEffectWithSchedule(Effect.succeed(value), schedule);\n/** @internal */\nexport const repeatEffectWithSchedule = (effect, schedule) => flatMap(fromEffect(Effect.zip(effect, Schedule.driver(schedule))), ([a, driver]) => concat(succeed(a), unfoldEffect(a, s => Effect.matchEffect(driver.next(s), {\n  onFailure: Effect.succeed,\n  onSuccess: () => Effect.map(effect, nextA => Option.some([nextA, nextA]))\n}))));\n/** @internal */\nexport const retry = /*#__PURE__*/dual(2, (self, schedule) => unwrap(Effect.map(Schedule.driver(schedule), driver => {\n  const loop = catchAll(self, error => unwrap(Effect.matchEffect(driver.next(error), {\n    onFailure: () => Effect.fail(error),\n    onSuccess: () => Effect.succeed(pipe(loop, tap(() => driver.reset)))\n  })));\n  return loop;\n})));\n/** @internal */\nexport const run = /*#__PURE__*/dual(2, (self, sink) => pipe(toChannel(self), channel.pipeToOrFail(_sink.toChannel(sink)), channel.runDrain));\n/** @internal */\nexport const runCollect = self => pipe(self, run(_sink.collectAll()));\n/** @internal */\nexport const runCount = self => pipe(self, run(_sink.count));\n/** @internal */\nexport const runDrain = self => pipe(self, run(_sink.drain));\n/** @internal */\nexport const runFold = /*#__PURE__*/dual(3, (self, s, f) => pipe(self, runFoldWhileScoped(s, constTrue, f), Effect.scoped));\n/** @internal */\nexport const runFoldEffect = /*#__PURE__*/dual(3, (self, s, f) => pipe(self, runFoldWhileScopedEffect(s, constTrue, f), Effect.scoped));\n/** @internal */\nexport const runFoldScoped = /*#__PURE__*/dual(3, (self, s, f) => pipe(self, runFoldWhileScoped(s, constTrue, f)));\n/** @internal */\nexport const runFoldScopedEffect = /*#__PURE__*/dual(3, (self, s, f) => pipe(self, runFoldWhileScopedEffect(s, constTrue, f)));\n/** @internal */\nexport const runFoldWhile = /*#__PURE__*/dual(4, (self, s, cont, f) => pipe(self, runFoldWhileScoped(s, cont, f), Effect.scoped));\n/** @internal */\nexport const runFoldWhileEffect = /*#__PURE__*/dual(4, (self, s, cont, f) => pipe(self, runFoldWhileScopedEffect(s, cont, f), Effect.scoped));\n/** @internal */\nexport const runFoldWhileScoped = /*#__PURE__*/dual(4, (self, s, cont, f) => pipe(self, runScoped(_sink.fold(s, cont, f))));\n/** @internal */\nexport const runFoldWhileScopedEffect = /*#__PURE__*/dual(4, (self, s, cont, f) => pipe(self, runScoped(_sink.foldEffect(s, cont, f))));\n/** @internal */\nexport const runForEach = /*#__PURE__*/dual(2, (self, f) => pipe(self, run(_sink.forEach(f))));\n/** @internal */\nexport const runForEachChunk = /*#__PURE__*/dual(2, (self, f) => pipe(self, run(_sink.forEachChunk(f))));\n/** @internal */\nexport const runForEachChunkScoped = /*#__PURE__*/dual(2, (self, f) => pipe(self, runScoped(_sink.forEachChunk(f))));\n/** @internal */\nexport const runForEachScoped = /*#__PURE__*/dual(2, (self, f) => pipe(self, runScoped(_sink.forEach(f))));\n/** @internal */\nexport const runForEachWhile = /*#__PURE__*/dual(2, (self, f) => pipe(self, run(_sink.forEachWhile(f))));\n/** @internal */\nexport const runForEachWhileScoped = /*#__PURE__*/dual(2, (self, f) => pipe(self, runScoped(_sink.forEachWhile(f))));\n/** @internal */\nexport const runHead = self => pipe(self, run(_sink.head()));\n/** @internal */\nexport const runIntoPubSub = /*#__PURE__*/dual(2, (self, pubsub) => pipe(self, runIntoQueue(pubsub)));\n/** @internal */\nexport const runIntoPubSubScoped = /*#__PURE__*/dual(2, (self, pubsub) => pipe(self, runIntoQueueScoped(pubsub)));\n/** @internal */\nexport const runIntoQueue = /*#__PURE__*/dual(2, (self, queue) => pipe(self, runIntoQueueScoped(queue), Effect.scoped));\n/** @internal */\nexport const runIntoQueueElementsScoped = /*#__PURE__*/dual(2, (self, queue) => {\n  const writer = core.readWithCause({\n    onInput: input => core.flatMap(core.fromEffect(Queue.offerAll(queue, Chunk.map(input, Exit.succeed))), () => writer),\n    onFailure: cause => core.fromEffect(Queue.offer(queue, Exit.failCause(Cause.map(cause, Option.some)))),\n    onDone: () => core.fromEffect(Queue.offer(queue, Exit.fail(Option.none())))\n  });\n  return pipe(core.pipeTo(toChannel(self), writer), channel.drain, channelExecutor.runScoped, Effect.asVoid);\n});\n/** @internal */\nexport const runIntoQueueScoped = /*#__PURE__*/dual(2, (self, queue) => {\n  const writer = core.readWithCause({\n    onInput: input => core.flatMap(core.write(InternalTake.chunk(input)), () => writer),\n    onFailure: cause => core.write(InternalTake.failCause(cause)),\n    onDone: () => core.write(InternalTake.end)\n  });\n  return pipe(core.pipeTo(toChannel(self), writer), channel.mapOutEffect(take => Queue.offer(queue, take)), channel.drain, channelExecutor.runScoped, Effect.asVoid);\n});\n/** @internal */\nexport const runLast = self => pipe(self, run(_sink.last()));\n/** @internal */\nexport const runScoped = /*#__PURE__*/dual(2, (self, sink) => pipe(toChannel(self), channel.pipeToOrFail(_sink.toChannel(sink)), channel.drain, channelExecutor.runScoped));\n/** @internal */\nexport const runSum = self => pipe(self, run(_sink.sum));\n/** @internal */\nexport const scan = /*#__PURE__*/dual(3, (self, s, f) => pipe(self, scanEffect(s, (s, a) => Effect.succeed(f(s, a)))));\n/** @internal */\nexport const scanReduce = /*#__PURE__*/dual(2, (self, f) => pipe(self, scanReduceEffect((a2, a) => Effect.succeed(f(a2, a)))));\n/** @internal */\nexport const scanReduceEffect = /*#__PURE__*/dual(2, (self, f) => pipe(self, mapAccumEffect(Option.none(), (option, a) => {\n  switch (option._tag) {\n    case \"None\":\n      {\n        return Effect.succeed([Option.some(a), a]);\n      }\n    case \"Some\":\n      {\n        return pipe(f(option.value, a), Effect.map(b => [Option.some(b), b]));\n      }\n  }\n})));\n/** @internal */\nexport const schedule = /*#__PURE__*/dual(2, (self, schedule) => filterMap(scheduleWith(self, schedule, {\n  onElement: Option.some,\n  onSchedule: Option.none\n}), identity));\n/** @internal */\nexport const scheduleWith = /*#__PURE__*/dual(3, (self, schedule, options) => {\n  const loop = (driver, iterator) => {\n    const next = iterator.next();\n    if (next.done) {\n      return core.readWithCause({\n        onInput: chunk => loop(driver, chunk[Symbol.iterator]()),\n        onFailure: core.failCause,\n        onDone: core.succeedNow\n      });\n    }\n    return channel.unwrap(Effect.matchEffect(driver.next(next.value), {\n      onFailure: () => pipe(driver.last, Effect.orDie, Effect.map(b => pipe(core.write(Chunk.make(options.onElement(next.value), options.onSchedule(b))), core.flatMap(() => loop(driver, iterator)))), Effect.zipLeft(driver.reset)),\n      onSuccess: () => Effect.succeed(pipe(core.write(Chunk.of(options.onElement(next.value))), core.flatMap(() => loop(driver, iterator))))\n    }));\n  };\n  return new StreamImpl(pipe(core.fromEffect(Schedule.driver(schedule)), core.flatMap(driver => pipe(toChannel(self), core.pipeTo(loop(driver, Chunk.empty()[Symbol.iterator]()))))));\n});\n/** @internal */\nexport const scanEffect = /*#__PURE__*/dual(3, (self, s, f) => new StreamImpl(pipe(core.write(Chunk.of(s)), core.flatMap(() => toChannel(pipe(self, mapAccumEffect(s, (s, a) => pipe(f(s, a), Effect.map(s => [s, s])))))))));\n/** @internal */\nexport const scoped = effect => new StreamImpl(channel.ensuring(channel.scoped(pipe(effect, Effect.map(Chunk.of))), Effect.void));\n/** @internal */\nexport const some = self => pipe(self, mapError(Option.some), someOrFail(() => Option.none()));\n/** @internal */\nexport const someOrElse = /*#__PURE__*/dual(2, (self, fallback) => pipe(self, map(Option.getOrElse(fallback))));\n/** @internal */\nexport const someOrFail = /*#__PURE__*/dual(2, (self, error) => mapEffectSequential(self, Option.match({\n  onNone: () => Effect.failSync(error),\n  onSome: Effect.succeed\n})));\n/** @internal */\nexport const sliding = /*#__PURE__*/dual(2, (self, chunkSize) => slidingSize(self, chunkSize, 1));\n/** @internal */\nexport const slidingSize = /*#__PURE__*/dual(3, (self, chunkSize, stepSize) => {\n  if (chunkSize <= 0 || stepSize <= 0) {\n    return die(new Cause.IllegalArgumentException(\"Invalid bounds - `chunkSize` and `stepSize` must be greater than zero\"));\n  }\n  return new StreamImpl(core.suspend(() => {\n    const queue = new RingBuffer(chunkSize);\n    const emitOnStreamEnd = (queueSize, channelEnd) => {\n      if (queueSize < chunkSize) {\n        const items = queue.toChunk();\n        const result = Chunk.isEmpty(items) ? Chunk.empty() : Chunk.of(items);\n        return pipe(core.write(result), core.flatMap(() => channelEnd));\n      }\n      const lastEmitIndex = queueSize - (queueSize - chunkSize) % stepSize;\n      if (lastEmitIndex === queueSize) {\n        return channelEnd;\n      }\n      const leftovers = queueSize - (lastEmitIndex - chunkSize + stepSize);\n      const lastItems = pipe(queue.toChunk(), Chunk.takeRight(leftovers));\n      const result = Chunk.isEmpty(lastItems) ? Chunk.empty() : Chunk.of(lastItems);\n      return pipe(core.write(result), core.flatMap(() => channelEnd));\n    };\n    const reader = queueSize => core.readWithCause({\n      onInput: input => core.flatMap(core.write(Chunk.filterMap(input, (element, index) => {\n        queue.put(element);\n        const currentIndex = queueSize + index + 1;\n        if (currentIndex < chunkSize || (currentIndex - chunkSize) % stepSize > 0) {\n          return Option.none();\n        }\n        return Option.some(queue.toChunk());\n      })), () => reader(queueSize + input.length)),\n      onFailure: cause => emitOnStreamEnd(queueSize, core.failCause(cause)),\n      onDone: () => emitOnStreamEnd(queueSize, core.void)\n    });\n    return pipe(toChannel(self), core.pipeTo(reader(0)));\n  }));\n});\n/** @internal */\nexport const split = /*#__PURE__*/dual(2, (self, predicate) => {\n  const split = (leftovers, input) => {\n    const [chunk, remaining] = pipe(leftovers, Chunk.appendAll(input), Chunk.splitWhere(predicate));\n    if (Chunk.isEmpty(chunk) || Chunk.isEmpty(remaining)) {\n      return loop(pipe(chunk, Chunk.appendAll(pipe(remaining, Chunk.drop(1)))));\n    }\n    return pipe(core.write(Chunk.of(chunk)), core.flatMap(() => split(Chunk.empty(), pipe(remaining, Chunk.drop(1)))));\n  };\n  const loop = leftovers => core.readWith({\n    onInput: input => split(leftovers, input),\n    onFailure: core.fail,\n    onDone: () => {\n      if (Chunk.isEmpty(leftovers)) {\n        return core.void;\n      }\n      if (Option.isNone(pipe(leftovers, Chunk.findFirst(predicate)))) {\n        return channel.zipRight(core.write(Chunk.of(leftovers)), core.void);\n      }\n      return channel.zipRight(split(Chunk.empty(), leftovers), core.void);\n    }\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(loop(Chunk.empty()))));\n});\n/** @internal */\nexport const splitOnChunk = /*#__PURE__*/dual(2, (self, delimiter) => {\n  const next = (leftover, delimiterIndex) => core.readWithCause({\n    onInput: inputChunk => {\n      let buffer;\n      const [carry, delimiterCursor] = pipe(inputChunk, Chunk.reduce([pipe(leftover, Option.getOrElse(() => Chunk.empty())), delimiterIndex], ([carry, delimiterCursor], a) => {\n        const concatenated = pipe(carry, Chunk.append(a));\n        if (delimiterCursor < delimiter.length && Equal.equals(a, pipe(delimiter, Chunk.unsafeGet(delimiterCursor)))) {\n          if (delimiterCursor + 1 === delimiter.length) {\n            if (buffer === undefined) {\n              buffer = [];\n            }\n            buffer.push(pipe(concatenated, Chunk.take(concatenated.length - delimiter.length)));\n            return [Chunk.empty(), 0];\n          }\n          return [concatenated, delimiterCursor + 1];\n        }\n        return [concatenated, Equal.equals(a, pipe(delimiter, Chunk.unsafeGet(0))) ? 1 : 0];\n      }));\n      const output = buffer === undefined ? Chunk.empty() : Chunk.unsafeFromArray(buffer);\n      return core.flatMap(core.write(output), () => next(Chunk.isNonEmpty(carry) ? Option.some(carry) : Option.none(), delimiterCursor));\n    },\n    onFailure: cause => Option.match(leftover, {\n      onNone: () => core.failCause(cause),\n      onSome: chunk => channel.zipRight(core.write(Chunk.of(chunk)), core.failCause(cause))\n    }),\n    onDone: done => Option.match(leftover, {\n      onNone: () => core.succeed(done),\n      onSome: chunk => channel.zipRight(core.write(Chunk.of(chunk)), core.succeed(done))\n    })\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(next(Option.none(), 0))));\n});\n/** @internal */\nexport const splitLines = self => pipeThroughChannel(self, channel.splitLines());\n/** @internal */\nexport const succeed = value => fromChunk(Chunk.of(value));\n/** @internal */\nexport const sync = evaluate => suspend(() => fromChunk(Chunk.of(evaluate())));\n/** @internal */\nexport const suspend = stream => new StreamImpl(core.suspend(() => toChannel(stream())));\n/** @internal */\nexport const take = /*#__PURE__*/dual(2, (self, n) => {\n  if (!Number.isInteger(n)) {\n    return die(new Cause.IllegalArgumentException(`${n} must be an integer`));\n  }\n  const loop = n => core.readWith({\n    onInput: input => {\n      const taken = pipe(input, Chunk.take(Math.min(n, Number.POSITIVE_INFINITY)));\n      const leftover = Math.max(0, n - taken.length);\n      const more = leftover > 0;\n      if (more) {\n        return pipe(core.write(taken), core.flatMap(() => loop(leftover)));\n      }\n      return core.write(taken);\n    },\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(0 < n ? loop(n) : core.void)));\n});\n/** @internal */\nexport const takeRight = /*#__PURE__*/dual(2, (self, n) => {\n  if (n <= 0) {\n    return empty;\n  }\n  return new StreamImpl(pipe(Effect.succeed(new RingBuffer(n)), Effect.map(queue => {\n    const reader = core.readWith({\n      onInput: input => {\n        for (const element of input) {\n          queue.put(element);\n        }\n        return reader;\n      },\n      onFailure: core.fail,\n      onDone: () => pipe(core.write(queue.toChunk()), channel.zipRight(core.void))\n    });\n    return pipe(toChannel(self), core.pipeTo(reader));\n  }), channel.unwrap));\n});\n/** @internal */\nexport const takeUntil = /*#__PURE__*/dual(2, (self, predicate) => {\n  const loop = core.readWith({\n    onInput: input => {\n      const taken = pipe(input, Chunk.takeWhile(a => !predicate(a)));\n      const last = pipe(input, Chunk.drop(taken.length), Chunk.take(1));\n      if (Chunk.isEmpty(last)) {\n        return pipe(core.write(taken), core.flatMap(() => loop));\n      }\n      return core.write(pipe(taken, Chunk.appendAll(last)));\n    },\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(loop)));\n});\n/** @internal */\nexport const takeUntilEffect = /*#__PURE__*/dual(2, (self, predicate) => {\n  const loop = iterator => {\n    const next = iterator.next();\n    if (next.done) {\n      return core.readWithCause({\n        onInput: elem => loop(elem[Symbol.iterator]()),\n        onFailure: core.failCause,\n        onDone: core.succeed\n      });\n    }\n    return pipe(predicate(next.value), Effect.map(bool => bool ? core.write(Chunk.of(next.value)) : pipe(core.write(Chunk.of(next.value)), core.flatMap(() => loop(iterator)))), channel.unwrap);\n  };\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(loop(Chunk.empty()[Symbol.iterator]()))));\n});\n/** @internal */\nexport const takeWhile = /*#__PURE__*/dual(2, (self, predicate) => {\n  const loop = core.readWith({\n    onInput: input => {\n      const taken = pipe(input, Chunk.takeWhile(predicate));\n      const more = taken.length === input.length;\n      if (more) {\n        return pipe(core.write(taken), core.flatMap(() => loop));\n      }\n      return core.write(taken);\n    },\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(loop)));\n});\n/** @internal */\nexport const tap = /*#__PURE__*/dual(2, (self, f) => mapEffectSequential(self, a => Effect.as(f(a), a)));\n/** @internal */\nexport const tapBoth = /*#__PURE__*/dual(2, (self, options) => pipe(self, tapError(options.onFailure), tap(options.onSuccess)));\n/** @internal */\nexport const tapError = /*#__PURE__*/dual(2, (self, f) => catchAll(self, error => fromEffect(Effect.zipRight(f(error), Effect.fail(error)))));\n/** @internal */\nexport const tapErrorCause = /*#__PURE__*/dual(2, (self, f) => {\n  const loop = core.readWithCause({\n    onInput: chunk => core.flatMap(core.write(chunk), () => loop),\n    onFailure: cause => core.fromEffect(Effect.zipRight(f(cause), Effect.failCause(cause))),\n    onDone: core.succeedNow\n  });\n  return new StreamImpl(pipe(toChannel(self), core.pipeTo(loop)));\n});\n/** @internal */\nexport const tapSink = /*#__PURE__*/dual(2, (self, sink) => pipe(fromEffect(Effect.all([Queue.bounded(1), Deferred.make()])), flatMap(([queue, deferred]) => {\n  const right = flattenTake(fromQueue(queue, {\n    maxChunkSize: 1\n  }));\n  const loop = core.readWithCause({\n    onInput: chunk => pipe(core.fromEffect(Queue.offer(queue, InternalTake.chunk(chunk))), core.foldCauseChannel({\n      onFailure: () => core.flatMap(core.write(chunk), () => channel.identityChannel()),\n      onSuccess: () => core.flatMap(core.write(chunk), () => loop)\n    })),\n    onFailure: cause => pipe(core.fromEffect(Queue.offer(queue, InternalTake.failCause(cause))), core.foldCauseChannel({\n      onFailure: () => core.failCause(cause),\n      onSuccess: () => core.failCause(cause)\n    })),\n    onDone: () => pipe(core.fromEffect(Queue.offer(queue, InternalTake.end)), core.foldCauseChannel({\n      onFailure: () => core.void,\n      onSuccess: () => core.void\n    }))\n  });\n  return pipe(new StreamImpl(pipe(core.pipeTo(toChannel(self), loop), channel.ensuring(Effect.zipRight(Effect.forkDaemon(Queue.offer(queue, InternalTake.end)), Deferred.await(deferred))))), merge(execute(pipe(run(right, sink), Effect.ensuring(Effect.zipRight(Queue.shutdown(queue), Deferred.succeed(deferred, void 0)))))));\n})));\n/** @internal */\nexport const throttle = /*#__PURE__*/dual(2, (self, options) => throttleEffect(self, {\n  ...options,\n  cost: chunk => Effect.succeed(options.cost(chunk))\n}));\n/** @internal */\nexport const throttleEffect = /*#__PURE__*/dual(2, (self, options) => {\n  if (options.strategy === \"enforce\") {\n    return throttleEnforceEffect(self, options.cost, options.units, options.duration, options.burst ?? 0);\n  }\n  return throttleShapeEffect(self, options.cost, options.units, options.duration, options.burst ?? 0);\n});\nconst throttleEnforceEffect = (self, cost, units, duration, burst) => {\n  const loop = (tokens, timestampMillis) => core.readWithCause({\n    onInput: input => pipe(cost(input), Effect.zip(Clock.currentTimeMillis), Effect.map(([weight, currentTimeMillis]) => {\n      const elapsed = currentTimeMillis - timestampMillis;\n      const cycles = elapsed / Duration.toMillis(duration);\n      const sum = tokens + cycles * units;\n      const max = units + burst < 0 ? Number.POSITIVE_INFINITY : units + burst;\n      const available = sum < 0 ? max : Math.min(sum, max);\n      if (weight <= available) {\n        return pipe(core.write(input), core.flatMap(() => loop(available - weight, currentTimeMillis)));\n      }\n      return loop(tokens, timestampMillis);\n    }), channel.unwrap),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  const throttled = pipe(Clock.currentTimeMillis, Effect.map(currentTimeMillis => loop(units, currentTimeMillis)), channel.unwrap);\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(throttled)));\n};\nconst throttleShapeEffect = (self, costFn, units, duration, burst) => {\n  const loop = (tokens, timestampMillis) => core.readWithCause({\n    onInput: input => pipe(costFn(input), Effect.zip(Clock.currentTimeMillis), Effect.map(([weight, currentTimeMillis]) => {\n      const elapsed = currentTimeMillis - timestampMillis;\n      const cycles = elapsed / Duration.toMillis(duration);\n      const sum = tokens + cycles * units;\n      const max = units + burst < 0 ? Number.POSITIVE_INFINITY : units + burst;\n      const available = sum < 0 ? max : Math.min(sum, max);\n      const remaining = available - weight;\n      const waitCycles = remaining >= 0 ? 0 : -remaining / units;\n      const delay = Duration.millis(Math.max(0, waitCycles * Duration.toMillis(duration)));\n      if (Duration.greaterThan(delay, Duration.zero)) {\n        return pipe(core.fromEffect(Clock.sleep(delay)), channel.zipRight(core.write(input)), core.flatMap(() => loop(remaining, currentTimeMillis)));\n      }\n      return core.flatMap(core.write(input), () => loop(remaining, currentTimeMillis));\n    }), channel.unwrap),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  const throttled = pipe(Clock.currentTimeMillis, Effect.map(currentTimeMillis => loop(units, currentTimeMillis)), channel.unwrap);\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(throttled)));\n};\n/** @internal */\nexport const tick = interval => repeatWithSchedule(void 0, Schedule.spaced(interval));\n/** @internal */\nexport const timeout = /*#__PURE__*/dual(2, (self, duration) => pipe(toPull(self), Effect.map(Effect.timeoutFail({\n  onTimeout: () => Option.none(),\n  duration\n})), fromPull));\n/** @internal */\nexport const timeoutFail = /*#__PURE__*/dual(3, (self, error, duration) => pipe(self, timeoutTo(duration, failSync(error))));\n/** @internal */\nexport const timeoutFailCause = /*#__PURE__*/dual(3, (self, cause, duration) => pipe(toPull(self), Effect.map(Effect.timeoutFailCause({\n  onTimeout: () => Cause.map(cause(), Option.some),\n  duration\n})), fromPull));\n/** @internal */\nexport const timeoutTo = /*#__PURE__*/dual(3, (self, duration, that) => {\n  const StreamTimeout = new Cause.RuntimeException(\"Stream Timeout\");\n  return pipe(self, timeoutFailCause(() => Cause.die(StreamTimeout), duration), catchSomeCause(cause => Cause.isDieType(cause) && Cause.isRuntimeException(cause.defect) && cause.defect.message !== undefined && cause.defect.message === \"Stream Timeout\" ? Option.some(that) : Option.none()));\n});\nconst pubsubFromOptions = options => {\n  if (typeof options === \"number\") {\n    return PubSub.bounded(options);\n  } else if (options.capacity === \"unbounded\") {\n    return PubSub.unbounded({\n      replay: options.replay\n    });\n  }\n  switch (options.strategy) {\n    case \"dropping\":\n      return PubSub.dropping(options);\n    case \"sliding\":\n      return PubSub.sliding(options);\n    default:\n      return PubSub.bounded(options);\n  }\n};\n/** @internal */\nexport const toPubSub = /*#__PURE__*/dual(2, (self, capacity) => pipe(Effect.acquireRelease(pubsubFromOptions(capacity), pubsub => PubSub.shutdown(pubsub)), Effect.tap(pubsub => pipe(self, runIntoPubSubScoped(pubsub), Effect.forkScoped))));\n/** @internal */\nexport const toPull = self => Effect.map(channel.toPull(toChannel(self)), pull => pipe(pull, Effect.mapError(Option.some), Effect.flatMap(Either.match({\n  onLeft: () => Effect.fail(Option.none()),\n  onRight: Effect.succeed\n}))));\n/** @internal */\nexport const toQueue = /*#__PURE__*/dual(args => isStream(args[0]), (self, options) => Effect.tap(Effect.acquireRelease(options?.strategy === \"unbounded\" ? Queue.unbounded() : options?.strategy === \"dropping\" ? Queue.dropping(options.capacity ?? 2) : options?.strategy === \"sliding\" ? Queue.sliding(options.capacity ?? 2) : Queue.bounded(options?.capacity ?? 2), queue => Queue.shutdown(queue)), queue => Effect.forkScoped(runIntoQueueScoped(self, queue))));\n/** @internal */\nexport const toQueueOfElements = /*#__PURE__*/dual(args => isStream(args[0]), (self, options) => Effect.tap(Effect.acquireRelease(Queue.bounded(options?.capacity ?? 2), queue => Queue.shutdown(queue)), queue => Effect.forkScoped(runIntoQueueElementsScoped(self, queue))));\n/** @internal */\nexport const toReadableStream = /*#__PURE__*/dual(args => isStream(args[0]), (self, options) => toReadableStreamRuntime(self, Runtime.defaultRuntime, options));\n/** @internal */\nexport const toReadableStreamEffect = /*#__PURE__*/dual(args => isStream(args[0]), (self, options) => Effect.map(Effect.runtime(), runtime => toReadableStreamRuntime(self, runtime, options)));\n/** @internal */\nexport const toReadableStreamRuntime = /*#__PURE__*/dual(args => isStream(args[0]), (self, runtime, options) => {\n  const runSync = Runtime.runSync(runtime);\n  const runFork = Runtime.runFork(runtime);\n  let pull;\n  let scope;\n  return new ReadableStream({\n    start(controller) {\n      scope = runSync(Scope.make());\n      pull = pipe(toPull(self), Scope.extend(scope), runSync, Effect.tap(chunk => Effect.sync(() => {\n        Chunk.map(chunk, a => {\n          controller.enqueue(a);\n        });\n      })), Effect.tapErrorCause(() => Scope.close(scope, Exit.void)), Effect.catchTags({\n        \"None\": () => Effect.sync(() => {\n          controller.close();\n        }),\n        \"Some\": error => Effect.sync(() => {\n          controller.error(error.value);\n        })\n      }), Effect.asVoid);\n    },\n    pull() {\n      return new Promise(resolve => {\n        runFork(pull, {\n          scope\n        }).addObserver(_ => resolve());\n      });\n    },\n    cancel() {\n      return new Promise(resolve => {\n        runFork(Scope.close(scope, Exit.void)).addObserver(_ => resolve());\n      });\n    }\n  }, options?.strategy);\n});\n/** @internal */\nexport const transduce = /*#__PURE__*/dual(2, (self, sink) => {\n  const newChannel = core.suspend(() => {\n    const leftovers = {\n      ref: Chunk.empty()\n    };\n    const upstreamDone = {\n      ref: false\n    };\n    const buffer = core.suspend(() => {\n      const leftover = leftovers.ref;\n      if (Chunk.isEmpty(leftover)) {\n        return core.readWith({\n          onInput: input => pipe(core.write(input), core.flatMap(() => buffer)),\n          onFailure: core.fail,\n          onDone: core.succeedNow\n        });\n      }\n      leftovers.ref = Chunk.empty();\n      return pipe(channel.writeChunk(leftover), core.flatMap(() => buffer));\n    });\n    const concatAndGet = chunk => {\n      const leftover = leftovers.ref;\n      const concatenated = Chunk.appendAll(leftover, Chunk.filter(chunk, chunk => chunk.length !== 0));\n      leftovers.ref = concatenated;\n      return concatenated;\n    };\n    const upstreamMarker = core.readWith({\n      onInput: input => core.flatMap(core.write(input), () => upstreamMarker),\n      onFailure: core.fail,\n      onDone: done => channel.zipRight(core.sync(() => {\n        upstreamDone.ref = true;\n      }), core.succeedNow(done))\n    });\n    const transducer = pipe(sink, _sink.toChannel, core.collectElements, core.flatMap(([leftover, z]) => pipe(core.succeed([upstreamDone.ref, concatAndGet(leftover)]), core.flatMap(([done, newLeftovers]) => {\n      const nextChannel = done && Chunk.isEmpty(newLeftovers) ? core.void : transducer;\n      return pipe(core.write(Chunk.of(z)), core.flatMap(() => nextChannel));\n    }))));\n    return pipe(toChannel(self), core.pipeTo(upstreamMarker), core.pipeTo(buffer), channel.pipeToOrFail(transducer));\n  });\n  return new StreamImpl(newChannel);\n});\n/** @internal */\nexport const unfold = (s, f) => unfoldChunk(s, s => pipe(f(s), Option.map(([a, s]) => [Chunk.of(a), s])));\n/** @internal */\nexport const unfoldChunk = (s, f) => {\n  const loop = s => Option.match(f(s), {\n    onNone: () => core.void,\n    onSome: ([chunk, s]) => core.flatMap(core.write(chunk), () => loop(s))\n  });\n  return new StreamImpl(core.suspend(() => loop(s)));\n};\n/** @internal */\nexport const unfoldChunkEffect = (s, f) => suspend(() => {\n  const loop = s => channel.unwrap(Effect.map(f(s), Option.match({\n    onNone: () => core.void,\n    onSome: ([chunk, s]) => core.flatMap(core.write(chunk), () => loop(s))\n  })));\n  return new StreamImpl(loop(s));\n});\n/** @internal */\nexport const unfoldEffect = (s, f) => unfoldChunkEffect(s, s => pipe(f(s), Effect.map(Option.map(([a, s]) => [Chunk.of(a), s]))));\nconst void_ = /*#__PURE__*/succeed(void 0);\nexport { /** @internal */\nvoid_ as void };\n/** @internal */\nexport const unwrap = effect => flatten(fromEffect(effect));\n/** @internal */\nexport const unwrapScoped = effect => flatten(scoped(effect));\n/** @internal */\nexport const updateService = /*#__PURE__*/dual(3, (self, tag, f) => pipe(self, mapInputContext(context => pipe(context, Context.add(tag, f(pipe(context, Context.unsafeGet(tag))))))));\n/** @internal */\nexport const when = /*#__PURE__*/dual(2, (self, test) => pipe(self, whenEffect(Effect.sync(test))));\n/** @internal */\nexport const whenCase = (evaluate, pf) => whenCaseEffect(pf)(Effect.sync(evaluate));\n/** @internal */\nexport const whenCaseEffect = /*#__PURE__*/dual(2, (self, pf) => pipe(fromEffect(self), flatMap(a => pipe(pf(a), Option.getOrElse(() => empty)))));\n/** @internal */\nexport const whenEffect = /*#__PURE__*/dual(2, (self, effect) => pipe(fromEffect(effect), flatMap(bool => bool ? self : empty)));\n/** @internal */\nexport const withSpan = function () {\n  const dataFirst = typeof arguments[0] !== \"string\";\n  const name = dataFirst ? arguments[1] : arguments[0];\n  const options = InternalTracer.addSpanStackTrace(dataFirst ? arguments[2] : arguments[1]);\n  if (dataFirst) {\n    const self = arguments[0];\n    return new StreamImpl(channel.withSpan(toChannel(self), name, options));\n  }\n  return self => new StreamImpl(channel.withSpan(toChannel(self), name, options));\n};\n/** @internal */\nexport const zip = /*#__PURE__*/dual(2, (self, that) => pipe(self, zipWith(that, (a, a2) => [a, a2])));\n/** @internal */\nexport const zipFlatten = /*#__PURE__*/dual(2, (self, that) => pipe(self, zipWith(that, (a, a2) => [...a, a2])));\n/** @internal */\nexport const zipAll = /*#__PURE__*/dual(2, (self, options) => zipAllWith(self, {\n  other: options.other,\n  onSelf: a => [a, options.defaultOther],\n  onOther: a2 => [options.defaultSelf, a2],\n  onBoth: (a, a2) => [a, a2]\n}));\n/** @internal */\nexport const zipAllLeft = /*#__PURE__*/dual(3, (self, other, defaultSelf) => zipAllWith(self, {\n  other,\n  onSelf: identity,\n  onOther: () => defaultSelf,\n  onBoth: a => a\n}));\n/** @internal */\nexport const zipAllRight = /*#__PURE__*/dual(3, (self, other, defaultRight) => zipAllWith(self, {\n  other,\n  onSelf: () => defaultRight,\n  onOther: identity,\n  onBoth: (_, a2) => a2\n}));\n/** @internal */\nexport const zipAllSortedByKey = /*#__PURE__*/dual(2, (self, options) => zipAllSortedByKeyWith(self, {\n  other: options.other,\n  onSelf: a => [a, options.defaultOther],\n  onOther: a2 => [options.defaultSelf, a2],\n  onBoth: (a, a2) => [a, a2],\n  order: options.order\n}));\n/** @internal */\nexport const zipAllSortedByKeyLeft = /*#__PURE__*/dual(2, (self, options) => zipAllSortedByKeyWith(self, {\n  other: options.other,\n  onSelf: identity,\n  onOther: () => options.defaultSelf,\n  onBoth: a => a,\n  order: options.order\n}));\n/** @internal */\nexport const zipAllSortedByKeyRight = /*#__PURE__*/dual(2, (self, options) => zipAllSortedByKeyWith(self, {\n  other: options.other,\n  onSelf: () => options.defaultOther,\n  onOther: identity,\n  onBoth: (_, a2) => a2,\n  order: options.order\n}));\n/** @internal */\nexport const zipAllSortedByKeyWith = /*#__PURE__*/dual(2, (self, options) => {\n  const pull = (state, pullLeft, pullRight) => {\n    switch (state._tag) {\n      case ZipAllState.OP_DRAIN_LEFT:\n        {\n          return pipe(pullLeft, Effect.match({\n            onFailure: Exit.fail,\n            onSuccess: leftChunk => Exit.succeed([Chunk.map(leftChunk, ([k, a]) => [k, options.onSelf(a)]), ZipAllState.DrainLeft])\n          }));\n        }\n      case ZipAllState.OP_DRAIN_RIGHT:\n        {\n          return pipe(pullRight, Effect.match({\n            onFailure: Exit.fail,\n            onSuccess: rightChunk => Exit.succeed([Chunk.map(rightChunk, ([k, a2]) => [k, options.onOther(a2)]), ZipAllState.DrainRight])\n          }));\n        }\n      case ZipAllState.OP_PULL_BOTH:\n        {\n          return pipe(unsome(pullLeft), Effect.zip(unsome(pullRight), {\n            concurrent: true\n          }), Effect.matchEffect({\n            onFailure: error => Effect.succeed(Exit.fail(Option.some(error))),\n            onSuccess: ([leftOption, rightOption]) => {\n              if (Option.isSome(leftOption) && Option.isSome(rightOption)) {\n                if (Chunk.isEmpty(leftOption.value) && Chunk.isEmpty(rightOption.value)) {\n                  return pull(ZipAllState.PullBoth, pullLeft, pullRight);\n                }\n                if (Chunk.isEmpty(leftOption.value)) {\n                  return pull(ZipAllState.PullLeft(rightOption.value), pullLeft, pullRight);\n                }\n                if (Chunk.isEmpty(rightOption.value)) {\n                  return pull(ZipAllState.PullRight(leftOption.value), pullLeft, pullRight);\n                }\n                return Effect.succeed(Exit.succeed(merge(leftOption.value, rightOption.value)));\n              }\n              if (Option.isSome(leftOption) && Option.isNone(rightOption)) {\n                if (Chunk.isEmpty(leftOption.value)) {\n                  return pull(ZipAllState.DrainLeft, pullLeft, pullRight);\n                }\n                return Effect.succeed(Exit.succeed([pipe(leftOption.value, Chunk.map(([k, a]) => [k, options.onSelf(a)])), ZipAllState.DrainLeft]));\n              }\n              if (Option.isNone(leftOption) && Option.isSome(rightOption)) {\n                if (Chunk.isEmpty(rightOption.value)) {\n                  return pull(ZipAllState.DrainRight, pullLeft, pullRight);\n                }\n                return Effect.succeed(Exit.succeed([pipe(rightOption.value, Chunk.map(([k, a2]) => [k, options.onOther(a2)])), ZipAllState.DrainRight]));\n              }\n              return Effect.succeed(Exit.fail(Option.none()));\n            }\n          }));\n        }\n      case ZipAllState.OP_PULL_LEFT:\n        {\n          return Effect.matchEffect(pullLeft, {\n            onFailure: Option.match({\n              onNone: () => Effect.succeed(Exit.succeed([pipe(state.rightChunk, Chunk.map(([k, a2]) => [k, options.onOther(a2)])), ZipAllState.DrainRight])),\n              onSome: error => Effect.succeed(Exit.fail(Option.some(error)))\n            }),\n            onSuccess: leftChunk => Chunk.isEmpty(leftChunk) ? pull(ZipAllState.PullLeft(state.rightChunk), pullLeft, pullRight) : Effect.succeed(Exit.succeed(merge(leftChunk, state.rightChunk)))\n          });\n        }\n      case ZipAllState.OP_PULL_RIGHT:\n        {\n          return Effect.matchEffect(pullRight, {\n            onFailure: Option.match({\n              onNone: () => Effect.succeed(Exit.succeed([Chunk.map(state.leftChunk, ([k, a]) => [k, options.onSelf(a)]), ZipAllState.DrainLeft])),\n              onSome: error => Effect.succeed(Exit.fail(Option.some(error)))\n            }),\n            onSuccess: rightChunk => Chunk.isEmpty(rightChunk) ? pull(ZipAllState.PullRight(state.leftChunk), pullLeft, pullRight) : Effect.succeed(Exit.succeed(merge(state.leftChunk, rightChunk)))\n          });\n        }\n    }\n  };\n  const merge = (leftChunk, rightChunk) => {\n    const hasNext = (chunk, index) => index < chunk.length - 1;\n    const builder = [];\n    let state = undefined;\n    let leftIndex = 0;\n    let rightIndex = 0;\n    let leftTuple = pipe(leftChunk, Chunk.unsafeGet(leftIndex));\n    let rightTuple = pipe(rightChunk, Chunk.unsafeGet(rightIndex));\n    let k1 = leftTuple[0];\n    let a = leftTuple[1];\n    let k2 = rightTuple[0];\n    let a2 = rightTuple[1];\n    let loop = true;\n    while (loop) {\n      const compare = options.order(k1, k2);\n      if (compare === 0) {\n        builder.push([k1, options.onBoth(a, a2)]);\n        if (hasNext(leftChunk, leftIndex) && hasNext(rightChunk, rightIndex)) {\n          leftIndex = leftIndex + 1;\n          rightIndex = rightIndex + 1;\n          leftTuple = pipe(leftChunk, Chunk.unsafeGet(leftIndex));\n          rightTuple = pipe(rightChunk, Chunk.unsafeGet(rightIndex));\n          k1 = leftTuple[0];\n          a = leftTuple[1];\n          k2 = rightTuple[0];\n          a2 = rightTuple[1];\n        } else if (hasNext(leftChunk, leftIndex)) {\n          state = ZipAllState.PullRight(pipe(leftChunk, Chunk.drop(leftIndex + 1)));\n          loop = false;\n        } else if (hasNext(rightChunk, rightIndex)) {\n          state = ZipAllState.PullLeft(pipe(rightChunk, Chunk.drop(rightIndex + 1)));\n          loop = false;\n        } else {\n          state = ZipAllState.PullBoth;\n          loop = false;\n        }\n      } else if (compare < 0) {\n        builder.push([k1, options.onSelf(a)]);\n        if (hasNext(leftChunk, leftIndex)) {\n          leftIndex = leftIndex + 1;\n          leftTuple = pipe(leftChunk, Chunk.unsafeGet(leftIndex));\n          k1 = leftTuple[0];\n          a = leftTuple[1];\n        } else {\n          const rightBuilder = [];\n          rightBuilder.push(rightTuple);\n          while (hasNext(rightChunk, rightIndex)) {\n            rightIndex = rightIndex + 1;\n            rightTuple = pipe(rightChunk, Chunk.unsafeGet(rightIndex));\n            rightBuilder.push(rightTuple);\n          }\n          state = ZipAllState.PullLeft(Chunk.unsafeFromArray(rightBuilder));\n          loop = false;\n        }\n      } else {\n        builder.push([k2, options.onOther(a2)]);\n        if (hasNext(rightChunk, rightIndex)) {\n          rightIndex = rightIndex + 1;\n          rightTuple = pipe(rightChunk, Chunk.unsafeGet(rightIndex));\n          k2 = rightTuple[0];\n          a2 = rightTuple[1];\n        } else {\n          const leftBuilder = [];\n          leftBuilder.push(leftTuple);\n          while (hasNext(leftChunk, leftIndex)) {\n            leftIndex = leftIndex + 1;\n            leftTuple = pipe(leftChunk, Chunk.unsafeGet(leftIndex));\n            leftBuilder.push(leftTuple);\n          }\n          state = ZipAllState.PullRight(Chunk.unsafeFromArray(leftBuilder));\n          loop = false;\n        }\n      }\n    }\n    return [Chunk.unsafeFromArray(builder), state];\n  };\n  return combineChunks(self, options.other, ZipAllState.PullBoth, pull);\n});\n/** @internal */\nexport const zipAllWith = /*#__PURE__*/dual(2, (self, options) => {\n  const pull = (state, pullLeft, pullRight) => {\n    switch (state._tag) {\n      case ZipAllState.OP_DRAIN_LEFT:\n        {\n          return Effect.matchEffect(pullLeft, {\n            onFailure: error => Effect.succeed(Exit.fail(error)),\n            onSuccess: leftChunk => Effect.succeed(Exit.succeed([Chunk.map(leftChunk, options.onSelf), ZipAllState.DrainLeft]))\n          });\n        }\n      case ZipAllState.OP_DRAIN_RIGHT:\n        {\n          return Effect.matchEffect(pullRight, {\n            onFailure: error => Effect.succeed(Exit.fail(error)),\n            onSuccess: rightChunk => Effect.succeed(Exit.succeed([Chunk.map(rightChunk, options.onOther), ZipAllState.DrainRight]))\n          });\n        }\n      case ZipAllState.OP_PULL_BOTH:\n        {\n          return pipe(unsome(pullLeft), Effect.zip(unsome(pullRight), {\n            concurrent: true\n          }), Effect.matchEffect({\n            onFailure: error => Effect.succeed(Exit.fail(Option.some(error))),\n            onSuccess: ([leftOption, rightOption]) => {\n              if (Option.isSome(leftOption) && Option.isSome(rightOption)) {\n                if (Chunk.isEmpty(leftOption.value) && Chunk.isEmpty(rightOption.value)) {\n                  return pull(ZipAllState.PullBoth, pullLeft, pullRight);\n                }\n                if (Chunk.isEmpty(leftOption.value)) {\n                  return pull(ZipAllState.PullLeft(rightOption.value), pullLeft, pullRight);\n                }\n                if (Chunk.isEmpty(rightOption.value)) {\n                  return pull(ZipAllState.PullRight(leftOption.value), pullLeft, pullRight);\n                }\n                return Effect.succeed(Exit.succeed(zip(leftOption.value, rightOption.value, options.onBoth)));\n              }\n              if (Option.isSome(leftOption) && Option.isNone(rightOption)) {\n                return Effect.succeed(Exit.succeed([Chunk.map(leftOption.value, options.onSelf), ZipAllState.DrainLeft]));\n              }\n              if (Option.isNone(leftOption) && Option.isSome(rightOption)) {\n                return Effect.succeed(Exit.succeed([Chunk.map(rightOption.value, options.onOther), ZipAllState.DrainRight]));\n              }\n              return Effect.succeed(Exit.fail(Option.none()));\n            }\n          }));\n        }\n      case ZipAllState.OP_PULL_LEFT:\n        {\n          return Effect.matchEffect(pullLeft, {\n            onFailure: Option.match({\n              onNone: () => Effect.succeed(Exit.succeed([Chunk.map(state.rightChunk, options.onOther), ZipAllState.DrainRight])),\n              onSome: error => Effect.succeed(Exit.fail(Option.some(error)))\n            }),\n            onSuccess: leftChunk => {\n              if (Chunk.isEmpty(leftChunk)) {\n                return pull(ZipAllState.PullLeft(state.rightChunk), pullLeft, pullRight);\n              }\n              if (Chunk.isEmpty(state.rightChunk)) {\n                return pull(ZipAllState.PullRight(leftChunk), pullLeft, pullRight);\n              }\n              return Effect.succeed(Exit.succeed(zip(leftChunk, state.rightChunk, options.onBoth)));\n            }\n          });\n        }\n      case ZipAllState.OP_PULL_RIGHT:\n        {\n          return Effect.matchEffect(pullRight, {\n            onFailure: Option.match({\n              onNone: () => Effect.succeed(Exit.succeed([Chunk.map(state.leftChunk, options.onSelf), ZipAllState.DrainLeft])),\n              onSome: error => Effect.succeed(Exit.fail(Option.some(error)))\n            }),\n            onSuccess: rightChunk => {\n              if (Chunk.isEmpty(rightChunk)) {\n                return pull(ZipAllState.PullRight(state.leftChunk), pullLeft, pullRight);\n              }\n              if (Chunk.isEmpty(state.leftChunk)) {\n                return pull(ZipAllState.PullLeft(rightChunk), pullLeft, pullRight);\n              }\n              return Effect.succeed(Exit.succeed(zip(state.leftChunk, rightChunk, options.onBoth)));\n            }\n          });\n        }\n    }\n  };\n  const zip = (leftChunk, rightChunk, f) => {\n    const [output, either] = zipChunks(leftChunk, rightChunk, f);\n    switch (either._tag) {\n      case \"Left\":\n        {\n          if (Chunk.isEmpty(either.left)) {\n            return [output, ZipAllState.PullBoth];\n          }\n          return [output, ZipAllState.PullRight(either.left)];\n        }\n      case \"Right\":\n        {\n          if (Chunk.isEmpty(either.right)) {\n            return [output, ZipAllState.PullBoth];\n          }\n          return [output, ZipAllState.PullLeft(either.right)];\n        }\n    }\n  };\n  return combineChunks(self, options.other, ZipAllState.PullBoth, pull);\n});\n/** @internal */\nexport const zipLatest = /*#__PURE__*/dual(2, (self, that) => pipe(self, zipLatestWith(that, (a, a2) => [a, a2])));\nexport const zipLatestAll = (...streams) => {\n  if (streams.length === 0) {\n    return empty;\n  } else if (streams.length === 1) {\n    return map(streams[0], x => [x]);\n  }\n  const [head, ...tail] = streams;\n  return zipLatestWith(head, zipLatestAll(...tail), (first, second) => [first, ...second]);\n};\n/** @internal */\nexport const zipLatestWith = /*#__PURE__*/dual(3, (self, that, f) => {\n  const pullNonEmpty = pull => pipe(pull, Effect.flatMap(chunk => Chunk.isEmpty(chunk) ? pullNonEmpty(pull) : Effect.succeed(chunk)));\n  return pipe(toPull(self), Effect.map(pullNonEmpty), Effect.zip(pipe(toPull(that), Effect.map(pullNonEmpty))), Effect.flatMap(([left, right]) => pipe(fromEffectOption(Effect.raceWith(left, right, {\n    onSelfDone: (leftDone, rightFiber) => pipe(Effect.suspend(() => leftDone), Effect.zipWith(Fiber.join(rightFiber), (l, r) => [l, r, true])),\n    onOtherDone: (rightDone, leftFiber) => pipe(Effect.suspend(() => rightDone), Effect.zipWith(Fiber.join(leftFiber), (l, r) => [r, l, false]))\n  })), flatMap(([l, r, leftFirst]) => pipe(fromEffect(Ref.make([Chunk.unsafeLast(l), Chunk.unsafeLast(r)])), flatMap(latest => pipe(fromChunk(leftFirst ? pipe(r, Chunk.map(a2 => f(Chunk.unsafeLast(l), a2))) : pipe(l, Chunk.map(a => f(a, Chunk.unsafeLast(r))))), concat(pipe(repeatEffectOption(left), mergeEither(repeatEffectOption(right)), mapEffectSequential(Either.match({\n    onLeft: leftChunk => pipe(Ref.modify(latest, ([_, rightLatest]) => [pipe(leftChunk, Chunk.map(a => f(a, rightLatest))), [Chunk.unsafeLast(leftChunk), rightLatest]])),\n    onRight: rightChunk => pipe(Ref.modify(latest, ([leftLatest, _]) => [pipe(rightChunk, Chunk.map(a2 => f(leftLatest, a2))), [leftLatest, Chunk.unsafeLast(rightChunk)]]))\n  })), flatMap(fromChunk))))))), toPull)), fromPull);\n});\n/** @internal */\nexport const zipLeft = /*#__PURE__*/dual(2, (self, that) => pipe(self, zipWithChunks(that, (left, right) => {\n  if (left.length > right.length) {\n    return [pipe(left, Chunk.take(right.length)), Either.left(pipe(left, Chunk.take(right.length)))];\n  }\n  return [left, Either.right(pipe(right, Chunk.drop(left.length)))];\n})));\n/** @internal */\nexport const zipRight = /*#__PURE__*/dual(2, (self, that) => pipe(self, zipWithChunks(that, (left, right) => {\n  if (left.length > right.length) {\n    return [right, Either.left(pipe(left, Chunk.take(right.length)))];\n  }\n  return [pipe(right, Chunk.take(left.length)), Either.right(pipe(right, Chunk.drop(left.length)))];\n})));\n/** @internal */\nexport const zipWith = /*#__PURE__*/dual(3, (self, that, f) => pipe(self, zipWithChunks(that, (leftChunk, rightChunk) => zipChunks(leftChunk, rightChunk, f))));\n/** @internal */\nexport const zipWithChunks = /*#__PURE__*/dual(3, (self, that, f) => {\n  const pull = (state, pullLeft, pullRight) => {\n    switch (state._tag) {\n      case ZipChunksState.OP_PULL_BOTH:\n        {\n          return pipe(unsome(pullLeft), Effect.zip(unsome(pullRight), {\n            concurrent: true\n          }), Effect.matchEffect({\n            onFailure: error => Effect.succeed(Exit.fail(Option.some(error))),\n            onSuccess: ([leftOption, rightOption]) => {\n              if (Option.isSome(leftOption) && Option.isSome(rightOption)) {\n                if (Chunk.isEmpty(leftOption.value) && Chunk.isEmpty(rightOption.value)) {\n                  return pull(ZipChunksState.PullBoth, pullLeft, pullRight);\n                }\n                if (Chunk.isEmpty(leftOption.value)) {\n                  return pull(ZipChunksState.PullLeft(rightOption.value), pullLeft, pullRight);\n                }\n                if (Chunk.isEmpty(rightOption.value)) {\n                  return pull(ZipChunksState.PullRight(leftOption.value), pullLeft, pullRight);\n                }\n                return Effect.succeed(Exit.succeed(zip(leftOption.value, rightOption.value)));\n              }\n              return Effect.succeed(Exit.fail(Option.none()));\n            }\n          }));\n        }\n      case ZipChunksState.OP_PULL_LEFT:\n        {\n          return Effect.matchEffect(pullLeft, {\n            onFailure: error => Effect.succeed(Exit.fail(error)),\n            onSuccess: leftChunk => {\n              if (Chunk.isEmpty(leftChunk)) {\n                return pull(ZipChunksState.PullLeft(state.rightChunk), pullLeft, pullRight);\n              }\n              if (Chunk.isEmpty(state.rightChunk)) {\n                return pull(ZipChunksState.PullRight(leftChunk), pullLeft, pullRight);\n              }\n              return Effect.succeed(Exit.succeed(zip(leftChunk, state.rightChunk)));\n            }\n          });\n        }\n      case ZipChunksState.OP_PULL_RIGHT:\n        {\n          return Effect.matchEffect(pullRight, {\n            onFailure: error => Effect.succeed(Exit.fail(error)),\n            onSuccess: rightChunk => {\n              if (Chunk.isEmpty(rightChunk)) {\n                return pull(ZipChunksState.PullRight(state.leftChunk), pullLeft, pullRight);\n              }\n              if (Chunk.isEmpty(state.leftChunk)) {\n                return pull(ZipChunksState.PullLeft(rightChunk), pullLeft, pullRight);\n              }\n              return Effect.succeed(Exit.succeed(zip(state.leftChunk, rightChunk)));\n            }\n          });\n        }\n    }\n  };\n  const zip = (leftChunk, rightChunk) => {\n    const [output, either] = f(leftChunk, rightChunk);\n    switch (either._tag) {\n      case \"Left\":\n        {\n          if (Chunk.isEmpty(either.left)) {\n            return [output, ZipChunksState.PullBoth];\n          }\n          return [output, ZipChunksState.PullRight(either.left)];\n        }\n      case \"Right\":\n        {\n          if (Chunk.isEmpty(either.right)) {\n            return [output, ZipChunksState.PullBoth];\n          }\n          return [output, ZipChunksState.PullLeft(either.right)];\n        }\n    }\n  };\n  return pipe(self, combineChunks(that, ZipChunksState.PullBoth, pull));\n});\n/** @internal */\nexport const zipWithIndex = self => pipe(self, mapAccum(0, (index, a) => [index + 1, [a, index]]));\n/** @internal */\nexport const zipWithNext = self => {\n  const process = last => core.readWithCause({\n    onInput: input => {\n      const [newLast, chunk] = Chunk.mapAccum(input, last, (prev, curr) => [Option.some(curr), pipe(prev, Option.map(a => [a, curr]))]);\n      const output = Chunk.filterMap(chunk, option => Option.isSome(option) ? Option.some([option.value[0], Option.some(option.value[1])]) : Option.none());\n      return core.flatMap(core.write(output), () => process(newLast));\n    },\n    onFailure: core.failCause,\n    onDone: () => Option.match(last, {\n      onNone: () => core.void,\n      onSome: value => channel.zipRight(core.write(Chunk.of([value, Option.none()])), core.void)\n    })\n  });\n  return new StreamImpl(pipe(toChannel(self), channel.pipeToOrFail(process(Option.none()))));\n};\n/** @internal */\nexport const zipWithPrevious = self => pipe(self, mapAccum(Option.none(), (prev, curr) => [Option.some(curr), [prev, curr]]));\n/** @internal */\nexport const zipWithPreviousAndNext = self => pipe(zipWithNext(zipWithPrevious(self)), map(([[prev, curr], next]) => [prev, curr, pipe(next, Option.map(tuple => tuple[1]))]));\n/** @internal */\nconst zipChunks = (left, right, f) => {\n  if (left.length > right.length) {\n    return [pipe(left, Chunk.take(right.length), Chunk.zipWith(right, f)), Either.left(pipe(left, Chunk.drop(right.length)))];\n  }\n  return [pipe(left, Chunk.zipWith(pipe(right, Chunk.take(left.length)), f)), Either.right(pipe(right, Chunk.drop(left.length)))];\n};\n// Do notation\n/** @internal */\nexport const Do = /*#__PURE__*/succeed({});\n/** @internal */\nexport const bind = /*#__PURE__*/dual(args => typeof args[0] !== \"string\", (self, tag, f, options) => flatMap(self, k => map(f(k), a => ({\n  ...k,\n  [tag]: a\n})), options));\n/* @internal */\nexport const bindTo = /*#__PURE__*/doNotation.bindTo(map);\n/* @internal */\nexport const let_ = /*#__PURE__*/doNotation.let_(map);\n// Circular with Channel\n/** @internal */\nexport const channelToStream = self => {\n  return new StreamImpl(self);\n};\n// =============================================================================\n// encoding\n// =============================================================================\n/** @internal */\nexport const decodeText = /*#__PURE__*/dual(args => isStream(args[0]), (self, encoding = \"utf-8\") => suspend(() => {\n  const decoder = new TextDecoder(encoding);\n  return map(self, s => decoder.decode(s));\n}));\n/** @internal */\nexport const encodeText = self => suspend(() => {\n  const encoder = new TextEncoder();\n  return map(self, s => encoder.encode(s));\n});\n/** @internal */\nexport const fromEventListener = (target, type, options) => _async(emit => {\n  let batch = [];\n  let taskRunning = false;\n  function cb(e) {\n    batch.push(e);\n    if (!taskRunning) {\n      taskRunning = true;\n      queueMicrotask(() => {\n        const events = batch;\n        batch = [];\n        taskRunning = false;\n        emit.chunk(Chunk.unsafeFromArray(events));\n      });\n    }\n  }\n  target.addEventListener(type, cb, options);\n  return Effect.sync(() => target.removeEventListener(type, cb, options));\n}, \"unbounded\");\n//# sourceMappingURL=stream.js.map","/** @internal */\nexport const OP_NOT_STARTED = \"NotStarted\";\n/** @internal */\nexport const OP_PREVIOUS = \"Previous\";\n/** @internal */\nexport const OP_CURRENT = \"Current\";\n/** @internal */\nexport const notStarted = {\n  _tag: OP_NOT_STARTED\n};\n/** @internal */\nexport const previous = fiber => ({\n  _tag: OP_PREVIOUS,\n  fiber\n});\n/** @internal */\nexport const current = fiber => ({\n  _tag: OP_CURRENT,\n  fiber\n});\n//# sourceMappingURL=debounceState.js.map","import * as Cause from \"../../Cause.js\";\nimport * as Chunk from \"../../Chunk.js\";\nimport * as Effect from \"../../Effect.js\";\nimport * as Exit from \"../../Exit.js\";\nimport { pipe } from \"../../Function.js\";\nimport * as Option from \"../../Option.js\";\n/** @internal */\nexport const make = emit => {\n  const ops = {\n    chunk(as) {\n      return this(Effect.succeed(as));\n    },\n    die(defect) {\n      return this(Effect.die(defect));\n    },\n    dieMessage(message) {\n      return this(Effect.dieMessage(message));\n    },\n    done(exit) {\n      return this(Effect.suspend(() => Exit.mapBoth(exit, {\n        onFailure: Option.some,\n        onSuccess: Chunk.of\n      })));\n    },\n    end() {\n      return this(Effect.fail(Option.none()));\n    },\n    fail(e) {\n      return this(Effect.fail(Option.some(e)));\n    },\n    fromEffect(effect) {\n      return this(Effect.mapBoth(effect, {\n        onFailure: Option.some,\n        onSuccess: Chunk.of\n      }));\n    },\n    fromEffectChunk(effect) {\n      return this(pipe(effect, Effect.mapError(Option.some)));\n    },\n    halt(cause) {\n      return this(Effect.failCause(pipe(cause, Cause.map(Option.some))));\n    },\n    single(value) {\n      return this(Effect.succeed(Chunk.of(value)));\n    }\n  };\n  return Object.assign(emit, ops);\n};\n//# sourceMappingURL=emit.js.map","import { dual } from \"../../Function.js\";\nimport * as OpCodes from \"../opCodes/streamHaltStrategy.js\";\n/** @internal */\nexport const Left = {\n  _tag: OpCodes.OP_LEFT\n};\n/** @internal */\nexport const Right = {\n  _tag: OpCodes.OP_RIGHT\n};\n/** @internal */\nexport const Both = {\n  _tag: OpCodes.OP_BOTH\n};\n/** @internal */\nexport const Either = {\n  _tag: OpCodes.OP_EITHER\n};\n/** @internal */\nexport const fromInput = input => {\n  switch (input) {\n    case \"left\":\n      return Left;\n    case \"right\":\n      return Right;\n    case \"both\":\n      return Both;\n    case \"either\":\n      return Either;\n    default:\n      return input;\n  }\n};\n/** @internal */\nexport const isLeft = self => self._tag === OpCodes.OP_LEFT;\n/** @internal */\nexport const isRight = self => self._tag === OpCodes.OP_RIGHT;\n/** @internal */\nexport const isBoth = self => self._tag === OpCodes.OP_BOTH;\n/** @internal */\nexport const isEither = self => self._tag === OpCodes.OP_EITHER;\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, options) => {\n  switch (self._tag) {\n    case OpCodes.OP_LEFT:\n      {\n        return options.onLeft();\n      }\n    case OpCodes.OP_RIGHT:\n      {\n        return options.onRight();\n      }\n    case OpCodes.OP_BOTH:\n      {\n        return options.onBoth();\n      }\n    case OpCodes.OP_EITHER:\n      {\n        return options.onEither();\n      }\n  }\n});\n//# sourceMappingURL=haltStrategy.js.map","import * as Deferred from \"../../Deferred.js\";\nimport * as Effect from \"../../Effect.js\";\nimport { dual, pipe } from \"../../Function.js\";\nimport * as Option from \"../../Option.js\";\nimport * as Ref from \"../../Ref.js\";\n/** @internal */\nexport const HandoffTypeId = /*#__PURE__*/Symbol.for(\"effect/Stream/Handoff\");\n/** @internal */\nexport const OP_HANDOFF_STATE_EMPTY = \"Empty\";\n/** @internal */\nexport const OP_HANDOFF_STATE_FULL = \"Full\";\n/** @internal */\nconst handoffStateEmpty = notifyConsumer => ({\n  _tag: OP_HANDOFF_STATE_EMPTY,\n  notifyConsumer\n});\n/** @internal */\nconst handoffStateFull = (value, notifyProducer) => ({\n  _tag: OP_HANDOFF_STATE_FULL,\n  value,\n  notifyProducer\n});\n/** @internal */\nconst handoffStateMatch = (onEmpty, onFull) => {\n  return self => {\n    switch (self._tag) {\n      case OP_HANDOFF_STATE_EMPTY:\n        {\n          return onEmpty(self.notifyConsumer);\n        }\n      case OP_HANDOFF_STATE_FULL:\n        {\n          return onFull(self.value, self.notifyProducer);\n        }\n    }\n  };\n};\nconst handoffVariance = {\n  /* c8 ignore next */\n  _A: _ => _\n};\n/** @internal */\nexport const make = () => pipe(Deferred.make(), Effect.flatMap(deferred => Ref.make(handoffStateEmpty(deferred))), Effect.map(ref => ({\n  [HandoffTypeId]: handoffVariance,\n  ref\n})));\n/** @internal */\nexport const offer = /*#__PURE__*/dual(2, (self, value) => {\n  return Effect.flatMap(Deferred.make(), deferred => Effect.flatten(Ref.modify(self.ref, state => pipe(state, handoffStateMatch(notifyConsumer => [Effect.zipRight(Deferred.succeed(notifyConsumer, void 0), Deferred.await(deferred)), handoffStateFull(value, deferred)], (_, notifyProducer) => [Effect.flatMap(Deferred.await(notifyProducer), () => pipe(self, offer(value))), state])))));\n});\n/** @internal */\nexport const take = self => Effect.flatMap(Deferred.make(), deferred => Effect.flatten(Ref.modify(self.ref, state => pipe(state, handoffStateMatch(notifyConsumer => [Effect.flatMap(Deferred.await(notifyConsumer), () => take(self)), state], (value, notifyProducer) => [Effect.as(Deferred.succeed(notifyProducer, void 0), value), handoffStateEmpty(deferred)])))));\n/** @internal */\nexport const poll = self => Effect.flatMap(Deferred.make(), deferred => Effect.flatten(Ref.modify(self.ref, state => pipe(state, handoffStateMatch(() => [Effect.succeed(Option.none()), state], (value, notifyProducer) => [Effect.as(Deferred.succeed(notifyProducer, void 0), Option.some(value)), handoffStateEmpty(deferred)])))));\n//# sourceMappingURL=handoff.js.map","/** @internal */\nexport const OP_EMIT = \"Emit\";\n/** @internal */\nexport const OP_HALT = \"Halt\";\n/** @internal */\nexport const OP_END = \"End\";\n/** @internal */\nexport const emit = elements => ({\n  _tag: OP_EMIT,\n  elements\n});\n/** @internal */\nexport const halt = cause => ({\n  _tag: OP_HALT,\n  cause\n});\n/** @internal */\nexport const end = reason => ({\n  _tag: OP_END,\n  reason\n});\n//# sourceMappingURL=handoffSignal.js.map","import * as Chunk from \"../../Chunk.js\";\nimport * as Effect from \"../../Effect.js\";\nimport * as Option from \"../../Option.js\";\nimport * as Queue from \"../../Queue.js\";\nimport * as take from \"../take.js\";\n/** @internal */\nexport const emit = value => Effect.succeed(Chunk.of(value));\n/** @internal */\nexport const emitChunk = chunk => Effect.succeed(chunk);\n/** @internal */\nexport const empty = () => Effect.succeed(Chunk.empty());\n/** @internal */\nexport const end = () => Effect.fail(Option.none());\n/** @internal */\nexport const fail = error => Effect.fail(Option.some(error));\n/** @internal */\nexport const failCause = cause => Effect.mapError(Effect.failCause(cause), Option.some);\n/** @internal */\nexport const fromDequeue = dequeue => Effect.flatMap(Queue.take(dequeue), take.done);\n//# sourceMappingURL=pull.js.map","/** @internal */\nexport const OP_SCHEDULE_END = \"ScheduleEnd\";\n/** @internal */\nexport const OP_UPSTREAM_END = \"UpstreamEnd\";\n/** @internal */\nexport const ScheduleEnd = {\n  _tag: OP_SCHEDULE_END\n};\n/** @internal */\nexport const UpstreamEnd = {\n  _tag: OP_UPSTREAM_END\n};\n//# sourceMappingURL=sinkEndReason.js.map","/** @internal */\nexport const OP_DRAIN_LEFT = \"DrainLeft\";\n/** @internal */\nexport const OP_DRAIN_RIGHT = \"DrainRight\";\n/** @internal */\nexport const OP_PULL_BOTH = \"PullBoth\";\n/** @internal */\nexport const OP_PULL_LEFT = \"PullLeft\";\n/** @internal */\nexport const OP_PULL_RIGHT = \"PullRight\";\n/** @internal */\nexport const DrainLeft = {\n  _tag: OP_DRAIN_LEFT\n};\n/** @internal */\nexport const DrainRight = {\n  _tag: OP_DRAIN_RIGHT\n};\n/** @internal */\nexport const PullBoth = {\n  _tag: OP_PULL_BOTH\n};\n/** @internal */\nexport const PullLeft = rightChunk => ({\n  _tag: OP_PULL_LEFT,\n  rightChunk\n});\n/** @internal */\nexport const PullRight = leftChunk => ({\n  _tag: OP_PULL_RIGHT,\n  leftChunk\n});\n//# sourceMappingURL=zipAllState.js.map","/** @internal */\nexport const OP_PULL_BOTH = \"PullBoth\";\n/** @internal */\nexport const OP_PULL_LEFT = \"PullLet\";\n/** @internal */\nexport const OP_PULL_RIGHT = \"PullRight\";\n/** @internal */\nexport const PullBoth = {\n  _tag: OP_PULL_BOTH\n};\n/** @internal */\nexport const PullLeft = rightChunk => ({\n  _tag: OP_PULL_LEFT,\n  rightChunk\n});\n/** @internal */\nexport const PullRight = leftChunk => ({\n  _tag: OP_PULL_RIGHT,\n  leftChunk\n});\n//# sourceMappingURL=zipChunksState.js.map","/**\n * Adapted from the `change-case` library.\n *\n * Copyright (c) 2014 Blake Embrey (hello@blakeembrey.com)\n */\n/** @internal */\nexport const lowerCase = str => str.toLowerCase();\n/** @internal */\nexport const upperCase = str => str.toUpperCase();\n/**\n * Replace `re` in the input string with the replacement value.\n */\nconst replace = (input, re, value) => re instanceof RegExp ? input.replace(re, value) : re.reduce((input, re) => input.replace(re, value), input);\n// Support camel case (\"camelCase\" -> \"camel Case\" and \"CAMELCase\" -> \"CAMEL Case\").\nconst DEFAULT_SPLIT_REGEXP = [/([a-z0-9])([A-Z])/g, /([A-Z])([A-Z][a-z])/g];\n// Remove all non-word characters.\nconst DEFAULT_STRIP_REGEXP = /[^A-Z0-9]+/gi;\n/**\n * Normalize the string into something other libraries can manipulate easier.\n */\nconst noCase = (input, options = {}) => {\n  const {\n    delimiter = \" \",\n    splitRegexp = DEFAULT_SPLIT_REGEXP,\n    stripRegexp = DEFAULT_STRIP_REGEXP,\n    transform = lowerCase\n  } = options;\n  const result = replace(replace(input, splitRegexp, \"$1\\0$2\"), stripRegexp, \"\\0\");\n  let start = 0;\n  let end = result.length;\n  // Trim the delimiter from around the output string.\n  while (result.charAt(start) === \"\\0\") {\n    start++;\n  }\n  while (result.charAt(end - 1) === \"\\0\") {\n    end--;\n  }\n  // Transform each token independently.\n  return result.slice(start, end).split(\"\\0\").map(transform).join(delimiter);\n};\nconst pascalCaseTransform = (input, index) => {\n  const firstChar = input.charAt(0);\n  const lowerChars = input.substring(1).toLowerCase();\n  if (index > 0 && firstChar >= \"0\" && firstChar <= \"9\") {\n    return `_${firstChar}${lowerChars}`;\n  }\n  return `${firstChar.toUpperCase()}${lowerChars}`;\n};\n/** @internal */\nexport const pascalCase = (input, options) => noCase(input, {\n  delimiter: \"\",\n  transform: pascalCaseTransform,\n  ...options\n});\nconst camelCaseTransform = (input, index) => index === 0 ? input.toLowerCase() : pascalCaseTransform(input, index);\n/** @internal */\nexport const camelCase = (input, options) => pascalCase(input, {\n  transform: camelCaseTransform,\n  ...options\n});\n/** @internal */\nexport const constantCase = (input, options) => noCase(input, {\n  delimiter: \"_\",\n  transform: upperCase,\n  ...options\n});\n/** @internal */\nexport const kebabCase = (input, options) => noCase(input, {\n  delimiter: \"-\",\n  ...options\n});\n/** @internal */\nexport const snakeCase = (input, options) => noCase(input, {\n  delimiter: \"_\",\n  ...options\n});\n//# sourceMappingURL=string-utils.js.map","import { pipe } from \"../Function.js\";\nimport { globalValue } from \"../GlobalValue.js\";\nimport * as MutableRef from \"../MutableRef.js\";\nimport { hasProperty, isTagged } from \"../Predicate.js\";\nimport * as SortedSet from \"../SortedSet.js\";\nimport * as core from \"./core.js\";\n/** @internal */\nconst SupervisorSymbolKey = \"effect/Supervisor\";\n/** @internal */\nexport const SupervisorTypeId = /*#__PURE__*/Symbol.for(SupervisorSymbolKey);\n/** @internal */\nexport const supervisorVariance = {\n  /* c8 ignore next */\n  _T: _ => _\n};\n/** @internal */\nexport class ProxySupervisor {\n  underlying;\n  value0;\n  [SupervisorTypeId] = supervisorVariance;\n  constructor(underlying, value0) {\n    this.underlying = underlying;\n    this.value0 = value0;\n  }\n  get value() {\n    return this.value0;\n  }\n  onStart(context, effect, parent, fiber) {\n    this.underlying.onStart(context, effect, parent, fiber);\n  }\n  onEnd(value, fiber) {\n    this.underlying.onEnd(value, fiber);\n  }\n  onEffect(fiber, effect) {\n    this.underlying.onEffect(fiber, effect);\n  }\n  onSuspend(fiber) {\n    this.underlying.onSuspend(fiber);\n  }\n  onResume(fiber) {\n    this.underlying.onResume(fiber);\n  }\n  map(f) {\n    return new ProxySupervisor(this, pipe(this.value, core.map(f)));\n  }\n  zip(right) {\n    return new Zip(this, right);\n  }\n}\n/** @internal */\nexport class Zip {\n  left;\n  right;\n  _tag = \"Zip\";\n  [SupervisorTypeId] = supervisorVariance;\n  constructor(left, right) {\n    this.left = left;\n    this.right = right;\n  }\n  get value() {\n    return core.zip(this.left.value, this.right.value);\n  }\n  onStart(context, effect, parent, fiber) {\n    this.left.onStart(context, effect, parent, fiber);\n    this.right.onStart(context, effect, parent, fiber);\n  }\n  onEnd(value, fiber) {\n    this.left.onEnd(value, fiber);\n    this.right.onEnd(value, fiber);\n  }\n  onEffect(fiber, effect) {\n    this.left.onEffect(fiber, effect);\n    this.right.onEffect(fiber, effect);\n  }\n  onSuspend(fiber) {\n    this.left.onSuspend(fiber);\n    this.right.onSuspend(fiber);\n  }\n  onResume(fiber) {\n    this.left.onResume(fiber);\n    this.right.onResume(fiber);\n  }\n  map(f) {\n    return new ProxySupervisor(this, pipe(this.value, core.map(f)));\n  }\n  zip(right) {\n    return new Zip(this, right);\n  }\n}\n/** @internal */\nexport const isZip = self => hasProperty(self, SupervisorTypeId) && isTagged(self, \"Zip\");\n/** @internal */\nexport class Track {\n  [SupervisorTypeId] = supervisorVariance;\n  fibers = /*#__PURE__*/new Set();\n  get value() {\n    return core.sync(() => Array.from(this.fibers));\n  }\n  onStart(_context, _effect, _parent, fiber) {\n    this.fibers.add(fiber);\n  }\n  onEnd(_value, fiber) {\n    this.fibers.delete(fiber);\n  }\n  onEffect(_fiber, _effect) {\n    //\n  }\n  onSuspend(_fiber) {\n    //\n  }\n  onResume(_fiber) {\n    //\n  }\n  map(f) {\n    return new ProxySupervisor(this, pipe(this.value, core.map(f)));\n  }\n  zip(right) {\n    return new Zip(this, right);\n  }\n  onRun(execution, _fiber) {\n    return execution();\n  }\n}\n/** @internal */\nexport class Const {\n  effect;\n  [SupervisorTypeId] = supervisorVariance;\n  constructor(effect) {\n    this.effect = effect;\n  }\n  get value() {\n    return this.effect;\n  }\n  onStart(_context, _effect, _parent, _fiber) {\n    //\n  }\n  onEnd(_value, _fiber) {\n    //\n  }\n  onEffect(_fiber, _effect) {\n    //\n  }\n  onSuspend(_fiber) {\n    //\n  }\n  onResume(_fiber) {\n    //\n  }\n  map(f) {\n    return new ProxySupervisor(this, pipe(this.value, core.map(f)));\n  }\n  zip(right) {\n    return new Zip(this, right);\n  }\n  onRun(execution, _fiber) {\n    return execution();\n  }\n}\nclass FibersIn {\n  ref;\n  [SupervisorTypeId] = supervisorVariance;\n  constructor(ref) {\n    this.ref = ref;\n  }\n  get value() {\n    return core.sync(() => MutableRef.get(this.ref));\n  }\n  onStart(_context, _effect, _parent, fiber) {\n    pipe(this.ref, MutableRef.set(pipe(MutableRef.get(this.ref), SortedSet.add(fiber))));\n  }\n  onEnd(_value, fiber) {\n    pipe(this.ref, MutableRef.set(pipe(MutableRef.get(this.ref), SortedSet.remove(fiber))));\n  }\n  onEffect(_fiber, _effect) {\n    //\n  }\n  onSuspend(_fiber) {\n    //\n  }\n  onResume(_fiber) {\n    //\n  }\n  map(f) {\n    return new ProxySupervisor(this, pipe(this.value, core.map(f)));\n  }\n  zip(right) {\n    return new Zip(this, right);\n  }\n  onRun(execution, _fiber) {\n    return execution();\n  }\n}\n/** @internal */\nexport const unsafeTrack = () => {\n  return new Track();\n};\n/** @internal */\nexport const track = /*#__PURE__*/core.sync(unsafeTrack);\n/** @internal */\nexport const fromEffect = effect => {\n  return new Const(effect);\n};\n/** @internal */\nexport const none = /*#__PURE__*/globalValue(\"effect/Supervisor/none\", () => fromEffect(core.void));\n/** @internal */\nexport const fibersIn = ref => core.sync(() => new FibersIn(ref));\n//# sourceMappingURL=supervisor.js.map","import * as Chunk from \"../../Chunk.js\";\nimport * as Differ from \"../../Differ.js\";\nimport * as Equal from \"../../Equal.js\";\nimport { pipe } from \"../../Function.js\";\nimport * as HashSet from \"../../HashSet.js\";\nimport * as supervisor from \"../supervisor.js\";\n/** @internal */\nexport const OP_EMPTY = \"Empty\";\n/** @internal */\nexport const OP_ADD_SUPERVISOR = \"AddSupervisor\";\n/** @internal */\nexport const OP_REMOVE_SUPERVISOR = \"RemoveSupervisor\";\n/** @internal */\nexport const OP_AND_THEN = \"AndThen\";\n/**\n * The empty `SupervisorPatch`.\n *\n * @internal\n */\nexport const empty = {\n  _tag: OP_EMPTY\n};\n/**\n * Combines two patches to produce a new patch that describes applying the\n * updates from this patch and then the updates from the specified patch.\n *\n * @internal\n */\nexport const combine = (self, that) => {\n  return {\n    _tag: OP_AND_THEN,\n    first: self,\n    second: that\n  };\n};\n/**\n * Applies a `SupervisorPatch` to a `Supervisor` to produce a new `Supervisor`.\n *\n * @internal\n */\nexport const patch = (self, supervisor) => {\n  return patchLoop(supervisor, Chunk.of(self));\n};\n/** @internal */\nconst patchLoop = (_supervisor, _patches) => {\n  let supervisor = _supervisor;\n  let patches = _patches;\n  while (Chunk.isNonEmpty(patches)) {\n    const head = Chunk.headNonEmpty(patches);\n    switch (head._tag) {\n      case OP_EMPTY:\n        {\n          patches = Chunk.tailNonEmpty(patches);\n          break;\n        }\n      case OP_ADD_SUPERVISOR:\n        {\n          supervisor = supervisor.zip(head.supervisor);\n          patches = Chunk.tailNonEmpty(patches);\n          break;\n        }\n      case OP_REMOVE_SUPERVISOR:\n        {\n          supervisor = removeSupervisor(supervisor, head.supervisor);\n          patches = Chunk.tailNonEmpty(patches);\n          break;\n        }\n      case OP_AND_THEN:\n        {\n          patches = Chunk.prepend(head.first)(Chunk.prepend(head.second)(Chunk.tailNonEmpty(patches)));\n          break;\n        }\n    }\n  }\n  return supervisor;\n};\n/** @internal */\nconst removeSupervisor = (self, that) => {\n  if (Equal.equals(self, that)) {\n    return supervisor.none;\n  } else {\n    if (supervisor.isZip(self)) {\n      return removeSupervisor(self.left, that).zip(removeSupervisor(self.right, that));\n    } else {\n      return self;\n    }\n  }\n};\n/** @internal */\nconst toSet = self => {\n  if (Equal.equals(self, supervisor.none)) {\n    return HashSet.empty();\n  } else {\n    if (supervisor.isZip(self)) {\n      return pipe(toSet(self.left), HashSet.union(toSet(self.right)));\n    } else {\n      return HashSet.make(self);\n    }\n  }\n};\n/** @internal */\nexport const diff = (oldValue, newValue) => {\n  if (Equal.equals(oldValue, newValue)) {\n    return empty;\n  }\n  const oldSupervisors = toSet(oldValue);\n  const newSupervisors = toSet(newValue);\n  const added = pipe(newSupervisors, HashSet.difference(oldSupervisors), HashSet.reduce(empty, (patch, supervisor) => combine(patch, {\n    _tag: OP_ADD_SUPERVISOR,\n    supervisor\n  })));\n  const removed = pipe(oldSupervisors, HashSet.difference(newSupervisors), HashSet.reduce(empty, (patch, supervisor) => combine(patch, {\n    _tag: OP_REMOVE_SUPERVISOR,\n    supervisor\n  })));\n  return combine(added, removed);\n};\n/** @internal */\nexport const differ = /*#__PURE__*/Differ.make({\n  empty,\n  patch,\n  combine,\n  diff\n});\n//# sourceMappingURL=patch.js.map","import { dual, pipe } from \"../Function.js\";\nimport * as Option from \"../Option.js\";\nimport * as core from \"./core.js\";\n/** @internal */\nexport const getAndUpdateEffect = /*#__PURE__*/dual(2, (self, f) => self.modifyEffect(value => core.map(f(value), result => [value, result])));\n/** @internal */\nexport const getAndUpdateSomeEffect = /*#__PURE__*/dual(2, (self, pf) => self.modifyEffect(value => {\n  const result = pf(value);\n  switch (result._tag) {\n    case \"None\":\n      {\n        return core.succeed([value, value]);\n      }\n    case \"Some\":\n      {\n        return core.map(result.value, newValue => [value, newValue]);\n      }\n  }\n}));\n/** @internal */\nexport const modify = /*#__PURE__*/dual(2, (self, f) => self.modify(f));\n/** @internal */\nexport const modifyEffect = /*#__PURE__*/dual(2, (self, f) => self.modifyEffect(f));\n/** @internal */\nexport const modifySomeEffect = /*#__PURE__*/dual(3, (self, fallback, pf) => self.modifyEffect(value => pipe(pf(value), Option.getOrElse(() => core.succeed([fallback, value])))));\n/** @internal */\nexport const updateEffect = /*#__PURE__*/dual(2, (self, f) => self.modifyEffect(value => core.map(f(value), result => [undefined, result])));\n/** @internal */\nexport const updateAndGetEffect = /*#__PURE__*/dual(2, (self, f) => self.modifyEffect(value => core.map(f(value), result => [result, result])));\n/** @internal */\nexport const updateSomeEffect = /*#__PURE__*/dual(2, (self, pf) => self.modifyEffect(value => {\n  const result = pf(value);\n  switch (result._tag) {\n    case \"None\":\n      {\n        return core.succeed([void 0, value]);\n      }\n    case \"Some\":\n      {\n        return core.map(result.value, a => [void 0, a]);\n      }\n  }\n}));\n//# sourceMappingURL=synchronizedRef.js.map","import * as Cause from \"../Cause.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Effect from \"../Effect.js\";\nimport * as Exit from \"../Exit.js\";\nimport { constFalse, constTrue, dual, pipe } from \"../Function.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\n/** @internal */\nconst TakeSymbolKey = \"effect/Take\";\n/** @internal */\nexport const TakeTypeId = /*#__PURE__*/Symbol.for(TakeSymbolKey);\nconst takeVariance = {\n  /* c8 ignore next */\n  _A: _ => _,\n  /* c8 ignore next */\n  _E: _ => _\n};\n/** @internal */\nexport class TakeImpl {\n  exit;\n  [TakeTypeId] = takeVariance;\n  constructor(exit) {\n    this.exit = exit;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const chunk = chunk => new TakeImpl(Exit.succeed(chunk));\n/** @internal */\nexport const die = defect => new TakeImpl(Exit.die(defect));\n/** @internal */\nexport const dieMessage = message => new TakeImpl(Exit.die(new Cause.RuntimeException(message)));\n/** @internal */\nexport const done = self => Effect.suspend(() => self.exit);\n/** @internal */\nexport const end = /*#__PURE__*/new TakeImpl( /*#__PURE__*/Exit.fail( /*#__PURE__*/Option.none()));\n/** @internal */\nexport const fail = error => new TakeImpl(Exit.fail(Option.some(error)));\n/** @internal */\nexport const failCause = cause => new TakeImpl(Exit.failCause(pipe(cause, Cause.map(Option.some))));\n/** @internal */\nexport const fromEffect = effect => Effect.matchCause(effect, {\n  onFailure: failCause,\n  onSuccess: of\n});\n/** @internal */\nexport const fromExit = exit => new TakeImpl(pipe(exit, Exit.mapBoth({\n  onFailure: Option.some,\n  onSuccess: Chunk.of\n})));\n/** @internal */\nexport const fromPull = pull => Effect.matchCause(pull, {\n  onFailure: cause => Option.match(Cause.flipCauseOption(cause), {\n    onNone: () => end,\n    onSome: failCause\n  }),\n  onSuccess: chunk\n});\n/** @internal */\nexport const isDone = self => Exit.match(self.exit, {\n  onFailure: cause => Option.isNone(Cause.flipCauseOption(cause)),\n  onSuccess: constFalse\n});\n/** @internal */\nexport const isFailure = self => Exit.match(self.exit, {\n  onFailure: cause => Option.isSome(Cause.flipCauseOption(cause)),\n  onSuccess: constFalse\n});\n/** @internal */\nexport const isSuccess = self => Exit.match(self.exit, {\n  onFailure: constFalse,\n  onSuccess: constTrue\n});\n/** @internal */\nexport const make = exit => new TakeImpl(exit);\n/** @internal */\nexport const match = /*#__PURE__*/dual(2, (self, {\n  onEnd,\n  onFailure,\n  onSuccess\n}) => Exit.match(self.exit, {\n  onFailure: cause => Option.match(Cause.flipCauseOption(cause), {\n    onNone: onEnd,\n    onSome: onFailure\n  }),\n  onSuccess\n}));\n/** @internal */\nexport const matchEffect = /*#__PURE__*/dual(2, (self, {\n  onEnd,\n  onFailure,\n  onSuccess\n}) => Exit.matchEffect(self.exit, {\n  onFailure: cause => Option.match(Cause.flipCauseOption(cause), {\n    onNone: () => onEnd,\n    onSome: onFailure\n  }),\n  onSuccess\n}));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => new TakeImpl(pipe(self.exit, Exit.map(Chunk.map(f)))));\n/** @internal */\nexport const of = value => new TakeImpl(Exit.succeed(Chunk.of(value)));\n/** @internal */\nexport const tap = /*#__PURE__*/dual(2, (self, f) => pipe(self.exit, Exit.forEachEffect(f), Effect.asVoid));\n//# sourceMappingURL=take.js.map","/**\n * @since 2.0.0\n */\nimport * as Context from \"../Context.js\";\n/** @internal */\nexport const TracerTypeId = /*#__PURE__*/Symbol.for(\"effect/Tracer\");\n/** @internal */\nexport const make = options => ({\n  [TracerTypeId]: TracerTypeId,\n  ...options\n});\n/** @internal */\nexport const tracerTag = /*#__PURE__*/Context.GenericTag(\"effect/Tracer\");\n/** @internal */\nexport const spanTag = /*#__PURE__*/Context.GenericTag(\"effect/ParentSpan\");\nconst randomHexString = /*#__PURE__*/function () {\n  const characters = \"abcdef0123456789\";\n  const charactersLength = characters.length;\n  return function (length) {\n    let result = \"\";\n    for (let i = 0; i < length; i++) {\n      result += characters.charAt(Math.floor(Math.random() * charactersLength));\n    }\n    return result;\n  };\n}();\n/** @internal */\nexport class NativeSpan {\n  name;\n  parent;\n  context;\n  links;\n  startTime;\n  kind;\n  _tag = \"Span\";\n  spanId;\n  traceId = \"native\";\n  sampled = true;\n  status;\n  attributes;\n  events = [];\n  constructor(name, parent, context, links, startTime, kind) {\n    this.name = name;\n    this.parent = parent;\n    this.context = context;\n    this.links = links;\n    this.startTime = startTime;\n    this.kind = kind;\n    this.status = {\n      _tag: \"Started\",\n      startTime\n    };\n    this.attributes = new Map();\n    this.traceId = parent._tag === \"Some\" ? parent.value.traceId : randomHexString(32);\n    this.spanId = randomHexString(16);\n  }\n  end(endTime, exit) {\n    this.status = {\n      _tag: \"Ended\",\n      endTime,\n      exit,\n      startTime: this.status.startTime\n    };\n  }\n  attribute(key, value) {\n    this.attributes.set(key, value);\n  }\n  event(name, startTime, attributes) {\n    this.events.push([name, startTime, attributes ?? {}]);\n  }\n}\n/** @internal */\nexport const nativeTracer = /*#__PURE__*/make({\n  span: (name, parent, context, links, startTime, kind) => new NativeSpan(name, parent, context, links, startTime, kind),\n  context: f => f()\n});\n/** @internal */\nexport const externalSpan = options => ({\n  _tag: \"ExternalSpan\",\n  spanId: options.spanId,\n  traceId: options.traceId,\n  sampled: options.sampled ?? true,\n  context: options.context ?? Context.empty()\n});\n/** @internal */\nexport const addSpanStackTrace = options => {\n  if (options?.captureStackTrace === false) {\n    return options;\n  } else if (options?.captureStackTrace !== undefined && typeof options.captureStackTrace !== \"boolean\") {\n    return options;\n  }\n  const limit = Error.stackTraceLimit;\n  Error.stackTraceLimit = 3;\n  const traceError = new Error();\n  Error.stackTraceLimit = limit;\n  let cache = false;\n  return {\n    ...options,\n    captureStackTrace: () => {\n      if (cache !== false) {\n        return cache;\n      }\n      if (traceError.stack !== undefined) {\n        const stack = traceError.stack.split(\"\\n\");\n        if (stack[3] !== undefined) {\n          cache = stack[3].trim();\n          return cache;\n        }\n      }\n    }\n  };\n};\n//# sourceMappingURL=tracer.js.map","let moduleVersion = \"3.5.7\";\nexport const getCurrentVersion = () => moduleVersion;\nexport const setCurrentVersion = version => {\n  moduleVersion = version;\n};\n//# sourceMappingURL=version.js.map","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { Stream } from '../../stream/Stream.js';\nconst AdaptedValue = Symbol('adapted-value');\nfunction toAdapterValue(rawValue, adapter) {\n    const adapted = adapter(rawValue.value_);\n    if (!adapted.adapted) {\n        return rawValue;\n    }\n    return new Value(adapted.value, AdaptedValue);\n}\nclass AdapterArbitrary extends Arbitrary {\n    constructor(sourceArb, adapter) {\n        super();\n        this.sourceArb = sourceArb;\n        this.adapter = adapter;\n        this.adaptValue = (rawValue) => toAdapterValue(rawValue, adapter);\n    }\n    generate(mrng, biasFactor) {\n        const rawValue = this.sourceArb.generate(mrng, biasFactor);\n        return this.adaptValue(rawValue);\n    }\n    canShrinkWithoutContext(value) {\n        return this.sourceArb.canShrinkWithoutContext(value) && !this.adapter(value).adapted;\n    }\n    shrink(value, context) {\n        if (context === AdaptedValue) {\n            if (!this.sourceArb.canShrinkWithoutContext(value)) {\n                return Stream.nil();\n            }\n            return this.sourceArb.shrink(value, undefined).map(this.adaptValue);\n        }\n        return this.sourceArb.shrink(value, context).map(this.adaptValue);\n    }\n}\nexport function adapter(sourceArb, adapter) {\n    return new AdapterArbitrary(sourceArb, adapter);\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { noUndefinedAsContext, UndefinedContextPlaceholder } from './helpers/NoUndefinedAsContext.js';\nexport class AlwaysShrinkableArbitrary extends Arbitrary {\n    constructor(arb) {\n        super();\n        this.arb = arb;\n    }\n    generate(mrng, biasFactor) {\n        const value = this.arb.generate(mrng, biasFactor);\n        return noUndefinedAsContext(value);\n    }\n    canShrinkWithoutContext(value) {\n        return true;\n    }\n    shrink(value, context) {\n        if (context === undefined && !this.arb.canShrinkWithoutContext(value)) {\n            return Stream.nil();\n        }\n        const safeContext = context !== UndefinedContextPlaceholder ? context : undefined;\n        return this.arb.shrink(value, safeContext).map(noUndefinedAsContext);\n    }\n}\n","import { Stream } from '../../stream/Stream.js';\nimport { cloneIfNeeded, cloneMethod } from '../../check/symbols.js';\nimport { integer } from '../integer.js';\nimport { makeLazy } from '../../stream/LazyIterableIterator.js';\nimport { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { getDepthContextFor } from './helpers/DepthContext.js';\nimport { buildSlicedGenerator } from './helpers/BuildSlicedGenerator.js';\nimport { safeMap, safePush, safeSlice } from '../../utils/globals.js';\nconst safeMathFloor = Math.floor;\nconst safeMathLog = Math.log;\nconst safeMathMax = Math.max;\nconst safeArrayIsArray = Array.isArray;\nfunction biasedMaxLength(minLength, maxLength) {\n    if (minLength === maxLength) {\n        return minLength;\n    }\n    return minLength + safeMathFloor(safeMathLog(maxLength - minLength) / safeMathLog(2));\n}\nexport class ArrayArbitrary extends Arbitrary {\n    constructor(arb, minLength, maxGeneratedLength, maxLength, depthIdentifier, setBuilder, customSlices) {\n        super();\n        this.arb = arb;\n        this.minLength = minLength;\n        this.maxGeneratedLength = maxGeneratedLength;\n        this.maxLength = maxLength;\n        this.setBuilder = setBuilder;\n        this.customSlices = customSlices;\n        this.lengthArb = integer({ min: minLength, max: maxGeneratedLength });\n        this.depthContext = getDepthContextFor(depthIdentifier);\n    }\n    preFilter(tab) {\n        if (this.setBuilder === undefined) {\n            return tab;\n        }\n        const s = this.setBuilder();\n        for (let index = 0; index !== tab.length; ++index) {\n            s.tryAdd(tab[index]);\n        }\n        return s.getData();\n    }\n    static makeItCloneable(vs, shrinkables) {\n        vs[cloneMethod] = () => {\n            const cloned = [];\n            for (let idx = 0; idx !== shrinkables.length; ++idx) {\n                safePush(cloned, shrinkables[idx].value);\n            }\n            this.makeItCloneable(cloned, shrinkables);\n            return cloned;\n        };\n        return vs;\n    }\n    generateNItemsNoDuplicates(setBuilder, N, mrng, biasFactorItems) {\n        let numSkippedInRow = 0;\n        const s = setBuilder();\n        const slicedGenerator = buildSlicedGenerator(this.arb, mrng, this.customSlices, biasFactorItems);\n        while (s.size() < N && numSkippedInRow < this.maxGeneratedLength) {\n            const current = slicedGenerator.next();\n            if (s.tryAdd(current)) {\n                numSkippedInRow = 0;\n            }\n            else {\n                numSkippedInRow += 1;\n            }\n        }\n        return s.getData();\n    }\n    safeGenerateNItemsNoDuplicates(setBuilder, N, mrng, biasFactorItems) {\n        const depthImpact = safeMathMax(0, N - biasedMaxLength(this.minLength, this.maxGeneratedLength));\n        this.depthContext.depth += depthImpact;\n        try {\n            return this.generateNItemsNoDuplicates(setBuilder, N, mrng, biasFactorItems);\n        }\n        finally {\n            this.depthContext.depth -= depthImpact;\n        }\n    }\n    generateNItems(N, mrng, biasFactorItems) {\n        const items = [];\n        const slicedGenerator = buildSlicedGenerator(this.arb, mrng, this.customSlices, biasFactorItems);\n        slicedGenerator.attemptExact(N);\n        for (let index = 0; index !== N; ++index) {\n            const current = slicedGenerator.next();\n            safePush(items, current);\n        }\n        return items;\n    }\n    safeGenerateNItems(N, mrng, biasFactorItems) {\n        const depthImpact = safeMathMax(0, N - biasedMaxLength(this.minLength, this.maxGeneratedLength));\n        this.depthContext.depth += depthImpact;\n        try {\n            return this.generateNItems(N, mrng, biasFactorItems);\n        }\n        finally {\n            this.depthContext.depth -= depthImpact;\n        }\n    }\n    wrapper(itemsRaw, shrunkOnce, itemsRawLengthContext, startIndex) {\n        const items = shrunkOnce ? this.preFilter(itemsRaw) : itemsRaw;\n        let cloneable = false;\n        const vs = [];\n        const itemsContexts = [];\n        for (let idx = 0; idx !== items.length; ++idx) {\n            const s = items[idx];\n            cloneable = cloneable || s.hasToBeCloned;\n            safePush(vs, s.value);\n            safePush(itemsContexts, s.context);\n        }\n        if (cloneable) {\n            ArrayArbitrary.makeItCloneable(vs, items);\n        }\n        const context = {\n            shrunkOnce,\n            lengthContext: itemsRaw.length === items.length && itemsRawLengthContext !== undefined\n                ? itemsRawLengthContext\n                : undefined,\n            itemsContexts,\n            startIndex,\n        };\n        return new Value(vs, context);\n    }\n    generate(mrng, biasFactor) {\n        const biasMeta = this.applyBias(mrng, biasFactor);\n        const targetSize = biasMeta.size;\n        const items = this.setBuilder !== undefined\n            ? this.safeGenerateNItemsNoDuplicates(this.setBuilder, targetSize, mrng, biasMeta.biasFactorItems)\n            : this.safeGenerateNItems(targetSize, mrng, biasMeta.biasFactorItems);\n        return this.wrapper(items, false, undefined, 0);\n    }\n    applyBias(mrng, biasFactor) {\n        if (biasFactor === undefined) {\n            return { size: this.lengthArb.generate(mrng, undefined).value };\n        }\n        if (this.minLength === this.maxGeneratedLength) {\n            return { size: this.lengthArb.generate(mrng, undefined).value, biasFactorItems: biasFactor };\n        }\n        if (mrng.nextInt(1, biasFactor) !== 1) {\n            return { size: this.lengthArb.generate(mrng, undefined).value };\n        }\n        if (mrng.nextInt(1, biasFactor) !== 1 || this.minLength === this.maxGeneratedLength) {\n            return { size: this.lengthArb.generate(mrng, undefined).value, biasFactorItems: biasFactor };\n        }\n        const maxBiasedLength = biasedMaxLength(this.minLength, this.maxGeneratedLength);\n        const targetSizeValue = integer({ min: this.minLength, max: maxBiasedLength }).generate(mrng, undefined);\n        return { size: targetSizeValue.value, biasFactorItems: biasFactor };\n    }\n    canShrinkWithoutContext(value) {\n        if (!safeArrayIsArray(value) || this.minLength > value.length || value.length > this.maxLength) {\n            return false;\n        }\n        for (let index = 0; index !== value.length; ++index) {\n            if (!(index in value)) {\n                return false;\n            }\n            if (!this.arb.canShrinkWithoutContext(value[index])) {\n                return false;\n            }\n        }\n        const filtered = this.preFilter(safeMap(value, (item) => new Value(item, undefined)));\n        return filtered.length === value.length;\n    }\n    shrinkItemByItem(value, safeContext, endIndex) {\n        const shrinks = [];\n        for (let index = safeContext.startIndex; index < endIndex; ++index) {\n            safePush(shrinks, makeLazy(() => this.arb.shrink(value[index], safeContext.itemsContexts[index]).map((v) => {\n                const beforeCurrent = safeMap(safeSlice(value, 0, index), (v, i) => new Value(cloneIfNeeded(v), safeContext.itemsContexts[i]));\n                const afterCurrent = safeMap(safeSlice(value, index + 1), (v, i) => new Value(cloneIfNeeded(v), safeContext.itemsContexts[i + index + 1]));\n                return [\n                    [...beforeCurrent, v, ...afterCurrent],\n                    undefined,\n                    index,\n                ];\n            })));\n        }\n        return Stream.nil().join(...shrinks);\n    }\n    shrinkImpl(value, context) {\n        if (value.length === 0) {\n            return Stream.nil();\n        }\n        const safeContext = context !== undefined\n            ? context\n            : { shrunkOnce: false, lengthContext: undefined, itemsContexts: [], startIndex: 0 };\n        return (this.lengthArb\n            .shrink(value.length, safeContext.lengthContext)\n            .drop(safeContext.shrunkOnce && safeContext.lengthContext === undefined && value.length > this.minLength + 1\n            ? 1\n            : 0)\n            .map((lengthValue) => {\n            const sliceStart = value.length - lengthValue.value;\n            return [\n                safeMap(safeSlice(value, sliceStart), (v, index) => new Value(cloneIfNeeded(v), safeContext.itemsContexts[index + sliceStart])),\n                lengthValue.context,\n                0,\n            ];\n        })\n            .join(makeLazy(() => value.length > this.minLength\n            ? this.shrinkItemByItem(value, safeContext, 1)\n            : this.shrinkItemByItem(value, safeContext, value.length)))\n            .join(value.length > this.minLength\n            ? makeLazy(() => {\n                const subContext = {\n                    shrunkOnce: false,\n                    lengthContext: undefined,\n                    itemsContexts: safeSlice(safeContext.itemsContexts, 1),\n                    startIndex: 0,\n                };\n                return this.shrinkImpl(safeSlice(value, 1), subContext)\n                    .filter((v) => this.minLength <= v[0].length + 1)\n                    .map((v) => {\n                    return [[new Value(cloneIfNeeded(value[0]), safeContext.itemsContexts[0]), ...v[0]], undefined, 0];\n                });\n            })\n            : Stream.nil()));\n    }\n    shrink(value, context) {\n        return this.shrinkImpl(value, context).map((contextualValue) => this.wrapper(contextualValue[0], true, contextualValue[1], contextualValue[2]));\n    }\n}\n","import { stream, Stream } from '../../stream/Stream.js';\nimport { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { add64, halve64, isEqual64, isStrictlyNegative64, isStrictlyPositive64, isStrictlySmaller64, isZero64, logLike64, substract64, Unit64, Zero64, } from './helpers/ArrayInt64.js';\nclass ArrayInt64Arbitrary extends Arbitrary {\n    constructor(min, max) {\n        super();\n        this.min = min;\n        this.max = max;\n        this.biasedRanges = null;\n    }\n    generate(mrng, biasFactor) {\n        const range = this.computeGenerateRange(mrng, biasFactor);\n        const uncheckedValue = mrng.nextArrayInt(range.min, range.max);\n        if (uncheckedValue.data.length === 1) {\n            uncheckedValue.data.unshift(0);\n        }\n        return new Value(uncheckedValue, undefined);\n    }\n    computeGenerateRange(mrng, biasFactor) {\n        if (biasFactor === undefined || mrng.nextInt(1, biasFactor) !== 1) {\n            return { min: this.min, max: this.max };\n        }\n        const ranges = this.retrieveBiasedRanges();\n        if (ranges.length === 1) {\n            return ranges[0];\n        }\n        const id = mrng.nextInt(-2 * (ranges.length - 1), ranges.length - 2);\n        return id < 0 ? ranges[0] : ranges[id + 1];\n    }\n    canShrinkWithoutContext(value) {\n        const unsafeValue = value;\n        return (typeof value === 'object' &&\n            value !== null &&\n            (unsafeValue.sign === -1 || unsafeValue.sign === 1) &&\n            Array.isArray(unsafeValue.data) &&\n            unsafeValue.data.length === 2 &&\n            ((isStrictlySmaller64(this.min, unsafeValue) && isStrictlySmaller64(unsafeValue, this.max)) ||\n                isEqual64(this.min, unsafeValue) ||\n                isEqual64(this.max, unsafeValue)));\n    }\n    shrinkArrayInt64(value, target, tryTargetAsap) {\n        const realGap = substract64(value, target);\n        function* shrinkGen() {\n            let previous = tryTargetAsap ? undefined : target;\n            const gap = tryTargetAsap ? realGap : halve64(realGap);\n            for (let toremove = gap; !isZero64(toremove); toremove = halve64(toremove)) {\n                const next = substract64(value, toremove);\n                yield new Value(next, previous);\n                previous = next;\n            }\n        }\n        return stream(shrinkGen());\n    }\n    shrink(current, context) {\n        if (!ArrayInt64Arbitrary.isValidContext(current, context)) {\n            const target = this.defaultTarget();\n            return this.shrinkArrayInt64(current, target, true);\n        }\n        if (this.isLastChanceTry(current, context)) {\n            return Stream.of(new Value(context, undefined));\n        }\n        return this.shrinkArrayInt64(current, context, false);\n    }\n    defaultTarget() {\n        if (!isStrictlyPositive64(this.min) && !isStrictlyNegative64(this.max)) {\n            return Zero64;\n        }\n        return isStrictlyNegative64(this.min) ? this.max : this.min;\n    }\n    isLastChanceTry(current, context) {\n        if (isZero64(current)) {\n            return false;\n        }\n        if (current.sign === 1) {\n            return isEqual64(current, add64(context, Unit64)) && isStrictlyPositive64(substract64(current, this.min));\n        }\n        else {\n            return isEqual64(current, substract64(context, Unit64)) && isStrictlyNegative64(substract64(current, this.max));\n        }\n    }\n    static isValidContext(_current, context) {\n        if (context === undefined) {\n            return false;\n        }\n        if (typeof context !== 'object' || context === null || !('sign' in context) || !('data' in context)) {\n            throw new Error(`Invalid context type passed to ArrayInt64Arbitrary (#1)`);\n        }\n        return true;\n    }\n    retrieveBiasedRanges() {\n        if (this.biasedRanges != null) {\n            return this.biasedRanges;\n        }\n        if (isEqual64(this.min, this.max)) {\n            this.biasedRanges = [{ min: this.min, max: this.max }];\n            return this.biasedRanges;\n        }\n        const minStrictlySmallerZero = isStrictlyNegative64(this.min);\n        const maxStrictlyGreaterZero = isStrictlyPositive64(this.max);\n        if (minStrictlySmallerZero && maxStrictlyGreaterZero) {\n            const logMin = logLike64(this.min);\n            const logMax = logLike64(this.max);\n            this.biasedRanges = [\n                { min: logMin, max: logMax },\n                { min: substract64(this.max, logMax), max: this.max },\n                { min: this.min, max: substract64(this.min, logMin) },\n            ];\n        }\n        else {\n            const logGap = logLike64(substract64(this.max, this.min));\n            const arbCloseToMin = { min: this.min, max: add64(this.min, logGap) };\n            const arbCloseToMax = { min: substract64(this.max, logGap), max: this.max };\n            this.biasedRanges = minStrictlySmallerZero\n                ? [arbCloseToMax, arbCloseToMin]\n                : [arbCloseToMin, arbCloseToMax];\n        }\n        return this.biasedRanges;\n    }\n}\nexport function arrayInt64(min, max) {\n    const arb = new ArrayInt64Arbitrary(min, max);\n    return arb;\n}\n","import { Stream } from '../../stream/Stream.js';\nimport { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { biasNumericRange, bigIntLogLike } from './helpers/BiasNumericRange.js';\nimport { shrinkBigInt } from './helpers/ShrinkBigInt.js';\nimport { BigInt } from '../../utils/globals.js';\nexport class BigIntArbitrary extends Arbitrary {\n    constructor(min, max) {\n        super();\n        this.min = min;\n        this.max = max;\n    }\n    generate(mrng, biasFactor) {\n        const range = this.computeGenerateRange(mrng, biasFactor);\n        return new Value(mrng.nextBigInt(range.min, range.max), undefined);\n    }\n    computeGenerateRange(mrng, biasFactor) {\n        if (biasFactor === undefined || mrng.nextInt(1, biasFactor) !== 1) {\n            return { min: this.min, max: this.max };\n        }\n        const ranges = biasNumericRange(this.min, this.max, bigIntLogLike);\n        if (ranges.length === 1) {\n            return ranges[0];\n        }\n        const id = mrng.nextInt(-2 * (ranges.length - 1), ranges.length - 2);\n        return id < 0 ? ranges[0] : ranges[id + 1];\n    }\n    canShrinkWithoutContext(value) {\n        return typeof value === 'bigint' && this.min <= value && value <= this.max;\n    }\n    shrink(current, context) {\n        if (!BigIntArbitrary.isValidContext(current, context)) {\n            const target = this.defaultTarget();\n            return shrinkBigInt(current, target, true);\n        }\n        if (this.isLastChanceTry(current, context)) {\n            return Stream.of(new Value(context, undefined));\n        }\n        return shrinkBigInt(current, context, false);\n    }\n    defaultTarget() {\n        if (this.min <= 0 && this.max >= 0) {\n            return BigInt(0);\n        }\n        return this.min < 0 ? this.max : this.min;\n    }\n    isLastChanceTry(current, context) {\n        if (current > 0)\n            return current === context + BigInt(1) && current > this.min;\n        if (current < 0)\n            return current === context - BigInt(1) && current < this.max;\n        return false;\n    }\n    static isValidContext(current, context) {\n        if (context === undefined) {\n            return false;\n        }\n        if (typeof context !== 'bigint') {\n            throw new Error(`Invalid context type passed to BigIntArbitrary (#1)`);\n        }\n        const differentSigns = (current > 0 && context < 0) || (current < 0 && context > 0);\n        if (context !== BigInt(0) && differentSigns) {\n            throw new Error(`Invalid context value passed to BigIntArbitrary (#2)`);\n        }\n        return true;\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { cloneMethod } from '../../check/symbols.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { safeMap, safePush } from '../../utils/globals.js';\nconst safeSymbolIterator = Symbol.iterator;\nconst safeIsArray = Array.isArray;\nconst safeObjectIs = Object.is;\nexport class CloneArbitrary extends Arbitrary {\n    constructor(arb, numValues) {\n        super();\n        this.arb = arb;\n        this.numValues = numValues;\n    }\n    generate(mrng, biasFactor) {\n        const items = [];\n        if (this.numValues <= 0) {\n            return this.wrapper(items);\n        }\n        for (let idx = 0; idx !== this.numValues - 1; ++idx) {\n            safePush(items, this.arb.generate(mrng.clone(), biasFactor));\n        }\n        safePush(items, this.arb.generate(mrng, biasFactor));\n        return this.wrapper(items);\n    }\n    canShrinkWithoutContext(value) {\n        if (!safeIsArray(value) || value.length !== this.numValues) {\n            return false;\n        }\n        if (value.length === 0) {\n            return true;\n        }\n        for (let index = 1; index < value.length; ++index) {\n            if (!safeObjectIs(value[0], value[index])) {\n                return false;\n            }\n        }\n        return this.arb.canShrinkWithoutContext(value[0]);\n    }\n    shrink(value, context) {\n        if (value.length === 0) {\n            return Stream.nil();\n        }\n        return new Stream(this.shrinkImpl(value, context !== undefined ? context : [])).map((v) => this.wrapper(v));\n    }\n    *shrinkImpl(value, contexts) {\n        const its = safeMap(value, (v, idx) => this.arb.shrink(v, contexts[idx])[safeSymbolIterator]());\n        let cur = safeMap(its, (it) => it.next());\n        while (!cur[0].done) {\n            yield safeMap(cur, (c) => c.value);\n            cur = safeMap(its, (it) => it.next());\n        }\n    }\n    static makeItCloneable(vs, shrinkables) {\n        vs[cloneMethod] = () => {\n            const cloned = [];\n            for (let idx = 0; idx !== shrinkables.length; ++idx) {\n                safePush(cloned, shrinkables[idx].value);\n            }\n            this.makeItCloneable(cloned, shrinkables);\n            return cloned;\n        };\n        return vs;\n    }\n    wrapper(items) {\n        let cloneable = false;\n        const vs = [];\n        const contexts = [];\n        for (let idx = 0; idx !== items.length; ++idx) {\n            const s = items[idx];\n            cloneable = cloneable || s.hasToBeCloned;\n            safePush(vs, s.value);\n            safePush(contexts, s.context);\n        }\n        if (cloneable) {\n            CloneArbitrary.makeItCloneable(vs, items);\n        }\n        return new Value(vs, contexts);\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { CommandsIterable } from '../../check/model/commands/CommandsIterable.js';\nimport { CommandWrapper } from '../../check/model/commands/CommandWrapper.js';\nimport { ReplayPath } from '../../check/model/ReplayPath.js';\nimport { makeLazy } from '../../stream/LazyIterableIterator.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { oneof } from '../oneof.js';\nimport { restrictedIntegerArbitraryBuilder } from './builders/RestrictedIntegerArbitraryBuilder.js';\nexport class CommandsArbitrary extends Arbitrary {\n    constructor(commandArbs, maxGeneratedCommands, maxCommands, sourceReplayPath, disableReplayLog) {\n        super();\n        this.sourceReplayPath = sourceReplayPath;\n        this.disableReplayLog = disableReplayLog;\n        this.oneCommandArb = oneof(...commandArbs).map((c) => new CommandWrapper(c));\n        this.lengthArb = restrictedIntegerArbitraryBuilder(0, maxGeneratedCommands, maxCommands);\n        this.replayPath = [];\n        this.replayPathPosition = 0;\n    }\n    metadataForReplay() {\n        return this.disableReplayLog ? '' : `replayPath=${JSON.stringify(ReplayPath.stringify(this.replayPath))}`;\n    }\n    buildValueFor(items, shrunkOnce) {\n        const commands = items.map((item) => item.value_);\n        const context = { shrunkOnce, items };\n        return new Value(new CommandsIterable(commands, () => this.metadataForReplay()), context);\n    }\n    generate(mrng) {\n        const size = this.lengthArb.generate(mrng, undefined);\n        const sizeValue = size.value;\n        const items = Array(sizeValue);\n        for (let idx = 0; idx !== sizeValue; ++idx) {\n            const item = this.oneCommandArb.generate(mrng, undefined);\n            items[idx] = item;\n        }\n        this.replayPathPosition = 0;\n        return this.buildValueFor(items, false);\n    }\n    canShrinkWithoutContext(value) {\n        return false;\n    }\n    filterOnExecution(itemsRaw) {\n        const items = [];\n        for (const c of itemsRaw) {\n            if (c.value_.hasRan) {\n                this.replayPath.push(true);\n                items.push(c);\n            }\n            else\n                this.replayPath.push(false);\n        }\n        return items;\n    }\n    filterOnReplay(itemsRaw) {\n        return itemsRaw.filter((c, idx) => {\n            const state = this.replayPath[this.replayPathPosition + idx];\n            if (state === undefined)\n                throw new Error(`Too short replayPath`);\n            if (!state && c.value_.hasRan)\n                throw new Error(`Mismatch between replayPath and real execution`);\n            return state;\n        });\n    }\n    filterForShrinkImpl(itemsRaw) {\n        if (this.replayPathPosition === 0) {\n            this.replayPath = this.sourceReplayPath !== null ? ReplayPath.parse(this.sourceReplayPath) : [];\n        }\n        const items = this.replayPathPosition < this.replayPath.length\n            ? this.filterOnReplay(itemsRaw)\n            : this.filterOnExecution(itemsRaw);\n        this.replayPathPosition += itemsRaw.length;\n        return items;\n    }\n    shrink(_value, context) {\n        if (context === undefined) {\n            return Stream.nil();\n        }\n        const safeContext = context;\n        const shrunkOnce = safeContext.shrunkOnce;\n        const itemsRaw = safeContext.items;\n        const items = this.filterForShrinkImpl(itemsRaw);\n        if (items.length === 0) {\n            return Stream.nil();\n        }\n        const rootShrink = shrunkOnce\n            ? Stream.nil()\n            : new Stream([[]][Symbol.iterator]());\n        const nextShrinks = [];\n        for (let numToKeep = 0; numToKeep !== items.length; ++numToKeep) {\n            nextShrinks.push(makeLazy(() => {\n                const fixedStart = items.slice(0, numToKeep);\n                return this.lengthArb\n                    .shrink(items.length - 1 - numToKeep, undefined)\n                    .map((l) => fixedStart.concat(items.slice(items.length - (l.value + 1))));\n            }));\n        }\n        for (let itemAt = 0; itemAt !== items.length; ++itemAt) {\n            nextShrinks.push(makeLazy(() => this.oneCommandArb\n                .shrink(items[itemAt].value_, items[itemAt].context)\n                .map((v) => items.slice(0, itemAt).concat([v], items.slice(itemAt + 1)))));\n        }\n        return rootShrink.join(...nextShrinks).map((shrinkables) => {\n            return this.buildValueFor(shrinkables.map((c) => new Value(c.value_.clone(), c.context)), true);\n        });\n    }\n}\n","import { Stream } from '../../stream/Stream.js';\nimport { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { cloneMethod, hasCloneMethod } from '../../check/symbols.js';\nconst safeObjectIs = Object.is;\nexport class ConstantArbitrary extends Arbitrary {\n    constructor(values) {\n        super();\n        this.values = values;\n    }\n    generate(mrng, _biasFactor) {\n        const idx = this.values.length === 1 ? 0 : mrng.nextInt(0, this.values.length - 1);\n        const value = this.values[idx];\n        if (!hasCloneMethod(value)) {\n            return new Value(value, idx);\n        }\n        return new Value(value, idx, () => value[cloneMethod]());\n    }\n    canShrinkWithoutContext(value) {\n        for (let idx = 0; idx !== this.values.length; ++idx) {\n            if (safeObjectIs(this.values[idx], value)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    shrink(value, context) {\n        if (context === 0 || safeObjectIs(value, this.values[0])) {\n            return Stream.nil();\n        }\n        return Stream.of(new Value(this.values[0], 0));\n    }\n}\n","import { Stream } from '../../stream/Stream.js';\nimport { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { getDepthContextFor } from './helpers/DepthContext.js';\nimport { depthBiasFromSizeForArbitrary } from './helpers/MaxLengthFromMinLength.js';\nimport { safePush } from '../../utils/globals.js';\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nconst safeMaxSafeInteger = Number.MAX_SAFE_INTEGER;\nconst safeNumberIsInteger = Number.isInteger;\nconst safeMathFloor = Math.floor;\nconst safeMathPow = Math.pow;\nconst safeMathMin = Math.min;\nexport class FrequencyArbitrary extends Arbitrary {\n    static from(warbs, constraints, label) {\n        if (warbs.length === 0) {\n            throw new Error(`${label} expects at least one weighted arbitrary`);\n        }\n        let totalWeight = 0;\n        for (let idx = 0; idx !== warbs.length; ++idx) {\n            const currentArbitrary = warbs[idx].arbitrary;\n            if (currentArbitrary === undefined) {\n                throw new Error(`${label} expects arbitraries to be specified`);\n            }\n            const currentWeight = warbs[idx].weight;\n            totalWeight += currentWeight;\n            if (!safeNumberIsInteger(currentWeight)) {\n                throw new Error(`${label} expects weights to be integer values`);\n            }\n            if (currentWeight < 0) {\n                throw new Error(`${label} expects weights to be superior or equal to 0`);\n            }\n        }\n        if (totalWeight <= 0) {\n            throw new Error(`${label} expects the sum of weights to be strictly superior to 0`);\n        }\n        const sanitizedConstraints = {\n            depthBias: depthBiasFromSizeForArbitrary(constraints.depthSize, constraints.maxDepth !== undefined),\n            maxDepth: constraints.maxDepth != undefined ? constraints.maxDepth : safePositiveInfinity,\n            withCrossShrink: !!constraints.withCrossShrink,\n        };\n        return new FrequencyArbitrary(warbs, sanitizedConstraints, getDepthContextFor(constraints.depthIdentifier));\n    }\n    constructor(warbs, constraints, context) {\n        super();\n        this.warbs = warbs;\n        this.constraints = constraints;\n        this.context = context;\n        let currentWeight = 0;\n        this.cumulatedWeights = [];\n        for (let idx = 0; idx !== warbs.length; ++idx) {\n            currentWeight += warbs[idx].weight;\n            safePush(this.cumulatedWeights, currentWeight);\n        }\n        this.totalWeight = currentWeight;\n    }\n    generate(mrng, biasFactor) {\n        if (this.mustGenerateFirst()) {\n            return this.safeGenerateForIndex(mrng, 0, biasFactor);\n        }\n        const selected = mrng.nextInt(this.computeNegDepthBenefit(), this.totalWeight - 1);\n        for (let idx = 0; idx !== this.cumulatedWeights.length; ++idx) {\n            if (selected < this.cumulatedWeights[idx]) {\n                return this.safeGenerateForIndex(mrng, idx, biasFactor);\n            }\n        }\n        throw new Error(`Unable to generate from fc.frequency`);\n    }\n    canShrinkWithoutContext(value) {\n        return this.canShrinkWithoutContextIndex(value) !== -1;\n    }\n    shrink(value, context) {\n        if (context !== undefined) {\n            const safeContext = context;\n            const selectedIndex = safeContext.selectedIndex;\n            const originalBias = safeContext.originalBias;\n            const originalArbitrary = this.warbs[selectedIndex].arbitrary;\n            const originalShrinks = originalArbitrary\n                .shrink(value, safeContext.originalContext)\n                .map((v) => this.mapIntoValue(selectedIndex, v, null, originalBias));\n            if (safeContext.clonedMrngForFallbackFirst !== null) {\n                if (safeContext.cachedGeneratedForFirst === undefined) {\n                    safeContext.cachedGeneratedForFirst = this.safeGenerateForIndex(safeContext.clonedMrngForFallbackFirst, 0, originalBias);\n                }\n                const valueFromFirst = safeContext.cachedGeneratedForFirst;\n                return Stream.of(valueFromFirst).join(originalShrinks);\n            }\n            return originalShrinks;\n        }\n        const potentialSelectedIndex = this.canShrinkWithoutContextIndex(value);\n        if (potentialSelectedIndex === -1) {\n            return Stream.nil();\n        }\n        return this.defaultShrinkForFirst(potentialSelectedIndex).join(this.warbs[potentialSelectedIndex].arbitrary\n            .shrink(value, undefined)\n            .map((v) => this.mapIntoValue(potentialSelectedIndex, v, null, undefined)));\n    }\n    defaultShrinkForFirst(selectedIndex) {\n        ++this.context.depth;\n        try {\n            if (!this.mustFallbackToFirstInShrink(selectedIndex) || this.warbs[0].fallbackValue === undefined) {\n                return Stream.nil();\n            }\n        }\n        finally {\n            --this.context.depth;\n        }\n        const rawShrinkValue = new Value(this.warbs[0].fallbackValue.default, undefined);\n        return Stream.of(this.mapIntoValue(0, rawShrinkValue, null, undefined));\n    }\n    canShrinkWithoutContextIndex(value) {\n        if (this.mustGenerateFirst()) {\n            return this.warbs[0].arbitrary.canShrinkWithoutContext(value) ? 0 : -1;\n        }\n        try {\n            ++this.context.depth;\n            for (let idx = 0; idx !== this.warbs.length; ++idx) {\n                const warb = this.warbs[idx];\n                if (warb.weight !== 0 && warb.arbitrary.canShrinkWithoutContext(value)) {\n                    return idx;\n                }\n            }\n            return -1;\n        }\n        finally {\n            --this.context.depth;\n        }\n    }\n    mapIntoValue(idx, value, clonedMrngForFallbackFirst, biasFactor) {\n        const context = {\n            selectedIndex: idx,\n            originalBias: biasFactor,\n            originalContext: value.context,\n            clonedMrngForFallbackFirst,\n        };\n        return new Value(value.value, context);\n    }\n    safeGenerateForIndex(mrng, idx, biasFactor) {\n        ++this.context.depth;\n        try {\n            const value = this.warbs[idx].arbitrary.generate(mrng, biasFactor);\n            const clonedMrngForFallbackFirst = this.mustFallbackToFirstInShrink(idx) ? mrng.clone() : null;\n            return this.mapIntoValue(idx, value, clonedMrngForFallbackFirst, biasFactor);\n        }\n        finally {\n            --this.context.depth;\n        }\n    }\n    mustGenerateFirst() {\n        return this.constraints.maxDepth <= this.context.depth;\n    }\n    mustFallbackToFirstInShrink(idx) {\n        return idx !== 0 && this.constraints.withCrossShrink && this.warbs[0].weight !== 0;\n    }\n    computeNegDepthBenefit() {\n        const depthBias = this.constraints.depthBias;\n        if (depthBias <= 0 || this.warbs[0].weight === 0) {\n            return 0;\n        }\n        const depthBenefit = safeMathFloor(safeMathPow(1 + depthBias, this.context.depth)) - 1;\n        return -safeMathMin(this.totalWeight * depthBenefit, safeMaxSafeInteger) || 0;\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { buildGeneratorValue } from './builders/GeneratorValueBuilder.js';\nimport { buildStableArbitraryGeneratorCache, naiveIsEqual } from './builders/StableArbitraryGeneratorCache.js';\nimport { tupleShrink } from './TupleArbitrary.js';\nexport class GeneratorArbitrary extends Arbitrary {\n    constructor() {\n        super(...arguments);\n        this.arbitraryCache = buildStableArbitraryGeneratorCache(naiveIsEqual);\n    }\n    generate(mrng, biasFactor) {\n        return buildGeneratorValue(mrng, biasFactor, () => [], this.arbitraryCache);\n    }\n    canShrinkWithoutContext(value) {\n        return false;\n    }\n    shrink(_value, context) {\n        if (context === undefined) {\n            return Stream.nil();\n        }\n        const safeContext = context;\n        const mrng = safeContext.mrng;\n        const biasFactor = safeContext.biasFactor;\n        const history = safeContext.history;\n        return tupleShrink(history.map((c) => c.arb), history.map((c) => c.value), history.map((c) => c.context)).map((shrink) => {\n            function computePreBuiltValues() {\n                const subValues = shrink.value;\n                const subContexts = shrink.context;\n                return history.map((entry, index) => ({\n                    arb: entry.arb,\n                    value: subValues[index],\n                    context: subContexts[index],\n                    mrng: entry.mrng,\n                }));\n            }\n            return buildGeneratorValue(mrng, biasFactor, computePreBuiltValues, this.arbitraryCache);\n        });\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { integerLogLike, biasNumericRange } from './helpers/BiasNumericRange.js';\nimport { shrinkInteger } from './helpers/ShrinkInteger.js';\nconst safeMathSign = Math.sign;\nconst safeNumberIsInteger = Number.isInteger;\nconst safeObjectIs = Object.is;\nexport class IntegerArbitrary extends Arbitrary {\n    constructor(min, max) {\n        super();\n        this.min = min;\n        this.max = max;\n    }\n    generate(mrng, biasFactor) {\n        const range = this.computeGenerateRange(mrng, biasFactor);\n        return new Value(mrng.nextInt(range.min, range.max), undefined);\n    }\n    canShrinkWithoutContext(value) {\n        return (typeof value === 'number' &&\n            safeNumberIsInteger(value) &&\n            !safeObjectIs(value, -0) &&\n            this.min <= value &&\n            value <= this.max);\n    }\n    shrink(current, context) {\n        if (!IntegerArbitrary.isValidContext(current, context)) {\n            const target = this.defaultTarget();\n            return shrinkInteger(current, target, true);\n        }\n        if (this.isLastChanceTry(current, context)) {\n            return Stream.of(new Value(context, undefined));\n        }\n        return shrinkInteger(current, context, false);\n    }\n    defaultTarget() {\n        if (this.min <= 0 && this.max >= 0) {\n            return 0;\n        }\n        return this.min < 0 ? this.max : this.min;\n    }\n    computeGenerateRange(mrng, biasFactor) {\n        if (biasFactor === undefined || mrng.nextInt(1, biasFactor) !== 1) {\n            return { min: this.min, max: this.max };\n        }\n        const ranges = biasNumericRange(this.min, this.max, integerLogLike);\n        if (ranges.length === 1) {\n            return ranges[0];\n        }\n        const id = mrng.nextInt(-2 * (ranges.length - 1), ranges.length - 2);\n        return id < 0 ? ranges[0] : ranges[id + 1];\n    }\n    isLastChanceTry(current, context) {\n        if (current > 0)\n            return current === context + 1 && current > this.min;\n        if (current < 0)\n            return current === context - 1 && current < this.max;\n        return false;\n    }\n    static isValidContext(current, context) {\n        if (context === undefined) {\n            return false;\n        }\n        if (typeof context !== 'number') {\n            throw new Error(`Invalid context type passed to IntegerArbitrary (#1)`);\n        }\n        if (context !== 0 && safeMathSign(current) !== safeMathSign(context)) {\n            throw new Error(`Invalid context value passed to IntegerArbitrary (#2)`);\n        }\n        return true;\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nexport class LazyArbitrary extends Arbitrary {\n    constructor(name) {\n        super();\n        this.name = name;\n        this.underlying = null;\n    }\n    generate(mrng, biasFactor) {\n        if (!this.underlying) {\n            throw new Error(`Lazy arbitrary ${JSON.stringify(this.name)} not correctly initialized`);\n        }\n        return this.underlying.generate(mrng, biasFactor);\n    }\n    canShrinkWithoutContext(value) {\n        if (!this.underlying) {\n            throw new Error(`Lazy arbitrary ${JSON.stringify(this.name)} not correctly initialized`);\n        }\n        return this.underlying.canShrinkWithoutContext(value);\n    }\n    shrink(value, context) {\n        if (!this.underlying) {\n            throw new Error(`Lazy arbitrary ${JSON.stringify(this.name)} not correctly initialized`);\n        }\n        return this.underlying.shrink(value, context);\n    }\n}\n","import { bigUintN } from '../bigUintN.js';\nimport { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { makeLazy } from '../../stream/LazyIterableIterator.js';\nimport { applyFlagsOnChars, computeFlagsFromChars, computeNextFlags, computeTogglePositions, } from './helpers/ToggleFlags.js';\nimport { safeJoin, safeSlice } from '../../utils/globals.js';\nimport { BigInt } from '../../utils/globals.js';\nexport class MixedCaseArbitrary extends Arbitrary {\n    constructor(stringArb, toggleCase, untoggleAll) {\n        super();\n        this.stringArb = stringArb;\n        this.toggleCase = toggleCase;\n        this.untoggleAll = untoggleAll;\n    }\n    buildContextFor(rawStringValue, flagsValue) {\n        return {\n            rawString: rawStringValue.value,\n            rawStringContext: rawStringValue.context,\n            flags: flagsValue.value,\n            flagsContext: flagsValue.context,\n        };\n    }\n    generate(mrng, biasFactor) {\n        const rawStringValue = this.stringArb.generate(mrng, biasFactor);\n        const chars = [...rawStringValue.value];\n        const togglePositions = computeTogglePositions(chars, this.toggleCase);\n        const flagsArb = bigUintN(togglePositions.length);\n        const flagsValue = flagsArb.generate(mrng, undefined);\n        applyFlagsOnChars(chars, flagsValue.value, togglePositions, this.toggleCase);\n        return new Value(safeJoin(chars, ''), this.buildContextFor(rawStringValue, flagsValue));\n    }\n    canShrinkWithoutContext(value) {\n        if (typeof value !== 'string') {\n            return false;\n        }\n        return this.untoggleAll !== undefined\n            ? this.stringArb.canShrinkWithoutContext(this.untoggleAll(value))\n            :\n                this.stringArb.canShrinkWithoutContext(value);\n    }\n    shrink(value, context) {\n        let contextSafe;\n        if (context !== undefined) {\n            contextSafe = context;\n        }\n        else {\n            if (this.untoggleAll !== undefined) {\n                const untoggledValue = this.untoggleAll(value);\n                const valueChars = [...value];\n                const untoggledValueChars = [...untoggledValue];\n                const togglePositions = computeTogglePositions(untoggledValueChars, this.toggleCase);\n                contextSafe = {\n                    rawString: untoggledValue,\n                    rawStringContext: undefined,\n                    flags: computeFlagsFromChars(untoggledValueChars, valueChars, togglePositions),\n                    flagsContext: undefined,\n                };\n            }\n            else {\n                contextSafe = {\n                    rawString: value,\n                    rawStringContext: undefined,\n                    flags: BigInt(0),\n                    flagsContext: undefined,\n                };\n            }\n        }\n        const rawString = contextSafe.rawString;\n        const flags = contextSafe.flags;\n        return this.stringArb\n            .shrink(rawString, contextSafe.rawStringContext)\n            .map((nRawStringValue) => {\n            const nChars = [...nRawStringValue.value];\n            const nTogglePositions = computeTogglePositions(nChars, this.toggleCase);\n            const nFlags = computeNextFlags(flags, nTogglePositions.length);\n            applyFlagsOnChars(nChars, nFlags, nTogglePositions, this.toggleCase);\n            return new Value(safeJoin(nChars, ''), this.buildContextFor(nRawStringValue, new Value(nFlags, undefined)));\n        })\n            .join(makeLazy(() => {\n            const chars = [...rawString];\n            const togglePositions = computeTogglePositions(chars, this.toggleCase);\n            return bigUintN(togglePositions.length)\n                .shrink(flags, contextSafe.flagsContext)\n                .map((nFlagsValue) => {\n                const nChars = safeSlice(chars);\n                applyFlagsOnChars(nChars, nFlagsValue.value, togglePositions, this.toggleCase);\n                return new Value(safeJoin(nChars, ''), this.buildContextFor(new Value(rawString, contextSafe.rawStringContext), nFlagsValue));\n            });\n        }));\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { SchedulerImplem } from './implementations/SchedulerImplem.js';\nfunction buildNextTaskIndex(mrng) {\n    const clonedMrng = mrng.clone();\n    return {\n        clone: () => buildNextTaskIndex(clonedMrng),\n        nextTaskIndex: (scheduledTasks) => {\n            return mrng.nextInt(0, scheduledTasks.length - 1);\n        },\n    };\n}\nexport class SchedulerArbitrary extends Arbitrary {\n    constructor(act) {\n        super();\n        this.act = act;\n    }\n    generate(mrng, _biasFactor) {\n        return new Value(new SchedulerImplem(this.act, buildNextTaskIndex(mrng.clone())), undefined);\n    }\n    canShrinkWithoutContext(value) {\n        return false;\n    }\n    shrink(_value, _context) {\n        return Stream.nil();\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { cloneMethod } from '../../check/symbols.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { safeJoin, safePush } from '../../utils/globals.js';\nimport { asyncStringify, asyncToStringMethod, stringify, toStringMethod } from '../../utils/stringify.js';\nconst safeObjectDefineProperties = Object.defineProperties;\nfunction prettyPrint(seenValuesStrings) {\n    return `Stream(${safeJoin(seenValuesStrings, ',')})`;\n}\nexport class StreamArbitrary extends Arbitrary {\n    constructor(arb) {\n        super();\n        this.arb = arb;\n    }\n    generate(mrng, biasFactor) {\n        const appliedBiasFactor = biasFactor !== undefined && mrng.nextInt(1, biasFactor) === 1 ? biasFactor : undefined;\n        const enrichedProducer = () => {\n            const seenValues = [];\n            const g = function* (arb, clonedMrng) {\n                while (true) {\n                    const value = arb.generate(clonedMrng, appliedBiasFactor).value;\n                    safePush(seenValues, value);\n                    yield value;\n                }\n            };\n            const s = new Stream(g(this.arb, mrng.clone()));\n            return safeObjectDefineProperties(s, {\n                toString: { value: () => prettyPrint(seenValues.map(stringify)) },\n                [toStringMethod]: { value: () => prettyPrint(seenValues.map(stringify)) },\n                [asyncToStringMethod]: { value: async () => prettyPrint(await Promise.all(seenValues.map(asyncStringify))) },\n                [cloneMethod]: { value: enrichedProducer, enumerable: true },\n            });\n        };\n        return new Value(enrichedProducer(), undefined);\n    }\n    canShrinkWithoutContext(value) {\n        return false;\n    }\n    shrink(_value, _context) {\n        return Stream.nil();\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { makeLazy } from '../../stream/LazyIterableIterator.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { safeMap, safePush, safeSlice, safeSort, safeSplice } from '../../utils/globals.js';\nimport { isSubarrayOf } from './helpers/IsSubarrayOf.js';\nimport { IntegerArbitrary } from './IntegerArbitrary.js';\nconst safeMathFloor = Math.floor;\nconst safeMathLog = Math.log;\nconst safeArrayIsArray = Array.isArray;\nexport class SubarrayArbitrary extends Arbitrary {\n    constructor(originalArray, isOrdered, minLength, maxLength) {\n        super();\n        this.originalArray = originalArray;\n        this.isOrdered = isOrdered;\n        this.minLength = minLength;\n        this.maxLength = maxLength;\n        if (minLength < 0 || minLength > originalArray.length)\n            throw new Error('fc.*{s|S}ubarrayOf expects the minimal length to be between 0 and the size of the original array');\n        if (maxLength < 0 || maxLength > originalArray.length)\n            throw new Error('fc.*{s|S}ubarrayOf expects the maximal length to be between 0 and the size of the original array');\n        if (minLength > maxLength)\n            throw new Error('fc.*{s|S}ubarrayOf expects the minimal length to be inferior or equal to the maximal length');\n        this.lengthArb = new IntegerArbitrary(minLength, maxLength);\n        this.biasedLengthArb =\n            minLength !== maxLength\n                ? new IntegerArbitrary(minLength, minLength + safeMathFloor(safeMathLog(maxLength - minLength) / safeMathLog(2)))\n                : this.lengthArb;\n    }\n    generate(mrng, biasFactor) {\n        const lengthArb = biasFactor !== undefined && mrng.nextInt(1, biasFactor) === 1 ? this.biasedLengthArb : this.lengthArb;\n        const size = lengthArb.generate(mrng, undefined);\n        const sizeValue = size.value;\n        const remainingElements = safeMap(this.originalArray, (_v, idx) => idx);\n        const ids = [];\n        for (let index = 0; index !== sizeValue; ++index) {\n            const selectedIdIndex = mrng.nextInt(0, remainingElements.length - 1);\n            safePush(ids, remainingElements[selectedIdIndex]);\n            safeSplice(remainingElements, selectedIdIndex, 1);\n        }\n        if (this.isOrdered) {\n            safeSort(ids, (a, b) => a - b);\n        }\n        return new Value(safeMap(ids, (i) => this.originalArray[i]), size.context);\n    }\n    canShrinkWithoutContext(value) {\n        if (!safeArrayIsArray(value)) {\n            return false;\n        }\n        if (!this.lengthArb.canShrinkWithoutContext(value.length)) {\n            return false;\n        }\n        return isSubarrayOf(this.originalArray, value);\n    }\n    shrink(value, context) {\n        if (value.length === 0) {\n            return Stream.nil();\n        }\n        return this.lengthArb\n            .shrink(value.length, context)\n            .map((newSize) => {\n            return new Value(safeSlice(value, value.length - newSize.value), newSize.context);\n        })\n            .join(value.length > this.minLength\n            ? makeLazy(() => this.shrink(safeSlice(value, 1), undefined)\n                .filter((newValue) => this.minLength <= newValue.value.length + 1)\n                .map((newValue) => new Value([value[0], ...newValue.value], undefined)))\n            : Stream.nil());\n    }\n}\n","import { Stream } from '../../stream/Stream.js';\nimport { cloneIfNeeded, cloneMethod } from '../../check/symbols.js';\nimport { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nimport { safeMap, safePush, safeSlice } from '../../utils/globals.js';\nimport { makeLazy } from '../../stream/LazyIterableIterator.js';\nconst safeArrayIsArray = Array.isArray;\nconst safeObjectDefineProperty = Object.defineProperty;\nfunction tupleMakeItCloneable(vs, values) {\n    return safeObjectDefineProperty(vs, cloneMethod, {\n        value: () => {\n            const cloned = [];\n            for (let idx = 0; idx !== values.length; ++idx) {\n                safePush(cloned, values[idx].value);\n            }\n            tupleMakeItCloneable(cloned, values);\n            return cloned;\n        },\n    });\n}\nfunction tupleWrapper(values) {\n    let cloneable = false;\n    const vs = [];\n    const ctxs = [];\n    for (let idx = 0; idx !== values.length; ++idx) {\n        const v = values[idx];\n        cloneable = cloneable || v.hasToBeCloned;\n        safePush(vs, v.value);\n        safePush(ctxs, v.context);\n    }\n    if (cloneable) {\n        tupleMakeItCloneable(vs, values);\n    }\n    return new Value(vs, ctxs);\n}\nexport function tupleShrink(arbs, value, context) {\n    const shrinks = [];\n    const safeContext = safeArrayIsArray(context) ? context : [];\n    for (let idx = 0; idx !== arbs.length; ++idx) {\n        safePush(shrinks, makeLazy(() => arbs[idx]\n            .shrink(value[idx], safeContext[idx])\n            .map((v) => {\n            const nextValues = safeMap(value, (v, idx) => new Value(cloneIfNeeded(v), safeContext[idx]));\n            return [...safeSlice(nextValues, 0, idx), v, ...safeSlice(nextValues, idx + 1)];\n        })\n            .map(tupleWrapper)));\n    }\n    return Stream.nil().join(...shrinks);\n}\nexport class TupleArbitrary extends Arbitrary {\n    constructor(arbs) {\n        super();\n        this.arbs = arbs;\n        for (let idx = 0; idx !== arbs.length; ++idx) {\n            const arb = arbs[idx];\n            if (arb == null || arb.generate == null)\n                throw new Error(`Invalid parameter encountered at index ${idx}: expecting an Arbitrary`);\n        }\n    }\n    generate(mrng, biasFactor) {\n        const mapped = [];\n        for (let idx = 0; idx !== this.arbs.length; ++idx) {\n            safePush(mapped, this.arbs[idx].generate(mrng, biasFactor));\n        }\n        return tupleWrapper(mapped);\n    }\n    canShrinkWithoutContext(value) {\n        if (!safeArrayIsArray(value) || value.length !== this.arbs.length) {\n            return false;\n        }\n        for (let index = 0; index !== this.arbs.length; ++index) {\n            if (!this.arbs[index].canShrinkWithoutContext(value[index])) {\n                return false;\n            }\n        }\n        return true;\n    }\n    shrink(value, context) {\n        return tupleShrink(this.arbs, value, context);\n    }\n}\n","import { Arbitrary } from '../../check/arbitrary/definition/Arbitrary.js';\nimport { Value } from '../../check/arbitrary/definition/Value.js';\nfunction isSafeContext(context) {\n    return context !== undefined;\n}\nfunction toGeneratorValue(value) {\n    if (value.hasToBeCloned) {\n        return new Value(value.value_, { generatorContext: value.context }, () => value.value);\n    }\n    return new Value(value.value_, { generatorContext: value.context });\n}\nfunction toShrinkerValue(value) {\n    if (value.hasToBeCloned) {\n        return new Value(value.value_, { shrinkerContext: value.context }, () => value.value);\n    }\n    return new Value(value.value_, { shrinkerContext: value.context });\n}\nexport class WithShrinkFromOtherArbitrary extends Arbitrary {\n    constructor(generatorArbitrary, shrinkerArbitrary) {\n        super();\n        this.generatorArbitrary = generatorArbitrary;\n        this.shrinkerArbitrary = shrinkerArbitrary;\n    }\n    generate(mrng, biasFactor) {\n        return toGeneratorValue(this.generatorArbitrary.generate(mrng, biasFactor));\n    }\n    canShrinkWithoutContext(value) {\n        return this.shrinkerArbitrary.canShrinkWithoutContext(value);\n    }\n    shrink(value, context) {\n        if (!isSafeContext(context)) {\n            return this.shrinkerArbitrary.shrink(value, undefined).map(toShrinkerValue);\n        }\n        if ('generatorContext' in context) {\n            return this.generatorArbitrary.shrink(value, context.generatorContext).map(toGeneratorValue);\n        }\n        return this.shrinkerArbitrary.shrink(value, context.shrinkerContext).map(toShrinkerValue);\n    }\n}\n","import { stringify } from '../../../utils/stringify.js';\nimport { array } from '../../array.js';\nimport { oneof } from '../../oneof.js';\nimport { tuple } from '../../tuple.js';\nimport { bigInt } from '../../bigInt.js';\nimport { date } from '../../date.js';\nimport { float32Array } from '../../float32Array.js';\nimport { float64Array } from '../../float64Array.js';\nimport { int16Array } from '../../int16Array.js';\nimport { int32Array } from '../../int32Array.js';\nimport { int8Array } from '../../int8Array.js';\nimport { uint16Array } from '../../uint16Array.js';\nimport { uint32Array } from '../../uint32Array.js';\nimport { uint8Array } from '../../uint8Array.js';\nimport { uint8ClampedArray } from '../../uint8ClampedArray.js';\nimport { sparseArray } from '../../sparseArray.js';\nimport { arrayToMapMapper, arrayToMapUnmapper } from '../mappers/ArrayToMap.js';\nimport { arrayToSetMapper, arrayToSetUnmapper } from '../mappers/ArrayToSet.js';\nimport { letrec } from '../../letrec.js';\nimport { uniqueArray } from '../../uniqueArray.js';\nimport { createDepthIdentifier } from '../helpers/DepthContext.js';\nimport { dictionary } from '../../dictionary.js';\nfunction mapOf(ka, va, maxKeys, size, depthIdentifier) {\n    return uniqueArray(tuple(ka, va), {\n        maxLength: maxKeys,\n        size,\n        comparator: 'SameValueZero',\n        selector: (t) => t[0],\n        depthIdentifier,\n    }).map(arrayToMapMapper, arrayToMapUnmapper);\n}\nfunction dictOf(ka, va, maxKeys, size, depthIdentifier, withNullPrototype) {\n    return dictionary(ka, va, {\n        maxKeys,\n        noNullPrototype: !withNullPrototype,\n        size,\n        depthIdentifier,\n    });\n}\nfunction setOf(va, maxKeys, size, depthIdentifier) {\n    return uniqueArray(va, { maxLength: maxKeys, size, comparator: 'SameValueZero', depthIdentifier }).map(arrayToSetMapper, arrayToSetUnmapper);\n}\nfunction typedArray(constraints) {\n    return oneof(int8Array(constraints), uint8Array(constraints), uint8ClampedArray(constraints), int16Array(constraints), uint16Array(constraints), int32Array(constraints), uint32Array(constraints), float32Array(constraints), float64Array(constraints));\n}\nexport function anyArbitraryBuilder(constraints) {\n    const arbitrariesForBase = constraints.values;\n    const depthSize = constraints.depthSize;\n    const depthIdentifier = createDepthIdentifier();\n    const maxDepth = constraints.maxDepth;\n    const maxKeys = constraints.maxKeys;\n    const size = constraints.size;\n    const baseArb = oneof(...arbitrariesForBase, ...(constraints.withBigInt ? [bigInt()] : []), ...(constraints.withDate ? [date()] : []));\n    return letrec((tie) => ({\n        anything: oneof({ maxDepth, depthSize, depthIdentifier }, baseArb, tie('array'), tie('object'), ...(constraints.withMap ? [tie('map')] : []), ...(constraints.withSet ? [tie('set')] : []), ...(constraints.withObjectString ? [tie('anything').map((o) => stringify(o))] : []), ...(constraints.withTypedArray ? [typedArray({ maxLength: maxKeys, size })] : []), ...(constraints.withSparseArray\n            ? [sparseArray(tie('anything'), { maxNumElements: maxKeys, size, depthIdentifier })]\n            : [])),\n        keys: constraints.withObjectString\n            ? oneof({ arbitrary: constraints.key, weight: 10 }, { arbitrary: tie('anything').map((o) => stringify(o)), weight: 1 })\n            : constraints.key,\n        array: array(tie('anything'), { maxLength: maxKeys, size, depthIdentifier }),\n        set: setOf(tie('anything'), maxKeys, size, depthIdentifier),\n        map: oneof(mapOf(tie('keys'), tie('anything'), maxKeys, size, depthIdentifier), mapOf(tie('anything'), tie('anything'), maxKeys, size, depthIdentifier)),\n        object: dictOf(tie('keys'), tie('anything'), maxKeys, size, depthIdentifier, constraints.withNullPrototype),\n    })).anything;\n}\n","import { unboxedToBoxedMapper, unboxedToBoxedUnmapper } from '../mappers/UnboxedToBoxed.js';\nexport function boxedArbitraryBuilder(arb) {\n    return arb.map(unboxedToBoxedMapper, unboxedToBoxedUnmapper);\n}\n","import { integer } from '../../integer.js';\nimport { indexToCharStringMapper, indexToCharStringUnmapper } from '../mappers/IndexToCharString.js';\nexport function buildCharacterArbitrary(min, max, mapToCode, unmapFromCode) {\n    return integer({ min, max }).map((n) => indexToCharStringMapper(mapToCode(n)), (c) => unmapFromCode(indexToCharStringUnmapper(c)));\n}\n","import { fullUnicode } from '../../fullUnicode.js';\nimport { oneof } from '../../oneof.js';\nimport { mapToConstant } from '../../mapToConstant.js';\nimport { safeCharCodeAt, safeNumberToString, encodeURIComponent } from '../../../utils/globals.js';\nconst safeStringFromCharCode = String.fromCharCode;\nconst lowerCaseMapper = { num: 26, build: (v) => safeStringFromCharCode(v + 0x61) };\nconst upperCaseMapper = { num: 26, build: (v) => safeStringFromCharCode(v + 0x41) };\nconst numericMapper = { num: 10, build: (v) => safeStringFromCharCode(v + 0x30) };\nfunction percentCharArbMapper(c) {\n    const encoded = encodeURIComponent(c);\n    return c !== encoded ? encoded : `%${safeNumberToString(safeCharCodeAt(c, 0), 16)}`;\n}\nfunction percentCharArbUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported');\n    }\n    const decoded = decodeURIComponent(value);\n    return decoded;\n}\nconst percentCharArb = fullUnicode().map(percentCharArbMapper, percentCharArbUnmapper);\nexport const buildLowerAlphaArbitrary = (others) => mapToConstant(lowerCaseMapper, { num: others.length, build: (v) => others[v] });\nexport const buildLowerAlphaNumericArbitrary = (others) => mapToConstant(lowerCaseMapper, numericMapper, { num: others.length, build: (v) => others[v] });\nexport const buildAlphaNumericArbitrary = (others) => mapToConstant(lowerCaseMapper, upperCaseMapper, numericMapper, { num: others.length, build: (v) => others[v] });\nexport const buildAlphaNumericPercentArbitrary = (others) => oneof({ weight: 10, arbitrary: buildAlphaNumericArbitrary(others) }, { weight: 1, arbitrary: percentCharArb });\n","import { escapeForMultilineComments } from '../helpers/TextEscaper.js';\nimport { cloneMethod } from '../../../check/symbols.js';\nimport { hash } from '../../../utils/hash.js';\nimport { stringify } from '../../../utils/stringify.js';\nimport { integer } from '../../integer.js';\nimport { tuple } from '../../tuple.js';\nimport { safeJoin } from '../../../utils/globals.js';\nconst safeObjectAssign = Object.assign;\nconst safeObjectKeys = Object.keys;\nexport function buildCompareFunctionArbitrary(cmp) {\n    return tuple(integer().noShrink(), integer({ min: 1, max: 0xffffffff }).noShrink()).map(([seed, hashEnvSize]) => {\n        const producer = () => {\n            const recorded = {};\n            const f = (a, b) => {\n                const reprA = stringify(a);\n                const reprB = stringify(b);\n                const hA = hash(`${seed}${reprA}`) % hashEnvSize;\n                const hB = hash(`${seed}${reprB}`) % hashEnvSize;\n                const val = cmp(hA, hB);\n                recorded[`[${reprA},${reprB}]`] = val;\n                return val;\n            };\n            return safeObjectAssign(f, {\n                toString: () => {\n                    const seenValues = safeObjectKeys(recorded)\n                        .sort()\n                        .map((k) => `${k} => ${stringify(recorded[k])}`)\n                        .map((line) => `/* ${escapeForMultilineComments(line)} */`);\n                    return `function(a, b) {\n  // With hash and stringify coming from fast-check${seenValues.length !== 0 ? `\\n  ${safeJoin(seenValues, '\\n  ')}` : ''}\n  const cmp = ${cmp};\n  const hA = hash('${seed}' + stringify(a)) % ${hashEnvSize};\n  const hB = hash('${seed}' + stringify(b)) % ${hashEnvSize};\n  return cmp(hA, hB);\n}`;\n                },\n                [cloneMethod]: producer,\n            });\n        };\n        return producer();\n    });\n}\n","import { Value } from '../../../check/arbitrary/definition/Value.js';\nimport { cloneMethod } from '../../../check/symbols.js';\nimport { stringify, toStringMethod } from '../../../utils/stringify.js';\nexport function buildGeneratorValue(mrng, biasFactor, computePreBuiltValues, arbitraryCache) {\n    const preBuiltValues = computePreBuiltValues();\n    let localMrng = mrng.clone();\n    const context = { mrng: mrng.clone(), biasFactor, history: [] };\n    const valueFunction = (arb) => {\n        const preBuiltValue = preBuiltValues[context.history.length];\n        if (preBuiltValue !== undefined && preBuiltValue.arb === arb) {\n            const value = preBuiltValue.value;\n            context.history.push({ arb, value, context: preBuiltValue.context, mrng: preBuiltValue.mrng });\n            localMrng = preBuiltValue.mrng.clone();\n            return value;\n        }\n        const g = arb.generate(localMrng, biasFactor);\n        context.history.push({ arb, value: g.value_, context: g.context, mrng: localMrng.clone() });\n        return g.value;\n    };\n    const memoedValueFunction = (arb, ...args) => {\n        return valueFunction(arbitraryCache(arb, args));\n    };\n    const valueMethods = {\n        values() {\n            return context.history.map((c) => c.value);\n        },\n        [cloneMethod]() {\n            return buildGeneratorValue(mrng, biasFactor, computePreBuiltValues, arbitraryCache).value;\n        },\n        [toStringMethod]() {\n            return stringify(context.history.map((c) => c.value));\n        },\n    };\n    const value = Object.assign(memoedValueFunction, valueMethods);\n    return new Value(value, context);\n}\n","import { integer } from '../../integer.js';\nimport { numberToPaddedEightMapper, numberToPaddedEightUnmapper } from '../mappers/NumberToPaddedEight.js';\nexport function buildPaddedNumberArbitrary(min, max) {\n    return integer({ min, max }).map(numberToPaddedEightMapper, numberToPaddedEightUnmapper);\n}\n","import { safeIndexOf, safePush } from '../../../utils/globals.js';\nimport { boolean } from '../../boolean.js';\nimport { constant } from '../../constant.js';\nimport { option } from '../../option.js';\nimport { tuple } from '../../tuple.js';\nimport { extractEnumerableKeys } from '../helpers/EnumerableKeysExtractor.js';\nimport { buildValuesAndSeparateKeysToObjectMapper, buildValuesAndSeparateKeysToObjectUnmapper, } from '../mappers/ValuesAndSeparateKeysToObject.js';\nconst noKeyValue = Symbol('no-key');\nexport function buildPartialRecordArbitrary(recordModel, requiredKeys, noNullPrototype) {\n    const keys = extractEnumerableKeys(recordModel);\n    const arbs = [];\n    for (let index = 0; index !== keys.length; ++index) {\n        const k = keys[index];\n        const requiredArbitrary = recordModel[k];\n        if (requiredKeys === undefined || safeIndexOf(requiredKeys, k) !== -1) {\n            safePush(arbs, requiredArbitrary);\n        }\n        else {\n            safePush(arbs, option(requiredArbitrary, { nil: noKeyValue }));\n        }\n    }\n    return tuple(tuple(...arbs), noNullPrototype ? constant(false) : boolean()).map(buildValuesAndSeparateKeysToObjectMapper(keys, noKeyValue), buildValuesAndSeparateKeysToObjectUnmapper(keys, noKeyValue));\n}\n","import { integer } from '../../integer.js';\nimport { WithShrinkFromOtherArbitrary } from '../WithShrinkFromOtherArbitrary.js';\nexport function restrictedIntegerArbitraryBuilder(min, maxGenerated, max) {\n    const generatorArbitrary = integer({ min, max: maxGenerated });\n    if (maxGenerated === max) {\n        return generatorArbitrary;\n    }\n    const shrinkerArbitrary = integer({ min, max });\n    return new WithShrinkFromOtherArbitrary(generatorArbitrary, shrinkerArbitrary);\n}\n","export function buildStableArbitraryGeneratorCache(isEqual) {\n    const previousCallsPerBuilder = new Map();\n    return function stableArbitraryGeneratorCache(builder, args) {\n        const entriesForBuilder = previousCallsPerBuilder.get(builder);\n        if (entriesForBuilder === undefined) {\n            const newValue = builder(...args);\n            previousCallsPerBuilder.set(builder, [{ args, value: newValue }]);\n            return newValue;\n        }\n        const safeEntriesForBuilder = entriesForBuilder;\n        for (const entry of safeEntriesForBuilder) {\n            if (isEqual(args, entry.args)) {\n                return entry.value;\n            }\n        }\n        const newValue = builder(...args);\n        safeEntriesForBuilder.push({ args, value: newValue });\n        return newValue;\n    };\n}\nexport function naiveIsEqual(v1, v2) {\n    if (v1 !== null && typeof v1 === 'object' && v2 !== null && typeof v2 === 'object') {\n        if (Array.isArray(v1)) {\n            if (!Array.isArray(v2))\n                return false;\n            if (v1.length !== v2.length)\n                return false;\n        }\n        else if (Array.isArray(v2)) {\n            return false;\n        }\n        if (Object.keys(v1).length !== Object.keys(v2).length) {\n            return false;\n        }\n        for (const index in v1) {\n            if (!(index in v2)) {\n                return false;\n            }\n            if (!naiveIsEqual(v1[index], v2[index])) {\n                return false;\n            }\n        }\n        return true;\n    }\n    else {\n        return Object.is(v1, v2);\n    }\n}\n","import { constantFrom } from '../../constantFrom.js';\nimport { nat } from '../../nat.js';\nimport { tuple } from '../../tuple.js';\nimport { natToStringifiedNatMapper, natToStringifiedNatUnmapper } from '../mappers/NatToStringifiedNat.js';\nexport function buildStringifiedNatArbitrary(maxValue) {\n    return tuple(constantFrom('dec', 'oct', 'hex'), nat(maxValue)).map(natToStringifiedNatMapper, natToStringifiedNatUnmapper);\n}\n","var __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport { array } from '../../array.js';\nexport function typedIntArrayArbitraryArbitraryBuilder(constraints, defaultMin, defaultMax, TypedArrayClass, arbitraryBuilder) {\n    const generatorName = TypedArrayClass.name;\n    const { min = defaultMin, max = defaultMax } = constraints, arrayConstraints = __rest(constraints, [\"min\", \"max\"]);\n    if (min > max) {\n        throw new Error(`Invalid range passed to ${generatorName}: min must be lower than or equal to max`);\n    }\n    if (min < defaultMin) {\n        throw new Error(`Invalid min value passed to ${generatorName}: min must be greater than or equal to ${defaultMin}`);\n    }\n    if (max > defaultMax) {\n        throw new Error(`Invalid max value passed to ${generatorName}: max must be lower than or equal to ${defaultMax}`);\n    }\n    return array(arbitraryBuilder({ min, max }), arrayConstraints).map((data) => TypedArrayClass.from(data), (value) => {\n        if (!(value instanceof TypedArrayClass))\n            throw new Error('Invalid type');\n        return [...value];\n    });\n}\n","import { webSegment } from '../../webSegment.js';\nimport { array } from '../../array.js';\nimport { segmentsToPathMapper, segmentsToPathUnmapper } from '../mappers/SegmentsToPath.js';\nimport { oneof } from '../../oneof.js';\nfunction sqrtSize(size) {\n    switch (size) {\n        case 'xsmall':\n            return ['xsmall', 'xsmall'];\n        case 'small':\n            return ['small', 'xsmall'];\n        case 'medium':\n            return ['small', 'small'];\n        case 'large':\n            return ['medium', 'small'];\n        case 'xlarge':\n            return ['medium', 'medium'];\n    }\n}\nfunction buildUriPathArbitraryInternal(segmentSize, numSegmentSize) {\n    return array(webSegment({ size: segmentSize }), { size: numSegmentSize }).map(segmentsToPathMapper, segmentsToPathUnmapper);\n}\nexport function buildUriPathArbitrary(resolvedSize) {\n    const [segmentSize, numSegmentSize] = sqrtSize(resolvedSize);\n    if (segmentSize === numSegmentSize) {\n        return buildUriPathArbitraryInternal(segmentSize, numSegmentSize);\n    }\n    return oneof(buildUriPathArbitraryInternal(segmentSize, numSegmentSize), buildUriPathArbitraryInternal(numSegmentSize, segmentSize));\n}\n","import { buildAlphaNumericPercentArbitrary } from './CharacterRangeArbitraryBuilder.js';\nimport { stringOf } from '../../stringOf.js';\nexport function buildUriQueryOrFragmentArbitrary(size) {\n    const others = ['-', '.', '_', '~', '!', '$', '&', \"'\", '(', ')', '*', '+', ',', ';', '=', ':', '@', '/', '?'];\n    return stringOf(buildAlphaNumericPercentArbitrary(others), { size });\n}\n","export const Zero64 = { sign: 1, data: [0, 0] };\nexport const Unit64 = { sign: 1, data: [0, 1] };\nexport function isZero64(a) {\n    return a.data[0] === 0 && a.data[1] === 0;\n}\nexport function isStrictlyNegative64(a) {\n    return a.sign === -1 && !isZero64(a);\n}\nexport function isStrictlyPositive64(a) {\n    return a.sign === 1 && !isZero64(a);\n}\nexport function isEqual64(a, b) {\n    if (a.data[0] === b.data[0] && a.data[1] === b.data[1]) {\n        return a.sign === b.sign || (a.data[0] === 0 && a.data[1] === 0);\n    }\n    return false;\n}\nfunction isStrictlySmaller64Internal(a, b) {\n    return a[0] < b[0] || (a[0] === b[0] && a[1] < b[1]);\n}\nexport function isStrictlySmaller64(a, b) {\n    if (a.sign === b.sign) {\n        return a.sign === 1\n            ? isStrictlySmaller64Internal(a.data, b.data)\n            : isStrictlySmaller64Internal(b.data, a.data);\n    }\n    return a.sign === -1 && (!isZero64(a) || !isZero64(b));\n}\nexport function clone64(a) {\n    return { sign: a.sign, data: [a.data[0], a.data[1]] };\n}\nfunction substract64DataInternal(a, b) {\n    let reminderLow = 0;\n    let low = a[1] - b[1];\n    if (low < 0) {\n        reminderLow = 1;\n        low = low >>> 0;\n    }\n    return [a[0] - b[0] - reminderLow, low];\n}\nfunction substract64Internal(a, b) {\n    if (a.sign === 1 && b.sign === -1) {\n        const low = a.data[1] + b.data[1];\n        const high = a.data[0] + b.data[0] + (low > 0xffffffff ? 1 : 0);\n        return { sign: 1, data: [high >>> 0, low >>> 0] };\n    }\n    return {\n        sign: 1,\n        data: a.sign === 1 ? substract64DataInternal(a.data, b.data) : substract64DataInternal(b.data, a.data),\n    };\n}\nexport function substract64(arrayIntA, arrayIntB) {\n    if (isStrictlySmaller64(arrayIntA, arrayIntB)) {\n        const out = substract64Internal(arrayIntB, arrayIntA);\n        out.sign = -1;\n        return out;\n    }\n    return substract64Internal(arrayIntA, arrayIntB);\n}\nexport function negative64(arrayIntA) {\n    return {\n        sign: -arrayIntA.sign,\n        data: [arrayIntA.data[0], arrayIntA.data[1]],\n    };\n}\nexport function add64(arrayIntA, arrayIntB) {\n    if (isZero64(arrayIntB)) {\n        if (isZero64(arrayIntA)) {\n            return clone64(Zero64);\n        }\n        return clone64(arrayIntA);\n    }\n    return substract64(arrayIntA, negative64(arrayIntB));\n}\nexport function halve64(a) {\n    return {\n        sign: a.sign,\n        data: [Math.floor(a.data[0] / 2), (a.data[0] % 2 === 1 ? 0x80000000 : 0) + Math.floor(a.data[1] / 2)],\n    };\n}\nexport function logLike64(a) {\n    return {\n        sign: a.sign,\n        data: [0, Math.floor(Math.log(a.data[0] * 0x100000000 + a.data[1]) / Math.log(2))],\n    };\n}\n","import { BigInt, String } from '../../../utils/globals.js';\nconst safeMathFloor = Math.floor;\nconst safeMathLog = Math.log;\nexport function integerLogLike(v) {\n    return safeMathFloor(safeMathLog(v) / safeMathLog(2));\n}\nexport function bigIntLogLike(v) {\n    if (v === BigInt(0))\n        return BigInt(0);\n    return BigInt(String(v).length);\n}\nfunction biasNumericRange(min, max, logLike) {\n    if (min === max) {\n        return [{ min: min, max: max }];\n    }\n    if (min < 0 && max > 0) {\n        const logMin = logLike(-min);\n        const logMax = logLike(max);\n        return [\n            { min: -logMin, max: logMax },\n            { min: (max - logMax), max: max },\n            { min: min, max: min + logMin },\n        ];\n    }\n    const logGap = logLike((max - min));\n    const arbCloseToMin = { min: min, max: min + logGap };\n    const arbCloseToMax = { min: (max - logGap), max: max };\n    return min < 0\n        ? [arbCloseToMax, arbCloseToMin]\n        : [arbCloseToMin, arbCloseToMax];\n}\nexport { biasNumericRange };\n","import { SchedulerImplem } from '../implementations/SchedulerImplem.js';\nfunction buildNextTaskIndex(ordering) {\n    let numTasks = 0;\n    return {\n        clone: () => buildNextTaskIndex(ordering),\n        nextTaskIndex: (scheduledTasks) => {\n            if (ordering.length <= numTasks) {\n                throw new Error(`Invalid schedulerFor defined: too many tasks have been scheduled`);\n            }\n            const taskIndex = scheduledTasks.findIndex((t) => t.taskId === ordering[numTasks]);\n            if (taskIndex === -1) {\n                throw new Error(`Invalid schedulerFor defined: unable to find next task`);\n            }\n            ++numTasks;\n            return taskIndex;\n        },\n    };\n}\nexport function buildSchedulerFor(act, ordering) {\n    return new SchedulerImplem(act, buildNextTaskIndex(ordering));\n}\n","import { NoopSlicedGenerator } from '../implementations/NoopSlicedGenerator.js';\nimport { SlicedBasedGenerator } from '../implementations/SlicedBasedGenerator.js';\nexport function buildSlicedGenerator(arb, mrng, slices, biasFactor) {\n    if (biasFactor === undefined || slices.length === 0 || mrng.nextInt(1, biasFactor) !== 1) {\n        return new NoopSlicedGenerator(arb, mrng, biasFactor);\n    }\n    return new SlicedBasedGenerator(arb, mrng, slices, biasFactor);\n}\n","import { safePush } from '../../../utils/globals.js';\nexport class CustomEqualSet {\n    constructor(isEqual) {\n        this.isEqual = isEqual;\n        this.data = [];\n    }\n    tryAdd(value) {\n        for (let idx = 0; idx !== this.data.length; ++idx) {\n            if (this.isEqual(this.data[idx], value)) {\n                return false;\n            }\n        }\n        safePush(this.data, value);\n        return true;\n    }\n    size() {\n        return this.data.length;\n    }\n    getData() {\n        return this.data;\n    }\n}\n","const depthContextCache = new Map();\nexport function getDepthContextFor(contextMeta) {\n    if (contextMeta === undefined) {\n        return { depth: 0 };\n    }\n    if (typeof contextMeta !== 'string') {\n        return contextMeta;\n    }\n    const cachedContext = depthContextCache.get(contextMeta);\n    if (cachedContext !== undefined) {\n        return cachedContext;\n    }\n    const context = { depth: 0 };\n    depthContextCache.set(contextMeta, context);\n    return context;\n}\nexport function createDepthIdentifier() {\n    const identifier = { depth: 0 };\n    return identifier;\n}\n","import { clone64, isEqual64 } from './ArrayInt64.js';\nconst safeNegativeInfinity = Number.NEGATIVE_INFINITY;\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nconst safeEpsilon = Number.EPSILON;\nconst INDEX_POSITIVE_INFINITY = { sign: 1, data: [2146435072, 0] };\nconst INDEX_NEGATIVE_INFINITY = { sign: -1, data: [2146435072, 1] };\nconst f64 = new Float64Array(1);\nconst u32 = new Uint32Array(f64.buffer, f64.byteOffset);\nfunction bitCastDoubleToUInt64(f) {\n    f64[0] = f;\n    return [u32[1], u32[0]];\n}\nexport function decomposeDouble(d) {\n    const { 0: hi, 1: lo } = bitCastDoubleToUInt64(d);\n    const signBit = hi >>> 31;\n    const exponentBits = (hi >>> 20) & 0x7ff;\n    const significandBits = (hi & 0xfffff) * 0x100000000 + lo;\n    const exponent = exponentBits === 0 ? -1022 : exponentBits - 1023;\n    let significand = exponentBits === 0 ? 0 : 1;\n    significand += significandBits / 2 ** 52;\n    significand *= signBit === 0 ? 1 : -1;\n    return { exponent, significand };\n}\nfunction positiveNumberToInt64(n) {\n    return [~~(n / 0x100000000), n >>> 0];\n}\nfunction indexInDoubleFromDecomp(exponent, significand) {\n    if (exponent === -1022) {\n        const rescaledSignificand = significand * 2 ** 52;\n        return positiveNumberToInt64(rescaledSignificand);\n    }\n    const rescaledSignificand = (significand - 1) * 2 ** 52;\n    const exponentOnlyHigh = (exponent + 1023) * 2 ** 20;\n    const index = positiveNumberToInt64(rescaledSignificand);\n    index[0] += exponentOnlyHigh;\n    return index;\n}\nexport function doubleToIndex(d) {\n    if (d === safePositiveInfinity) {\n        return clone64(INDEX_POSITIVE_INFINITY);\n    }\n    if (d === safeNegativeInfinity) {\n        return clone64(INDEX_NEGATIVE_INFINITY);\n    }\n    const decomp = decomposeDouble(d);\n    const exponent = decomp.exponent;\n    const significand = decomp.significand;\n    if (d > 0 || (d === 0 && 1 / d === safePositiveInfinity)) {\n        return { sign: 1, data: indexInDoubleFromDecomp(exponent, significand) };\n    }\n    else {\n        const indexOpposite = indexInDoubleFromDecomp(exponent, -significand);\n        if (indexOpposite[1] === 0xffffffff) {\n            indexOpposite[0] += 1;\n            indexOpposite[1] = 0;\n        }\n        else {\n            indexOpposite[1] += 1;\n        }\n        return { sign: -1, data: indexOpposite };\n    }\n}\nexport function indexToDouble(index) {\n    if (index.sign === -1) {\n        const indexOpposite = { sign: 1, data: [index.data[0], index.data[1]] };\n        if (indexOpposite.data[1] === 0) {\n            indexOpposite.data[0] -= 1;\n            indexOpposite.data[1] = 0xffffffff;\n        }\n        else {\n            indexOpposite.data[1] -= 1;\n        }\n        return -indexToDouble(indexOpposite);\n    }\n    if (isEqual64(index, INDEX_POSITIVE_INFINITY)) {\n        return safePositiveInfinity;\n    }\n    if (index.data[0] < 0x200000) {\n        return (index.data[0] * 0x100000000 + index.data[1]) * 2 ** -1074;\n    }\n    const postIndexHigh = index.data[0] - 0x200000;\n    const exponent = -1021 + (postIndexHigh >> 20);\n    const significand = 1 + ((postIndexHigh & 0xfffff) * 2 ** 32 + index.data[1]) * safeEpsilon;\n    return significand * 2 ** exponent;\n}\n","import { refineConstraintsForFloatingOnly } from './FloatingOnlyHelpers.js';\nconst safeNegativeInfinity = Number.NEGATIVE_INFINITY;\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nconst safeMaxValue = Number.MAX_VALUE;\nexport const maxNonIntegerValue = 4503599627370495.5;\nexport const onlyIntegersAfterThisValue = 4503599627370496;\nexport function refineConstraintsForDoubleOnly(constraints) {\n    return refineConstraintsForFloatingOnly(constraints, safeMaxValue, maxNonIntegerValue, onlyIntegersAfterThisValue);\n}\nexport function doubleOnlyMapper(value) {\n    return value === onlyIntegersAfterThisValue\n        ? safePositiveInfinity\n        : value === -onlyIntegersAfterThisValue\n            ? safeNegativeInfinity\n            : value;\n}\nexport function doubleOnlyUnmapper(value) {\n    if (typeof value !== 'number')\n        throw new Error('Unsupported type');\n    return value === safePositiveInfinity\n        ? onlyIntegersAfterThisValue\n        : value === safeNegativeInfinity\n            ? -onlyIntegersAfterThisValue\n            : value;\n}\n","const safeObjectKeys = Object.keys;\nconst safeObjectGetOwnPropertySymbols = Object.getOwnPropertySymbols;\nconst safeObjectGetOwnPropertyDescriptor = Object.getOwnPropertyDescriptor;\nexport function extractEnumerableKeys(instance) {\n    const keys = safeObjectKeys(instance);\n    const symbols = safeObjectGetOwnPropertySymbols(instance);\n    for (let index = 0; index !== symbols.length; ++index) {\n        const symbol = symbols[index];\n        const descriptor = safeObjectGetOwnPropertyDescriptor(instance, symbol);\n        if (descriptor && descriptor.enumerable) {\n            keys.push(symbol);\n        }\n    }\n    return keys;\n}\n","const safeNegativeInfinity = Number.NEGATIVE_INFINITY;\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nexport const MIN_VALUE_32 = 2 ** -126 * 2 ** -23;\nexport const MAX_VALUE_32 = 2 ** 127 * (1 + (2 ** 23 - 1) / 2 ** 23);\nexport const EPSILON_32 = 2 ** -23;\nconst INDEX_POSITIVE_INFINITY = 2139095040;\nconst INDEX_NEGATIVE_INFINITY = -2139095041;\nconst f32 = new Float32Array(1);\nconst u32 = new Uint32Array(f32.buffer, f32.byteOffset);\nfunction bitCastFloatToUInt32(f) {\n    f32[0] = f;\n    return u32[0];\n}\nexport function decomposeFloat(f) {\n    const bits = bitCastFloatToUInt32(f);\n    const signBit = bits >>> 31;\n    const exponentBits = (bits >>> 23) & 0xff;\n    const significandBits = bits & 0x7fffff;\n    const exponent = exponentBits === 0 ? -126 : exponentBits - 127;\n    let significand = exponentBits === 0 ? 0 : 1;\n    significand += significandBits / 2 ** 23;\n    significand *= signBit === 0 ? 1 : -1;\n    return { exponent, significand };\n}\nfunction indexInFloatFromDecomp(exponent, significand) {\n    if (exponent === -126) {\n        return significand * 0x800000;\n    }\n    return (exponent + 127) * 0x800000 + (significand - 1) * 0x800000;\n}\nexport function floatToIndex(f) {\n    if (f === safePositiveInfinity) {\n        return INDEX_POSITIVE_INFINITY;\n    }\n    if (f === safeNegativeInfinity) {\n        return INDEX_NEGATIVE_INFINITY;\n    }\n    const decomp = decomposeFloat(f);\n    const exponent = decomp.exponent;\n    const significand = decomp.significand;\n    if (f > 0 || (f === 0 && 1 / f === safePositiveInfinity)) {\n        return indexInFloatFromDecomp(exponent, significand);\n    }\n    else {\n        return -indexInFloatFromDecomp(exponent, -significand) - 1;\n    }\n}\nexport function indexToFloat(index) {\n    if (index < 0) {\n        return -indexToFloat(-index - 1);\n    }\n    if (index === INDEX_POSITIVE_INFINITY) {\n        return safePositiveInfinity;\n    }\n    if (index < 0x1000000) {\n        return index * 2 ** -149;\n    }\n    const postIndex = index - 0x1000000;\n    const exponent = -125 + (postIndex >> 23);\n    const significand = 1 + (postIndex & 0x7fffff) / 0x800000;\n    return significand * 2 ** exponent;\n}\n","import { MAX_VALUE_32 } from './FloatHelpers.js';\nimport { refineConstraintsForFloatingOnly } from './FloatingOnlyHelpers.js';\nconst safeNegativeInfinity = Number.NEGATIVE_INFINITY;\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nconst safeMaxValue = MAX_VALUE_32;\nexport const maxNonIntegerValue = 8388607.5;\nexport const onlyIntegersAfterThisValue = 8388608;\nexport function refineConstraintsForFloatOnly(constraints) {\n    return refineConstraintsForFloatingOnly(constraints, safeMaxValue, maxNonIntegerValue, onlyIntegersAfterThisValue);\n}\nexport function floatOnlyMapper(value) {\n    return value === onlyIntegersAfterThisValue\n        ? safePositiveInfinity\n        : value === -onlyIntegersAfterThisValue\n            ? safeNegativeInfinity\n            : value;\n}\nexport function floatOnlyUnmapper(value) {\n    if (typeof value !== 'number')\n        throw new Error('Unsupported type');\n    return value === safePositiveInfinity\n        ? onlyIntegersAfterThisValue\n        : value === safeNegativeInfinity\n            ? -onlyIntegersAfterThisValue\n            : value;\n}\n","const safeNumberIsInteger = Number.isInteger;\nconst safeObjectIs = Object.is;\nconst safeNegativeInfinity = Number.NEGATIVE_INFINITY;\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nexport function refineConstraintsForFloatingOnly(constraints, maxValue, maxNonIntegerValue, onlyIntegersAfterThisValue) {\n    const { noDefaultInfinity = false, minExcluded = false, maxExcluded = false, min = noDefaultInfinity ? -maxValue : safeNegativeInfinity, max = noDefaultInfinity ? maxValue : safePositiveInfinity, } = constraints;\n    const effectiveMin = minExcluded\n        ? min < -maxNonIntegerValue\n            ? -onlyIntegersAfterThisValue\n            : Math.max(min, -maxNonIntegerValue)\n        : min === safeNegativeInfinity\n            ? Math.max(min, -onlyIntegersAfterThisValue)\n            : Math.max(min, -maxNonIntegerValue);\n    const effectiveMax = maxExcluded\n        ? max > maxNonIntegerValue\n            ? onlyIntegersAfterThisValue\n            : Math.min(max, maxNonIntegerValue)\n        : max === safePositiveInfinity\n            ? Math.min(max, onlyIntegersAfterThisValue)\n            : Math.min(max, maxNonIntegerValue);\n    const fullConstraints = {\n        noDefaultInfinity: false,\n        minExcluded: minExcluded || ((min !== safeNegativeInfinity || minExcluded) && safeNumberIsInteger(effectiveMin)),\n        maxExcluded: maxExcluded || ((max !== safePositiveInfinity || maxExcluded) && safeNumberIsInteger(effectiveMax)),\n        min: safeObjectIs(effectiveMin, -0) ? 0 : effectiveMin,\n        max: safeObjectIs(effectiveMax, 0) ? -0 : effectiveMax,\n        noNaN: constraints.noNaN || false,\n    };\n    return fullConstraints;\n}\n","export function filterInvalidSubdomainLabel(subdomainLabel) {\n    if (subdomainLabel.length > 63) {\n        return false;\n    }\n    return (subdomainLabel.length < 4 ||\n        subdomainLabel[0] !== 'x' ||\n        subdomainLabel[1] !== 'n' ||\n        subdomainLabel[2] !== '-' ||\n        subdomainLabel[3] !== '-');\n}\n","export function isSubarrayOf(source, small) {\n    const countMap = new Map();\n    let countMinusZero = 0;\n    for (const sourceEntry of source) {\n        if (Object.is(sourceEntry, -0)) {\n            ++countMinusZero;\n        }\n        else {\n            const oldCount = countMap.get(sourceEntry) || 0;\n            countMap.set(sourceEntry, oldCount + 1);\n        }\n    }\n    for (let index = 0; index !== small.length; ++index) {\n        if (!(index in small)) {\n            return false;\n        }\n        const smallEntry = small[index];\n        if (Object.is(smallEntry, -0)) {\n            if (countMinusZero === 0)\n                return false;\n            --countMinusZero;\n        }\n        else {\n            const oldCount = countMap.get(smallEntry) || 0;\n            if (oldCount === 0)\n                return false;\n            countMap.set(smallEntry, oldCount - 1);\n        }\n    }\n    return true;\n}\n","import { boolean } from '../../boolean.js';\nimport { constant } from '../../constant.js';\nimport { double } from '../../double.js';\nexport function jsonConstraintsBuilder(stringArbitrary, constraints) {\n    const { depthSize, maxDepth } = constraints;\n    const key = stringArbitrary;\n    const values = [\n        boolean(),\n        double({ noDefaultInfinity: true, noNaN: true }),\n        stringArbitrary,\n        constant(null),\n    ];\n    return { key, values, depthSize, maxDepth };\n}\n","import { readConfigureGlobal } from '../../../check/runner/configuration/GlobalParameters.js';\nimport { safeIndexOf } from '../../../utils/globals.js';\nconst safeMathFloor = Math.floor;\nconst safeMathMin = Math.min;\nexport const MaxLengthUpperBound = 0x7fffffff;\nconst orderedSize = ['xsmall', 'small', 'medium', 'large', 'xlarge'];\nconst orderedRelativeSize = ['-4', '-3', '-2', '-1', '=', '+1', '+2', '+3', '+4'];\nexport const DefaultSize = 'small';\nexport function maxLengthFromMinLength(minLength, size) {\n    switch (size) {\n        case 'xsmall':\n            return safeMathFloor(1.1 * minLength) + 1;\n        case 'small':\n            return 2 * minLength + 10;\n        case 'medium':\n            return 11 * minLength + 100;\n        case 'large':\n            return 101 * minLength + 1000;\n        case 'xlarge':\n            return 1001 * minLength + 10000;\n        default:\n            throw new Error(`Unable to compute lengths based on received size: ${size}`);\n    }\n}\nexport function relativeSizeToSize(size, defaultSize) {\n    const sizeInRelative = safeIndexOf(orderedRelativeSize, size);\n    if (sizeInRelative === -1) {\n        return size;\n    }\n    const defaultSizeInSize = safeIndexOf(orderedSize, defaultSize);\n    if (defaultSizeInSize === -1) {\n        throw new Error(`Unable to offset size based on the unknown defaulted one: ${defaultSize}`);\n    }\n    const resultingSizeInSize = defaultSizeInSize + sizeInRelative - 4;\n    return resultingSizeInSize < 0\n        ? orderedSize[0]\n        : resultingSizeInSize >= orderedSize.length\n            ? orderedSize[orderedSize.length - 1]\n            : orderedSize[resultingSizeInSize];\n}\nexport function maxGeneratedLengthFromSizeForArbitrary(size, minLength, maxLength, specifiedMaxLength) {\n    const { baseSize: defaultSize = DefaultSize, defaultSizeToMaxWhenMaxSpecified } = readConfigureGlobal() || {};\n    const definedSize = size !== undefined ? size : specifiedMaxLength && defaultSizeToMaxWhenMaxSpecified ? 'max' : defaultSize;\n    if (definedSize === 'max') {\n        return maxLength;\n    }\n    const finalSize = relativeSizeToSize(definedSize, defaultSize);\n    return safeMathMin(maxLengthFromMinLength(minLength, finalSize), maxLength);\n}\nexport function depthBiasFromSizeForArbitrary(depthSizeOrSize, specifiedMaxDepth) {\n    if (typeof depthSizeOrSize === 'number') {\n        return 1 / depthSizeOrSize;\n    }\n    const { baseSize: defaultSize = DefaultSize, defaultSizeToMaxWhenMaxSpecified } = readConfigureGlobal() || {};\n    const definedSize = depthSizeOrSize !== undefined\n        ? depthSizeOrSize\n        : specifiedMaxDepth && defaultSizeToMaxWhenMaxSpecified\n            ? 'max'\n            : defaultSize;\n    if (definedSize === 'max') {\n        return 0;\n    }\n    const finalSize = relativeSizeToSize(definedSize, defaultSize);\n    switch (finalSize) {\n        case 'xsmall':\n            return 1;\n        case 'small':\n            return 0.5;\n        case 'medium':\n            return 0.25;\n        case 'large':\n            return 0.125;\n        case 'xlarge':\n            return 0.0625;\n    }\n}\nexport function resolveSize(size) {\n    const { baseSize: defaultSize = DefaultSize } = readConfigureGlobal() || {};\n    if (size === undefined) {\n        return defaultSize;\n    }\n    return relativeSizeToSize(size, defaultSize);\n}\n","import { Value } from '../../../check/arbitrary/definition/Value.js';\nexport const UndefinedContextPlaceholder = Symbol('UndefinedContextPlaceholder');\nexport function noUndefinedAsContext(value) {\n    if (value.context !== undefined) {\n        return value;\n    }\n    if (value.hasToBeCloned) {\n        return new Value(value.value_, UndefinedContextPlaceholder, () => value.value);\n    }\n    return new Value(value.value_, UndefinedContextPlaceholder);\n}\n","import { boolean } from '../../boolean.js';\nimport { constant } from '../../constant.js';\nimport { double } from '../../double.js';\nimport { fullUnicodeString } from '../../fullUnicodeString.js';\nimport { maxSafeInteger } from '../../maxSafeInteger.js';\nimport { oneof } from '../../oneof.js';\nimport { string } from '../../string.js';\nimport { boxedArbitraryBuilder } from '../builders/BoxedArbitraryBuilder.js';\nfunction defaultValues(constraints, stringArbitrary) {\n    return [\n        boolean(),\n        maxSafeInteger(),\n        double(),\n        stringArbitrary(constraints),\n        oneof(stringArbitrary(constraints), constant(null), constant(undefined)),\n    ];\n}\nfunction boxArbitraries(arbs) {\n    return arbs.map((arb) => boxedArbitraryBuilder(arb));\n}\nfunction boxArbitrariesIfNeeded(arbs, boxEnabled) {\n    return boxEnabled ? boxArbitraries(arbs).concat(arbs) : arbs;\n}\nexport function toQualifiedObjectConstraints(settings = {}) {\n    function orDefault(optionalValue, defaultValue) {\n        return optionalValue !== undefined ? optionalValue : defaultValue;\n    }\n    const stringArbitrary = settings.withUnicodeString ? fullUnicodeString : string;\n    const valueConstraints = { size: settings.size };\n    return {\n        key: orDefault(settings.key, stringArbitrary(valueConstraints)),\n        values: boxArbitrariesIfNeeded(orDefault(settings.values, defaultValues(valueConstraints, stringArbitrary)), orDefault(settings.withBoxedValues, false)),\n        depthSize: settings.depthSize,\n        maxDepth: settings.maxDepth,\n        maxKeys: settings.maxKeys,\n        size: settings.size,\n        withSet: orDefault(settings.withSet, false),\n        withMap: orDefault(settings.withMap, false),\n        withObjectString: orDefault(settings.withObjectString, false),\n        withNullPrototype: orDefault(settings.withNullPrototype, false),\n        withBigInt: orDefault(settings.withBigInt, false),\n        withDate: orDefault(settings.withDate, false),\n        withTypedArray: orDefault(settings.withTypedArray, false),\n        withSparseArray: orDefault(settings.withSparseArray, false),\n    };\n}\n","function charSizeAt(text, pos) {\n    return text[pos] >= '\\uD800' && text[pos] <= '\\uDBFF' && text[pos + 1] >= '\\uDC00' && text[pos + 1] <= '\\uDFFF'\n        ? 2\n        : 1;\n}\nfunction isHexaDigit(char) {\n    return (char >= '0' && char <= '9') || (char >= 'a' && char <= 'f') || (char >= 'A' && char <= 'F');\n}\nfunction isDigit(char) {\n    return char >= '0' && char <= '9';\n}\nfunction squaredBracketBlockContentEndFrom(text, from) {\n    for (let index = from; index !== text.length; ++index) {\n        const char = text[index];\n        if (char === '\\\\') {\n            index += 1;\n        }\n        else if (char === ']') {\n            return index;\n        }\n    }\n    throw new Error(`Missing closing ']'`);\n}\nfunction parenthesisBlockContentEndFrom(text, from) {\n    let numExtraOpened = 0;\n    for (let index = from; index !== text.length; ++index) {\n        const char = text[index];\n        if (char === '\\\\') {\n            index += 1;\n        }\n        else if (char === ')') {\n            if (numExtraOpened === 0) {\n                return index;\n            }\n            numExtraOpened -= 1;\n        }\n        else if (char === '[') {\n            index = squaredBracketBlockContentEndFrom(text, index);\n        }\n        else if (char === '(') {\n            numExtraOpened += 1;\n        }\n    }\n    throw new Error(`Missing closing ')'`);\n}\nfunction curlyBracketBlockContentEndFrom(text, from) {\n    let foundComma = false;\n    for (let index = from; index !== text.length; ++index) {\n        const char = text[index];\n        if (isDigit(char)) {\n        }\n        else if (from === index) {\n            return -1;\n        }\n        else if (char === ',') {\n            if (foundComma) {\n                return -1;\n            }\n            foundComma = true;\n        }\n        else if (char === '}') {\n            return index;\n        }\n        else {\n            return -1;\n        }\n    }\n    return -1;\n}\nexport var TokenizerBlockMode;\n(function (TokenizerBlockMode) {\n    TokenizerBlockMode[TokenizerBlockMode[\"Full\"] = 0] = \"Full\";\n    TokenizerBlockMode[TokenizerBlockMode[\"Character\"] = 1] = \"Character\";\n})(TokenizerBlockMode || (TokenizerBlockMode = {}));\nfunction blockEndFrom(text, from, unicodeMode, mode) {\n    switch (text[from]) {\n        case '[': {\n            if (mode === TokenizerBlockMode.Character) {\n                return from + 1;\n            }\n            return squaredBracketBlockContentEndFrom(text, from + 1) + 1;\n        }\n        case '{': {\n            if (mode === TokenizerBlockMode.Character) {\n                return from + 1;\n            }\n            const foundEnd = curlyBracketBlockContentEndFrom(text, from + 1);\n            if (foundEnd === -1) {\n                return from + 1;\n            }\n            return foundEnd + 1;\n        }\n        case '(': {\n            if (mode === TokenizerBlockMode.Character) {\n                return from + 1;\n            }\n            return parenthesisBlockContentEndFrom(text, from + 1) + 1;\n        }\n        case ']':\n        case '}':\n        case ')':\n            return from + 1;\n        case '\\\\': {\n            const next1 = text[from + 1];\n            switch (next1) {\n                case 'x':\n                    if (isHexaDigit(text[from + 2]) && isHexaDigit(text[from + 3])) {\n                        return from + 4;\n                    }\n                    throw new Error(`Unexpected token '${text.substring(from, from + 4)}' found`);\n                case 'u':\n                    if (text[from + 2] === '{') {\n                        if (!unicodeMode) {\n                            return from + 2;\n                        }\n                        if (text[from + 4] === '}') {\n                            if (isHexaDigit(text[from + 3])) {\n                                return from + 5;\n                            }\n                            throw new Error(`Unexpected token '${text.substring(from, from + 5)}' found`);\n                        }\n                        if (text[from + 5] === '}') {\n                            if (isHexaDigit(text[from + 3]) && isHexaDigit(text[from + 4])) {\n                                return from + 6;\n                            }\n                            throw new Error(`Unexpected token '${text.substring(from, from + 6)}' found`);\n                        }\n                        if (text[from + 6] === '}') {\n                            if (isHexaDigit(text[from + 3]) && isHexaDigit(text[from + 4]) && isHexaDigit(text[from + 5])) {\n                                return from + 7;\n                            }\n                            throw new Error(`Unexpected token '${text.substring(from, from + 7)}' found`);\n                        }\n                        if (text[from + 7] === '}') {\n                            if (isHexaDigit(text[from + 3]) &&\n                                isHexaDigit(text[from + 4]) &&\n                                isHexaDigit(text[from + 5]) &&\n                                isHexaDigit(text[from + 6])) {\n                                return from + 8;\n                            }\n                            throw new Error(`Unexpected token '${text.substring(from, from + 8)}' found`);\n                        }\n                        if (text[from + 8] === '}' &&\n                            isHexaDigit(text[from + 3]) &&\n                            isHexaDigit(text[from + 4]) &&\n                            isHexaDigit(text[from + 5]) &&\n                            isHexaDigit(text[from + 6]) &&\n                            isHexaDigit(text[from + 7])) {\n                            return from + 9;\n                        }\n                        throw new Error(`Unexpected token '${text.substring(from, from + 9)}' found`);\n                    }\n                    if (isHexaDigit(text[from + 2]) &&\n                        isHexaDigit(text[from + 3]) &&\n                        isHexaDigit(text[from + 4]) &&\n                        isHexaDigit(text[from + 5])) {\n                        return from + 6;\n                    }\n                    throw new Error(`Unexpected token '${text.substring(from, from + 6)}' found`);\n                case 'p':\n                case 'P': {\n                    if (!unicodeMode) {\n                        return from + 2;\n                    }\n                    let subIndex = from + 2;\n                    for (; subIndex < text.length && text[subIndex] !== '}'; subIndex += text[subIndex] === '\\\\' ? 2 : 1) {\n                    }\n                    if (text[subIndex] !== '}') {\n                        throw new Error(`Invalid \\\\P definition`);\n                    }\n                    return subIndex + 1;\n                }\n                case 'k': {\n                    let subIndex = from + 2;\n                    for (; subIndex < text.length && text[subIndex] !== '>'; ++subIndex) {\n                    }\n                    if (text[subIndex] !== '>') {\n                        if (!unicodeMode) {\n                            return from + 2;\n                        }\n                        throw new Error(`Invalid \\\\k definition`);\n                    }\n                    return subIndex + 1;\n                }\n                default: {\n                    if (isDigit(next1)) {\n                        const maxIndex = unicodeMode ? text.length : Math.min(from + 4, text.length);\n                        let subIndex = from + 2;\n                        for (; subIndex < maxIndex && isDigit(text[subIndex]); ++subIndex) {\n                        }\n                        return subIndex;\n                    }\n                    const charSize = unicodeMode ? charSizeAt(text, from + 1) : 1;\n                    return from + charSize + 1;\n                }\n            }\n        }\n        default: {\n            const charSize = unicodeMode ? charSizeAt(text, from) : 1;\n            return from + charSize;\n        }\n    }\n}\nexport function readFrom(text, from, unicodeMode, mode) {\n    const to = blockEndFrom(text, from, unicodeMode, mode);\n    return text.substring(from, to);\n}\n","import { Set, safeAdd, safePush } from '../../../utils/globals.js';\nconst safeObjectIs = Object.is;\nexport class SameValueSet {\n    constructor(selector) {\n        this.selector = selector;\n        this.selectedItemsExceptMinusZero = new Set();\n        this.data = [];\n        this.hasMinusZero = false;\n    }\n    tryAdd(value) {\n        const selected = this.selector(value);\n        if (safeObjectIs(selected, -0)) {\n            if (this.hasMinusZero) {\n                return false;\n            }\n            safePush(this.data, value);\n            this.hasMinusZero = true;\n            return true;\n        }\n        const sizeBefore = this.selectedItemsExceptMinusZero.size;\n        safeAdd(this.selectedItemsExceptMinusZero, selected);\n        if (sizeBefore !== this.selectedItemsExceptMinusZero.size) {\n            safePush(this.data, value);\n            return true;\n        }\n        return false;\n    }\n    size() {\n        return this.data.length;\n    }\n    getData() {\n        return this.data;\n    }\n}\n","import { Set, safeAdd, safePush } from '../../../utils/globals.js';\nexport class SameValueZeroSet {\n    constructor(selector) {\n        this.selector = selector;\n        this.selectedItems = new Set();\n        this.data = [];\n    }\n    tryAdd(value) {\n        const selected = this.selector(value);\n        const sizeBefore = this.selectedItems.size;\n        safeAdd(this.selectedItems, selected);\n        if (sizeBefore !== this.selectedItems.size) {\n            safePush(this.data, value);\n            return true;\n        }\n        return false;\n    }\n    size() {\n        return this.data.length;\n    }\n    getData() {\n        return this.data;\n    }\n}\n","import { stringify } from '../../../utils/stringify.js';\nfunction raiseUnsupportedASTNode(astNode) {\n    return new Error(`Unsupported AST node! Received: ${stringify(astNode)}`);\n}\nfunction addMissingDotStarTraversalAddMissing(astNode, isFirst, isLast) {\n    if (!isFirst && !isLast) {\n        return astNode;\n    }\n    const traversalResults = { hasStart: false, hasEnd: false };\n    const revampedNode = addMissingDotStarTraversal(astNode, isFirst, isLast, traversalResults);\n    const missingStart = isFirst && !traversalResults.hasStart;\n    const missingEnd = isLast && !traversalResults.hasEnd;\n    if (!missingStart && !missingEnd) {\n        return revampedNode;\n    }\n    const expressions = [];\n    if (missingStart) {\n        expressions.push({ type: 'Assertion', kind: '^' });\n        expressions.push({\n            type: 'Repetition',\n            quantifier: { type: 'Quantifier', kind: '*', greedy: true },\n            expression: { type: 'Char', kind: 'meta', symbol: '.', value: '.', codePoint: Number.NaN },\n        });\n    }\n    expressions.push(revampedNode);\n    if (missingEnd) {\n        expressions.push({\n            type: 'Repetition',\n            quantifier: { type: 'Quantifier', kind: '*', greedy: true },\n            expression: { type: 'Char', kind: 'meta', symbol: '.', value: '.', codePoint: Number.NaN },\n        });\n        expressions.push({ type: 'Assertion', kind: '$' });\n    }\n    return { type: 'Group', capturing: false, expression: { type: 'Alternative', expressions } };\n}\nfunction addMissingDotStarTraversal(astNode, isFirst, isLast, traversalResults) {\n    switch (astNode.type) {\n        case 'Char':\n            return astNode;\n        case 'Repetition':\n            return astNode;\n        case 'Quantifier':\n            throw new Error(`Wrongly defined AST tree, Quantifier nodes not supposed to be scanned!`);\n        case 'Alternative':\n            traversalResults.hasStart = true;\n            traversalResults.hasEnd = true;\n            return Object.assign(Object.assign({}, astNode), { expressions: astNode.expressions.map((node, index) => addMissingDotStarTraversalAddMissing(node, isFirst && index === 0, isLast && index === astNode.expressions.length - 1)) });\n        case 'CharacterClass':\n            return astNode;\n        case 'ClassRange':\n            return astNode;\n        case 'Group': {\n            return Object.assign(Object.assign({}, astNode), { expression: addMissingDotStarTraversal(astNode.expression, isFirst, isLast, traversalResults) });\n        }\n        case 'Disjunction': {\n            traversalResults.hasStart = true;\n            traversalResults.hasEnd = true;\n            return Object.assign(Object.assign({}, astNode), { left: astNode.left !== null ? addMissingDotStarTraversalAddMissing(astNode.left, isFirst, isLast) : null, right: astNode.right !== null ? addMissingDotStarTraversalAddMissing(astNode.right, isFirst, isLast) : null });\n        }\n        case 'Assertion': {\n            if (astNode.kind === '^' || astNode.kind === 'Lookahead') {\n                traversalResults.hasStart = true;\n                return astNode;\n            }\n            else if (astNode.kind === '$' || astNode.kind === 'Lookbehind') {\n                traversalResults.hasEnd = true;\n                return astNode;\n            }\n            else {\n                throw new Error(`Assertions of kind ${astNode.kind} not implemented yet!`);\n            }\n        }\n        case 'Backreference':\n            return astNode;\n        default:\n            throw raiseUnsupportedASTNode(astNode);\n    }\n}\nexport function addMissingDotStar(astNode) {\n    return addMissingDotStarTraversalAddMissing(astNode, true, true);\n}\n","import { stream } from '../../../stream/Stream.js';\nimport { Value } from '../../../check/arbitrary/definition/Value.js';\nimport { BigInt } from '../../../utils/globals.js';\nfunction halveBigInt(n) {\n    return n / BigInt(2);\n}\nexport function shrinkBigInt(current, target, tryTargetAsap) {\n    const realGap = current - target;\n    function* shrinkDecr() {\n        let previous = tryTargetAsap ? undefined : target;\n        const gap = tryTargetAsap ? realGap : halveBigInt(realGap);\n        for (let toremove = gap; toremove > 0; toremove = halveBigInt(toremove)) {\n            const next = current - toremove;\n            yield new Value(next, previous);\n            previous = next;\n        }\n    }\n    function* shrinkIncr() {\n        let previous = tryTargetAsap ? undefined : target;\n        const gap = tryTargetAsap ? realGap : halveBigInt(realGap);\n        for (let toremove = gap; toremove < 0; toremove = halveBigInt(toremove)) {\n            const next = current - toremove;\n            yield new Value(next, previous);\n            previous = next;\n        }\n    }\n    return realGap > 0 ? stream(shrinkDecr()) : stream(shrinkIncr());\n}\n","import { Value } from '../../../check/arbitrary/definition/Value.js';\nimport { stream } from '../../../stream/Stream.js';\nconst safeMathCeil = Math.ceil;\nconst safeMathFloor = Math.floor;\nfunction halvePosInteger(n) {\n    return safeMathFloor(n / 2);\n}\nfunction halveNegInteger(n) {\n    return safeMathCeil(n / 2);\n}\nexport function shrinkInteger(current, target, tryTargetAsap) {\n    const realGap = current - target;\n    function* shrinkDecr() {\n        let previous = tryTargetAsap ? undefined : target;\n        const gap = tryTargetAsap ? realGap : halvePosInteger(realGap);\n        for (let toremove = gap; toremove > 0; toremove = halvePosInteger(toremove)) {\n            const next = toremove === realGap ? target : current - toremove;\n            yield new Value(next, previous);\n            previous = next;\n        }\n    }\n    function* shrinkIncr() {\n        let previous = tryTargetAsap ? undefined : target;\n        const gap = tryTargetAsap ? realGap : halveNegInteger(realGap);\n        for (let toremove = gap; toremove < 0; toremove = halveNegInteger(toremove)) {\n            const next = toremove === realGap ? target : current - toremove;\n            yield new Value(next, previous);\n            previous = next;\n        }\n    }\n    return realGap > 0 ? stream(shrinkDecr()) : stream(shrinkIncr());\n}\n","import { safePush } from '../../../utils/globals.js';\nconst dangerousStrings = [\n    '__defineGetter__',\n    '__defineSetter__',\n    '__lookupGetter__',\n    '__lookupSetter__',\n    '__proto__',\n    'constructor',\n    'hasOwnProperty',\n    'isPrototypeOf',\n    'propertyIsEnumerable',\n    'toLocaleString',\n    'toString',\n    'valueOf',\n    'apply',\n    'arguments',\n    'bind',\n    'call',\n    'caller',\n    'length',\n    'name',\n    'prototype',\n    'key',\n    'ref',\n];\nfunction computeCandidateString(dangerous, charArbitrary, stringSplitter) {\n    let candidate;\n    try {\n        candidate = stringSplitter(dangerous);\n    }\n    catch (err) {\n        return undefined;\n    }\n    for (const entry of candidate) {\n        if (!charArbitrary.canShrinkWithoutContext(entry)) {\n            return undefined;\n        }\n    }\n    return candidate;\n}\nexport function createSlicesForString(charArbitrary, stringSplitter) {\n    const slicesForString = [];\n    for (const dangerous of dangerousStrings) {\n        const candidate = computeCandidateString(dangerous, charArbitrary, stringSplitter);\n        if (candidate !== undefined) {\n            safePush(slicesForString, candidate);\n        }\n    }\n    return slicesForString;\n}\n","import { safeAdd, safePush, Set } from '../../../utils/globals.js';\nconst safeNumberIsNaN = Number.isNaN;\nexport class StrictlyEqualSet {\n    constructor(selector) {\n        this.selector = selector;\n        this.selectedItemsExceptNaN = new Set();\n        this.data = [];\n    }\n    tryAdd(value) {\n        const selected = this.selector(value);\n        if (safeNumberIsNaN(selected)) {\n            safePush(this.data, value);\n            return true;\n        }\n        const sizeBefore = this.selectedItemsExceptNaN.size;\n        safeAdd(this.selectedItemsExceptNaN, selected);\n        if (sizeBefore !== this.selectedItemsExceptNaN.size) {\n            safePush(this.data, value);\n            return true;\n        }\n        return false;\n    }\n    size() {\n        return this.data.length;\n    }\n    getData() {\n        return this.data;\n    }\n}\n","export function escapeForTemplateString(originalText) {\n    return originalText.replace(/([$`\\\\])/g, '\\\\$1').replace(/\\r/g, '\\\\r');\n}\nexport function escapeForMultilineComments(originalText) {\n    return originalText.replace(/\\*\\//g, '*\\\\/');\n}\n","import { BigInt, safePush } from '../../../utils/globals.js';\nexport function countToggledBits(n) {\n    let count = 0;\n    while (n > BigInt(0)) {\n        if (n & BigInt(1))\n            ++count;\n        n >>= BigInt(1);\n    }\n    return count;\n}\nexport function computeNextFlags(flags, nextSize) {\n    const allowedMask = (BigInt(1) << BigInt(nextSize)) - BigInt(1);\n    const preservedFlags = flags & allowedMask;\n    let numMissingFlags = countToggledBits(flags - preservedFlags);\n    let nFlags = preservedFlags;\n    for (let mask = BigInt(1); mask <= allowedMask && numMissingFlags !== 0; mask <<= BigInt(1)) {\n        if (!(nFlags & mask)) {\n            nFlags |= mask;\n            --numMissingFlags;\n        }\n    }\n    return nFlags;\n}\nexport function computeTogglePositions(chars, toggleCase) {\n    const positions = [];\n    for (let idx = chars.length - 1; idx !== -1; --idx) {\n        if (toggleCase(chars[idx]) !== chars[idx])\n            safePush(positions, idx);\n    }\n    return positions;\n}\nexport function computeFlagsFromChars(untoggledChars, toggledChars, togglePositions) {\n    let flags = BigInt(0);\n    for (let idx = 0, mask = BigInt(1); idx !== togglePositions.length; ++idx, mask <<= BigInt(1)) {\n        if (untoggledChars[togglePositions[idx]] !== toggledChars[togglePositions[idx]]) {\n            flags |= mask;\n        }\n    }\n    return flags;\n}\nexport function applyFlagsOnChars(chars, flags, togglePositions, toggleCase) {\n    for (let idx = 0, mask = BigInt(1); idx !== togglePositions.length; ++idx, mask <<= BigInt(1)) {\n        if (flags & mask)\n            chars[togglePositions[idx]] = toggleCase(chars[togglePositions[idx]]);\n    }\n}\n","import { safeIndexOf } from '../../../utils/globals.js';\nimport { TokenizerBlockMode, readFrom } from './ReadRegex.js';\nconst safeStringFromCodePoint = String.fromCodePoint;\nfunction safePop(tokens) {\n    const previous = tokens.pop();\n    if (previous === undefined) {\n        throw new Error('Unable to extract token preceeding the currently parsed one');\n    }\n    return previous;\n}\nfunction isDigit(char) {\n    return char >= '0' && char <= '9';\n}\nfunction simpleChar(char, escaped) {\n    return {\n        type: 'Char',\n        kind: 'simple',\n        symbol: char,\n        value: char,\n        codePoint: char.codePointAt(0) || -1,\n        escaped,\n    };\n}\nfunction metaEscapedChar(block, symbol) {\n    return {\n        type: 'Char',\n        kind: 'meta',\n        symbol,\n        value: block,\n        codePoint: symbol.codePointAt(0) || -1,\n    };\n}\nfunction toSingleToken(tokens, allowEmpty) {\n    if (tokens.length > 1) {\n        return {\n            type: 'Alternative',\n            expressions: tokens,\n        };\n    }\n    if (!allowEmpty && tokens.length === 0) {\n        throw new Error(`Unsupported no token`);\n    }\n    return tokens[0];\n}\nfunction blockToCharToken(block) {\n    if (block[0] === '\\\\') {\n        const next = block[1];\n        switch (next) {\n            case 'x': {\n                const allDigits = block.substring(2);\n                const codePoint = Number.parseInt(allDigits, 16);\n                const symbol = safeStringFromCodePoint(codePoint);\n                return { type: 'Char', kind: 'hex', symbol, value: block, codePoint };\n            }\n            case 'u': {\n                if (block === '\\\\u') {\n                    return simpleChar('u', true);\n                }\n                const allDigits = block[2] === '{' ? block.substring(3, block.length - 1) : block.substring(2);\n                const codePoint = Number.parseInt(allDigits, 16);\n                const symbol = safeStringFromCodePoint(codePoint);\n                return { type: 'Char', kind: 'unicode', symbol, value: block, codePoint };\n            }\n            case '0': {\n                return metaEscapedChar(block, '\\0');\n            }\n            case 'n': {\n                return metaEscapedChar(block, '\\n');\n            }\n            case 'f': {\n                return metaEscapedChar(block, '\\f');\n            }\n            case 'r': {\n                return metaEscapedChar(block, '\\r');\n            }\n            case 't': {\n                return metaEscapedChar(block, '\\t');\n            }\n            case 'v': {\n                return metaEscapedChar(block, '\\v');\n            }\n            case 'w':\n            case 'W':\n            case 'd':\n            case 'D':\n            case 's':\n            case 'S':\n            case 'b':\n            case 'B': {\n                return { type: 'Char', kind: 'meta', symbol: undefined, value: block, codePoint: Number.NaN };\n            }\n            default: {\n                if (isDigit(next)) {\n                    const allDigits = block.substring(1);\n                    const codePoint = Number(allDigits);\n                    const symbol = safeStringFromCodePoint(codePoint);\n                    return { type: 'Char', kind: 'decimal', symbol, value: block, codePoint };\n                }\n                if (block.length > 2 && (next === 'p' || next === 'P')) {\n                    throw new Error(`UnicodeProperty not implemented yet!`);\n                }\n                const char = block.substring(1);\n                return simpleChar(char, true);\n            }\n        }\n    }\n    return simpleChar(block);\n}\nfunction pushTokens(tokens, regexSource, unicodeMode, groups) {\n    let disjunctions = null;\n    for (let index = 0, block = readFrom(regexSource, index, unicodeMode, TokenizerBlockMode.Full); index !== regexSource.length; index += block.length, block = readFrom(regexSource, index, unicodeMode, TokenizerBlockMode.Full)) {\n        const firstInBlock = block[0];\n        switch (firstInBlock) {\n            case '|': {\n                if (disjunctions === null) {\n                    disjunctions = [];\n                }\n                disjunctions.push(toSingleToken(tokens.splice(0), true) || null);\n                break;\n            }\n            case '.': {\n                tokens.push({ type: 'Char', kind: 'meta', symbol: block, value: block, codePoint: Number.NaN });\n                break;\n            }\n            case '*':\n            case '+': {\n                const previous = safePop(tokens);\n                tokens.push({\n                    type: 'Repetition',\n                    expression: previous,\n                    quantifier: { type: 'Quantifier', kind: firstInBlock, greedy: true },\n                });\n                break;\n            }\n            case '?': {\n                const previous = safePop(tokens);\n                if (previous.type === 'Repetition') {\n                    previous.quantifier.greedy = false;\n                    tokens.push(previous);\n                }\n                else {\n                    tokens.push({\n                        type: 'Repetition',\n                        expression: previous,\n                        quantifier: { type: 'Quantifier', kind: firstInBlock, greedy: true },\n                    });\n                }\n                break;\n            }\n            case '{': {\n                if (block === '{') {\n                    tokens.push(simpleChar(block));\n                    break;\n                }\n                const previous = safePop(tokens);\n                const quantifierText = block.substring(1, block.length - 1);\n                const quantifierTokens = quantifierText.split(',');\n                const from = Number(quantifierTokens[0]);\n                const to = quantifierTokens.length === 1\n                    ? from\n                    : quantifierTokens[1].length !== 0\n                        ? Number(quantifierTokens[1])\n                        : undefined;\n                tokens.push({\n                    type: 'Repetition',\n                    expression: previous,\n                    quantifier: { type: 'Quantifier', kind: 'Range', greedy: true, from, to },\n                });\n                break;\n            }\n            case '[': {\n                const blockContent = block.substring(1, block.length - 1);\n                const subTokens = [];\n                let negative = undefined;\n                let previousWasSimpleDash = false;\n                for (let subIndex = 0, subBlock = readFrom(blockContent, subIndex, unicodeMode, TokenizerBlockMode.Character); subIndex !== blockContent.length; subIndex += subBlock.length,\n                    subBlock = readFrom(blockContent, subIndex, unicodeMode, TokenizerBlockMode.Character)) {\n                    if (subIndex === 0 && subBlock === '^') {\n                        negative = true;\n                        continue;\n                    }\n                    const newToken = blockToCharToken(subBlock);\n                    if (subBlock === '-') {\n                        subTokens.push(newToken);\n                        previousWasSimpleDash = true;\n                    }\n                    else {\n                        const operand1Token = subTokens.length >= 2 ? subTokens[subTokens.length - 2] : undefined;\n                        if (previousWasSimpleDash && operand1Token !== undefined && operand1Token.type === 'Char') {\n                            subTokens.pop();\n                            subTokens.pop();\n                            subTokens.push({ type: 'ClassRange', from: operand1Token, to: newToken });\n                        }\n                        else {\n                            subTokens.push(newToken);\n                        }\n                        previousWasSimpleDash = false;\n                    }\n                }\n                tokens.push({ type: 'CharacterClass', expressions: subTokens, negative });\n                break;\n            }\n            case '(': {\n                const blockContent = block.substring(1, block.length - 1);\n                const subTokens = [];\n                if (blockContent[0] === '?') {\n                    if (blockContent[1] === ':') {\n                        pushTokens(subTokens, blockContent.substring(2), unicodeMode, groups);\n                        tokens.push({\n                            type: 'Group',\n                            capturing: false,\n                            expression: toSingleToken(subTokens),\n                        });\n                    }\n                    else if (blockContent[1] === '=' || blockContent[1] === '!') {\n                        pushTokens(subTokens, blockContent.substring(2), unicodeMode, groups);\n                        tokens.push({\n                            type: 'Assertion',\n                            kind: 'Lookahead',\n                            negative: blockContent[1] === '!' ? true : undefined,\n                            assertion: toSingleToken(subTokens),\n                        });\n                    }\n                    else if (blockContent[1] === '<' && (blockContent[2] === '=' || blockContent[2] === '!')) {\n                        pushTokens(subTokens, blockContent.substring(3), unicodeMode, groups);\n                        tokens.push({\n                            type: 'Assertion',\n                            kind: 'Lookbehind',\n                            negative: blockContent[2] === '!' ? true : undefined,\n                            assertion: toSingleToken(subTokens),\n                        });\n                    }\n                    else {\n                        const chunks = blockContent.split('>');\n                        if (chunks.length < 2 || chunks[0][1] !== '<') {\n                            throw new Error(`Unsupported regex content found at ${JSON.stringify(block)}`);\n                        }\n                        const groupIndex = ++groups.lastIndex;\n                        const nameRaw = chunks[0].substring(2);\n                        groups.named.set(nameRaw, groupIndex);\n                        pushTokens(subTokens, chunks.slice(1).join('>'), unicodeMode, groups);\n                        tokens.push({\n                            type: 'Group',\n                            capturing: true,\n                            nameRaw,\n                            name: nameRaw,\n                            number: groupIndex,\n                            expression: toSingleToken(subTokens),\n                        });\n                    }\n                }\n                else {\n                    const groupIndex = ++groups.lastIndex;\n                    pushTokens(subTokens, blockContent, unicodeMode, groups);\n                    tokens.push({\n                        type: 'Group',\n                        capturing: true,\n                        number: groupIndex,\n                        expression: toSingleToken(subTokens),\n                    });\n                }\n                break;\n            }\n            default: {\n                if (block === '^') {\n                    tokens.push({ type: 'Assertion', kind: block });\n                }\n                else if (block === '$') {\n                    tokens.push({ type: 'Assertion', kind: block });\n                }\n                else if (block[0] === '\\\\' && isDigit(block[1])) {\n                    const reference = Number(block.substring(1));\n                    if (unicodeMode || reference <= groups.lastIndex) {\n                        tokens.push({ type: 'Backreference', kind: 'number', number: reference, reference });\n                    }\n                    else {\n                        tokens.push(blockToCharToken(block));\n                    }\n                }\n                else if (block[0] === '\\\\' && block[1] === 'k' && block.length !== 2) {\n                    const referenceRaw = block.substring(3, block.length - 1);\n                    tokens.push({\n                        type: 'Backreference',\n                        kind: 'name',\n                        number: groups.named.get(referenceRaw) || 0,\n                        referenceRaw,\n                        reference: referenceRaw,\n                    });\n                }\n                else {\n                    tokens.push(blockToCharToken(block));\n                }\n                break;\n            }\n        }\n    }\n    if (disjunctions !== null) {\n        disjunctions.push(toSingleToken(tokens.splice(0), true) || null);\n        let currentDisjunction = {\n            type: 'Disjunction',\n            left: disjunctions[0],\n            right: disjunctions[1],\n        };\n        for (let index = 2; index < disjunctions.length; ++index) {\n            currentDisjunction = {\n                type: 'Disjunction',\n                left: currentDisjunction,\n                right: disjunctions[index],\n            };\n        }\n        tokens.push(currentDisjunction);\n    }\n}\nexport function tokenizeRegex(regex) {\n    const unicodeMode = safeIndexOf([...regex.flags], 'u') !== -1;\n    const regexSource = regex.source;\n    const tokens = [];\n    pushTokens(tokens, regexSource, unicodeMode, { lastIndex: 0, named: new Map() });\n    return toSingleToken(tokens);\n}\n","export class NoopSlicedGenerator {\n    constructor(arb, mrng, biasFactor) {\n        this.arb = arb;\n        this.mrng = mrng;\n        this.biasFactor = biasFactor;\n    }\n    attemptExact() {\n        return;\n    }\n    next() {\n        return this.arb.generate(this.mrng, this.biasFactor);\n    }\n}\n","import { escapeForTemplateString } from '../helpers/TextEscaper.js';\nimport { cloneMethod } from '../../../check/symbols.js';\nimport { stringify } from '../../../utils/stringify.js';\nconst defaultSchedulerAct = (f) => f();\nexport class SchedulerImplem {\n    constructor(act, taskSelector) {\n        this.act = act;\n        this.taskSelector = taskSelector;\n        this.lastTaskId = 0;\n        this.sourceTaskSelector = taskSelector.clone();\n        this.scheduledTasks = [];\n        this.triggeredTasks = [];\n        this.scheduledWatchers = [];\n    }\n    static buildLog(reportItem) {\n        return `[task\\${${reportItem.taskId}}] ${reportItem.label.length !== 0 ? `${reportItem.schedulingType}::${reportItem.label}` : reportItem.schedulingType} ${reportItem.status}${reportItem.outputValue !== undefined ? ` with value ${escapeForTemplateString(reportItem.outputValue)}` : ''}`;\n    }\n    log(schedulingType, taskId, label, metadata, status, data) {\n        this.triggeredTasks.push({\n            status,\n            schedulingType,\n            taskId,\n            label,\n            metadata,\n            outputValue: data !== undefined ? stringify(data) : undefined,\n        });\n    }\n    scheduleInternal(schedulingType, label, task, metadata, customAct, thenTaskToBeAwaited) {\n        let trigger = null;\n        const taskId = ++this.lastTaskId;\n        const scheduledPromise = new Promise((resolve, reject) => {\n            trigger = () => {\n                (thenTaskToBeAwaited ? task.then(() => thenTaskToBeAwaited()) : task).then((data) => {\n                    this.log(schedulingType, taskId, label, metadata, 'resolved', data);\n                    return resolve(data);\n                }, (err) => {\n                    this.log(schedulingType, taskId, label, metadata, 'rejected', err);\n                    return reject(err);\n                });\n            };\n        });\n        this.scheduledTasks.push({\n            original: task,\n            scheduled: scheduledPromise,\n            trigger: trigger,\n            schedulingType,\n            taskId,\n            label,\n            metadata,\n            customAct,\n        });\n        if (this.scheduledWatchers.length !== 0) {\n            this.scheduledWatchers[0]();\n        }\n        return scheduledPromise;\n    }\n    schedule(task, label, metadata, customAct) {\n        return this.scheduleInternal('promise', label || '', task, metadata, customAct || defaultSchedulerAct);\n    }\n    scheduleFunction(asyncFunction, customAct) {\n        return (...args) => this.scheduleInternal('function', `${asyncFunction.name}(${args.map(stringify).join(',')})`, asyncFunction(...args), undefined, customAct || defaultSchedulerAct);\n    }\n    scheduleSequence(sequenceBuilders, customAct) {\n        const status = { done: false, faulty: false };\n        const dummyResolvedPromise = { then: (f) => f() };\n        let resolveSequenceTask = () => { };\n        const sequenceTask = new Promise((resolve) => (resolveSequenceTask = resolve));\n        sequenceBuilders\n            .reduce((previouslyScheduled, item) => {\n            const [builder, label, metadata] = typeof item === 'function' ? [item, item.name, undefined] : [item.builder, item.label, item.metadata];\n            return previouslyScheduled.then(() => {\n                const scheduled = this.scheduleInternal('sequence', label, dummyResolvedPromise, metadata, customAct || defaultSchedulerAct, () => builder());\n                scheduled.catch(() => {\n                    status.faulty = true;\n                    resolveSequenceTask();\n                });\n                return scheduled;\n            });\n        }, dummyResolvedPromise)\n            .then(() => {\n            status.done = true;\n            resolveSequenceTask();\n        }, () => {\n        });\n        return Object.assign(status, {\n            task: Promise.resolve(sequenceTask).then(() => {\n                return { done: status.done, faulty: status.faulty };\n            }),\n        });\n    }\n    count() {\n        return this.scheduledTasks.length;\n    }\n    internalWaitOne() {\n        if (this.scheduledTasks.length === 0) {\n            throw new Error('No task scheduled');\n        }\n        const taskIndex = this.taskSelector.nextTaskIndex(this.scheduledTasks);\n        const [scheduledTask] = this.scheduledTasks.splice(taskIndex, 1);\n        return scheduledTask.customAct(async () => {\n            scheduledTask.trigger();\n            try {\n                await scheduledTask.scheduled;\n            }\n            catch (_err) {\n            }\n        });\n    }\n    async waitOne(customAct) {\n        const waitAct = customAct || defaultSchedulerAct;\n        await this.act(() => waitAct(async () => await this.internalWaitOne()));\n    }\n    async waitAll(customAct) {\n        while (this.scheduledTasks.length > 0) {\n            await this.waitOne(customAct);\n        }\n    }\n    async waitFor(unscheduledTask, customAct) {\n        let taskResolved = false;\n        let awaiterPromise = null;\n        const awaiter = async () => {\n            while (!taskResolved && this.scheduledTasks.length > 0) {\n                await this.waitOne(customAct);\n            }\n            awaiterPromise = null;\n        };\n        const handleNotified = () => {\n            if (awaiterPromise !== null) {\n                return;\n            }\n            awaiterPromise = Promise.resolve().then(awaiter);\n        };\n        const clearAndReplaceWatcher = () => {\n            const handleNotifiedIndex = this.scheduledWatchers.indexOf(handleNotified);\n            if (handleNotifiedIndex !== -1) {\n                this.scheduledWatchers.splice(handleNotifiedIndex, 1);\n            }\n            if (handleNotifiedIndex === 0 && this.scheduledWatchers.length !== 0) {\n                this.scheduledWatchers[0]();\n            }\n        };\n        const rewrappedTask = unscheduledTask.then((ret) => {\n            taskResolved = true;\n            if (awaiterPromise === null) {\n                clearAndReplaceWatcher();\n                return ret;\n            }\n            return awaiterPromise.then(() => {\n                clearAndReplaceWatcher();\n                return ret;\n            });\n        }, (err) => {\n            taskResolved = true;\n            if (awaiterPromise === null) {\n                clearAndReplaceWatcher();\n                throw err;\n            }\n            return awaiterPromise.then(() => {\n                clearAndReplaceWatcher();\n                throw err;\n            });\n        });\n        if (this.scheduledTasks.length > 0 && this.scheduledWatchers.length === 0) {\n            handleNotified();\n        }\n        this.scheduledWatchers.push(handleNotified);\n        return rewrappedTask;\n    }\n    report() {\n        return [\n            ...this.triggeredTasks,\n            ...this.scheduledTasks.map((t) => ({\n                status: 'pending',\n                schedulingType: t.schedulingType,\n                taskId: t.taskId,\n                label: t.label,\n                metadata: t.metadata,\n            })),\n        ];\n    }\n    toString() {\n        return ('schedulerFor()`\\n' +\n            this.report()\n                .map(SchedulerImplem.buildLog)\n                .map((log) => `-> ${log}`)\n                .join('\\n') +\n            '`');\n    }\n    [cloneMethod]() {\n        return new SchedulerImplem(this.act, this.sourceTaskSelector);\n    }\n}\n","import { Value } from '../../../check/arbitrary/definition/Value.js';\nimport { safePush } from '../../../utils/globals.js';\nconst safeMathMin = Math.min;\nconst safeMathMax = Math.max;\nexport class SlicedBasedGenerator {\n    constructor(arb, mrng, slices, biasFactor) {\n        this.arb = arb;\n        this.mrng = mrng;\n        this.slices = slices;\n        this.biasFactor = biasFactor;\n        this.activeSliceIndex = 0;\n        this.nextIndexInSlice = 0;\n        this.lastIndexInSlice = -1;\n    }\n    attemptExact(targetLength) {\n        if (targetLength !== 0 && this.mrng.nextInt(1, this.biasFactor) === 1) {\n            const eligibleIndices = [];\n            for (let index = 0; index !== this.slices.length; ++index) {\n                const slice = this.slices[index];\n                if (slice.length === targetLength) {\n                    safePush(eligibleIndices, index);\n                }\n            }\n            if (eligibleIndices.length === 0) {\n                return;\n            }\n            this.activeSliceIndex = eligibleIndices[this.mrng.nextInt(0, eligibleIndices.length - 1)];\n            this.nextIndexInSlice = 0;\n            this.lastIndexInSlice = targetLength - 1;\n        }\n    }\n    next() {\n        if (this.nextIndexInSlice <= this.lastIndexInSlice) {\n            return new Value(this.slices[this.activeSliceIndex][this.nextIndexInSlice++], undefined);\n        }\n        if (this.mrng.nextInt(1, this.biasFactor) !== 1) {\n            return this.arb.generate(this.mrng, this.biasFactor);\n        }\n        this.activeSliceIndex = this.mrng.nextInt(0, this.slices.length - 1);\n        const slice = this.slices[this.activeSliceIndex];\n        if (this.mrng.nextInt(1, this.biasFactor) !== 1) {\n            this.nextIndexInSlice = 1;\n            this.lastIndexInSlice = slice.length - 1;\n            return new Value(slice[0], undefined);\n        }\n        const rangeBoundaryA = this.mrng.nextInt(0, slice.length - 1);\n        const rangeBoundaryB = this.mrng.nextInt(0, slice.length - 1);\n        this.nextIndexInSlice = safeMathMin(rangeBoundaryA, rangeBoundaryB);\n        this.lastIndexInSlice = safeMathMax(rangeBoundaryA, rangeBoundaryB);\n        return new Value(slice[this.nextIndexInSlice++], undefined);\n    }\n}\n","export function arrayToMapMapper(data) {\n    return new Map(data);\n}\nexport function arrayToMapUnmapper(value) {\n    if (typeof value !== 'object' || value === null) {\n        throw new Error('Incompatible instance received: should be a non-null object');\n    }\n    if (!('constructor' in value) || value.constructor !== Map) {\n        throw new Error('Incompatible instance received: should be of exact type Map');\n    }\n    return Array.from(value);\n}\n","export function arrayToSetMapper(data) {\n    return new Set(data);\n}\nexport function arrayToSetUnmapper(value) {\n    if (typeof value !== 'object' || value === null) {\n        throw new Error('Incompatible instance received: should be a non-null object');\n    }\n    if (!('constructor' in value) || value.constructor !== Set) {\n        throw new Error('Incompatible instance received: should be of exact type Set');\n    }\n    return Array.from(value);\n}\n","import { safeJoin, safeSplit } from '../../../utils/globals.js';\nexport function charsToStringMapper(tab) {\n    return safeJoin(tab, '');\n}\nexport function charsToStringUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Cannot unmap the passed value');\n    }\n    return safeSplit(value, '');\n}\n","import { safeJoin } from '../../../utils/globals.js';\nexport function codePointsToStringMapper(tab) {\n    return safeJoin(tab, '');\n}\nexport function codePointsToStringUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Cannot unmap the passed value');\n    }\n    return [...value];\n}\n","import { safeEndsWith, safeJoin, safeSlice, safeSplit, safeStartsWith, safeSubstring } from '../../../utils/globals.js';\nfunction readBh(value) {\n    if (value.length === 0)\n        return [];\n    else\n        return safeSplit(value, ':');\n}\nfunction extractEhAndL(value) {\n    const valueSplits = safeSplit(value, ':');\n    if (valueSplits.length >= 2 && valueSplits[valueSplits.length - 1].length <= 4) {\n        return [\n            safeSlice(valueSplits, 0, valueSplits.length - 2),\n            `${valueSplits[valueSplits.length - 2]}:${valueSplits[valueSplits.length - 1]}`,\n        ];\n    }\n    return [safeSlice(valueSplits, 0, valueSplits.length - 1), valueSplits[valueSplits.length - 1]];\n}\nexport function fullySpecifiedMapper(data) {\n    return `${safeJoin(data[0], ':')}:${data[1]}`;\n}\nexport function fullySpecifiedUnmapper(value) {\n    if (typeof value !== 'string')\n        throw new Error('Invalid type');\n    return extractEhAndL(value);\n}\nexport function onlyTrailingMapper(data) {\n    return `::${safeJoin(data[0], ':')}:${data[1]}`;\n}\nexport function onlyTrailingUnmapper(value) {\n    if (typeof value !== 'string')\n        throw new Error('Invalid type');\n    if (!safeStartsWith(value, '::'))\n        throw new Error('Invalid value');\n    return extractEhAndL(safeSubstring(value, 2));\n}\nexport function multiTrailingMapper(data) {\n    return `${safeJoin(data[0], ':')}::${safeJoin(data[1], ':')}:${data[2]}`;\n}\nexport function multiTrailingUnmapper(value) {\n    if (typeof value !== 'string')\n        throw new Error('Invalid type');\n    const [bhString, trailingString] = safeSplit(value, '::', 2);\n    const [eh, l] = extractEhAndL(trailingString);\n    return [readBh(bhString), eh, l];\n}\nexport function multiTrailingMapperOne(data) {\n    return multiTrailingMapper([data[0], [data[1]], data[2]]);\n}\nexport function multiTrailingUnmapperOne(value) {\n    const out = multiTrailingUnmapper(value);\n    return [out[0], safeJoin(out[1], ':'), out[2]];\n}\nexport function singleTrailingMapper(data) {\n    return `${safeJoin(data[0], ':')}::${data[1]}`;\n}\nexport function singleTrailingUnmapper(value) {\n    if (typeof value !== 'string')\n        throw new Error('Invalid type');\n    const [bhString, trailing] = safeSplit(value, '::', 2);\n    return [readBh(bhString), trailing];\n}\nexport function noTrailingMapper(data) {\n    return `${safeJoin(data[0], ':')}::`;\n}\nexport function noTrailingUnmapper(value) {\n    if (typeof value !== 'string')\n        throw new Error('Invalid type');\n    if (!safeEndsWith(value, '::'))\n        throw new Error('Invalid value');\n    return [readBh(safeSubstring(value, 0, value.length - 2))];\n}\n","import { safeCharCodeAt } from '../../../utils/globals.js';\nexport const indexToCharStringMapper = String.fromCodePoint;\nexport function indexToCharStringUnmapper(c) {\n    if (typeof c !== 'string') {\n        throw new Error('Cannot unmap non-string');\n    }\n    if (c.length === 0 || c.length > 2) {\n        throw new Error('Cannot unmap string with more or less than one character');\n    }\n    const c1 = safeCharCodeAt(c, 0);\n    if (c.length === 1) {\n        return c1;\n    }\n    const c2 = safeCharCodeAt(c, 1);\n    if (c1 < 0xd800 || c1 > 0xdbff || c2 < 0xdc00 || c2 > 0xdfff) {\n        throw new Error('Cannot unmap invalid surrogate pairs');\n    }\n    return c.codePointAt(0);\n}\n","export function indexToMappedConstantMapperFor(entries) {\n    return function indexToMappedConstantMapper(choiceIndex) {\n        let idx = -1;\n        let numSkips = 0;\n        while (choiceIndex >= numSkips) {\n            numSkips += entries[++idx].num;\n        }\n        return entries[idx].build(choiceIndex - numSkips + entries[idx].num);\n    };\n}\nfunction buildReverseMapping(entries) {\n    const reverseMapping = { mapping: new Map(), negativeZeroIndex: undefined };\n    let choiceIndex = 0;\n    for (let entryIdx = 0; entryIdx !== entries.length; ++entryIdx) {\n        const entry = entries[entryIdx];\n        for (let idxInEntry = 0; idxInEntry !== entry.num; ++idxInEntry) {\n            const value = entry.build(idxInEntry);\n            if (value === 0 && 1 / value === Number.NEGATIVE_INFINITY) {\n                reverseMapping.negativeZeroIndex = choiceIndex;\n            }\n            else {\n                reverseMapping.mapping.set(value, choiceIndex);\n            }\n            ++choiceIndex;\n        }\n    }\n    return reverseMapping;\n}\nexport function indexToMappedConstantUnmapperFor(entries) {\n    let reverseMapping = null;\n    return function indexToMappedConstantUnmapper(value) {\n        if (reverseMapping === null) {\n            reverseMapping = buildReverseMapping(entries);\n        }\n        const choiceIndex = Object.is(value, -0) ? reverseMapping.negativeZeroIndex : reverseMapping.mapping.get(value);\n        if (choiceIndex === undefined) {\n            throw new Error('Unknown value encountered cannot be built using this mapToConstant');\n        }\n        return choiceIndex;\n    };\n}\n","export function indexToPrintableIndexMapper(v) {\n    if (v < 95)\n        return v + 0x20;\n    if (v <= 0x7e)\n        return v - 95;\n    return v;\n}\nexport function indexToPrintableIndexUnmapper(v) {\n    if (v >= 0x20 && v <= 0x7e)\n        return v - 0x20;\n    if (v >= 0 && v <= 0x1f)\n        return v + 95;\n    return v;\n}\n","import { Error, safeEvery } from '../../../utils/globals.js';\nconst safeObjectCreate = Object.create;\nconst safeObjectDefineProperty = Object.defineProperty;\nconst safeObjectGetOwnPropertyDescriptor = Object.getOwnPropertyDescriptor;\nconst safeObjectGetPrototypeOf = Object.getPrototypeOf;\nconst safeObjectGetOwnPropertySymbols = Object.getOwnPropertySymbols;\nconst safeObjectGetOwnPropertyNames = Object.getOwnPropertyNames;\nconst safeObjectEntries = Object.entries;\nexport function keyValuePairsToObjectMapper(definition) {\n    const obj = definition[1] ? safeObjectCreate(null) : {};\n    for (const keyValue of definition[0]) {\n        safeObjectDefineProperty(obj, keyValue[0], {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: keyValue[1],\n        });\n    }\n    return obj;\n}\nfunction buildIsValidPropertyNameFilter(obj) {\n    return function isValidPropertyNameFilter(key) {\n        const descriptor = safeObjectGetOwnPropertyDescriptor(obj, key);\n        return (descriptor !== undefined &&\n            !!descriptor.configurable &&\n            !!descriptor.enumerable &&\n            !!descriptor.writable &&\n            descriptor.get === undefined &&\n            descriptor.set === undefined);\n    };\n}\nexport function keyValuePairsToObjectUnmapper(value) {\n    if (typeof value !== 'object' || value === null) {\n        throw new Error('Incompatible instance received: should be a non-null object');\n    }\n    const hasNullPrototype = safeObjectGetPrototypeOf(value) === null;\n    const hasObjectPrototype = 'constructor' in value && value.constructor === Object;\n    if (!hasNullPrototype && !hasObjectPrototype) {\n        throw new Error('Incompatible instance received: should be of exact type Object');\n    }\n    if (safeObjectGetOwnPropertySymbols(value).length > 0) {\n        throw new Error('Incompatible instance received: should contain symbols');\n    }\n    if (!safeEvery(safeObjectGetOwnPropertyNames(value), buildIsValidPropertyNameFilter(value))) {\n        throw new Error('Incompatible instance received: should contain only c/e/w properties without get/set');\n    }\n    return [safeObjectEntries(value), hasNullPrototype];\n}\n","import { safeNumberToString, safeSubstring } from '../../../utils/globals.js';\nconst safeNumberParseInt = Number.parseInt;\nexport function natToStringifiedNatMapper(options) {\n    const [style, v] = options;\n    switch (style) {\n        case 'oct':\n            return `0${safeNumberToString(v, 8)}`;\n        case 'hex':\n            return `0x${safeNumberToString(v, 16)}`;\n        case 'dec':\n        default:\n            return `${v}`;\n    }\n}\nexport function tryParseStringifiedNat(stringValue, radix) {\n    const parsedNat = safeNumberParseInt(stringValue, radix);\n    if (safeNumberToString(parsedNat, radix) !== stringValue) {\n        throw new Error('Invalid value');\n    }\n    return parsedNat;\n}\nexport function natToStringifiedNatUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Invalid type');\n    }\n    if (value.length >= 2 && value[0] === '0') {\n        if (value[1] === 'x') {\n            return ['hex', tryParseStringifiedNat(safeSubstring(value, 2), 16)];\n        }\n        return ['oct', tryParseStringifiedNat(safeSubstring(value, 1), 8)];\n    }\n    return ['dec', tryParseStringifiedNat(value, 10)];\n}\n","import { safeNumberToString, safePadStart } from '../../../utils/globals.js';\nexport function numberToPaddedEightMapper(n) {\n    return safePadStart(safeNumberToString(n, 16), 8, '0');\n}\nexport function numberToPaddedEightUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported type');\n    }\n    if (value.length !== 8) {\n        throw new Error('Unsupported value: invalid length');\n    }\n    const n = parseInt(value, 16);\n    if (value !== numberToPaddedEightMapper(n)) {\n        throw new Error('Unsupported value: invalid content');\n    }\n    return n;\n}\n","import { safeSubstring } from '../../../utils/globals.js';\nexport function paddedEightsToUuidMapper(t) {\n    return `${t[0]}-${safeSubstring(t[1], 4)}-${safeSubstring(t[1], 0, 4)}-${safeSubstring(t[2], 0, 4)}-${safeSubstring(t[2], 4)}${t[3]}`;\n}\nconst UuidRegex = /^([0-9a-f]{8})-([0-9a-f]{4})-([0-9a-f]{4})-([0-9a-f]{4})-([0-9a-f]{12})$/;\nexport function paddedEightsToUuidUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported type');\n    }\n    const m = UuidRegex.exec(value);\n    if (m === null) {\n        throw new Error('Unsupported type');\n    }\n    return [m[1], m[3] + m[2], m[4] + safeSubstring(m[5], 0, 4), safeSubstring(m[5], 4)];\n}\n","export function partsToUrlMapper(data) {\n    const [scheme, authority, path] = data;\n    const query = data[3] === null ? '' : `?${data[3]}`;\n    const fragments = data[4] === null ? '' : `#${data[4]}`;\n    return `${scheme}://${authority}${path}${query}${fragments}`;\n}\nconst UrlSplitRegex = /^([[A-Za-z][A-Za-z0-9+.-]*):\\/\\/([^/?#]*)([^?#]*)(\\?[A-Za-z0-9\\-._~!$&'()*+,;=:@/?%]*)?(#[A-Za-z0-9\\-._~!$&'()*+,;=:@/?%]*)?$/;\nexport function partsToUrlUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Incompatible value received: type');\n    }\n    const m = UrlSplitRegex.exec(value);\n    if (m === null) {\n        throw new Error('Incompatible value received');\n    }\n    const scheme = m[1];\n    const authority = m[2];\n    const path = m[3];\n    const query = m[4];\n    const fragments = m[5];\n    return [\n        scheme,\n        authority,\n        path,\n        query !== undefined ? query.substring(1) : null,\n        fragments !== undefined ? fragments.substring(1) : null,\n    ];\n}\n","import { MaxLengthUpperBound } from '../helpers/MaxLengthFromMinLength.js';\nimport { safeJoin, safePop, safePush, safeSubstring } from '../../../utils/globals.js';\nexport function patternsToStringMapper(tab) {\n    return safeJoin(tab, '');\n}\nexport function patternsToStringUnmapperFor(patternsArb, constraints) {\n    return function patternsToStringUnmapper(value) {\n        if (typeof value !== 'string') {\n            throw new Error('Unsupported value');\n        }\n        const minLength = constraints.minLength !== undefined ? constraints.minLength : 0;\n        const maxLength = constraints.maxLength !== undefined ? constraints.maxLength : MaxLengthUpperBound;\n        if (value.length === 0) {\n            if (minLength > 0) {\n                throw new Error('Unable to unmap received string');\n            }\n            return [];\n        }\n        const stack = [{ endIndexChunks: 0, nextStartIndex: 1, chunks: [] }];\n        while (stack.length > 0) {\n            const last = safePop(stack);\n            for (let index = last.nextStartIndex; index <= value.length; ++index) {\n                const chunk = safeSubstring(value, last.endIndexChunks, index);\n                if (patternsArb.canShrinkWithoutContext(chunk)) {\n                    const newChunks = [...last.chunks, chunk];\n                    if (index === value.length) {\n                        if (newChunks.length < minLength || newChunks.length > maxLength) {\n                            break;\n                        }\n                        return newChunks;\n                    }\n                    safePush(stack, { endIndexChunks: last.endIndexChunks, nextStartIndex: index + 1, chunks: last.chunks });\n                    safePush(stack, { endIndexChunks: index, nextStartIndex: index + 1, chunks: newChunks });\n                    break;\n                }\n            }\n        }\n        throw new Error('Unable to unmap received string');\n    };\n}\n","import { safeJoin, safeMap, safeSplice, safeSplit } from '../../../utils/globals.js';\nexport function segmentsToPathMapper(segments) {\n    return safeJoin(safeMap(segments, (v) => `/${v}`), '');\n}\nexport function segmentsToPathUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Incompatible value received: type');\n    }\n    if (value.length !== 0 && value[0] !== '/') {\n        throw new Error('Incompatible value received: start');\n    }\n    return safeSplice(safeSplit(value, '/'), 1);\n}\n","import { safeSubstring } from '../../../utils/globals.js';\nexport function stringToBase64Mapper(s) {\n    switch (s.length % 4) {\n        case 0:\n            return s;\n        case 3:\n            return `${s}=`;\n        case 2:\n            return `${s}==`;\n        default:\n            return safeSubstring(s, 1);\n    }\n}\nexport function stringToBase64Unmapper(value) {\n    if (typeof value !== 'string' || value.length % 4 !== 0) {\n        throw new Error('Invalid string received');\n    }\n    const lastTrailingIndex = value.indexOf('=');\n    if (lastTrailingIndex === -1) {\n        return value;\n    }\n    const numTrailings = value.length - lastTrailingIndex;\n    if (numTrailings > 2) {\n        throw new Error('Cannot unmap the passed value');\n    }\n    return safeSubstring(value, 0, lastTrailingIndex);\n}\n","import { Date, Error, safeGetTime } from '../../../utils/globals.js';\nconst safeNaN = Number.NaN;\nconst safeNumberIsNaN = Number.isNaN;\nexport function timeToDateMapper(time) {\n    return new Date(time);\n}\nexport function timeToDateUnmapper(value) {\n    if (!(value instanceof Date) || value.constructor !== Date) {\n        throw new Error('Not a valid value for date unmapper');\n    }\n    return safeGetTime(value);\n}\nexport function timeToDateMapperWithNaN(valueForNaN) {\n    return (time) => {\n        return time === valueForNaN ? new Date(safeNaN) : timeToDateMapper(time);\n    };\n}\nexport function timeToDateUnmapperWithNaN(valueForNaN) {\n    return (value) => {\n        const time = timeToDateUnmapper(value);\n        return safeNumberIsNaN(time) ? valueForNaN : time;\n    };\n}\n","import { Error, String } from '../../../utils/globals.js';\nconst encodeSymbolLookupTable = {\n    10: 'A',\n    11: 'B',\n    12: 'C',\n    13: 'D',\n    14: 'E',\n    15: 'F',\n    16: 'G',\n    17: 'H',\n    18: 'J',\n    19: 'K',\n    20: 'M',\n    21: 'N',\n    22: 'P',\n    23: 'Q',\n    24: 'R',\n    25: 'S',\n    26: 'T',\n    27: 'V',\n    28: 'W',\n    29: 'X',\n    30: 'Y',\n    31: 'Z',\n};\nconst decodeSymbolLookupTable = {\n    '0': 0,\n    '1': 1,\n    '2': 2,\n    '3': 3,\n    '4': 4,\n    '5': 5,\n    '6': 6,\n    '7': 7,\n    '8': 8,\n    '9': 9,\n    A: 10,\n    B: 11,\n    C: 12,\n    D: 13,\n    E: 14,\n    F: 15,\n    G: 16,\n    H: 17,\n    J: 18,\n    K: 19,\n    M: 20,\n    N: 21,\n    P: 22,\n    Q: 23,\n    R: 24,\n    S: 25,\n    T: 26,\n    V: 27,\n    W: 28,\n    X: 29,\n    Y: 30,\n    Z: 31,\n};\nfunction encodeSymbol(symbol) {\n    return symbol < 10 ? String(symbol) : encodeSymbolLookupTable[symbol];\n}\nfunction pad(value, paddingLength) {\n    let extraPadding = '';\n    while (value.length + extraPadding.length < paddingLength) {\n        extraPadding += '0';\n    }\n    return extraPadding + value;\n}\nfunction smallUintToBase32StringMapper(num) {\n    let base32Str = '';\n    for (let remaining = num; remaining !== 0;) {\n        const next = remaining >> 5;\n        const current = remaining - (next << 5);\n        base32Str = encodeSymbol(current) + base32Str;\n        remaining = next;\n    }\n    return base32Str;\n}\nexport function uintToBase32StringMapper(num, paddingLength) {\n    const head = ~~(num / 0x40000000);\n    const tail = num & 0x3fffffff;\n    return pad(smallUintToBase32StringMapper(head), paddingLength - 6) + pad(smallUintToBase32StringMapper(tail), 6);\n}\nexport function paddedUintToBase32StringMapper(paddingLength) {\n    return function padded(num) {\n        return uintToBase32StringMapper(num, paddingLength);\n    };\n}\nexport function uintToBase32StringUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported type');\n    }\n    let accumulated = 0;\n    let power = 1;\n    for (let index = value.length - 1; index >= 0; --index) {\n        const char = value[index];\n        const numericForChar = decodeSymbolLookupTable[char];\n        if (numericForChar === undefined) {\n            throw new Error('Unsupported type');\n        }\n        accumulated += numericForChar * power;\n        power *= 32;\n    }\n    return accumulated;\n}\n","import { Boolean, Number, String } from '../../../utils/globals.js';\nexport function unboxedToBoxedMapper(value) {\n    switch (typeof value) {\n        case 'boolean':\n            return new Boolean(value);\n        case 'number':\n            return new Number(value);\n        case 'string':\n            return new String(value);\n        default:\n            return value;\n    }\n}\nexport function unboxedToBoxedUnmapper(value) {\n    if (typeof value !== 'object' || value === null || !('constructor' in value)) {\n        return value;\n    }\n    return value.constructor === Boolean || value.constructor === Number || value.constructor === String\n        ?\n            value.valueOf()\n        : value;\n}\n","import { safePush } from '../../../utils/globals.js';\nconst safeObjectCreate = Object.create;\nconst safeObjectDefineProperty = Object.defineProperty;\nconst safeObjectGetOwnPropertyDescriptor = Object.getOwnPropertyDescriptor;\nconst safeObjectGetOwnPropertyNames = Object.getOwnPropertyNames;\nconst safeObjectGetOwnPropertySymbols = Object.getOwnPropertySymbols;\nexport function buildValuesAndSeparateKeysToObjectMapper(keys, noKeyValue) {\n    return function valuesAndSeparateKeysToObjectMapper(definition) {\n        const obj = definition[1] ? safeObjectCreate(null) : {};\n        for (let idx = 0; idx !== keys.length; ++idx) {\n            const valueWrapper = definition[0][idx];\n            if (valueWrapper !== noKeyValue) {\n                safeObjectDefineProperty(obj, keys[idx], {\n                    value: valueWrapper,\n                    configurable: true,\n                    enumerable: true,\n                    writable: true,\n                });\n            }\n        }\n        return obj;\n    };\n}\nexport function buildValuesAndSeparateKeysToObjectUnmapper(keys, noKeyValue) {\n    return function valuesAndSeparateKeysToObjectUnmapper(value) {\n        if (typeof value !== 'object' || value === null) {\n            throw new Error('Incompatible instance received: should be a non-null object');\n        }\n        const hasNullPrototype = Object.getPrototypeOf(value) === null;\n        const hasObjectPrototype = 'constructor' in value && value.constructor === Object;\n        if (!hasNullPrototype && !hasObjectPrototype) {\n            throw new Error('Incompatible instance received: should be of exact type Object');\n        }\n        let extractedPropertiesCount = 0;\n        const extractedValues = [];\n        for (let idx = 0; idx !== keys.length; ++idx) {\n            const descriptor = safeObjectGetOwnPropertyDescriptor(value, keys[idx]);\n            if (descriptor !== undefined) {\n                if (!descriptor.configurable || !descriptor.enumerable || !descriptor.writable) {\n                    throw new Error('Incompatible instance received: should contain only c/e/w properties');\n                }\n                if (descriptor.get !== undefined || descriptor.set !== undefined) {\n                    throw new Error('Incompatible instance received: should contain only no get/set properties');\n                }\n                ++extractedPropertiesCount;\n                safePush(extractedValues, descriptor.value);\n            }\n            else {\n                safePush(extractedValues, noKeyValue);\n            }\n        }\n        const namePropertiesCount = safeObjectGetOwnPropertyNames(value).length;\n        const symbolPropertiesCount = safeObjectGetOwnPropertySymbols(value).length;\n        if (extractedPropertiesCount !== namePropertiesCount + symbolPropertiesCount) {\n            throw new Error('Incompatible instance received: should not contain extra properties');\n        }\n        return [extractedValues, hasNullPrototype];\n    };\n}\n","import { safeJoin, safeMap, safePush, safeSplit, safeSubstring, safeToLowerCase, safeToUpperCase, } from '../../../utils/globals.js';\nexport function wordsToJoinedStringMapper(words) {\n    return safeJoin(safeMap(words, (w) => (w[w.length - 1] === ',' ? safeSubstring(w, 0, w.length - 1) : w)), ' ');\n}\nexport function wordsToJoinedStringUnmapperFor(wordsArbitrary) {\n    return function wordsToJoinedStringUnmapper(value) {\n        if (typeof value !== 'string') {\n            throw new Error('Unsupported type');\n        }\n        const words = [];\n        for (const candidate of safeSplit(value, ' ')) {\n            if (wordsArbitrary.canShrinkWithoutContext(candidate))\n                safePush(words, candidate);\n            else if (wordsArbitrary.canShrinkWithoutContext(candidate + ','))\n                safePush(words, candidate + ',');\n            else\n                throw new Error('Unsupported word');\n        }\n        return words;\n    };\n}\nexport function wordsToSentenceMapper(words) {\n    let sentence = safeJoin(words, ' ');\n    if (sentence[sentence.length - 1] === ',') {\n        sentence = safeSubstring(sentence, 0, sentence.length - 1);\n    }\n    return safeToUpperCase(sentence[0]) + safeSubstring(sentence, 1) + '.';\n}\nexport function wordsToSentenceUnmapperFor(wordsArbitrary) {\n    return function wordsToSentenceUnmapper(value) {\n        if (typeof value !== 'string') {\n            throw new Error('Unsupported type');\n        }\n        if (value.length < 2 ||\n            value[value.length - 1] !== '.' ||\n            value[value.length - 2] === ',' ||\n            safeToUpperCase(safeToLowerCase(value[0])) !== value[0]) {\n            throw new Error('Unsupported value');\n        }\n        const adaptedValue = safeToLowerCase(value[0]) + safeSubstring(value, 1, value.length - 1);\n        const words = [];\n        const candidates = safeSplit(adaptedValue, ' ');\n        for (let idx = 0; idx !== candidates.length; ++idx) {\n            const candidate = candidates[idx];\n            if (wordsArbitrary.canShrinkWithoutContext(candidate))\n                safePush(words, candidate);\n            else if (idx === candidates.length - 1 && wordsArbitrary.canShrinkWithoutContext(candidate + ','))\n                safePush(words, candidate + ',');\n            else\n                throw new Error('Unsupported word');\n        }\n        return words;\n    };\n}\nexport function sentencesToParagraphMapper(sentences) {\n    return safeJoin(sentences, ' ');\n}\nexport function sentencesToParagraphUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported type');\n    }\n    const sentences = safeSplit(value, '. ');\n    for (let idx = 0; idx < sentences.length - 1; ++idx) {\n        sentences[idx] += '.';\n    }\n    return sentences;\n}\n","import { anyArbitraryBuilder } from './_internals/builders/AnyArbitraryBuilder.js';\nimport { toQualifiedObjectConstraints } from './_internals/helpers/QualifiedObjectConstraints.js';\nfunction anything(constraints) {\n    return anyArbitraryBuilder(toQualifiedObjectConstraints(constraints));\n}\nexport { anything };\n","import { ArrayArbitrary } from './_internals/ArrayArbitrary.js';\nimport { MaxLengthUpperBound, maxGeneratedLengthFromSizeForArbitrary, } from './_internals/helpers/MaxLengthFromMinLength.js';\nfunction array(arb, constraints = {}) {\n    const size = constraints.size;\n    const minLength = constraints.minLength || 0;\n    const maxLengthOrUnset = constraints.maxLength;\n    const depthIdentifier = constraints.depthIdentifier;\n    const maxLength = maxLengthOrUnset !== undefined ? maxLengthOrUnset : MaxLengthUpperBound;\n    const specifiedMaxLength = maxLengthOrUnset !== undefined;\n    const maxGeneratedLength = maxGeneratedLengthFromSizeForArbitrary(size, minLength, maxLength, specifiedMaxLength);\n    const customSlices = constraints.experimentalCustomSlices || [];\n    return new ArrayArbitrary(arb, minLength, maxGeneratedLength, maxLength, depthIdentifier, undefined, customSlices);\n}\nexport { array };\n","import { buildCharacterArbitrary } from './_internals/builders/CharacterArbitraryBuilder.js';\nimport { indexToPrintableIndexMapper, indexToPrintableIndexUnmapper } from './_internals/mappers/IndexToPrintableIndex.js';\nexport function ascii() {\n    return buildCharacterArbitrary(0x00, 0x7f, indexToPrintableIndexMapper, indexToPrintableIndexUnmapper);\n}\n","import { array } from './array.js';\nimport { ascii } from './ascii.js';\nimport { codePointsToStringMapper, codePointsToStringUnmapper } from './_internals/mappers/CodePointsToString.js';\nimport { createSlicesForString } from './_internals/helpers/SlicesForStringBuilder.js';\nconst safeObjectAssign = Object.assign;\nexport function asciiString(constraints = {}) {\n    const charArbitrary = ascii();\n    const experimentalCustomSlices = createSlicesForString(charArbitrary, codePointsToStringUnmapper);\n    const enrichedConstraints = safeObjectAssign(safeObjectAssign({}, constraints), {\n        experimentalCustomSlices,\n    });\n    return array(charArbitrary, enrichedConstraints).map(codePointsToStringMapper, codePointsToStringUnmapper);\n}\n","import { buildCharacterArbitrary } from './_internals/builders/CharacterArbitraryBuilder.js';\nfunction base64Mapper(v) {\n    if (v < 26)\n        return v + 65;\n    if (v < 52)\n        return v + 97 - 26;\n    if (v < 62)\n        return v + 48 - 52;\n    return v === 62 ? 43 : 47;\n}\nfunction base64Unmapper(v) {\n    if (v >= 65 && v <= 90)\n        return v - 65;\n    if (v >= 97 && v <= 122)\n        return v - 97 + 26;\n    if (v >= 48 && v <= 57)\n        return v - 48 + 52;\n    return v === 43 ? 62 : v === 47 ? 63 : -1;\n}\nexport function base64() {\n    return buildCharacterArbitrary(0, 63, base64Mapper, base64Unmapper);\n}\n","import { array } from './array.js';\nimport { base64 } from './base64.js';\nimport { MaxLengthUpperBound } from './_internals/helpers/MaxLengthFromMinLength.js';\nimport { codePointsToStringMapper, codePointsToStringUnmapper } from './_internals/mappers/CodePointsToString.js';\nimport { stringToBase64Mapper, stringToBase64Unmapper } from './_internals/mappers/StringToBase64.js';\nimport { createSlicesForString } from './_internals/helpers/SlicesForStringBuilder.js';\nfunction base64String(constraints = {}) {\n    const { minLength: unscaledMinLength = 0, maxLength: unscaledMaxLength = MaxLengthUpperBound, size } = constraints;\n    const minLength = unscaledMinLength + 3 - ((unscaledMinLength + 3) % 4);\n    const maxLength = unscaledMaxLength - (unscaledMaxLength % 4);\n    const requestedSize = constraints.maxLength === undefined && size === undefined ? '=' : size;\n    if (minLength > maxLength)\n        throw new Error('Minimal length should be inferior or equal to maximal length');\n    if (minLength % 4 !== 0)\n        throw new Error('Minimal length of base64 strings must be a multiple of 4');\n    if (maxLength % 4 !== 0)\n        throw new Error('Maximal length of base64 strings must be a multiple of 4');\n    const charArbitrary = base64();\n    const experimentalCustomSlices = createSlicesForString(charArbitrary, codePointsToStringUnmapper);\n    const enrichedConstraints = {\n        minLength,\n        maxLength,\n        size: requestedSize,\n        experimentalCustomSlices,\n    };\n    return array(charArbitrary, enrichedConstraints)\n        .map(codePointsToStringMapper, codePointsToStringUnmapper)\n        .map(stringToBase64Mapper, stringToBase64Unmapper);\n}\nexport { base64String };\n","import { BigInt } from '../utils/globals.js';\nimport { BigIntArbitrary } from './_internals/BigIntArbitrary.js';\nfunction buildCompleteBigIntConstraints(constraints) {\n    const DefaultPow = 256;\n    const DefaultMin = BigInt(-1) << BigInt(DefaultPow - 1);\n    const DefaultMax = (BigInt(1) << BigInt(DefaultPow - 1)) - BigInt(1);\n    const min = constraints.min;\n    const max = constraints.max;\n    return {\n        min: min !== undefined ? min : DefaultMin - (max !== undefined && max < BigInt(0) ? max * max : BigInt(0)),\n        max: max !== undefined ? max : DefaultMax + (min !== undefined && min > BigInt(0) ? min * min : BigInt(0)),\n    };\n}\nfunction extractBigIntConstraints(args) {\n    if (args[0] === undefined) {\n        return {};\n    }\n    if (args[1] === undefined) {\n        const constraints = args[0];\n        return constraints;\n    }\n    return { min: args[0], max: args[1] };\n}\nfunction bigInt(...args) {\n    const constraints = buildCompleteBigIntConstraints(extractBigIntConstraints(args));\n    if (constraints.min > constraints.max) {\n        throw new Error('fc.bigInt expects max to be greater than or equal to min');\n    }\n    return new BigIntArbitrary(constraints.min, constraints.max);\n}\nexport { bigInt };\n","import { BigInt, BigInt64Array } from '../utils/globals.js';\nimport { bigInt } from './bigInt.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function bigInt64Array(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, BigInt('-9223372036854775808'), BigInt('9223372036854775807'), BigInt64Array, bigInt);\n}\n","import { BigInt } from '../utils/globals.js';\nimport { BigIntArbitrary } from './_internals/BigIntArbitrary.js';\nexport function bigIntN(n) {\n    if (n < 1) {\n        throw new Error('fc.bigIntN expects requested number of bits to be superior or equal to 1');\n    }\n    const min = BigInt(-1) << BigInt(n - 1);\n    const max = (BigInt(1) << BigInt(n - 1)) - BigInt(1);\n    return new BigIntArbitrary(min, max);\n}\n","import { BigInt } from '../utils/globals.js';\nimport { BigIntArbitrary } from './_internals/BigIntArbitrary.js';\nfunction computeDefaultMax() {\n    return (BigInt(1) << BigInt(256)) - BigInt(1);\n}\nfunction bigUint(constraints) {\n    const requestedMax = typeof constraints === 'object' ? constraints.max : constraints;\n    const max = requestedMax !== undefined ? requestedMax : computeDefaultMax();\n    if (max < 0) {\n        throw new Error('fc.bigUint expects max to be greater than or equal to zero');\n    }\n    return new BigIntArbitrary(BigInt(0), max);\n}\nexport { bigUint };\n","import { BigInt, BigUint64Array } from '../utils/globals.js';\nimport { bigInt } from './bigInt.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function bigUint64Array(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, BigInt(0), BigInt('18446744073709551615'), BigUint64Array, bigInt);\n}\n","import { BigInt } from '../utils/globals.js';\nimport { BigIntArbitrary } from './_internals/BigIntArbitrary.js';\nexport function bigUintN(n) {\n    if (n < 0) {\n        throw new Error('fc.bigUintN expects requested number of bits to be superior or equal to 0');\n    }\n    const min = BigInt(0);\n    const max = (BigInt(1) << BigInt(n)) - BigInt(1);\n    return new BigIntArbitrary(min, max);\n}\n","import { integer } from './integer.js';\nfunction booleanMapper(v) {\n    return v === 1;\n}\nfunction booleanUnmapper(v) {\n    if (typeof v !== 'boolean')\n        throw new Error('Unsupported input type');\n    return v === true ? 1 : 0;\n}\nfunction boolean() {\n    return integer({ min: 0, max: 1 }).map(booleanMapper, booleanUnmapper).noBias();\n}\nexport { boolean };\n","import { buildCharacterArbitrary } from './_internals/builders/CharacterArbitraryBuilder.js';\nfunction identity(v) {\n    return v;\n}\nexport function char() {\n    return buildCharacterArbitrary(0x20, 0x7e, identity, identity);\n}\n","import { buildCharacterArbitrary } from './_internals/builders/CharacterArbitraryBuilder.js';\nimport { indexToPrintableIndexMapper, indexToPrintableIndexUnmapper } from './_internals/mappers/IndexToPrintableIndex.js';\nexport function char16bits() {\n    return buildCharacterArbitrary(0x0000, 0xffff, indexToPrintableIndexMapper, indexToPrintableIndexUnmapper);\n}\n","import { CloneArbitrary } from './_internals/CloneArbitrary.js';\nfunction clone(arb, numValues) {\n    return new CloneArbitrary(arb, numValues);\n}\nexport { clone };\n","import { CommandsArbitrary } from './_internals/CommandsArbitrary.js';\nimport { maxGeneratedLengthFromSizeForArbitrary, MaxLengthUpperBound, } from './_internals/helpers/MaxLengthFromMinLength.js';\nfunction commands(commandArbs, constraints = {}) {\n    const { size, maxCommands = MaxLengthUpperBound, disableReplayLog = false, replayPath = null } = constraints;\n    const specifiedMaxCommands = constraints.maxCommands !== undefined;\n    const maxGeneratedCommands = maxGeneratedLengthFromSizeForArbitrary(size, 0, maxCommands, specifiedMaxCommands);\n    return new CommandsArbitrary(commandArbs, maxGeneratedCommands, maxCommands, replayPath, disableReplayLog);\n}\nexport { commands };\n","import { buildCompareFunctionArbitrary } from './_internals/builders/CompareFunctionArbitraryBuilder.js';\nconst safeObjectAssign = Object.assign;\nexport function compareBooleanFunc() {\n    return buildCompareFunctionArbitrary(safeObjectAssign((hA, hB) => hA < hB, {\n        toString() {\n            return '(hA, hB) => hA < hB';\n        },\n    }));\n}\n","import { buildCompareFunctionArbitrary } from './_internals/builders/CompareFunctionArbitraryBuilder.js';\nconst safeObjectAssign = Object.assign;\nexport function compareFunc() {\n    return buildCompareFunctionArbitrary(safeObjectAssign((hA, hB) => hA - hB, {\n        toString() {\n            return '(hA, hB) => hA - hB';\n        },\n    }));\n}\n","import { ConstantArbitrary } from './_internals/ConstantArbitrary.js';\nexport function constant(value) {\n    return new ConstantArbitrary([value]);\n}\n","import { ConstantArbitrary } from './_internals/ConstantArbitrary.js';\nfunction constantFrom(...values) {\n    if (values.length === 0) {\n        throw new Error('fc.constantFrom expects at least one parameter');\n    }\n    return new ConstantArbitrary(values);\n}\nexport { constantFrom };\n","import { cloneMethod } from '../check/symbols.js';\nimport { constant } from './constant.js';\nclass ContextImplem {\n    constructor() {\n        this.receivedLogs = [];\n    }\n    log(data) {\n        this.receivedLogs.push(data);\n    }\n    size() {\n        return this.receivedLogs.length;\n    }\n    toString() {\n        return JSON.stringify({ logs: this.receivedLogs });\n    }\n    [cloneMethod]() {\n        return new ContextImplem();\n    }\n}\nexport function context() {\n    return constant(new ContextImplem());\n}\n","import { safeGetTime } from '../utils/globals.js';\nimport { integer } from './integer.js';\nimport { timeToDateMapper, timeToDateMapperWithNaN, timeToDateUnmapper, timeToDateUnmapperWithNaN, } from './_internals/mappers/TimeToDate.js';\nconst safeNumberIsNaN = Number.isNaN;\nexport function date(constraints = {}) {\n    const intMin = constraints.min !== undefined ? safeGetTime(constraints.min) : -8640000000000000;\n    const intMax = constraints.max !== undefined ? safeGetTime(constraints.max) : 8640000000000000;\n    const noInvalidDate = constraints.noInvalidDate === undefined || constraints.noInvalidDate;\n    if (safeNumberIsNaN(intMin))\n        throw new Error('fc.date min must be valid instance of Date');\n    if (safeNumberIsNaN(intMax))\n        throw new Error('fc.date max must be valid instance of Date');\n    if (intMin > intMax)\n        throw new Error('fc.date max must be greater or equal to min');\n    if (noInvalidDate) {\n        return integer({ min: intMin, max: intMax }).map(timeToDateMapper, timeToDateUnmapper);\n    }\n    const valueForNaN = intMax + 1;\n    return integer({ min: intMin, max: intMax + 1 }).map(timeToDateMapperWithNaN(valueForNaN), timeToDateUnmapperWithNaN(valueForNaN));\n}\n","import { tuple } from './tuple.js';\nimport { uniqueArray } from './uniqueArray.js';\nimport { keyValuePairsToObjectMapper, keyValuePairsToObjectUnmapper } from './_internals/mappers/KeyValuePairsToObject.js';\nimport { constant } from './constant.js';\nimport { boolean } from './boolean.js';\nfunction dictionaryKeyExtractor(entry) {\n    return entry[0];\n}\nexport function dictionary(keyArb, valueArb, constraints = {}) {\n    const noNullPrototype = constraints.noNullPrototype !== false;\n    return tuple(uniqueArray(tuple(keyArb, valueArb), {\n        minLength: constraints.minKeys,\n        maxLength: constraints.maxKeys,\n        size: constraints.size,\n        selector: dictionaryKeyExtractor,\n        depthIdentifier: constraints.depthIdentifier,\n    }), noNullPrototype ? constant(false) : boolean()).map(keyValuePairsToObjectMapper, keyValuePairsToObjectUnmapper);\n}\n","import { array } from './array.js';\nimport { buildLowerAlphaArbitrary, buildLowerAlphaNumericArbitrary, } from './_internals/builders/CharacterRangeArbitraryBuilder.js';\nimport { option } from './option.js';\nimport { stringOf } from './stringOf.js';\nimport { tuple } from './tuple.js';\nimport { filterInvalidSubdomainLabel } from './_internals/helpers/InvalidSubdomainLabelFiIter.js';\nimport { resolveSize, relativeSizeToSize } from './_internals/helpers/MaxLengthFromMinLength.js';\nimport { adapter } from './_internals/AdapterArbitrary.js';\nimport { safeJoin, safeSlice, safeSplit, safeSubstring } from '../utils/globals.js';\nfunction toSubdomainLabelMapper([f, d]) {\n    return d === null ? f : `${f}${d[0]}${d[1]}`;\n}\nfunction toSubdomainLabelUnmapper(value) {\n    if (typeof value !== 'string' || value.length === 0) {\n        throw new Error('Unsupported');\n    }\n    if (value.length === 1) {\n        return [value[0], null];\n    }\n    return [value[0], [safeSubstring(value, 1, value.length - 1), value[value.length - 1]]];\n}\nfunction subdomainLabel(size) {\n    const alphaNumericArb = buildLowerAlphaNumericArbitrary([]);\n    const alphaNumericHyphenArb = buildLowerAlphaNumericArbitrary(['-']);\n    return tuple(alphaNumericArb, option(tuple(stringOf(alphaNumericHyphenArb, { size, maxLength: 61 }), alphaNumericArb)))\n        .map(toSubdomainLabelMapper, toSubdomainLabelUnmapper)\n        .filter(filterInvalidSubdomainLabel);\n}\nfunction labelsMapper(elements) {\n    return `${safeJoin(elements[0], '.')}.${elements[1]}`;\n}\nfunction labelsUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported type');\n    }\n    const lastDotIndex = value.lastIndexOf('.');\n    return [safeSplit(safeSubstring(value, 0, lastDotIndex), '.'), safeSubstring(value, lastDotIndex + 1)];\n}\nfunction labelsAdapter(labels) {\n    const [subDomains, suffix] = labels;\n    let lengthNotIncludingIndex = suffix.length;\n    for (let index = 0; index !== subDomains.length; ++index) {\n        lengthNotIncludingIndex += 1 + subDomains[index].length;\n        if (lengthNotIncludingIndex > 255) {\n            return { adapted: true, value: [safeSlice(subDomains, 0, index), suffix] };\n        }\n    }\n    return { adapted: false, value: labels };\n}\nexport function domain(constraints = {}) {\n    const resolvedSize = resolveSize(constraints.size);\n    const resolvedSizeMinusOne = relativeSizeToSize('-1', resolvedSize);\n    const alphaNumericArb = buildLowerAlphaArbitrary([]);\n    const publicSuffixArb = stringOf(alphaNumericArb, { minLength: 2, maxLength: 63, size: resolvedSizeMinusOne });\n    return (adapter(tuple(array(subdomainLabel(resolvedSize), { size: resolvedSizeMinusOne, minLength: 1, maxLength: 127 }), publicSuffixArb), labelsAdapter).map(labelsMapper, labelsUnmapper));\n}\n","import { add64, isEqual64, isStrictlyPositive64, isStrictlySmaller64, substract64, Unit64, } from './_internals/helpers/ArrayInt64.js';\nimport { arrayInt64 } from './_internals/ArrayInt64Arbitrary.js';\nimport { doubleToIndex, indexToDouble } from './_internals/helpers/DoubleHelpers.js';\nimport { doubleOnlyMapper, doubleOnlyUnmapper, refineConstraintsForDoubleOnly, } from './_internals/helpers/DoubleOnlyHelpers.js';\nconst safeNumberIsInteger = Number.isInteger;\nconst safeNumberIsNaN = Number.isNaN;\nconst safeNegativeInfinity = Number.NEGATIVE_INFINITY;\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nconst safeMaxValue = Number.MAX_VALUE;\nconst safeNaN = Number.NaN;\nfunction safeDoubleToIndex(d, constraintsLabel) {\n    if (safeNumberIsNaN(d)) {\n        throw new Error('fc.double constraints.' + constraintsLabel + ' must be a 64-bit float');\n    }\n    return doubleToIndex(d);\n}\nfunction unmapperDoubleToIndex(value) {\n    if (typeof value !== 'number')\n        throw new Error('Unsupported type');\n    return doubleToIndex(value);\n}\nfunction numberIsNotInteger(value) {\n    return !safeNumberIsInteger(value);\n}\nfunction anyDouble(constraints) {\n    const { noDefaultInfinity = false, noNaN = false, minExcluded = false, maxExcluded = false, min = noDefaultInfinity ? -safeMaxValue : safeNegativeInfinity, max = noDefaultInfinity ? safeMaxValue : safePositiveInfinity, } = constraints;\n    const minIndexRaw = safeDoubleToIndex(min, 'min');\n    const minIndex = minExcluded ? add64(minIndexRaw, Unit64) : minIndexRaw;\n    const maxIndexRaw = safeDoubleToIndex(max, 'max');\n    const maxIndex = maxExcluded ? substract64(maxIndexRaw, Unit64) : maxIndexRaw;\n    if (isStrictlySmaller64(maxIndex, minIndex)) {\n        throw new Error('fc.double constraints.min must be smaller or equal to constraints.max');\n    }\n    if (noNaN) {\n        return arrayInt64(minIndex, maxIndex).map(indexToDouble, unmapperDoubleToIndex);\n    }\n    const positiveMaxIdx = isStrictlyPositive64(maxIndex);\n    const minIndexWithNaN = positiveMaxIdx ? minIndex : substract64(minIndex, Unit64);\n    const maxIndexWithNaN = positiveMaxIdx ? add64(maxIndex, Unit64) : maxIndex;\n    return arrayInt64(minIndexWithNaN, maxIndexWithNaN).map((index) => {\n        if (isStrictlySmaller64(maxIndex, index) || isStrictlySmaller64(index, minIndex))\n            return safeNaN;\n        else\n            return indexToDouble(index);\n    }, (value) => {\n        if (typeof value !== 'number')\n            throw new Error('Unsupported type');\n        if (safeNumberIsNaN(value))\n            return !isEqual64(maxIndex, maxIndexWithNaN) ? maxIndexWithNaN : minIndexWithNaN;\n        return doubleToIndex(value);\n    });\n}\nexport function double(constraints = {}) {\n    if (!constraints.noInteger) {\n        return anyDouble(constraints);\n    }\n    return anyDouble(refineConstraintsForDoubleOnly(constraints))\n        .map(doubleOnlyMapper, doubleOnlyUnmapper)\n        .filter(numberIsNotInteger);\n}\n","import { array } from './array.js';\nimport { buildLowerAlphaNumericArbitrary } from './_internals/builders/CharacterRangeArbitraryBuilder.js';\nimport { domain } from './domain.js';\nimport { stringOf } from './stringOf.js';\nimport { tuple } from './tuple.js';\nimport { adapter } from './_internals/AdapterArbitrary.js';\nimport { safeJoin, safeSlice, safeSplit } from '../utils/globals.js';\nfunction dotAdapter(a) {\n    let currentLength = a[0].length;\n    for (let index = 1; index !== a.length; ++index) {\n        currentLength += 1 + a[index].length;\n        if (currentLength > 64) {\n            return { adapted: true, value: safeSlice(a, 0, index) };\n        }\n    }\n    return { adapted: false, value: a };\n}\nfunction dotMapper(a) {\n    return safeJoin(a, '.');\n}\nfunction dotUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported');\n    }\n    return safeSplit(value, '.');\n}\nfunction atMapper(data) {\n    return `${data[0]}@${data[1]}`;\n}\nfunction atUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported');\n    }\n    return safeSplit(value, '@', 2);\n}\nexport function emailAddress(constraints = {}) {\n    const others = ['!', '#', '$', '%', '&', \"'\", '*', '+', '-', '/', '=', '?', '^', '_', '`', '{', '|', '}', '~'];\n    const atextArb = buildLowerAlphaNumericArbitrary(others);\n    const localPartArb = adapter(array(stringOf(atextArb, {\n        minLength: 1,\n        maxLength: 64,\n        size: constraints.size,\n    }), { minLength: 1, maxLength: 32, size: constraints.size }), dotAdapter).map(dotMapper, dotUnmapper);\n    return tuple(localPartArb, domain({ size: constraints.size })).map(atMapper, atUnmapper);\n}\n","import { BigInt } from '../utils/globals.js';\nimport { constantFrom } from './constantFrom.js';\nexport function falsy(constraints) {\n    if (!constraints || !constraints.withBigInt) {\n        return constantFrom(false, null, undefined, 0, '', NaN);\n    }\n    return constantFrom(false, null, undefined, 0, '', NaN, BigInt(0));\n}\n","import { integer } from './integer.js';\nimport { floatToIndex, indexToFloat, MAX_VALUE_32 } from './_internals/helpers/FloatHelpers.js';\nimport { floatOnlyMapper, floatOnlyUnmapper, refineConstraintsForFloatOnly, } from './_internals/helpers/FloatOnlyHelpers.js';\nconst safeNumberIsInteger = Number.isInteger;\nconst safeNumberIsNaN = Number.isNaN;\nconst safeMathFround = Math.fround;\nconst safeNegativeInfinity = Number.NEGATIVE_INFINITY;\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nconst safeNaN = Number.NaN;\nfunction safeFloatToIndex(f, constraintsLabel) {\n    const conversionTrick = 'you can convert any double to a 32-bit float by using `Math.fround(myDouble)`';\n    const errorMessage = 'fc.float constraints.' + constraintsLabel + ' must be a 32-bit float - ' + conversionTrick;\n    if (safeNumberIsNaN(f) || safeMathFround(f) !== f) {\n        throw new Error(errorMessage);\n    }\n    return floatToIndex(f);\n}\nfunction unmapperFloatToIndex(value) {\n    if (typeof value !== 'number')\n        throw new Error('Unsupported type');\n    return floatToIndex(value);\n}\nfunction numberIsNotInteger(value) {\n    return !safeNumberIsInteger(value);\n}\nfunction anyFloat(constraints) {\n    const { noDefaultInfinity = false, noNaN = false, minExcluded = false, maxExcluded = false, min = noDefaultInfinity ? -MAX_VALUE_32 : safeNegativeInfinity, max = noDefaultInfinity ? MAX_VALUE_32 : safePositiveInfinity, } = constraints;\n    const minIndexRaw = safeFloatToIndex(min, 'min');\n    const minIndex = minExcluded ? minIndexRaw + 1 : minIndexRaw;\n    const maxIndexRaw = safeFloatToIndex(max, 'max');\n    const maxIndex = maxExcluded ? maxIndexRaw - 1 : maxIndexRaw;\n    if (minIndex > maxIndex) {\n        throw new Error('fc.float constraints.min must be smaller or equal to constraints.max');\n    }\n    if (noNaN) {\n        return integer({ min: minIndex, max: maxIndex }).map(indexToFloat, unmapperFloatToIndex);\n    }\n    const minIndexWithNaN = maxIndex > 0 ? minIndex : minIndex - 1;\n    const maxIndexWithNaN = maxIndex > 0 ? maxIndex + 1 : maxIndex;\n    return integer({ min: minIndexWithNaN, max: maxIndexWithNaN }).map((index) => {\n        if (index > maxIndex || index < minIndex)\n            return safeNaN;\n        else\n            return indexToFloat(index);\n    }, (value) => {\n        if (typeof value !== 'number')\n            throw new Error('Unsupported type');\n        if (safeNumberIsNaN(value))\n            return maxIndex !== maxIndexWithNaN ? maxIndexWithNaN : minIndexWithNaN;\n        return floatToIndex(value);\n    });\n}\nexport function float(constraints = {}) {\n    if (!constraints.noInteger) {\n        return anyFloat(constraints);\n    }\n    return anyFloat(refineConstraintsForFloatOnly(constraints))\n        .map(floatOnlyMapper, floatOnlyUnmapper)\n        .filter(numberIsNotInteger);\n}\n","import { float } from './float.js';\nimport { array } from './array.js';\nimport { Float32Array } from '../utils/globals.js';\nfunction toTypedMapper(data) {\n    return Float32Array.from(data);\n}\nfunction fromTypedUnmapper(value) {\n    if (!(value instanceof Float32Array))\n        throw new Error('Unexpected type');\n    return [...value];\n}\nexport function float32Array(constraints = {}) {\n    return array(float(constraints), constraints).map(toTypedMapper, fromTypedUnmapper);\n}\n","import { double } from './double.js';\nimport { array } from './array.js';\nimport { Float64Array } from '../utils/globals.js';\nfunction toTypedMapper(data) {\n    return Float64Array.from(data);\n}\nfunction fromTypedUnmapper(value) {\n    if (!(value instanceof Float64Array))\n        throw new Error('Unexpected type');\n    return [...value];\n}\nexport function float64Array(constraints = {}) {\n    return array(double(constraints), constraints).map(toTypedMapper, fromTypedUnmapper);\n}\n","import { buildCharacterArbitrary } from './_internals/builders/CharacterArbitraryBuilder.js';\nimport { indexToPrintableIndexMapper, indexToPrintableIndexUnmapper } from './_internals/mappers/IndexToPrintableIndex.js';\nconst gapSize = 0xdfff + 1 - 0xd800;\nfunction unicodeMapper(v) {\n    if (v < 0xd800)\n        return indexToPrintableIndexMapper(v);\n    return v + gapSize;\n}\nfunction unicodeUnmapper(v) {\n    if (v < 0xd800)\n        return indexToPrintableIndexUnmapper(v);\n    if (v <= 0xdfff)\n        return -1;\n    return v - gapSize;\n}\nexport function fullUnicode() {\n    return buildCharacterArbitrary(0x0000, 0x10ffff - gapSize, unicodeMapper, unicodeUnmapper);\n}\n","import { array } from './array.js';\nimport { fullUnicode } from './fullUnicode.js';\nimport { codePointsToStringMapper, codePointsToStringUnmapper } from './_internals/mappers/CodePointsToString.js';\nimport { createSlicesForString } from './_internals/helpers/SlicesForStringBuilder.js';\nconst safeObjectAssign = Object.assign;\nexport function fullUnicodeString(constraints = {}) {\n    const charArbitrary = fullUnicode();\n    const experimentalCustomSlices = createSlicesForString(charArbitrary, codePointsToStringUnmapper);\n    const enrichedConstraints = safeObjectAssign(safeObjectAssign({}, constraints), {\n        experimentalCustomSlices,\n    });\n    return array(charArbitrary, enrichedConstraints).map(codePointsToStringMapper, codePointsToStringUnmapper);\n}\n","import { hash } from '../utils/hash.js';\nimport { asyncStringify, asyncToStringMethod, stringify, toStringMethod } from '../utils/stringify.js';\nimport { cloneMethod, hasCloneMethod } from '../check/symbols.js';\nimport { array } from './array.js';\nimport { integer } from './integer.js';\nimport { tuple } from './tuple.js';\nimport { escapeForMultilineComments } from './_internals/helpers/TextEscaper.js';\nimport { safeMap, safeSort } from '../utils/globals.js';\nconst safeObjectDefineProperties = Object.defineProperties;\nconst safeObjectKeys = Object.keys;\nexport function func(arb) {\n    return tuple(array(arb, { minLength: 1 }), integer().noShrink()).map(([outs, seed]) => {\n        const producer = () => {\n            const recorded = {};\n            const f = (...args) => {\n                const repr = stringify(args);\n                const val = outs[hash(`${seed}${repr}`) % outs.length];\n                recorded[repr] = val;\n                return hasCloneMethod(val) ? val[cloneMethod]() : val;\n            };\n            function prettyPrint(stringifiedOuts) {\n                const seenValues = safeMap(safeMap(safeSort(safeObjectKeys(recorded)), (k) => `${k} => ${stringify(recorded[k])}`), (line) => `/* ${escapeForMultilineComments(line)} */`);\n                return `function(...args) {\n  // With hash and stringify coming from fast-check${seenValues.length !== 0 ? `\\n  ${seenValues.join('\\n  ')}` : ''}\n  const outs = ${stringifiedOuts};\n  return outs[hash('${seed}' + stringify(args)) % outs.length];\n}`;\n            }\n            return safeObjectDefineProperties(f, {\n                toString: { value: () => prettyPrint(stringify(outs)) },\n                [toStringMethod]: { value: () => prettyPrint(stringify(outs)) },\n                [asyncToStringMethod]: { value: async () => prettyPrint(await asyncStringify(outs)) },\n                [cloneMethod]: { value: producer, configurable: true },\n            });\n        };\n        return producer();\n    });\n}\n","import { GeneratorArbitrary } from './_internals/GeneratorArbitrary.js';\nexport function gen() {\n    return new GeneratorArbitrary();\n}\n","import { buildCharacterArbitrary } from './_internals/builders/CharacterArbitraryBuilder.js';\nfunction hexaMapper(v) {\n    return v < 10\n        ? v + 48\n        : v + 97 - 10;\n}\nfunction hexaUnmapper(v) {\n    return v < 58\n        ? v - 48\n        : v >= 97 && v < 103\n            ? v - 97 + 10\n            : -1;\n}\nexport function hexa() {\n    return buildCharacterArbitrary(0, 15, hexaMapper, hexaUnmapper);\n}\n","import { array } from './array.js';\nimport { hexa } from './hexa.js';\nimport { codePointsToStringMapper, codePointsToStringUnmapper } from './_internals/mappers/CodePointsToString.js';\nimport { createSlicesForString } from './_internals/helpers/SlicesForStringBuilder.js';\nconst safeObjectAssign = Object.assign;\nfunction hexaString(constraints = {}) {\n    const charArbitrary = hexa();\n    const experimentalCustomSlices = createSlicesForString(charArbitrary, codePointsToStringUnmapper);\n    const enrichedConstraints = safeObjectAssign(safeObjectAssign({}, constraints), {\n        experimentalCustomSlices,\n    });\n    return array(charArbitrary, enrichedConstraints).map(codePointsToStringMapper, codePointsToStringUnmapper);\n}\nexport { hexaString };\n","import { StreamArbitrary } from './_internals/StreamArbitrary.js';\nfunction infiniteStream(arb) {\n    return new StreamArbitrary(arb);\n}\nexport { infiniteStream };\n","import { Int16Array } from '../utils/globals.js';\nimport { integer } from './integer.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function int16Array(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, -32768, 32767, Int16Array, integer);\n}\n","import { Int32Array } from '../utils/globals.js';\nimport { integer } from './integer.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function int32Array(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, -0x80000000, 0x7fffffff, Int32Array, integer);\n}\n","import { Int8Array } from '../utils/globals.js';\nimport { integer } from './integer.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function int8Array(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, -128, 127, Int8Array, integer);\n}\n","import { IntegerArbitrary } from './_internals/IntegerArbitrary.js';\nconst safeNumberIsInteger = Number.isInteger;\nfunction buildCompleteIntegerConstraints(constraints) {\n    const min = constraints.min !== undefined ? constraints.min : -0x80000000;\n    const max = constraints.max !== undefined ? constraints.max : 0x7fffffff;\n    return { min, max };\n}\nexport function integer(constraints = {}) {\n    const fullConstraints = buildCompleteIntegerConstraints(constraints);\n    if (fullConstraints.min > fullConstraints.max) {\n        throw new Error('fc.integer maximum value should be equal or greater than the minimum one');\n    }\n    if (!safeNumberIsInteger(fullConstraints.min)) {\n        throw new Error('fc.integer minimum value should be an integer');\n    }\n    if (!safeNumberIsInteger(fullConstraints.max)) {\n        throw new Error('fc.integer maximum value should be an integer');\n    }\n    return new IntegerArbitrary(fullConstraints.min, fullConstraints.max);\n}\n","import { safeJoin, safeMap, safeSplit } from '../utils/globals.js';\nimport { nat } from './nat.js';\nimport { tuple } from './tuple.js';\nimport { tryParseStringifiedNat } from './_internals/mappers/NatToStringifiedNat.js';\nfunction dotJoinerMapper(data) {\n    return safeJoin(data, '.');\n}\nfunction dotJoinerUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Invalid type');\n    }\n    return safeMap(safeSplit(value, '.'), (v) => tryParseStringifiedNat(v, 10));\n}\nexport function ipV4() {\n    return tuple(nat(255), nat(255), nat(255), nat(255)).map(dotJoinerMapper, dotJoinerUnmapper);\n}\n","import { safeJoin, safeSplit } from '../utils/globals.js';\nimport { oneof } from './oneof.js';\nimport { tuple } from './tuple.js';\nimport { buildStringifiedNatArbitrary } from './_internals/builders/StringifiedNatArbitraryBuilder.js';\nfunction dotJoinerMapper(data) {\n    return safeJoin(data, '.');\n}\nfunction dotJoinerUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Invalid type');\n    }\n    return safeSplit(value, '.');\n}\nexport function ipV4Extended() {\n    return oneof(tuple(buildStringifiedNatArbitrary(255), buildStringifiedNatArbitrary(255), buildStringifiedNatArbitrary(255), buildStringifiedNatArbitrary(255)).map(dotJoinerMapper, dotJoinerUnmapper), tuple(buildStringifiedNatArbitrary(255), buildStringifiedNatArbitrary(255), buildStringifiedNatArbitrary(65535)).map(dotJoinerMapper, dotJoinerUnmapper), tuple(buildStringifiedNatArbitrary(255), buildStringifiedNatArbitrary(16777215)).map(dotJoinerMapper, dotJoinerUnmapper), buildStringifiedNatArbitrary(4294967295));\n}\n","import { array } from './array.js';\nimport { oneof } from './oneof.js';\nimport { hexaString } from './hexaString.js';\nimport { tuple } from './tuple.js';\nimport { ipV4 } from './ipV4.js';\nimport { fullySpecifiedMapper, fullySpecifiedUnmapper, onlyTrailingMapper, onlyTrailingUnmapper, multiTrailingMapper, multiTrailingUnmapper, multiTrailingMapperOne, multiTrailingUnmapperOne, singleTrailingMapper, singleTrailingUnmapper, noTrailingMapper, noTrailingUnmapper, } from './_internals/mappers/EntitiesToIPv6.js';\nfunction h16sTol32Mapper([a, b]) {\n    return `${a}:${b}`;\n}\nfunction h16sTol32Unmapper(value) {\n    if (typeof value !== 'string')\n        throw new Error('Invalid type');\n    if (!value.includes(':'))\n        throw new Error('Invalid value');\n    return value.split(':', 2);\n}\nexport function ipV6() {\n    const h16Arb = hexaString({ minLength: 1, maxLength: 4, size: 'max' });\n    const ls32Arb = oneof(tuple(h16Arb, h16Arb).map(h16sTol32Mapper, h16sTol32Unmapper), ipV4());\n    return oneof(tuple(array(h16Arb, { minLength: 6, maxLength: 6, size: 'max' }), ls32Arb).map(fullySpecifiedMapper, fullySpecifiedUnmapper), tuple(array(h16Arb, { minLength: 5, maxLength: 5, size: 'max' }), ls32Arb).map(onlyTrailingMapper, onlyTrailingUnmapper), tuple(array(h16Arb, { minLength: 0, maxLength: 1, size: 'max' }), array(h16Arb, { minLength: 4, maxLength: 4, size: 'max' }), ls32Arb).map(multiTrailingMapper, multiTrailingUnmapper), tuple(array(h16Arb, { minLength: 0, maxLength: 2, size: 'max' }), array(h16Arb, { minLength: 3, maxLength: 3, size: 'max' }), ls32Arb).map(multiTrailingMapper, multiTrailingUnmapper), tuple(array(h16Arb, { minLength: 0, maxLength: 3, size: 'max' }), array(h16Arb, { minLength: 2, maxLength: 2, size: 'max' }), ls32Arb).map(multiTrailingMapper, multiTrailingUnmapper), tuple(array(h16Arb, { minLength: 0, maxLength: 4, size: 'max' }), h16Arb, ls32Arb).map(multiTrailingMapperOne, multiTrailingUnmapperOne), tuple(array(h16Arb, { minLength: 0, maxLength: 5, size: 'max' }), ls32Arb).map(singleTrailingMapper, singleTrailingUnmapper), tuple(array(h16Arb, { minLength: 0, maxLength: 6, size: 'max' }), h16Arb).map(singleTrailingMapper, singleTrailingUnmapper), tuple(array(h16Arb, { minLength: 0, maxLength: 7, size: 'max' })).map(noTrailingMapper, noTrailingUnmapper));\n}\n","import { jsonValue } from './jsonValue.js';\nexport function json(constraints = {}) {\n    const arb = jsonValue(constraints);\n    return arb.map(JSON.stringify);\n}\n","import { string } from './string.js';\nimport { jsonConstraintsBuilder } from './_internals/helpers/JsonConstraintsBuilder.js';\nimport { anything } from './anything.js';\nimport { fullUnicodeString } from './fullUnicodeString.js';\nexport function jsonValue(constraints = {}) {\n    const noUnicodeString = constraints.noUnicodeString === undefined || constraints.noUnicodeString === true;\n    const stringArbitrary = noUnicodeString ? string() : fullUnicodeString();\n    return anything(jsonConstraintsBuilder(stringArbitrary, constraints));\n}\n","import { LazyArbitrary } from './_internals/LazyArbitrary.js';\nimport { safeHasOwnProperty } from '../utils/globals.js';\nconst safeObjectCreate = Object.create;\nexport function letrec(builder) {\n    const lazyArbs = safeObjectCreate(null);\n    const tie = (key) => {\n        if (!safeHasOwnProperty(lazyArbs, key)) {\n            lazyArbs[key] = new LazyArbitrary(String(key));\n        }\n        return lazyArbs[key];\n    };\n    const strictArbs = builder(tie);\n    for (const key in strictArbs) {\n        if (!safeHasOwnProperty(strictArbs, key)) {\n            continue;\n        }\n        const lazyAtKey = lazyArbs[key];\n        const lazyArb = lazyAtKey !== undefined ? lazyAtKey : new LazyArbitrary(key);\n        lazyArb.underlying = strictArbs[key];\n        lazyArbs[key] = lazyArb;\n    }\n    return strictArbs;\n}\n","import { array } from './array.js';\nimport { constant } from './constant.js';\nimport { oneof } from './oneof.js';\nimport { sentencesToParagraphMapper, sentencesToParagraphUnmapper, wordsToJoinedStringMapper, wordsToJoinedStringUnmapperFor, wordsToSentenceMapper, wordsToSentenceUnmapperFor, } from './_internals/mappers/WordsToLorem.js';\nconst h = (v, w) => {\n    return { arbitrary: constant(v), weight: w };\n};\nfunction loremWord() {\n    return oneof(h('non', 6), h('adipiscing', 5), h('ligula', 5), h('enim', 5), h('pellentesque', 5), h('in', 5), h('augue', 5), h('et', 5), h('nulla', 5), h('lorem', 4), h('sit', 4), h('sed', 4), h('diam', 4), h('fermentum', 4), h('ut', 4), h('eu', 4), h('aliquam', 4), h('mauris', 4), h('vitae', 4), h('felis', 4), h('ipsum', 3), h('dolor', 3), h('amet,', 3), h('elit', 3), h('euismod', 3), h('mi', 3), h('orci', 3), h('erat', 3), h('praesent', 3), h('egestas', 3), h('leo', 3), h('vel', 3), h('sapien', 3), h('integer', 3), h('curabitur', 3), h('convallis', 3), h('purus', 3), h('risus', 2), h('suspendisse', 2), h('lectus', 2), h('nec,', 2), h('ultricies', 2), h('sed,', 2), h('cras', 2), h('elementum', 2), h('ultrices', 2), h('maecenas', 2), h('massa,', 2), h('varius', 2), h('a,', 2), h('semper', 2), h('proin', 2), h('nec', 2), h('nisl', 2), h('amet', 2), h('duis', 2), h('congue', 2), h('libero', 2), h('vestibulum', 2), h('pede', 2), h('blandit', 2), h('sodales', 2), h('ante', 2), h('nibh', 2), h('ac', 2), h('aenean', 2), h('massa', 2), h('suscipit', 2), h('sollicitudin', 2), h('fusce', 2), h('tempus', 2), h('aliquam,', 2), h('nunc', 2), h('ullamcorper', 2), h('rhoncus', 2), h('metus', 2), h('faucibus,', 2), h('justo', 2), h('magna', 2), h('at', 2), h('tincidunt', 2), h('consectetur', 1), h('tortor,', 1), h('dignissim', 1), h('congue,', 1), h('non,', 1), h('porttitor,', 1), h('nonummy', 1), h('molestie,', 1), h('est', 1), h('eleifend', 1), h('mi,', 1), h('arcu', 1), h('scelerisque', 1), h('vitae,', 1), h('consequat', 1), h('in,', 1), h('pretium', 1), h('volutpat', 1), h('pharetra', 1), h('tempor', 1), h('bibendum', 1), h('odio', 1), h('dui', 1), h('primis', 1), h('faucibus', 1), h('luctus', 1), h('posuere', 1), h('cubilia', 1), h('curae,', 1), h('hendrerit', 1), h('velit', 1), h('mauris,', 1), h('gravida', 1), h('ornare', 1), h('ut,', 1), h('pulvinar', 1), h('varius,', 1), h('turpis', 1), h('nibh,', 1), h('eros', 1), h('id', 1), h('aliquet', 1), h('quis', 1), h('lobortis', 1), h('consectetuer', 1), h('morbi', 1), h('vehicula', 1), h('tortor', 1), h('tellus,', 1), h('id,', 1), h('eu,', 1), h('quam', 1), h('feugiat,', 1), h('posuere,', 1), h('iaculis', 1), h('lectus,', 1), h('tristique', 1), h('mollis,', 1), h('nisl,', 1), h('vulputate', 1), h('sem', 1), h('vivamus', 1), h('placerat', 1), h('imperdiet', 1), h('cursus', 1), h('rutrum', 1), h('iaculis,', 1), h('augue,', 1), h('lacus', 1));\n}\nexport function lorem(constraints = {}) {\n    const { maxCount, mode = 'words', size } = constraints;\n    if (maxCount !== undefined && maxCount < 1) {\n        throw new Error(`lorem has to produce at least one word/sentence`);\n    }\n    const wordArbitrary = loremWord();\n    if (mode === 'sentences') {\n        const sentence = array(wordArbitrary, { minLength: 1, size: 'small' }).map(wordsToSentenceMapper, wordsToSentenceUnmapperFor(wordArbitrary));\n        return array(sentence, { minLength: 1, maxLength: maxCount, size }).map(sentencesToParagraphMapper, sentencesToParagraphUnmapper);\n    }\n    else {\n        return array(wordArbitrary, { minLength: 1, maxLength: maxCount, size }).map(wordsToJoinedStringMapper, wordsToJoinedStringUnmapperFor(wordArbitrary));\n    }\n}\n","import { nat } from './nat.js';\nimport { indexToMappedConstantMapperFor, indexToMappedConstantUnmapperFor, } from './_internals/mappers/IndexToMappedConstant.js';\nfunction computeNumChoices(options) {\n    if (options.length === 0)\n        throw new Error(`fc.mapToConstant expects at least one option`);\n    let numChoices = 0;\n    for (let idx = 0; idx !== options.length; ++idx) {\n        if (options[idx].num < 0)\n            throw new Error(`fc.mapToConstant expects all options to have a number of entries greater or equal to zero`);\n        numChoices += options[idx].num;\n    }\n    if (numChoices === 0)\n        throw new Error(`fc.mapToConstant expects at least one choice among options`);\n    return numChoices;\n}\nexport function mapToConstant(...entries) {\n    const numChoices = computeNumChoices(entries);\n    return nat({ max: numChoices - 1 }).map(indexToMappedConstantMapperFor(entries), indexToMappedConstantUnmapperFor(entries));\n}\n","import { IntegerArbitrary } from './_internals/IntegerArbitrary.js';\nconst safeMinSafeInteger = Number.MIN_SAFE_INTEGER;\nconst safeMaxSafeInteger = Number.MAX_SAFE_INTEGER;\nexport function maxSafeInteger() {\n    return new IntegerArbitrary(safeMinSafeInteger, safeMaxSafeInteger);\n}\n","import { IntegerArbitrary } from './_internals/IntegerArbitrary.js';\nconst safeMaxSafeInteger = Number.MAX_SAFE_INTEGER;\nexport function maxSafeNat() {\n    return new IntegerArbitrary(0, safeMaxSafeInteger);\n}\n","import { safeHasOwnProperty } from '../utils/globals.js';\nlet contextRemainingDepth = 10;\nexport function memo(builder) {\n    const previous = {};\n    return ((maxDepth) => {\n        const n = maxDepth !== undefined ? maxDepth : contextRemainingDepth;\n        if (!safeHasOwnProperty(previous, n)) {\n            const prev = contextRemainingDepth;\n            contextRemainingDepth = n - 1;\n            previous[n] = builder(n);\n            contextRemainingDepth = prev;\n        }\n        return previous[n];\n    });\n}\n","import { safeToUpperCase, safeToLowerCase, BigInt, Error } from '../utils/globals.js';\nimport { MixedCaseArbitrary } from './_internals/MixedCaseArbitrary.js';\nfunction defaultToggleCase(rawChar) {\n    const upper = safeToUpperCase(rawChar);\n    if (upper !== rawChar)\n        return upper;\n    return safeToLowerCase(rawChar);\n}\nexport function mixedCase(stringArb, constraints) {\n    if (typeof BigInt === 'undefined') {\n        throw new Error(`mixedCase requires BigInt support`);\n    }\n    const toggleCase = (constraints && constraints.toggleCase) || defaultToggleCase;\n    const untoggleAll = constraints && constraints.untoggleAll;\n    return new MixedCaseArbitrary(stringArb, toggleCase, untoggleAll);\n}\n","import { IntegerArbitrary } from './_internals/IntegerArbitrary.js';\nconst safeNumberIsInteger = Number.isInteger;\nfunction nat(arg) {\n    const max = typeof arg === 'number' ? arg : arg && arg.max !== undefined ? arg.max : 0x7fffffff;\n    if (max < 0) {\n        throw new Error('fc.nat value should be greater than or equal to 0');\n    }\n    if (!safeNumberIsInteger(max)) {\n        throw new Error('fc.nat maximum value should be an integer');\n    }\n    return new IntegerArbitrary(0, max);\n}\nexport { nat };\n","import { dictionary } from './dictionary.js';\nimport { anyArbitraryBuilder } from './_internals/builders/AnyArbitraryBuilder.js';\nimport { toQualifiedObjectConstraints } from './_internals/helpers/QualifiedObjectConstraints.js';\nfunction objectInternal(constraints) {\n    return dictionary(constraints.key, anyArbitraryBuilder(constraints), {\n        maxKeys: constraints.maxKeys,\n        noNullPrototype: !constraints.withNullPrototype,\n        size: constraints.size,\n    });\n}\nfunction object(constraints) {\n    return objectInternal(toQualifiedObjectConstraints(constraints));\n}\nexport { object };\n","import { isArbitrary } from '../check/arbitrary/definition/Arbitrary.js';\nimport { safeMap, safeSlice } from '../utils/globals.js';\nimport { FrequencyArbitrary } from './_internals/FrequencyArbitrary.js';\nfunction isOneOfContraints(param) {\n    return (param != null &&\n        typeof param === 'object' &&\n        !('generate' in param) &&\n        !('arbitrary' in param) &&\n        !('weight' in param));\n}\nfunction toWeightedArbitrary(maybeWeightedArbitrary) {\n    if (isArbitrary(maybeWeightedArbitrary)) {\n        return { arbitrary: maybeWeightedArbitrary, weight: 1 };\n    }\n    return maybeWeightedArbitrary;\n}\nfunction oneof(...args) {\n    const constraints = args[0];\n    if (isOneOfContraints(constraints)) {\n        const weightedArbs = safeMap(safeSlice(args, 1), toWeightedArbitrary);\n        return FrequencyArbitrary.from(weightedArbs, constraints, 'fc.oneof');\n    }\n    const weightedArbs = safeMap(args, toWeightedArbitrary);\n    return FrequencyArbitrary.from(weightedArbs, {}, 'fc.oneof');\n}\nexport { oneof };\n","import { constant } from './constant.js';\nimport { FrequencyArbitrary } from './_internals/FrequencyArbitrary.js';\nimport { safeHasOwnProperty } from '../utils/globals.js';\nexport function option(arb, constraints = {}) {\n    const freq = constraints.freq == null ? 5 : constraints.freq;\n    const nilValue = safeHasOwnProperty(constraints, 'nil') ? constraints.nil : null;\n    const nilArb = constant(nilValue);\n    const weightedArbs = [\n        { arbitrary: nilArb, weight: 1, fallbackValue: { default: nilValue } },\n        { arbitrary: arb, weight: freq },\n    ];\n    const frequencyConstraints = {\n        withCrossShrink: true,\n        depthSize: constraints.depthSize,\n        maxDepth: constraints.maxDepth,\n        depthIdentifier: constraints.depthIdentifier,\n    };\n    return FrequencyArbitrary.from(weightedArbs, frequencyConstraints, 'fc.option');\n}\n","import { buildPartialRecordArbitrary } from './_internals/builders/PartialRecordArbitraryBuilder.js';\nfunction record(recordModel, constraints) {\n    const noNullPrototype = constraints === undefined || constraints.noNullPrototype === undefined || constraints.noNullPrototype;\n    if (constraints == null) {\n        return buildPartialRecordArbitrary(recordModel, undefined, noNullPrototype);\n    }\n    if ('withDeletedKeys' in constraints && 'requiredKeys' in constraints) {\n        throw new Error(`requiredKeys and withDeletedKeys cannot be used together in fc.record`);\n    }\n    const requireDeletedKeys = ('requiredKeys' in constraints && constraints.requiredKeys !== undefined) ||\n        ('withDeletedKeys' in constraints && !!constraints.withDeletedKeys);\n    if (!requireDeletedKeys) {\n        return buildPartialRecordArbitrary(recordModel, undefined, noNullPrototype);\n    }\n    const requiredKeys = ('requiredKeys' in constraints ? constraints.requiredKeys : undefined) || [];\n    for (let idx = 0; idx !== requiredKeys.length; ++idx) {\n        const descriptor = Object.getOwnPropertyDescriptor(recordModel, requiredKeys[idx]);\n        if (descriptor === undefined) {\n            throw new Error(`requiredKeys cannot reference keys that have not been defined in recordModel`);\n        }\n        if (!descriptor.enumerable) {\n            throw new Error(`requiredKeys cannot reference keys that have are enumerable in recordModel`);\n        }\n    }\n    return buildPartialRecordArbitrary(recordModel, requiredKeys, noNullPrototype);\n}\nexport { record };\n","import { buildSchedulerFor } from './_internals/helpers/BuildSchedulerFor.js';\nimport { SchedulerArbitrary } from './_internals/SchedulerArbitrary.js';\nexport function scheduler(constraints) {\n    const { act = (f) => f() } = constraints || {};\n    return new SchedulerArbitrary(act);\n}\nfunction schedulerFor(customOrderingOrConstraints, constraintsOrUndefined) {\n    const { act = (f) => f() } = Array.isArray(customOrderingOrConstraints)\n        ? constraintsOrUndefined || {}\n        : customOrderingOrConstraints || {};\n    if (Array.isArray(customOrderingOrConstraints)) {\n        return buildSchedulerFor(act, customOrderingOrConstraints);\n    }\n    return function (_strs, ...ordering) {\n        return buildSchedulerFor(act, ordering);\n    };\n}\nexport { schedulerFor };\n","import { SubarrayArbitrary } from './_internals/SubarrayArbitrary.js';\nexport function shuffledSubarray(originalArray, constraints = {}) {\n    const { minLength = 0, maxLength = originalArray.length } = constraints;\n    return new SubarrayArbitrary(originalArray, false, minLength, maxLength);\n}\n","import { Array, safeMap, safeSlice } from '../utils/globals.js';\nimport { tuple } from './tuple.js';\nimport { uniqueArray } from './uniqueArray.js';\nimport { restrictedIntegerArbitraryBuilder } from './_internals/builders/RestrictedIntegerArbitraryBuilder.js';\nimport { maxGeneratedLengthFromSizeForArbitrary, MaxLengthUpperBound, } from './_internals/helpers/MaxLengthFromMinLength.js';\nconst safeMathMin = Math.min;\nconst safeMathMax = Math.max;\nconst safeArrayIsArray = Array.isArray;\nconst safeObjectEntries = Object.entries;\nfunction extractMaxIndex(indexesAndValues) {\n    let maxIndex = -1;\n    for (let index = 0; index !== indexesAndValues.length; ++index) {\n        maxIndex = safeMathMax(maxIndex, indexesAndValues[index][0]);\n    }\n    return maxIndex;\n}\nfunction arrayFromItems(length, indexesAndValues) {\n    const array = Array(length);\n    for (let index = 0; index !== indexesAndValues.length; ++index) {\n        const it = indexesAndValues[index];\n        if (it[0] < length)\n            array[it[0]] = it[1];\n    }\n    return array;\n}\nexport function sparseArray(arb, constraints = {}) {\n    const { size, minNumElements = 0, maxLength = MaxLengthUpperBound, maxNumElements = maxLength, noTrailingHole, depthIdentifier, } = constraints;\n    const maxGeneratedNumElements = maxGeneratedLengthFromSizeForArbitrary(size, minNumElements, maxNumElements, constraints.maxNumElements !== undefined);\n    const maxGeneratedLength = maxGeneratedLengthFromSizeForArbitrary(size, maxGeneratedNumElements, maxLength, constraints.maxLength !== undefined);\n    if (minNumElements > maxLength) {\n        throw new Error(`The minimal number of non-hole elements cannot be higher than the maximal length of the array`);\n    }\n    if (minNumElements > maxNumElements) {\n        throw new Error(`The minimal number of non-hole elements cannot be higher than the maximal number of non-holes`);\n    }\n    const resultedMaxNumElements = safeMathMin(maxNumElements, maxLength);\n    const resultedSizeMaxNumElements = constraints.maxNumElements !== undefined || size !== undefined ? size : '=';\n    const maxGeneratedIndexAuthorized = safeMathMax(maxGeneratedLength - 1, 0);\n    const maxIndexAuthorized = safeMathMax(maxLength - 1, 0);\n    const sparseArrayNoTrailingHole = uniqueArray(tuple(restrictedIntegerArbitraryBuilder(0, maxGeneratedIndexAuthorized, maxIndexAuthorized), arb), {\n        size: resultedSizeMaxNumElements,\n        minLength: minNumElements,\n        maxLength: resultedMaxNumElements,\n        selector: (item) => item[0],\n        depthIdentifier,\n    }).map((items) => {\n        const lastIndex = extractMaxIndex(items);\n        return arrayFromItems(lastIndex + 1, items);\n    }, (value) => {\n        if (!safeArrayIsArray(value)) {\n            throw new Error('Not supported entry type');\n        }\n        if (noTrailingHole && value.length !== 0 && !(value.length - 1 in value)) {\n            throw new Error('No trailing hole');\n        }\n        return safeMap(safeObjectEntries(value), (entry) => [Number(entry[0]), entry[1]]);\n    });\n    if (noTrailingHole || maxLength === minNumElements) {\n        return sparseArrayNoTrailingHole;\n    }\n    return tuple(sparseArrayNoTrailingHole, restrictedIntegerArbitraryBuilder(minNumElements, maxGeneratedLength, maxLength)).map((data) => {\n        const sparse = data[0];\n        const targetLength = data[1];\n        if (sparse.length >= targetLength) {\n            return sparse;\n        }\n        const longerSparse = safeSlice(sparse);\n        longerSparse.length = targetLength;\n        return longerSparse;\n    }, (value) => {\n        if (!safeArrayIsArray(value)) {\n            throw new Error('Not supported entry type');\n        }\n        return [value, value.length];\n    });\n}\n","import { array } from './array.js';\nimport { char } from './char.js';\nimport { codePointsToStringMapper, codePointsToStringUnmapper } from './_internals/mappers/CodePointsToString.js';\nimport { createSlicesForString } from './_internals/helpers/SlicesForStringBuilder.js';\nconst safeObjectAssign = Object.assign;\nexport function string(constraints = {}) {\n    const charArbitrary = char();\n    const experimentalCustomSlices = createSlicesForString(charArbitrary, codePointsToStringUnmapper);\n    const enrichedConstraints = safeObjectAssign(safeObjectAssign({}, constraints), {\n        experimentalCustomSlices,\n    });\n    return array(charArbitrary, enrichedConstraints).map(codePointsToStringMapper, codePointsToStringUnmapper);\n}\n","import { array } from './array.js';\nimport { char16bits } from './char16bits.js';\nimport { charsToStringMapper, charsToStringUnmapper } from './_internals/mappers/CharsToString.js';\nimport { createSlicesForString } from './_internals/helpers/SlicesForStringBuilder.js';\nconst safeObjectAssign = Object.assign;\nexport function string16bits(constraints = {}) {\n    const charArbitrary = char16bits();\n    const experimentalCustomSlices = createSlicesForString(charArbitrary, charsToStringUnmapper);\n    const enrichedConstraints = safeObjectAssign(safeObjectAssign({}, constraints), {\n        experimentalCustomSlices,\n    });\n    return array(charArbitrary, enrichedConstraints).map(charsToStringMapper, charsToStringUnmapper);\n}\n","import { safeEvery, safeJoin } from '../utils/globals.js';\nimport { Error, safeIndexOf, safeMap } from '../utils/globals.js';\nimport { stringify } from '../utils/stringify.js';\nimport { addMissingDotStar } from './_internals/helpers/SanitizeRegexAst.js';\nimport { tokenizeRegex } from './_internals/helpers/TokenizeRegex.js';\nimport { char } from './char.js';\nimport { constant } from './constant.js';\nimport { constantFrom } from './constantFrom.js';\nimport { integer } from './integer.js';\nimport { oneof } from './oneof.js';\nimport { stringOf } from './stringOf.js';\nimport { tuple } from './tuple.js';\nconst safeStringFromCodePoint = String.fromCodePoint;\nconst wordChars = [...'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_'];\nconst digitChars = [...'0123456789'];\nconst spaceChars = [...' \\t\\r\\n\\v\\f'];\nconst newLineChars = [...'\\r\\n'];\nconst terminatorChars = [...'\\x1E\\x15'];\nconst newLineAndTerminatorChars = [...newLineChars, ...terminatorChars];\nconst defaultChar = char();\nfunction raiseUnsupportedASTNode(astNode) {\n    return new Error(`Unsupported AST node! Received: ${stringify(astNode)}`);\n}\nfunction toMatchingArbitrary(astNode, constraints, flags) {\n    switch (astNode.type) {\n        case 'Char': {\n            if (astNode.kind === 'meta') {\n                switch (astNode.value) {\n                    case '\\\\w': {\n                        return constantFrom(...wordChars);\n                    }\n                    case '\\\\W': {\n                        return defaultChar.filter((c) => safeIndexOf(wordChars, c) === -1);\n                    }\n                    case '\\\\d': {\n                        return constantFrom(...digitChars);\n                    }\n                    case '\\\\D': {\n                        return defaultChar.filter((c) => safeIndexOf(digitChars, c) === -1);\n                    }\n                    case '\\\\s': {\n                        return constantFrom(...spaceChars);\n                    }\n                    case '\\\\S': {\n                        return defaultChar.filter((c) => safeIndexOf(spaceChars, c) === -1);\n                    }\n                    case '\\\\b':\n                    case '\\\\B': {\n                        throw new Error(`Meta character ${astNode.value} not implemented yet!`);\n                    }\n                    case '.': {\n                        const forbiddenChars = flags.dotAll ? terminatorChars : newLineAndTerminatorChars;\n                        return defaultChar.filter((c) => safeIndexOf(forbiddenChars, c) === -1);\n                    }\n                }\n            }\n            if (astNode.symbol === undefined) {\n                throw new Error(`Unexpected undefined symbol received for non-meta Char! Received: ${stringify(astNode)}`);\n            }\n            return constant(astNode.symbol);\n        }\n        case 'Repetition': {\n            const node = toMatchingArbitrary(astNode.expression, constraints, flags);\n            switch (astNode.quantifier.kind) {\n                case '*': {\n                    return stringOf(node, constraints);\n                }\n                case '+': {\n                    return stringOf(node, Object.assign(Object.assign({}, constraints), { minLength: 1 }));\n                }\n                case '?': {\n                    return stringOf(node, Object.assign(Object.assign({}, constraints), { minLength: 0, maxLength: 1 }));\n                }\n                case 'Range': {\n                    return stringOf(node, Object.assign(Object.assign({}, constraints), { minLength: astNode.quantifier.from, maxLength: astNode.quantifier.to }));\n                }\n                default: {\n                    throw raiseUnsupportedASTNode(astNode.quantifier);\n                }\n            }\n        }\n        case 'Quantifier': {\n            throw new Error(`Wrongly defined AST tree, Quantifier nodes not supposed to be scanned!`);\n        }\n        case 'Alternative': {\n            return tuple(...safeMap(astNode.expressions, (n) => toMatchingArbitrary(n, constraints, flags))).map((vs) => safeJoin(vs, ''));\n        }\n        case 'CharacterClass':\n            if (astNode.negative) {\n                const childrenArbitraries = safeMap(astNode.expressions, (n) => toMatchingArbitrary(n, constraints, flags));\n                return defaultChar.filter((c) => safeEvery(childrenArbitraries, (arb) => !arb.canShrinkWithoutContext(c)));\n            }\n            return oneof(...safeMap(astNode.expressions, (n) => toMatchingArbitrary(n, constraints, flags)));\n        case 'ClassRange': {\n            const min = astNode.from.codePoint;\n            const max = astNode.to.codePoint;\n            return integer({ min, max }).map((n) => safeStringFromCodePoint(n), (c) => {\n                if (typeof c !== 'string')\n                    throw new Error('Invalid type');\n                if ([...c].length !== 1)\n                    throw new Error('Invalid length');\n                return c.codePointAt(0);\n            });\n        }\n        case 'Group': {\n            return toMatchingArbitrary(astNode.expression, constraints, flags);\n        }\n        case 'Disjunction': {\n            const left = astNode.left !== null ? toMatchingArbitrary(astNode.left, constraints, flags) : constant('');\n            const right = astNode.right !== null ? toMatchingArbitrary(astNode.right, constraints, flags) : constant('');\n            return oneof(left, right);\n        }\n        case 'Assertion': {\n            if (astNode.kind === '^' || astNode.kind === '$') {\n                if (flags.multiline) {\n                    if (astNode.kind === '^') {\n                        return oneof(constant(''), tuple(stringOf(defaultChar), constantFrom(...newLineChars)).map((t) => `${t[0]}${t[1]}`, (value) => {\n                            if (typeof value !== 'string' || value.length === 0)\n                                throw new Error('Invalid type');\n                            return [value.substring(0, value.length - 1), value[value.length - 1]];\n                        }));\n                    }\n                    else {\n                        return oneof(constant(''), tuple(constantFrom(...newLineChars), stringOf(defaultChar)).map((t) => `${t[0]}${t[1]}`, (value) => {\n                            if (typeof value !== 'string' || value.length === 0)\n                                throw new Error('Invalid type');\n                            return [value[0], value.substring(1)];\n                        }));\n                    }\n                }\n                return constant('');\n            }\n            throw new Error(`Assertions of kind ${astNode.kind} not implemented yet!`);\n        }\n        case 'Backreference': {\n            throw new Error(`Backreference nodes not implemented yet!`);\n        }\n        default: {\n            throw raiseUnsupportedASTNode(astNode);\n        }\n    }\n}\nexport function stringMatching(regex, constraints = {}) {\n    for (const flag of regex.flags) {\n        if (flag !== 'd' && flag !== 'g' && flag !== 'm' && flag !== 's' && flag !== 'u') {\n            throw new Error(`Unable to use \"stringMatching\" against a regex using the flag ${flag}`);\n        }\n    }\n    const sanitizedConstraints = { size: constraints.size };\n    const flags = { multiline: regex.multiline, dotAll: regex.dotAll };\n    const regexRootToken = addMissingDotStar(tokenizeRegex(regex));\n    return toMatchingArbitrary(regexRootToken, sanitizedConstraints, flags);\n}\n","import { array } from './array.js';\nimport { patternsToStringMapper, patternsToStringUnmapperFor } from './_internals/mappers/PatternsToString.js';\nimport { createSlicesForString } from './_internals/helpers/SlicesForStringBuilder.js';\nconst safeObjectAssign = Object.assign;\nexport function stringOf(charArb, constraints = {}) {\n    const unmapper = patternsToStringUnmapperFor(charArb, constraints);\n    const experimentalCustomSlices = createSlicesForString(charArb, unmapper);\n    const enrichedConstraints = safeObjectAssign(safeObjectAssign({}, constraints), {\n        experimentalCustomSlices,\n    });\n    return array(charArb, enrichedConstraints).map(patternsToStringMapper, unmapper);\n}\n","import { SubarrayArbitrary } from './_internals/SubarrayArbitrary.js';\nexport function subarray(originalArray, constraints = {}) {\n    const { minLength = 0, maxLength = originalArray.length } = constraints;\n    return new SubarrayArbitrary(originalArray, true, minLength, maxLength);\n}\n","import { TupleArbitrary } from './_internals/TupleArbitrary.js';\nexport function tuple(...arbs) {\n    return new TupleArbitrary(arbs);\n}\n","import { Uint16Array } from '../utils/globals.js';\nimport { integer } from './integer.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function uint16Array(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, 0, 65535, Uint16Array, integer);\n}\n","import { Uint32Array } from '../utils/globals.js';\nimport { integer } from './integer.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function uint32Array(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, 0, 0xffffffff, Uint32Array, integer);\n}\n","import { Uint8Array } from '../utils/globals.js';\nimport { integer } from './integer.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function uint8Array(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, 0, 255, Uint8Array, integer);\n}\n","import { Uint8ClampedArray } from '../utils/globals.js';\nimport { integer } from './integer.js';\nimport { typedIntArrayArbitraryArbitraryBuilder } from './_internals/builders/TypedIntArrayArbitraryBuilder.js';\nexport function uint8ClampedArray(constraints = {}) {\n    return typedIntArrayArbitraryArbitraryBuilder(constraints, 0, 255, Uint8ClampedArray, integer);\n}\n","import { tuple } from './tuple.js';\nimport { integer } from './integer.js';\nimport { paddedUintToBase32StringMapper, uintToBase32StringUnmapper } from './_internals/mappers/UintToBase32String.js';\nconst padded10Mapper = paddedUintToBase32StringMapper(10);\nconst padded8Mapper = paddedUintToBase32StringMapper(8);\nfunction ulidMapper(parts) {\n    return (padded10Mapper(parts[0]) +\n        padded8Mapper(parts[1]) +\n        padded8Mapper(parts[2]));\n}\nfunction ulidUnmapper(value) {\n    if (typeof value !== 'string' || value.length !== 26) {\n        throw new Error('Unsupported type');\n    }\n    return [\n        uintToBase32StringUnmapper(value.slice(0, 10)),\n        uintToBase32StringUnmapper(value.slice(10, 18)),\n        uintToBase32StringUnmapper(value.slice(18)),\n    ];\n}\nexport function ulid() {\n    const timestampPartArbitrary = integer({ min: 0, max: 0xffffffffffff });\n    const randomnessPartOneArbitrary = integer({ min: 0, max: 0xffffffffff });\n    const randomnessPartTwoArbitrary = integer({ min: 0, max: 0xffffffffff });\n    return tuple(timestampPartArbitrary, randomnessPartOneArbitrary, randomnessPartTwoArbitrary).map(ulidMapper, ulidUnmapper);\n}\n","import { buildCharacterArbitrary } from './_internals/builders/CharacterArbitraryBuilder.js';\nimport { indexToPrintableIndexMapper, indexToPrintableIndexUnmapper } from './_internals/mappers/IndexToPrintableIndex.js';\nconst gapSize = 0xdfff + 1 - 0xd800;\nfunction unicodeMapper(v) {\n    if (v < 0xd800)\n        return indexToPrintableIndexMapper(v);\n    return v + gapSize;\n}\nfunction unicodeUnmapper(v) {\n    if (v < 0xd800)\n        return indexToPrintableIndexUnmapper(v);\n    if (v <= 0xdfff)\n        return -1;\n    return v - gapSize;\n}\nexport function unicode() {\n    return buildCharacterArbitrary(0x0000, 0xffff - gapSize, unicodeMapper, unicodeUnmapper);\n}\n","import { unicodeJsonValue } from './unicodeJsonValue.js';\nexport function unicodeJson(constraints = {}) {\n    const arb = unicodeJsonValue(constraints);\n    return arb.map(JSON.stringify);\n}\n","import { unicodeString } from './unicodeString.js';\nimport { jsonConstraintsBuilder } from './_internals/helpers/JsonConstraintsBuilder.js';\nimport { anything } from './anything.js';\nexport function unicodeJsonValue(constraints = {}) {\n    return anything(jsonConstraintsBuilder(unicodeString(), constraints));\n}\n","import { array } from './array.js';\nimport { unicode } from './unicode.js';\nimport { codePointsToStringMapper, codePointsToStringUnmapper } from './_internals/mappers/CodePointsToString.js';\nimport { createSlicesForString } from './_internals/helpers/SlicesForStringBuilder.js';\nconst safeObjectAssign = Object.assign;\nexport function unicodeString(constraints = {}) {\n    const charArbitrary = unicode();\n    const experimentalCustomSlices = createSlicesForString(charArbitrary, codePointsToStringUnmapper);\n    const enrichedConstraints = safeObjectAssign(safeObjectAssign({}, constraints), {\n        experimentalCustomSlices,\n    });\n    return array(charArbitrary, enrichedConstraints).map(codePointsToStringMapper, codePointsToStringUnmapper);\n}\n","import { ArrayArbitrary } from './_internals/ArrayArbitrary.js';\nimport { maxGeneratedLengthFromSizeForArbitrary, MaxLengthUpperBound, } from './_internals/helpers/MaxLengthFromMinLength.js';\nimport { CustomEqualSet } from './_internals/helpers/CustomEqualSet.js';\nimport { StrictlyEqualSet } from './_internals/helpers/StrictlyEqualSet.js';\nimport { SameValueSet } from './_internals/helpers/SameValueSet.js';\nimport { SameValueZeroSet } from './_internals/helpers/SameValueZeroSet.js';\nfunction buildUniqueArraySetBuilder(constraints) {\n    if (typeof constraints.comparator === 'function') {\n        if (constraints.selector === undefined) {\n            const comparator = constraints.comparator;\n            const isEqualForBuilder = (nextA, nextB) => comparator(nextA.value_, nextB.value_);\n            return () => new CustomEqualSet(isEqualForBuilder);\n        }\n        const comparator = constraints.comparator;\n        const selector = constraints.selector;\n        const refinedSelector = (next) => selector(next.value_);\n        const isEqualForBuilder = (nextA, nextB) => comparator(refinedSelector(nextA), refinedSelector(nextB));\n        return () => new CustomEqualSet(isEqualForBuilder);\n    }\n    const selector = constraints.selector || ((v) => v);\n    const refinedSelector = (next) => selector(next.value_);\n    switch (constraints.comparator) {\n        case 'IsStrictlyEqual':\n            return () => new StrictlyEqualSet(refinedSelector);\n        case 'SameValueZero':\n            return () => new SameValueZeroSet(refinedSelector);\n        case 'SameValue':\n        case undefined:\n            return () => new SameValueSet(refinedSelector);\n    }\n}\nexport function uniqueArray(arb, constraints = {}) {\n    const minLength = constraints.minLength !== undefined ? constraints.minLength : 0;\n    const maxLength = constraints.maxLength !== undefined ? constraints.maxLength : MaxLengthUpperBound;\n    const maxGeneratedLength = maxGeneratedLengthFromSizeForArbitrary(constraints.size, minLength, maxLength, constraints.maxLength !== undefined);\n    const depthIdentifier = constraints.depthIdentifier;\n    const setBuilder = buildUniqueArraySetBuilder(constraints);\n    const arrayArb = new ArrayArbitrary(arb, minLength, maxGeneratedLength, maxLength, depthIdentifier, setBuilder, []);\n    if (minLength === 0)\n        return arrayArb;\n    return arrayArb.filter((tab) => tab.length >= minLength);\n}\n","import { tuple } from './tuple.js';\nimport { buildPaddedNumberArbitrary } from './_internals/builders/PaddedNumberArbitraryBuilder.js';\nimport { paddedEightsToUuidMapper, paddedEightsToUuidUnmapper } from './_internals/mappers/PaddedEightsToUuid.js';\nexport function uuid() {\n    const padded = buildPaddedNumberArbitrary(0, 0xffffffff);\n    const secondPadded = buildPaddedNumberArbitrary(0x10000000, 0x5fffffff);\n    const thirdPadded = buildPaddedNumberArbitrary(0x80000000, 0xbfffffff);\n    return tuple(padded, secondPadded, thirdPadded, padded).map(paddedEightsToUuidMapper, paddedEightsToUuidUnmapper);\n}\n","import { tuple } from './tuple.js';\nimport { buildPaddedNumberArbitrary } from './_internals/builders/PaddedNumberArbitraryBuilder.js';\nimport { paddedEightsToUuidMapper, paddedEightsToUuidUnmapper } from './_internals/mappers/PaddedEightsToUuid.js';\nexport function uuidV(versionNumber) {\n    const padded = buildPaddedNumberArbitrary(0, 0xffffffff);\n    const offsetSecond = versionNumber * 0x10000000;\n    const secondPadded = buildPaddedNumberArbitrary(offsetSecond, offsetSecond + 0x0fffffff);\n    const thirdPadded = buildPaddedNumberArbitrary(0x80000000, 0xbfffffff);\n    return tuple(padded, secondPadded, thirdPadded, padded).map(paddedEightsToUuidMapper, paddedEightsToUuidUnmapper);\n}\n","import { buildAlphaNumericPercentArbitrary } from './_internals/builders/CharacterRangeArbitraryBuilder.js';\nimport { constant } from './constant.js';\nimport { domain } from './domain.js';\nimport { ipV4 } from './ipV4.js';\nimport { ipV4Extended } from './ipV4Extended.js';\nimport { ipV6 } from './ipV6.js';\nimport { nat } from './nat.js';\nimport { oneof } from './oneof.js';\nimport { option } from './option.js';\nimport { stringOf } from './stringOf.js';\nimport { tuple } from './tuple.js';\nfunction hostUserInfo(size) {\n    const others = ['-', '.', '_', '~', '!', '$', '&', \"'\", '(', ')', '*', '+', ',', ';', '=', ':'];\n    return stringOf(buildAlphaNumericPercentArbitrary(others), { size });\n}\nfunction userHostPortMapper([u, h, p]) {\n    return (u === null ? '' : `${u}@`) + h + (p === null ? '' : `:${p}`);\n}\nfunction userHostPortUnmapper(value) {\n    if (typeof value !== 'string') {\n        throw new Error('Unsupported');\n    }\n    const atPosition = value.indexOf('@');\n    const user = atPosition !== -1 ? value.substring(0, atPosition) : null;\n    const portRegex = /:(\\d+)$/;\n    const m = portRegex.exec(value);\n    const port = m !== null ? Number(m[1]) : null;\n    const host = m !== null ? value.substring(atPosition + 1, value.length - m[1].length - 1) : value.substring(atPosition + 1);\n    return [user, host, port];\n}\nfunction bracketedMapper(s) {\n    return `[${s}]`;\n}\nfunction bracketedUnmapper(value) {\n    if (typeof value !== 'string' || value[0] !== '[' || value[value.length - 1] !== ']') {\n        throw new Error('Unsupported');\n    }\n    return value.substring(1, value.length - 1);\n}\nexport function webAuthority(constraints) {\n    const c = constraints || {};\n    const size = c.size;\n    const hostnameArbs = [\n        domain({ size }),\n        ...(c.withIPv4 === true ? [ipV4()] : []),\n        ...(c.withIPv6 === true ? [ipV6().map(bracketedMapper, bracketedUnmapper)] : []),\n        ...(c.withIPv4Extended === true ? [ipV4Extended()] : []),\n    ];\n    return tuple(c.withUserInfo === true ? option(hostUserInfo(size)) : constant(null), oneof(...hostnameArbs), c.withPort === true ? option(nat(65535)) : constant(null)).map(userHostPortMapper, userHostPortUnmapper);\n}\n","import { buildUriQueryOrFragmentArbitrary } from './_internals/builders/UriQueryOrFragmentArbitraryBuilder.js';\nexport function webFragments(constraints = {}) {\n    return buildUriQueryOrFragmentArbitrary(constraints.size);\n}\n","import { resolveSize } from './_internals/helpers/MaxLengthFromMinLength.js';\nimport { buildUriPathArbitrary } from './_internals/builders/UriPathArbitraryBuilder.js';\nexport function webPath(constraints) {\n    const c = constraints || {};\n    const resolvedSize = resolveSize(c.size);\n    return buildUriPathArbitrary(resolvedSize);\n}\n","import { buildUriQueryOrFragmentArbitrary } from './_internals/builders/UriQueryOrFragmentArbitraryBuilder.js';\nexport function webQueryParameters(constraints = {}) {\n    return buildUriQueryOrFragmentArbitrary(constraints.size);\n}\n","import { buildAlphaNumericPercentArbitrary } from './_internals/builders/CharacterRangeArbitraryBuilder.js';\nimport { stringOf } from './stringOf.js';\nexport function webSegment(constraints = {}) {\n    const others = ['-', '.', '_', '~', '!', '$', '&', \"'\", '(', ')', '*', '+', ',', ';', '=', ':', '@'];\n    return stringOf(buildAlphaNumericPercentArbitrary(others), { size: constraints.size });\n}\n","import { constantFrom } from './constantFrom.js';\nimport { constant } from './constant.js';\nimport { option } from './option.js';\nimport { tuple } from './tuple.js';\nimport { webQueryParameters } from './webQueryParameters.js';\nimport { webFragments } from './webFragments.js';\nimport { webAuthority } from './webAuthority.js';\nimport { partsToUrlMapper, partsToUrlUnmapper } from './_internals/mappers/PartsToUrl.js';\nimport { relativeSizeToSize, resolveSize } from './_internals/helpers/MaxLengthFromMinLength.js';\nimport { webPath } from './webPath.js';\nconst safeObjectAssign = Object.assign;\nexport function webUrl(constraints) {\n    const c = constraints || {};\n    const resolvedSize = resolveSize(c.size);\n    const resolvedAuthoritySettingsSize = c.authoritySettings !== undefined && c.authoritySettings.size !== undefined\n        ? relativeSizeToSize(c.authoritySettings.size, resolvedSize)\n        : resolvedSize;\n    const resolvedAuthoritySettings = safeObjectAssign(safeObjectAssign({}, c.authoritySettings), {\n        size: resolvedAuthoritySettingsSize,\n    });\n    const validSchemes = c.validSchemes || ['http', 'https'];\n    const schemeArb = constantFrom(...validSchemes);\n    const authorityArb = webAuthority(resolvedAuthoritySettings);\n    return tuple(schemeArb, authorityArb, webPath({ size: resolvedSize }), c.withQueryParameters === true ? option(webQueryParameters({ size: resolvedSize })) : constant(null), c.withFragments === true ? option(webFragments({ size: resolvedSize })) : constant(null)).map(partsToUrlMapper, partsToUrlUnmapper);\n}\n","import { Stream } from '../../../stream/Stream.js';\nimport { cloneMethod, hasCloneMethod } from '../../symbols.js';\nimport { Value } from './Value.js';\nconst safeObjectAssign = Object.assign;\nexport class Arbitrary {\n    filter(refinement) {\n        return new FilterArbitrary(this, refinement);\n    }\n    map(mapper, unmapper) {\n        return new MapArbitrary(this, mapper, unmapper);\n    }\n    chain(chainer) {\n        return new ChainArbitrary(this, chainer);\n    }\n    noShrink() {\n        return new NoShrinkArbitrary(this);\n    }\n    noBias() {\n        return new NoBiasArbitrary(this);\n    }\n}\nclass ChainArbitrary extends Arbitrary {\n    constructor(arb, chainer) {\n        super();\n        this.arb = arb;\n        this.chainer = chainer;\n    }\n    generate(mrng, biasFactor) {\n        const clonedMrng = mrng.clone();\n        const src = this.arb.generate(mrng, biasFactor);\n        return this.valueChainer(src, mrng, clonedMrng, biasFactor);\n    }\n    canShrinkWithoutContext(value) {\n        return false;\n    }\n    shrink(value, context) {\n        if (this.isSafeContext(context)) {\n            return (!context.stoppedForOriginal\n                ? this.arb\n                    .shrink(context.originalValue, context.originalContext)\n                    .map((v) => this.valueChainer(v, context.clonedMrng.clone(), context.clonedMrng, context.originalBias))\n                : Stream.nil()).join(context.chainedArbitrary.shrink(value, context.chainedContext).map((dst) => {\n                const newContext = safeObjectAssign(safeObjectAssign({}, context), {\n                    chainedContext: dst.context,\n                    stoppedForOriginal: true,\n                });\n                return new Value(dst.value_, newContext);\n            }));\n        }\n        return Stream.nil();\n    }\n    valueChainer(v, generateMrng, clonedMrng, biasFactor) {\n        const chainedArbitrary = this.chainer(v.value_);\n        const dst = chainedArbitrary.generate(generateMrng, biasFactor);\n        const context = {\n            originalBias: biasFactor,\n            originalValue: v.value_,\n            originalContext: v.context,\n            stoppedForOriginal: false,\n            chainedArbitrary,\n            chainedContext: dst.context,\n            clonedMrng,\n        };\n        return new Value(dst.value_, context);\n    }\n    isSafeContext(context) {\n        return (context != null &&\n            typeof context === 'object' &&\n            'originalBias' in context &&\n            'originalValue' in context &&\n            'originalContext' in context &&\n            'stoppedForOriginal' in context &&\n            'chainedArbitrary' in context &&\n            'chainedContext' in context &&\n            'clonedMrng' in context);\n    }\n}\nclass MapArbitrary extends Arbitrary {\n    constructor(arb, mapper, unmapper) {\n        super();\n        this.arb = arb;\n        this.mapper = mapper;\n        this.unmapper = unmapper;\n        this.bindValueMapper = (v) => this.valueMapper(v);\n    }\n    generate(mrng, biasFactor) {\n        const g = this.arb.generate(mrng, biasFactor);\n        return this.valueMapper(g);\n    }\n    canShrinkWithoutContext(value) {\n        if (this.unmapper !== undefined) {\n            try {\n                const unmapped = this.unmapper(value);\n                return this.arb.canShrinkWithoutContext(unmapped);\n            }\n            catch (_err) {\n                return false;\n            }\n        }\n        return false;\n    }\n    shrink(value, context) {\n        if (this.isSafeContext(context)) {\n            return this.arb.shrink(context.originalValue, context.originalContext).map(this.bindValueMapper);\n        }\n        if (this.unmapper !== undefined) {\n            const unmapped = this.unmapper(value);\n            return this.arb.shrink(unmapped, undefined).map(this.bindValueMapper);\n        }\n        return Stream.nil();\n    }\n    mapperWithCloneIfNeeded(v) {\n        const sourceValue = v.value;\n        const mappedValue = this.mapper(sourceValue);\n        if (v.hasToBeCloned &&\n            ((typeof mappedValue === 'object' && mappedValue !== null) || typeof mappedValue === 'function') &&\n            Object.isExtensible(mappedValue) &&\n            !hasCloneMethod(mappedValue)) {\n            Object.defineProperty(mappedValue, cloneMethod, { get: () => () => this.mapperWithCloneIfNeeded(v)[0] });\n        }\n        return [mappedValue, sourceValue];\n    }\n    valueMapper(v) {\n        const [mappedValue, sourceValue] = this.mapperWithCloneIfNeeded(v);\n        const context = { originalValue: sourceValue, originalContext: v.context };\n        return new Value(mappedValue, context);\n    }\n    isSafeContext(context) {\n        return (context != null &&\n            typeof context === 'object' &&\n            'originalValue' in context &&\n            'originalContext' in context);\n    }\n}\nclass FilterArbitrary extends Arbitrary {\n    constructor(arb, refinement) {\n        super();\n        this.arb = arb;\n        this.refinement = refinement;\n        this.bindRefinementOnValue = (v) => this.refinementOnValue(v);\n    }\n    generate(mrng, biasFactor) {\n        while (true) {\n            const g = this.arb.generate(mrng, biasFactor);\n            if (this.refinementOnValue(g)) {\n                return g;\n            }\n        }\n    }\n    canShrinkWithoutContext(value) {\n        return this.arb.canShrinkWithoutContext(value) && this.refinement(value);\n    }\n    shrink(value, context) {\n        return this.arb.shrink(value, context).filter(this.bindRefinementOnValue);\n    }\n    refinementOnValue(v) {\n        return this.refinement(v.value);\n    }\n}\nclass NoShrinkArbitrary extends Arbitrary {\n    constructor(arb) {\n        super();\n        this.arb = arb;\n    }\n    generate(mrng, biasFactor) {\n        return this.arb.generate(mrng, biasFactor);\n    }\n    canShrinkWithoutContext(value) {\n        return this.arb.canShrinkWithoutContext(value);\n    }\n    shrink(_value, _context) {\n        return Stream.nil();\n    }\n    noShrink() {\n        return this;\n    }\n}\nclass NoBiasArbitrary extends Arbitrary {\n    constructor(arb) {\n        super();\n        this.arb = arb;\n    }\n    generate(mrng, _biasFactor) {\n        return this.arb.generate(mrng, undefined);\n    }\n    canShrinkWithoutContext(value) {\n        return this.arb.canShrinkWithoutContext(value);\n    }\n    shrink(value, context) {\n        return this.arb.shrink(value, context);\n    }\n    noBias() {\n        return this;\n    }\n}\nexport function isArbitrary(instance) {\n    return (typeof instance === 'object' &&\n        instance !== null &&\n        'generate' in instance &&\n        'shrink' in instance &&\n        'canShrinkWithoutContext' in instance);\n}\nexport function assertIsArbitrary(instance) {\n    if (!isArbitrary(instance)) {\n        throw new Error('Unexpected value received: not an instance of Arbitrary');\n    }\n}\n","import { cloneMethod, hasCloneMethod } from '../../symbols.js';\nconst safeObjectDefineProperty = Object.defineProperty;\nexport class Value {\n    constructor(value_, context, customGetValue = undefined) {\n        this.value_ = value_;\n        this.context = context;\n        this.hasToBeCloned = customGetValue !== undefined || hasCloneMethod(value_);\n        this.readOnce = false;\n        if (this.hasToBeCloned) {\n            safeObjectDefineProperty(this, 'value', { get: customGetValue !== undefined ? customGetValue : this.getValue });\n        }\n        else {\n            this.value = value_;\n        }\n    }\n    getValue() {\n        if (this.hasToBeCloned) {\n            if (!this.readOnce) {\n                this.readOnce = true;\n                return this.value_;\n            }\n            return this.value_[cloneMethod]();\n        }\n        return this.value_;\n    }\n}\n","import { scheduleCommands } from './commands/ScheduledCommand.js';\nconst genericModelRun = (s, cmds, initialValue, runCmd, then) => {\n    return s.then((o) => {\n        const { model, real } = o;\n        let state = initialValue;\n        for (const c of cmds) {\n            state = then(state, () => {\n                return runCmd(c, model, real);\n            });\n        }\n        return state;\n    });\n};\nconst internalModelRun = (s, cmds) => {\n    const then = (_p, c) => c();\n    const setupProducer = {\n        then: (fun) => {\n            fun(s());\n            return undefined;\n        },\n    };\n    const runSync = (cmd, m, r) => {\n        if (cmd.check(m))\n            cmd.run(m, r);\n        return undefined;\n    };\n    return genericModelRun(setupProducer, cmds, undefined, runSync, then);\n};\nconst isAsyncSetup = (s) => {\n    return typeof s.then === 'function';\n};\nconst internalAsyncModelRun = async (s, cmds, defaultPromise = Promise.resolve()) => {\n    const then = (p, c) => p.then(c);\n    const setupProducer = {\n        then: (fun) => {\n            const out = s();\n            if (isAsyncSetup(out))\n                return out.then(fun);\n            else\n                return fun(out);\n        },\n    };\n    const runAsync = async (cmd, m, r) => {\n        if (await cmd.check(m))\n            await cmd.run(m, r);\n    };\n    return await genericModelRun(setupProducer, cmds, defaultPromise, runAsync, then);\n};\nexport function modelRun(s, cmds) {\n    internalModelRun(s, cmds);\n}\nexport async function asyncModelRun(s, cmds) {\n    await internalAsyncModelRun(s, cmds);\n}\nexport async function scheduledModelRun(scheduler, s, cmds) {\n    const scheduledCommands = scheduleCommands(scheduler, cmds);\n    const out = internalAsyncModelRun(s, scheduledCommands, scheduler.schedule(Promise.resolve(), 'startModel'));\n    await scheduler.waitFor(out);\n    await scheduler.waitAll();\n}\n","export class ReplayPath {\n    static parse(replayPathStr) {\n        const [serializedCount, serializedChanges] = replayPathStr.split(':');\n        const counts = this.parseCounts(serializedCount);\n        const changes = this.parseChanges(serializedChanges);\n        return this.parseOccurences(counts, changes);\n    }\n    static stringify(replayPath) {\n        const occurences = this.countOccurences(replayPath);\n        const serializedCount = this.stringifyCounts(occurences);\n        const serializedChanges = this.stringifyChanges(occurences);\n        return `${serializedCount}:${serializedChanges}`;\n    }\n    static intToB64(n) {\n        if (n < 26)\n            return String.fromCharCode(n + 65);\n        if (n < 52)\n            return String.fromCharCode(n + 97 - 26);\n        if (n < 62)\n            return String.fromCharCode(n + 48 - 52);\n        return String.fromCharCode(n === 62 ? 43 : 47);\n    }\n    static b64ToInt(c) {\n        if (c >= 'a')\n            return c.charCodeAt(0) - 97 + 26;\n        if (c >= 'A')\n            return c.charCodeAt(0) - 65;\n        if (c >= '0')\n            return c.charCodeAt(0) - 48 + 52;\n        return c === '+' ? 62 : 63;\n    }\n    static countOccurences(replayPath) {\n        return replayPath.reduce((counts, cur) => {\n            if (counts.length === 0 || counts[counts.length - 1].count === 64 || counts[counts.length - 1].value !== cur)\n                counts.push({ value: cur, count: 1 });\n            else\n                counts[counts.length - 1].count += 1;\n            return counts;\n        }, []);\n    }\n    static parseOccurences(counts, changes) {\n        const replayPath = [];\n        for (let idx = 0; idx !== counts.length; ++idx) {\n            const count = counts[idx];\n            const value = changes[idx];\n            for (let num = 0; num !== count; ++num)\n                replayPath.push(value);\n        }\n        return replayPath;\n    }\n    static stringifyChanges(occurences) {\n        let serializedChanges = '';\n        for (let idx = 0; idx < occurences.length; idx += 6) {\n            const changesInt = occurences\n                .slice(idx, idx + 6)\n                .reduceRight((prev, cur) => prev * 2 + (cur.value ? 1 : 0), 0);\n            serializedChanges += this.intToB64(changesInt);\n        }\n        return serializedChanges;\n    }\n    static parseChanges(serializedChanges) {\n        const changesInt = serializedChanges.split('').map((c) => this.b64ToInt(c));\n        const changes = [];\n        for (let idx = 0; idx !== changesInt.length; ++idx) {\n            let current = changesInt[idx];\n            for (let n = 0; n !== 6; ++n, current >>= 1) {\n                changes.push(current % 2 === 1);\n            }\n        }\n        return changes;\n    }\n    static stringifyCounts(occurences) {\n        return occurences.map(({ count }) => this.intToB64(count - 1)).join('');\n    }\n    static parseCounts(serializedCount) {\n        return serializedCount.split('').map((c) => this.b64ToInt(c) + 1);\n    }\n}\n","import { asyncToStringMethod, hasAsyncToStringMethod, hasToStringMethod, toStringMethod, } from '../../../utils/stringify.js';\nimport { cloneMethod, hasCloneMethod } from '../../symbols.js';\nexport class CommandWrapper {\n    constructor(cmd) {\n        this.cmd = cmd;\n        this.hasRan = false;\n        if (hasToStringMethod(cmd)) {\n            const method = cmd[toStringMethod];\n            this[toStringMethod] = function toStringMethod() {\n                return method.call(cmd);\n            };\n        }\n        if (hasAsyncToStringMethod(cmd)) {\n            const method = cmd[asyncToStringMethod];\n            this[asyncToStringMethod] = function asyncToStringMethod() {\n                return method.call(cmd);\n            };\n        }\n    }\n    check(m) {\n        return this.cmd.check(m);\n    }\n    run(m, r) {\n        this.hasRan = true;\n        return this.cmd.run(m, r);\n    }\n    clone() {\n        if (hasCloneMethod(this.cmd))\n            return new CommandWrapper(this.cmd[cloneMethod]());\n        return new CommandWrapper(this.cmd);\n    }\n    toString() {\n        return this.cmd.toString();\n    }\n}\n","import { cloneMethod } from '../../symbols.js';\nexport class CommandsIterable {\n    constructor(commands, metadataForReplay) {\n        this.commands = commands;\n        this.metadataForReplay = metadataForReplay;\n    }\n    [Symbol.iterator]() {\n        return this.commands[Symbol.iterator]();\n    }\n    [cloneMethod]() {\n        return new CommandsIterable(this.commands.map((c) => c.clone()), this.metadataForReplay);\n    }\n    toString() {\n        const serializedCommands = this.commands\n            .filter((c) => c.hasRan)\n            .map((c) => c.toString())\n            .join(',');\n        const metadata = this.metadataForReplay();\n        return metadata.length !== 0 ? `${serializedCommands} /*${metadata}*/` : serializedCommands;\n    }\n}\n","export class ScheduledCommand {\n    constructor(s, cmd) {\n        this.s = s;\n        this.cmd = cmd;\n    }\n    async check(m) {\n        let error = null;\n        let checkPassed = false;\n        const status = await this.s.scheduleSequence([\n            {\n                label: `check@${this.cmd.toString()}`,\n                builder: async () => {\n                    try {\n                        checkPassed = await Promise.resolve(this.cmd.check(m));\n                    }\n                    catch (err) {\n                        error = err;\n                        throw err;\n                    }\n                },\n            },\n        ]).task;\n        if (status.faulty) {\n            throw error;\n        }\n        return checkPassed;\n    }\n    async run(m, r) {\n        let error = null;\n        const status = await this.s.scheduleSequence([\n            {\n                label: `run@${this.cmd.toString()}`,\n                builder: async () => {\n                    try {\n                        await this.cmd.run(m, r);\n                    }\n                    catch (err) {\n                        error = err;\n                        throw err;\n                    }\n                },\n            },\n        ]).task;\n        if (status.faulty) {\n            throw error;\n        }\n    }\n}\nexport const scheduleCommands = function* (s, cmds) {\n    for (const cmd of cmds) {\n        yield new ScheduledCommand(s, cmd);\n    }\n};\n","import { PreconditionFailure } from './PreconditionFailure.js';\nexport function pre(expectTruthy) {\n    if (!expectTruthy) {\n        throw new PreconditionFailure();\n    }\n}\n","export class PreconditionFailure extends Error {\n    constructor(interruptExecution = false) {\n        super();\n        this.interruptExecution = interruptExecution;\n        this.footprint = PreconditionFailure.SharedFootPrint;\n    }\n    static isFailure(err) {\n        return err != null && err.footprint === PreconditionFailure.SharedFootPrint;\n    }\n}\nPreconditionFailure.SharedFootPrint = Symbol.for('fast-check/PreconditionFailure');\n","import { PreconditionFailure } from '../precondition/PreconditionFailure.js';\nimport { runIdToFrequency } from './IRawProperty.js';\nimport { readConfigureGlobal } from '../runner/configuration/GlobalParameters.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { noUndefinedAsContext, UndefinedContextPlaceholder, } from '../../arbitrary/_internals/helpers/NoUndefinedAsContext.js';\nimport { Error, String } from '../../utils/globals.js';\nexport class AsyncProperty {\n    constructor(arb, predicate) {\n        this.arb = arb;\n        this.predicate = predicate;\n        const { asyncBeforeEach, asyncAfterEach, beforeEach, afterEach } = readConfigureGlobal() || {};\n        if (asyncBeforeEach !== undefined && beforeEach !== undefined) {\n            throw Error('Global \"asyncBeforeEach\" and \"beforeEach\" parameters can\\'t be set at the same time when running async properties');\n        }\n        if (asyncAfterEach !== undefined && afterEach !== undefined) {\n            throw Error('Global \"asyncAfterEach\" and \"afterEach\" parameters can\\'t be set at the same time when running async properties');\n        }\n        this.beforeEachHook = asyncBeforeEach || beforeEach || AsyncProperty.dummyHook;\n        this.afterEachHook = asyncAfterEach || afterEach || AsyncProperty.dummyHook;\n    }\n    isAsync() {\n        return true;\n    }\n    generate(mrng, runId) {\n        const value = this.arb.generate(mrng, runId != null ? runIdToFrequency(runId) : undefined);\n        return noUndefinedAsContext(value);\n    }\n    shrink(value) {\n        if (value.context === undefined && !this.arb.canShrinkWithoutContext(value.value_)) {\n            return Stream.nil();\n        }\n        const safeContext = value.context !== UndefinedContextPlaceholder ? value.context : undefined;\n        return this.arb.shrink(value.value_, safeContext).map(noUndefinedAsContext);\n    }\n    async runBeforeEach() {\n        await this.beforeEachHook();\n    }\n    async runAfterEach() {\n        await this.afterEachHook();\n    }\n    async run(v, dontRunHook) {\n        if (!dontRunHook) {\n            await this.beforeEachHook();\n        }\n        try {\n            const output = await this.predicate(v);\n            return output == null || output === true\n                ? null\n                : {\n                    error: new Error('Property failed by returning false'),\n                    errorMessage: 'Error: Property failed by returning false',\n                };\n        }\n        catch (err) {\n            if (PreconditionFailure.isFailure(err))\n                return err;\n            if (err instanceof Error && err.stack) {\n                return { error: err, errorMessage: err.stack };\n            }\n            return { error: err, errorMessage: String(err) };\n        }\n        finally {\n            if (!dontRunHook) {\n                await this.afterEachHook();\n            }\n        }\n    }\n    beforeEach(hookFunction) {\n        const previousBeforeEachHook = this.beforeEachHook;\n        this.beforeEachHook = () => hookFunction(previousBeforeEachHook);\n        return this;\n    }\n    afterEach(hookFunction) {\n        const previousAfterEachHook = this.afterEachHook;\n        this.afterEachHook = () => hookFunction(previousAfterEachHook);\n        return this;\n    }\n}\nAsyncProperty.dummyHook = () => { };\n","import { assertIsArbitrary } from '../arbitrary/definition/Arbitrary.js';\nimport { tuple } from '../../arbitrary/tuple.js';\nimport { AsyncProperty } from './AsyncProperty.generic.js';\nimport { AlwaysShrinkableArbitrary } from '../../arbitrary/_internals/AlwaysShrinkableArbitrary.js';\nimport { safeForEach, safeMap, safeSlice } from '../../utils/globals.js';\nfunction asyncProperty(...args) {\n    if (args.length < 2) {\n        throw new Error('asyncProperty expects at least two parameters');\n    }\n    const arbs = safeSlice(args, 0, args.length - 1);\n    const p = args[args.length - 1];\n    safeForEach(arbs, assertIsArbitrary);\n    const mappedArbs = safeMap(arbs, (arb) => new AlwaysShrinkableArbitrary(arb));\n    return new AsyncProperty(tuple(...mappedArbs), (t) => p(...t));\n}\nexport { asyncProperty };\n","const safeMathLog = Math.log;\nexport function runIdToFrequency(runId) {\n    return 2 + ~~(safeMathLog(runId + 1) * 0.4342944819032518);\n}\n","import { stringify } from '../../utils/stringify.js';\nimport { PreconditionFailure } from '../precondition/PreconditionFailure.js';\nfunction fromSyncCached(cachedValue) {\n    return cachedValue === null ? new PreconditionFailure() : cachedValue;\n}\nfunction fromCached(...data) {\n    if (data[1])\n        return data[0].then(fromSyncCached);\n    return fromSyncCached(data[0]);\n}\nfunction fromCachedUnsafe(cachedValue, isAsync) {\n    return fromCached(cachedValue, isAsync);\n}\nexport class IgnoreEqualValuesProperty {\n    constructor(property, skipRuns) {\n        this.property = property;\n        this.skipRuns = skipRuns;\n        this.coveredCases = new Map();\n        if (this.property.runBeforeEach !== undefined && this.property.runAfterEach !== undefined) {\n            this.runBeforeEach = () => this.property.runBeforeEach();\n            this.runAfterEach = () => this.property.runAfterEach();\n        }\n    }\n    isAsync() {\n        return this.property.isAsync();\n    }\n    generate(mrng, runId) {\n        return this.property.generate(mrng, runId);\n    }\n    shrink(value) {\n        return this.property.shrink(value);\n    }\n    run(v, dontRunHook) {\n        const stringifiedValue = stringify(v);\n        if (this.coveredCases.has(stringifiedValue)) {\n            const lastOutput = this.coveredCases.get(stringifiedValue);\n            if (!this.skipRuns) {\n                return lastOutput;\n            }\n            return fromCachedUnsafe(lastOutput, this.property.isAsync());\n        }\n        const out = this.property.run(v, dontRunHook);\n        this.coveredCases.set(stringifiedValue, out);\n        return out;\n    }\n}\n","import { PreconditionFailure } from '../precondition/PreconditionFailure.js';\nimport { runIdToFrequency } from './IRawProperty.js';\nimport { readConfigureGlobal } from '../runner/configuration/GlobalParameters.js';\nimport { Stream } from '../../stream/Stream.js';\nimport { noUndefinedAsContext, UndefinedContextPlaceholder, } from '../../arbitrary/_internals/helpers/NoUndefinedAsContext.js';\nimport { Error, String } from '../../utils/globals.js';\nexport class Property {\n    constructor(arb, predicate) {\n        this.arb = arb;\n        this.predicate = predicate;\n        const { beforeEach = Property.dummyHook, afterEach = Property.dummyHook, asyncBeforeEach, asyncAfterEach, } = readConfigureGlobal() || {};\n        if (asyncBeforeEach !== undefined) {\n            throw Error('\"asyncBeforeEach\" can\\'t be set when running synchronous properties');\n        }\n        if (asyncAfterEach !== undefined) {\n            throw Error('\"asyncAfterEach\" can\\'t be set when running synchronous properties');\n        }\n        this.beforeEachHook = beforeEach;\n        this.afterEachHook = afterEach;\n    }\n    isAsync() {\n        return false;\n    }\n    generate(mrng, runId) {\n        const value = this.arb.generate(mrng, runId != null ? runIdToFrequency(runId) : undefined);\n        return noUndefinedAsContext(value);\n    }\n    shrink(value) {\n        if (value.context === undefined && !this.arb.canShrinkWithoutContext(value.value_)) {\n            return Stream.nil();\n        }\n        const safeContext = value.context !== UndefinedContextPlaceholder ? value.context : undefined;\n        return this.arb.shrink(value.value_, safeContext).map(noUndefinedAsContext);\n    }\n    runBeforeEach() {\n        this.beforeEachHook();\n    }\n    runAfterEach() {\n        this.afterEachHook();\n    }\n    run(v, dontRunHook) {\n        if (!dontRunHook) {\n            this.beforeEachHook();\n        }\n        try {\n            const output = this.predicate(v);\n            return output == null || output === true\n                ? null\n                : {\n                    error: new Error('Property failed by returning false'),\n                    errorMessage: 'Error: Property failed by returning false',\n                };\n        }\n        catch (err) {\n            if (PreconditionFailure.isFailure(err))\n                return err;\n            if (err instanceof Error && err.stack) {\n                return { error: err, errorMessage: err.stack };\n            }\n            return { error: err, errorMessage: String(err) };\n        }\n        finally {\n            if (!dontRunHook) {\n                this.afterEachHook();\n            }\n        }\n    }\n    beforeEach(hookFunction) {\n        const previousBeforeEachHook = this.beforeEachHook;\n        this.beforeEachHook = () => hookFunction(previousBeforeEachHook);\n        return this;\n    }\n    afterEach(hookFunction) {\n        const previousAfterEachHook = this.afterEachHook;\n        this.afterEachHook = () => hookFunction(previousAfterEachHook);\n        return this;\n    }\n}\nProperty.dummyHook = () => { };\n","import { assertIsArbitrary } from '../arbitrary/definition/Arbitrary.js';\nimport { tuple } from '../../arbitrary/tuple.js';\nimport { Property } from './Property.generic.js';\nimport { AlwaysShrinkableArbitrary } from '../../arbitrary/_internals/AlwaysShrinkableArbitrary.js';\nimport { safeForEach, safeMap, safeSlice } from '../../utils/globals.js';\nfunction property(...args) {\n    if (args.length < 2) {\n        throw new Error('property expects at least two parameters');\n    }\n    const arbs = safeSlice(args, 0, args.length - 1);\n    const p = args[args.length - 1];\n    safeForEach(arbs, assertIsArbitrary);\n    const mappedArbs = safeMap(arbs, (arb) => new AlwaysShrinkableArbitrary(arb));\n    return new Property(tuple(...mappedArbs), (t) => p(...t));\n}\nexport { property };\n","import { PreconditionFailure } from '../precondition/PreconditionFailure.js';\nfunction interruptAfter(timeMs, setTimeoutSafe, clearTimeoutSafe) {\n    let timeoutHandle = null;\n    const promise = new Promise((resolve) => {\n        timeoutHandle = setTimeoutSafe(() => {\n            const preconditionFailure = new PreconditionFailure(true);\n            resolve(preconditionFailure);\n        }, timeMs);\n    });\n    return {\n        clear: () => clearTimeoutSafe(timeoutHandle),\n        promise,\n    };\n}\nexport class SkipAfterProperty {\n    constructor(property, getTime, timeLimit, interruptExecution, setTimeoutSafe, clearTimeoutSafe) {\n        this.property = property;\n        this.getTime = getTime;\n        this.interruptExecution = interruptExecution;\n        this.setTimeoutSafe = setTimeoutSafe;\n        this.clearTimeoutSafe = clearTimeoutSafe;\n        this.skipAfterTime = this.getTime() + timeLimit;\n        if (this.property.runBeforeEach !== undefined && this.property.runAfterEach !== undefined) {\n            this.runBeforeEach = () => this.property.runBeforeEach();\n            this.runAfterEach = () => this.property.runAfterEach();\n        }\n    }\n    isAsync() {\n        return this.property.isAsync();\n    }\n    generate(mrng, runId) {\n        return this.property.generate(mrng, runId);\n    }\n    shrink(value) {\n        return this.property.shrink(value);\n    }\n    run(v, dontRunHook) {\n        const remainingTime = this.skipAfterTime - this.getTime();\n        if (remainingTime <= 0) {\n            const preconditionFailure = new PreconditionFailure(this.interruptExecution);\n            if (this.isAsync()) {\n                return Promise.resolve(preconditionFailure);\n            }\n            else {\n                return preconditionFailure;\n            }\n        }\n        if (this.interruptExecution && this.isAsync()) {\n            const t = interruptAfter(remainingTime, this.setTimeoutSafe, this.clearTimeoutSafe);\n            const propRun = Promise.race([this.property.run(v, dontRunHook), t.promise]);\n            propRun.then(t.clear, t.clear);\n            return propRun;\n        }\n        return this.property.run(v, dontRunHook);\n    }\n}\n","import { Error } from '../../utils/globals.js';\nconst timeoutAfter = (timeMs, setTimeoutSafe, clearTimeoutSafe) => {\n    let timeoutHandle = null;\n    const promise = new Promise((resolve) => {\n        timeoutHandle = setTimeoutSafe(() => {\n            resolve({\n                error: new Error(`Property timeout: exceeded limit of ${timeMs} milliseconds`),\n                errorMessage: `Property timeout: exceeded limit of ${timeMs} milliseconds`,\n            });\n        }, timeMs);\n    });\n    return {\n        clear: () => clearTimeoutSafe(timeoutHandle),\n        promise,\n    };\n};\nexport class TimeoutProperty {\n    constructor(property, timeMs, setTimeoutSafe, clearTimeoutSafe) {\n        this.property = property;\n        this.timeMs = timeMs;\n        this.setTimeoutSafe = setTimeoutSafe;\n        this.clearTimeoutSafe = clearTimeoutSafe;\n        if (this.property.runBeforeEach !== undefined && this.property.runAfterEach !== undefined) {\n            this.runBeforeEach = () => Promise.resolve(this.property.runBeforeEach());\n            this.runAfterEach = () => Promise.resolve(this.property.runAfterEach());\n        }\n    }\n    isAsync() {\n        return true;\n    }\n    generate(mrng, runId) {\n        return this.property.generate(mrng, runId);\n    }\n    shrink(value) {\n        return this.property.shrink(value);\n    }\n    async run(v, dontRunHook) {\n        const t = timeoutAfter(this.timeMs, this.setTimeoutSafe, this.clearTimeoutSafe);\n        const propRun = Promise.race([this.property.run(v, dontRunHook), t.promise]);\n        propRun.then(t.clear, t.clear);\n        return propRun;\n    }\n}\n","export class UnbiasedProperty {\n    constructor(property) {\n        this.property = property;\n        if (this.property.runBeforeEach !== undefined && this.property.runAfterEach !== undefined) {\n            this.runBeforeEach = () => this.property.runBeforeEach();\n            this.runAfterEach = () => this.property.runAfterEach();\n        }\n    }\n    isAsync() {\n        return this.property.isAsync();\n    }\n    generate(mrng, _runId) {\n        return this.property.generate(mrng, undefined);\n    }\n    shrink(value) {\n        return this.property.shrink(value);\n    }\n    run(v, dontRunHook) {\n        return this.property.run(v, dontRunHook);\n    }\n}\n","import { SkipAfterProperty } from '../property/SkipAfterProperty.js';\nimport { TimeoutProperty } from '../property/TimeoutProperty.js';\nimport { UnbiasedProperty } from '../property/UnbiasedProperty.js';\nimport { IgnoreEqualValuesProperty } from '../property/IgnoreEqualValuesProperty.js';\nconst safeDateNow = Date.now;\nconst safeSetTimeout = setTimeout;\nconst safeClearTimeout = clearTimeout;\nexport function decorateProperty(rawProperty, qParams) {\n    let prop = rawProperty;\n    if (rawProperty.isAsync() && qParams.timeout != null) {\n        prop = new TimeoutProperty(prop, qParams.timeout, safeSetTimeout, safeClearTimeout);\n    }\n    if (qParams.unbiased) {\n        prop = new UnbiasedProperty(prop);\n    }\n    if (qParams.skipAllAfterTimeLimit != null) {\n        prop = new SkipAfterProperty(prop, safeDateNow, qParams.skipAllAfterTimeLimit, false, safeSetTimeout, safeClearTimeout);\n    }\n    if (qParams.interruptAfterTimeLimit != null) {\n        prop = new SkipAfterProperty(prop, safeDateNow, qParams.interruptAfterTimeLimit, true, safeSetTimeout, safeClearTimeout);\n    }\n    if (qParams.skipEqualValues) {\n        prop = new IgnoreEqualValuesProperty(prop, true);\n    }\n    if (qParams.ignoreEqualValues) {\n        prop = new IgnoreEqualValuesProperty(prop, false);\n    }\n    return prop;\n}\n","import { Stream, stream } from '../../stream/Stream.js';\nimport { readConfigureGlobal } from './configuration/GlobalParameters.js';\nimport { QualifiedParameters } from './configuration/QualifiedParameters.js';\nimport { decorateProperty } from './DecorateProperty.js';\nimport { RunnerIterator } from './RunnerIterator.js';\nimport { SourceValuesIterator } from './SourceValuesIterator.js';\nimport { lazyToss, toss } from './Tosser.js';\nimport { pathWalk } from './utils/PathWalker.js';\nimport { asyncReportRunDetails, reportRunDetails } from './utils/RunDetailsFormatter.js';\nconst safeObjectAssign = Object.assign;\nfunction runIt(property, shrink, sourceValues, verbose, interruptedAsFailure) {\n    const isModernProperty = property.runBeforeEach !== undefined && property.runAfterEach !== undefined;\n    const runner = new RunnerIterator(sourceValues, shrink, verbose, interruptedAsFailure);\n    for (const v of runner) {\n        if (isModernProperty) {\n            property.runBeforeEach();\n        }\n        const out = property.run(v, isModernProperty);\n        if (isModernProperty) {\n            property.runAfterEach();\n        }\n        runner.handleResult(out);\n    }\n    return runner.runExecution;\n}\nasync function asyncRunIt(property, shrink, sourceValues, verbose, interruptedAsFailure) {\n    const isModernProperty = property.runBeforeEach !== undefined && property.runAfterEach !== undefined;\n    const runner = new RunnerIterator(sourceValues, shrink, verbose, interruptedAsFailure);\n    for (const v of runner) {\n        if (isModernProperty) {\n            await property.runBeforeEach();\n        }\n        const out = await property.run(v, isModernProperty);\n        if (isModernProperty) {\n            await property.runAfterEach();\n        }\n        runner.handleResult(out);\n    }\n    return runner.runExecution;\n}\nfunction check(rawProperty, params) {\n    if (rawProperty == null || rawProperty.generate == null)\n        throw new Error('Invalid property encountered, please use a valid property');\n    if (rawProperty.run == null)\n        throw new Error('Invalid property encountered, please use a valid property not an arbitrary');\n    const qParams = QualifiedParameters.read(safeObjectAssign(safeObjectAssign({}, readConfigureGlobal()), params));\n    if (qParams.reporter !== null && qParams.asyncReporter !== null)\n        throw new Error('Invalid parameters encountered, reporter and asyncReporter cannot be specified together');\n    if (qParams.asyncReporter !== null && !rawProperty.isAsync())\n        throw new Error('Invalid parameters encountered, only asyncProperty can be used when asyncReporter specified');\n    const property = decorateProperty(rawProperty, qParams);\n    const maxInitialIterations = qParams.path.length === 0 || qParams.path.indexOf(':') === -1 ? qParams.numRuns : -1;\n    const maxSkips = qParams.numRuns * qParams.maxSkipsPerRun;\n    const shrink = (...args) => property.shrink(...args);\n    const initialValues = qParams.path.length === 0\n        ? toss(property, qParams.seed, qParams.randomType, qParams.examples)\n        : pathWalk(qParams.path, stream(lazyToss(property, qParams.seed, qParams.randomType, qParams.examples)), shrink);\n    const sourceValues = new SourceValuesIterator(initialValues, maxInitialIterations, maxSkips);\n    const finalShrink = !qParams.endOnFailure ? shrink : Stream.nil;\n    return property.isAsync()\n        ? asyncRunIt(property, finalShrink, sourceValues, qParams.verbose, qParams.markInterruptAsFailure).then((e) => e.toRunDetails(qParams.seed, qParams.path, maxSkips, qParams))\n        : runIt(property, finalShrink, sourceValues, qParams.verbose, qParams.markInterruptAsFailure).toRunDetails(qParams.seed, qParams.path, maxSkips, qParams);\n}\nfunction assert(property, params) {\n    const out = check(property, params);\n    if (property.isAsync())\n        return out.then(asyncReportRunDetails);\n    else\n        reportRunDetails(out);\n}\nexport { check, assert };\n","import { PreconditionFailure } from '../precondition/PreconditionFailure.js';\nimport { RunExecution } from './reporter/RunExecution.js';\nexport class RunnerIterator {\n    constructor(sourceValues, shrink, verbose, interruptedAsFailure) {\n        this.sourceValues = sourceValues;\n        this.shrink = shrink;\n        this.runExecution = new RunExecution(verbose, interruptedAsFailure);\n        this.currentIdx = -1;\n        this.nextValues = sourceValues;\n    }\n    [Symbol.iterator]() {\n        return this;\n    }\n    next() {\n        const nextValue = this.nextValues.next();\n        if (nextValue.done || this.runExecution.interrupted) {\n            return { done: true, value: undefined };\n        }\n        this.currentValue = nextValue.value;\n        ++this.currentIdx;\n        return { done: false, value: nextValue.value.value_ };\n    }\n    handleResult(result) {\n        if (result != null && typeof result === 'object' && !PreconditionFailure.isFailure(result)) {\n            this.runExecution.fail(this.currentValue.value_, this.currentIdx, result);\n            this.currentIdx = -1;\n            this.nextValues = this.shrink(this.currentValue);\n        }\n        else if (result != null) {\n            if (!result.interruptExecution) {\n                this.runExecution.skip(this.currentValue.value_);\n                this.sourceValues.skippedOne();\n            }\n            else {\n                this.runExecution.interrupt();\n            }\n        }\n        else {\n            this.runExecution.success(this.currentValue.value_);\n        }\n    }\n}\n","import { stream } from '../../stream/Stream.js';\nimport { Property } from '../property/Property.generic.js';\nimport { UnbiasedProperty } from '../property/UnbiasedProperty.js';\nimport { readConfigureGlobal } from './configuration/GlobalParameters.js';\nimport { QualifiedParameters } from './configuration/QualifiedParameters.js';\nimport { lazyToss, toss } from './Tosser.js';\nimport { pathWalk } from './utils/PathWalker.js';\nfunction toProperty(generator, qParams) {\n    const prop = !Object.prototype.hasOwnProperty.call(generator, 'isAsync')\n        ? new Property(generator, () => true)\n        : generator;\n    return qParams.unbiased === true ? new UnbiasedProperty(prop) : prop;\n}\nfunction streamSample(generator, params) {\n    const extendedParams = typeof params === 'number'\n        ? Object.assign(Object.assign({}, readConfigureGlobal()), { numRuns: params }) : Object.assign(Object.assign({}, readConfigureGlobal()), params);\n    const qParams = QualifiedParameters.read(extendedParams);\n    const nextProperty = toProperty(generator, qParams);\n    const shrink = nextProperty.shrink.bind(nextProperty);\n    const tossedValues = qParams.path.length === 0\n        ? stream(toss(nextProperty, qParams.seed, qParams.randomType, qParams.examples))\n        : pathWalk(qParams.path, stream(lazyToss(nextProperty, qParams.seed, qParams.randomType, qParams.examples)), shrink);\n    return tossedValues.take(qParams.numRuns).map((s) => s.value_);\n}\nfunction sample(generator, params) {\n    return [...streamSample(generator, params)];\n}\nfunction round2(n) {\n    return (Math.round(n * 100) / 100).toFixed(2);\n}\nfunction statistics(generator, classify, params) {\n    const extendedParams = typeof params === 'number'\n        ? Object.assign(Object.assign({}, readConfigureGlobal()), { numRuns: params }) : Object.assign(Object.assign({}, readConfigureGlobal()), params);\n    const qParams = QualifiedParameters.read(extendedParams);\n    const recorded = {};\n    for (const g of streamSample(generator, params)) {\n        const out = classify(g);\n        const categories = Array.isArray(out) ? out : [out];\n        for (const c of categories) {\n            recorded[c] = (recorded[c] || 0) + 1;\n        }\n    }\n    const data = Object.entries(recorded)\n        .sort((a, b) => b[1] - a[1])\n        .map((i) => [i[0], `${round2((i[1] * 100.0) / qParams.numRuns)}%`]);\n    const longestName = data.map((i) => i[0].length).reduce((p, c) => Math.max(p, c), 0);\n    const longestPercent = data.map((i) => i[1].length).reduce((p, c) => Math.max(p, c), 0);\n    for (const item of data) {\n        qParams.logger(`${item[0].padEnd(longestName, '.')}..${item[1].padStart(longestPercent, '.')}`);\n    }\n}\nexport { sample, statistics };\n","export class SourceValuesIterator {\n    constructor(initialValues, maxInitialIterations, remainingSkips) {\n        this.initialValues = initialValues;\n        this.maxInitialIterations = maxInitialIterations;\n        this.remainingSkips = remainingSkips;\n    }\n    [Symbol.iterator]() {\n        return this;\n    }\n    next() {\n        if (--this.maxInitialIterations !== -1 && this.remainingSkips >= 0) {\n            const n = this.initialValues.next();\n            if (!n.done)\n                return { value: n.value, done: false };\n        }\n        return { value: undefined, done: true };\n    }\n    skippedOne() {\n        --this.remainingSkips;\n        ++this.maxInitialIterations;\n    }\n}\n","import { skipN } from 'pure-rand';\nimport { Random } from '../../random/generator/Random.js';\nimport { Value } from '../arbitrary/definition/Value.js';\nimport { safeMap } from '../../utils/globals.js';\nfunction tossNext(generator, rng, index) {\n    rng.unsafeJump();\n    return generator.generate(new Random(rng), index);\n}\nexport function* toss(generator, seed, random, examples) {\n    for (let idx = 0; idx !== examples.length; ++idx) {\n        yield new Value(examples[idx], undefined);\n    }\n    for (let idx = 0, rng = random(seed);; ++idx) {\n        yield tossNext(generator, rng, idx);\n    }\n}\nfunction lazyGenerate(generator, rng, idx) {\n    return () => generator.generate(new Random(rng), idx);\n}\nexport function* lazyToss(generator, seed, random, examples) {\n    yield* safeMap(examples, (e) => () => new Value(e, undefined));\n    let idx = 0;\n    let rng = random(seed);\n    for (;;) {\n        rng = rng.jump ? rng.jump() : skipN(rng, 42);\n        yield lazyGenerate(generator, rng, idx++);\n    }\n}\n","let globalParameters = {};\nexport function configureGlobal(parameters) {\n    globalParameters = parameters;\n}\nexport function readConfigureGlobal() {\n    return globalParameters;\n}\nexport function resetConfigureGlobal() {\n    globalParameters = {};\n}\n","import prand, { unsafeSkipN } from 'pure-rand';\nimport { VerbosityLevel } from './VerbosityLevel.js';\nconst safeDateNow = Date.now;\nconst safeMathMin = Math.min;\nconst safeMathRandom = Math.random;\nexport class QualifiedParameters {\n    constructor(op) {\n        const p = op || {};\n        this.seed = QualifiedParameters.readSeed(p);\n        this.randomType = QualifiedParameters.readRandomType(p);\n        this.numRuns = QualifiedParameters.readNumRuns(p);\n        this.verbose = QualifiedParameters.readVerbose(p);\n        this.maxSkipsPerRun = QualifiedParameters.readOrDefault(p, 'maxSkipsPerRun', 100);\n        this.timeout = QualifiedParameters.safeTimeout(QualifiedParameters.readOrDefault(p, 'timeout', null));\n        this.skipAllAfterTimeLimit = QualifiedParameters.safeTimeout(QualifiedParameters.readOrDefault(p, 'skipAllAfterTimeLimit', null));\n        this.interruptAfterTimeLimit = QualifiedParameters.safeTimeout(QualifiedParameters.readOrDefault(p, 'interruptAfterTimeLimit', null));\n        this.markInterruptAsFailure = QualifiedParameters.readBoolean(p, 'markInterruptAsFailure');\n        this.skipEqualValues = QualifiedParameters.readBoolean(p, 'skipEqualValues');\n        this.ignoreEqualValues = QualifiedParameters.readBoolean(p, 'ignoreEqualValues');\n        this.logger = QualifiedParameters.readOrDefault(p, 'logger', (v) => {\n            console.log(v);\n        });\n        this.path = QualifiedParameters.readOrDefault(p, 'path', '');\n        this.unbiased = QualifiedParameters.readBoolean(p, 'unbiased');\n        this.examples = QualifiedParameters.readOrDefault(p, 'examples', []);\n        this.endOnFailure = QualifiedParameters.readBoolean(p, 'endOnFailure');\n        this.reporter = QualifiedParameters.readOrDefault(p, 'reporter', null);\n        this.asyncReporter = QualifiedParameters.readOrDefault(p, 'asyncReporter', null);\n        this.errorWithCause = QualifiedParameters.readBoolean(p, 'errorWithCause');\n    }\n    toParameters() {\n        const orUndefined = (value) => (value !== null ? value : undefined);\n        const parameters = {\n            seed: this.seed,\n            randomType: this.randomType,\n            numRuns: this.numRuns,\n            maxSkipsPerRun: this.maxSkipsPerRun,\n            timeout: orUndefined(this.timeout),\n            skipAllAfterTimeLimit: orUndefined(this.skipAllAfterTimeLimit),\n            interruptAfterTimeLimit: orUndefined(this.interruptAfterTimeLimit),\n            markInterruptAsFailure: this.markInterruptAsFailure,\n            skipEqualValues: this.skipEqualValues,\n            ignoreEqualValues: this.ignoreEqualValues,\n            path: this.path,\n            logger: this.logger,\n            unbiased: this.unbiased,\n            verbose: this.verbose,\n            examples: this.examples,\n            endOnFailure: this.endOnFailure,\n            reporter: orUndefined(this.reporter),\n            asyncReporter: orUndefined(this.asyncReporter),\n            errorWithCause: this.errorWithCause,\n        };\n        return parameters;\n    }\n    static read(op) {\n        return new QualifiedParameters(op);\n    }\n}\nQualifiedParameters.createQualifiedRandomGenerator = (random) => {\n    return (seed) => {\n        const rng = random(seed);\n        if (rng.unsafeJump === undefined) {\n            rng.unsafeJump = () => unsafeSkipN(rng, 42);\n        }\n        return rng;\n    };\n};\nQualifiedParameters.readSeed = (p) => {\n    if (p.seed == null)\n        return safeDateNow() ^ (safeMathRandom() * 0x100000000);\n    const seed32 = p.seed | 0;\n    if (p.seed === seed32)\n        return seed32;\n    const gap = p.seed - seed32;\n    return seed32 ^ (gap * 0x100000000);\n};\nQualifiedParameters.readRandomType = (p) => {\n    if (p.randomType == null)\n        return prand.xorshift128plus;\n    if (typeof p.randomType === 'string') {\n        switch (p.randomType) {\n            case 'mersenne':\n                return QualifiedParameters.createQualifiedRandomGenerator(prand.mersenne);\n            case 'congruential':\n            case 'congruential32':\n                return QualifiedParameters.createQualifiedRandomGenerator(prand.congruential32);\n            case 'xorshift128plus':\n                return prand.xorshift128plus;\n            case 'xoroshiro128plus':\n                return prand.xoroshiro128plus;\n            default:\n                throw new Error(`Invalid random specified: '${p.randomType}'`);\n        }\n    }\n    const mrng = p.randomType(0);\n    if ('min' in mrng && mrng.min !== -0x80000000) {\n        throw new Error(`Invalid random number generator: min must equal -0x80000000, got ${String(mrng.min)}`);\n    }\n    if ('max' in mrng && mrng.max !== 0x7fffffff) {\n        throw new Error(`Invalid random number generator: max must equal 0x7fffffff, got ${String(mrng.max)}`);\n    }\n    if ('unsafeJump' in mrng) {\n        return p.randomType;\n    }\n    return QualifiedParameters.createQualifiedRandomGenerator(p.randomType);\n};\nQualifiedParameters.readNumRuns = (p) => {\n    const defaultValue = 100;\n    if (p.numRuns != null)\n        return p.numRuns;\n    if (p.num_runs != null)\n        return p.num_runs;\n    return defaultValue;\n};\nQualifiedParameters.readVerbose = (p) => {\n    if (p.verbose == null)\n        return VerbosityLevel.None;\n    if (typeof p.verbose === 'boolean') {\n        return p.verbose === true ? VerbosityLevel.Verbose : VerbosityLevel.None;\n    }\n    if (p.verbose <= VerbosityLevel.None) {\n        return VerbosityLevel.None;\n    }\n    if (p.verbose >= VerbosityLevel.VeryVerbose) {\n        return VerbosityLevel.VeryVerbose;\n    }\n    return p.verbose | 0;\n};\nQualifiedParameters.readBoolean = (p, key) => p[key] === true;\nQualifiedParameters.readOrDefault = (p, key, defaultValue) => {\n    const value = p[key];\n    return value != null ? value : defaultValue;\n};\nQualifiedParameters.safeTimeout = (value) => {\n    if (value === null) {\n        return null;\n    }\n    return safeMathMin(value, 0x7fffffff);\n};\n","export var VerbosityLevel;\n(function (VerbosityLevel) {\n    VerbosityLevel[VerbosityLevel[\"None\"] = 0] = \"None\";\n    VerbosityLevel[VerbosityLevel[\"Verbose\"] = 1] = \"Verbose\";\n    VerbosityLevel[VerbosityLevel[\"VeryVerbose\"] = 2] = \"VeryVerbose\";\n})(VerbosityLevel || (VerbosityLevel = {}));\n","export var ExecutionStatus;\n(function (ExecutionStatus) {\n    ExecutionStatus[ExecutionStatus[\"Success\"] = 0] = \"Success\";\n    ExecutionStatus[ExecutionStatus[\"Skipped\"] = -1] = \"Skipped\";\n    ExecutionStatus[ExecutionStatus[\"Failure\"] = 1] = \"Failure\";\n})(ExecutionStatus || (ExecutionStatus = {}));\n","import { VerbosityLevel } from '../configuration/VerbosityLevel.js';\nimport { ExecutionStatus } from './ExecutionStatus.js';\nimport { safeSplit } from '../../../utils/globals.js';\nexport class RunExecution {\n    constructor(verbosity, interruptedAsFailure) {\n        this.verbosity = verbosity;\n        this.interruptedAsFailure = interruptedAsFailure;\n        this.isSuccess = () => this.pathToFailure == null;\n        this.firstFailure = () => (this.pathToFailure ? +safeSplit(this.pathToFailure, ':')[0] : -1);\n        this.numShrinks = () => (this.pathToFailure ? safeSplit(this.pathToFailure, ':').length - 1 : 0);\n        this.rootExecutionTrees = [];\n        this.currentLevelExecutionTrees = this.rootExecutionTrees;\n        this.failure = null;\n        this.numSkips = 0;\n        this.numSuccesses = 0;\n        this.interrupted = false;\n    }\n    appendExecutionTree(status, value) {\n        const currentTree = { status, value, children: [] };\n        this.currentLevelExecutionTrees.push(currentTree);\n        return currentTree;\n    }\n    fail(value, id, failure) {\n        if (this.verbosity >= VerbosityLevel.Verbose) {\n            const currentTree = this.appendExecutionTree(ExecutionStatus.Failure, value);\n            this.currentLevelExecutionTrees = currentTree.children;\n        }\n        if (this.pathToFailure == null)\n            this.pathToFailure = `${id}`;\n        else\n            this.pathToFailure += `:${id}`;\n        this.value = value;\n        this.failure = failure;\n    }\n    skip(value) {\n        if (this.verbosity >= VerbosityLevel.VeryVerbose) {\n            this.appendExecutionTree(ExecutionStatus.Skipped, value);\n        }\n        if (this.pathToFailure == null) {\n            ++this.numSkips;\n        }\n    }\n    success(value) {\n        if (this.verbosity >= VerbosityLevel.VeryVerbose) {\n            this.appendExecutionTree(ExecutionStatus.Success, value);\n        }\n        if (this.pathToFailure == null) {\n            ++this.numSuccesses;\n        }\n    }\n    interrupt() {\n        this.interrupted = true;\n    }\n    extractFailures() {\n        if (this.isSuccess()) {\n            return [];\n        }\n        const failures = [];\n        let cursor = this.rootExecutionTrees;\n        while (cursor.length > 0 && cursor[cursor.length - 1].status === ExecutionStatus.Failure) {\n            const failureTree = cursor[cursor.length - 1];\n            failures.push(failureTree.value);\n            cursor = failureTree.children;\n        }\n        return failures;\n    }\n    toRunDetails(seed, basePath, maxSkips, qParams) {\n        if (!this.isSuccess()) {\n            return {\n                failed: true,\n                interrupted: this.interrupted,\n                numRuns: this.firstFailure() + 1 - this.numSkips,\n                numSkips: this.numSkips,\n                numShrinks: this.numShrinks(),\n                seed,\n                counterexample: this.value,\n                counterexamplePath: RunExecution.mergePaths(basePath, this.pathToFailure),\n                error: this.failure.errorMessage,\n                errorInstance: this.failure.error,\n                failures: this.extractFailures(),\n                executionSummary: this.rootExecutionTrees,\n                verbose: this.verbosity,\n                runConfiguration: qParams.toParameters(),\n            };\n        }\n        const considerInterruptedAsFailure = this.interruptedAsFailure || this.numSuccesses === 0;\n        const failed = this.numSkips > maxSkips || (this.interrupted && considerInterruptedAsFailure);\n        const out = {\n            failed,\n            interrupted: this.interrupted,\n            numRuns: this.numSuccesses,\n            numSkips: this.numSkips,\n            numShrinks: 0,\n            seed,\n            counterexample: null,\n            counterexamplePath: null,\n            error: null,\n            errorInstance: null,\n            failures: [],\n            executionSummary: this.rootExecutionTrees,\n            verbose: this.verbosity,\n            runConfiguration: qParams.toParameters(),\n        };\n        return out;\n    }\n}\nRunExecution.mergePaths = (offsetPath, path) => {\n    if (offsetPath.length === 0)\n        return path;\n    const offsetItems = offsetPath.split(':');\n    const remainingItems = path.split(':');\n    const middle = +offsetItems[offsetItems.length - 1] + +remainingItems[0];\n    return [...offsetItems.slice(0, offsetItems.length - 1), `${middle}`, ...remainingItems.slice(1)].join(':');\n};\n","function produce(producer) {\n    return producer();\n}\nexport function pathWalk(path, initialProducers, shrink) {\n    const producers = initialProducers;\n    const segments = path.split(':').map((text) => +text);\n    if (segments.length === 0) {\n        return producers.map(produce);\n    }\n    if (!segments.every((v) => !Number.isNaN(v))) {\n        throw new Error(`Unable to replay, got invalid path=${path}`);\n    }\n    let values = producers.drop(segments[0]).map(produce);\n    for (const s of segments.slice(1)) {\n        const valueToShrink = values.getNthOrLast(0);\n        if (valueToShrink === null) {\n            throw new Error(`Unable to replay, got wrong path=${path}`);\n        }\n        values = shrink(valueToShrink).drop(s);\n    }\n    return values;\n}\n","import { Error, safePush, safeReplace } from '../../../utils/globals.js';\nimport { stringify, possiblyAsyncStringify } from '../../../utils/stringify.js';\nimport { VerbosityLevel } from '../configuration/VerbosityLevel.js';\nimport { ExecutionStatus } from '../reporter/ExecutionStatus.js';\nconst safeObjectAssign = Object.assign;\nfunction formatHints(hints) {\n    if (hints.length === 1) {\n        return `Hint: ${hints[0]}`;\n    }\n    return hints.map((h, idx) => `Hint (${idx + 1}): ${h}`).join('\\n');\n}\nfunction formatFailures(failures, stringifyOne) {\n    return `Encountered failures were:\\n- ${failures.map(stringifyOne).join('\\n- ')}`;\n}\nfunction formatExecutionSummary(executionTrees, stringifyOne) {\n    const summaryLines = [];\n    const remainingTreesAndDepth = [];\n    for (const tree of executionTrees.slice().reverse()) {\n        remainingTreesAndDepth.push({ depth: 1, tree });\n    }\n    while (remainingTreesAndDepth.length !== 0) {\n        const currentTreeAndDepth = remainingTreesAndDepth.pop();\n        const currentTree = currentTreeAndDepth.tree;\n        const currentDepth = currentTreeAndDepth.depth;\n        const statusIcon = currentTree.status === ExecutionStatus.Success\n            ? '\\x1b[32m\\u221A\\x1b[0m'\n            : currentTree.status === ExecutionStatus.Failure\n                ? '\\x1b[31m\\xD7\\x1b[0m'\n                : '\\x1b[33m!\\x1b[0m';\n        const leftPadding = Array(currentDepth).join('. ');\n        summaryLines.push(`${leftPadding}${statusIcon} ${stringifyOne(currentTree.value)}`);\n        for (const tree of currentTree.children.slice().reverse()) {\n            remainingTreesAndDepth.push({ depth: currentDepth + 1, tree });\n        }\n    }\n    return `Execution summary:\\n${summaryLines.join('\\n')}`;\n}\nfunction preFormatTooManySkipped(out, stringifyOne) {\n    const message = `Failed to run property, too many pre-condition failures encountered\\n{ seed: ${out.seed} }\\n\\nRan ${out.numRuns} time(s)\\nSkipped ${out.numSkips} time(s)`;\n    let details = null;\n    const hints = [\n        'Try to reduce the number of rejected values by combining map, flatMap and built-in arbitraries',\n        'Increase failure tolerance by setting maxSkipsPerRun to an higher value',\n    ];\n    if (out.verbose >= VerbosityLevel.VeryVerbose) {\n        details = formatExecutionSummary(out.executionSummary, stringifyOne);\n    }\n    else {\n        safePush(hints, 'Enable verbose mode at level VeryVerbose in order to check all generated values and their associated status');\n    }\n    return { message, details, hints };\n}\nfunction preFormatFailure(out, stringifyOne) {\n    const noErrorInMessage = out.runConfiguration.errorWithCause;\n    const messageErrorPart = noErrorInMessage ? '' : `\\nGot ${safeReplace(out.error, /^Error: /, 'error: ')}`;\n    const message = `Property failed after ${out.numRuns} tests\\n{ seed: ${out.seed}, path: \"${out.counterexamplePath}\", endOnFailure: true }\\nCounterexample: ${stringifyOne(out.counterexample)}\\nShrunk ${out.numShrinks} time(s)${messageErrorPart}`;\n    let details = null;\n    const hints = [];\n    if (out.verbose >= VerbosityLevel.VeryVerbose) {\n        details = formatExecutionSummary(out.executionSummary, stringifyOne);\n    }\n    else if (out.verbose === VerbosityLevel.Verbose) {\n        details = formatFailures(out.failures, stringifyOne);\n    }\n    else {\n        safePush(hints, 'Enable verbose mode in order to have the list of all failing values encountered during the run');\n    }\n    return { message, details, hints };\n}\nfunction preFormatEarlyInterrupted(out, stringifyOne) {\n    const message = `Property interrupted after ${out.numRuns} tests\\n{ seed: ${out.seed} }`;\n    let details = null;\n    const hints = [];\n    if (out.verbose >= VerbosityLevel.VeryVerbose) {\n        details = formatExecutionSummary(out.executionSummary, stringifyOne);\n    }\n    else {\n        safePush(hints, 'Enable verbose mode at level VeryVerbose in order to check all generated values and their associated status');\n    }\n    return { message, details, hints };\n}\nfunction defaultReportMessageInternal(out, stringifyOne) {\n    if (!out.failed)\n        return;\n    const { message, details, hints } = out.counterexamplePath === null\n        ? out.interrupted\n            ? preFormatEarlyInterrupted(out, stringifyOne)\n            : preFormatTooManySkipped(out, stringifyOne)\n        : preFormatFailure(out, stringifyOne);\n    let errorMessage = message;\n    if (details != null)\n        errorMessage += `\\n\\n${details}`;\n    if (hints.length > 0)\n        errorMessage += `\\n\\n${formatHints(hints)}`;\n    return errorMessage;\n}\nfunction defaultReportMessage(out) {\n    return defaultReportMessageInternal(out, stringify);\n}\nasync function asyncDefaultReportMessage(out) {\n    const pendingStringifieds = [];\n    function stringifyOne(value) {\n        const stringified = possiblyAsyncStringify(value);\n        if (typeof stringified === 'string') {\n            return stringified;\n        }\n        pendingStringifieds.push(Promise.all([value, stringified]));\n        return '\\u2026';\n    }\n    const firstTryMessage = defaultReportMessageInternal(out, stringifyOne);\n    if (pendingStringifieds.length === 0) {\n        return firstTryMessage;\n    }\n    const registeredValues = new Map(await Promise.all(pendingStringifieds));\n    function stringifySecond(value) {\n        const asyncStringifiedIfRegistered = registeredValues.get(value);\n        if (asyncStringifiedIfRegistered !== undefined) {\n            return asyncStringifiedIfRegistered;\n        }\n        return stringify(value);\n    }\n    return defaultReportMessageInternal(out, stringifySecond);\n}\nfunction buildError(errorMessage, out) {\n    if (!out.runConfiguration.errorWithCause) {\n        throw new Error(errorMessage);\n    }\n    const ErrorWithCause = Error;\n    const error = new ErrorWithCause(errorMessage, { cause: out.errorInstance });\n    if (!('cause' in error)) {\n        safeObjectAssign(error, { cause: out.errorInstance });\n    }\n    return error;\n}\nfunction throwIfFailed(out) {\n    if (!out.failed)\n        return;\n    throw buildError(defaultReportMessage(out), out);\n}\nasync function asyncThrowIfFailed(out) {\n    if (!out.failed)\n        return;\n    throw buildError(await asyncDefaultReportMessage(out), out);\n}\nexport function reportRunDetails(out) {\n    if (out.runConfiguration.asyncReporter)\n        return out.runConfiguration.asyncReporter(out);\n    else if (out.runConfiguration.reporter)\n        return out.runConfiguration.reporter(out);\n    else\n        return throwIfFailed(out);\n}\nexport async function asyncReportRunDetails(out) {\n    if (out.runConfiguration.asyncReporter)\n        return out.runConfiguration.asyncReporter(out);\n    else if (out.runConfiguration.reporter)\n        return out.runConfiguration.reporter(out);\n    else\n        return asyncThrowIfFailed(out);\n}\nexport { defaultReportMessage, asyncDefaultReportMessage };\n","export const cloneMethod = Symbol.for('fast-check/cloneMethod');\nexport function hasCloneMethod(instance) {\n    return (instance !== null &&\n        (typeof instance === 'object' || typeof instance === 'function') &&\n        cloneMethod in instance &&\n        typeof instance[cloneMethod] === 'function');\n}\nexport function cloneIfNeeded(instance) {\n    return hasCloneMethod(instance) ? instance[cloneMethod]() : instance;\n}\n","import { pre } from './check/precondition/Pre.js';\nimport { asyncProperty } from './check/property/AsyncProperty.js';\nimport { property } from './check/property/Property.js';\nimport { assert, check } from './check/runner/Runner.js';\nimport { sample, statistics } from './check/runner/Sampler.js';\nimport { gen } from './arbitrary/gen.js';\nimport { array } from './arbitrary/array.js';\nimport { bigInt } from './arbitrary/bigInt.js';\nimport { bigIntN } from './arbitrary/bigIntN.js';\nimport { bigUint } from './arbitrary/bigUint.js';\nimport { bigUintN } from './arbitrary/bigUintN.js';\nimport { boolean } from './arbitrary/boolean.js';\nimport { falsy } from './arbitrary/falsy.js';\nimport { ascii } from './arbitrary/ascii.js';\nimport { base64 } from './arbitrary/base64.js';\nimport { char } from './arbitrary/char.js';\nimport { char16bits } from './arbitrary/char16bits.js';\nimport { fullUnicode } from './arbitrary/fullUnicode.js';\nimport { hexa } from './arbitrary/hexa.js';\nimport { unicode } from './arbitrary/unicode.js';\nimport { constant } from './arbitrary/constant.js';\nimport { constantFrom } from './arbitrary/constantFrom.js';\nimport { context } from './arbitrary/context.js';\nimport { date } from './arbitrary/date.js';\nimport { clone } from './arbitrary/clone.js';\nimport { dictionary } from './arbitrary/dictionary.js';\nimport { emailAddress } from './arbitrary/emailAddress.js';\nimport { double } from './arbitrary/double.js';\nimport { float } from './arbitrary/float.js';\nimport { compareBooleanFunc } from './arbitrary/compareBooleanFunc.js';\nimport { compareFunc } from './arbitrary/compareFunc.js';\nimport { func } from './arbitrary/func.js';\nimport { domain } from './arbitrary/domain.js';\nimport { integer } from './arbitrary/integer.js';\nimport { maxSafeInteger } from './arbitrary/maxSafeInteger.js';\nimport { maxSafeNat } from './arbitrary/maxSafeNat.js';\nimport { nat } from './arbitrary/nat.js';\nimport { ipV4 } from './arbitrary/ipV4.js';\nimport { ipV4Extended } from './arbitrary/ipV4Extended.js';\nimport { ipV6 } from './arbitrary/ipV6.js';\nimport { letrec } from './arbitrary/letrec.js';\nimport { lorem } from './arbitrary/lorem.js';\nimport { mapToConstant } from './arbitrary/mapToConstant.js';\nimport { memo } from './arbitrary/memo.js';\nimport { mixedCase } from './arbitrary/mixedCase.js';\nimport { object } from './arbitrary/object.js';\nimport { json } from './arbitrary/json.js';\nimport { anything } from './arbitrary/anything.js';\nimport { unicodeJsonValue } from './arbitrary/unicodeJsonValue.js';\nimport { jsonValue } from './arbitrary/jsonValue.js';\nimport { unicodeJson } from './arbitrary/unicodeJson.js';\nimport { oneof } from './arbitrary/oneof.js';\nimport { option } from './arbitrary/option.js';\nimport { record } from './arbitrary/record.js';\nimport { uniqueArray } from './arbitrary/uniqueArray.js';\nimport { infiniteStream } from './arbitrary/infiniteStream.js';\nimport { asciiString } from './arbitrary/asciiString.js';\nimport { base64String } from './arbitrary/base64String.js';\nimport { fullUnicodeString } from './arbitrary/fullUnicodeString.js';\nimport { hexaString } from './arbitrary/hexaString.js';\nimport { string } from './arbitrary/string.js';\nimport { string16bits } from './arbitrary/string16bits.js';\nimport { stringOf } from './arbitrary/stringOf.js';\nimport { unicodeString } from './arbitrary/unicodeString.js';\nimport { subarray } from './arbitrary/subarray.js';\nimport { shuffledSubarray } from './arbitrary/shuffledSubarray.js';\nimport { tuple } from './arbitrary/tuple.js';\nimport { ulid } from './arbitrary/ulid.js';\nimport { uuid } from './arbitrary/uuid.js';\nimport { uuidV } from './arbitrary/uuidV.js';\nimport { webAuthority } from './arbitrary/webAuthority.js';\nimport { webFragments } from './arbitrary/webFragments.js';\nimport { webPath } from './arbitrary/webPath.js';\nimport { webQueryParameters } from './arbitrary/webQueryParameters.js';\nimport { webSegment } from './arbitrary/webSegment.js';\nimport { webUrl } from './arbitrary/webUrl.js';\nimport { commands } from './arbitrary/commands.js';\nimport { asyncModelRun, modelRun, scheduledModelRun } from './check/model/ModelRunner.js';\nimport { Random } from './random/generator/Random.js';\nimport { configureGlobal, readConfigureGlobal, resetConfigureGlobal, } from './check/runner/configuration/GlobalParameters.js';\nimport { VerbosityLevel } from './check/runner/configuration/VerbosityLevel.js';\nimport { ExecutionStatus } from './check/runner/reporter/ExecutionStatus.js';\nimport { cloneMethod, cloneIfNeeded, hasCloneMethod } from './check/symbols.js';\nimport { Stream, stream } from './stream/Stream.js';\nimport { hash } from './utils/hash.js';\nimport { stringify, asyncStringify, toStringMethod, hasToStringMethod, asyncToStringMethod, hasAsyncToStringMethod, } from './utils/stringify.js';\nimport { scheduler, schedulerFor } from './arbitrary/scheduler.js';\nimport { defaultReportMessage, asyncDefaultReportMessage } from './check/runner/utils/RunDetailsFormatter.js';\nimport { PreconditionFailure } from './check/precondition/PreconditionFailure.js';\nimport { int8Array } from './arbitrary/int8Array.js';\nimport { int16Array } from './arbitrary/int16Array.js';\nimport { int32Array } from './arbitrary/int32Array.js';\nimport { uint8Array } from './arbitrary/uint8Array.js';\nimport { uint8ClampedArray } from './arbitrary/uint8ClampedArray.js';\nimport { uint16Array } from './arbitrary/uint16Array.js';\nimport { uint32Array } from './arbitrary/uint32Array.js';\nimport { float32Array } from './arbitrary/float32Array.js';\nimport { float64Array } from './arbitrary/float64Array.js';\nimport { sparseArray } from './arbitrary/sparseArray.js';\nimport { Arbitrary } from './check/arbitrary/definition/Arbitrary.js';\nimport { Value } from './check/arbitrary/definition/Value.js';\nimport { createDepthIdentifier, getDepthContextFor } from './arbitrary/_internals/helpers/DepthContext.js';\nimport { bigInt64Array } from './arbitrary/bigInt64Array.js';\nimport { bigUint64Array } from './arbitrary/bigUint64Array.js';\nimport { stringMatching } from './arbitrary/stringMatching.js';\nconst __type = 'module';\nconst __version = '3.19.0';\nconst __commitHash = '0eed51496955271dde0ef5fa4d0862c13cd2fbd5';\nexport { __type, __version, __commitHash, sample, statistics, check, assert, pre, PreconditionFailure, property, asyncProperty, boolean, falsy, float, double, integer, nat, maxSafeInteger, maxSafeNat, bigIntN, bigUintN, bigInt, bigUint, char, ascii, char16bits, unicode, fullUnicode, hexa, base64, mixedCase, string, asciiString, string16bits, stringOf, unicodeString, fullUnicodeString, hexaString, base64String, stringMatching, lorem, constant, constantFrom, mapToConstant, option, oneof, clone, shuffledSubarray, subarray, array, sparseArray, infiniteStream, uniqueArray, tuple, record, dictionary, anything, object, json, jsonValue, unicodeJson, unicodeJsonValue, letrec, memo, compareBooleanFunc, compareFunc, func, context, gen, date, ipV4, ipV4Extended, ipV6, domain, webAuthority, webSegment, webFragments, webPath, webQueryParameters, webUrl, emailAddress, ulid, uuid, uuidV, int8Array, uint8Array, uint8ClampedArray, int16Array, uint16Array, int32Array, uint32Array, float32Array, float64Array, bigInt64Array, bigUint64Array, asyncModelRun, modelRun, scheduledModelRun, commands, scheduler, schedulerFor, Arbitrary, Value, cloneMethod, cloneIfNeeded, hasCloneMethod, toStringMethod, hasToStringMethod, asyncToStringMethod, hasAsyncToStringMethod, getDepthContextFor, stringify, asyncStringify, defaultReportMessage, asyncDefaultReportMessage, hash, VerbosityLevel, configureGlobal, readConfigureGlobal, resetConfigureGlobal, ExecutionStatus, Random, Stream, stream, createDepthIdentifier, };\n","import * as fc from './fast-check-default.js';\nexport default fc;\nexport * from './fast-check-default.js';\n","import { unsafeUniformArrayIntDistribution, unsafeUniformBigIntDistribution, unsafeUniformIntDistribution, } from 'pure-rand';\nexport class Random {\n    constructor(sourceRng) {\n        this.internalRng = sourceRng.clone();\n    }\n    clone() {\n        return new Random(this.internalRng);\n    }\n    next(bits) {\n        return unsafeUniformIntDistribution(0, (1 << bits) - 1, this.internalRng);\n    }\n    nextBoolean() {\n        return unsafeUniformIntDistribution(0, 1, this.internalRng) == 1;\n    }\n    nextInt(min, max) {\n        return unsafeUniformIntDistribution(min == null ? Random.MIN_INT : min, max == null ? Random.MAX_INT : max, this.internalRng);\n    }\n    nextBigInt(min, max) {\n        return unsafeUniformBigIntDistribution(min, max, this.internalRng);\n    }\n    nextArrayInt(min, max) {\n        return unsafeUniformArrayIntDistribution(min, max, this.internalRng);\n    }\n    nextDouble() {\n        const a = this.next(26);\n        const b = this.next(27);\n        return (a * Random.DBL_FACTOR + b) * Random.DBL_DIVISOR;\n    }\n    getState() {\n        if ('getState' in this.internalRng && typeof this.internalRng.getState === 'function') {\n            return this.internalRng.getState();\n        }\n        return undefined;\n    }\n}\nRandom.MIN_INT = 0x80000000 | 0;\nRandom.MAX_INT = 0x7fffffff | 0;\nRandom.DBL_FACTOR = Math.pow(2, 27);\nRandom.DBL_DIVISOR = Math.pow(2, -53);\n","class LazyIterableIterator {\n    constructor(producer) {\n        this.producer = producer;\n    }\n    [Symbol.iterator]() {\n        if (this.it === undefined) {\n            this.it = this.producer();\n        }\n        return this.it;\n    }\n    next() {\n        if (this.it === undefined) {\n            this.it = this.producer();\n        }\n        return this.it.next();\n    }\n}\nexport function makeLazy(producer) {\n    return new LazyIterableIterator(producer);\n}\n","import { filterHelper, flatMapHelper, joinHelper, mapHelper, nilHelper, takeNHelper, takeWhileHelper, } from './StreamHelpers.js';\nconst safeSymbolIterator = Symbol.iterator;\nexport class Stream {\n    static nil() {\n        return new Stream(nilHelper());\n    }\n    static of(...elements) {\n        return new Stream(elements[safeSymbolIterator]());\n    }\n    constructor(g) {\n        this.g = g;\n    }\n    next() {\n        return this.g.next();\n    }\n    [safeSymbolIterator]() {\n        return this.g;\n    }\n    map(f) {\n        return new Stream(mapHelper(this.g, f));\n    }\n    flatMap(f) {\n        return new Stream(flatMapHelper(this.g, f));\n    }\n    dropWhile(f) {\n        let foundEligible = false;\n        function* helper(v) {\n            if (foundEligible || !f(v)) {\n                foundEligible = true;\n                yield v;\n            }\n        }\n        return this.flatMap(helper);\n    }\n    drop(n) {\n        if (n <= 0) {\n            return this;\n        }\n        let idx = 0;\n        function helper() {\n            return idx++ < n;\n        }\n        return this.dropWhile(helper);\n    }\n    takeWhile(f) {\n        return new Stream(takeWhileHelper(this.g, f));\n    }\n    take(n) {\n        return new Stream(takeNHelper(this.g, n));\n    }\n    filter(f) {\n        return new Stream(filterHelper(this.g, f));\n    }\n    every(f) {\n        for (const v of this.g) {\n            if (!f(v)) {\n                return false;\n            }\n        }\n        return true;\n    }\n    has(f) {\n        for (const v of this.g) {\n            if (f(v)) {\n                return [true, v];\n            }\n        }\n        return [false, null];\n    }\n    join(...others) {\n        return new Stream(joinHelper(this.g, others));\n    }\n    getNthOrLast(nth) {\n        let remaining = nth;\n        let last = null;\n        for (const v of this.g) {\n            if (remaining-- === 0)\n                return v;\n            last = v;\n        }\n        return last;\n    }\n}\nexport function stream(g) {\n    return new Stream(g);\n}\n","class Nil {\n    [Symbol.iterator]() {\n        return this;\n    }\n    next(value) {\n        return { value, done: true };\n    }\n}\nNil.nil = new Nil();\nexport function nilHelper() {\n    return Nil.nil;\n}\nexport function* mapHelper(g, f) {\n    for (const v of g) {\n        yield f(v);\n    }\n}\nexport function* flatMapHelper(g, f) {\n    for (const v of g) {\n        yield* f(v);\n    }\n}\nexport function* filterHelper(g, f) {\n    for (const v of g) {\n        if (f(v)) {\n            yield v;\n        }\n    }\n}\nexport function* takeNHelper(g, n) {\n    for (let i = 0; i < n; ++i) {\n        const cur = g.next();\n        if (cur.done) {\n            break;\n        }\n        yield cur.value;\n    }\n}\nexport function* takeWhileHelper(g, f) {\n    let cur = g.next();\n    while (!cur.done && f(cur.value)) {\n        yield cur.value;\n        cur = g.next();\n    }\n}\nexport function* joinHelper(g, others) {\n    for (let cur = g.next(); !cur.done; cur = g.next()) {\n        yield cur.value;\n    }\n    for (const s of others) {\n        for (let cur = s.next(); !cur.done; cur = s.next()) {\n            yield cur.value;\n        }\n    }\n}\n","const untouchedApply = Function.prototype.apply;\nconst ApplySymbol = Symbol('apply');\nfunction safeExtractApply(f) {\n    try {\n        return f.apply;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction safeApplyHacky(f, instance, args) {\n    const ff = f;\n    ff[ApplySymbol] = untouchedApply;\n    const out = ff[ApplySymbol](instance, args);\n    delete ff[ApplySymbol];\n    return out;\n}\nexport function safeApply(f, instance, args) {\n    if (safeExtractApply(f) === untouchedApply) {\n        return f.apply(instance, args);\n    }\n    return safeApplyHacky(f, instance, args);\n}\n","import { safeApply } from './apply.js';\nconst SArray = typeof Array !== 'undefined' ? Array : undefined;\nexport { SArray as Array };\nconst SBigInt = typeof BigInt !== 'undefined' ? BigInt : undefined;\nexport { SBigInt as BigInt };\nconst SBigInt64Array = typeof BigInt64Array !== 'undefined' ? BigInt64Array : undefined;\nexport { SBigInt64Array as BigInt64Array };\nconst SBigUint64Array = typeof BigUint64Array !== 'undefined' ? BigUint64Array : undefined;\nexport { SBigUint64Array as BigUint64Array };\nconst SBoolean = typeof Boolean !== 'undefined' ? Boolean : undefined;\nexport { SBoolean as Boolean };\nconst SDate = typeof Date !== 'undefined' ? Date : undefined;\nexport { SDate as Date };\nconst SError = typeof Error !== 'undefined' ? Error : undefined;\nexport { SError as Error };\nconst SFloat32Array = typeof Float32Array !== 'undefined' ? Float32Array : undefined;\nexport { SFloat32Array as Float32Array };\nconst SFloat64Array = typeof Float64Array !== 'undefined' ? Float64Array : undefined;\nexport { SFloat64Array as Float64Array };\nconst SInt8Array = typeof Int8Array !== 'undefined' ? Int8Array : undefined;\nexport { SInt8Array as Int8Array };\nconst SInt16Array = typeof Int16Array !== 'undefined' ? Int16Array : undefined;\nexport { SInt16Array as Int16Array };\nconst SInt32Array = typeof Int32Array !== 'undefined' ? Int32Array : undefined;\nexport { SInt32Array as Int32Array };\nconst SNumber = typeof Number !== 'undefined' ? Number : undefined;\nexport { SNumber as Number };\nconst SString = typeof String !== 'undefined' ? String : undefined;\nexport { SString as String };\nconst SSet = typeof Set !== 'undefined' ? Set : undefined;\nexport { SSet as Set };\nconst SUint8Array = typeof Uint8Array !== 'undefined' ? Uint8Array : undefined;\nexport { SUint8Array as Uint8Array };\nconst SUint8ClampedArray = typeof Uint8ClampedArray !== 'undefined' ? Uint8ClampedArray : undefined;\nexport { SUint8ClampedArray as Uint8ClampedArray };\nconst SUint16Array = typeof Uint16Array !== 'undefined' ? Uint16Array : undefined;\nexport { SUint16Array as Uint16Array };\nconst SUint32Array = typeof Uint32Array !== 'undefined' ? Uint32Array : undefined;\nexport { SUint32Array as Uint32Array };\nconst SencodeURIComponent = typeof encodeURIComponent !== 'undefined' ? encodeURIComponent : undefined;\nexport { SencodeURIComponent as encodeURIComponent };\nconst untouchedForEach = Array.prototype.forEach;\nconst untouchedIndexOf = Array.prototype.indexOf;\nconst untouchedJoin = Array.prototype.join;\nconst untouchedMap = Array.prototype.map;\nconst untouchedFilter = Array.prototype.filter;\nconst untouchedPush = Array.prototype.push;\nconst untouchedPop = Array.prototype.pop;\nconst untouchedSplice = Array.prototype.splice;\nconst untouchedSlice = Array.prototype.slice;\nconst untouchedSort = Array.prototype.sort;\nconst untouchedEvery = Array.prototype.every;\nfunction extractForEach(instance) {\n    try {\n        return instance.forEach;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractIndexOf(instance) {\n    try {\n        return instance.indexOf;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractJoin(instance) {\n    try {\n        return instance.join;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractMap(instance) {\n    try {\n        return instance.map;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractFilter(instance) {\n    try {\n        return instance.filter;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractPush(instance) {\n    try {\n        return instance.push;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractPop(instance) {\n    try {\n        return instance.pop;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractSplice(instance) {\n    try {\n        return instance.splice;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractSlice(instance) {\n    try {\n        return instance.slice;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractSort(instance) {\n    try {\n        return instance.sort;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractEvery(instance) {\n    try {\n        return instance.every;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nexport function safeForEach(instance, fn) {\n    if (extractForEach(instance) === untouchedForEach) {\n        return instance.forEach(fn);\n    }\n    return safeApply(untouchedForEach, instance, [fn]);\n}\nexport function safeIndexOf(instance, ...args) {\n    if (extractIndexOf(instance) === untouchedIndexOf) {\n        return instance.indexOf(...args);\n    }\n    return safeApply(untouchedIndexOf, instance, args);\n}\nexport function safeJoin(instance, ...args) {\n    if (extractJoin(instance) === untouchedJoin) {\n        return instance.join(...args);\n    }\n    return safeApply(untouchedJoin, instance, args);\n}\nexport function safeMap(instance, fn) {\n    if (extractMap(instance) === untouchedMap) {\n        return instance.map(fn);\n    }\n    return safeApply(untouchedMap, instance, [fn]);\n}\nexport function safeFilter(instance, predicate) {\n    if (extractFilter(instance) === untouchedFilter) {\n        return instance.filter(predicate);\n    }\n    return safeApply(untouchedFilter, instance, [predicate]);\n}\nexport function safePush(instance, ...args) {\n    if (extractPush(instance) === untouchedPush) {\n        return instance.push(...args);\n    }\n    return safeApply(untouchedPush, instance, args);\n}\nexport function safePop(instance) {\n    if (extractPop(instance) === untouchedPop) {\n        return instance.pop();\n    }\n    return safeApply(untouchedPop, instance, []);\n}\nexport function safeSplice(instance, ...args) {\n    if (extractSplice(instance) === untouchedSplice) {\n        return instance.splice(...args);\n    }\n    return safeApply(untouchedSplice, instance, args);\n}\nexport function safeSlice(instance, ...args) {\n    if (extractSlice(instance) === untouchedSlice) {\n        return instance.slice(...args);\n    }\n    return safeApply(untouchedSlice, instance, args);\n}\nexport function safeSort(instance, ...args) {\n    if (extractSort(instance) === untouchedSort) {\n        return instance.sort(...args);\n    }\n    return safeApply(untouchedSort, instance, args);\n}\nexport function safeEvery(instance, ...args) {\n    if (extractEvery(instance) === untouchedEvery) {\n        return instance.every(...args);\n    }\n    return safeApply(untouchedEvery, instance, args);\n}\nconst untouchedGetTime = Date.prototype.getTime;\nconst untouchedToISOString = Date.prototype.toISOString;\nfunction extractGetTime(instance) {\n    try {\n        return instance.getTime;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractToISOString(instance) {\n    try {\n        return instance.toISOString;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nexport function safeGetTime(instance) {\n    if (extractGetTime(instance) === untouchedGetTime) {\n        return instance.getTime();\n    }\n    return safeApply(untouchedGetTime, instance, []);\n}\nexport function safeToISOString(instance) {\n    if (extractToISOString(instance) === untouchedToISOString) {\n        return instance.toISOString();\n    }\n    return safeApply(untouchedToISOString, instance, []);\n}\nconst untouchedAdd = Set.prototype.add;\nfunction extractAdd(instance) {\n    try {\n        return instance.add;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nexport function safeAdd(instance, value) {\n    if (extractAdd(instance) === untouchedAdd) {\n        return instance.add(value);\n    }\n    return safeApply(untouchedAdd, instance, [value]);\n}\nconst untouchedSplit = String.prototype.split;\nconst untouchedStartsWith = String.prototype.startsWith;\nconst untouchedEndsWith = String.prototype.endsWith;\nconst untouchedSubstring = String.prototype.substring;\nconst untouchedToLowerCase = String.prototype.toLowerCase;\nconst untouchedToUpperCase = String.prototype.toUpperCase;\nconst untouchedPadStart = String.prototype.padStart;\nconst untouchedCharCodeAt = String.prototype.charCodeAt;\nconst untouchedReplace = String.prototype.replace;\nfunction extractSplit(instance) {\n    try {\n        return instance.split;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractStartsWith(instance) {\n    try {\n        return instance.startsWith;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractEndsWith(instance) {\n    try {\n        return instance.endsWith;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractSubstring(instance) {\n    try {\n        return instance.substring;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractToLowerCase(instance) {\n    try {\n        return instance.toLowerCase;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractToUpperCase(instance) {\n    try {\n        return instance.toUpperCase;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractPadStart(instance) {\n    try {\n        return instance.padStart;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractCharCodeAt(instance) {\n    try {\n        return instance.charCodeAt;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nfunction extractReplace(instance) {\n    try {\n        return instance.replace;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nexport function safeSplit(instance, ...args) {\n    if (extractSplit(instance) === untouchedSplit) {\n        return instance.split(...args);\n    }\n    return safeApply(untouchedSplit, instance, args);\n}\nexport function safeStartsWith(instance, ...args) {\n    if (extractStartsWith(instance) === untouchedStartsWith) {\n        return instance.startsWith(...args);\n    }\n    return safeApply(untouchedStartsWith, instance, args);\n}\nexport function safeEndsWith(instance, ...args) {\n    if (extractEndsWith(instance) === untouchedEndsWith) {\n        return instance.endsWith(...args);\n    }\n    return safeApply(untouchedEndsWith, instance, args);\n}\nexport function safeSubstring(instance, ...args) {\n    if (extractSubstring(instance) === untouchedSubstring) {\n        return instance.substring(...args);\n    }\n    return safeApply(untouchedSubstring, instance, args);\n}\nexport function safeToLowerCase(instance) {\n    if (extractToLowerCase(instance) === untouchedToLowerCase) {\n        return instance.toLowerCase();\n    }\n    return safeApply(untouchedToLowerCase, instance, []);\n}\nexport function safeToUpperCase(instance) {\n    if (extractToUpperCase(instance) === untouchedToUpperCase) {\n        return instance.toUpperCase();\n    }\n    return safeApply(untouchedToUpperCase, instance, []);\n}\nexport function safePadStart(instance, ...args) {\n    if (extractPadStart(instance) === untouchedPadStart) {\n        return instance.padStart(...args);\n    }\n    return safeApply(untouchedPadStart, instance, args);\n}\nexport function safeCharCodeAt(instance, index) {\n    if (extractCharCodeAt(instance) === untouchedCharCodeAt) {\n        return instance.charCodeAt(index);\n    }\n    return safeApply(untouchedCharCodeAt, instance, [index]);\n}\nexport function safeReplace(instance, pattern, replacement) {\n    if (extractReplace(instance) === untouchedReplace) {\n        return instance.replace(pattern, replacement);\n    }\n    return safeApply(untouchedReplace, instance, [pattern, replacement]);\n}\nconst untouchedNumberToString = Number.prototype.toString;\nfunction extractNumberToString(instance) {\n    try {\n        return instance.toString;\n    }\n    catch (err) {\n        return undefined;\n    }\n}\nexport function safeNumberToString(instance, ...args) {\n    if (extractNumberToString(instance) === untouchedNumberToString) {\n        return instance.toString(...args);\n    }\n    return safeApply(untouchedNumberToString, instance, args);\n}\nconst untouchedHasOwnProperty = Object.prototype.hasOwnProperty;\nconst untouchedToString = Object.prototype.toString;\nexport function safeHasOwnProperty(instance, v) {\n    return safeApply(untouchedHasOwnProperty, instance, [v]);\n}\nexport function safeToString(instance) {\n    return safeApply(untouchedToString, instance, []);\n}\n","import { safeCharCodeAt } from './globals.js';\nconst crc32Table = [\n    0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419, 0x706af48f, 0xe963a535, 0x9e6495a3, 0x0edb8832,\n    0x79dcb8a4, 0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91, 0x1db71064, 0x6ab020f2,\n    0xf3b97148, 0x84be41de, 0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7, 0x136c9856, 0x646ba8c0, 0xfd62f97a,\n    0x8a65c9ec, 0x14015c4f, 0x63066cd9, 0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172,\n    0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b, 0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3,\n    0x45df5c75, 0xdcd60dcf, 0xabd13d59, 0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423,\n    0xcfba9599, 0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924, 0x2f6f7c87, 0x58684c11, 0xc1611dab,\n    0xb6662d3d, 0x76dc4190, 0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f, 0x9fbfe4a5, 0xe8b8d433,\n    0x7807c9a2, 0x0f00f934, 0x9609a88e, 0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01, 0x6b6b51f4,\n    0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950,\n    0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65, 0x4db26158, 0x3ab551ce, 0xa3bc0074,\n    0xd4bb30e2, 0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0,\n    0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa, 0xbe0b1010, 0xc90c2086, 0x5768b525,\n    0x206f85b3, 0xb966d409, 0xce61e49f, 0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17, 0x2eb40d81,\n    0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6, 0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615,\n    0x73dc1683, 0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8, 0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1,\n    0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb, 0x196c3671, 0x6e6b06e7, 0xfed41b76,\n    0x89d32be0, 0x10da7a5a, 0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5, 0xd6d6a3e8, 0xa1d1937e,\n    0x38d8c2c4, 0x4fdff252, 0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b, 0xd80d2bda, 0xaf0a1b4c, 0x36034af6,\n    0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef, 0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,\n    0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe, 0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7,\n    0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d, 0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x026d930a, 0x9c0906a9, 0xeb0e363f,\n    0x72076785, 0x05005713, 0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7,\n    0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242, 0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777,\n    0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c, 0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45, 0xa00ae278,\n    0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc,\n    0x40df0b66, 0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9, 0xbdbdf21c, 0xcabac28a, 0x53b39330,\n    0x24b4a3a6, 0xbad03605, 0xcdd70693, 0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94,\n    0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d,\n];\nexport function hash(repr) {\n    let crc = 0xffffffff;\n    for (let idx = 0; idx < repr.length; ++idx) {\n        const c = safeCharCodeAt(repr, idx);\n        if (c < 0x80) {\n            crc = crc32Table[(crc & 0xff) ^ c] ^ (crc >> 8);\n        }\n        else if (c < 0x800) {\n            crc = crc32Table[(crc & 0xff) ^ (192 | ((c >> 6) & 31))] ^ (crc >> 8);\n            crc = crc32Table[(crc & 0xff) ^ (128 | (c & 63))] ^ (crc >> 8);\n        }\n        else if (c >= 0xd800 && c < 0xe000) {\n            const cNext = safeCharCodeAt(repr, ++idx);\n            if (c >= 0xdc00 || cNext < 0xdc00 || cNext > 0xdfff || Number.isNaN(cNext)) {\n                idx -= 1;\n                crc = crc32Table[(crc & 0xff) ^ 0xef] ^ (crc >> 8);\n                crc = crc32Table[(crc & 0xff) ^ 0xbf] ^ (crc >> 8);\n                crc = crc32Table[(crc & 0xff) ^ 0xbd] ^ (crc >> 8);\n            }\n            else {\n                const c1 = (c & 1023) + 64;\n                const c2 = cNext & 1023;\n                crc = crc32Table[(crc & 0xff) ^ (240 | ((c1 >> 8) & 7))] ^ (crc >> 8);\n                crc = crc32Table[(crc & 0xff) ^ (128 | ((c1 >> 2) & 63))] ^ (crc >> 8);\n                crc = crc32Table[(crc & 0xff) ^ (128 | ((c2 >> 6) & 15) | ((c1 & 3) << 4))] ^ (crc >> 8);\n                crc = crc32Table[(crc & 0xff) ^ (128 | (c2 & 63))] ^ (crc >> 8);\n            }\n        }\n        else {\n            crc = crc32Table[(crc & 0xff) ^ (224 | ((c >> 12) & 15))] ^ (crc >> 8);\n            crc = crc32Table[(crc & 0xff) ^ (128 | ((c >> 6) & 63))] ^ (crc >> 8);\n            crc = crc32Table[(crc & 0xff) ^ (128 | (c & 63))] ^ (crc >> 8);\n        }\n    }\n    return (crc | 0) + 0x80000000;\n}\n","import { safeFilter, safeGetTime, safeIndexOf, safeJoin, safeMap, safePush, safeToISOString, safeToString, String, } from './globals.js';\nconst safeArrayFrom = Array.from;\nconst safeBufferIsBuffer = typeof Buffer !== 'undefined' ? Buffer.isBuffer : undefined;\nconst safeJsonStringify = JSON.stringify;\nconst safeNumberIsNaN = Number.isNaN;\nconst safeObjectKeys = Object.keys;\nconst safeObjectGetOwnPropertySymbols = Object.getOwnPropertySymbols;\nconst safeObjectGetOwnPropertyDescriptor = Object.getOwnPropertyDescriptor;\nconst safeObjectGetPrototypeOf = Object.getPrototypeOf;\nconst safeNegativeInfinity = Number.NEGATIVE_INFINITY;\nconst safePositiveInfinity = Number.POSITIVE_INFINITY;\nexport const toStringMethod = Symbol.for('fast-check/toStringMethod');\nexport function hasToStringMethod(instance) {\n    return (instance !== null &&\n        (typeof instance === 'object' || typeof instance === 'function') &&\n        toStringMethod in instance &&\n        typeof instance[toStringMethod] === 'function');\n}\nexport const asyncToStringMethod = Symbol.for('fast-check/asyncToStringMethod');\nexport function hasAsyncToStringMethod(instance) {\n    return (instance !== null &&\n        (typeof instance === 'object' || typeof instance === 'function') &&\n        asyncToStringMethod in instance &&\n        typeof instance[asyncToStringMethod] === 'function');\n}\nconst findSymbolNameRegex = /^Symbol\\((.*)\\)$/;\nfunction getSymbolDescription(s) {\n    if (s.description !== undefined)\n        return s.description;\n    const m = findSymbolNameRegex.exec(String(s));\n    return m && m[1].length ? m[1] : null;\n}\nfunction stringifyNumber(numValue) {\n    switch (numValue) {\n        case 0:\n            return 1 / numValue === safeNegativeInfinity ? '-0' : '0';\n        case safeNegativeInfinity:\n            return 'Number.NEGATIVE_INFINITY';\n        case safePositiveInfinity:\n            return 'Number.POSITIVE_INFINITY';\n        default:\n            return numValue === numValue ? String(numValue) : 'Number.NaN';\n    }\n}\nfunction isSparseArray(arr) {\n    let previousNumberedIndex = -1;\n    for (const index in arr) {\n        const numberedIndex = Number(index);\n        if (numberedIndex !== previousNumberedIndex + 1)\n            return true;\n        previousNumberedIndex = numberedIndex;\n    }\n    return previousNumberedIndex + 1 !== arr.length;\n}\nexport function stringifyInternal(value, previousValues, getAsyncContent) {\n    const currentValues = [...previousValues, value];\n    if (typeof value === 'object') {\n        if (safeIndexOf(previousValues, value) !== -1) {\n            return '[cyclic]';\n        }\n    }\n    if (hasAsyncToStringMethod(value)) {\n        const content = getAsyncContent(value);\n        if (content.state === 'fulfilled') {\n            return content.value;\n        }\n    }\n    if (hasToStringMethod(value)) {\n        try {\n            return value[toStringMethod]();\n        }\n        catch (err) {\n        }\n    }\n    switch (safeToString(value)) {\n        case '[object Array]': {\n            const arr = value;\n            if (arr.length >= 50 && isSparseArray(arr)) {\n                const assignments = [];\n                for (const index in arr) {\n                    if (!safeNumberIsNaN(Number(index)))\n                        safePush(assignments, `${index}:${stringifyInternal(arr[index], currentValues, getAsyncContent)}`);\n                }\n                return assignments.length !== 0\n                    ? `Object.assign(Array(${arr.length}),{${safeJoin(assignments, ',')}})`\n                    : `Array(${arr.length})`;\n            }\n            const stringifiedArray = safeJoin(safeMap(arr, (v) => stringifyInternal(v, currentValues, getAsyncContent)), ',');\n            return arr.length === 0 || arr.length - 1 in arr ? `[${stringifiedArray}]` : `[${stringifiedArray},]`;\n        }\n        case '[object BigInt]':\n            return `${value}n`;\n        case '[object Boolean]': {\n            const unboxedToString = value == true ? 'true' : 'false';\n            return typeof value === 'boolean' ? unboxedToString : `new Boolean(${unboxedToString})`;\n        }\n        case '[object Date]': {\n            const d = value;\n            return safeNumberIsNaN(safeGetTime(d)) ? `new Date(NaN)` : `new Date(${safeJsonStringify(safeToISOString(d))})`;\n        }\n        case '[object Map]':\n            return `new Map(${stringifyInternal(Array.from(value), currentValues, getAsyncContent)})`;\n        case '[object Null]':\n            return `null`;\n        case '[object Number]':\n            return typeof value === 'number' ? stringifyNumber(value) : `new Number(${stringifyNumber(Number(value))})`;\n        case '[object Object]': {\n            try {\n                const toStringAccessor = value.toString;\n                if (typeof toStringAccessor === 'function' && toStringAccessor !== Object.prototype.toString) {\n                    return value.toString();\n                }\n            }\n            catch (err) {\n                return '[object Object]';\n            }\n            const mapper = (k) => `${k === '__proto__'\n                ? '[\"__proto__\"]'\n                : typeof k === 'symbol'\n                    ? `[${stringifyInternal(k, currentValues, getAsyncContent)}]`\n                    : safeJsonStringify(k)}:${stringifyInternal(value[k], currentValues, getAsyncContent)}`;\n            const stringifiedProperties = [\n                ...safeMap(safeObjectKeys(value), mapper),\n                ...safeMap(safeFilter(safeObjectGetOwnPropertySymbols(value), (s) => {\n                    const descriptor = safeObjectGetOwnPropertyDescriptor(value, s);\n                    return descriptor && descriptor.enumerable;\n                }), mapper),\n            ];\n            const rawRepr = '{' + safeJoin(stringifiedProperties, ',') + '}';\n            if (safeObjectGetPrototypeOf(value) === null) {\n                return rawRepr === '{}' ? 'Object.create(null)' : `Object.assign(Object.create(null),${rawRepr})`;\n            }\n            return rawRepr;\n        }\n        case '[object Set]':\n            return `new Set(${stringifyInternal(Array.from(value), currentValues, getAsyncContent)})`;\n        case '[object String]':\n            return typeof value === 'string' ? safeJsonStringify(value) : `new String(${safeJsonStringify(value)})`;\n        case '[object Symbol]': {\n            const s = value;\n            if (Symbol.keyFor(s) !== undefined) {\n                return `Symbol.for(${safeJsonStringify(Symbol.keyFor(s))})`;\n            }\n            const desc = getSymbolDescription(s);\n            if (desc === null) {\n                return 'Symbol()';\n            }\n            const knownSymbol = desc.startsWith('Symbol.') && Symbol[desc.substring(7)];\n            return s === knownSymbol ? desc : `Symbol(${safeJsonStringify(desc)})`;\n        }\n        case '[object Promise]': {\n            const promiseContent = getAsyncContent(value);\n            switch (promiseContent.state) {\n                case 'fulfilled':\n                    return `Promise.resolve(${stringifyInternal(promiseContent.value, currentValues, getAsyncContent)})`;\n                case 'rejected':\n                    return `Promise.reject(${stringifyInternal(promiseContent.value, currentValues, getAsyncContent)})`;\n                case 'pending':\n                    return `new Promise(() => {/*pending*/})`;\n                case 'unknown':\n                default:\n                    return `new Promise(() => {/*unknown*/})`;\n            }\n        }\n        case '[object Error]':\n            if (value instanceof Error) {\n                return `new Error(${stringifyInternal(value.message, currentValues, getAsyncContent)})`;\n            }\n            break;\n        case '[object Undefined]':\n            return `undefined`;\n        case '[object Int8Array]':\n        case '[object Uint8Array]':\n        case '[object Uint8ClampedArray]':\n        case '[object Int16Array]':\n        case '[object Uint16Array]':\n        case '[object Int32Array]':\n        case '[object Uint32Array]':\n        case '[object Float32Array]':\n        case '[object Float64Array]':\n        case '[object BigInt64Array]':\n        case '[object BigUint64Array]': {\n            if (typeof safeBufferIsBuffer === 'function' && safeBufferIsBuffer(value)) {\n                return `Buffer.from(${stringifyInternal(safeArrayFrom(value.values()), currentValues, getAsyncContent)})`;\n            }\n            const valuePrototype = safeObjectGetPrototypeOf(value);\n            const className = valuePrototype && valuePrototype.constructor && valuePrototype.constructor.name;\n            if (typeof className === 'string') {\n                const typedArray = value;\n                const valuesFromTypedArr = typedArray.values();\n                return `${className}.from(${stringifyInternal(safeArrayFrom(valuesFromTypedArr), currentValues, getAsyncContent)})`;\n            }\n            break;\n        }\n    }\n    try {\n        return value.toString();\n    }\n    catch (_a) {\n        return safeToString(value);\n    }\n}\nexport function stringify(value) {\n    return stringifyInternal(value, [], () => ({ state: 'unknown', value: undefined }));\n}\nexport function possiblyAsyncStringify(value) {\n    const stillPendingMarker = Symbol();\n    const pendingPromisesForCache = [];\n    const cache = new Map();\n    function createDelay0() {\n        let handleId = null;\n        const cancel = () => {\n            if (handleId !== null) {\n                clearTimeout(handleId);\n            }\n        };\n        const delay = new Promise((resolve) => {\n            handleId = setTimeout(() => {\n                handleId = null;\n                resolve(stillPendingMarker);\n            }, 0);\n        });\n        return { delay, cancel };\n    }\n    const unknownState = { state: 'unknown', value: undefined };\n    const getAsyncContent = function getAsyncContent(data) {\n        const cacheKey = data;\n        if (cache.has(cacheKey)) {\n            return cache.get(cacheKey);\n        }\n        const delay0 = createDelay0();\n        const p = asyncToStringMethod in data\n            ? Promise.resolve().then(() => data[asyncToStringMethod]())\n            : data;\n        p.catch(() => { });\n        pendingPromisesForCache.push(Promise.race([p, delay0.delay]).then((successValue) => {\n            if (successValue === stillPendingMarker)\n                cache.set(cacheKey, { state: 'pending', value: undefined });\n            else\n                cache.set(cacheKey, { state: 'fulfilled', value: successValue });\n            delay0.cancel();\n        }, (errorValue) => {\n            cache.set(cacheKey, { state: 'rejected', value: errorValue });\n            delay0.cancel();\n        }));\n        cache.set(cacheKey, unknownState);\n        return unknownState;\n    };\n    function loop() {\n        const stringifiedValue = stringifyInternal(value, [], getAsyncContent);\n        if (pendingPromisesForCache.length === 0) {\n            return stringifiedValue;\n        }\n        return Promise.all(pendingPromisesForCache.splice(0)).then(loop);\n    }\n    return loop();\n}\nexport async function asyncStringify(value) {\n    return Promise.resolve(possiblyAsyncStringify(value));\n}\n","import { urlAlphabet } from './url-alphabet/index.js'\nlet random = bytes => crypto.getRandomValues(new Uint8Array(bytes))\nlet customRandom = (alphabet, defaultSize, getRandom) => {\n  let mask = (2 << (Math.log(alphabet.length - 1) / Math.LN2)) - 1\n  let step = -~((1.6 * mask * defaultSize) / alphabet.length)\n  return (size = defaultSize) => {\n    let id = ''\n    while (true) {\n      let bytes = getRandom(step)\n      let j = step\n      while (j--) {\n        id += alphabet[bytes[j] & mask] || ''\n        if (id.length === size) return id\n      }\n    }\n  }\n}\nlet customAlphabet = (alphabet, size = 21) =>\n  customRandom(alphabet, size, random)\nlet nanoid = (size = 21) =>\n  crypto.getRandomValues(new Uint8Array(size)).reduce((id, byte) => {\n    byte &= 63\n    if (byte < 36) {\n      id += byte.toString(36)\n    } else if (byte < 62) {\n      id += (byte - 26).toString(36).toUpperCase()\n    } else if (byte > 62) {\n      id += '-'\n    } else {\n      id += '_'\n    }\n    return id\n  }, '')\nexport { nanoid, customAlphabet, customRandom, urlAlphabet, random }\n","let urlAlphabet =\n  'useandom-26T198340PX75pxJACKVERYMINDBUSHWOLF_GQZbfghjklqvwyzrict'\nexport { urlAlphabet }\n","import { unsafeUniformArrayIntDistribution } from './UnsafeUniformArrayIntDistribution.js';\nfunction uniformArrayIntDistribution(from, to, rng) {\n    if (rng != null) {\n        var nextRng = rng.clone();\n        return [unsafeUniformArrayIntDistribution(from, to, nextRng), nextRng];\n    }\n    return function (rng) {\n        var nextRng = rng.clone();\n        return [unsafeUniformArrayIntDistribution(from, to, nextRng), nextRng];\n    };\n}\nexport { uniformArrayIntDistribution };\n","import { unsafeUniformBigIntDistribution } from './UnsafeUniformBigIntDistribution.js';\nfunction uniformBigIntDistribution(from, to, rng) {\n    if (rng != null) {\n        var nextRng = rng.clone();\n        return [unsafeUniformBigIntDistribution(from, to, nextRng), nextRng];\n    }\n    return function (rng) {\n        var nextRng = rng.clone();\n        return [unsafeUniformBigIntDistribution(from, to, nextRng), nextRng];\n    };\n}\nexport { uniformBigIntDistribution };\n","import { unsafeUniformIntDistribution } from './UnsafeUniformIntDistribution.js';\nfunction uniformIntDistribution(from, to, rng) {\n    if (rng != null) {\n        var nextRng = rng.clone();\n        return [unsafeUniformIntDistribution(from, to, nextRng), nextRng];\n    }\n    return function (rng) {\n        var nextRng = rng.clone();\n        return [unsafeUniformIntDistribution(from, to, nextRng), nextRng];\n    };\n}\nexport { uniformIntDistribution };\n","import { addArrayIntToNew, addOneToPositiveArrayInt, substractArrayIntToNew, trimArrayIntInplace, } from './internals/ArrayInt.js';\nimport { unsafeUniformArrayIntDistributionInternal } from './internals/UnsafeUniformArrayIntDistributionInternal.js';\nexport function unsafeUniformArrayIntDistribution(from, to, rng) {\n    var rangeSize = trimArrayIntInplace(addOneToPositiveArrayInt(substractArrayIntToNew(to, from)));\n    var emptyArrayIntData = rangeSize.data.slice(0);\n    var g = unsafeUniformArrayIntDistributionInternal(emptyArrayIntData, rangeSize.data, rng);\n    return trimArrayIntInplace(addArrayIntToNew({ sign: 1, data: g }, from));\n}\n","var SBigInt = typeof BigInt !== 'undefined' ? BigInt : undefined;\nexport function unsafeUniformBigIntDistribution(from, to, rng) {\n    var diff = to - from + SBigInt(1);\n    var MinRng = SBigInt(-0x80000000);\n    var NumValues = SBigInt(0x100000000);\n    var FinalNumValues = NumValues;\n    var NumIterations = 1;\n    while (FinalNumValues < diff) {\n        FinalNumValues *= NumValues;\n        ++NumIterations;\n    }\n    var MaxAcceptedRandom = FinalNumValues - (FinalNumValues % diff);\n    while (true) {\n        var value = SBigInt(0);\n        for (var num = 0; num !== NumIterations; ++num) {\n            var out = rng.unsafeNext();\n            value = NumValues * value + (SBigInt(out) - MinRng);\n        }\n        if (value < MaxAcceptedRandom) {\n            var inDiff = value % diff;\n            return inDiff + from;\n        }\n    }\n}\n","import { unsafeUniformIntDistributionInternal } from './internals/UnsafeUniformIntDistributionInternal.js';\nimport { fromNumberToArrayInt64, substractArrayInt64 } from './internals/ArrayInt.js';\nimport { unsafeUniformArrayIntDistributionInternal } from './internals/UnsafeUniformArrayIntDistributionInternal.js';\nvar safeNumberMaxSafeInteger = Number.MAX_SAFE_INTEGER;\nvar sharedA = { sign: 1, data: [0, 0] };\nvar sharedB = { sign: 1, data: [0, 0] };\nvar sharedC = { sign: 1, data: [0, 0] };\nvar sharedData = [0, 0];\nfunction uniformLargeIntInternal(from, to, rangeSize, rng) {\n    var rangeSizeArrayIntValue = rangeSize <= safeNumberMaxSafeInteger\n        ? fromNumberToArrayInt64(sharedC, rangeSize)\n        : substractArrayInt64(sharedC, fromNumberToArrayInt64(sharedA, to), fromNumberToArrayInt64(sharedB, from));\n    if (rangeSizeArrayIntValue.data[1] === 0xffffffff) {\n        rangeSizeArrayIntValue.data[0] += 1;\n        rangeSizeArrayIntValue.data[1] = 0;\n    }\n    else {\n        rangeSizeArrayIntValue.data[1] += 1;\n    }\n    unsafeUniformArrayIntDistributionInternal(sharedData, rangeSizeArrayIntValue.data, rng);\n    return sharedData[0] * 0x100000000 + sharedData[1] + from;\n}\nexport function unsafeUniformIntDistribution(from, to, rng) {\n    var rangeSize = to - from;\n    if (rangeSize <= 0xffffffff) {\n        var g = unsafeUniformIntDistributionInternal(rangeSize + 1, rng);\n        return g + from;\n    }\n    return uniformLargeIntInternal(from, to, rangeSize, rng);\n}\n","export function addArrayIntToNew(arrayIntA, arrayIntB) {\n    if (arrayIntA.sign !== arrayIntB.sign) {\n        return substractArrayIntToNew(arrayIntA, { sign: -arrayIntB.sign, data: arrayIntB.data });\n    }\n    var data = [];\n    var reminder = 0;\n    var dataA = arrayIntA.data;\n    var dataB = arrayIntB.data;\n    for (var indexA = dataA.length - 1, indexB = dataB.length - 1; indexA >= 0 || indexB >= 0; --indexA, --indexB) {\n        var vA = indexA >= 0 ? dataA[indexA] : 0;\n        var vB = indexB >= 0 ? dataB[indexB] : 0;\n        var current = vA + vB + reminder;\n        data.push(current >>> 0);\n        reminder = ~~(current / 0x100000000);\n    }\n    if (reminder !== 0) {\n        data.push(reminder);\n    }\n    return { sign: arrayIntA.sign, data: data.reverse() };\n}\nexport function addOneToPositiveArrayInt(arrayInt) {\n    arrayInt.sign = 1;\n    var data = arrayInt.data;\n    for (var index = data.length - 1; index >= 0; --index) {\n        if (data[index] === 0xffffffff) {\n            data[index] = 0;\n        }\n        else {\n            data[index] += 1;\n            return arrayInt;\n        }\n    }\n    data.unshift(1);\n    return arrayInt;\n}\nfunction isStrictlySmaller(dataA, dataB) {\n    var maxLength = Math.max(dataA.length, dataB.length);\n    for (var index = 0; index < maxLength; ++index) {\n        var indexA = index + dataA.length - maxLength;\n        var indexB = index + dataB.length - maxLength;\n        var vA = indexA >= 0 ? dataA[indexA] : 0;\n        var vB = indexB >= 0 ? dataB[indexB] : 0;\n        if (vA < vB)\n            return true;\n        if (vA > vB)\n            return false;\n    }\n    return false;\n}\nexport function substractArrayIntToNew(arrayIntA, arrayIntB) {\n    if (arrayIntA.sign !== arrayIntB.sign) {\n        return addArrayIntToNew(arrayIntA, { sign: -arrayIntB.sign, data: arrayIntB.data });\n    }\n    var dataA = arrayIntA.data;\n    var dataB = arrayIntB.data;\n    if (isStrictlySmaller(dataA, dataB)) {\n        var out = substractArrayIntToNew(arrayIntB, arrayIntA);\n        out.sign = -out.sign;\n        return out;\n    }\n    var data = [];\n    var reminder = 0;\n    for (var indexA = dataA.length - 1, indexB = dataB.length - 1; indexA >= 0 || indexB >= 0; --indexA, --indexB) {\n        var vA = indexA >= 0 ? dataA[indexA] : 0;\n        var vB = indexB >= 0 ? dataB[indexB] : 0;\n        var current = vA - vB - reminder;\n        data.push(current >>> 0);\n        reminder = current < 0 ? 1 : 0;\n    }\n    return { sign: arrayIntA.sign, data: data.reverse() };\n}\nexport function trimArrayIntInplace(arrayInt) {\n    var data = arrayInt.data;\n    var firstNonZero = 0;\n    for (; firstNonZero !== data.length && data[firstNonZero] === 0; ++firstNonZero) { }\n    if (firstNonZero === data.length) {\n        arrayInt.sign = 1;\n        arrayInt.data = [0];\n        return arrayInt;\n    }\n    data.splice(0, firstNonZero);\n    return arrayInt;\n}\nexport function fromNumberToArrayInt64(out, n) {\n    if (n < 0) {\n        var posN = -n;\n        out.sign = -1;\n        out.data[0] = ~~(posN / 0x100000000);\n        out.data[1] = posN >>> 0;\n    }\n    else {\n        out.sign = 1;\n        out.data[0] = ~~(n / 0x100000000);\n        out.data[1] = n >>> 0;\n    }\n    return out;\n}\nexport function substractArrayInt64(out, arrayIntA, arrayIntB) {\n    var lowA = arrayIntA.data[1];\n    var highA = arrayIntA.data[0];\n    var signA = arrayIntA.sign;\n    var lowB = arrayIntB.data[1];\n    var highB = arrayIntB.data[0];\n    var signB = arrayIntB.sign;\n    out.sign = 1;\n    if (signA === 1 && signB === -1) {\n        var low_1 = lowA + lowB;\n        var high = highA + highB + (low_1 > 0xffffffff ? 1 : 0);\n        out.data[0] = high >>> 0;\n        out.data[1] = low_1 >>> 0;\n        return out;\n    }\n    var lowFirst = lowA;\n    var highFirst = highA;\n    var lowSecond = lowB;\n    var highSecond = highB;\n    if (signA === -1) {\n        lowFirst = lowB;\n        highFirst = highB;\n        lowSecond = lowA;\n        highSecond = highA;\n    }\n    var reminderLow = 0;\n    var low = lowFirst - lowSecond;\n    if (low < 0) {\n        reminderLow = 1;\n        low = low >>> 0;\n    }\n    out.data[0] = highFirst - highSecond - reminderLow;\n    out.data[1] = low;\n    return out;\n}\n","import { unsafeUniformIntDistributionInternal } from './UnsafeUniformIntDistributionInternal.js';\nexport function unsafeUniformArrayIntDistributionInternal(out, rangeSize, rng) {\n    var rangeLength = rangeSize.length;\n    while (true) {\n        for (var index = 0; index !== rangeLength; ++index) {\n            var indexRangeSize = index === 0 ? rangeSize[0] + 1 : 0x100000000;\n            var g = unsafeUniformIntDistributionInternal(indexRangeSize, rng);\n            out[index] = g;\n        }\n        for (var index = 0; index !== rangeLength; ++index) {\n            var current = out[index];\n            var currentInRange = rangeSize[index];\n            if (current < currentInRange) {\n                return out;\n            }\n            else if (current > currentInRange) {\n                break;\n            }\n        }\n    }\n}\n","export function unsafeUniformIntDistributionInternal(rangeSize, rng) {\n    var MaxAllowed = rangeSize > 2 ? ~~(0x100000000 / rangeSize) * rangeSize : 0x100000000;\n    var deltaV = rng.unsafeNext() + 0x80000000;\n    while (deltaV >= MaxAllowed) {\n        deltaV = rng.unsafeNext() + 0x80000000;\n    }\n    return deltaV % rangeSize;\n}\n","var MULTIPLIER = 0x000343fd;\nvar INCREMENT = 0x00269ec3;\nvar MASK = 0xffffffff;\nvar MASK_2 = (1 << 31) - 1;\nvar computeNextSeed = function (seed) {\n    return (seed * MULTIPLIER + INCREMENT) & MASK;\n};\nvar computeValueFromNextSeed = function (nextseed) {\n    return (nextseed & MASK_2) >> 16;\n};\nvar LinearCongruential32 = (function () {\n    function LinearCongruential32(seed) {\n        this.seed = seed;\n    }\n    LinearCongruential32.prototype.clone = function () {\n        return new LinearCongruential32(this.seed);\n    };\n    LinearCongruential32.prototype.next = function () {\n        var nextRng = new LinearCongruential32(this.seed);\n        var out = nextRng.unsafeNext();\n        return [out, nextRng];\n    };\n    LinearCongruential32.prototype.unsafeNext = function () {\n        var s1 = computeNextSeed(this.seed);\n        var v1 = computeValueFromNextSeed(s1);\n        var s2 = computeNextSeed(s1);\n        var v2 = computeValueFromNextSeed(s2);\n        this.seed = computeNextSeed(s2);\n        var v3 = computeValueFromNextSeed(this.seed);\n        var vnext = v3 + ((v2 + (v1 << 15)) << 15);\n        return vnext | 0;\n    };\n    LinearCongruential32.prototype.getState = function () {\n        return [this.seed];\n    };\n    return LinearCongruential32;\n}());\nfunction fromState(state) {\n    var valid = state.length === 1;\n    if (!valid) {\n        throw new Error('The state must have been produced by a congruential32 RandomGenerator');\n    }\n    return new LinearCongruential32(state[0]);\n}\nexport var congruential32 = Object.assign(function (seed) {\n    return new LinearCongruential32(seed);\n}, { fromState: fromState });\n","var __read = (this && this.__read) || function (o, n) {\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\n    if (!m) return o;\n    var i = m.call(o), r, ar = [], e;\n    try {\n        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\n    }\n    catch (error) { e = { error: error }; }\n    finally {\n        try {\n            if (r && !r.done && (m = i[\"return\"])) m.call(i);\n        }\n        finally { if (e) throw e.error; }\n    }\n    return ar;\n};\nvar __spreadArray = (this && this.__spreadArray) || function (to, from, pack) {\n    if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\n        if (ar || !(i in from)) {\n            if (!ar) ar = Array.prototype.slice.call(from, 0, i);\n            ar[i] = from[i];\n        }\n    }\n    return to.concat(ar || Array.prototype.slice.call(from));\n};\nvar MersenneTwister = (function () {\n    function MersenneTwister(states, index) {\n        this.states = states;\n        this.index = index;\n    }\n    MersenneTwister.twist = function (prev) {\n        var mt = prev.slice();\n        for (var idx = 0; idx !== MersenneTwister.N - MersenneTwister.M; ++idx) {\n            var y_1 = (mt[idx] & MersenneTwister.MASK_UPPER) + (mt[idx + 1] & MersenneTwister.MASK_LOWER);\n            mt[idx] = mt[idx + MersenneTwister.M] ^ (y_1 >>> 1) ^ (-(y_1 & 1) & MersenneTwister.A);\n        }\n        for (var idx = MersenneTwister.N - MersenneTwister.M; idx !== MersenneTwister.N - 1; ++idx) {\n            var y_2 = (mt[idx] & MersenneTwister.MASK_UPPER) + (mt[idx + 1] & MersenneTwister.MASK_LOWER);\n            mt[idx] = mt[idx + MersenneTwister.M - MersenneTwister.N] ^ (y_2 >>> 1) ^ (-(y_2 & 1) & MersenneTwister.A);\n        }\n        var y = (mt[MersenneTwister.N - 1] & MersenneTwister.MASK_UPPER) + (mt[0] & MersenneTwister.MASK_LOWER);\n        mt[MersenneTwister.N - 1] = mt[MersenneTwister.M - 1] ^ (y >>> 1) ^ (-(y & 1) & MersenneTwister.A);\n        return mt;\n    };\n    MersenneTwister.seeded = function (seed) {\n        var out = Array(MersenneTwister.N);\n        out[0] = seed;\n        for (var idx = 1; idx !== MersenneTwister.N; ++idx) {\n            var xored = out[idx - 1] ^ (out[idx - 1] >>> 30);\n            out[idx] = (Math.imul(MersenneTwister.F, xored) + idx) | 0;\n        }\n        return out;\n    };\n    MersenneTwister.from = function (seed) {\n        return new MersenneTwister(MersenneTwister.twist(MersenneTwister.seeded(seed)), 0);\n    };\n    MersenneTwister.prototype.clone = function () {\n        return new MersenneTwister(this.states, this.index);\n    };\n    MersenneTwister.prototype.next = function () {\n        var nextRng = new MersenneTwister(this.states, this.index);\n        var out = nextRng.unsafeNext();\n        return [out, nextRng];\n    };\n    MersenneTwister.prototype.unsafeNext = function () {\n        var y = this.states[this.index];\n        y ^= this.states[this.index] >>> MersenneTwister.U;\n        y ^= (y << MersenneTwister.S) & MersenneTwister.B;\n        y ^= (y << MersenneTwister.T) & MersenneTwister.C;\n        y ^= y >>> MersenneTwister.L;\n        if (++this.index >= MersenneTwister.N) {\n            this.states = MersenneTwister.twist(this.states);\n            this.index = 0;\n        }\n        return y;\n    };\n    MersenneTwister.prototype.getState = function () {\n        return __spreadArray([this.index], __read(this.states), false);\n    };\n    MersenneTwister.fromState = function (state) {\n        var valid = state.length === MersenneTwister.N + 1 && state[0] >= 0 && state[0] < MersenneTwister.N;\n        if (!valid) {\n            throw new Error('The state must have been produced by a mersenne RandomGenerator');\n        }\n        return new MersenneTwister(state.slice(1), state[0]);\n    };\n    MersenneTwister.N = 624;\n    MersenneTwister.M = 397;\n    MersenneTwister.R = 31;\n    MersenneTwister.A = 0x9908b0df;\n    MersenneTwister.F = 1812433253;\n    MersenneTwister.U = 11;\n    MersenneTwister.S = 7;\n    MersenneTwister.B = 0x9d2c5680;\n    MersenneTwister.T = 15;\n    MersenneTwister.C = 0xefc60000;\n    MersenneTwister.L = 18;\n    MersenneTwister.MASK_LOWER = Math.pow(2, MersenneTwister.R) - 1;\n    MersenneTwister.MASK_UPPER = Math.pow(2, MersenneTwister.R);\n    return MersenneTwister;\n}());\nfunction fromState(state) {\n    return MersenneTwister.fromState(state);\n}\nexport default Object.assign(function (seed) {\n    return MersenneTwister.from(seed);\n}, { fromState: fromState });\n","export function unsafeGenerateN(rng, num) {\n    var out = [];\n    for (var idx = 0; idx != num; ++idx) {\n        out.push(rng.unsafeNext());\n    }\n    return out;\n}\nexport function generateN(rng, num) {\n    var nextRng = rng.clone();\n    var out = unsafeGenerateN(nextRng, num);\n    return [out, nextRng];\n}\nexport function unsafeSkipN(rng, num) {\n    for (var idx = 0; idx != num; ++idx) {\n        rng.unsafeNext();\n    }\n}\nexport function skipN(rng, num) {\n    var nextRng = rng.clone();\n    unsafeSkipN(nextRng, num);\n    return nextRng;\n}\n","var XorShift128Plus = (function () {\n    function XorShift128Plus(s01, s00, s11, s10) {\n        this.s01 = s01;\n        this.s00 = s00;\n        this.s11 = s11;\n        this.s10 = s10;\n    }\n    XorShift128Plus.prototype.clone = function () {\n        return new XorShift128Plus(this.s01, this.s00, this.s11, this.s10);\n    };\n    XorShift128Plus.prototype.next = function () {\n        var nextRng = new XorShift128Plus(this.s01, this.s00, this.s11, this.s10);\n        var out = nextRng.unsafeNext();\n        return [out, nextRng];\n    };\n    XorShift128Plus.prototype.unsafeNext = function () {\n        var a0 = this.s00 ^ (this.s00 << 23);\n        var a1 = this.s01 ^ ((this.s01 << 23) | (this.s00 >>> 9));\n        var b0 = a0 ^ this.s10 ^ ((a0 >>> 18) | (a1 << 14)) ^ ((this.s10 >>> 5) | (this.s11 << 27));\n        var b1 = a1 ^ this.s11 ^ (a1 >>> 18) ^ (this.s11 >>> 5);\n        var out = (this.s00 + this.s10) | 0;\n        this.s01 = this.s11;\n        this.s00 = this.s10;\n        this.s11 = b1;\n        this.s10 = b0;\n        return out;\n    };\n    XorShift128Plus.prototype.jump = function () {\n        var nextRng = new XorShift128Plus(this.s01, this.s00, this.s11, this.s10);\n        nextRng.unsafeJump();\n        return nextRng;\n    };\n    XorShift128Plus.prototype.unsafeJump = function () {\n        var ns01 = 0;\n        var ns00 = 0;\n        var ns11 = 0;\n        var ns10 = 0;\n        var jump = [0x635d2dff, 0x8a5cd789, 0x5c472f96, 0x121fd215];\n        for (var i = 0; i !== 4; ++i) {\n            for (var mask = 1; mask; mask <<= 1) {\n                if (jump[i] & mask) {\n                    ns01 ^= this.s01;\n                    ns00 ^= this.s00;\n                    ns11 ^= this.s11;\n                    ns10 ^= this.s10;\n                }\n                this.unsafeNext();\n            }\n        }\n        this.s01 = ns01;\n        this.s00 = ns00;\n        this.s11 = ns11;\n        this.s10 = ns10;\n    };\n    XorShift128Plus.prototype.getState = function () {\n        return [this.s01, this.s00, this.s11, this.s10];\n    };\n    return XorShift128Plus;\n}());\nfunction fromState(state) {\n    var valid = state.length === 4;\n    if (!valid) {\n        throw new Error('The state must have been produced by a xorshift128plus RandomGenerator');\n    }\n    return new XorShift128Plus(state[0], state[1], state[2], state[3]);\n}\nexport var xorshift128plus = Object.assign(function (seed) {\n    return new XorShift128Plus(-1, ~seed, seed | 0, 0);\n}, { fromState: fromState });\n","var XoroShiro128Plus = (function () {\n    function XoroShiro128Plus(s01, s00, s11, s10) {\n        this.s01 = s01;\n        this.s00 = s00;\n        this.s11 = s11;\n        this.s10 = s10;\n    }\n    XoroShiro128Plus.prototype.clone = function () {\n        return new XoroShiro128Plus(this.s01, this.s00, this.s11, this.s10);\n    };\n    XoroShiro128Plus.prototype.next = function () {\n        var nextRng = new XoroShiro128Plus(this.s01, this.s00, this.s11, this.s10);\n        var out = nextRng.unsafeNext();\n        return [out, nextRng];\n    };\n    XoroShiro128Plus.prototype.unsafeNext = function () {\n        var out = (this.s00 + this.s10) | 0;\n        var a0 = this.s10 ^ this.s00;\n        var a1 = this.s11 ^ this.s01;\n        var s00 = this.s00;\n        var s01 = this.s01;\n        this.s00 = (s00 << 24) ^ (s01 >>> 8) ^ a0 ^ (a0 << 16);\n        this.s01 = (s01 << 24) ^ (s00 >>> 8) ^ a1 ^ ((a1 << 16) | (a0 >>> 16));\n        this.s10 = (a1 << 5) ^ (a0 >>> 27);\n        this.s11 = (a0 << 5) ^ (a1 >>> 27);\n        return out;\n    };\n    XoroShiro128Plus.prototype.jump = function () {\n        var nextRng = new XoroShiro128Plus(this.s01, this.s00, this.s11, this.s10);\n        nextRng.unsafeJump();\n        return nextRng;\n    };\n    XoroShiro128Plus.prototype.unsafeJump = function () {\n        var ns01 = 0;\n        var ns00 = 0;\n        var ns11 = 0;\n        var ns10 = 0;\n        var jump = [0xd8f554a5, 0xdf900294, 0x4b3201fc, 0x170865df];\n        for (var i = 0; i !== 4; ++i) {\n            for (var mask = 1; mask; mask <<= 1) {\n                if (jump[i] & mask) {\n                    ns01 ^= this.s01;\n                    ns00 ^= this.s00;\n                    ns11 ^= this.s11;\n                    ns10 ^= this.s10;\n                }\n                this.unsafeNext();\n            }\n        }\n        this.s01 = ns01;\n        this.s00 = ns00;\n        this.s11 = ns11;\n        this.s10 = ns10;\n    };\n    XoroShiro128Plus.prototype.getState = function () {\n        return [this.s01, this.s00, this.s11, this.s10];\n    };\n    return XoroShiro128Plus;\n}());\nfunction fromState(state) {\n    var valid = state.length === 4;\n    if (!valid) {\n        throw new Error('The state must have been produced by a xoroshiro128plus RandomGenerator');\n    }\n    return new XoroShiro128Plus(state[0], state[1], state[2], state[3]);\n}\nexport var xoroshiro128plus = Object.assign(function (seed) {\n    return new XoroShiro128Plus(-1, ~seed, seed | 0, 0);\n}, { fromState: fromState });\n","import { generateN, skipN, unsafeGenerateN, unsafeSkipN } from './generator/RandomGenerator.js';\nimport { congruential32 } from './generator/LinearCongruential.js';\nimport mersenne from './generator/MersenneTwister.js';\nimport { xorshift128plus } from './generator/XorShift.js';\nimport { xoroshiro128plus } from './generator/XoroShiro.js';\nimport { uniformArrayIntDistribution } from './distribution/UniformArrayIntDistribution.js';\nimport { uniformBigIntDistribution } from './distribution/UniformBigIntDistribution.js';\nimport { uniformIntDistribution } from './distribution/UniformIntDistribution.js';\nimport { unsafeUniformArrayIntDistribution } from './distribution/UnsafeUniformArrayIntDistribution.js';\nimport { unsafeUniformBigIntDistribution } from './distribution/UnsafeUniformBigIntDistribution.js';\nimport { unsafeUniformIntDistribution } from './distribution/UnsafeUniformIntDistribution.js';\nvar __type = 'module';\nvar __version = '6.1.0';\nvar __commitHash = 'a413dd2b721516be2ef29adffb515c5ae67bfbad';\nexport { __type, __version, __commitHash, generateN, skipN, unsafeGenerateN, unsafeSkipN, congruential32, mersenne, xorshift128plus, xoroshiro128plus, uniformArrayIntDistribution, uniformBigIntDistribution, uniformIntDistribution, unsafeUniformArrayIntDistribution, unsafeUniformBigIntDistribution, unsafeUniformIntDistribution, };\n","import * as prand from './pure-rand-default.js';\nexport default prand;\nexport * from './pure-rand-default.js';\n"],"names":[],"sourceRoot":""}